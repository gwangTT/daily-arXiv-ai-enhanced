{"id": "2508.04917", "pdf": "https://arxiv.org/pdf/2508.04917", "abs": "https://arxiv.org/abs/2508.04917", "authors": ["Atharva Gondhalekar", "Kjetil Haugen", "Thomas Gibson", "Wu-chun Feng"], "title": "Mapping Sparse Triangular Solves to GPUs via Fine-grained Domain Decomposition", "categories": ["cs.PF", "cs.NA", "math.NA", "G.1.3; D.1.3"], "comment": "14 pages, 14 figures", "summary": "Sparse linear systems are typically solved using preconditioned iterative\nmethods, but applying preconditioners via sparse triangular solves introduces\nbottlenecks due to irregular memory accesses and data dependencies. This work\nleverages fine-grained domain decomposition to adapt triangular solves to the\nGPU architecture. We develop a fine-grained domain decomposition strategy that\ngenerates non-overlapping subdomains, increasing parallelism in the application\nof preconditioner at the expense of a modest increase in the iteration count\nfor convergence. Each subdomain is assigned to a thread block and is sized such\nthat the subdomain vector fits in the GPU shared memory, eliminating the need\nfor inter-block synchronization and reducing irregular global memory accesses.\nCompared to other state-of-the-art implementations using the ROCm$^{\\text{TM}}$\nsoftware stack, we achieve a 10.7$\\times$ speedup for triangular solves and a\n3.2$\\times$ speedup for the ILU0-preconditioned biconjugate gradient stabilized\n(BiCGSTAB) solver on the AMD Instinct$^{\\text{TM}}$ MI210 GPU.", "AI": {"tldr": "This paper focuses on optimizing sparse linear systems on GPUs by proposing a fine-grained domain decomposition method which enhances parallelism and memory efficiency, yielding significant speedups.", "motivation": "Sparse linear systems often encounter bottlenecks when using preconditioners due to irregular memory access and data dependency during triangular solves. The goal is to address these limitations in GPU architectures.", "method": "A fine-grained domain decomposition strategy assigns non-overlapping subdomains to thread blocks, with subdomains designed to fit in GPU shared memory, minimizing synchronization issues and irregular global memory accesses.", "result": "The proposed method shows a 10.7\u00d7 speedup for triangular solves and a 3.2\u00d7 speedup for BiCGSTAB solver with ILU0-preconditioners on AMD Instinct MI210 GPU compared to ROCm-state techniques.", "conclusion": "The approach successfully adapts triangular solves for GPUs, boosting solver performance while tolerating a modest increase in convergence iteration count."}}
{"id": "2508.05621", "pdf": "https://arxiv.org/pdf/2508.05621", "abs": "https://arxiv.org/abs/2508.05621", "authors": ["Max Hawkins", "Richard Vuduc"], "title": "Back to Bits: Extending Shannon's communication performance framework to computing", "categories": ["cs.PF", "D.4.8; K.6.2"], "comment": "5 pages, 4 figures", "summary": "This work proposes a novel computing performance unit grounded in information\ntheory. Modern computing systems are increasingly diverse, supporting\nlow-precision formats, hardware specialization, and emerging paradigms such as\nanalog, quantum, and reversible logic. Traditional metrics like floating-point\noperations (flops) no longer accurately capture this complexity. We frame\ncomputing as the transformation of information through a channel and define\nperformance in terms of the mutual information between a system's inputs and\noutputs. This approach measures not just the quantity of data processed, but\nthe amount of meaningful information encoded, manipulated, and retained through\ncomputation. Our framework provides a principled, implementation-agnostic\nfoundation for evaluating performance.", "AI": {"tldr": "The paper introduces a new performance metric based on information theory for diverse modern computing systems, replacing outdated measures like flops.", "motivation": "Traditional metrics for computing systems, such as flops, fail to capture the complexity of emerging computing paradigms like analog, quantum, and reversible logic.", "method": "Performance is redefined as mutual information between inputs and outputs, viewing computing as a channel for transforming information.", "result": "The authors provide a framework that evaluates computing systems by measuring meaningful information encoded and manipulated during computation.", "conclusion": "This novel, implementation-agnostic framework serves as a more accurate and principled method to evaluate computing performance in increasingly diverse systems."}}
{"id": "2508.05266", "pdf": "https://arxiv.org/pdf/2508.05266", "abs": "https://arxiv.org/abs/2508.05266", "authors": ["Jiazheng Zhang", "Cheng Liu", "Huawei Li"], "title": "Understanding and Mitigating Errors of LLM-Generated RTL Code", "categories": ["cs.AR", "cs.CL", "cs.LG"], "comment": "14 pages, 26 figures", "summary": "Despite the promising potential of large language model (LLM) based\nregister-transfer-level (RTL) code generation, the overall success rate remains\nunsatisfactory. Errors arise from various factors, with limited understanding\nof specific failure causes hindering improvement. To address this, we conduct a\ncomprehensive error analysis and manual categorization. Our findings reveal\nthat most errors stem not from LLM reasoning limitations, but from insufficient\nRTL programming knowledge, poor understanding of circuit concepts, ambiguous\ndesign descriptions, or misinterpretation of complex multimodal inputs.\nLeveraging in-context learning, we propose targeted error correction\ntechniques. Specifically, we construct a domain-specific knowledge base and\nemploy retrieval-augmented generation (RAG) to supply necessary RTL knowledge.\nTo mitigate ambiguity errors, we introduce design description rules and\nimplement a rule-checking mechanism. For multimodal misinterpretation, we\nintegrate external tools to convert inputs into LLM-compatible meta-formats.\nFor remaining errors, we adopt an iterative debugging loop (simulation-error\nlocalization-correction). Integrating these techniques into an LLM-based\nframework significantly improves performance. We incorporate these error\ncorrection techniques into a foundational LLM-based RTL code generation\nframework, resulting in significantly improved performance. Experimental\nresults show that our enhanced framework achieves 91.0\\% accuracy on the\nVerilogEval benchmark, surpassing the baseline code generation approach by\n32.7\\%, demonstrating the effectiveness of our methods.", "AI": {"tldr": "This paper analyzes errors in LLM-based RTL code generation and proposes targeted correction techniques, achieving significant accuracy improvements.", "motivation": "LLM-based RTL code generation faces low success rates due to insufficient understanding of error causes, necessitating a detailed analysis and targeted solutions.", "method": "The authors conduct comprehensive error analysis and categorization, use in-context learning, and integrate strategies like retrieval-augmented generation, design rules, meta-format conversion, and iterative debugging to correct errors.", "result": "The proposed framework achieves 91.0% accuracy on the VerilogEval benchmark, representing a 32.7% performance improvement over the baseline method.", "conclusion": "The integration of error correction techniques into an LLM-based RTL framework greatly enhances its performance, highlighting the value of addressing specific error types systematically."}}
{"id": "2508.05354", "pdf": "https://arxiv.org/pdf/2508.05354", "abs": "https://arxiv.org/abs/2508.05354", "authors": ["Michael Rogenmoser", "Angelo Garofalo", "Luca Benini"], "title": "relOBI: A Reliable Low-latency Interconnect for Tightly-Coupled On-chip Communication", "categories": ["cs.AR"], "comment": "2 pages extended abstract, accepted at IIRW 2025", "summary": "On-chip communication is a critical element of modern systems-on-chip (SoCs),\nallowing processor cores to interact with memory and peripherals. Interconnects\nrequire special care in radiation-heavy environments, as any soft error within\nthe SoC interconnect is likely to cause a functional failure of the whole SoC.\nThis work proposes relOBI, an extension to Open Bus Interface (OBI) combining\ntriple modular redundancy (TMR) for critical handshake signals with error\ncorrection codes (ECC) protection on other signals for complete reliability.\nImplementing and testing a fully reliable crossbar shows improved reliability\nto injected faults from a vulnerability of 34.85 % to 0 % compared to a\nreference design, with an area increase of 2.6x and 1.4x timing impact. The\narea overhead is 1.8x lower than that reported in the literature for\nfine-grained triplication and voting.", "AI": {"tldr": "The paper introduces relOBI, improving fault tolerance in SoC interconnects using Triple Modular Redundancy and Error Correction Codes, achieving zero vulnerability with moderate area and timing overhead.", "motivation": "To ensure reliable on-chip communication in radiation-heavy environments, preventing functional failures in SoCs due to interconnect errors.", "method": "The approach integrates Triple Modular Redundancy (TMR) for handshake signals and Error Correction Codes (ECC) for other signals into Open Bus Interface (OBI). A fully reliable crossbar is implemented and tested.", "result": "Fault vulnerability reduced from 34.85% to 0% compared to the reference design. Area increased by 2.6x and timing impact by 1.4x; area overhead was notably lower than fine-grained triplication reported in literature.", "conclusion": "RelOBI effectively enhances reliability in critical interconnects, offering a balanced trade-off between robustness and hardware overhead."}}
{"id": "2508.04799", "pdf": "https://arxiv.org/pdf/2508.04799", "abs": "https://arxiv.org/abs/2508.04799", "authors": ["Michael R. Wartmann", "B. Erik Ydstie"], "title": "Optimality Principles and Neural Ordinary Differential Equations-based Process Modeling for Distributed Control", "categories": ["cs.NE", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": "27 pages, 7 figures", "summary": "Most recent advances in machine learning and analytics for process control\npose the question of how to naturally integrate new data-driven methods with\nclassical process models and control. We propose a process modeling framework\nenabling integration of data-driven algorithms through consistent topological\nproperties and conservation of extensive quantities. Interconnections among\nprocess network units are represented through connectivity matrices and network\ngraphs. We derive the system's natural objective function equivalent to the\nnon-equilibrium entropy production in a steady state system as a driving force\nfor the process dynamics. We illustrate how distributed control and\noptimization can be implemented into process network structures and how control\nlaws and algorithms alter the system's natural equilibrium towards engineered\nobjectives. The basic requirement is that the flow conditions can be expressed\nin terms of conic sector (passivity) conditions. Our formalism allows\nintegration of fundamental conservation properties from topology with learned\ndynamic relations from data through sparse deep neural networks.\n  We demonstrate in a practical example of a simple inventory control system\nhow to integrate the basic topology of a process with a neural network ordinary\ndifferential equation model. The system specific constitutive equations are\nleft undescribed and learned by the neural ordinary differential equation\nalgorithm using the adjoint method in combination with an adaptive ODE solver\nfrom synthetic time-series data. The resulting neural network forms a state\nspace model for use in e.g. a model predictive control algorithm.", "AI": {"tldr": "The paper introduces a framework that blends classical process modeling with data-driven methods, focusing on conservation properties and dynamic relations learned via sparse neural networks.", "motivation": "To address challenges in integrating recent machine learning advances into classical process models and control strategies.", "method": "A framework is developed utilizing topology and conservation properties with neural ordinary differential equations for modeling process dynamics, demonstrated with inventory control systems.", "result": "The framework successfully integrates sparse neural networks with process topology to create a state-space model suitable for model predictive control.", "conclusion": "The proposed approach enables a consistent and scalable integration of data-driven algorithms with classical process models while maintaining fundamental conservation laws."}}
{"id": "2508.04833", "pdf": "https://arxiv.org/pdf/2508.04833", "abs": "https://arxiv.org/abs/2508.04833", "authors": ["Nicolas Nicolaou", "Onyeka Obi", "Aayush Rajasekaran", "Alejandro Bergasov", "Aleksandr Bezobchuk", "Kishori M. Konwar", "Michael Meier", "Santiago Paiva", "Har Preet Singh", "Swarnabha Sinha"], "title": "OPTIMUMP2P: Fast and Reliable Gossiping in P2P Networks", "categories": ["cs.DC", "E.4, C.2.4"], "comment": null, "summary": "Gossip algorithms are pivotal in the dissemination of information within\ndecentralized systems. Consequently, numerous gossip libraries have been\ndeveloped and widely utilized especially in blockchain protocols for the\npropagation of blocks and transactions. A well-established library is libp2p,\nwhich provides two gossip algorithms: floodsup and gossibsup. These algorithms\nenable the delivery of published messages to a set of peers. In this work we\naim to enhance the performance and reliability of libp2p by introducing\nOPTIMUMP2P, a novel gossip algorithm that leverages the capabilities of Random\nLinear Network Coding (RLNC) to expedite the dissemination of information in a\npeer-to-peer (P2P) network while ensuring reliable delivery, even in the\npresence of malicious actors capable of corrupting the transmitted data.\nPreliminary research from the Ethereum Foundation has demonstrated the use of\nRLNC in the significant improvement in the block propagation time [14]. Here we\npresent extensive evaluation results both in simulation and real-world\nenvironments that demonstrate the performance gains of OPTIMUMP2P over the\nGossipsub protocol.", "AI": {"tldr": "The paper introduces OPTIMUMP2P, a gossip algorithm utilizing Random Linear Network Coding (RLNC) to enhance performance and reliability in decentralized systems, outperforming existing libp2p protocols.", "motivation": "To enhance the efficiency and reliability of information dissemination in decentralized systems, particularly blockchain protocols.", "method": "OPTIMUMP2P employs Random Linear Network Coding (RLNC) for faster and reliable message propagation in peer-to-peer networks, overcoming challenges from malicious data corruption.", "result": "Evaluations, both simulated and real-world, indicate that OPTIMUMP2P delivers superior performance compared to the Gossipsub protocol.", "conclusion": "OPTIMUMP2P effectively improves the performance and reliability of libp2p by leveraging RLNC, proving significant potential in decentralized systems."}}
{"id": "2508.04714", "pdf": "https://arxiv.org/pdf/2508.04714", "abs": "https://arxiv.org/abs/2508.04714", "authors": ["Chitranshu Harbola", "Anupam Purwar"], "title": "Prescriptive Agents based on Rag for Automated Maintenance (PARAM)", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "eess.SP"], "comment": null, "summary": "Industrial machinery maintenance requires timely intervention to prevent\ncatastrophic failures and optimize operational efficiency. This paper presents\nan integrated Large Language Model (LLM)-based intelligent system for\nprescriptive maintenance that extends beyond traditional anomaly detection to\nprovide actionable maintenance recommendations. Building upon our prior LAMP\nframework for numerical data analysis, we develop a comprehensive solution that\ncombines bearing vibration frequency analysis with multi agentic generation for\nintelligent maintenance planning. Our approach serializes bearing vibration\ndata (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM\nprocessing, enabling few-shot anomaly detection with high accuracy. The system\nclassifies fault types (inner race, outer race, ball/roller, cage faults) and\nassesses severity levels. A multi-agentic component processes maintenance\nmanuals using vector embeddings and semantic search, while also conducting web\nsearches to retrieve comprehensive procedural knowledge and access up-to-date\nmaintenance practices for more accurate and in-depth recommendations. The\nGemini model then generates structured maintenance recommendations includes\nimmediate actions, inspection checklists, corrective measures, parts\nrequirements, and timeline specifications. Experimental validation in bearing\nvibration datasets demonstrates effective anomaly detection and contextually\nrelevant maintenance guidance. The system successfully bridges the gap between\ncondition monitoring and actionable maintenance planning, providing industrial\npractitioners with intelligent decision support. This work advances the\napplication of LLMs in industrial maintenance, offering a scalable framework\nfor prescriptive maintenance across machinery components and industrial\nsectors.", "AI": {"tldr": "This paper introduces an intelligent prescriptive maintenance system using Large Language Models (LLMs) for analyzing bearing vibration data and generating actionable maintenance recommendations beyond anomaly detection.", "motivation": "To prevent machinery failures, optimize operational efficiency, and address the gap between condition monitoring and actionable maintenance planning.", "method": "The proposed system uses LLMs to process serialized bearing vibration data for anomaly detection and fault classification. Also, it utilizes multi-agentic mechanisms for analyzing maintenance manuals and web retrieval, generating actionable and structured maintenance recommendations.", "result": "Experimental validation shows effective anomaly detection and maintenance guidance for bearings, leveraging advanced integration of LLMs and contextual data processing.", "conclusion": "The approach provides intelligent decision support that scales across industrial components and sectors, advancing the use of LLMs in industrial maintenance."}}
{"id": "2508.04749", "pdf": "https://arxiv.org/pdf/2508.04749", "abs": "https://arxiv.org/abs/2508.04749", "authors": ["Yifan Wang", "Jingyuan Sun", "Jichen Zheng", "Yunhao Zhang", "Chunyu Ye", "Jixing Li", "Chengqing Zong", "Shaonan Wang"], "title": "Bridging Brains and Models: MoE-Based Functional Lesions for Simulating and Rehabilitating Aphasia", "categories": ["q-bio.NC"], "comment": null, "summary": "The striking alignment between large language models (LLMs) and human brain\nactivity positions them as powerful models of healthy cognition. This parallel\nraises a fundamental question: if LLMs can model the intact brain, can we\nlesion them to simulate the linguistic deficits of the injured brain? In this\nwork, we introduce a methodology to model aphasia - a complex language disorder\ncaused by neural injury - by selectively disabling components in a modular\nMixture-of-Experts (MoE) language model. We simulate distinct aphasia subtypes,\nvalidate their linguistic outputs against real patient speech, and then\ninvestigate functional recovery by retraining the model's remaining healthy\nexperts. Our results demonstrate that lesioning functionally-specialized\nexperts for syntax or semantics induces distinct impairments that closely\nresemble Broca's and Wernicke's aphasia, respectively. Crucially, we show that\nfreezing the damaged experts and retraining the intact ones on conversational\ndata restores significant linguistic function, demonstrating a computational\nanalogue for rehabilitation. These findings establish modular LLMs as a\npowerful and clinically-relevant potential framework for modeling the\nmechanisms of language disorders and for computationally exploring novel\npathways for therapy.", "AI": {"tldr": "This paper uses a modular language model to simulate and study language disorders like aphasia by selectively disabling components. They validate these simulations against real patient data and explore the potential for rehabilitation via retraining.", "motivation": "To determine if large language models, which align with human brain activity, can simulate linguistic deficits caused by brain injuries, and to assess their potential for exploring therapeutic pathways.", "method": "The authors selectively disabled components in a modular Mixture-of-Experts language model to simulate subtypes of aphasia, validated the outputs against patient speech data, and tested recovery by retraining intact parts of the model.", "result": "Lesioning functionally-specialized experts produced linguistic impairments mimicking Broca's and Wernicke's aphasia. Retraining intact components on conversational data partially restored language function.", "conclusion": "Modular large language models can effectively simulate language deficits and recovery, offering a useful framework for studying language disorders and potential therapeutic interventions."}}
{"id": "2508.04820", "pdf": "https://arxiv.org/pdf/2508.04820", "abs": "https://arxiv.org/abs/2508.04820", "authors": ["Mayra Sofia Ruiz Rodriguez", "SayedHassan Khatoonabadi", "Emad Shihab"], "title": "Automated File-Level Logging Generation for Machine Learning Applications using LLMs: A Case Study using GPT-4o Mini", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": null, "summary": "Logging is essential in software development, helping developers monitor\nsystem behavior and aiding in debugging applications. Given the ability of\nlarge language models (LLMs) to generate natural language and code, researchers\nare exploring their potential to generate log statements. However, prior work\nfocuses on evaluating logs introduced in code functions, leaving file-level log\ngeneration underexplored -- especially in machine learning (ML) applications,\nwhere comprehensive logging can enhance reliability. In this study, we evaluate\nthe capacity of GPT-4o mini as a case study to generate log statements for ML\nprojects at file level. We gathered a set of 171 ML repositories containing\n4,073 Python files with at least one log statement. We identified and removed\nthe original logs from the files, prompted the LLM to generate logs for them,\nand evaluated both the position of the logs and log level, variables, and text\nquality of the generated logs compared to human-written logs. In addition, we\nmanually analyzed a representative sample of generated logs to identify common\npatterns and challenges. We find that the LLM introduces logs in the same place\nas humans in 63.91% of cases, but at the cost of a high overlogging rate of\n82.66%. Furthermore, our manual analysis reveals challenges for file-level\nlogging, which shows overlogging at the beginning or end of a function,\ndifficulty logging within large code blocks, and misalignment with\nproject-specific logging conventions. While the LLM shows promise for\ngenerating logs for complete files, these limitations remain to be addressed\nfor practical implementation.", "AI": {"tldr": "The study evaluates GPT-4o mini's ability to generate file-level log statements in ML projects, finding high overlogging and challenges with alignment to human conventions.", "motivation": "The study is motivated by the importance of logging in software development, particularly in ML applications, and the underexplored potential of LLMs for file-level log generation.", "method": "The researchers analyzed 4,073 Python files from 171 ML repositories, removed original logs, prompted GPT-4o mini to generate new logs, and compared its outputs with human-written logs based on location, content, and quality. Additionally, a manual review identified patterns and challenges.", "result": "The LLM introduced logs in the same locations as humans 63.91% of the time but exhibited a high overlogging rate of 82.66%. Challenges include excessive logging at function boundaries, difficulty with large code blocks, and poor adaptation to project-specific conventions.", "conclusion": "GPT-4o mini shows potential in logging for complete files but faces significant challenges in practical applications due to issues like overlogging and misalignment with human practices."}}
{"id": "2508.04834", "pdf": "https://arxiv.org/pdf/2508.04834", "abs": "https://arxiv.org/abs/2508.04834", "authors": ["Morten Roed Frederiksen", "Kasper St\u00f8y"], "title": "On the causality between affective impact and coordinated human-robot reactions", "categories": ["cs.RO"], "comment": "7 pages, 5 figures, 29th IEEE International Workshop on Robot and\n  Human Communication (ROMAN)", "summary": "In an effort to improve how robots function in social contexts, this paper\ninvestigates if a robot that actively shares a reaction to an event with a\nhuman alters how the human perceives the robot's affective impact. To verify\nthis, we created two different test setups. One to highlight and isolate the\nreaction element of affective robot expressions, and one to investigate the\neffects of applying specific timing delays to a robot reacting to a physical\nencounter with a human. The first test was conducted with two different groups\n(n=84) of human observers, a test group and a control group both interacting\nwith the robot. The second test was performed with 110 participants using\nincreasingly longer reaction delays for the robot with every ten participants.\nThe results show a statistically significant change (p$<$.05) in perceived\naffective impact for the robots when they react to an event shared with a human\nobserver rather than reacting at random. The result also shows for shared\nphysical interaction, the near-human reaction times from the robot are most\nappropriate for the scenario. The paper concludes that a delay time around\n200ms may render the biggest impact on human observers for small-sized\nnon-humanoid robots. It further concludes that a slightly shorter reaction time\naround 100ms is most effective when the goal is to make the human observers\nfeel they made the biggest impact on the robot.", "AI": {"tldr": "This paper explores how a robot's shared reactions to events and human-like reaction timing affect human perception of the robot's emotional impact.", "motivation": "To enhance robot functionalities in social contexts by investigating the perceived affective impact of shared reactions and precise timing during human-robot interactions.", "method": "Two experiments: (1) testing shared reaction impact (n=84) and (2) evaluating reaction timing effects with progressive delays (n=110).", "result": "Robots that react to events shared with humans rather than randomly create significant affective impact; human-like reaction times (~200ms) are most engaging.", "conclusion": "Around 200ms delays enhance perceived robot affective impact, while 100ms delays maximize perceived human influence on robots in small non-humanoid models."}}
{"id": "2508.04797", "pdf": "https://arxiv.org/pdf/2508.04797", "abs": "https://arxiv.org/abs/2508.04797", "authors": ["Mohab Kishawy", "Ali Abdellatif Hussein", "Jun Chen"], "title": "RetinexDual: Retinex-based Dual Nature Approach for Generalized Ultra-High-Definition Image Restoration", "categories": ["cs.CV"], "comment": null, "summary": "Advancements in image sensing have elevated the importance of\nUltra-High-Definition Image Restoration (UHD IR). Traditional methods, such as\nextreme downsampling or transformation from the spatial to the frequency\ndomain, encounter significant drawbacks: downsampling induces irreversible\ninformation loss in UHD images, while our frequency analysis reveals that pure\nfrequency-domain approaches are ineffective for spatially confined image\nartifacts, primarily due to the loss of degradation locality. To overcome these\nlimitations, we present RetinexDual, a novel Retinex theory-based framework\ndesigned for generalized UHD IR tasks. RetinexDual leverages two complementary\nsub-networks: the Scale-Attentive maMBA (SAMBA) and the Frequency Illumination\nAdaptor (FIA). SAMBA, responsible for correcting the reflectance component,\nutilizes a coarse-to-fine mechanism to overcome the causal modeling of mamba,\nwhich effectively reduces artifacts and restores intricate details. On the\nother hand, FIA ensures precise correction of color and illumination\ndistortions by operating in the frequency domain and leveraging the global\ncontext provided by it. Evaluating RetinexDual on four UHD IR tasks, namely\nderaining, deblurring, dehazing, and Low-Light Image Enhancement (LLIE), shows\nthat it outperforms recent methods qualitatively and quantitatively. Ablation\nstudies demonstrate the importance of employing distinct designs for each\nbranch in RetinexDual, as well as the effectiveness of its various components.", "AI": {"tldr": "RetinexDual is a novel framework based on Retinex theory for Ultra-High-Definition Image Restoration (UHD IR), utilizing SAMBA and FIA sub-networks to address spatial artifacts and global contexts respectively, outperforming existing methods.", "motivation": "Traditional UHD IR methods suffer from irreversible information loss and inefficacy in handling spatially confined image artifacts. This paper introduces RetinexDual to address these challenges and enhance restoration quality.", "method": "RetinexDual comprises SAMBA and FIA sub-networks. SAMBA adopts a coarse-to-fine approach for reflectance correction, while FIA operates in the frequency domain to adjust color and illumination focusing on global context.", "result": "RetinexDual outperformed recent methods qualitatively and quantitatively across four UHD IR tasks: deraining, deblurring, dehazing, and Low-Light Image Enhancement.", "conclusion": "This study establishes RetinexDual as an effective framework for UHD IR tasks, validating its distinct design and components through ablation studies."}}
{"id": "2508.04795", "pdf": "https://arxiv.org/pdf/2508.04795", "abs": "https://arxiv.org/abs/2508.04795", "authors": ["Thomas Thebaud", "Yen-Ju Lu", "Matthew Wiesner", "Peter Viechnicki", "Najim Dehak"], "title": "Enhancing Dialogue Annotation with Speaker Characteristics Leveraging a Frozen LLM", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "comment": "Accepted in the 2025 IEEE Automatic Speech Recognition and\n  Understanding Workshop", "summary": "In dialogue transcription pipelines, Large Language Models (LLMs) are\nfrequently employed in post-processing to improve grammar, punctuation, and\nreadability. We explore a complementary post-processing step: enriching\ntranscribed dialogues by adding metadata tags for speaker characteristics such\nas age, gender, and emotion. Some of the tags are global to the entire\ndialogue, while some are time-variant. Our approach couples frozen audio\nfoundation models, such as Whisper or WavLM, with a frozen LLAMA language model\nto infer these speaker attributes, without requiring task-specific fine-tuning\nof either model. Using lightweight, efficient connectors to bridge audio and\nlanguage representations, we achieve competitive performance on speaker\nprofiling tasks while preserving modularity and speed. Additionally, we\ndemonstrate that a frozen LLAMA model can compare x-vectors directly, achieving\nan Equal Error Rate of 8.8% in some scenarios.", "AI": {"tldr": "This paper explores enriching dialogue transcriptions by tagging speaker traits such as age, gender, and emotion using frozen audio models and an LLAMA model, without fine-tuning.", "motivation": "To enhance the utility of dialogue transcripts by not just improving their readability but also adding valuable metadata about speaker characteristics.", "method": "The approach uses frozen audio foundation models (e.g., Whisper, WavLM) and a frozen LLAMA language model connected via lightweight connectors to infer speaker attributes.", "result": "The proposed method achieves competitive performance in speaker profiling without losing modularity or speed, and also enables comparing x-vectors with an Equal Error Rate of 8.8% in some cases.", "conclusion": "Metadata tagging for speaker profiles can complement traditional transcription pipelines, achieved efficiently without task-specific fine-tuning of models."}}
{"id": "2508.04829", "pdf": "https://arxiv.org/pdf/2508.04829", "abs": "https://arxiv.org/abs/2508.04829", "authors": ["Devora Chait-Roth", "Kedar S. Namjoshi", "Thomas Wies"], "title": "Consistent Updates for Scalable Microservices", "categories": ["cs.PL"], "comment": null, "summary": "Online services are commonly implemented with a scalable microservice\narchitecture, where isomorphic worker processes service client requests,\nrecording persistent state in a backend data store. To maintain service, any\nmodifications to the service functionality must be made on the fly -- i.e., as\nthe service continues to process client requests -- but doing so is\nchallenging. The central difficulty is that of avoiding potential\ninconsistencies caused by ''mixed mode'' operation, where workers of current\nand new versions are concurrently active and interact via the data store. Some\nupdate methods avoid mixed mode altogether, but only at the cost of substantial\ninefficiency -- by doubling resources (memory and compute), or by halving\nthroughput. The alternative is a so-called ''rolling'' update, which is\nuncontrolled and runs the risk of serious service failures arising from\ninconsistent mixed-mode behavior.\n  In this paper, we present the first algorithms that guarantee consistency for\nmixed mode updates. The algorithms rely on semantic properties of service\nactions, such as commutativity. We show that semantic awareness is required, by\nproving that any semantically oblivious, mixed-mode update method cannot avoid\ninconsistencies. Ideally, it should appear to every client that a service\nupdate takes effect atomically; this ensures that a client is not exposed to\ninconsistent mixed-mode behavior. We introduce a framework that formalizes this\nintuition and develop foundational theory for reasoning about the consistency\nof mixed-mode updates, applying that theory to derive the new algorithms and\nestablish their correctness.", "AI": {"tldr": "The paper addresses the challenge of maintaining service consistency during mixed-mode updates in scalable microservice architectures by resolving inconsistencies through novel semantics-based algorithms.", "motivation": "Service updates in microservice architectures must occur dynamically without disrupting existing client requests. However, mixed-mode operations\u2014where different service versions interact\u2014can cause inconsistencies or inefficiencies if not handled properly.", "method": "The proposed approach introduces algorithms that leverage semantic properties of service actions, such as commutativity. The authors prove that semantic-awareness is essential for achieving consistency and develop a formal framework to analyze these updates theoretically, ensuring their correctness.", "result": "The paper establishes foundational theory for consistent mixed-mode updates and derives algorithms guaranteed to handle updates without inconsistencies.", "conclusion": "Semantic-aware update methods are necessary and sufficient to avoid inconsistencies during mixed-mode updates in microservice architectures, offering a more reliable and efficient alternative to existing approaches."}}
{"id": "2508.04800", "pdf": "https://arxiv.org/pdf/2508.04800", "abs": "https://arxiv.org/abs/2508.04800", "authors": ["Yuxuan Tao", "Adel Javanmard"], "title": "Differentially Private Model-X Knockoffs via Johnson-Lindenstrauss Transform", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": "68 pages, 6 figures", "summary": "We introduce a novel privatization framework for high-dimensional controlled\nvariable selection. Our framework enables rigorous False Discovery Rate (FDR)\ncontrol under differential privacy constraints. While the Model-X knockoff\nprocedure provides FDR guarantees by constructing provably exchangeable\n``negative control\" features, existing privacy mechanisms like Laplace or\nGaussian noise injection disrupt its core exchangeability conditions. Our key\ninnovation lies in privatizing the data knockoff matrix through the Gaussian\nJohnson-Lindenstrauss Transformation (JLT), a dimension reduction technique\nthat simultaneously preserves covariate relationships through approximate\nisometry for $(\\epsilon,\\delta)$-differential privacy.\n  We theoretically characterize both FDR and the power of the proposed private\nvariable selection procedure, in an asymptotic regime. Our theoretical analysis\ncharacterizes the role of different factors, such as the JLT's dimension\nreduction ratio, signal-to-noise ratio, differential privacy parameters, sample\nsize and feature dimension, in shaping the privacy-power trade-off. Our\nanalysis is based on a novel `debiasing technique' for high-dimensional private\nknockoff procedure. We further establish sufficient conditions under which the\npower of the proposed procedure converges to one. This work bridges two\ncritical paradigms -- knockoff-based FDR control and private data release --\nenabling reliable variable selection in sensitive domains. Our analysis\ndemonstrates that structural privacy preservation through random projections\noutperforms the classical noise addition mechanism, maintaining statistical\npower even under strict privacy budgets.", "AI": {"tldr": "The paper introduces a novel framework for variable selection that combines False Discovery Rate (FDR) control with differential privacy. It utilizes Gaussian Johnson-Lindenstrauss Transformation (JLT) for data privatization, bypassing limitations of traditional privacy mechanisms.", "motivation": "To address the challenge of rigorous False Discovery Rate (FDR) control in high-dimensional settings while adhering to differential privacy constraints.", "method": "The Gaussian Johnson-Lindenstrauss Transformation (JLT) is used to reduce dimensions and privatize data while preserving covariate relationships. A debiasing technique is applied for the private knockoff procedure.", "result": "The proposed framework provides theoretical guarantees for controlling FDR and maintaining statistical power. Conditions under which the method achieves high power are derived.", "conclusion": "The work bridges knockoff-based FDR control and differential privacy, showing the effectiveness of structural privacy preservation techniques over traditional noise addition mechanisms."}}
{"id": "2508.04731", "pdf": "https://arxiv.org/pdf/2508.04731", "abs": "https://arxiv.org/abs/2508.04731", "authors": ["Shruti Saxena", "Arijit Khan", "Joydeep Chandra"], "title": "NAEx: A Plug-and-Play Framework for Explaining Network Alignment", "categories": ["cs.LG", "cs.IR", "cs.SI"], "comment": null, "summary": "Network alignment (NA) identifies corresponding nodes across multiple\nnetworks, with applications in domains like social networks, co-authorship, and\nbiology. Despite advances in alignment models, their interpretability remains\nlimited, making it difficult to understand alignment decisions and posing\nchallenges in building trust, particularly in high-stakes domains. To address\nthis, we introduce NAEx, a plug-and-play, model-agnostic framework that\nexplains alignment models by identifying key subgraphs and features influencing\npredictions. NAEx addresses the key challenge of preserving the joint\ncross-network dependencies on alignment decisions by: (1) jointly\nparameterizing graph structures and feature spaces through learnable edge and\nfeature masks, and (2) introducing an optimization objective that ensures\nexplanations are both faithful to the original predictions and enable\nmeaningful comparisons of structural and feature-based similarities between\nnetworks. NAEx is an inductive framework that efficiently generates NA\nexplanations for previously unseen data. We introduce evaluation metrics\ntailored to alignment explainability and demonstrate NAEx's effectiveness and\nefficiency on benchmark datasets by integrating it with four representative NA\nmodels.", "AI": {"tldr": "The paper introduces NAEx, a framework for explaining network alignment decisions by focusing on key subgraphs and features, improving interpretability without being model-specific.", "motivation": "To enhance the interpretability of network alignment models, which is crucial in high-stakes domains where understanding alignment decisions is critical.", "method": "NAEx uses learnable edge and feature masks to jointly parameterize graph structures and feature spaces, combined with a tailored optimization objective to ensure faithful and meaningful explanations.", "result": "NAEx generates efficient, interpretable explanations for network alignment models on benchmark datasets, as validated by newly introduced evaluation metrics.", "conclusion": "NAEx successfully addresses the challenge of explaining network alignment models in a model-agnostic and efficient manner, fostering trust and understanding in diverse applications."}}
{"id": "2508.04828", "pdf": "https://arxiv.org/pdf/2508.04828", "abs": "https://arxiv.org/abs/2508.04828", "authors": ["James Winters", "Mathieu Charbonneau"], "title": "Modelling the emergence of open-ended technological evolution", "categories": ["cs.NE", "q-bio.PE", "stat.CO"], "comment": "25 pages, 4 figures, under review at Philosophical Transactions of\n  the Royal Society B, created in Typst", "summary": "Humans stand alone in terms of their potential to collectively and\ncumulatively improve technologies in an open-ended manner. This open-endedness\nprovides societies with the ability to continually expand their resources and\nto increase their capacity to store, transmit and process information at a\ncollective-level. Here, we propose that the production of resources arises from\nthe interaction between technological systems (a society's repertoire of\ninterdependent skills, techniques and artifacts) and search spaces (the\naggregate collection of needs, problems and goals within a society). Starting\nfrom this premise we develop a macro-level model wherein both technological\nsystems and search spaces are subject to cultural evolutionary dynamics. By\nmanipulating the extent to which these dynamics are characterised by stochastic\nor selection-like processes, we demonstrate that open-ended growth is extremely\nrare, historically contingent and only possible when technological systems and\nsearch spaces co-evolve. Here, stochastic factors must be strong enough to\ncontinually perturb the dynamics into a far-from-equilibrium state, whereas\nselection-like factors help maintain effectiveness and ensure the sustained\nproduction of resources. Only when this co-evolutionary dynamic maintains\neffective technological systems, supports the ongoing expansion of the search\nspace and leads to an increased provision of resources do we observe open-ended\ntechnological evolution.", "AI": {"tldr": "The paper explores how open-ended technological evolution is influenced by the interaction between technological systems and societal needs/problems, highlighting the rarity and dependence on co-evolutionary dynamics.", "motivation": "Open-ended technological advancement enables societies to continually expand resources and collective information-processing capabilities, defining human progress.", "method": "The authors develop a macro-level model of cultural evolutionary dynamics involving co-evolving technological systems and societal needs, manipulated by stochastic and selection-like processes.", "result": "Open-ended growth in technological evolution is rare and contingent upon strong stochastic perturbations and selection-like processes to maintain effective dynamics and resource production.", "conclusion": "Co-evolutionary dynamics between technological systems and search spaces are crucial for sustained open-ended technological evolution and resource expansion."}}
{"id": "2508.04870", "pdf": "https://arxiv.org/pdf/2508.04870", "abs": "https://arxiv.org/abs/2508.04870", "authors": ["Khaled Jawhar", "Evangelos Kranakis"], "title": "Linear Search for Capturing an Oblivious Mobile Target in the Sender/Receiver Model", "categories": ["cs.DC"], "comment": null, "summary": "We consider linear search for capturing an oblivious moving target by two\nautonomous robots with different communicating abilities. Both robots can\ncommunicate Face-to-Face (F2F) when co-located but in addition one robot is a\nSender (can also send messages wirelessly) and the other also a Receiver (can\nalso receive messages wirelessly). This is known as Sender/Receiver (S/R, for\nshort) communication model. The robots can move with max speed $1$. The moving\ntarget starts at distance $d$ from the origin and can move either with speed\n$v<1$ away from the origin in the ``away'' model or with speed $v \\geq 0$\ntoward the origin in the ``toward'' model. We assume that the direction of\nmotion of the target (i.e., whether it is the away or toward model) is known to\nthe robots in advance. To capture the target the two robots must be co-located\nwith it.\n  We design new linear search algorithms and analyze the competitive ratio of\nthe time required to capture the target. The approach takes into account\nvarious scenarios related to what the robots know about the search environment\n(e.g., starting distance or speed of the mobile, away or toward model, or a\ncombination thereof). Our study contributes to understanding how asymmetric\ncommunication affects the competitive ratio of linear search.", "AI": {"tldr": "The paper studies how two robots with asymmetric communication capabilities work together to capture a mobile target moving on a linear path using newly designed search algorithms.", "motivation": "The motivation is to investigate the role of asymmetric communication capabilities in improving the efficiency of robotic linear search to capture a mobile target.", "method": "The authors develop linear search algorithms customized for two robots\u2014Sender and Receiver\u2014with distinct communication modes, accounting for different target speeds and movement models.", "result": "Competitive ratios of the time to capture the target under varying scenarios (e.g., target speed, direction) are analyzed, demonstrating how the robots' asymmetric communication impacts efficiency.", "conclusion": "The analysis underscores that asymmetric communication capabilities between robots influence the effectiveness of linear search strategies to capture moving targets."}}
{"id": "2508.04719", "pdf": "https://arxiv.org/pdf/2508.04719", "abs": "https://arxiv.org/abs/2508.04719", "authors": ["Amulya Bhattaram", "Justin Chung", "Stanley Chung", "Ranit Gupta", "Janani Ramamoorthy", "Kartikeya Gullapalli", "Diana Marculescu", "Dimitrios Stamoulis"], "title": "GeoFlow: Agentic Workflow Automation for Geospatial Tasks", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted to ACM SIGSPATIAL 2025", "summary": "We present GeoFlow, a method that automatically generates agentic workflows\nfor geospatial tasks. Unlike prior work that focuses on reasoning decomposition\nand leaves API selection implicit, our method provides each agent with detailed\ntool-calling objectives to guide geospatial API invocation at runtime. GeoFlow\nincreases agentic success by 6.8% and reduces token usage by up to fourfold\nacross major LLM families compared to state-of-the-art approaches.", "AI": {"tldr": "GeoFlow is a method designed to enhance agent-driven workflows for geospatial tasks by optimizing API invocation and improving efficiency.", "motivation": "The paper aims to address challenges in geospatial tasks, specifically improving detailed tool-calling for APIs to enhance agent success.", "method": "GeoFlow provides agents with explicit tool-calling objectives for invoking geospatial APIs, moving beyond reasoning decomposition approaches.", "result": "GeoFlow achieves a 6.8% increase in agentic success and significantly lowers token usage by up to fourfold compared to leading methods.", "conclusion": "GeoFlow demonstrates superior performance in geospatial task workflows, making it a more efficient and effective approach compared to state-of-the-art techniques."}}
{"id": "2508.04824", "pdf": "https://arxiv.org/pdf/2508.04824", "abs": "https://arxiv.org/abs/2508.04824", "authors": ["Paul Triebkorn", "Huifang E. Wang", "Marmaduke Woodman", "Maxime Guye", "Fabrice Bartolomei", "Viktor Jirsa"], "title": "Delay-constrained re-entry governs large-scale brain seizures and other network pathologies", "categories": ["q-bio.NC"], "comment": "26 pages, 15 figures", "summary": "Re-entry of travelling excitation loops is a long-suspected driver of human\nseizures, yet how such loops arise in patient brain networks -- and how\nsusceptible they are to targeted disruption -- remains unclear. We reconstruct\na millimetre-scale virtual brain from diffusion MRI of a drug-resistant\nepilepsy patient, embed excitable Epileptor neural fields, and show that\nrealistic cortico-cortical delays are sufficient to generate self-sustaining\nre-entry. Systematic parameter sweeps reveal a narrow delay-coupling window\nthat predicts oscillation frequency and seizure duration across 184 recorded\nseizures. Precisely timed biphasic stimuli or sub-millimetre virtual lesions\nabort re-entry in silico, yielding phase-dependent termination rules validated\nin intracranial recordings. Our framework exposes delay-constrained re-entry as\na generic dynamical mechanism for large-scale brain synchrony and provides a\npatient-specific testbed for precision neuromodulation and minimally invasive\ndisconnection.", "AI": {"tldr": "The paper investigates how re-entry of excitation loops contributes to seizures using a virtual brain model built from patient data, and identifies strategies for disrupting these loops.", "motivation": "To understand how re-entry of traveling excitation loops arises in patient brain networks during seizures, and their susceptibility to disruption.", "method": "The researchers created a millimetre-scale virtual brain based on diffusion MRI data, embedded neural field models, conducted parameter sweeps, and tested interventions like stimuli and virtual lesions.", "result": "The study identified narrow delay-coupling windows predicting oscillation frequencies and seizure durations, and found phase-dependent interventions that effectively aborted re-entry loops in simulations.", "conclusion": "Delay-constrained re-entry is a fundamental mechanism in large-scale brain synchrony and could guide precision interventions for drug-resistant epilepsy."}}
{"id": "2508.04895", "pdf": "https://arxiv.org/pdf/2508.04895", "abs": "https://arxiv.org/abs/2508.04895", "authors": ["Wentao Lu", "Alexander Senchenko", "Abram Hindle", "Cor-Paul Bezemer"], "title": "Automated Bug Frame Retrieval from Gameplay Videos Using Vision-Language Models", "categories": ["cs.SE"], "comment": null, "summary": "Modern game studios deliver new builds and patches at a rapid pace,\ngenerating thousands of bug reports, many of which embed gameplay videos. To\nverify and triage these bug reports, developers must watch the submitted\nvideos. This manual review is labour-intensive, slow, and hard to scale. In\nthis paper, we introduce an automated pipeline that reduces each video to a\nsingle frame that best matches the reported bug description, giving developers\ninstant visual evidence that pinpoints the bug.\n  Our pipeline begins with FFmpeg for keyframe extraction, reducing each video\nto a median of just 1.90% of its original frames while still capturing bug\nmoments in 98.79 of cases. These keyframes are then evaluated by a\nvision--language model (GPT-4o), which ranks them based on how well they match\nthe textual bug description and selects the most representative frame. We\nevaluated this approach using real-world developer-submitted gameplay videos\nand JIRA bug reports from a popular First-Person Shooter (FPS) game. The\npipeline achieves an overall F1 score of 0.79 and Accuracy of 0.89 for the\ntop-1 retrieved frame. Performance is highest for the Lighting & Shadow (F1 =\n0.94), Physics & Collision (0.86), and UI & HUD (0.83) bug categories, and\nlowest for Animation & VFX (0.51).\n  By replacing video viewing with an immediately informative image, our\napproach dramatically reduces manual effort and speeds up triage and regression\nchecks, offering practical benefits to quality assurance (QA) teams and\ndevelopers across the game industry.", "AI": {"tldr": "The paper proposes an automated system to extract single frames from gameplay videos that match textual bug descriptions for faster bug triage in game development.", "motivation": "The manual process of reviewing gameplay videos for bug verification is labor-intensive, slow, and hard to scale. This creates challenges in rapidly identifying issues reported in bug submissions.", "method": "The pipeline uses FFmpeg for extracting keyframes and employs a vision-language model (GPT-4o) to rank frames based on textual bug descriptions, selecting the most representative frame for developers.", "result": "The system captures bug moments in 98.79% of cases, achieves an F1 score of 0.79 and an accuracy of 0.89 for top-1 frame retrieval, and performs well in most bug categories, with lower performance for Animation & VFX bugs.", "conclusion": "The approach significantly reduces manual effort by providing developers with a single, most relevant frame representative of the bug description, facilitating faster regression checks and triage for game development QA teams."}}
{"id": "2508.04931", "pdf": "https://arxiv.org/pdf/2508.04931", "abs": "https://arxiv.org/abs/2508.04931", "authors": ["Jin Wang", "Weijie Wang", "Boyuan Deng", "Heng Zhang", "Rui Dai", "Nikos Tsagarakis"], "title": "INTENTION: Inferring Tendencies of Humanoid Robot Motion Through Interactive Intuition and Grounded VLM", "categories": ["cs.RO", "cs.AI"], "comment": "Project Web: https://robo-intention.github.io", "summary": "Traditional control and planning for robotic manipulation heavily rely on\nprecise physical models and predefined action sequences. While effective in\nstructured environments, such approaches often fail in real-world scenarios due\nto modeling inaccuracies and struggle to generalize to novel tasks. In\ncontrast, humans intuitively interact with their surroundings, demonstrating\nremarkable adaptability, making efficient decisions through implicit physical\nunderstanding. In this work, we propose INTENTION, a novel framework enabling\nrobots with learned interactive intuition and autonomous manipulation in\ndiverse scenarios, by integrating Vision-Language Models (VLMs) based scene\nreasoning with interaction-driven memory. We introduce Memory Graph to record\nscenes from previous task interactions which embodies human-like understanding\nand decision-making about different tasks in real world. Meanwhile, we design\nan Intuitive Perceptor that extracts physical relations and affordances from\nvisual scenes. Together, these components empower robots to infer appropriate\ninteraction behaviors in new scenes without relying on repetitive instructions.\nVideos: https://robo-intention.github.io", "AI": {"tldr": "The paper introduces INTENTION, a robotics framework combining Vision-Language Models and interaction-driven memory to enable autonomous and adaptable manipulation across diverse tasks.", "motivation": "To address the limitations of robotics relying on precise physical models which fail in real-world scenarios and lack adaptability compared to humans' intuitive interaction abilities.", "method": "The framework integrates Vision-Language Models for scene reasoning and a Memory Graph for recalling previous task interactions. It also includes an Intuitive Perceptor for extracting physical relations and affordances.", "result": "The proposed framework enables robots to infer appropriate behaviors in novel scenes without repetitive instructions.", "conclusion": "INTENTION demonstrates human-like understanding and adaptability in robotic manipulation, paving the way for more versatile and autonomous robotics."}}
{"id": "2508.04801", "pdf": "https://arxiv.org/pdf/2508.04801", "abs": "https://arxiv.org/abs/2508.04801", "authors": ["Trong-Thuan Nguyen", "Viet-Tham Huynh", "Thao Thi Phuong Dao", "Ha Nguyen Thi", "Tien To Vu Thuy", "Uyen Hanh Tran", "Tam V. Nguyen", "Thanh Dinh Le", "Minh-Triet Tran"], "title": "ACM Multimedia Grand Challenge on ENT Endoscopy Analysis", "categories": ["cs.CV"], "comment": null, "summary": "Automated analysis of endoscopic imagery is a critical yet underdeveloped\ncomponent of ENT (ear, nose, and throat) care, hindered by variability in\ndevices and operators, subtle and localized findings, and fine-grained\ndistinctions such as laterality and vocal-fold state. In addition to\nclassification, clinicians require reliable retrieval of similar cases, both\nvisually and through concise textual descriptions. These capabilities are\nrarely supported by existing public benchmarks. To this end, we introduce\nENTRep, the ACM Multimedia 2025 Grand Challenge on ENT endoscopy analysis,\nwhich integrates fine-grained anatomical classification with image-to-image and\ntext-to-image retrieval under bilingual (Vietnamese and English) clinical\nsupervision. Specifically, the dataset comprises expert-annotated images,\nlabeled for anatomical region and normal or abnormal status, and accompanied by\ndual-language narrative descriptions. In addition, we define three benchmark\ntasks, standardize the submission protocol, and evaluate performance on public\nand private test splits using server-side scoring. Moreover, we report results\nfrom the top-performing teams and provide an insight discussion.", "AI": {"tldr": "The paper introduces ENTRap, a benchmark for automated analysis of ENT endoscopy images, supporting bilingual classification and retrieval tasks.", "motivation": "Automated analysis for ENT imagery is underdeveloped due to variability, subtle findings, and fine-grained distinctions. Clinicians need tools for reliable case retrieval and concise descriptions.", "method": "The authors introduce a dataset with expert annotations, dual-language descriptions, and propose benchmarks for anatomical classification and bilingual image and text retrieval.", "result": "They created standards for submissions, evaluated systems with public/private tests, and analyzed top-performing team results.", "conclusion": "ENTRap aims to advance ENT endoscopy analysis by integrating classification and retrieval tasks, enhancing standardization and bilingual accessibility."}}
{"id": "2508.04796", "pdf": "https://arxiv.org/pdf/2508.04796", "abs": "https://arxiv.org/abs/2508.04796", "authors": ["Negar Foroutan", "Clara Meister", "Debjit Paul", "Joel Niklaus", "Sina Ahmadi", "Antoine Bosselut", "Rico Sennrich"], "title": "Parity-Aware Byte-Pair Encoding: Improving Cross-lingual Fairness in Tokenization", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Tokenization is the first -- and often least scrutinized -- step of most NLP\npipelines. Standard algorithms for learning tokenizers rely on frequency-based\nobjectives, which favor languages dominant in the training data and\nconsequently leave lower-resource languages with tokenizations that are\ndisproportionately longer, morphologically implausible, or even riddled with\n<UNK> placeholders. This phenomenon ultimately amplifies computational and\nfinancial inequalities between users from different language backgrounds. To\nremedy this, we introduce Parity-aware Byte Pair Encoding (BPE), a variant of\nthe widely-used BPE algorithm. At every merge step, Parity-aware BPE maximizes\nthe compression gain of the currently worst-compressed language, trading a\nsmall amount of global compression for cross-lingual parity. We find\nempirically that Parity-aware BPE leads to more equitable token counts across\nlanguages, with negligible impact on global compression rate and no substantial\neffect on language-model performance in downstream tasks.", "AI": {"tldr": "The paper introduces Parity-aware Byte Pair Encoding (BPE) to improve tokenization fairness across languages.", "motivation": "Standard tokenization methods disproportionately disadvantage low-resource languages, leading to computational and financial inequalities.", "method": "Parity-aware BPE adjusts tokenization by maximizing compression gain for the worst-compressed language at each merge step, balancing cross-lingual parity.", "result": "Parity-aware BPE results in more equitable token counts without significantly impacting global compression or language model performance.", "conclusion": "The proposed method effectively promotes fairness in tokenization across languages with minimal trade-offs in performance or compression."}}
{"id": "2508.04865", "pdf": "https://arxiv.org/pdf/2508.04865", "abs": "https://arxiv.org/abs/2508.04865", "authors": ["Aleksander Boruch-Gruszecki", "Yangtian Zi", "Zixuan Wu", "Tejas Oberoi", "Carolyn Jane Anderson", "Joydeep Biswas", "Arjun Guha"], "title": "Agnostics: Learning to Code in Any Programming Language via Reinforcement with a Universal Learning Environment", "categories": ["cs.LG", "cs.PL"], "comment": "18 pages, 19 figures. For artifacts, see https://agnostics.abgru.me", "summary": "Large language models (LLMs) already excel at writing code in high-resource\nlanguages such as Python and JavaScript, yet stumble on low-resource languages\nthat remain essential to science and engineering. Besides the obvious shortage\nof pre-training data, post-training itself is a bottleneck: every new language\nseems to require new datasets, test harnesses, and reinforcement-learning (RL)\ninfrastructure.\n  We introduce Agnostics, a language-agnostic post-training pipeline that\neliminates this per-language engineering. The key idea is to judge code solely\nby its externally observable behavior, so a single verifier can test solutions\nwritten in any language. Concretely, we (i) use an LLM to rewrite existing\nunit-test datasets into an I/O format, (ii) supply a short configuration that\ntells the verifier how to compile and run a target language, and (iii) apply\nreinforcement learning with verifiable rewards (RLVR) in a robust code\nexecution environment.\n  Applied to five low-resource languages--Lua, Julia, R, OCaml, and\nFortran--Agnostics (1) improves Qwen-3 4B to performance that rivals other\n16B-70B open-weight models; (2) scales cleanly to larger and diverse model\nfamilies (Qwen-3 8B, DeepSeek Coder 6.7B Instruct, Phi 4 Mini); and (3) for\n${\\le} 16$B parameter models, sets new state-of-the-art pass@1 results on\nMultiPL-E and a new multi-language version LiveCodeBench that we introduce.\n  We will release the language-agnostic training datasets (Ag-MBPP-X,\nAg-Codeforces-X, Ag-LiveCodeBench-X), training code, and ready-to-use\nconfigurations, making RL post-training in any programming language as simple\nas editing a short YAML file.", "AI": {"tldr": "The paper introduces Agnostics, a language-agnostic post-training pipeline for improving large language models' performance in low-resource programming languages using reinforcement learning and universal verifiers.", "motivation": "LLMs struggle with low-resource programming languages, which are crucial for science and engineering, due to limited pre-training data and per-language post-training requirements.", "method": "Agnostics uses a pipeline involving I/O-based unit test conversion, language compilation configuration, and reinforcement learning with verifiable rewards to evaluate code based on externally observable behavior.", "result": "Agnostics enhances the performance of LLMs like Qwen-3, achieving state-of-the-art results in several low-resource languages and enabling scalable adaptations across different models.", "conclusion": "Agnostics simplifies RL post-training for any programming language, providing datasets, codes, and configurations for broader accessibility and efficiency."}}
{"id": "2508.04884", "pdf": "https://arxiv.org/pdf/2508.04884", "abs": "https://arxiv.org/abs/2508.04884", "authors": ["Leo Zhang"], "title": "The Cosine Schedule is Fisher-Rao-Optimal for Masked Discrete Diffusion Models", "categories": ["stat.ML", "cs.LG"], "comment": "Preprint", "summary": "In this work, we study the problem of choosing the discretisation schedule\nfor sampling from masked discrete diffusion models in terms of the information\ngeometry of the induced probability path. Specifically, we show that the\noptimal schedule under the Fisher-Rao geometry recovers the popularly-used\ncosine schedule.", "AI": {"tldr": "The research gives theoretical backing to the use of cosine scheduling for discrete diffusion models using information geometry principles.", "motivation": "To optimize discretization schedules for sampling from masked discrete diffusion models through a geometric perspective.", "method": "Investigating discretization schedules using the Fisher-Rao geometry of the probability path.", "result": "Demonstrated that the cosine schedule aligns with the optimal schedule derived from the Fisher-Rao geometry.", "conclusion": "Validates the cosine schedule as optimal for masked discrete diffusion models under Fisher-Rao geometry, providing theoretical support for its widespread use."}}
{"id": "2508.04732", "pdf": "https://arxiv.org/pdf/2508.04732", "abs": "https://arxiv.org/abs/2508.04732", "authors": ["Xiaoqi Dong", "Xiangyu Zhou", "Nicholas Evans", "Yujia Lin"], "title": "LumiGen: An LVLM-Enhanced Iterative Framework for Fine-Grained Text-to-Image Generation", "categories": ["cs.LG", "cs.GR"], "comment": null, "summary": "Text-to-Image (T2I) generation has made significant advancements with\ndiffusion models, yet challenges persist in handling complex instructions,\nensuring fine-grained content control, and maintaining deep semantic\nconsistency. Existing T2I models often struggle with tasks like accurate text\nrendering, precise pose generation, or intricate compositional coherence.\nConcurrently, Vision-Language Models (LVLMs) have demonstrated powerful\ncapabilities in cross-modal understanding and instruction following. We propose\nLumiGen, a novel LVLM-enhanced iterative framework designed to elevate T2I\nmodel performance, particularly in areas requiring fine-grained control,\nthrough a closed-loop, LVLM-driven feedback mechanism. LumiGen comprises an\nIntelligent Prompt Parsing & Augmentation (IPPA) module for proactive prompt\nenhancement and an Iterative Visual Feedback & Refinement (IVFR) module, which\nacts as a \"visual critic\" to iteratively correct and optimize generated images.\nEvaluated on the challenging LongBench-T2I Benchmark, LumiGen achieves a\nsuperior average score of 3.08, outperforming state-of-the-art baselines.\nNotably, our framework demonstrates significant improvements in critical\ndimensions such as text rendering and pose expression, validating the\neffectiveness of LVLM integration for more controllable and higher-quality\nimage generation.", "AI": {"tldr": "LumiGen improves Text-to-Image (T2I) generation through Vision-Language Model (LVLM) integration for control and quality, featuring iterative refinement mechanisms.", "motivation": "Enhance T2I generation to address limitations in content control, semantic consistency, and handling intricate instructions.", "method": "Proposed LumiGen, combining Intelligent Prompt Parsing & Augmentation (IPPA) and Iterative Visual Feedback & Refinement (IVFR) modules for iterative improvement.", "result": "LumiGen achieves state-of-the-art performance on LongBench-T2I Benchmark with notable advancements in text rendering and pose expression.", "conclusion": "LVLM integration in LumiGen is effective for achieving controllable, high-quality T2I generation and addressing existing challenges."}}
{"id": "2508.05341", "pdf": "https://arxiv.org/pdf/2508.05341", "abs": "https://arxiv.org/abs/2508.05341", "authors": ["Mariia Sorokina"], "title": "Harmonic fractal transformation for modeling complex neuronal effects: from bursting and noise shaping to waveform sensitivity and noise-induced subthreshold spiking", "categories": ["q-bio.NC", "cs.LG", "cs.NE"], "comment": null, "summary": "We propose the first fractal frequency mapping, which in a simple form\nenables to replicate complex neuronal effects. Unlike the conventional filters,\nwhich suppress or amplify the input spectral components according to the filter\nweights, the transformation excites novel components by a fractal recomposition\nof the input spectra resulting in a formation of spikes at resonant frequencies\nthat are optimal for sampling. This enables high sensitivity detection,\nrobustness to noise and noise-induced signal amplification. The proposed model\nillustrates that a neuronal functionality can be viewed as a linear summation\nof spectrum over nonlinearly transformed frequency domain.", "AI": {"tldr": "The paper introduces a fractal frequency mapping method that replicates complex neuronal effects, differing from conventional filters.", "motivation": "The motivation of the study is to better understand complex neuronal functionalities using a novel spectral approach that excites new frequency components, instead of merely suppressing or amplifying them.", "method": "The authors propose a fractal recomposition of input spectra, forming spikes at resonant frequencies, which provides a nonlinear transformation of the frequency domain.", "result": "The method achieves high sensitivity detection and robustness to noise while amplifying signals induced by noise.", "conclusion": "The study suggests neuronal functionalities can be viewed as the linear summation of spectrum over nonlinearly transformed frequency domains, demonstrating the impact of fractal frequency mapping."}}
{"id": "2508.04944", "pdf": "https://arxiv.org/pdf/2508.04944", "abs": "https://arxiv.org/abs/2508.04944", "authors": ["Craig Barnes", "Kyle Burton", "Michael S. Fitzsimons", "Hara Prasad Juvvala", "Brienna Larrick", "Christopher Meyer", "Pauline Ribeyre", "Ao Liu", "Clint Malson", "Noah Metoki-Shlubsky", "Andrii Prokhorenkov", "Jawad Qureshi", "Radhika Reddy", "L. Philip Schumm", "Mingfei Shao", "Trevar Simmons", "Alexander VanTol", "Peter Vassilatos", "Aarti Venkat", "Robert L. Grossman"], "title": "Managing, Analyzing and Sharing Research Data with Gen3 Data Commons", "categories": ["cs.DC"], "comment": "20 pages, 9 figures", "summary": "Gen3 is an open-source data platform for building data commons. A data\ncommons is a cloud-based data platform for managing, analyzing, and sharing\ndata with a research community. Gen3 has been used to build over a dozen data\ncommons that in aggregate contain over 28 PB of data and 64 million FAIR data\nobjects. To set up a Gen3 data commons, you first define a data model. Gen3\nthen autogenerates 1) a data portal for searching and exploring data in the\ncommons; 2) a data portal for submitting data to the commons; and 3) FAIR APIs\nfor accessing the data programmatically. Gen3 is built over a small number of\nstandards-based software services, which are designed to support current and\nfuture Gen3 components so that Gen3 can interoperate with other data platforms\nand data ecosystems.", "AI": {"tldr": "Gen3 is an open-source platform for building data commons, providing features for managing, analyzing, and sharing research data, equipped with autogenerated tools for portals and APIs.", "motivation": "The paper is motivated by the need to develop a scalable and efficient platform to manage, analyze, and share research data within communities, supporting FAIR principles.", "method": "The Gen3 platform implements a defined data model to automatically generate tools like data portals for exploration and submission, and FAIR APIs for programmatic data access.", "result": "Gen3 has successfully been used to create over a dozen data commons aggregating 28 PB of data and 64 million FAIR data objects.", "conclusion": "Gen3 establishes itself as a scalable and interoperable solution for organizing and sharing research data while aligning with standards to ensure future compatibility with external platforms."}}
{"id": "2508.04720", "pdf": "https://arxiv.org/pdf/2508.04720", "abs": "https://arxiv.org/abs/2508.04720", "authors": ["Yingjie Zhou", "Jiezhang Cao", "Farong Wen", "Li Xu", "Yanwei Jiang", "Jun Jia", "Ronghui Li", "Xiaohong Liu", "Yu Zhou", "Xiongkuo Min", "Jie Guo", "Zicheng Zhang", "Guangtao Zhai"], "title": "Who is a Better Player: LLM against LLM", "categories": ["cs.AI"], "comment": null, "summary": "Adversarial board games, as a paradigmatic domain of strategic reasoning and\nintelligence, have long served as both a popular competitive activity and a\nbenchmark for evaluating artificial intelligence (AI) systems. Building on this\nfoundation, we propose an adversarial benchmarking framework to assess the\ncomprehensive performance of Large Language Models (LLMs) through board games\ncompetition, compensating the limitation of data dependency of the mainstream\nQuestion-and-Answer (Q&A) based benchmark method. We introduce Qi Town, a\nspecialized evaluation platform that supports 5 widely played games and\ninvolves 20 LLM-driven players. The platform employs both the Elo rating system\nand a novel Performance Loop Graph (PLG) to quantitatively evaluate the\ntechnical capabilities of LLMs, while also capturing Positive Sentiment Score\n(PSS) throughout gameplay to assess mental fitness. The evaluation is\nstructured as a round-robin tournament, enabling systematic comparison across\nplayers. Experimental results indicate that, despite technical differences,\nmost LLMs remain optimistic about winning and losing, demonstrating greater\nadaptability to high-stress adversarial environments than humans. On the other\nhand, the complex relationship between cyclic wins and losses in PLGs exposes\nthe instability of LLMs' skill play during games, warranting further\nexplanation and exploration.", "AI": {"tldr": "This paper introduces Qi Town, an adversarial evaluation framework that assesses the performance of Large Language Models (LLMs) through competitive board games, using metrics like Elo rating, Performance Loop Graph (PLG), and Positive Sentiment Score (PSS).", "motivation": "The motivation is to address the limitations of traditional Q&A benchmarks for assessing LLMs by offering a more comprehensive evaluation through the framework of adversarial board games.", "method": "The authors developed Qi Town, a platform supporting 5 board games and 20 LLM-driven players. They utilize Elo ratings for skill evaluation, PLG for analyzing cyclic skill fluctuations, and PSS for gauging mental fitness during competition.", "result": "The study found that LLMs generally exhibit optimism in high-stress environments but demonstrate instability in gameplay skills, as revealed by PLG analyses.", "conclusion": "While LLMs show adaptability and optimism during adversarial challenges, the inconsistencies in gameplay performance highlight areas that need further investigation for enhancing strategic reasoning."}}
{"id": "2508.05288", "pdf": "https://arxiv.org/pdf/2508.05288", "abs": "https://arxiv.org/abs/2508.05288", "authors": ["Xuanyu Shen", "Yu Hu"], "title": "Covariance spectrum in nonlinear recurrent neural networks", "categories": ["q-bio.NC", "nlin.CD"], "comment": "33 pages, 9 figures", "summary": "Advances in simultaneous recordings of large numbers of neurons have driven\nsignificant interest in the structure of neural population activity such as\ndimension. A key question is how these dynamic features arise mechanistically\nand their relationship to circuit connectivity. It was previously proposed to\nuse the covariance eigenvalue distribution, or spectrum, which can be\nanalytically derived in random recurrent networks, as a robust measure to\ndescribe the shape of neural population activity beyond the dimension (Hu and\nSompolinsky 2022). Applications of the theoretical spectrum have broadly found\naccurate matches to experimental data across brain areas providing mechanistic\ninsights into the observed low dimensional population dynamics (Morales et al.\n2023). However, the empirical success highlights a gap in theory, as the neural\nnetwork model used to derive the spectrum was minimal with linear neurons. In\nthis work, we aim to close this gap by studying the covariance spectrum in\nnetworks with nonlinear neurons and under broader dynamical regimes including\nchaos. Surprisingly, we found that the spectrum can be precisely understood by\nequations analogous to the linear theory substituted with an effective\nrecurrent connection strength parameter, that reflects both the connection\nweights and the nonlinearity of neurons. Across dynamical regimes, this\neffective connection strength provides a unified interpretation for the\nspectrum and dimension changes, and stays near the critical value in the\nchaotic regime without fine-tuning. These results further our understanding of\nnonlinear neural population dynamics and provide additional theoretical support\nfor applying the covariance spectrum analysis in biological circuits.", "AI": {"tldr": "The paper explores covariance spectrum as a tool to understand nonlinear neural population dynamics across various dynamical regimes, extending previous theoretical insights achieved with minimal linear neuronal models.", "motivation": "To bridge the gap in theory regarding covariance eigenvalue distributions in nonlinear neural networks and chaotic regimes, since previous approaches relied on minimal linear models.", "method": "The authors extend the analysis of covariance spectra, incorporating nonlinear neurons and broader dynamical regimes like chaos, while using an effective recurrent connection strength parameter.", "result": "The covariance spectrum can be precisely described using equations similar to linear theory but adjusted with an effective connection strength, offering unified insights into dynamical changes and maintaining a critical value without fine-tuning in chaotic regimes.", "conclusion": "The findings reinforce the applicability of covariance spectrum analysis to biological circuits, advancing theoretical understanding of nonlinear neural population dynamics."}}
{"id": "2508.04921", "pdf": "https://arxiv.org/pdf/2508.04921", "abs": "https://arxiv.org/abs/2508.04921", "authors": ["Zixuan Feng", "Reed Milewicz", "Emerson Murphy-Hill", "Tyler Menezes", "Alexander Serebrenik", "Igor Steinmacher", "Anita Sarma"], "title": "Charting Uncertain Waters: A Socio-Technical Framework for Navigating GenAI's Impact on Open Source Communities", "categories": ["cs.SE"], "comment": "13 pages, 1 figure", "summary": "Open Source Software communities face a wave of uncertainty as Generative AI\nrapidly transforms how software is created, maintained, and governed. Without\nclear frameworks, communities risk being overwhelmed by the complexity and\nambiguity introduced by GenAI, threatening the collaborative ethos that\nunderpins OSS. We conduct a scenario-driven, conceptual exploration using a\nsocio-technical framework inspired by McLuhan's Tetrad to surface both risks\nand opportunities for community resilience amid GenAI-driven disruption of OSS\ndevelopment across four domains: software practices, documentation, community\nengagement, and governance. By adopting this lens, OSS leaders and researchers\ncan proactively shape the future of their ecosystems, rather than simply\nreacting to technological upheaval.", "AI": {"tldr": "The paper explores how Generative AI impacts open-source software (OSS) through risks and opportunities in areas like development, documentation, engagement, and governance.", "motivation": "To address the uncertainty and potential risks that Generative AI introduces to Open Source Software (OSS) and provide a way for communities to adapt constructively.", "method": "A conceptual exploration using McLuhan's Tetrad socio-technical framework, applied to scenario-driven analysis across four OSS domains: practices, documentation, governance, and community engagement.", "result": "This approach identified risks and opportunities in OSS development and highlighted strategies for community resilience to GenAI-driven disruptions.", "conclusion": "By applying the socio-technical framework proactively, OSS leaders can better manage and adapt their ecosystems amidst Generative AI-induced changes."}}
{"id": "2508.04981", "pdf": "https://arxiv.org/pdf/2508.04981", "abs": "https://arxiv.org/abs/2508.04981", "authors": ["Tianyuan Zheng", "Jingang Yi", "Kaiyan Yu"], "title": "Optimal Planning for Multi-Robot Simultaneous Area and Line Coverage Using Hierarchical Cyclic Merging Regulation", "categories": ["cs.RO"], "comment": null, "summary": "The double coverage problem focuses on determining efficient, collision-free\nroutes for multiple robots to simultaneously cover linear features (e.g.,\nsurface cracks or road routes) and survey areas (e.g., parking lots or local\nregions) in known environments. In these problems, each robot carries two\nfunctional roles: service (linear feature footprint coverage) and exploration\n(complete area coverage). Service has a smaller operational footprint but\nincurs higher costs (e.g., time) compared to exploration. We present optimal\nplanning algorithms for the double coverage problems using hierarchical cyclic\nmerging regulation (HCMR). To reduce the complexity for optimal planning\nsolutions, we analyze the manifold attachment process during graph traversal\nfrom a Morse theory perspective. We show that solutions satisfying minimum path\nlength and collision-free constraints must belong to a Morse-bounded\ncollection. To identify this collection, we introduce the HCMR algorithm. In\nHCMR, cyclic merging search regulates traversal behavior, while edge sequence\nback propagation converts these regulations into graph edge traversal\nsequences. Incorporating balanced partitioning, the optimal sequence is\nselected to generate routes for each robot. We prove the optimality of the HCMR\nalgorithm under a fixed sweep direction. The multi-robot simulation results\ndemonstrate that the HCMR algorithm significantly improves planned path length\nby at least 10.0%, reduces task time by at least 16.9% in average, and ensures\nconflict-free operation compared to other state-of-the-art planning methods.", "AI": {"tldr": "The paper addresses the challenge of creating efficient, collision-free robot routes for covering both linear features and larger areas, proposing the HCMR algorithm.", "motivation": "To develop an optimal planning solution for robots tasked with simultaneous linear feature coverage and area exploration in known environments.", "method": "A hierarchical cyclic merging regulation (HCMR) algorithm is introduced, supported by a Morse theory-based analysis to regulate traversal behavior and generate optimal routes.", "result": "Simulation results indicate at least a 10.0% improvement in path length, a 16.9% reduction in task time, and successful conflict-free operations compared to existing methods.", "conclusion": "The HCMR algorithm effectively achieves optimal, cost-efficient, and collision-free robot operation, surpassing existing planning methods in performance."}}
{"id": "2508.04816", "pdf": "https://arxiv.org/pdf/2508.04816", "abs": "https://arxiv.org/abs/2508.04816", "authors": ["Sriram Mandalika", "Lalitha V"], "title": "CoMAD: A Multiple-Teacher Self-Supervised Distillation Framework", "categories": ["cs.CV", "cs.AI"], "comment": "8 Pages, 2 Figures", "summary": "Numerous self-supervised learning paradigms, such as contrastive learning and\nmasked image modeling, learn powerful representations from unlabeled data but\nare typically pretrained in isolation, overlooking complementary insights and\nyielding large models that are impractical for resource-constrained deployment.\nTo overcome these challenges, we introduce Consensus-oriented Masked\nDistillation (CoMAD), a lightweight, parameter-free framework that unifies\nknowledge from multiple current state-of-the-art self-supervised Vision\nTransformers into a compact student network. CoMAD distills from three\npretrained ViT-Base teachers, MAE, MoCo v3, and iBOT, each offering distinct\nsemantic and contextual priors. Rather than naively averaging teacher outputs,\nwe apply asymmetric masking: the student sees only 25 percent of patches while\neach teacher receives a progressively lighter, unique mask, forcing the student\nto interpolate missing features under richer contexts. Teacher embeddings are\naligned to the student's space via a linear adapter and layer normalization,\nthen fused through our joint consensus gating, which weights each token by\ncombining cosine affinity with inter-teacher agreement. The student is trained\nwith dual-level KL divergence on visible tokens and reconstructed feature maps,\ncapturing both local and global structure. On ImageNet-1K, CoMAD's ViT-Tiny\nachieves 75.4 percent Top-1, an increment of 0.4 percent over the previous\nstate-of-the-art. In dense-prediction transfers, it attains 47.3 percent mIoU\non ADE20K, and 44.5 percent box average precision and 40.5 percent mask average\nprecision on MS-COCO, establishing a new state-of-the-art in compact SSL\ndistillation.", "AI": {"tldr": "CoMAD is a lightweight framework unifying knowledge from multiple self-supervised ViT embeddings into a compact student model, achieving state-of-the-art performance in compact distillation.", "motivation": "Self-supervised learning methods like Masked Image Modeling and Contrastive Learning produce powerful representations but are computationally expensive and trained in isolation, limiting their practical use in resource-constrained environments.", "method": "CoMAD unifies knowledge from three pretrained ViT-Base teachers using asymmetric patch masking, linear adapter alignment, consensus gating, and KL divergence training for effective distillation into a compact student network.", "result": "CoMAD's ViT-Tiny achieves 75.4 percent Top-1 accuracy on ImageNet-1K, outperforming prior compact SSL distillation methods. It also sets benchmarks in dense-prediction tasks like ADE20K and MS-COCO.", "conclusion": "CoMAD demonstrates effective integration of complementary insights from self-supervised ViT models, offering resource-efficient solutions without sacrificing performance in both classification and dense-prediction tasks."}}
{"id": "2508.04814", "pdf": "https://arxiv.org/pdf/2508.04814", "abs": "https://arxiv.org/abs/2508.04814", "authors": ["David Sasu", "Natalie Schluter"], "title": "Pitch Accent Detection improves Pretrained Automatic Speech Recognition", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "We show the performance of Automatic Speech Recognition (ASR) systems that\nuse semi-supervised speech representations can be boosted by a complimentary\npitch accent detection module, by introducing a joint ASR and pitch accent\ndetection model. The pitch accent detection component of our model achieves a\nsignificant improvement on the state-of-the-art for the task, closing the gap\nin F1-score by 41%. Additionally, the ASR performance in joint training\ndecreases WER by 28.3% on LibriSpeech, under limited resource fine-tuning. With\nthese results, we show the importance of extending pretrained speech models to\nretain or re-learn important prosodic cues such as pitch accent.", "AI": {"tldr": "The study improves ASR systems by integrating a pitch accent detection module, showing significant enhancements in both tasks.", "motivation": "To enhance ASR performance by leveraging prosodic cues, such as pitch accent, which are not fully utilized by current pre-trained speech models.", "method": "Introduced a joint model combining ASR and pitch accent detection, improving both tasks via semi-supervised speech representations and fine-tuning.", "result": "The model achieved a 41% improvement in F1-score for pitch accent detection and a 28.3% WER reduction for ASR on the LibriSpeech dataset.", "conclusion": "Extending pretrained speech models to include prosodic features like pitch accent significantly boosts both ASR and pitch detection capabilities."}}
{"id": "2508.05212", "pdf": "https://arxiv.org/pdf/2508.05212", "abs": "https://arxiv.org/abs/2508.05212", "authors": ["Ziliang Shen", "Caixing Wang", "Shaoli Wang", "Yibo Yan"], "title": "High-Dimensional Differentially Private Quantile Regression: Distributed Estimation and Statistical Inference", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "With the development of big data and machine learning, privacy concerns have\nbecome increasingly critical, especially when handling heterogeneous datasets\ncontaining sensitive personal information. Differential privacy provides a\nrigorous framework for safeguarding individual privacy while enabling\nmeaningful statistical analysis. In this paper, we propose a differentially\nprivate quantile regression method for high-dimensional data in a distributed\nsetting. Quantile regression is a powerful and robust tool for modeling the\nrelationships between the covariates and responses in the presence of outliers\nor heavy-tailed distributions. To address the computational challenges due to\nthe non-smoothness of the quantile loss function, we introduce a Newton-type\ntransformation that reformulates the quantile regression task into an ordinary\nleast squares problem. Building on this, we develop a differentially private\nestimation algorithm with iterative updates, ensuring both near-optimal\nstatistical accuracy and formal privacy guarantees. For inference, we further\npropose a differentially private debiased estimator, which enables valid\nconfidence interval construction and hypothesis testing. Additionally, we\npropose a communication-efficient and differentially private bootstrap for\nsimultaneous hypothesis testing in high-dimensional quantile regression,\nsuitable for distributed settings with both small and abundant local data.\nExtensive simulations demonstrate the robustness and effectiveness of our\nmethods in practical scenarios.", "AI": {"tldr": "The paper introduces a differentially private quantile regression method for high-dimensional distributed data, addressing privacy concerns while enabling statistical analysis.", "motivation": "There is a need to ensure privacy in machine learning models, especially when analyzing heterogeneous datasets containing sensitive personal information.", "method": "The paper reformulates the quantile regression problem using a Newton-type transformation and develops iterative estimation and inference techniques. It also includes communication-efficient bootstrapping for distributed settings.", "result": "The proposed methods ensure near-optimal statistical accuracy, formal privacy guarantees, and effective hypothesis testing in high-dimensional data settings.", "conclusion": "The techniques presented are robust, efficient, and practically applicable, balancing privacy and accuracy in distributed data analysis."}}
{"id": "2508.04740", "pdf": "https://arxiv.org/pdf/2508.04740", "abs": "https://arxiv.org/abs/2508.04740", "authors": ["Youran Zhou", "Mohamed Reda Bouadjenek", "Sunil Aryal"], "title": "MissMecha: An All-in-One Python Package for Studying Missing Data Mechanisms", "categories": ["cs.LG", "cs.MS"], "comment": null, "summary": "Incomplete data is a persistent challenge in real-world datasets, often\ngoverned by complex and unobservable missing mechanisms. Simulating missingness\nhas become a standard approach for understanding its impact on learning and\nanalysis. However, existing tools are fragmented, mechanism-limited, and\ntypically focus only on numerical variables, overlooking the heterogeneous\nnature of real-world tabular data. We present MissMecha, an open-source Python\ntoolkit for simulating, visualizing, and evaluating missing data under MCAR,\nMAR, and MNAR assumptions. MissMecha supports both numerical and categorical\nfeatures, enabling mechanism-aware studies across mixed-type tabular datasets.\nIt includes visual diagnostics, MCAR testing utilities, and type-aware\nimputation evaluation metrics. Designed to support data quality research,\nbenchmarking, and education,MissMecha offers a unified platform for researchers\nand practitioners working with incomplete data.", "AI": {"tldr": "MissMecha is a Python toolkit addressing missing data in tabular datasets by simulating and evaluating under different assumptions.", "motivation": "The paper aims to tackle the challenge of incomplete data in real-world datasets and provide better tools for understanding and analyzing its impact.", "method": "MissMecha uses simulation, visual diagnostics, MCAR testing, and type-aware evaluation to handle missing data under MCAR, MAR, and MNAR assumptions.", "result": "MissMecha supports numerical and categorical data, provides easy diagnostics, and improves researchers' ability to evaluate and benchmark missing data studies.", "conclusion": "MissMecha is positioned as a comprehensive tool for researchers and practitioners dealing with heterogeneous tabular datasets containing missing data."}}
{"id": "2508.05416", "pdf": "https://arxiv.org/pdf/2508.05416", "abs": "https://arxiv.org/abs/2508.05416", "authors": ["Mansi Sharma", "Enrico Sartor", "Marc Cavazza", "Helmut Prendinger"], "title": "Echo State Networks for Bitcoin Time Series Prediction", "categories": ["cs.LG", "cs.CE", "cs.NE"], "comment": null, "summary": "Forecasting stock and cryptocurrency prices is challenging due to high\nvolatility and non-stationarity, influenced by factors like economic changes\nand market sentiment. Previous research shows that Echo State Networks (ESNs)\ncan effectively model short-term stock market movements, capturing nonlinear\npatterns in dynamic data. To the best of our knowledge, this work is among the\nfirst to explore ESNs for cryptocurrency forecasting, especially during extreme\nvolatility. We also conduct chaos analysis through the Lyapunov exponent in\nchaotic periods and show that our approach outperforms existing machine\nlearning methods by a significant margin. Our findings are consistent with the\nLyapunov exponent analysis, showing that ESNs are robust during chaotic periods\nand excel under high chaos compared to Boosting and Na\\\"ive methods.", "AI": {"tldr": "The paper explores using Echo State Networks (ESNs) for forecasting stock and cryptocurrency prices, especially during volatile, chaotic market conditions, and shows superior performance compared to other methods.", "motivation": "The highly volatile and non-stationary nature of stock and cryptocurrency prices makes forecasting challenging, requiring advanced techniques to handle such complexity.", "method": "The authors applied Echo State Networks (ESNs) and used chaos analysis via the Lyapunov exponent to examine dynamics during chaotic periods. They compared ESNs' performance against existing machine learning methods like Boosting and Naive methods.", "result": "The study found that ESNs outperform other machine learning models during chaotic market conditions, demonstrating robustness and accuracy under high chaos.", "conclusion": "ESNs are effective tools for forecasting in volatile and chaotic markets, outperforming traditional methods and exhibiting robustness that aligns with chaos analysis findings."}}
{"id": "2508.04953", "pdf": "https://arxiv.org/pdf/2508.04953", "abs": "https://arxiv.org/abs/2508.04953", "authors": ["Song Bian", "Saurabh Agarwal", "Md. Tareq Mahmood", "Shivaram Venkataraman"], "title": "Tesserae: Scalable Placement Policies for Deep Learning Workloads", "categories": ["cs.DC", "cs.AI"], "comment": "16 pages, 18 figures", "summary": "Training deep learning (DL) models has become a dominant workload in\ndata-centers and improving resource utilization is a key goal of DL cluster\nschedulers. In order to do this, schedulers typically incorporate placement\npolicies that govern where jobs are placed on the cluster. Existing placement\npolicies are either designed as ad-hoc heuristics or incorporated as\nconstraints within a complex optimization problem and thus either suffer from\nsuboptimal performance or poor scalability. Our key insight is that many\nplacement constraints can be formulated as graph matching problems and based on\nthat we design novel placement policies for minimizing job migration overheads\nand job packing. We integrate these policies into Tesserae and describe how our\ndesign leads to a scalable and effective GPU cluster scheduler. Our\nexperimental results show that Tesserae improves average JCT by up to 1.62x and\nthe Makespan by up to 1.15x compared with the existing schedulers.", "AI": {"tldr": "The paper introduces Tesserae, a scalable and efficient GPU cluster scheduler that leverages graph matching-based placement policies, achieving significant performance improvements.", "motivation": "Improving resource utilization in data centers, particularly in DL cluster schedulers, through better job placement policies.", "method": "The paper proposes designing placement policies based on graph matching problems to optimize job migration overheads and job packing, integrating these policies into Tesserae.", "result": "Tesserae demonstrated improved performance metrics, achieving up to 1.62x better average Job Completion Time (JCT) and up to 1.15x improvement in Makespan compared to existing schedulers.", "conclusion": "Graph matching-based placement policies are effective and scalable, and their integration into Tesserae significantly enhances GPU cluster scheduling performance."}}
{"id": "2508.04846", "pdf": "https://arxiv.org/pdf/2508.04846", "abs": "https://arxiv.org/abs/2508.04846", "authors": ["Mahdi Nazari Ashani", "Ali Asghar Alesheikh", "Saba Kazemi", "Kimya Kheirkhah", "Yasin Mohammadi", "Fatemeh Rezaie", "Amir Mahdi Manafi", "Hedieh Zarkesh"], "title": "Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Autonomous web-based geographical information systems (AWebGIS) aim to\nperform geospatial operations from natural language input, providing intuitive,\nintelligent, and hands-free interaction. However, most current solutions rely\non cloud-based large language models (LLMs), which require continuous internet\naccess and raise users' privacy and scalability issues due to centralized\nserver processing. This study compares three approaches to enabling AWebGIS:\n(1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2)\na semi-automated offline method using classical machine learning classifiers\nsuch as support vector machine and random forest; and (3) a fully autonomous\noffline (client-side) method based on a fine-tuned small language model (SLM),\nspecifically T5-small model, executed in the client's web browser. The third\napproach, which leverages SLMs, achieved the highest accuracy among all\nmethods, with an exact matching accuracy of 0.93, Levenshtein similarity of\n0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L\nscores of 0.98. Crucially, this client-side computation strategy reduces the\nload on backend servers by offloading processing to the user's device,\neliminating the need for server-based inference. These results highlight the\nfeasibility of browser-executable models for AWebGIS solutions.", "AI": {"tldr": "This paper evaluates three methods for enabling autonomous web-based GIS, focusing on client-side small language models, achieving high accuracy and eliminating server reliance.", "motivation": "The paper addresses the need for intuitive, private, and scalable autonomous geographical information systems by overcoming reliance on cloud-based models.", "method": "Three approaches are compared: cloud-based LLMs, semi-automated classical machine learning classifiers, and offline client-side small language models fine-tuned for use in browsers.", "result": "Client-side small language models, specifically a fine-tuned T5-small model, demonstrated the highest accuracy (e.g., exact matching: 0.93, ROUGE-1: 0.98) and eliminated backend dependencies.", "conclusion": "Client-side browser-executable models are a viable and efficient solution for AWebGIS, providing high accuracy while addressing privacy and scalability issues."}}
{"id": "2508.04925", "pdf": "https://arxiv.org/pdf/2508.04925", "abs": "https://arxiv.org/abs/2508.04925", "authors": ["Sigma Jahan", "Saurabh Singh Rajput", "Tushar Sharma", "Mohammad Masudur Rahman"], "title": "Taxonomy of Faults in Attention-Based Neural Networks", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Attention mechanisms are at the core of modern neural architectures, powering\nsystems ranging from ChatGPT to autonomous vehicles and driving a major\neconomic impact. However, high-profile failures, such as ChatGPT's nonsensical\noutputs or Google's suspension of Gemini's image generation due to attention\nweight errors, highlight a critical gap: existing deep learning fault\ntaxonomies might not adequately capture the unique failures introduced by\nattention mechanisms. This gap leaves practitioners without actionable\ndiagnostic guidance. To address this gap, we present the first comprehensive\nempirical study of faults in attention-based neural networks (ABNNs). Our work\nis based on a systematic analysis of 555 real-world faults collected from 96\nprojects across ten frameworks, including GitHub, Hugging Face, and Stack\nOverflow. Through our analysis, we develop a novel taxonomy comprising seven\nattention-specific fault categories, not captured by existing work. Our results\nshow that over half of the ABNN faults arise from mechanisms unique to\nattention architectures. We further analyze the root causes and manifestations\nof these faults through various symptoms. Finally, by analyzing symptom-root\ncause associations, we identify four evidence-based diagnostic heuristics that\nexplain 33.0% of attention-specific faults, offering the first systematic\ndiagnostic guidance for attention-based models.", "AI": {"tldr": "This paper investigates faults in attention-based neural networks (ABNNs), introduces a novel taxonomy of seven fault categories, and provides diagnostic heuristics for practitioners.", "motivation": "To address the gap in understanding and diagnosing the unique failures arising in attention mechanisms, as existing fault taxonomies fall short.", "method": "A systematic analysis of 555 real-world faults in ABNNs from 96 projects across ten frameworks, followed by the development of a fault taxonomy and evidence-based heuristics.", "result": "The study identifies seven unique fault categories specific to attention mechanisms, links root causes to symptoms, and suggests four diagnostic heuristics explaining 33% of these faults.", "conclusion": "This work fills a critical gap by providing actionable diagnostic guidance for attention-based models, enhancing reliability and understanding of attention mechanisms."}}
{"id": "2508.04994", "pdf": "https://arxiv.org/pdf/2508.04994", "abs": "https://arxiv.org/abs/2508.04994", "authors": ["Wenjie Hu", "Ye Zhou", "Hann Woei Ho"], "title": "Hierarchical Deep Deterministic Policy Gradient for Autonomous Maze Navigation of Mobile Robots", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Maze navigation is a fundamental challenge in robotics, requiring agents to\ntraverse complex environments efficiently. While the Deep Deterministic Policy\nGradient (DDPG) algorithm excels in control tasks, its performance in maze\nnavigation suffers from sparse rewards, inefficient exploration, and\nlong-horizon planning difficulties, often leading to low success rates and\naverage rewards, sometimes even failing to achieve effective navigation. To\naddress these limitations, this paper proposes an efficient Hierarchical DDPG\n(HDDPG) algorithm, which includes high-level and low-level policies. The\nhigh-level policy employs an advanced DDPG framework to generate intermediate\nsubgoals from a long-term perspective and on a higher temporal scale. The\nlow-level policy, also powered by the improved DDPG algorithm, generates\nprimitive actions by observing current states and following the subgoal\nassigned by the high-level policy. The proposed method enhances stability with\noff-policy correction, refining subgoal assignments by relabeling historical\nexperiences. Additionally, adaptive parameter space noise is utilized to\nimprove exploration, and a reshaped intrinsic-extrinsic reward function is\nemployed to boost learning efficiency. Further optimizations, including\ngradient clipping and Xavier initialization, are employed to improve\nrobustness. The proposed algorithm is rigorously evaluated through numerical\nsimulation experiments executed using the Robot Operating System (ROS) and\nGazebo. Regarding the three distinct final targets in autonomous maze\nnavigation tasks, HDDPG significantly overcomes the limitations of standard\nDDPG and its variants, improving the success rate by at least 56.59% and\nboosting the average reward by a minimum of 519.03 compared to baseline\nalgorithms.", "AI": {"tldr": "The paper introduces a Hierarchical DDPG (HDDPG) algorithm to address challenges in maze navigation, notably sparse rewards and inefficient exploration.", "motivation": "To improve the performance of the DDPG algorithm for autonomous maze navigation, addressing issues like sparse rewards and long-horizon planning difficulties.", "method": "The HDDPG algorithm employs high-level subgoal generation and low-level primitive action planning, using refined experience relabeling, adaptive parameter space noise, and a reshaped reward function for enhanced stability and exploration.", "result": "HDDPG improved maze navigation success rates by at least 56.59% and average rewards by a minimum of 519.03 compared to baseline approaches.", "conclusion": "The HDDPG algorithm significantly enhances the capabilities of DDPG for complex maze navigation tasks, presenting a robust solution to its limitations."}}
{"id": "2508.04818", "pdf": "https://arxiv.org/pdf/2508.04818", "abs": "https://arxiv.org/abs/2508.04818", "authors": ["Mehrdad Moradi", "Marco Grasso", "Bianca Maria Colosimo", "Kamran Paynabar"], "title": "Single-Step Reconstruction-Free Anomaly Detection and Segmentation via Diffusion Models", "categories": ["cs.CV", "eess.IV", "stat.ML", "62H35, 68T07, 62M40, 68T45", "I.2.6; I.2.10; I.4.6; I.4.8; I.5.1; I.5.4"], "comment": "9 pages, 8 figures, 2 tables. Submitted to an IEEE conference", "summary": "Generative models have demonstrated significant success in anomaly detection\nand segmentation over the past decade. Recently, diffusion models have emerged\nas a powerful alternative, outperforming previous approaches such as GANs and\nVAEs. In typical diffusion-based anomaly detection, a model is trained on\nnormal data, and during inference, anomalous images are perturbed to a\npredefined intermediate step in the forward diffusion process. The\ncorresponding normal image is then reconstructed through iterative reverse\nsampling.\n  However, reconstruction-based approaches present three major challenges: (1)\nthe reconstruction process is computationally expensive due to multiple\nsampling steps, making real-time applications impractical; (2) for complex or\nsubtle patterns, the reconstructed image may correspond to a different normal\npattern rather than the original input; and (3) Choosing an appropriate\nintermediate noise level is challenging because it is application-dependent and\noften assumes prior knowledge of anomalies, an assumption that does not hold in\nunsupervised settings.\n  We introduce Reconstruction-free Anomaly Detection with Attention-based\ndiffusion models in Real-time (RADAR), which overcomes the limitations of\nreconstruction-based anomaly detection. Unlike current SOTA methods that\nreconstruct the input image, RADAR directly produces anomaly maps from the\ndiffusion model, improving both detection accuracy and computational\nefficiency. We evaluate RADAR on real-world 3D-printed material and the\nMVTec-AD dataset. Our approach surpasses state-of-the-art diffusion-based and\nstatistical machine learning models across all key metrics, including accuracy,\nprecision, recall, and F1 score. Specifically, RADAR improves F1 score by 7% on\nMVTec-AD and 13% on the 3D-printed material dataset compared to the next best\nmodel.\n  Code available at: https://github.com/mehrdadmoradi124/RADAR", "AI": {"tldr": "RADAR outperforms existing anomaly detection methods by utilizing attention-based diffusion models for direct anomaly mapping, achieving better accuracy, computational efficiency, and F1 scores.", "motivation": "Existing reconstruction-based anomaly detection methods using diffusion models are computationally expensive, struggle with subtle patterns, and lack adaptability to application-specific noise levels.", "method": "RADAR uses attention-based diffusion models to directly generate anomaly maps, eliminating the need for an iterative reconstruction process and leveraging attention mechanisms for improved accuracy.", "result": "RADAR surpasses state-of-the-art methods in accuracy, precision, recall, and F1 score, with a 7% improvement in F1 score for MVTec-AD and 13% for 3D-printed materials datasets.", "conclusion": "RADAR presents a significant advancement in real-time anomaly detection, addressing limitations in reconstruction-based approaches and delivering superior performance metrics."}}
{"id": "2508.04826", "pdf": "https://arxiv.org/pdf/2508.04826", "abs": "https://arxiv.org/abs/2508.04826", "authors": ["Tommaso Tosato", "Saskia Helbling", "Yorguin-Jose Mantilla-Ramos", "Mahmood Hegazy", "Alberto Tosato", "David John Lemay", "Irina Rish", "Guillaume Dumas"], "title": "Persistent Instability in LLM's Personality Measurements: Effects of Scale, Reasoning, and Conversation History", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models require consistent behavioral patterns for safe\ndeployment, yet their personality-like traits remain poorly understood. We\npresent PERSIST (PERsonality Stability in Synthetic Text), a comprehensive\nevaluation framework testing 25+ open-source models (1B-671B parameters) across\n500,000+ responses. Using traditional (BFI-44, SD3) and novel LLM-adapted\npersonality instruments, we systematically vary question order, paraphrasing,\npersonas, and reasoning modes. Our findings challenge fundamental deployment\nassumptions: (1) Even 400B+ models exhibit substantial response variability (SD\n> 0.4); (2) Minor prompt reordering alone shifts personality measurements by up\nto 20%; (3) Interventions expected to stabilize behavior, such as\nchain-of-thought reasoning, detailed personas instruction, inclusion of\nconversation history, can paradoxically increase variability; (4) LLM-adapted\ninstruments show equal instability to human-centric versions, confirming\narchitectural rather than translational limitations. This persistent\ninstability across scales and mitigation strategies suggests current LLMs lack\nthe foundations for genuine behavioral consistency. For safety-critical\napplications requiring predictable behavior, these findings indicate that\npersonality-based alignment strategies may be fundamentally inadequate.", "AI": {"tldr": "Current large language models are unstable in personality-like traits, even with interventions, and lack consistent behavior required for safety-critical applications.", "motivation": "Understanding personality-like traits in large language models to ensure safe deployment and behavioral consistency.", "method": "Developed a framework (PERSIST) testing over 25 models with 500,000+ responses using traditional and LLM-specific personality tests, varying prompts and reasoning setups.", "result": "Identified substantial variabilities in model responses, challenges in stabilizing behavior, and limitations in existing personality alignment strategies.", "conclusion": "Current large language models are not suitable for applications requiring consistent, predictable behavior due to inherent architectural limitations."}}
{"id": "2508.05567", "pdf": "https://arxiv.org/pdf/2508.05567", "abs": "https://arxiv.org/abs/2508.05567", "authors": ["Bingfan Liu", "Peijun Sang"], "title": "L1-Regularized Functional Support Vector Machine", "categories": ["stat.ML", "cs.LG", "stat.CO"], "comment": null, "summary": "In functional data analysis, binary classification with one functional\ncovariate has been extensively studied. We aim to fill in the gap of\nconsidering multivariate functional covariates in classification. In\nparticular, we propose an $L_1$-regularized functional support vector machine\nfor binary classification. An accompanying algorithm is developed to fit the\nclassifier. By imposing an $L_1$ penalty, the algorithm enables us to identify\nrelevant functional covariates of the binary response. Numerical results from\nsimulations and one real-world application demonstrate that the proposed\nclassifier enjoys good performance in both prediction and feature selection.", "AI": {"tldr": "The paper proposes an $L_1$-regularized functional support vector machine for binary classification with multivariate functional covariates.", "motivation": "There is a gap in binary classification research focused on functional data when dealing with multiple covariates.", "method": "An $L_1$-regularized functional support vector machine is developed alongside an algorithm for classification and covariate selection.", "result": "Simulations and real-world application validate its effectiveness in prediction and feature selection.", "conclusion": "The proposed approach improves classification accuracy while identifying relevant covariates."}}
{"id": "2508.04745", "pdf": "https://arxiv.org/pdf/2508.04745", "abs": "https://arxiv.org/abs/2508.04745", "authors": ["Nan Li", "Wanting Yang", "Marie Siew", "Zehui Xiong", "Binbin Chen", "Shiwen Mao", "Kwok-Yan Lam"], "title": "Edge-Assisted Collaborative Fine-Tuning for Multi-User Personalized Artificial Intelligence Generated Content (AIGC)", "categories": ["cs.LG"], "comment": null, "summary": "Diffusion models (DMs) have emerged as powerful tools for high-quality\ncontent generation, yet their intensive computational requirements for\ninference pose challenges for resource-constrained edge devices. Cloud-based\nsolutions aid in computation but often fall short in addressing privacy risks,\npersonalization efficiency, and communication costs in multi-user edge-AIGC\nscenarios. To bridge this gap, we first analyze existing edge-AIGC applications\nin personalized content synthesis, revealing their limitations in efficiency\nand scalability. We then propose a novel cluster-aware hierarchical federated\naggregation framework. Based on parameter-efficient local fine-tuning via\nLow-Rank Adaptation (LoRA), the framework first clusters clients based on the\nsimilarity of their uploaded task requirements, followed by an intra-cluster\naggregation for enhanced personalization at the server-side. Subsequently, an\ninter-cluster knowledge interaction paradigm is implemented to enable\nhybrid-style content generation across diverse clusters.Building upon federated\nlearning (FL) collaboration, our framework simultaneously trains personalized\nmodels for individual users at the devices and a shared global model enhanced\nwith multiple LoRA adapters on the server,enabling efficient edge inference;\nmeanwhile, all prompts for clustering and inference are encoded prior to\ntransmission, thereby further mitigating the risk of plaintext leakage. Our\nevaluations demonstrate that the framework achieves accelerated convergence\nwhile maintaining practical viability for scalable multi-user personalized AIGC\nservices under edge constraints.", "AI": {"tldr": "The paper proposes a federated learning framework to enable efficient, privacy-conscious, and scalable diffusion models for generating personalized content on resource-limited edge devices.", "motivation": "High-quality content generation using diffusion models is hindered by their high computational requirements, which are unsuitable for edge devices. Current cloud-based solutions compromise on privacy, scalability, and communication in multi-user scenarios.", "method": "The paper introduces a hierarchical federated learning framework incorporating Low-Rank Adaptation (LoRA). It clusters clients based on task similarities for intra-cluster aggregation and facilitates inter-cluster interactions for hybrid content generation. Prompts are securely encoded to ensure privacy.", "result": "The suggested framework achieves faster convergence and is viable for multi-user personalized content generation on edge devices, addressing efficiency and scalability under resource constraints.", "conclusion": "The proposed approach successfully bridges the efficiency, privacy, and scalability gaps in personalized AIGC applications for edge devices, making it practical for real-world scenarios."}}
{"id": "2508.05433", "pdf": "https://arxiv.org/pdf/2508.05433", "abs": "https://arxiv.org/abs/2508.05433", "authors": ["Qinglong Hu", "Xialiang Tong", "Mingxuan Yuan", "Fei Liu", "Zhichao Lu", "Qingfu Zhang"], "title": "Discovering Interpretable Programmatic Policies via Multimodal LLM-assisted Evolutionary Search", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "Interpretability and high performance are essential goals in designing\ncontrol policies, particularly for safety-critical tasks. Deep reinforcement\nlearning has greatly enhanced performance, yet its inherent lack of\ninterpretability often undermines trust and hinders real-world deployment. This\nwork addresses these dual challenges by introducing a novel approach for\nprogrammatic policy discovery, called Multimodal Large Language Model-assisted\nEvolutionary Search (MLES). MLES utilizes multimodal large language models as\npolicy generators, combining them with evolutionary mechanisms for automatic\npolicy optimization. It integrates visual feedback-driven behavior analysis\nwithin the policy generation process to identify failure patterns and\nfacilitate targeted improvements, enhancing the efficiency of policy discovery\nand producing adaptable, human-aligned policies. Experimental results show that\nMLES achieves policy discovery capabilities and efficiency comparable to\nProximal Policy Optimization (PPO) across two control tasks, while offering\ntransparent control logic and traceable design processes. This paradigm\novercomes the limitations of predefined domain-specific languages, facilitates\nknowledge transfer and reuse, and is scalable across various control tasks.\nMLES shows promise as a leading approach for the next generation of\ninterpretable control policy discovery.", "AI": {"tldr": "This paper introduces MLES (Multimodal Large Language Model-assisted Evolutionary Search), a novel interpretable and high-performing method for policy discovery combining large language models and evolutionary mechanisms.", "motivation": "To address the lack of interpretability in deep reinforcement learning, which hinders trust and real-world deployment, while retaining high performance in control tasks.", "method": "The authors propose MLES, which combines multimodal large language models with evolutionary search for policy optimization. It also incorporates visual feedback-driven behavior analysis to identify failure patterns and improve policies.", "result": "Experimental results show that MLES achieves efficiency and policy discovery capabilities comparable to Proximal Policy Optimization (PPO) across two control tasks, while providing transparent and traceable processes.", "conclusion": "MLES overcomes predefined language limitations, enables reusable knowledge transfer, and scales across control tasks, presenting itself as a promising approach for interpretable and adaptable control policy discovery."}}
{"id": "2508.05020", "pdf": "https://arxiv.org/pdf/2508.05020", "abs": "https://arxiv.org/abs/2508.05020", "authors": ["Anjiang Wei", "Hang Song", "Mert Hidayetoglu", "Elliott Slaughter", "Sanjiva K. Lele", "Alex Aiken"], "title": "Task-Based Programming for Adaptive Mesh Refinement in Compressible Flow Simulations", "categories": ["cs.DC", "cs.CE", "cs.MS"], "comment": null, "summary": "High-order solvers for compressible flows are vital in scientific\napplications. Adaptive mesh refinement (AMR) is a key technique for reducing\ncomputational cost by concentrating resolution in regions of interest. In this\nwork, we develop an AMR-based numerical solver using Regent, a high-level\nprogramming language for the Legion programming model. We address several\nchallenges associated with implementing AMR in Regent. These include dynamic\ndata structures for patch refinement/coarsening, mesh validity enforcement, and\nreducing task launch overhead via task fusion. Experimental results show that\ntask fusion achieves 18x speedup, while automated GPU kernel generation via\nsimple annotations yields 9.7x speedup for the targeted kernel. We demonstrate\nour approach through simulations of two canonical compressible flow problems\ngoverned by the Euler equations.", "AI": {"tldr": "This paper presents an AMR-based numerical solver for compressible flows in Regent, achieving significant speedups through task fusion and GPU kernel optimization.", "motivation": "To improve computational efficiency in high-order solvers for compressible flows using AMR while integrating with the Regent language and overcoming dynamic data structure, mesh validity, and performance bottleneck challenges.", "method": "Developed an AMR-based solver implemented in Regent, tackled challenges like patch refinement, mesh validity, and task launch overhead through task fusion, and used simple annotations for GPU kernel generation.", "result": "Task fusion achieved 18x speedup, and GPU kernel annotations delivered 9.7x speedup, validated through compressible flow Euler equation simulations.", "conclusion": "The proposed solver is effective in leveraging AMR and Regent capabilities for efficiency in compressible flow simulations, showcasing substantial computational improvements."}}
{"id": "2508.04848", "pdf": "https://arxiv.org/pdf/2508.04848", "abs": "https://arxiv.org/abs/2508.04848", "authors": ["Chang Tian", "Matthew B. Blaschko", "Mingzhe Xing", "Xiuxing Li", "Yinliang Yue", "Marie-Francine Moens"], "title": "Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning", "categories": ["cs.AI"], "comment": "large language models, large vision-language model, reasoning,\n  non-ideal conditions, reinforcement learning", "summary": "Reinforcement learning (RL) has become a key technique for enhancing the\nreasoning abilities of large language models (LLMs), with policy-gradient\nalgorithms dominating the post-training stage because of their efficiency and\neffectiveness. However, most existing benchmarks evaluate large-language-model\nreasoning under idealized settings, overlooking performance in realistic,\nnon-ideal scenarios. We identify three representative non-ideal scenarios with\npractical relevance: summary inference, fine-grained noise suppression, and\ncontextual filtering. We introduce a new research direction guided by\nbrain-science findings that human reasoning remains reliable under imperfect\ninputs. We formally define and evaluate these challenging scenarios. We\nfine-tune three LLMs and a state-of-the-art large vision-language model (LVLM)\nusing RL with a representative policy-gradient algorithm and then test their\nperformance on eight public datasets. Our results reveal that while RL\nfine-tuning improves baseline reasoning under idealized settings, performance\ndeclines significantly across all three non-ideal scenarios, exposing critical\nlimitations in advanced reasoning capabilities. Although we propose a\nscenario-specific remediation method, our results suggest current methods leave\nthese reasoning deficits largely unresolved. This work highlights that the\nreasoning abilities of large models are often overstated and underscores the\nimportance of evaluating models under non-ideal scenarios. The code and data\nwill be released at XXXX.", "AI": {"tldr": "While reinforcement learning enhances reasoning abilities of large language models in ideal scenarios, their performance drops significantly in non-ideal ones such as summary inference, noise suppression, and contextual filtering. Current methods remain insufficient for resolving these deficits.", "motivation": "The paper aims to address the gap in evaluating the reasoning abilities of large language models under realistic, non-ideal scenarios, reflecting practical challenges.", "method": "The authors formally define and evaluate non-ideal reasoning scenarios, fine-tune three large language models and one large vision-language model using a policy-gradient algorithm, and test them across eight datasets.", "result": "Fine-tuned models improved baseline reasoning in idealized settings but displayed significant performance declines under non-ideal scenarios, despite attempts at scenario-specific remediation.", "conclusion": "The current methods overstate the reasoning abilities of large models, emphasizing the necessity of evaluating models under real-world, non-ideal conditions to uncover critical limitations."}}
{"id": "2508.04983", "pdf": "https://arxiv.org/pdf/2508.04983", "abs": "https://arxiv.org/abs/2508.04983", "authors": ["Li-Ru Zhang", "Haiping Huang"], "title": "Kinetic energy in random recurrent neural networks", "categories": ["cond-mat.stat-mech", "nlin.CD", "q-bio.NC"], "comment": "8 pages, 6 figures", "summary": "The relationship between unstable fixed points and chaotic dynamics in\nhigh-dimensional neural dynamics remains elusive. In this work, we investigate\nthe kinetic energy distribution of random recurrent neural networks by\ncombining dynamical mean-field theory with extensive numerical simulations. We\nfind that the average kinetic energy shifts continuously from zero to a\npositive value at a critical value of coupling variance (synaptic gain), with a\npower-law behavior close to the critical point. The steady-state activity\ndistribution is further calculated by the theory and compared with simulations\non finite-size systems. This study provides a first step toward understanding\nthe landscape of kinetic energy, which may reflect the structure of phase space\nfor the non-equilibrium dynamics.", "AI": {"tldr": "This paper investigates the kinetic energy distribution in random recurrent neural networks, identifying a critical behavior linked to synaptic gain, with a continuous shift near the critical point.", "motivation": "To explore the connection between high-dimensional neural dynamics, specifically kinetic energy distribution, and chaotic behavior to understand phase space structures.", "method": "The researchers employ dynamical mean-field theory in conjunction with extensive numerical simulations to analyze kinetic energy and steady-state activity distribution.", "result": "The study finds a continuous shift of average kinetic energy at a critical synaptic gain, revealing power-law dynamics near the critical point, and validates the theoretical results with finite-size simulations.", "conclusion": "The work initiates a deeper understanding of kinetic energy landscapes in neural dynamics and their implications for non-equilibrium phase space structure."}}
{"id": "2508.05005", "pdf": "https://arxiv.org/pdf/2508.05005", "abs": "https://arxiv.org/abs/2508.05005", "authors": ["Gang Xu", "Airong Wang", "Yushan Pan"], "title": "Generative AI for Object-Oriented Programming: Writing the Right Code and Reasoning the Right Logic", "categories": ["cs.SE"], "comment": null, "summary": "We find ourselves in the midst of an explosion in artificial intelligence\nresearch, particularly with large language models (LLMs). These models have\ndiverse applications spanning finance, commonsense knowledge graphs, medicine,\nand visual analysis. In the world of Object-Oriented Programming(OOP), a robust\nbody of knowledge and methods has been developed for managing complex tasks\nthrough object-oriented thinking. However, the intersection of LLMs with OOP\nremains an underexplored territory. Empirically, we currently possess limited\nunderstanding of how LLMs can enhance the effectiveness of OOP learning and\ncode writing, as well as how we can evaluate such AI-powered tools. Our work\naims to address this gap by presenting a vision from the perspectives of key\nstakeholders involved in an OOP task: programmers, mariners, and experienced\nprogrammers. We identify critical junctures within typical coding workflows\nwhere the integration of LLMs can offer significant benefits. Furthermore, we\npropose ways to augment existing logical reasoning and code writing, ultimately\nenhancing the programming experience.", "AI": {"tldr": "The paper explores how Large Language Models (LLMs) can be integrated into Object-Oriented Programming (OOP) workflows to improve learning and coding outcomes.", "motivation": "The intersection of LLMs with OOP methods and workflows is underexamined, and this paper aims to explore how LLMs can enhance OOP learning and code-writing processes.", "method": "The authors identify critical moments in coding workflows where LLM integration could provide substantial benefits and propose strategies to improve logical reasoning and code-writing using LLMs.", "result": "Critical coding workflows were mapped and opportunities for LLM-supported interventions were suggested to improve OOP learning and code writing.", "conclusion": "Integrating LLMs into OOP workflows can significantly aid programmers by boosting reasoning and writing in coding tasks, thereby enriching the programming experience."}}
{"id": "2508.05021", "pdf": "https://arxiv.org/pdf/2508.05021", "abs": "https://arxiv.org/abs/2508.05021", "authors": ["Weifan Zhang", "Tingguang Li", "Yuzhen Liu"], "title": "MAG-Nav: Language-Driven Object Navigation Leveraging Memory-Reserved Active Grounding", "categories": ["cs.RO"], "comment": null, "summary": "Visual navigation in unknown environments based solely on natural language\ndescriptions is a key capability for intelligent robots. In this work, we\npropose a navigation framework built upon off-the-shelf Visual Language Models\n(VLMs), enhanced with two human-inspired mechanisms: perspective-based active\ngrounding, which dynamically adjusts the robot's viewpoint for improved visual\ninspection, and historical memory backtracking, which enables the system to\nretain and re-evaluate uncertain observations over time. Unlike existing\napproaches that passively rely on incidental visual inputs, our method actively\noptimizes perception and leverages memory to resolve ambiguity, significantly\nimproving vision-language grounding in complex, unseen environments. Our\nframework operates in a zero-shot manner, achieving strong generalization to\ndiverse and open-ended language descriptions without requiring labeled data or\nmodel fine-tuning. Experimental results on Habitat-Matterport 3D (HM3D) show\nthat our method outperforms state-of-the-art approaches in language-driven\nobject navigation. We further demonstrate its practicality through real-world\ndeployment on a quadruped robot, achieving robust and effective navigation\nperformance.", "AI": {"tldr": "The paper introduces a zero-shot navigation framework using off-the-shelf Visual Language Models enhanced by active grounding and historical memory for robots in complex environments.", "motivation": "Enable robots to navigate complex unknown environments using only natural language descriptions.", "method": "Uses Visual Language Models with active grounding for viewpoint adjustment and historical memory for re-evaluating uncertain observations.", "result": "Achieves state-of-the-art performance in language-driven navigation in both simulated (HM3D) and real-world settings.", "conclusion": "Demonstrates effective zero-shot generalization and robust robot navigation, not requiring labeled data or fine-tuning."}}
{"id": "2508.04827", "pdf": "https://arxiv.org/pdf/2508.04827", "abs": "https://arxiv.org/abs/2508.04827", "authors": ["Chirag Seth", "Divya Naiken", "Keyan Lin"], "title": "A deep learning approach to track eye movements based on events", "categories": ["cs.CV", "68T05, 68T07", "I.2.10; I.5.1; I.4.8; J.4"], "comment": null, "summary": "This research project addresses the challenge of accurately tracking eye\nmovements during specific events by leveraging previous research. Given the\nrapid movements of human eyes, which can reach speeds of 300{\\deg}/s, precise\neye tracking typically requires expensive and high-speed cameras. Our primary\nobjective is to locate the eye center position (x, y) using inputs from an\nevent camera. Eye movement analysis has extensive applications in consumer\nelectronics, especially in VR and AR product development. Therefore, our\nultimate goal is to develop an interpretable and cost-effective algorithm using\ndeep learning methods to predict human attention, thereby improving device\ncomfort and enhancing overall user experience. To achieve this goal, we\nexplored various approaches, with the CNN\\_LSTM model proving most effective,\nachieving approximately 81\\% accuracy. Additionally, we propose future work\nfocusing on Layer-wise Relevance Propagation (LRP) to further enhance the\nmodel's interpretability and predictive performance.", "AI": {"tldr": "This paper proposes a cost-effective deep learning algorithm to locate eye center positions using event cameras for applications in VR/AR, achieving 81% accuracy with a CNN_LSTM model.", "motivation": "Precise eye tracking is crucial for VR/AR applications but traditionally requires expensive equipment. The study seeks a cost-effective solution leveraging event cameras and deep learning.", "method": "The research tested various algorithms and identified the CNN_LSTM model as the most effective. It aims to improve interpretability through methods like Layer-wise Relevance Propagation (LRP).", "result": "The CNN_LSTM model achieved approximately 81% accuracy in predicting eye center positions, showing promise for practical applications.", "conclusion": "The study demonstrates the feasibility of using event cameras and deep learning for accurate and cost-effective eye tracking, hinting at future work for better interpretability and performance."}}
{"id": "2508.04903", "pdf": "https://arxiv.org/pdf/2508.04903", "abs": "https://arxiv.org/abs/2508.04903", "authors": ["Jun Liu", "Zhenglun Kong", "Changdi Yang", "Fan Yang", "Tianqi Li", "Peiyan Dong", "Joannah Nanjekye", "Hao Tang", "Geng Yuan", "Wei Niu", "Wenbin Zhang", "Pu Zhao", "Xue Lin", "Dong Huang", "Yanzhi Wang"], "title": "RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory", "categories": ["cs.CL", "cs.AI", "cs.MA"], "comment": null, "summary": "Multi-agent large language model (LLM) systems have shown strong potential in\ncomplex reasoning and collaborative decision-making tasks. However, most\nexisting coordination schemes rely on static or full-context routing\nstrategies, which lead to excessive token consumption, redundant memory\nexposure, and limited adaptability across interaction rounds. We introduce\nRCR-Router, a modular and role-aware context routing framework designed to\nenable efficient, adaptive collaboration in multi-agent LLMs. To our knowledge,\nthis is the first routing approach that dynamically selects semantically\nrelevant memory subsets for each agent based on its role and task stage, while\nadhering to a strict token budget. A lightweight scoring policy guides memory\nselection, and agent outputs are iteratively integrated into a shared memory\nstore to facilitate progressive context refinement. To better evaluate model\nbehavior, we further propose an Answer Quality Score metric that captures\nLLM-generated explanations beyond standard QA accuracy. Experiments on three\nmulti-hop QA benchmarks -- HotPotQA, MuSiQue, and 2WikiMultihop -- demonstrate\nthat RCR-Router reduces token usage (up to 30%) while improving or maintaining\nanswer quality. These results highlight the importance of structured memory\nrouting and output-aware evaluation in advancing scalable multi-agent LLM\nsystems.", "AI": {"tldr": "RCR-Router is a context-routing framework for multi-agent LLMs that reduces token usage while improving answer quality.", "motivation": "Existing multi-agent LLM coordination schemes often rely on inefficient static or full-context routing, consuming excessive tokens and limiting adaptability.", "method": "RCR-Router dynamically routes semantically relevant memory subsets based on agent roles and task stages. It uses a scoring policy for memory selection and integrates outputs iteratively into shared memory while adhering to token budgets.", "result": "The framework reduced token use by up to 30% and improved or maintained answer quality on HotPotQA, MuSiQue, and 2WikiMultihop benchmarks.", "conclusion": "Adaptive and structured memory routing enables efficient and scalable collaboration in multi-agent LLMs while maintaining high-quality outputs."}}
{"id": "2508.05570", "pdf": "https://arxiv.org/pdf/2508.05570", "abs": "https://arxiv.org/abs/2508.05570", "authors": ["Ilya Levin", "Alexey Naumov", "Sergey Samsonov"], "title": "High-Order Error Bounds for Markovian LSA with Richardson-Romberg Extrapolation", "categories": ["stat.ML", "cs.LG", "math.OC", "math.ST", "stat.TH", "62L20"], "comment": null, "summary": "In this paper, we study the bias and high-order error bounds of the Linear\nStochastic Approximation (LSA) algorithm with Polyak-Ruppert (PR) averaging\nunder Markovian noise. We focus on the version of the algorithm with constant\nstep size $\\alpha$ and propose a novel decomposition of the bias via a\nlinearization technique. We analyze the structure of the bias and show that the\nleading-order term is linear in $\\alpha$ and cannot be eliminated by PR\naveraging. To address this, we apply the Richardson-Romberg (RR) extrapolation\nprocedure, which effectively cancels the leading bias term. We derive\nhigh-order moment bounds for the RR iterates and show that the leading error\nterm aligns with the asymptotically optimal covariance matrix of the vanilla\naveraged LSA iterates.", "AI": {"tldr": "The paper examines the Linear Stochastic Approximation (LSA) algorithm with Polyak-Ruppert averaging under Markovian noise, identifies bias challenges, and uses Richardson-Romberg extrapolation to mitigate leading bias terms.", "motivation": "To address bias and error bounds in the LSA algorithm with PR averaging under Markovian noise and identify ways to improve it.", "method": "A novel linearization technique is employed to decompose bias, followed by applying Richardson-Romberg extrapolation to cancel leading bias terms. High-order moment bounds for iterates are derived.", "result": "The leading-order bias term is linear in the step size and cannot be removed by PR averaging, but it can be effectively mitigated through Richardson-Romberg extrapolation.", "conclusion": "Richardson-Romberg extrapolation improves the performance of the LSA algorithm by addressing its leading bias term and aligning the error with the asymptotically optimal covariance matrix."}}
{"id": "2508.04746", "pdf": "https://arxiv.org/pdf/2508.04746", "abs": "https://arxiv.org/abs/2508.04746", "authors": ["Pengtao Dang", "Tingbo Guo", "Sha Cao", "Chi Zhang"], "title": "A Foundational Multi-Modal Model for Few-Shot Learning", "categories": ["cs.LG"], "comment": "11 pages, 5 figures", "summary": "Few-shot learning (FSL) is a machine learning paradigm that aims to\ngeneralize models from a small number of labeled examples, typically fewer than\n10 per class. FSL is particularly crucial in biomedical, environmental,\nmaterials, and mechanical sciences, where samples are limited and data\ncollection is often prohibitively costly, time-consuming, or ethically\nconstrained. In this study, we present an innovative approach to FSL by\ndemonstrating that a Large Multi-Modal Model (LMMM), trained on a set of\nindependent tasks spanning diverse domains, task types, and input modalities,\ncan substantially improve the generalization of FSL models, outperforming\nmodels based on conventional meta-learning on tasks of the same type. To\nsupport this, we first constructed a Multi-Modal Model Few-shot Dataset (M3FD,\nover 10K+ few-shot samples), which includes 2D RGB images, 2D/3D medical scans,\ntabular and time-course datasets, from which we manually curated FSL tasks such\nas classification. We further introduced M3F (Multi-Modal Model for Few-shot\nlearning framework), a novel Large Multi-Modal Model framework tailored for\ndata-constrained scientific applications. M3F supports a wide range of\nscientific data types through a modular pipeline. By fine-tuning the model on\nM3FD, M3F improves model performance, making LMMM feasible for real-world FSL\ndeployment. The source code is located at https://github.com/ptdang1001/M3F. To\ndemocratize access to complex FSL data and promote reproducibility for public\nusage, M3FD is paired with a flexible and user-friendly tool that enables\nefficient querying, task-specific sampling, and preprocessing. Together, our\ndataset and framework offer a unified, scalable solution that significantly\nlowers the barrier to applying LMMMs in data-scarce scientific domains.", "AI": {"tldr": "The paper introduces a novel Few-shot Learning (FSL) approach using a Large Multi-Modal Model (LMMM), demonstrating superior generalization on data-scarce scientific tasks through a newly proposed dataset (M3FD) and framework (M3F).", "motivation": "The motivation is to address challenges in data-scarce domains, especially in sciences like biomedical and environmental fields, where data collection is costly, time-intensive, and sometimes ethically challenging.", "method": "The method involves building a Multi-Modal Model Few-shot Dataset (M3FD) containing diverse data types and tasks, and developing the M3F framework, which uses a modular pipeline to fine-tune an LMMM for improved performance on Few-shot Learning tasks.", "result": "The proposed approach significantly improves generalization and outperforms traditional meta-learning models on few-shot tasks, making Large Multi-Modal Models (LMMMs) effective in real-world applications.", "conclusion": "The study offers a scalable and accessible solution for deploying LMMMs in FSL across data-constrained domains through its novel dataset (M3FD) and framework (M3F), lowering barriers and promoting reproducibility."}}
{"id": "2508.05616", "pdf": "https://arxiv.org/pdf/2508.05616", "abs": "https://arxiv.org/abs/2508.05616", "authors": ["Zhikai Zhao", "Chuanbo Hua", "Federico Berto", "Kanghoon Lee", "Zihan Ma", "Jiachen Li", "Jinkyoo Park"], "title": "TrajEvo: Trajectory Prediction Heuristics Design via LLM-driven Evolution", "categories": ["cs.LG", "cs.AI", "cs.NE", "cs.RO"], "comment": "arXiv admin note: substantial text overlap with arXiv:2505.04480", "summary": "Trajectory prediction is a critical task in modeling human behavior,\nespecially in safety-critical domains such as social robotics and autonomous\nvehicle navigation. Traditional heuristics based on handcrafted rules often\nlack accuracy and generalizability. Although deep learning approaches offer\nimproved performance, they typically suffer from high computational cost,\nlimited explainability, and, importantly, poor generalization to\nout-of-distribution (OOD) scenarios. In this paper, we introduce TrajEvo, a\nframework that leverages Large Language Models (LLMs) to automatically design\ntrajectory prediction heuristics. TrajEvo employs an evolutionary algorithm to\ngenerate and refine prediction heuristics from past trajectory data. We propose\ntwo key innovations: Cross-Generation Elite Sampling to encourage population\ndiversity, and a Statistics Feedback Loop that enables the LLM to analyze and\nimprove alternative predictions. Our evaluations demonstrate that TrajEvo\noutperforms existing heuristic methods across multiple real-world datasets, and\nnotably surpasses both heuristic and deep learning methods in generalizing to\nan unseen OOD real-world dataset. TrajEvo marks a promising step toward the\nautomated design of fast, explainable, and generalizable trajectory prediction\nheuristics. We release our source code to facilitate future research at\nhttps://github.com/ai4co/trajevo.", "AI": {"tldr": "Introduction of TrajEvo, a framework that leverages Large Language Models (LLMs) and evolutionary algorithms for better trajectory prediction. It surpasses other methods in generalization to Out-of-Distribution (OOD) datasets.", "motivation": "Traditional handcrafted heuristics struggle with accuracy and adaptability, while deep learning offers better results but faces issues like high computational demands and poor generalization in Out-of-Distribution (OOD) scenarios.", "method": "TrajEvo utilizes an evolutionary algorithm supported by LLMs. Key features include Cross-Generation Elite Sampling to ensure population diversity and a Statistics Feedback Loop for iterative refinement of trajectory prediction heuristics.", "result": "TrajEvo demonstrated superior performance compared to traditional heuristics and deep learning approaches in trajectory prediction across multiple datasets, especially in OOD scenarios.", "conclusion": "TrajEvo offers a promising method for creating fast, explainable, and generalizable trajectory prediction heuristics, showcasing its potential for applications in safety-critical domains."}}
{"id": "2508.05029", "pdf": "https://arxiv.org/pdf/2508.05029", "abs": "https://arxiv.org/abs/2508.05029", "authors": ["Felipe Arambur\u00fa", "William Malpica", "Kaouther Abrougui", "Amin Aramoon", "Romulo Auccapuclla", "Claude Brisson", "Matthijs Brobbel", "Colby Farrell", "Pradeep Garigipati", "Joost Hoozemans", "Supun Kamburugamuve", "Akhil Nair", "Alexander Ocsa", "Johan Peltenburg", "Rub\u00e9n Quesada L\u00f3pez", "Deepak Sihag", "Ahmet Uyar", "Dhruv Vats", "Michael Wendt", "Jignesh M. Patel", "Rodrigo Arambur\u00fa"], "title": "Theseus: A Distributed and Scalable GPU-Accelerated Query Processing Platform Optimized for Efficient Data Movement", "categories": ["cs.DC", "cs.DB", "H.2.4"], "comment": "6 Pages,6 Figures", "summary": "Online analytical processing of queries on datasets in the many-terabyte\nrange is only possible with costly distributed computing systems. To decrease\nthe cost and increase the throughput, systems can leverage accelerators such as\nGPUs, which are now ubiquitous in the compute infrastructure. This introduces\nmany challenges, the majority of which are related to when, where, and how to\nbest move data around the system. We present Theseus -- a production-ready\nenterprise-scale distributed accelerator-native query engine designed to\nbalance data movement, memory utilization, and computation in an\naccelerator-based system context. Specialized asynchronous control mechanisms\nare tightly coupled to the hardware resources for the purpose of network\ncommunication, data pre-loading, data spilling across memories and storage, and\nGPU compute tasks. The memory subsystem contains a mechanism for fixed-size\npage-locked host memory allocations to increase throughput and reduce memory\nfragmentation. For the TPC-H benchmarks at scale factors ranging from 1k to 30k\non cloud infrastructure, Theseus outperforms Databricks Photon by up to\n$4\\times$ at cost parity. Theseus is capable of processing all queries of the\nTPC-H and TPC-DS benchmarks at scale factor 100k (100 TB scale) with as few as\n2 DGX A100 640GB nodes.", "AI": {"tldr": "Theseus is a specialized, GPU-focused, distributed query engine that optimizes data movement, memory use, and computation, achieving significant performance gains on large-scale benchmarks.", "motivation": "The need to handle terabyte-scale datasets efficiently with reduced costs, leveraging ubiquitous GPU accelerators despite the challenges of data movement and system optimization.", "method": "Theseus employs asynchronous control mechanisms for network communication, data pre-loading, spilling, and GPU compute tasks, with customized memory allocation techniques to enhance throughput and reduce fragmentation.", "result": "Theseus achieves up to 4x performance improvement over Databricks Photon with cost parity on TPC-H benchmarks, and efficiently handles 100TB scale datasets with minimal hardware.", "conclusion": "Theseus establishes itself as a high-performance, cost-effective, GPU-optimized query engine capable of addressing enterprise-large-scale analytics needs."}}
{"id": "2508.04915", "pdf": "https://arxiv.org/pdf/2508.04915", "abs": "https://arxiv.org/abs/2508.04915", "authors": ["Huiya Zhao", "Yinghao Zhu", "Zixiang Wang", "Yasha Wang", "Junyi Gao", "Liantao Ma"], "title": "ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis", "categories": ["cs.AI", "cs.CL", "cs.MA"], "comment": "Code: https://github.com/PKU-AICare/ConfAgents", "summary": "The efficacy of AI agents in healthcare research is hindered by their\nreliance on static, predefined strategies. This creates a critical limitation:\nagents can become better tool-users but cannot learn to become better strategic\nplanners, a crucial skill for complex domains like healthcare. We introduce\nHealthFlow, a self-evolving AI agent that overcomes this limitation through a\nnovel meta-level evolution mechanism. HealthFlow autonomously refines its own\nhigh-level problem-solving policies by distilling procedural successes and\nfailures into a durable, strategic knowledge base. To anchor our research and\nfacilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark\nfeaturing complex, realistic health data analysis tasks derived from\npeer-reviewed clinical research. Our comprehensive experiments demonstrate that\nHealthFlow's self-evolving approach significantly outperforms state-of-the-art\nagent frameworks. This work marks a necessary shift from building better\ntool-users to designing smarter, self-evolving task-managers, paving the way\nfor more autonomous and effective AI for scientific discovery.", "AI": {"tldr": "The paper introduces HealthFlow, a self-evolving AI agent for healthcare problem-solving, along with a benchmark called EHRFlowBench. Experiments show HealthFlow significantly outperforms current frameworks.", "motivation": "Current AI agents in healthcare rely on static strategies, limiting their ability to develop high-level strategic planning skills for complex domains.", "method": "The authors propose HealthFlow, an AI agent that uses a meta-level evolution mechanism to refine strategic policies based on successes and failures. They also introduce EHRFlowBench for evaluation.", "result": "Experimental findings show HealthFlow's self-evolving approach surpasses state-of-the-art agent frameworks in tasks derived from realistic health data.", "conclusion": "HealthFlow represents a shift toward creating smarter, autonomous AI agents that can independently improve their high-level task-management skills, enhancing scientific discovery in healthcare."}}
{"id": "2508.05034", "pdf": "https://arxiv.org/pdf/2508.05034", "abs": "https://arxiv.org/abs/2508.05034", "authors": ["Arabat", "Ali", "Sayagh", "Mohammed", "Hassine", "Jameleddine"], "title": "An ML-based Approach to Predicting Software Change Dependencies: Insights from an Empirical Study on OpenStack", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "As software systems grow in complexity, accurately identifying and managing\ndependencies among changes becomes increasingly critical. For instance, a\nchange that leverages a function must depend on the change that introduces it.\nEstablishing such dependencies allows CI/CD pipelines to build and orchestrate\nchanges effectively, preventing build failures and incomplete feature\ndeployments. In modern software systems, dependencies often span multiple\ncomponents across teams, creating challenges for development and deployment.\nThey serve various purposes, from enabling new features to managing\nconfigurations, and can even involve traditionally independent changes like\ndocumentation updates. To address these challenges, we conducted a preliminary\nstudy on dependency management in OpenStack, a large-scale software system. Our\nstudy revealed that a substantial portion of software changes in OpenStack over\nthe past 10 years are interdependent. Surprisingly, 51.08% of these\ndependencies are identified during the code review phase-after a median delay\nof 5.06 hours-rather than at the time of change creation. Developers often\nspend a median of 57.12 hours identifying dependencies, searching among a\nmedian of 463 other changes. To help developers proactively identify\ndependencies, we propose a semi-automated approach that leverages two ML\nmodels. The first model predicts the likelihood of dependencies among changes,\nwhile the second identifies the exact pairs of dependent changes. Our proposed\nmodels demonstrate strong performance, achieving average AUC scores of 79.33%\nand 91.89%, and Brier scores of 0.11 and 0.014, respectively. Indeed, the\nsecond model has a good top-k recall across all types of pairs, while the top-k\nprecision has room for improvement.", "AI": {"tldr": "The paper addresses dependency management in complex software systems, focusing on OpenStack. It proposes ML models for proactively identifying dependencies, achieving promising accuracy metrics.", "motivation": "The increasing complexity of software systems necessitates better management of dependencies among changes to avoid operational inefficiencies and deployment issues.", "method": "The study examines dependency detection in OpenStack over a 10-year period and introduces two machine learning models: one to predict the likelihood of dependencies and another to identify specific pairs of dependent changes.", "result": "The ML models show strong performance, with AUC scores of 79.33% and 91.89% and Brier scores of 0.11 and 0.014, respectively. Dependency detection during code reviews, however, remains delayed.", "conclusion": "Proactive dependency management using ML models offers a significant improvement compared to current manual detection methods, although further refinement in precision is required."}}
{"id": "2508.05027", "pdf": "https://arxiv.org/pdf/2508.05027", "abs": "https://arxiv.org/abs/2508.05027", "authors": ["Philip Huang", "Yorai Shaoul", "Jiaoyang Li"], "title": "Benchmarking Shortcutting Techniques for Multi-Robot-Arm Motion Planning", "categories": ["cs.RO"], "comment": "9 pages, 6 figures, accepted for publication at 2025 IEEE/RSJ\n  International Conference on Intelligent Robots and Systems (IROS 2025)", "summary": "Generating high-quality motion plans for multiple robot arms is challenging\ndue to the high dimensionality of the system and the potential for inter-arm\ncollisions. Traditional motion planning methods often produce motions that are\nsuboptimal in terms of smoothness and execution time for multi-arm systems.\nPost-processing via shortcutting is a common approach to improve motion quality\nfor efficient and smooth execution. However, in multi-arm scenarios, optimizing\none arm's motion must not introduce collisions with other arms. Although\nexisting multi-arm planning works often use some form of shortcutting\ntechniques, their exact methodology and impact on performance are often vaguely\ndescribed. In this work, we present a comprehensive study quantitatively\ncomparing existing shortcutting methods for multi-arm trajectories across\ndiverse simulated scenarios. We carefully analyze the pros and cons of each\nshortcutting method and propose two simple strategies for combining these\nmethods to achieve the best performance-runtime tradeoff. Video, code, and\ndataset are available at https://philip-huang.github.io/mr-shortcut/.", "AI": {"tldr": "This paper studies and compares shortcutting techniques for motion planning in multi-robot arm systems, proposing strategies for better performance-runtime tradeoffs.", "motivation": "To address the difficulty in generating high-quality, collision-free, and smooth motion plans for multi-arm robotic systems, and to improve upon traditional methods using shortcutting techniques.", "method": "The study performs a quantitative analysis of existing shortcutting methods across diverse simulated scenarios, examining their pros and cons. It also proposes two strategies for combining these methods to optimize performance and efficiency.", "result": "The study identifies the strengths and weaknesses of existing shortcutting techniques and demonstrates how the proposed combination strategies improve performance and runtime in multi-arm motion planning.", "conclusion": "Effective shortcutting is critical for high-quality multi-arm trajectory planning, and the proposed combination strategies enhance execution quality and efficiency."}}
{"id": "2508.04847", "pdf": "https://arxiv.org/pdf/2508.04847", "abs": "https://arxiv.org/abs/2508.04847", "authors": ["Md Zahidul Hasan", "A. Ben Hamza", "Nizar Bouguila"], "title": "LuKAN: A Kolmogorov-Arnold Network Framework for 3D Human Motion Prediction", "categories": ["cs.CV"], "comment": null, "summary": "The goal of 3D human motion prediction is to forecast future 3D poses of the\nhuman body based on historical motion data. Existing methods often face\nlimitations in achieving a balance between prediction accuracy and\ncomputational efficiency. In this paper, we present LuKAN, an effective model\nbased on Kolmogorov-Arnold Networks (KANs) with Lucas polynomial activations.\nOur model first applies the discrete wavelet transform to encode temporal\ninformation in the input motion sequence. Then, a spatial projection layer is\nused to capture inter-joint dependencies, ensuring structural consistency of\nthe human body. At the core of LuKAN is the Temporal Dependency Learner, which\nemploys a KAN layer parameterized by Lucas polynomials for efficient function\napproximation. These polynomials provide computational efficiency and an\nenhanced capability to handle oscillatory behaviors. Finally, the inverse\ndiscrete wavelet transform reconstructs motion sequences in the time domain,\ngenerating temporally coherent predictions. Extensive experiments on three\nbenchmark datasets demonstrate the competitive performance of our model\ncompared to strong baselines, as evidenced by both quantitative and qualitative\nevaluations. Moreover, its compact architecture coupled with the linear\nrecurrence of Lucas polynomials, ensures computational efficiency.", "AI": {"tldr": "Presented LuKAN, a 3D human motion prediction model that balances accuracy and efficiency using Kolmogorov-Arnold Networks and Lucas polynomials.", "motivation": "To address limitations in balancing prediction accuracy and computational efficiency in 3D human motion prediction.", "method": "Utilizes discrete wavelet transform for temporal encoding, a spatial projection layer for inter-joint dependency, and a KAN layer with Lucas polynomials for efficient function approximation.", "result": "Extensive experiments on three benchmark datasets show competitive performance against strong baselines, both quantitatively and qualitatively.", "conclusion": "LuKAN achieves temporally coherent predictions with a compact architecture, offering computational efficiency and robust prediction capabilities."}}
{"id": "2508.04939", "pdf": "https://arxiv.org/pdf/2508.04939", "abs": "https://arxiv.org/abs/2508.04939", "authors": ["Julia Kharchenko", "Tanya Roosta", "Aman Chadha", "Chirag Shah"], "title": "I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations", "categories": ["cs.CL"], "comment": null, "summary": "This paper introduces a comprehensive benchmark for evaluating how Large\nLanguage Models (LLMs) respond to linguistic shibboleths: subtle linguistic\nmarkers that can inadvertently reveal demographic attributes such as gender,\nsocial class, or regional background. Through carefully constructed interview\nsimulations using 100 validated question-response pairs, we demonstrate how\nLLMs systematically penalize certain linguistic patterns, particularly hedging\nlanguage, despite equivalent content quality. Our benchmark generates\ncontrolled linguistic variations that isolate specific phenomena while\nmaintaining semantic equivalence, which enables the precise measurement of\ndemographic bias in automated evaluation systems. We validate our approach\nalong multiple linguistic dimensions, showing that hedged responses receive\n25.6% lower ratings on average, and demonstrate the benchmark's effectiveness\nin identifying model-specific biases. This work establishes a foundational\nframework for detecting and measuring linguistic discrimination in AI systems,\nwith broad applications to fairness in automated decision-making contexts.", "AI": {"tldr": "This paper introduces a benchmark for identifying demographic biases in Large Language Models (LLMs) based on linguistic patterns.", "motivation": "The study aims to understand how subtle linguistic markers may reveal demographic attributes and lead to biases in AI systems.", "method": "The researchers constructed interview simulations using 100 validated question-response pairs with controlled linguistic variations while maintaining semantic equivalence.", "result": "Their benchmark showed that hedged responses were systematically penalized with 25.6% lower ratings, revealing biases in LLMs.", "conclusion": "The paper provides a foundational framework for measuring linguistic discrimination in AI systems, crucial for ensuring fairness in automated decision-making."}}
{"id": "2505.22107", "pdf": "https://arxiv.org/pdf/2505.22107", "abs": "https://arxiv.org/abs/2505.22107", "authors": ["Shuhai Zhang", "Zeng You", "Yaofo Chen", "Zhiquan Wen", "Qianyue Wang", "Zhijie Qiu", "Yuanqing Li", "Mingkui Tan"], "title": "Curse of High Dimensionality Issue in Transformer for Long-context Modeling", "categories": ["cs.CL", "cs.LG", "stat.ML"], "comment": "Accepted at ICML 2025", "summary": "Transformer-based large language models (LLMs) excel in natural language\nprocessing tasks by capturing long-range dependencies through self-attention\nmechanisms. However, long-context modeling faces significant computational\ninefficiencies due to \\textit{redundant} attention computations: while\nattention weights are often \\textit{sparse}, all tokens consume \\textit{equal}\ncomputational resources. In this paper, we reformulate traditional\nprobabilistic sequence modeling as a \\textit{supervised learning task},\nenabling the separation of relevant and irrelevant tokens and providing a\nclearer understanding of redundancy. Based on this reformulation, we\ntheoretically analyze attention sparsity, revealing that only a few tokens\nsignificantly contribute to predictions. Building on this, we formulate\nattention optimization as a linear coding problem and propose a \\textit{group\ncoding strategy}, theoretically showing its ability to improve robustness\nagainst random noise and enhance learning efficiency. Motivated by this, we\npropose \\textit{Dynamic Group Attention} (DGA), which leverages the group\ncoding to explicitly reduce redundancy by aggregating less important tokens\nduring attention computation. Empirical results show that our DGA significantly\nreduces computational costs while maintaining competitive performance.Code is\navailable at https://github.com/bolixinyu/DynamicGroupAttention.", "AI": {"tldr": "The paper introduces Dynamic Group Attention (DGA), which reduces redundancy in attention computation for large language models, decreasing computational costs without compromising performance.", "motivation": "Current transformer-based large language models (LLMs) face inefficiencies in long-context modeling due to redundant attention computations, as all tokens consume equal computational resources despite sparseness in attention weights.", "method": "The authors reformulate probabilistic sequence modeling into a supervised learning task, analyze attention sparsity to identify significant tokens, and introduce a group coding strategy that aggregates less important tokens to optimize attention computation. They then propose Dynamic Group Attention (DGA) based on this framework.", "result": "The proposed DGA approach reduces computational costs significantly while maintaining competitive performance in comparison to traditional methods.", "conclusion": "Dynamic Group Attention (DGA) enhances the efficiency of attention computations in LLMs by reducing redundancy, which can contribute to more resource-efficient natural language processing tasks."}}
{"id": "2508.04748", "pdf": "https://arxiv.org/pdf/2508.04748", "abs": "https://arxiv.org/abs/2508.04748", "authors": ["Xuan Lin", "Long Chen", "Yile Wang"], "title": "AttriLens-Mol: Attribute Guided Reinforcement Learning for Molecular Property Prediction with Large Language Models", "categories": ["cs.LG"], "comment": "9 pages", "summary": "Large Language Models (LLMs) have shown promise in assisting molecular\nproperty prediction tasks but often rely on human-crafted prompts and\nchain-of-thought templates. While recent advanced large reasoning models like\nDeepSeek-R1 employ reinforcement learning for an extended ``thinking'' process,\ntheir reasoning can be verbose and lack relevance. We introduce AttriLens-Mol,\nan attribute-guided reinforcement learning framework for molecular property\nprediction with LLMs. AttriLens-Mol steers the model's reasoning by using: (1)\na format reward encouraging attribute-based structured output, (2) a count\nreward to avoid enumerating irrelevant attributes, and (3) a rationality reward\nusing advanced LLMs and RDKit to verify the relatedness of the generated\nattributes. This approach implicitly elicits the model's inherent knowledge of\nrelevant molecular attributes during reasoning, enables making predictions for\nthe molecular property more effectively. Experiments on both in-distribution\nand out-of-distribution datasets show that, training both 7B-size\nR1-Distilled-Qwen2.5 and R1-Distilled-LLaMA3.1 models on 4,000 samples with our\nproposed AttriLens-Mol method significantly boosts the performance, getting\ncomparable or better results than supervised fine-tuning models\n(Mol-Instructions, ChemDFM, etc.) and advanced models (GPT-3.5, GPT-4o,\nDeepSeek-V3, DeepSeek-R1, etc.). Further, our extracted attributes for the\ntarget property, when used as features for an interpretable decision tree\nmodel, yield superior performance compared to attributes generated by prompting\nLLMs. This shows that AttriLens-Mol effectively elicits more relevant and\npredictive molecular attributes, leading to enhanced interpretability and\nperformance for property prediction. We release the code in\nhttps://github.com/szu-tera/AttriLens-Mol.", "AI": {"tldr": "AttriLens-Mol proposes an attribute-guided reinforcement learning framework that improves molecular property prediction using LLMs without highly verbose or irrelevant reasoning.", "motivation": "Current LLMs used for molecular property prediction often rely on human-made prompts and generate verbose, less relevant reasoning.", "method": "AttriLens-Mol uses reinforcement learning rewards: format reward, count reward, and rationality reward to guide LLMs\u2019 reasoning towards structured and relevant molecular attributes.", "result": "Models trained with AttriLens-Mol outperformed both fine-tuned and advanced models in prediction performance using attributes as features for decision tree models.", "conclusion": "AttriLens-Mol enhances performance and interpretability in molecular property prediction by eliciting more relevant and predictive molecular attributes, proving to be an effective alternative to existing methods."}}
{"id": "2508.05370", "pdf": "https://arxiv.org/pdf/2508.05370", "abs": "https://arxiv.org/abs/2508.05370", "authors": ["Sumit Kumar", "Arjun Temura", "Naman Sharma", "Ramanjeet Singh", "Meet Dadhania", "Praveen Tammana", "Satananda Burla", "Abed Mohammad Kamaluddin", "Rinku Shah"], "title": "Simulating LLM training workloads for heterogeneous compute and network infrastructure", "categories": ["cs.DC"], "comment": null, "summary": "The growing demand for large-scale GPU clusters in distributed model training\npresents a significant barrier to innovation, particularly in model\noptimization, performance tuning, and system-level enhancements. To address\nthis challenge, LLM training simulators are employed to estimate training time\nand guide design decisions. However, the state-of-the-art LLM training\nsimulators assume homogeneous compute and network infrastructure. In practice,\ndevice heterogeneity is inevitable due to resource sharing in cloud\nenvironments, frequent shifts in device generations, and inherent intra-chip\ninterconnect heterogeneity. To address the gap between state-of-the-art and\npractical requirements, we propose the design of a heterogeneity-aware\ndistributed LLM simulator capable of predicting training time while enabling\nabstractions to specify custom configurations for device groups and\ndevice-to-parallelism mapping. We present the design requirements and\nchallenges in building a heterogeneity-aware distributed ML training simulator,\nand design components such as non-uniform workload partitioning. Our initial\nsimulation results demonstrate the impact of heterogeneity on the model\ncomputation and communication time.", "AI": {"tldr": "This paper introduces a heterogeneity-aware distributed LLM training simulator to estimate training time in settings with non-uniform compute and network infrastructure, addressing the gap between existing simulators and practical needs.", "motivation": "The paper addresses the need for efficient and realistic LLM training simulation due to hindrances like GPU cluster heterogeneity in modern distributed training, which current simulators overlook.", "method": "The authors built a simulator incorporating abstractions for custom configurations in device groups and mapping, along with non-uniform workload partitioning, to account for heterogeneous infrastructures.", "result": "Initial simulations showed the influence of heterogeneity on both computation and communication times in distributed LLM training.", "conclusion": "The proposed simulator highlights how device heterogeneity impacts training performance and provides a valuable tool for optimizing models and systems in practical, varied environments."}}
{"id": "2508.05006", "pdf": "https://arxiv.org/pdf/2508.05006", "abs": "https://arxiv.org/abs/2508.05006", "authors": ["Youzhi Zhang", "Yufei Li", "Gaofeng Meng", "Hongbin Liu", "Jiebo Luo"], "title": "The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein--Ligand Binding", "categories": ["cs.AI"], "comment": "21 pages, 9 figures", "summary": "Molecular docking is a crucial aspect of drug discovery, as it predicts the\nbinding interactions between small-molecule ligands and protein pockets.\nHowever, current multi-task learning models for docking often show inferior\nperformance in ligand docking compared to protein pocket docking. This\ndisparity arises largely due to the distinct structural complexities of ligands\nand proteins. To address this issue, we propose a novel game-theoretic\nframework that models the protein-ligand interaction as a two-player game\ncalled the Docking Game, with the ligand docking module acting as the ligand\nplayer and the protein pocket docking module as the protein player. To solve\nthis game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which\nalternately trains these players through a two-level loop. In the outer loop,\nthe players exchange predicted poses, allowing each to incorporate the other's\nstructural predictions, which fosters mutual adaptation over multiple\niterations. In the inner loop, each player dynamically refines its predictions\nby incorporating its own predicted ligand or pocket poses back into its model.\nWe theoretically show the convergence of LoopPlay, ensuring stable\noptimization. Extensive experiments conducted on public benchmark datasets\ndemonstrate that LoopPlay achieves approximately a 10\\% improvement in\npredicting accurate binding modes compared to previous state-of-the-art\nmethods. This highlights its potential to enhance the accuracy of molecular\ndocking in drug discovery.", "AI": {"tldr": "The paper presents Loop Self-Play (LoopPlay), a game-theoretic algorithm that enhances molecular docking prediction by treating it as a Docking Game, achieving a 10% accuracy improvement.", "motivation": "Current multi-task learning models underperform in ligand docking compared to protein pocket docking due to structural differences, necessitating new approaches.", "method": "Proposes a game-theoretic Docking Game framework, where ligand and protein docking modules are modeled as players, optimized using LoopPlay that alternates between mutual adaptation and individual refinement loops.", "result": "LoopPlay achieves about 10% improvement in predicting accurate binding modes over state-of-the-art methods, as validated on benchmark datasets.", "conclusion": "LoopPlay demonstrates strong potential in advancing molecular docking, making it valuable for drug discovery applications."}}
{"id": "2508.05085", "pdf": "https://arxiv.org/pdf/2508.05085", "abs": "https://arxiv.org/abs/2508.05085", "authors": ["Junayed Mahmud", "James Chen", "Terry Achille", "Camilo Alvarez-Velez", "Darren Dean Bansil", "Patrick Ijieh", "Samar Karanch", "Nadeeshan De Silva", "Oscar Chaparro", "Andrian Marcus", "Kevin Moran"], "title": "LadyBug: A GitHub Bot for UI-Enhanced Bug Localization in Mobile Apps", "categories": ["cs.SE"], "comment": "5 pages, to appear in the Proceedings of the 41st International\n  Conference on Software Maintenance and Evolution (ICSME'25) - Tool\n  Demonstration Track", "summary": "This paper introduces LadyBug, a GitHub bot that automatically localizes bugs\nfor Android apps by combining UI interaction information with text retrieval.\nLadyBug connects to an Android app's GitHub repository, and is triggered when a\nbug is reported in the corresponding issue tracker. Developers can then record\na reproduction trace for the bug on a device or emulator and upload the trace\nto LadyBug via the GitHub issue tracker. This enables LadyBug to utilize both\nthe text from the original bug description, and UI information from the\nreproduction trace to accurately retrieve a ranked list of files from the\nproject that most likely contain the reported bug.\n  We empirically evaluated LadyBug using an automated testing pipeline and\nbenchmark called RedWing that contains 80 fully-localized and reproducible bug\nreports from 39 Android apps. Our results illustrate that LadyBug outperforms\ntext-retrieval-based baselines and that the utilization of UI information leads\nto a substantial increase in localization accuracy. LadyBug is an open-source\ntool, available at https://github.com/LadyBugML/ladybug.\n  A video showing the capabilities of Ladybug can be viewed here:\nhttps://youtu.be/hI3tzbRK0Cw", "AI": {"tldr": "LadyBug is an open-source GitHub bot that identifies and ranks files likely containing bugs in Android apps by combining text and UI interaction data, outperforming text-retrieval-only methods.", "motivation": "Developers often face challenges in accurately localizing bugs in Android apps, leading to inefficiencies in debugging. This paper seeks to improve bug localization accuracy.", "method": "LadyBug leverages a combination of textual bug descriptions and UI reproduction traces uploaded through GitHub issue trackers to determine the most probable files containing bugs. It uses automation tools and a benchmark dataset, RedWing, for empirical evaluation.", "result": "Experiments with LadyBug on the RedWing benchmark demonstrated enhanced bug localization accuracy, surpassing text-retrieval-based approaches by incorporating UI interaction data.", "conclusion": "LadyBug effectively combines UI and text retrieval data for improved bug localization in Android apps and is publicly accessible as an open-source tool."}}
{"id": "2508.05040", "pdf": "https://arxiv.org/pdf/2508.05040", "abs": "https://arxiv.org/abs/2508.05040", "authors": ["Boyang Zhang", "Jiahui Zuo", "Zeyu Duan", "Fumin Zhang"], "title": "A Vision-Based Collision Sensing Method for Stable Circular Object Grasping with A Soft Gripper System", "categories": ["cs.RO"], "comment": null, "summary": "External collisions to robot actuators typically pose risks to grasping\ncircular objects. This work presents a vision-based sensing module capable of\ndetecting collisions to maintain stable grasping with a soft gripper system.\nThe system employs an eye-in-palm camera with a broad field of view to\nsimultaneously monitor the motion of fingers and the grasped object.\nFurthermore, we have developed a collision-rich grasping strategy to ensure the\nstability and security of the entire dynamic grasping process. A physical soft\ngripper was manufactured and affixed to a collaborative robotic arm to evaluate\nthe performance of the collision detection mechanism. An experiment regarding\ntesting the response time of the mechanism confirmed the system has the\ncapability to react to the collision instantaneously. A dodging test was\nconducted to demonstrate the gripper can detect the direction and scale of\nexternal collisions precisely.", "AI": {"tldr": "The study develops a vision-based sensing system for soft grippers to detect and respond to external collisions, enhancing grasp stability.", "motivation": "Ensure stable grasping of circular objects in the presence of external collisions, which pose risks to robotic systems.", "method": "The system integrates an eye-in-palm camera with a wide field of view and introduces a collision-rich grasping strategy. A physical soft gripper was created and used on a robotic arm for testing.", "result": "Experiments validated that the system reacts to collisions instantaneously and can accurately determine the direction and scale of collisions.", "conclusion": "The presented vision-based sensing approach ensures dynamic stability and security in robotic grasping amidst external disturbances."}}
{"id": "2508.04852", "pdf": "https://arxiv.org/pdf/2508.04852", "abs": "https://arxiv.org/abs/2508.04852", "authors": ["Chenhui Qiang", "Zhaoyang Wei", "Xumeng Han Zipeng Wang", "Siyao Li", "Xiangyuan Lan", "Jianbin Jiao", "Zhenjun Han"], "title": "VER-Bench: Evaluating MLLMs on Reasoning with Fine-Grained Visual Evidence", "categories": ["cs.CV"], "comment": "Accept by ACMM2025 Dataset track", "summary": "With the rapid development of MLLMs, evaluating their visual capabilities has\nbecome increasingly crucial. Current benchmarks primarily fall into two main\ntypes: basic perception benchmarks, which focus on local details but lack deep\nreasoning (e.g., \"what is in the image?\"), and mainstream reasoning benchmarks,\nwhich concentrate on prominent image elements but may fail to assess subtle\nclues requiring intricate analysis. However, profound visual understanding and\ncomplex reasoning depend more on interpreting subtle, inconspicuous local\ndetails than on perceiving salient, macro-level objects. These details, though\noccupying minimal image area, often contain richer, more critical information\nfor robust analysis. To bridge this gap, we introduce the VER-Bench, a novel\nframework to evaluate MLLMs' ability to: 1) identify fine-grained visual clues,\noften occupying on average just 0.25% of the image area; 2) integrate these\nclues with world knowledge for complex reasoning. Comprising 374 carefully\ndesigned questions across Geospatial, Temporal, Situational, Intent, System\nState, and Symbolic reasoning, each question in VER-Bench is accompanied by\nstructured evidence: visual clues and question-related reasoning derived from\nthem. VER-Bench reveals current models' limitations in extracting subtle visual\nevidence and constructing evidence-based arguments, highlighting the need to\nenhance models's capabilities in fine-grained visual evidence extraction,\nintegration, and reasoning for genuine visual understanding and human-like\nanalysis. Dataset and additional materials are available\nhttps://github.com/verbta/ACMMM-25-Materials.", "AI": {"tldr": "This paper introduces VER-Bench, a new benchmark designed to evaluate MLLMs' capability to identify subtle visual clues and perform complex reasoning, addressing the limitations of existing benchmarks.", "motivation": "Current MLLM benchmarks either focus on basic perception or prominent image elements but fail to evaluate models' ability to interpret subtle, intricate details critical for profound visual understanding and reasoning.", "method": "The paper presents VER-Bench, a framework with 374 tailored questions on six reasoning categories (Geospatial, Temporal, Situational, Intent, System State, Symbolic), along with structured evidence, designed to assess models' abilities in fine-grained clue identification and reasoning.", "result": "VER-Bench demonstrates that current models have limited capabilities in extracting subtle visual evidence and constructing evidence-based reasoning, exposing a gap in their visual understanding skills.", "conclusion": "The study highlights the need for improved MLLMs with robust capabilities in subtle evidence extraction and complex reasoning for better visual understanding and human-like analysis."}}
{"id": "2508.04945", "pdf": "https://arxiv.org/pdf/2508.04945", "abs": "https://arxiv.org/abs/2508.04945", "authors": ["Louie Hong Yao", "Nicholas Jarvis", "Tianyu Jiang"], "title": "Towards Robust Evaluation of Visual Activity Recognition: Resolving Verb Ambiguity with Sense Clustering", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "18 pages, 5 figures", "summary": "Evaluating visual activity recognition systems is challenging due to inherent\nambiguities in verb semantics and image interpretation. When describing actions\nin images, synonymous verbs can refer to the same event (e.g., brushing vs.\ngrooming), while different perspectives can lead to equally valid but distinct\nverb choices (e.g., piloting vs. operating). Standard exact-match evaluation,\nwhich relies on a single gold answer, fails to capture these ambiguities,\nresulting in an incomplete assessment of model performance. To address this, we\npropose a vision-language clustering framework that constructs verb sense\nclusters, providing a more robust evaluation. Our analysis of the imSitu\ndataset shows that each image maps to an average of 2.8 sense clusters, with\neach cluster representing a distinct perspective of the image. We evaluate\nmultiple activity recognition models and compare our cluster-based evaluation\nwith standard evaluation methods. Additionally, our human alignment analysis\nsuggests that the cluster-based evaluation better aligns with human judgements,\noffering a more nuanced assessment of model performance.", "AI": {"tldr": "This paper highlights the limitations of existing evaluation methods for visual activity recognition systems and introduces a clustering framework to account for verb ambiguities and perspectives.", "motivation": "Understanding and addressing ambiguities in verb semantics and image interpretation within visual activity recognition systems.", "method": "A novel vision-language clustering framework that categorizes verb sense clusters for evaluating model accuracy, considering human-like perspectives.", "result": "Analysis of the imSitu dataset confirms an average mapping of 2.8 sense clusters per image; evaluations show improved alignment with human judgments compared to standard methods.", "conclusion": "Cluster-based evaluation offers a nuanced and robust alternative for assessing visual activity recognition models, aligning more closely with human interpretations."}}
{"id": "2508.02903", "pdf": "https://arxiv.org/pdf/2508.02903", "abs": "https://arxiv.org/abs/2508.02903", "authors": ["Mehrdad Moradi", "Kamran Paynabar"], "title": "RDDPM: Robust Denoising Diffusion Probabilistic Model for Unsupervised Anomaly Segmentation", "categories": ["cs.CV", "eess.IV", "stat.ML", "68T07", "I.4.9; I.2.10"], "comment": "10 pages, 5 figures. Accepted to the ICCV 2025 Workshop on\n  Vision-based Industrial InspectiON (VISION)", "summary": "Recent advancements in diffusion models have demonstrated significant success\nin unsupervised anomaly segmentation. For anomaly segmentation, these models\nare first trained on normal data; then, an anomalous image is noised to an\nintermediate step, and the normal image is reconstructed through backward\ndiffusion. Unlike traditional statistical methods, diffusion models do not rely\non specific assumptions about the data or target anomalies, making them\nversatile for use across different domains. However, diffusion models typically\nassume access to normal data for training, limiting their applicability in\nrealistic settings. In this paper, we propose novel robust denoising diffusion\nmodels for scenarios where only contaminated (i.e., a mix of normal and\nanomalous) unlabeled data is available. By casting maximum likelihood\nestimation of the data as a nonlinear regression problem, we reinterpret the\ndenoising diffusion probabilistic model through a regression lens. Using robust\nregression, we derive a robust version of denoising diffusion probabilistic\nmodels. Our novel framework offers flexibility in constructing various robust\ndiffusion models. Our experiments show that our approach outperforms current\nstate of the art diffusion models, for unsupervised anomaly segmentation when\nonly contaminated data is available. Our method outperforms existing\ndiffusion-based approaches, achieving up to 8.08\\% higher AUROC and 10.37\\%\nhigher AUPRC on MVTec datasets. The implementation code is available at:\nhttps://github.com/mehrdadmoradi124/RDDPM", "AI": {"tldr": "The paper introduces robust denoising diffusion models designed to handle contaminated data, improving unsupervised anomaly segmentation performance.", "motivation": "Existing diffusion models require access to purely normal data for training, which is unrealistic in many practical applications dealing with contaminated datasets.", "method": "The paper reinterprets denoising diffusion probabilistic models as a nonlinear regression problem, applying robust regression techniques to derive robust diffusion models capable of handling contaminated data.", "result": "The proposed method achieves significant improvements over existing diffusion models, with up to 8.08% higher AUROC and 10.37% higher AUPRC performance on the MVTec dataset.", "conclusion": "The introduced framework broadens the applicability of diffusion models to scenarios without pure normal data, marking progress in unsupervised anomaly segmentation and enhancing real-world utility."}}
{"id": "2508.04750", "pdf": "https://arxiv.org/pdf/2508.04750", "abs": "https://arxiv.org/abs/2508.04750", "authors": ["Chanjuan Liu", "Shengzhi Wang", "Enqiang Zhu"], "title": "PA-RNet: Perturbation-Aware Reasoning Network for Multimodal Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "In real-world applications, multimodal time series data often suffer from\ninterference, especially in the textual modality. Existing methods for\nmultimodal time series forecasting often neglect the inherent perturbations\nwithin textual data, where irrelevant, noisy, or ambiguous content can\nsignificantly degrade model performance, particularly when the noise exhibits\nvarying intensity or stems from structural inconsistencies. To address this\nchallenge, we propose PA-RNet (Perturbation-Aware Reasoning Network for\nMultimodal Time Series Forecasting), a robust multimodal forecasting framework.\nPA-RNet features a perturbation-aware projection module and a cross-modal\nattention mechanism to effectively separate noise from the textual embeddings\nwhile maintaining semantically meaningful representations, thereby enhancing\nthe model's generalization ability. Theoretically, we establish the Lipschitz\ncontinuity of PA-RNet with respect to textual inputs and prove that the\nproposed perturbation module can reduce expected prediction error, offering\nstrong guarantees of stability under noisy conditions. Furthermore, we\nintroduce a textual perturbation pipeline that can be seamlessly incorporated\ninto existing multimodal time series forecasting tasks, allowing for systematic\nevaluation of the model's robustness in the presence of varying levels of\ntextual noise. Extensive experiments across diverse domains and temporal\nsettings demonstrate that PA-RNet consistently outperforms state-of-the-art\nbaselines.", "AI": {"tldr": "This paper introduces PA-RNet, a framework to improve multimodal time series forecasting by addressing textual noise and interference.", "motivation": "Existing methods often neglect the impact of noisy or irrelevant textual data on multimodal time series forecasting, which significantly degrades model performance.", "method": "PA-RNet leverages a perturbation-aware projection module and cross-modal attention mechanism to separate noise from textual embeddings while retaining meaningful semantic representations.", "result": "PA-RNet demonstrated superior performance over state-of-the-art baselines in various domains and conditions, with theoretical guarantees of stability and reduced prediction error under noisy inputs.", "conclusion": "PA-RNet effectively improves the robustness and generalization in multimodal forecasting tasks by addressing textual perturbations and can be seamlessly integrated into existing workflows."}}
{"id": "2508.05511", "pdf": "https://arxiv.org/pdf/2508.05511", "abs": "https://arxiv.org/abs/2508.05511", "authors": ["Rasman Mubtasim Swargo", "Engin Arslan", "Md Arifuzzaman"], "title": "Adaptive Parallel Downloader for Large Genomic Datasets", "categories": ["cs.DC"], "comment": null, "summary": "Modern next-generation sequencing (NGS) projects routinely generate terabytes\nof data, which researchers commonly download from public repositories such as\nSRA or ENA. Existing download tools often employ static concurrency settings,\nleading to inefficient bandwidth utilization and prolonged download times due\nto their inability to adapt to dynamic network conditions. We introduce\nFastBioDL, a parallel file downloader designed for large biological datasets,\nfeaturing an adaptive concurrency controller. FastBioDL frames the download\nprocess as an online optimization problem, utilizing a utility function and\ngradient descent to adjust the number of concurrent socket streams in real-time\ndynamically. This approach maximizes download throughput while minimizing\nresource overhead. Comprehensive evaluations on public genomic datasets\ndemonstrate that FastBioDL achieves up to $4x$ speedup over state-of-the-art\ntools. Moreover, in high-speed network experiments, its adaptive design was up\nto $2.1x$ faster than existing tools. By intelligently optimizing standard HTTP\nor FTP downloads on the client side, FastBioDL provides a robust and efficient\nsolution for large-scale genomic data acquisition, democratizing\nhigh-performance data retrieval for researchers without requiring specialized\ncommercial software or protocols.", "AI": {"tldr": "FastBioDL is a parallel downloader for large biological datasets that uses adaptive concurrency to improve download speed, achieving up to 4x faster performance compared to existing tools.", "motivation": "Researchers need efficient tools to download large-scale genomic datasets from public repositories, as current tools are unable to adapt to changing network conditions, leading to slow performance.", "method": "FastBioDL models the download as an online optimization problem, using a utility function and gradient descent to dynamically adjust concurrent socket streams for maximum throughput.", "result": "FastBioDL achieved up to a 4x speedup compared to existing tools on public genomic datasets and showed a 2.1x improvement even in high-speed networks.", "conclusion": "FastBioDL democratizes high-performance genomic data downloading by providing a fast, adaptive, and resource-efficient solution using standard protocols, eliminating the need for specialized software or hardware."}}
{"id": "2508.05009", "pdf": "https://arxiv.org/pdf/2508.05009", "abs": "https://arxiv.org/abs/2508.05009", "authors": ["Bin Han", "Robert Wolfe", "Anat Caspi", "Bill Howe"], "title": "Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "We explore the application of large language models (LLMs) to empower domain\nexperts in integrating large, heterogeneous, and noisy urban spatial datasets.\nTraditional rule-based integration methods are unable to cover all edge cases,\nrequiring manual verification and repair. Machine learning approaches require\ncollecting and labeling of large numbers of task-specific samples. In this\nstudy, we investigate the potential of LLMs for spatial data integration. Our\nanalysis first considers how LLMs reason about environmental spatial\nrelationships mediated by human experience, such as between roads and\nsidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they\nstruggle to connect the macro-scale environment with the relevant computational\ngeometry tasks, often producing logically incoherent responses. But when\nprovided relevant features, thereby reducing dependence on spatial reasoning,\nLLMs are able to generate high-performing results. We then adapt a\nreview-and-refine method, which proves remarkably effective in correcting\nerroneous initial responses while preserving accurate responses. We discuss\npractical implications of employing LLMs for spatial data integration in\nreal-world contexts and outline future research directions, including\npost-training, multi-modal integration methods, and support for diverse data\nformats. Our findings position LLMs as a promising and flexible alternative to\ntraditional rule-based heuristics, advancing the capabilities of adaptive\nspatial data integration.", "AI": {"tldr": "The paper investigates the use of large language models (LLMs) for integrating noisy urban spatial datasets, comparing effectiveness to traditional methods.", "motivation": "Traditional methods for spatial data integration struggle with edge cases and require manual intervention, while machine learning demands extensive labeled data. This paper aims to test LLMs as a potential solution.", "method": "The authors analyzed LLMs' reasoning about spatial relationships, tested how reducing dependence on spatial reasoning impacts performance, and applied a review-and-refine approach for improving responses.", "result": "LLMs exhibit spatial reasoning but fail on computational geometry tasks; however, refining their input features significantly boosts their performance.", "conclusion": "LLMs emerge as a promising alternative to rule-based heuristics for spatial data integration, with scope for enhancement through post-training and multi-modal methods."}}
{"id": "2508.05170", "pdf": "https://arxiv.org/pdf/2508.05170", "abs": "https://arxiv.org/abs/2508.05170", "authors": ["Lishui Fan", "Yu Zhang", "Mouxiang Chen", "Zhongxin Liu"], "title": "Posterior-GRPO: Rewarding Reasoning Processes in Code Generation", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Reinforcement learning (RL) has significantly advanced code generation for\nlarge language models (LLMs). However, current paradigms rely on outcome-based\nrewards from test cases, neglecting the quality of the intermediate reasoning\nprocess. While supervising the reasoning process directly is a promising\ndirection, it is highly susceptible to reward hacking, where the policy model\nlearns to exploit the reasoning reward signal without improving final outcomes.\nTo address this, we introduce a unified framework that can effectively\nincorporate the quality of the reasoning process during RL. First, to enable\nreasoning evaluation, we develop LCB-RB, a benchmark comprising preference\npairs of superior and inferior reasoning processes. Second, to accurately score\nreasoning quality, we introduce an Optimized-Degraded based (OD-based) method\nfor reward model training. This method generates high-quality preference pairs\nby systematically optimizing and degrading initial reasoning paths along\ncurated dimensions of reasoning quality, such as factual accuracy, logical\nrigor, and coherence. A 7B parameter reward model with this method achieves\nstate-of-the-art (SOTA) performance on LCB-RB and generalizes well to other\nbenchmarks. Finally, we introduce Posterior-GRPO (P-GRPO), a novel RL method\nthat conditions process-based rewards on task success. By selectively applying\nrewards to the reasoning processes of only successful outcomes, P-GRPO\neffectively mitigates reward hacking and aligns the model's internal reasoning\nwith final code correctness. A 7B parameter model with P-GRPO achieves superior\nperformance across diverse code generation tasks, outperforming outcome-only\nbaselines by 4.5%, achieving comparable performance to GPT-4-Turbo. We further\ndemonstrate the generalizability of our approach by extending it to\nmathematical tasks. Our models, dataset, and code are publicly available.", "AI": {"tldr": "The paper introduces methods to enhance reinforcement learning for code generation in large language models by focusing on reasoning process quality through new benchmarks, reward modeling techniques, and RL methods.", "motivation": "Existing RL paradigms for code generation neglect the intermediate reasoning process, which is crucial for high-quality outcomes and lead to reward hacking.", "method": "The authors developed the LCB-RB benchmark for reasoning evaluation, an OD-based reward model training method, and the Posterior-GRPO algorithm that applies reasoning-based rewards selectively on successful outcomes.", "result": "A reward model trained with the OD-based method achieved state-of-the-art performance on reasoning benchmarks. Models utilizing P-GRPO outperformed baselines by 4.5% and performed comparably to GPT-4-Turbo.", "conclusion": "Focusing on reasoning process quality significantly improves code generation RL models\u2019 performance and generalizability across diverse tasks, including mathematical reasoning."}}
{"id": "2508.05104", "pdf": "https://arxiv.org/pdf/2508.05104", "abs": "https://arxiv.org/abs/2508.05104", "authors": ["Andrej L\u00fa\u010dny", "Matilde Antonj", "Carlo Mazzola", "Hana Horn\u00e1\u010dkov\u00e1", "Ana Fari\u0107", "Krist\u00edna Malinovsk\u00e1", "Michal Vavrecka", "Igor Farka\u0161"], "title": "Examining the legibility of humanoid robot arm movements in a pointing task", "categories": ["cs.RO"], "comment": "Published at ICSR 2025", "summary": "Human--robot interaction requires robots whose actions are legible, allowing\nhumans to interpret, predict, and feel safe around them. This study\ninvestigates the legibility of humanoid robot arm movements in a pointing task,\naiming to understand how humans predict robot intentions from truncated\nmovements and bodily cues. We designed an experiment using the NICO humanoid\nrobot, where participants observed its arm movements towards targets on a\ntouchscreen. Robot cues varied across conditions: gaze, pointing, and pointing\nwith congruent or incongruent gaze. Arm trajectories were stopped at 60\\% or\n80\\% of their full length, and participants predicted the final target. We\ntested the multimodal superiority and ocular primacy hypotheses, both of which\nwere supported by the experiment.", "AI": {"tldr": "This study examines how humans interpret humanoid robot arm movements during pointing tasks by varying cues like gaze and stopping arm motions early, finding support for multimodal superiority and ocular primacy hypotheses.", "motivation": "The paper aims to improve human-robot interaction by exploring how humanoid robots can make their actions more legible and predictable to humans, ensuring safety and effective collaboration.", "method": "Participants observed the NICO humanoid robot performing pointing tasks using different cues (gaze and arm movements). The robot's arm trajectories were truncated, and participants predicted target destinations.", "result": "Results supported the multimodal superiority hypothesis (cues are better combined) and ocular primacy hypothesis (gaze plays a key role in predicting intentions).", "conclusion": "Multimodal robot cues, especially gaze, enhance understanding and prediction of robot actions, facilitating safer and better human-robot interaction."}}
{"id": "2508.04868", "pdf": "https://arxiv.org/pdf/2508.04868", "abs": "https://arxiv.org/abs/2508.04868", "authors": ["Noreen Anwar", "Guillaume-Alexandre Bilodeau", "Wassim Bouachir"], "title": "Dual-Stream Attention with Multi-Modal Queries for Object Detection in Transportation Applications", "categories": ["cs.CV"], "comment": "10 pages", "summary": "Transformer-based object detectors often struggle with occlusions,\nfine-grained localization, and computational inefficiency caused by fixed\nqueries and dense attention. We propose DAMM, Dual-stream Attention with\nMulti-Modal queries, a novel framework introducing both query adaptation and\nstructured cross-attention for improved accuracy and efficiency. DAMM\ncapitalizes on three types of queries: appearance-based queries from\nvision-language models, positional queries using polygonal embeddings, and\nrandom learned queries for general scene coverage. Furthermore, a dual-stream\ncross-attention module separately refines semantic and spatial features,\nboosting localization precision in cluttered scenes. We evaluated DAMM on four\nchallenging benchmarks, and it achieved state-of-the-art performance in average\nprecision (AP) and recall, demonstrating the effectiveness of multi-modal query\nadaptation and dual-stream attention. Source code is at:\n\\href{https://github.com/DET-LIP/DAMM}{GitHub}.", "AI": {"tldr": "The paper introduces DAMM, an improved object detection framework addressing occlusions, localization, and efficiency issues by using multi-modal queries and dual-stream cross-attention.", "motivation": "Transformers struggle with occlusions, fine-grained localization, and inefficiency due to fixed queries and dense attention in object detection tasks.", "method": "The paper proposes DAMM, a framework utilizing appearance-based, positional, and random queries, alongside a dual-stream cross-attention module, to improve detection accuracy and efficiency.", "result": "DAMM achieved state-of-the-art performance in average precision (AP) and recall on four challenging benchmarks.", "conclusion": "The multi-modal query adaptation and dual-stream attention strategy employed by DAMM effectively enhance object detection under challenging scenarios."}}
{"id": "2508.05003", "pdf": "https://arxiv.org/pdf/2508.05003", "abs": "https://arxiv.org/abs/2508.05003", "authors": ["Song Wang", "Yishu Wei", "Haotian Ma", "Max Lovitt", "Kelly Deng", "Yuan Meng", "Zihan Xu", "Jingze Zhang", "Yunyu Xiao", "Ying Ding", "Xuhai Xu", "Joydeep Ghosh", "Yifan Peng"], "title": "A Multi-Stage Large Language Model Framework for Extracting Suicide-Related Social Determinants of Health", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Background: Understanding social determinants of health (SDoH) factors\ncontributing to suicide incidents is crucial for early intervention and\nprevention. However, data-driven approaches to this goal face challenges such\nas long-tailed factor distributions, analyzing pivotal stressors preceding\nsuicide incidents, and limited model explainability. Methods: We present a\nmulti-stage large language model framework to enhance SDoH factor extraction\nfrom unstructured text. Our approach was compared to other state-of-the-art\nlanguage models (i.e., pre-trained BioBERT and GPT-3.5-turbo) and reasoning\nmodels (i.e., DeepSeek-R1). We also evaluated how the model's explanations help\npeople annotate SDoH factors more quickly and accurately. The analysis included\nboth automated comparisons and a pilot user study. Results: We show that our\nproposed framework demonstrated performance boosts in the overarching task of\nextracting SDoH factors and in the finer-grained tasks of retrieving relevant\ncontext. Additionally, we show that fine-tuning a smaller, task-specific model\nachieves comparable or better performance with reduced inference costs. The\nmulti-stage design not only enhances extraction but also provides intermediate\nexplanations, improving model explainability. Conclusions: Our approach\nimproves both the accuracy and transparency of extracting suicide-related SDoH\nfrom unstructured texts. These advancements have the potential to support early\nidentification of individuals at risk and inform more effective prevention\nstrategies.", "AI": {"tldr": "The study develops a multi-stage language model framework to improve the extraction of social determinants of health (SDoH) related to suicide incidents, achieving better accuracy, explainability, and efficiency compared to existing methods.", "motivation": "The study aims to address challenges in data-driven analysis of suicide incidents, particularly the difficulty in handling long-tailed SDoH factor distributions, identifying pivotal stressors, and enhancing model explainability.", "method": "A multi-stage large language model was developed and tested against state-of-the-art language models like BioBERT and GPT-3.5-turbo and reasoning models like DeepSeek-R1. The study also conducted a pilot user study to evaluate annotation speed and accuracy with model explanations.", "result": "The proposed framework outperformed existing models in extracting SDoH factors and retrieving relevant contexts. Fine-tuning smaller, task-specific models delivered comparable or better results with reduced costs. The framework also improved model explainability through intermediate explanations.", "conclusion": "The approach advances both the precision and transparency of SDoH extraction related to suicide, enabling more accurate identification of at-risk individuals and potential improvements in suicide prevention strategies."}}
{"id": "2508.04753", "pdf": "https://arxiv.org/pdf/2508.04753", "abs": "https://arxiv.org/abs/2508.04753", "authors": ["Mehmet Emre Akbulut", "Hazem Hesham Yousef Shalby", "Fabrizio Pittorino", "Manuel Roveri"], "title": "InfoQ: Mixed-Precision Quantization via Global Information Flow", "categories": ["cs.LG"], "comment": null, "summary": "Mixed-precision quantization (MPQ) is crucial for deploying deep neural\nnetworks on resource-constrained devices, but finding the optimal bit-width for\neach layer represents a complex combinatorial optimization problem. Current\nstate-of-the-art methods rely on computationally expensive search algorithms or\nlocal sensitivity heuristic proxies like the Hessian, which fail to capture the\ncascading global effects of quantization error. In this work, we argue that the\nquantization sensitivity of a layer should not be measured by its local\nproperties, but by its impact on the information flow throughout the entire\nnetwork. We introduce InfoQ, a novel framework for MPQ that is training-free in\nthe bit-width search phase. InfoQ assesses layer sensitivity by quantizing each\nlayer at different bit-widths and measuring, through a single forward pass, the\nresulting change in mutual information in the subsequent layers. This\nquantifies how much each layer quantization impacts the network information\nflow. The resulting scores are used to formulate bit-width allocation as an\ninteger linear programming problem, which is solved efficiently to minimize\ntotal sensitivity under a given budget (e.g., model size or BitOps). Our\nretraining-free search phase provides a superior search-time/accuracy trade-off\n(using two orders of magnitude less data compared to state-of-the-art methods\nsuch as LIMPQ), while yielding up to a 1% accuracy improvement for MobileNetV2\nand ResNet18 on ImageNet at high compression rates (14X and 10.66X).", "AI": {"tldr": "The paper introduces a training-free framework (InfoQ) for mixed-precision quantization (MPQ) that improves network quantization by focusing on the information flow disruption caused in layers and achieves better efficiency and accuracy.", "motivation": "The paper aims to address the computational complexity and inefficiency of finding the optimal bit-width for neural network layers, highlighting the limitations of current methods which use expensive searches or local sensitivity assessments that overlook global network effects.", "method": "The authors propose InfoQ, a method that quantizes each layer at various bit-widths and measures mutual information changes through a single forward pass. These scores are used to solve bit-width allocation as an integer linear programming problem under a resource budget.", "result": "InfoQ provides a significantly better search-time/accuracy trade-off compared to state-of-the-art methods (e.g., using two orders of magnitude less data than LIMPQ) and achieves up to a 1% accuracy improvement for compressed MobileNetV2 and ResNet18 models.", "conclusion": "InfoQ reframes sensitivity measurement to account for global network effects, offering an efficient and retraining-free MPQ framework. This approach achieves better performance with lower computational costs, making it practical for resource-limited environments."}}
{"id": "2508.05546", "pdf": "https://arxiv.org/pdf/2508.05546", "abs": "https://arxiv.org/abs/2508.05546", "authors": ["Rasman Mubtasim Swargo", "Engin Arslan", "Md Arifuzzaman"], "title": "Modular Architecture for High-Performance and Low Overhead Data Transfers", "categories": ["cs.DC"], "comment": null, "summary": "High-performance applications necessitate rapid and dependable transfer of\nmassive datasets across geographically dispersed locations. Traditional file\ntransfer tools often suffer from resource underutilization and instability\nbecause of fixed configurations or monolithic optimization methods. We propose\nAutoMDT, a novel modular data transfer architecture that employs a deep\nreinforcement learning based agent to simultaneously optimize concurrency\nlevels for read, network, and write operations. Our solution incorporates a\nlightweight network-system simulator, enabling offline training of a Proximal\nPolicy Optimization (PPO) agent in approximately 45 minutes on average, thereby\novercoming the impracticality of lengthy online training in production\nnetworks. AutoMDT's modular design decouples I/O and network tasks, allowing\nthe agent to capture complex buffer dynamics precisely and to adapt quickly to\nchanging system and network conditions. Evaluations on production-grade\ntestbeds show that AutoMDT achieves up to 8x faster convergence and a 68%\nreduction in transfer completion times compared with state-of-the-art\nsolutions.", "AI": {"tldr": "AutoMDT is a modular architecture for efficient data transfer using deep reinforcement learning, reducing completion times by 68%.", "motivation": "Traditional file transfer tools are inefficient due to fixed configurations and monolithic optimization approaches, causing resource underutilization.", "method": "AutoMDT employs a modular design with a deep reinforcement learning agent using Proximal Policy Optimization for offline training in a lightweight simulator.", "result": "AutoMDT achieves up to 8x faster convergence and reduces transfer completion times by 68% compared to existing solutions.", "conclusion": "The modular architecture and adaptive capabilities of AutoMDT significantly enhance data transfer performance across geographically dispersed systems."}}
{"id": "2508.05081", "pdf": "https://arxiv.org/pdf/2508.05081", "abs": "https://arxiv.org/abs/2508.05081", "authors": ["Jiarun Liu", "Chunhong Zhang", "Zheng Hu"], "title": "Cognitive Duality for Adaptive Web Agents", "categories": ["cs.AI", "cs.CL", "cs.MA"], "comment": null, "summary": "Web navigation represents a critical and challenging domain for evaluating\nartificial general intelligence (AGI), demanding complex decision-making within\nhigh-entropy, dynamic environments with combinatorially explosive action\nspaces. Current approaches to building autonomous web agents either focus on\noffline imitation learning or online exploration, but rarely integrate both\nparadigms effectively. Inspired by the dual-process theory of human cognition,\nwe derive a principled decomposition into fast System 1 and slow System 2\ncognitive processes. This decomposition provides a unifying perspective on\nexisting web agent methodologies, bridging the gap between offline learning of\nintuitive reactive behaviors and online acquisition of deliberative planning\ncapabilities. We implement this framework in CogniWeb, a modular agent\narchitecture that adaptively toggles between fast intuitive processing and\ndeliberate reasoning based on task complexity. Our evaluation on WebArena\ndemonstrates that CogniWeb achieves competitive performance (43.96% success\nrate) while maintaining significantly higher efficiency (75% reduction in token\nusage).", "AI": {"tldr": "The paper introduces CogniWeb, an autonomous web navigation agent inspired by dual-process theory, combining fast intuitive processing and slow deliberative reasoning to achieve competitive success rates and higher efficiency.", "motivation": "The paper addresses the challenge of building autonomous web agents capable of effective decision-making in complex, dynamic environments, and integrates offline imitation learning with online exploration.", "method": "The method involves using a dual-process cognitive framework to design CogniWeb, which toggles between fast intuitive processing (System 1) and slow deliberative reasoning (System 2) based on task complexity.", "result": "CogniWeb achieved a 43.96% success rate and a 75% reduction in token usage during evaluation on WebArena, demonstrating both competitive performance and efficiency.", "conclusion": "The dual-process framework implemented in CogniWeb provides an effective approach for web navigation tasks, combining intuitive offline behaviors with deliberative online planning for optimal efficiency and performance."}}
{"id": "2508.05192", "pdf": "https://arxiv.org/pdf/2508.05192", "abs": "https://arxiv.org/abs/2508.05192", "authors": ["Felix Neubauer", "J\u00fcrgen Pleiss", "Benjamin Uekermann"], "title": "AI-assisted JSON Schema Creation and Mapping", "categories": ["cs.SE", "H.2.3; I.2.6; D.2.2"], "comment": "Accepted for Tools and Demonstrations Track of ACM/IEEE MODELS'25", "summary": "Model-Driven Engineering (MDE) places models at the core of system and data\nengineering processes. In the context of research data, these models are\ntypically expressed as schemas that define the structure and semantics of\ndatasets. However, many domains still lack standardized models, and creating\nthem remains a significant barrier, especially for non-experts. We present a\nhybrid approach that combines large language models (LLMs) with deterministic\ntechniques to enable JSON Schema creation, modification, and schema mapping\nbased on natural language inputs by the user. These capabilities are integrated\ninto the open-source tool MetaConfigurator, which already provides visual model\nediting, validation, code generation, and form generation from models. For data\nintegration, we generate schema mappings from heterogeneous JSON, CSV, XML, and\nYAML data using LLMs, while ensuring scalability and reliability through\ndeterministic execution of generated mapping rules. The applicability of our\nwork is demonstrated in an application example in the field of chemistry. By\ncombining natural language interaction with deterministic safeguards, this work\nsignificantly lowers the barrier to structured data modeling and data\nintegration for non-experts.", "AI": {"tldr": "The paper introduces a hybrid approach combining large language models (LLMs) and deterministic techniques for JSON Schema creation and data integration using natural language inputs, integrated into the MetaConfigurator tool.", "motivation": "To address the lack of standardized models across various domains and reduce the barriers for non-experts in structured data modeling and data integration.", "method": "The approach utilizes a combination of LLMs and deterministic techniques, integrated into the MetaConfigurator tool, for creating, modifying, and mapping JSON Schemas based on user inputs. The deterministic safeguards ensure scalability and reliability.", "result": "The solution provides automated JSON Schema creation and mappings across heterogeneous data formats like JSON, CSV, XML, and YAML, demonstrated in an example from the field of chemistry.", "conclusion": "This hybrid approach enhances accessibility to structured data modeling and data integration for non-experts, bridging gaps with natural language interaction and reliable execution."}}
{"id": "2508.05143", "pdf": "https://arxiv.org/pdf/2508.05143", "abs": "https://arxiv.org/abs/2508.05143", "authors": ["Sim\u00e9on Capy", "Thomas M. Kwok", "Kevin Joseph", "Yuichiro Kawasumi", "Koichi Nagashima", "Tomoya Sasaki", "Yue Hu", "Eiichi Yoshida"], "title": "From Canada to Japan: How 10,000 km Affect User Perception in Robot Teleoperation", "categories": ["cs.RO"], "comment": "Author preprint - Accepted for Humanoids 2025", "summary": "Robot teleoperation (RTo) has emerged as a viable alternative to local\ncontrol, particularly when human intervention is still necessary. This research\naims to study the distance effect on user perception in RTo, exploring the\npotential of teleoperated robots for older adult care. We propose an evaluation\nof non-expert users' perception of long-distance RTo, examining how their\nperception changes before and after interaction, as well as comparing it to\nthat of locally operated robots. We have designed a specific protocol\nconsisting of multiple questionnaires, along with a dedicated software\narchitecture using the Robotics Operating System (ROS) and Unity. The results\nrevealed no statistically significant differences between the local and remote\nrobot conditions, suggesting that robots may be a viable alternative to\ntraditional local control.", "AI": {"tldr": "The study investigates user perception of long-distance versus local robot teleoperation, finding no major differences between the two.", "motivation": "Explore the utility of robot teleoperation for tasks requiring human intervention, particularly in elder care.", "method": "Develop a protocol with questionnaires and implement software using ROS and Unity to evaluate user perception.", "result": "Statistical analysis showed no significant difference in perception between local and remote robot operation.", "conclusion": "Robot teleoperation can be as effective as local control, potentially enabling broader applications in elder care."}}
{"id": "2508.04900", "pdf": "https://arxiv.org/pdf/2508.04900", "abs": "https://arxiv.org/abs/2508.04900", "authors": ["Shuonan Yang", "Tailin Chen", "Rahul Singh", "Jiangbei Yue", "Jianbo Jiao", "Zeyu Fu"], "title": "Revealing Temporal Label Noise in Multimodal Hateful Video Classification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The rapid proliferation of online multimedia content has intensified the\nspread of hate speech, presenting critical societal and regulatory challenges.\nWhile recent work has advanced multimodal hateful video detection, most\napproaches rely on coarse, video-level annotations that overlook the temporal\ngranularity of hateful content. This introduces substantial label noise, as\nvideos annotated as hateful often contain long non-hateful segments. In this\npaper, we investigate the impact of such label ambiguity through a fine-grained\napproach. Specifically, we trim hateful videos from the HateMM and\nMultiHateClip English datasets using annotated timestamps to isolate explicitly\nhateful segments. We then conduct an exploratory analysis of these trimmed\nsegments to examine the distribution and characteristics of both hateful and\nnon-hateful content. This analysis highlights the degree of semantic overlap\nand the confusion introduced by coarse, video-level annotations. Finally,\ncontrolled experiments demonstrated that time-stamp noise fundamentally alters\nmodel decision boundaries and weakens classification confidence, highlighting\nthe inherent context dependency and temporal continuity of hate speech\nexpression. Our findings provide new insights into the temporal dynamics of\nmultimodal hateful videos and highlight the need for temporally aware models\nand benchmarks for improved robustness and interpretability. Code and data are\navailable at\nhttps://github.com/Multimodal-Intelligence-Lab-MIL/HatefulVideoLabelNoise.", "AI": {"tldr": "This paper highlights the issue of coarse video-level annotations in multimodal hateful video detection, emphasizing the importance of temporally fine-grained approaches.", "motivation": "The proliferation of hateful content in online multimedia necessitates robust detection methods. Current techniques using coarse video-level annotations fail to address the temporal granularity, leading to label noise and reduced model performance.", "method": "The authors trim hateful videos from two datasets using annotated timestamps to isolate explicitly hateful segments. They then conduct exploratory analyses and perform controlled experiments to investigate the impact of temporal noise on model performance.", "result": "Their analysis shows significant semantic overlap and confusion due to coarse annotations. Experiments reveal that timestamp noise alters decision boundaries and reduces classification confidence, highlighting the importance of temporal context.", "conclusion": "The study underscores the need for temporally aware models and benchmarks to improve the robustness and interpretability of hateful video detection systems."}}
{"id": "2508.05023", "pdf": "https://arxiv.org/pdf/2508.05023", "abs": "https://arxiv.org/abs/2508.05023", "authors": ["Kun Peng", "Cong Cao", "Hao Peng", "Zhifeng Hao", "Lei Jiang", "Kongjing Gu", "Yanbing Liu", "Philip S. Yu"], "title": "Dialogues Aspect-based Sentiment Quadruple Extraction via Structural Entropy Minimization Partitioning", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by CIKM2025", "summary": "Dialogues Aspect-based Sentiment Quadruple Extraction (DiaASQ) aims to\nextract all target-aspect-opinion-sentiment quadruples from a given\nmulti-round, multi-participant dialogue. Existing methods typically learn word\nrelations across entire dialogues, assuming a uniform distribution of sentiment\nelements. However, we find that dialogues often contain multiple semantically\nindependent sub-dialogues without clear dependencies between them. Therefore,\nlearning word relationships across the entire dialogue inevitably introduces\nadditional noise into the extraction process. To address this, our method\nfocuses on partitioning dialogues into semantically independent sub-dialogues.\nAchieving completeness while minimizing these sub-dialogues presents a\nsignificant challenge. Simply partitioning based on reply relationships is\nineffective. Instead, we propose utilizing a structural entropy minimization\nalgorithm to partition the dialogues. This approach aims to preserve relevant\nutterances while distinguishing irrelevant ones as much as possible.\nFurthermore, we introduce a two-step framework for quadruple extraction: first\nextracting individual sentiment elements at the utterance level, then matching\nquadruples at the sub-dialogue level. Extensive experiments demonstrate that\nour approach achieves state-of-the-art performance in DiaASQ with much lower\ncomputational costs.", "AI": {"tldr": "The paper presents a novel approach for Dialogues Aspect-based Sentiment Quadruple Extraction (DiaASQ), focusing on partitioning dialogues into semantically independent sub-dialogues, significantly improving extraction accuracy and computational efficiency.", "motivation": "Current methods assume uniform distribution of sentiment elements across dialogues, which is ineffective due to the presence of multiple semantically independent sub-dialogues. This results in noise and inefficiencies in extraction.", "method": "The paper proposes a method involving structural entropy minimization to partition dialogues into independent sub-dialogues, coupled with a two-step framework: extract sentiment elements at the utterance level and match quadruples at the sub-dialogue level.", "result": "Experiments show the proposed method achieves state-of-the-art performance in DiaASQ tasks, with significantly lower computational costs compared to existing techniques.", "conclusion": "Partitioning dialogues into semantically independent sub-dialogues eliminates noise and improves accuracy, marking a substantial improvement over previous methods in sentiment quadruple extraction tasks."}}
{"id": "2508.04830", "pdf": "https://arxiv.org/pdf/2508.04830", "abs": "https://arxiv.org/abs/2508.04830", "authors": ["Jonathan Benchimol", "Sophia Kazinnik", "Yossi Saadon"], "title": "Federal Reserve Communication and the COVID-19 Pandemic", "categories": ["econ.GN", "cs.CL", "cs.IT", "math.IT", "q-fin.EC", "stat.AP", "stat.ML"], "comment": null, "summary": "In this study, we examine the Federal Reserve's communication strategies\nduring the COVID-19 pandemic, comparing them with communication during previous\nperiods of economic stress. Using specialized dictionaries tailored to\nCOVID-19, unconventional monetary policy (UMP), and financial stability,\ncombined with sentiment analysis and topic modeling techniques, we identify a\ndistinct focus in Fed communication during the pandemic on financial stability,\nmarket volatility, social welfare, and UMP, characterized by notable contextual\nuncertainty. Through comparative analysis, we juxtapose the Fed's communication\nduring the COVID-19 crisis with its responses during the dot-com and global\nfinancial crises, examining content, sentiment, and timing dimensions. Our\nfindings reveal that Fed communication and policy actions were more reactive to\nthe COVID-19 crisis than to previous crises. Additionally, declining sentiment\nrelated to financial stability in interest rate announcements and minutes\nanticipated subsequent accommodative monetary policy decisions. We further\ndocument that communicating about UMP has become the \"new normal\" for the Fed's\nFederal Open Market Committee meeting minutes and Chairman's speeches since the\nGlobal Financial Crisis, reflecting an institutional adaptation in\ncommunication strategy following periods of economic distress. These findings\ncontribute to our understanding of how central bank communication evolves\nduring crises and how communication strategies adapt to exceptional economic\ncircumstances.", "AI": {"tldr": "This paper analyzes the Federal Reserve's evolving communication strategies during COVID-19 compared to previous crises, revealing a reactive approach and adaptation to unconventional monetary policy (UMP).", "motivation": "To understand how central banks adapt communication strategies during exceptional economic circumstances like crises.", "method": "The study utilizes specialized dictionaries, sentiment analysis, and topic modeling to analyze Fed communication content, sentiment, and timing during different economic crises.", "result": "Findings show that Fed communication during COVID-19 prioritized financial stability and unconventional monetary policies, with reactiveness surpassing other crises like the dot-com and global financial crises.", "conclusion": "Fed communication has evolved, institutionalizing unconventional monetary policy discussion as a standard post-crisis adaptation, contributing to effective crisis management."}}
{"id": "2508.04755", "pdf": "https://arxiv.org/pdf/2508.04755", "abs": "https://arxiv.org/abs/2508.04755", "authors": ["Zhiyao Luo", "Tingting Zhu"], "title": "Are Large Language Models Dynamic Treatment Planners? An In Silico Study from a Prior Knowledge Injection Angle", "categories": ["cs.LG", "cs.CE"], "comment": "20 pages", "summary": "Reinforcement learning (RL)-based dynamic treatment regimes (DTRs) hold\npromise for automating complex clinical decision-making, yet their practical\ndeployment remains hindered by the intensive engineering required to inject\nclinical knowledge and ensure patient safety. Recent advancements in large\nlanguage models (LLMs) suggest a complementary approach, where implicit prior\nknowledge and clinical heuristics are naturally embedded through linguistic\nprompts without requiring environment-specific training. In this study, we\nrigorously evaluate open-source LLMs as dynamic insulin dosing agents in an in\nsilico Type 1 diabetes simulator, comparing their zero-shot inference\nperformance against small neural network-based RL agents (SRAs) explicitly\ntrained for the task. Our results indicate that carefully designed zero-shot\nprompts enable smaller LLMs (e.g., Qwen2.5-7B) to achieve comparable or\nsuperior clinical performance relative to extensively trained SRAs,\nparticularly in stable patient cohorts. However, LLMs exhibit notable\nlimitations, such as overly aggressive insulin dosing when prompted with\nchain-of-thought (CoT) reasoning, highlighting critical failure modes including\narithmetic hallucination, temporal misinterpretation, and inconsistent clinical\nlogic. Incorporating explicit reasoning about latent clinical states (e.g.,\nmeals) yielded minimal performance gains, underscoring the current model's\nlimitations in capturing complex, hidden physiological dynamics solely through\ntextual inference. Our findings advocate for cautious yet optimistic\nintegration of LLMs into clinical workflows, emphasising the necessity of\ntargeted prompt engineering, careful validation, and potentially hybrid\napproaches that combine linguistic reasoning with structured physiological\nmodelling to achieve safe, robust, and clinically effective decision-support\nsystems.", "AI": {"tldr": "The paper explores the use of large language models (LLMs) as dynamic insulin dosing agents, showing promise in certain scenarios but highlighting their limitations in complex clinical inference.", "motivation": "The study aims to address challenges in deploying reinforcement-learning-based dynamic treatment regimes for clinical decision-making, leveraging LLMs to embed clinical heuristics without intensive engineering.", "method": "The authors conducted a rigorous evaluation by comparing zero-shot inference performance of open-source LLMs to trained small neural network-based RL agents in a Type 1 diabetes simulator.", "result": "LLMs demonstrated competitive clinical performance with well-designed prompts but showed significant limitations like aggressive dosing and reasoning failures in complex cases.", "conclusion": "Cautious adoption of LLMs in clinical workflows is recommended, integrating prompt engineering and hybrid approaches for safe and effective solutions."}}
{"id": "2508.05135", "pdf": "https://arxiv.org/pdf/2508.05135", "abs": "https://arxiv.org/abs/2508.05135", "authors": ["Thinh Nguyen", "Trung Phan", "Binh T. Nguyen", "Khoa D Doan", "Kok-Seng Wong"], "title": "HFedATM: Hierarchical Federated Domain Generalization via Optimal Transport and Regularized Mean Aggregation", "categories": ["cs.LG", "cs.DC", "C.2.4; I.2.11"], "comment": "11 pages, 3 figures", "summary": "Federated Learning (FL) is a decentralized approach where multiple clients\ncollaboratively train a shared global model without sharing their raw data.\nDespite its effectiveness, conventional FL faces scalability challenges due to\nexcessive computational and communication demands placed on a single central\nserver as the number of participating devices grows. Hierarchical Federated\nLearning (HFL) addresses these issues by distributing model aggregation tasks\nacross intermediate nodes (stations), thereby enhancing system scalability and\nrobustness against single points of failure. However, HFL still suffers from a\ncritical yet often overlooked limitation: domain shift, where data\ndistributions vary significantly across different clients and stations,\nreducing model performance on unseen target domains. While Federated Domain\nGeneralization (FedDG) methods have emerged to improve robustness to domain\nshifts, their integration into HFL frameworks remains largely unexplored. In\nthis paper, we formally introduce Hierarchical Federated Domain Generalization\n(HFedDG), a novel scenario designed to investigate domain shift within\nhierarchical architectures. Specifically, we propose HFedATM, a hierarchical\naggregation method that first aligns the convolutional filters of models from\ndifferent stations through Filter-wise Optimal Transport Alignment and\nsubsequently merges aligned models using a Shrinkage-aware Regularized Mean\nAggregation. Our extensive experimental evaluations demonstrate that HFedATM\nsignificantly boosts the performance of existing FedDG baselines across\nmultiple datasets and maintains computational and communication efficiency.\nMoreover, theoretical analyses indicate that HFedATM achieves tighter\ngeneralization error bounds compared to standard hierarchical averaging,\nresulting in faster convergence and stable training behavior.", "AI": {"tldr": "The paper introduces HFedATM, a method to improve robustness against domain shifts in Hierarchical Federated Learning by aligning and merging models more effectively.", "motivation": "The motivation of the paper is to address the challenges of domain shifts in Hierarchical Federated Learning frameworks, which negatively affect model performance across different data distributions.", "method": "The proposed HFedATM method involves aligning convolutional filters using Filter-wise Optimal Transport Alignment and merging models through Shrinkage-aware Regularized Mean Aggregation.", "result": "Experimental results show HFedATM significantly improves Federated Domain Generalization performance across datasets while being computationally and communication-efficient. Theoretical analysis confirms improved generalization error bounds and faster convergence.", "conclusion": "HFedATM enhances performance and robustness in Hierarchical Federated Learning under domain shift conditions, showing potential for real-world distributed systems with diverse data distributions."}}
{"id": "2508.05083", "pdf": "https://arxiv.org/pdf/2508.05083", "abs": "https://arxiv.org/abs/2508.05083", "authors": ["Dexuan Xu", "Jieyi Wang", "Zhongyan Chai", "Yongzhi Cao", "Hanpin Wang", "Huamin Zhang", "Yu Huang"], "title": "MedMKEB: A Comprehensive Knowledge Editing Benchmark for Medical Multimodal Large Language Models", "categories": ["cs.AI"], "comment": "18 pages", "summary": "Recent advances in multimodal large language models (MLLMs) have\nsignificantly improved medical AI, enabling it to unify the understanding of\nvisual and textual information. However, as medical knowledge continues to\nevolve, it is critical to allow these models to efficiently update outdated or\nincorrect information without retraining from scratch. Although textual\nknowledge editing has been widely studied, there is still a lack of systematic\nbenchmarks for multimodal medical knowledge editing involving image and text\nmodalities. To fill this gap, we present MedMKEB, the first comprehensive\nbenchmark designed to evaluate the reliability, generality, locality,\nportability, and robustness of knowledge editing in medical multimodal large\nlanguage models. MedMKEB is built on a high-quality medical visual\nquestion-answering dataset and enriched with carefully constructed editing\ntasks, including counterfactual correction, semantic generalization, knowledge\ntransfer, and adversarial robustness. We incorporate human expert validation to\nensure the accuracy and reliability of the benchmark. Extensive single editing\nand sequential editing experiments on state-of-the-art general and medical\nMLLMs demonstrate the limitations of existing knowledge-based editing\napproaches in medicine, highlighting the need to develop specialized editing\nstrategies. MedMKEB will serve as a standard benchmark to promote the\ndevelopment of trustworthy and efficient medical knowledge editing algorithms.", "AI": {"tldr": "The paper introduces MedMKEB, a benchmark for evaluating medical multimodal language model editing capabilities across various criteria and editing tasks.", "motivation": "To address the evolving nature of medical knowledge and the need for efficient updates in multimodal medical AI models, without full model retraining.", "method": "MedMKEB consists of carefully constructed editing tasks and validations like counterfactual correction, semantic generalization, and adversarial robustness, tested with expert feedback and experimentation on existing models.", "result": "Experiments reveal significant limitations in current knowledge-editing methods for medical multimodal models, highlighting areas for improvement.", "conclusion": "MedMKEB offers a standardized measurement tool to drive progress in developing efficient and trustworthy editing strategies for multimodal medical knowledge systems."}}
{"id": "2508.05193", "pdf": "https://arxiv.org/pdf/2508.05193", "abs": "https://arxiv.org/abs/2508.05193", "authors": ["Kaiwen Yan", "Yuhang Chang", "Zirui Guo", "Yaling Mou", "Jiang Ming", "Jingwei Sun"], "title": "STEPWISE-CODEX-Bench: Evaluating Complex Multi-Function Comprehension and Fine-Grained Execution Reasoning", "categories": ["cs.SE"], "comment": null, "summary": "In recent years, large language models (LLMs) have made significant progress\nin code intelligence, yet systematically evaluating their code understanding\nand reasoning abilities remains challenging. Mainstream benchmarks such as\nHumanEval and MBPP primarily assess functional correctness, while reasoning\nbenchmarks like CRUXEVAL are limited to single-function, low-complexity\nscenarios. As a result, advanced models achieve nearly saturated scores,\nlimiting their discriminative power. To address this, we present\nSTEPWISE-CODEX-Bench (SX-Bench), a novel benchmark designed for complex\nmulti-function understanding and fine-grained execution reasoning. SX-Bench\nfeatures tasks involving collaboration among multiple sub-functions (e.g.,\nchained calls, nested loops), shifting evaluation towards overall control and\ndata flow modeling. It defines \"computation steps\" as the minimal execution\nunit and requires models to predict the total number of steps in reasoning\ntasks, thereby assessing a model's in-depth understanding of dynamic execution\nbeyond simple I/O matching. Evaluation on over 20 mainstream models (including\n14 reasoning-enhanced models) demonstrates that SX-Bench is highly\ndiscriminative: even the state-of-the-art OpenAI-O3 achieves only 78.37 percent\naccuracy on Hard-Reasoning tasks, much lower than its saturated scores on\nprevious benchmarks, thereby revealing bottlenecks in complex and fine-grained\nreasoning. We also release an automated pipeline combining program synthesis,\nsymbolic execution, and LLM-aided validation for efficient benchmark generation\nand quality assurance. SX-Bench advances code evaluation from \"single-function\nverification\" to \"multi-function dynamic reasoning,\" providing a key tool for\nthe in-depth assessment of advanced code intelligence models.", "AI": {"tldr": "STEPWISE-CODEX-Bench (SX-Bench) is a new benchmark addressing the limitations of current code reasoning evaluations by focusing on complex multi-function scenarios and fine-grained execution reasoning.", "motivation": "Current benchmarks fail to adequately assess large language models in complex reasoning scenarios, leading to nearly saturated scores for advanced models.", "method": "SX-Bench employs tasks with multi-function collaboration and evaluates models' understanding using computation steps, incorporating dynamic reasoning beyond simple input/output assessments.", "result": "Evaluation of over 20 models reveals SX-Bench's high discrimination power, exposing weaknesses in current state-of-the-art systems like OpenAI-O3 on complex reasoning.", "conclusion": "SX-Bench enhances code intelligence evaluation by shifting focus to multi-function dynamic reasoning, addressing bottlenecks in existing benchmarks and improving assessment of advanced models."}}
{"id": "2508.05148", "pdf": "https://arxiv.org/pdf/2508.05148", "abs": "https://arxiv.org/abs/2508.05148", "authors": ["Francisco Munguia-Galeano", "Zhengxue Zhou", "Satheeshkumar Veeramani", "Hatem Fakhruldeen", "Louis Longley", "Rob Clowes", "Andrew I. Cooper"], "title": "Chemist Eye: A Visual Language Model-Powered System for Safety Monitoring and Robot Decision-Making in Self-Driving Laboratories", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "The integration of robotics and automation into self-driving laboratories\n(SDLs) can introduce additional safety complexities, in addition to those that\nalready apply to conventional research laboratories. Personal protective\nequipment (PPE) is an essential requirement for ensuring the safety and\nwell-being of workers in laboratories, self-driving or otherwise. Fires are\nanother important risk factor in chemical laboratories. In SDLs, fires that\noccur close to mobile robots, which use flammable lithium batteries, could have\nincreased severity. Here, we present Chemist Eye, a distributed safety\nmonitoring system designed to enhance situational awareness in SDLs. The system\nintegrates multiple stations equipped with RGB, depth, and infrared cameras,\ndesigned to monitor incidents in SDLs. Chemist Eye is also designed to spot\nworkers who have suffered a potential accident or medical emergency, PPE\ncompliance and fire hazards. To do this, Chemist Eye uses decision-making\ndriven by a vision-language model (VLM). Chemist Eye is designed for seamless\nintegration, enabling real-time communication with robots. Based on the VLM\nrecommendations, the system attempts to drive mobile robots away from potential\nfire locations, exits, or individuals not wearing PPE, and issues audible\nwarnings where necessary. It also integrates with third-party messaging\nplatforms to provide instant notifications to lab personnel. We tested Chemist\nEye with real-world data from an SDL equipped with three mobile robots and\nfound that the spotting of possible safety hazards and decision-making\nperformances reached 97 % and 95 %, respectively.", "AI": {"tldr": "The paper introduces Chemist Eye, an AI-driven safety monitoring system for self-driving laboratories that achieves high accuracy in hazard detection and decision-making.", "motivation": "The motivation is to address the additional safety risks posed by integrating robotics, such as fire hazards from lithium batteries and the need for PPE compliance, into self-driving laboratories.", "method": "The system uses RGB, depth, and infrared cameras along with a vision-language model (VLM) to detect fire hazards, PPE compliance, and worker emergencies in real time.", "result": "Chemist Eye was tested in a self-driving lab with three mobile robots, achieving a 97% accuracy in hazard detection and 95% in decision-making.", "conclusion": "Chemist Eye effectively enhances safety in self-driving labs by integrating real-time monitoring, decision-making, and notification mechanisms."}}
{"id": "2508.04924", "pdf": "https://arxiv.org/pdf/2508.04924", "abs": "https://arxiv.org/abs/2508.04924", "authors": ["Zahidul Islam", "Sujoy Paul", "Mrigank Rochan"], "title": "Test-Time Adaptation for Video Highlight Detection Using Meta-Auxiliary Learning and Cross-Modality Hallucinations", "categories": ["cs.CV"], "comment": null, "summary": "Existing video highlight detection methods, although advanced, struggle to\ngeneralize well to all test videos. These methods typically employ a generic\nhighlight detection model for each test video, which is suboptimal as it fails\nto account for the unique characteristics and variations of individual test\nvideos. Such fixed models do not adapt to the diverse content, styles, or audio\nand visual qualities present in new, unseen test videos, leading to reduced\nhighlight detection performance. In this paper, we propose Highlight-TTA, a\ntest-time adaptation framework for video highlight detection that addresses\nthis limitation by dynamically adapting the model during testing to better\nalign with the specific characteristics of each test video, thereby improving\ngeneralization and highlight detection performance. Highlight-TTA is jointly\noptimized with an auxiliary task, cross-modality hallucinations, alongside the\nprimary highlight detection task. We utilize a meta-auxiliary training scheme\nto enable effective adaptation through the auxiliary task while enhancing the\nprimary task. During testing, we adapt the trained model using the auxiliary\ntask on the test video to further enhance its highlight detection performance.\nExtensive experiments with three state-of-the-art highlight detection models\nand three benchmark datasets show that the introduction of Highlight-TTA to\nthese models improves their performance, yielding superior results.", "AI": {"tldr": "Highlight-TTA is proposed as a test-time adaptation framework to enhance video highlight detection by dynamically adapting models to the specific characteristics of each test video.", "motivation": "Current video highlight detection methods fail to account for unique features of individual test videos, leading to limited generalization and suboptimal performance.", "method": "The framework uses a cross-modality hallucination auxiliary task alongside the highlight detection task, with meta-auxiliary training enabling dynamic adaptation during testing.", "result": "Highlight-TTA improves performance in video highlight detection across three state-of-the-art models and benchmark datasets.", "conclusion": "The proposed framework addresses existing limitations and enhances video highlight detection through test-time dynamic model adaptation."}}
{"id": "2508.05028", "pdf": "https://arxiv.org/pdf/2508.05028", "abs": "https://arxiv.org/abs/2508.05028", "authors": ["Shu Han Ho"], "title": "Evaluation of LLMs in AMR Parsing", "categories": ["cs.CL", "cs.AI"], "comment": "27 pages, 32 figures", "summary": "Meaning Representation (AMR) is a semantic formalism that encodes sentence\nmeaning as rooted, directed, acyclic graphs, where nodes represent concepts and\nedges denote semantic relations. Finetuning decoder only Large Language Models\n(LLMs) represent a promising novel straightfoward direction for AMR parsing.\nThis paper presents a comprehensive evaluation of finetuning four distinct LLM\narchitectures, Phi 3.5, Gemma 2, LLaMA 3.2, and DeepSeek R1 LLaMA Distilled\nusing the LDC2020T02 Gold AMR3.0 test set. Our results have shown that\nstraightfoward finetuning of decoder only LLMs can achieve comparable\nperformance to complex State of the Art (SOTA) AMR parsers. Notably, LLaMA 3.2\ndemonstrates competitive performance against SOTA AMR parsers given a\nstraightforward finetuning approach. We achieved SMATCH F1: 0.804 on the full\nLDC2020T02 test split, on par with APT + Silver (IBM) at 0.804 and approaching\nGraphene Smatch (MBSE) at 0.854. Across our analysis, we also observed a\nconsistent pattern where LLaMA 3.2 leads in semantic performance while Phi 3.5\nexcels in structural validity.", "AI": {"tldr": "The paper evaluates the effectiveness of finetuning Large Language Models (LLMs) for Abstract Meaning Representation (AMR) parsing, demonstrating that straightforward finetuning achieves performance comparable to state-of-the-art methods.", "motivation": "Developing simpler yet effective alternatives to complex state-of-the-art methods for AMR parsing, leveraging LLMs to reduce methodological complexity.", "method": "The study finetunes four different LLM architectures (Phi 3.5, Gemma 2, LLaMA 3.2, DeepSeek R1 LLaMA Distilled) using the LDC2020T02 Gold AMR3.0 test set and compares their performance with existing AMR parsers.", "result": "Straightforward finetuning of decoder-only LLMs yielded competitive results, with LLaMA 3.2 achieving an SMATCH F1 score of 0.804, comparable to SOTA parsers such as APT+Silver (IBM) and approaching Graphene Smatch (MBSE).", "conclusion": "Finetuning decoder-only LLMs is a promising alternative to complex methods for AMR parsing, with distinct strengths observed in different architectures (e.g., semantic performance by LLaMA 3.2, structural validity by Phi 3.5)."}}
{"id": "2508.04883", "pdf": "https://arxiv.org/pdf/2508.04883", "abs": "https://arxiv.org/abs/2508.04883", "authors": ["Sinho Chewi", "Philippe Rigollet", "Yuling Yan"], "title": "Gaussian mixture layers for neural networks", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "The mean-field theory for two-layer neural networks considers infinitely wide\nnetworks that are linearly parameterized by a probability measure over the\nparameter space. This nonparametric perspective has significantly advanced both\nthe theoretical and conceptual understanding of neural networks, with\nsubstantial efforts made to validate its applicability to networks of moderate\nwidth. In this work, we explore the opposite direction, investigating whether\ndynamics can be directly implemented over probability measures. Specifically,\nwe employ Gaussian mixture models as a flexible and expressive parametric\nfamily of distributions together with the theory of Wasserstein gradient flows\nto derive training dynamics for such measures. Our approach introduces a new\ntype of layer -- the Gaussian mixture (GM) layer -- that can be integrated into\nneural network architectures. As a proof of concept, we validate our proposal\nthrough experiments on simple classification tasks, where a GM layer achieves\ntest performance comparable to that of a two-layer fully connected network.\nFurthermore, we examine the behavior of these dynamics and demonstrate\nnumerically that GM layers exhibit markedly different behavior compared to\nclassical fully connected layers, even when the latter are large enough to be\nconsidered in the mean-field regime.", "AI": {"tldr": "The paper introduces a Gaussian Mixture (GM) layer and explores direct training dynamics for networks using probability measures, validating its efficacy through experiments.", "motivation": "To investigate whether training dynamics can be directly implemented over probability measures and potentially explore alternatives to conventional neural network training paradigms.", "method": "The authors employ Gaussian mixture models and leverage Wasserstein gradient flows to derive training dynamics and introduce the Gaussian Mixture layer into neural network architectures.", "result": "GM layers achieve performance comparable to two-layer fully connected networks on simple classification tasks and exhibit distinct behavior when compared to classical layers in mean-field regimes.", "conclusion": "The GM layer is a promising addition to neural networks, offering a different conceptual and operational approach, with results suggesting it could serve as a viable alternative to classical network models."}}
{"id": "2508.04780", "pdf": "https://arxiv.org/pdf/2508.04780", "abs": "https://arxiv.org/abs/2508.04780", "authors": ["Lin Jiang", "Dahai Yu", "Rongchao Xu", "Tian Tang", "Guang Wang"], "title": "Uncertainty-aware Predict-Then-Optimize Framework for Equitable Post-Disaster Power Restoration", "categories": ["cs.LG", "cs.AI", "cs.SI"], "comment": "9 pages,12 figures", "summary": "The increasing frequency of extreme weather events, such as hurricanes,\nhighlights the urgent need for efficient and equitable power system\nrestoration. Many electricity providers make restoration decisions primarily\nbased on the volume of power restoration requests from each region. However,\nour data-driven analysis reveals significant disparities in request submission\nvolume, as disadvantaged communities tend to submit fewer restoration requests.\nThis disparity makes the current restoration solution inequitable, leaving\nthese communities vulnerable to extended power outages. To address this, we aim\nto propose an equity-aware power restoration strategy that balances both\nrestoration efficiency and equity across communities. However, achieving this\ngoal is challenging for two reasons: the difficulty of predicting repair\ndurations under dataset heteroscedasticity, and the tendency of reinforcement\nlearning agents to favor low-uncertainty actions, which potentially undermine\nequity. To overcome these challenges, we design a predict-then-optimize\nframework called EPOPR with two key components: (1) Equity-Conformalized\nQuantile Regression for uncertainty-aware repair duration prediction, and (2)\nSpatial-Temporal Attentional RL that adapts to varying uncertainty levels\nacross regions for equitable decision-making. Experimental results show that\nour EPOPR effectively reduces the average power outage duration by 3.60% and\ndecreases inequity between different communities by 14.19% compared to\nstate-of-the-art baselines.", "AI": {"tldr": "This paper identifies inequities in power restoration and proposes an equity-aware solution using a novel framework, EPOPR, which reduces outage duration and improves equity.", "motivation": "The study aims to address disparities in power restoration decisions that disproportionately disadvantage certain communities, particularly in the wake of extreme weather events.", "method": "The researchers propose a predict-then-optimize framework called EPOPR, combining Equity-Conformalized Quantile Regression for improved uncertainty prediction and Spatial-Temporal Attentional RL for equitable restoration decisions.", "result": "The proposed EPOPR framework reduces average power outage duration by 3.60% and decreases inequity across communities by 14.19%, outperforming standard restoration methods.", "conclusion": "EPOPR demonstrates that incorporating equity-aware mechanisms in power restoration strategies can significantly improve both efficiency and fairness, benefiting underserved communities."}}
{"id": "2508.05568", "pdf": "https://arxiv.org/pdf/2508.05568", "abs": "https://arxiv.org/abs/2508.05568", "authors": ["Qinghua Yao", "Xiangrui Xu", "Zhize Li"], "title": "X-VFL: A New Vertical Federated Learning Framework with Cross Completion and Decision Subspace Alignment", "categories": ["cs.LG", "cs.CV", "cs.DC", "math.OC"], "comment": "20 pages", "summary": "Vertical Federated Learning (VFL) enables collaborative learning by\nintegrating disjoint feature subsets from multiple clients/parties. However,\nVFL typically faces two key challenges: i) the requirement for perfectly\naligned data samples across all clients (missing features are not allowed); ii)\nthe requirement for joint collaborative inference/prediction involving all\nclients (it does not support locally independent inference on a single client).\nTo address these challenges, we propose X-VFL, a new VFL framework designed to\ndeal with the non-aligned data samples with (partially) missing features and to\nsupport locally independent inference of new data samples for each client. In\nparticular, we design two novel modules in X-VFL: Cross Completion (XCom) and\nDecision Subspace Alignment (DS-Align). XCom can complete/reconstruct missing\nfeatures for non-aligned data samples by leveraging information from other\nclients. DS-Align aligns local features with completed and global features\nacross all clients within the decision subspace, thus enabling locally\nindependent inference at each client. Moreover, we provide convergence theorems\nfor different algorithms used in training X-VFL, showing an $O(1/\\sqrt{T})$\nconvergence rate for SGD-type algorithms and an $O(1/T)$ rate for PAGE-type\nalgorithms, where $T$ denotes the number of training update steps. Extensive\nexperiments on real-world datasets demonstrate that X-VFL significantly\noutperforms existing methods, e.g., achieving a 15% improvement in accuracy on\nthe image CIFAR-10 dataset and a 43% improvement on the medical MIMIC-III\ndataset. These results validate the practical effectiveness and superiority of\nX-VFL, particularly in scenarios involving partially missing features and\nlocally independent inference.", "AI": {"tldr": "X-VFL addresses challenges in Vertical Federated Learning (VFL) by enabling collaborative learning with non-aligned data samples and locally independent inference.", "motivation": "The paper aims to overcome the limitations of VFL that include strict requirements for aligned data samples and the inability to support locally independent inference.", "method": "Introducing X-VFL framework with two new modules \u2013 Cross Completion (XCom) for reconstructing missing features, and Decision Subspace Alignment (DS-Align) for feature alignment within the decision subspace.", "result": "X-VFL demonstrates a 15% accuracy improvement on CIFAR-10 and 43% on MIMIC-III datasets compared to existing methods.", "conclusion": "X-VFL proves its effectiveness and superiority for collaborative learning, particularly in cases of data samples with missing features and local inference needs."}}
{"id": "2508.05113", "pdf": "https://arxiv.org/pdf/2508.05113", "abs": "https://arxiv.org/abs/2508.05113", "authors": ["Xinyue Wu", "Fan Hu", "Shaik Jani Babu", "Yi Zhao", "Xinfei Guo"], "title": "EasySize: Elastic Analog Circuit Sizing via LLM-Guided Heuristic Search", "categories": ["cs.AI"], "comment": null, "summary": "Analog circuit design is a time-consuming, experience-driven task in chip\ndevelopment. Despite advances in AI, developing universal, fast, and stable\ngate sizing methods for analog circuits remains a significant challenge. Recent\napproaches combine Large Language Models (LLMs) with heuristic search\ntechniques to enhance generalizability, but they often depend on large model\nsizes and lack portability across different technology nodes. To overcome these\nlimitations, we propose EasySize, the first lightweight gate sizing framework\nbased on a finetuned Qwen3-8B model, designed for universal applicability\nacross process nodes, design specifications, and circuit topologies. EasySize\nexploits the varying Ease of Attainability (EOA) of performance metrics to\ndynamically construct task-specific loss functions, enabling efficient\nheuristic search through global Differential Evolution (DE) and local Particle\nSwarm Optimization (PSO) within a feedback-enhanced flow. Although finetuned\nsolely on 350nm node data, EasySize achieves strong performance on 5\noperational amplifier (Op-Amp) netlists across 180nm, 45nm, and 22nm technology\nnodes without additional targeted training, and outperforms AutoCkt, a\nwidely-used Reinforcement Learning based sizing framework, on 86.67\\% of tasks\nwith more than 96.67\\% of simulation resources reduction. We argue that\nEasySize can significantly reduce the reliance on human expertise and\ncomputational resources in gate sizing, thereby accelerating and simplifying\nthe analog circuit design process. EasySize will be open-sourced at a later\ndate.", "AI": {"tldr": "EasySize introduces a lightweight gate sizing framework applying a finetuned Qwen3-8B model, leveraging efficient heuristics to automate analog circuit design across technology nodes with reduced computational demands.", "motivation": "The motivation is to address the challenges of slow, experience-driven analog circuit design and the limitations of current AI-based methods, such as dependence on large models and lack of adaptability across technology nodes.", "method": "The paper introduces the EasySize framework, using a finetuned Qwen3-8B model combined with heuristic optimization techniques like Differential Evolution and Particle Swarm Optimization, along with dynamic loss functions based on Ease of Attainability (EOA).", "result": "EasySize demonstrates universal applicability, achieving strong performance across multiple technology nodes (350nm to 22nm) without targeted retraining and surpasses AutoCkt in efficiency on over 86% of tasks, with over 96% simulation resource savings.", "conclusion": "EasySize reduces reliance on human expertise, accelerates analog circuit design, and significantly lowers computational resource needs, providing an open-sourced solution for universal gate sizing."}}
{"id": "2508.05199", "pdf": "https://arxiv.org/pdf/2508.05199", "abs": "https://arxiv.org/abs/2508.05199", "authors": ["Igor Costa", "Christopher Baran"], "title": "EvoGraph: Hybrid Directed Graph Evolution toward Software 3.0", "categories": ["cs.SE", "cs.AI", "D.2.2; D.2.7; I.2.2"], "comment": "15 pages, 3 tables, 1 algorithm. Submitted to ICSE 2025", "summary": "We introduce **EvoGraph**, a framework that enables software systems to\nevolve their own source code, build pipelines, documentation, and tickets.\nEvoGraph represents every artefact in a typed directed graph, applies learned\nmutation operators driven by specialized small language models (SLMs), and\nselects survivors with a multi-objective fitness. On three benchmarks, EvoGraph\nfixes 83% of known security vulnerabilities, translates COBOL to Java with 93%\nfunctional equivalence (test verified), and maintains documentation freshness\nwithin two minutes. Experiments show a 40% latency reduction and a sevenfold\ndrop in feature lead time compared with strong baselines. We extend our\napproach to **evoGraph**, leveraging language-specific SLMs for modernizing\n.NET, Lisp, CGI, ColdFusion, legacy Python, and C codebases, achieving 82-96%\nsemantic equivalence across languages while reducing computational costs by 90%\ncompared to large language models. EvoGraph's design responds to empirical\nfailure modes in legacy modernization, such as implicit contracts, performance\npreservation, and integration evolution. Our results suggest a practical path\ntoward Software 3.0, where systems adapt continuously yet remain under\nmeasurable control.", "AI": {"tldr": "EvoGraph is a software framework that advances self-evolving systems, achieving automation in code evolution and significant functional equivalencies across languages while reducing costs.", "motivation": "To create a framework where software systems can autonomously and efficiently evolve, modernize, and manage their codebase and related artifacts.", "method": "EvoGraph employs a typed directed graph to represent software artifacts, uses specialized small language models for mutation, and applies a multi-objective fitness selection mechanism.", "result": "EvoGraph demonstrates the ability to fix security vulnerabilities, achieve high functional equivalence in code translations, and maintain documentation freshness with significant reductions in latency and cost.", "conclusion": "This framework presents a tangible method for continuous software evolution, paving the way for highly adaptive systems within measurable constraints, termed as Software 3.0."}}
{"id": "2508.05153", "pdf": "https://arxiv.org/pdf/2508.05153", "abs": "https://arxiv.org/abs/2508.05153", "authors": ["Mohammed Daba", "Jing Qiu"], "title": "FCBV-Net: Category-Level Robotic Garment Smoothing via Feature-Conditioned Bimanual Value Prediction", "categories": ["cs.RO", "cs.AI", "I.2.9; I.2.6; I.4.8"], "comment": "7 pages, 3 figures, 1 table. Submitted to IEEE Robotics and\n  Automation Letters", "summary": "Category-level generalization for robotic garment manipulation, such as\nbimanual smoothing, remains a significant hurdle due to high dimensionality,\ncomplex dynamics, and intra-category variations. Current approaches often\nstruggle, either overfitting with concurrently learned visual features for a\nspecific instance or, despite category-level perceptual generalization, failing\nto predict the value of synergistic bimanual actions. We propose the\nFeature-Conditioned Bimanual Value Network (FCBV-Net), operating on 3D point\nclouds to specifically enhance category-level policy generalization for garment\nsmoothing. FCBV-Net conditions bimanual action value prediction on pre-trained,\nfrozen dense geometric features, ensuring robustness to intra-category garment\nvariations. Trainable downstream components then learn a task-specific policy\nusing these static features. In simulated GarmentLab experiments with the\nCLOTH3D dataset, FCBV-Net demonstrated superior category-level generalization.\nIt exhibited only an 11.5% efficiency drop (Steps80) on unseen garments\ncompared to 96.2% for a 2D image-based baseline, and achieved 89% final\ncoverage, outperforming an 83% coverage from a 3D correspondence-based baseline\nthat uses identical per-point geometric features but a fixed primitive. These\nresults highlight that the decoupling of geometric understanding from bimanual\naction value learning enables better category-level generalization.", "AI": {"tldr": "The paper introduces FCBV-Net for robotic garment manipulation, enhancing category-level generalization using pre-trained 3D geometric features.", "motivation": "The study aims to address challenges in robotic garment manipulation due to high dimensionality, complex dynamics, and intra-category variations.", "method": "FCBV-Net employs pre-trained frozen 3D geometric features for bimanual value prediction and trains downstream components for specific garment smoothing tasks.", "result": "In simulated GarmentLab experiments, FCBV-Net showed superior performance over benchmarks, with minimal efficiency drop and improved coverage.", "conclusion": "FCBV-Net's approach of separating geometric understanding from bimanual action learning improves generalization in garment manipulation."}}
{"id": "2508.04928", "pdf": "https://arxiv.org/pdf/2508.04928", "abs": "https://arxiv.org/abs/2508.04928", "authors": ["Suchisrit Gangopadhyay", "Jung-Hee Kim", "Xien Chen", "Patrick Rim", "Hyoungseob Park", "Alex Wong"], "title": "Extending Foundational Monocular Depth Estimators to Fisheye Cameras with Calibration Tokens", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "We propose a method to extend foundational monocular depth estimators\n(FMDEs), trained on perspective images, to fisheye images. Despite being\ntrained on tens of millions of images, FMDEs are susceptible to the covariate\nshift introduced by changes in camera calibration (intrinsic, distortion)\nparameters, leading to erroneous depth estimates. Our method aligns the\ndistribution of latent embeddings encoding fisheye images to those of\nperspective images, enabling the reuse of FMDEs for fisheye cameras without\nretraining or finetuning. To this end, we introduce a set of Calibration Tokens\nas a light-weight adaptation mechanism that modulates the latent embeddings for\nalignment. By exploiting the already expressive latent space of FMDEs, we posit\nthat modulating their embeddings avoids the negative impact of artifacts and\nloss introduced in conventional recalibration or map projection to a canonical\nreference frame in the image space. Our method is self-supervised and does not\nrequire fisheye images but leverages publicly available large-scale perspective\nimage datasets. This is done by recalibrating perspective images to fisheye\nimages, and enforcing consistency between their estimates during training. We\nevaluate our approach with several FMDEs, on both indoors and outdoors, where\nwe consistently improve over state-of-the-art methods using a single set of\ntokens for both. Code available at:\nhttps://github.com/JungHeeKim29/calibration-token.", "AI": {"tldr": "A method to adapt monocular depth estimators to fisheye images, using calibration tokens for latent embedding alignment.", "motivation": "Monocular depth estimators struggle with covariate shifts introduced by fisheye cameras, which leads to inaccurate depth predictions.", "method": "The approach introduces Calibration Tokens to align fisheye image embeddings with perspective embeddings, leveraging existing datasets and employing self-supervised training.", "result": "The method improves depth estimation accuracy for fisheye images compared to state-of-the-art techniques without the need for retraining or finetuning.", "conclusion": "Calibration Tokens enable effective adaptation of FMDEs to fisheye cameras, addressing covariate shift while reducing artifacts compared to traditional methods."}}
{"id": "2508.05078", "pdf": "https://arxiv.org/pdf/2508.05078", "abs": "https://arxiv.org/abs/2508.05078", "authors": ["Jinda Liu", "Bo Cheng", "Yi Chang", "Yuan Wu"], "title": "Align, Don't Divide: Revisiting the LoRA Architecture in Multi-Task Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Parameter-Efficient Fine-Tuning (PEFT) is essential for adapting Large\nLanguage Models (LLMs). In practice, LLMs are often required to handle a\ndiverse set of tasks from multiple domains, a scenario naturally addressed by\nmulti-task learning (MTL). Within this MTL context, a prevailing trend involves\nLoRA variants with multiple adapters or heads, which advocate for structural\ndiversity to capture task-specific knowledge. Our findings present a direct\nchallenge to this paradigm. We first show that a simplified multi-head\narchitecture with high inter-head similarity substantially outperforms complex\nmulti-adapter and multi-head systems. This leads us to question the\nmulti-component paradigm itself, and we further demonstrate that a standard\nsingle-adapter LoRA, with a sufficiently increased rank, also achieves highly\ncompetitive performance. These results lead us to a new hypothesis: effective\nMTL generalization hinges on learning robust shared representations, not\nisolating task-specific features. To validate this, we propose Align-LoRA,\nwhich incorporates an explicit loss to align task representations within the\nshared adapter space. Experiments confirm that Align-LoRA significantly\nsurpasses all baselines, establishing a simpler yet more effective paradigm for\nadapting LLMs to multiple tasks. The code is available at\nhttps://github.com/jinda-liu/Align-LoRA.", "AI": {"tldr": "The paper challenges the trend of using complex multi-adapter approaches in multi-task learning for adapting LLMs, proposing instead simpler architectures with high inter-head similarity. It introduces Align-LoRA, which aligns task representations and achieves superior performance.", "motivation": "The paper aims to improve the adaptation of LLMs for diverse tasks by questioning the structural complexity of existing PEFT approaches in multi-task learning and emphasizing the need for robust shared representations.", "method": "The authors propose Align-LoRA, a simple fine-tuning method utilizing a loss function to align task representations within a shared adapter space across tasks.", "result": "Align-LoRA outperformed complex multi-adapter and multi-head systems in experiments, demonstrating competitive results using standard single-adapter systems with increased rank.", "conclusion": "Simpler architectures focusing on aligning shared representations are more efficient and effective for adapting LLMs to multiple tasks than complex multi-component systems."}}
{"id": "2508.04985", "pdf": "https://arxiv.org/pdf/2508.04985", "abs": "https://arxiv.org/abs/2508.04985", "authors": ["Kumar Anurag", "Kasra Azizi", "Francesco Sorrentino", "Wenbin Wan"], "title": "RCUKF: Data-Driven Modeling Meets Bayesian Estimation", "categories": ["cs.LG", "cs.SY", "eess.SY", "stat.ML", "93E11, 68T07", "I.2.6; I.5.1"], "comment": "6 pages, 6 figures. Accepted at IFAC MECC 2025 (Modeling, Estimation\n  and Control Conference)", "summary": "Accurate modeling is crucial in many engineering and scientific applications,\nyet obtaining a reliable process model for complex systems is often\nchallenging. To address this challenge, we propose a novel framework, reservoir\ncomputing with unscented Kalman filtering (RCUKF), which integrates data-driven\nmodeling via reservoir computing (RC) with Bayesian estimation through the\nunscented Kalman filter (UKF). The RC component learns the nonlinear system\ndynamics directly from data, serving as a surrogate process model in the UKF\nprediction step to generate state estimates in high-dimensional or chaotic\nregimes where nominal mathematical models may fail. Meanwhile, the UKF\nmeasurement update integrates real-time sensor data to correct potential drift\nin the data-driven model. We demonstrate RCUKF effectiveness on well-known\nbenchmark problems and a real-time vehicle trajectory estimation task in a\nhigh-fidelity simulation environment.", "AI": {"tldr": "The paper introduces RCUKF, a framework combining reservoir computing (RC) and unscented Kalman filtering (UKF) for accurate state estimation in complex systems.", "motivation": "Accurate process modeling for complex systems is often difficult, and existing mathematical models may fail in high-dimensional or chaotic scenarios.", "method": "RCUKF leverages reservoir computing to learn system dynamics from data and integrates it with the unscented Kalman filter to estimate and correct system states using real-time sensor input.", "result": "RCUKF showed strong performance on benchmark problems and in a simulated real-time vehicle trajectory estimation task.", "conclusion": "RCUKF provides an effective hybrid modeling framework for complex systems, addressing challenges where standard models are unreliable."}}
{"id": "2508.04792", "pdf": "https://arxiv.org/pdf/2508.04792", "abs": "https://arxiv.org/abs/2508.04792", "authors": ["Jaehyung Lim", "Wonbin Kweon", "Woojoo Kim", "Junyoung Kim", "Seongjin Choi", "Dongha Kim", "Hwanjo Yu"], "title": "Federated Continual Recommendation", "categories": ["cs.LG", "cs.IR", "H.3.3; I.2.6; C.2.4"], "comment": "Accepted to CIKM 2025", "summary": "The increasing emphasis on privacy in recommendation systems has led to the\nadoption of Federated Learning (FL) as a privacy-preserving solution, enabling\ncollaborative training without sharing user data. While Federated\nRecommendation (FedRec) effectively protects privacy, existing methods struggle\nwith non-stationary data streams, failing to maintain consistent recommendation\nquality over time. On the other hand, Continual Learning Recommendation (CLRec)\nmethods address evolving user preferences but typically assume centralized data\naccess, making them incompatible with FL constraints. To bridge this gap, we\nintroduce Federated Continual Recommendation (FCRec), a novel task that\nintegrates FedRec and CLRec, requiring models to learn from streaming data\nwhile preserving privacy. As a solution, we propose F3CRec, a framework\ndesigned to balance knowledge retention and adaptation under the strict\nconstraints of FCRec. F3CRec introduces two key components: Adaptive Replay\nMemory on the client side, which selectively retains past preferences based on\nuser-specific shifts, and Item-wise Temporal Mean on the server side, which\nintegrates new knowledge while preserving prior information. Extensive\nexperiments demonstrate that F3CRec outperforms existing approaches in\nmaintaining recommendation quality over time in a federated environment.", "AI": {"tldr": "The paper introduces F3CRec, a framework combining Federated Learning (FL) and Continual Learning for privacy-preserving, evolving user preference recommendations.", "motivation": "To address the limitations of Federated Recommendation systems with non-stationary data streams while maintaining privacy.", "method": "F3CRec utilizes Adaptive Replay Memory on clients for selective retention of past data and Item-wise Temporal Mean on servers to balance new and old information.", "result": "F3CRec outperformed existing approaches in maintaining consistent recommendation quality over time in a federated setup.", "conclusion": "Integrating FL and continual learning through F3CRec resolves privacy and non-stationary data challenges, ensuring long-term recommendation efficiency."}}
{"id": "2508.05116", "pdf": "https://arxiv.org/pdf/2508.05116", "abs": "https://arxiv.org/abs/2508.05116", "authors": ["Peer-Benedikt Degen", "Igor Asanov"], "title": "Beyond Automation: Socratic AI, Epistemic Agency, and the Implications of the Emergence of Orchestrated Multi-Agent Learning Architectures", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Generative AI is no longer a peripheral tool in higher education. It is\nrapidly evolving into a general-purpose infrastructure that reshapes how\nknowledge is generated, mediated, and validated. This paper presents findings\nfrom a controlled experiment evaluating a Socratic AI Tutor, a large language\nmodel designed to scaffold student research question development through\nstructured dialogue grounded in constructivist theory. Conducted with 65\npre-service teacher students in Germany, the study compares interaction with\nthe Socratic Tutor to engagement with an uninstructed AI chatbot. Students\nusing the Socratic Tutor reported significantly greater support for critical,\nindependent, and reflective thinking, suggesting that dialogic AI can stimulate\nmetacognitive engagement and challenging recent narratives of de-skilling due\nto generative AI usage. These findings serve as a proof of concept for a\nbroader pedagogical shift: the use of multi-agent systems (MAS) composed of\nspecialised AI agents. To conceptualise this, we introduce the notion of\norchestrated MAS, modular, pedagogically aligned agent constellations, curated\nby educators, that support diverse learning trajectories through differentiated\nroles and coordinated interaction. To anchor this shift, we propose an adapted\noffer-and-use model, in which students appropriate instructional offers from\nthese agents. Beyond technical feasibility, we examine system-level\nimplications for higher education institutions and students, including funding\nnecessities, changes to faculty roles, curriculars, competencies and assessment\npractices. We conclude with a comparative cost-effectiveness analysis\nhighlighting the scalability of such systems. In sum, this study contributes\nboth empirical evidence and a conceptual roadmap for hybrid learning ecosystems\nthat embed human-AI co-agency and pedagogical alignment.", "AI": {"tldr": "This study explores the application of a Socratic AI Tutor to enhance student research question development compared to basic AI chatbots, proposing a broader pedagogical shift towards orchestrated multi-agent systems in education.", "motivation": "The paper aims to address the evolving role of generative AI in higher education by examining how structured AI dialogue can enhance critical thinking and metacognitive engagement, countering concerns about de-skilling.", "method": "A controlled experiment was conducted with 65 pre-service teacher students in Germany, comparing interactions with the Socratic AI Tutor and an uninstructed AI chatbot, grounded in constructivist educational theory.", "result": "Students reported better support for critical, independent, and reflective thinking with the Socratic AI Tutor, demonstrating its effectiveness in fostering metacognitive engagement.", "conclusion": "The study highlights the potential of dialogic AI systems for stimulating deeper learning and introduces the concept of orchestrated multi-agent systems (MAS) curated by educators, presenting implications for education systems regarding scalability, costs, and faculty roles."}}
{"id": "2508.05301", "pdf": "https://arxiv.org/pdf/2508.05301", "abs": "https://arxiv.org/abs/2508.05301", "authors": ["Victoria Torres Bosch", "Ronny Seiger", "Manuela Albert Albiol", "Antoni Mestre Gascon", "Pedro Jose Valderas Aranda"], "title": "A Conceptual Model and Methodology for Sustainability-aware, IoT-enhanced Business Processes", "categories": ["cs.SE", "cs.CY"], "comment": "Submitted to Information Systems Frontiers (1572-9419)", "summary": "The real-time data collection and automation capabilities offered by the\nInternet of Things (IoT) are revolutionizing and transforming Business\nProcesses (BPs) into IoT-enhanced BPs, showing high potential for improving\nsustainability. Although already studied in Business Process Management (BPM),\nsustainability research has primarily focused on environmental concerns.\nHowever, achieving a holistic and lasting impact requires a systematic approach\nto address sustainability beyond the environmental dimension. This work\nproposes a conceptual model and a structured methodology with the goal of\nanalyzing the potential of IoT to measure and improve the sustainability of\nBPs. The conceptual model formally represents key sustainability concepts,\nlinking BPM and IoT by highlighting how IoT devices support and contribute to\nsustainability. The methodology guides the systematic analysis of existing BPs,\nidentifies opportunities, and implements sustainability-aware, IoT-enhanced\nBPs. The approach is illustrated through a running example from the tourism\ndomain and a case study in healthcare.", "AI": {"tldr": "The paper proposes a conceptual model and methodology to enhance Business Processes (BPs) sustainability using Internet of Things (IoT), extending sustainability considerations beyond environmental dimensions.", "motivation": "The motivation is to address sustainability in Business Processes comprehensively by integrating IoT capabilities, beyond the usual focus on environmental concerns in Business Process Management (BPM) research.", "method": "The authors developed a conceptual model linking BPM and IoT through key sustainability concepts, coupled with a methodology to systematically analyze and redesign BPs for IoT-enhanced sustainability.", "result": "The model and methodology were applied to examples in tourism and healthcare, demonstrating their practicality and effectiveness in identifying and implementing sustainability-aware BPs.", "conclusion": "The paper concludes that IoT technology can significantly contribute to the multidimensional sustainability of Business Processes, offering structured tools for systematic improvement beyond environmental factors."}}
{"id": "2508.05186", "pdf": "https://arxiv.org/pdf/2508.05186", "abs": "https://arxiv.org/abs/2508.05186", "authors": ["Yongjie Bai", "Zhouxia Wang", "Yang Liu", "Weixing Chen", "Ziliang Chen", "Mingtong Dai", "Yongsen Zheng", "Lingbo Liu", "Guanbin Li", "Liang Lin"], "title": "Learning to See and Act: Task-Aware View Planning for Robotic Manipulation", "categories": ["cs.RO", "cs.CV"], "comment": "7 pages, 9 figures, project page: https://hcplab-sysu.github.io/TAVP", "summary": "Recent vision-language-action (VLA) models for multi-task robotic\nmanipulation commonly rely on static viewpoints and shared visual encoders,\nwhich limit 3D perception and cause task interference, hindering robustness and\ngeneralization. In this work, we propose Task-Aware View Planning (TAVP), a\nframework designed to overcome these challenges by integrating active view\nplanning with task-specific representation learning. TAVP employs an efficient\nexploration policy, accelerated by a novel pseudo-environment, to actively\nacquire informative views. Furthermore, we introduce a Mixture-of-Experts (MoE)\nvisual encoder to disentangle features across different tasks, boosting both\nrepresentation fidelity and task generalization. By learning to see the world\nin a task-aware way, TAVP generates more complete and discriminative visual\nrepresentations, demonstrating significantly enhanced action prediction across\na wide array of manipulation challenges. Extensive experiments on RLBench tasks\nshow that our proposed TAVP model achieves superior performance over\nstate-of-the-art fixed-view approaches. Visual results and code are provided\nat: https://hcplab-sysu.github.io/TAVP.", "AI": {"tldr": "The paper introduces TAVP, a framework addressing limitations in multi-task robotic manipulation using active view planning and task-specific representation learning, outperforming existing methods.", "motivation": "To overcome issues like static viewpoints and shared visual encoders in VLA models, which limit 3D perception and cause task interference.", "method": "TAVP integrates an exploration policy with a pseudo-environment for active view acquisition and employs a Mixture-of-Experts visual encoder for task-specific feature representation.", "result": "Experiments show that TAVP significantly improves action prediction and surpasses fixed-view methods in multi-task robotic manipulation.", "conclusion": "Task-Aware View Planning provides more comprehensive and discriminative visual representations, which enhance robustness and generalization in robotic manipulation tasks."}}
{"id": "2508.04941", "pdf": "https://arxiv.org/pdf/2508.04941", "abs": "https://arxiv.org/abs/2508.04941", "authors": ["Bo Deng", "Levi Heath"], "title": "Toward Errorless Training ImageNet-1k", "categories": ["cs.CV", "cs.LG", "68T07"], "comment": "14 pages, 2 figures", "summary": "In this paper, we describe a feedforward artificial neural network trained on\nthe ImageNet 2012 contest dataset [7] with the new method of [5] to an accuracy\nrate of 98.3% with a 99.69 Top-1 rate, and an average of 285.9 labels that are\nperfectly classified over the 10 batch partitions of the dataset. The best\nperforming model uses 322,430,160 parameters, with 4 decimal places precision.\nWe conjecture that the reason our model does not achieve a 100% accuracy rate\nis due to a double-labeling problem, by which there are duplicate images in the\ndataset with different labels.", "AI": {"tldr": "This paper presents a high-performance feedforward neural network trained on the ImageNet 2012 dataset, reaching near-perfect accuracy.", "motivation": "The motivation is to achieve high accuracy on image classification tasks using the ImageNet 2012 dataset and explore potential reasons for any performance limitations.", "method": "A feedforward artificial neural network with 322,430,160 parameters and four-decimal precision was employed. It was trained using a specific method referenced from another work.", "result": "The model achieved 98.3% accuracy, 99.69% Top-1 accuracy, and averaged 285.9 perfectly classified labels per batch despite a double-labeling issue in the dataset.", "conclusion": "The model performs exceptionally well, but a double-labeling issue in the dataset might prevent achieving absolute 100% accuracy."}}
{"id": "2508.05097", "pdf": "https://arxiv.org/pdf/2508.05097", "abs": "https://arxiv.org/abs/2508.05097", "authors": ["Aditya Kishore", "Gaurav Kumar", "Jasabanta Patro"], "title": "Multimodal Fact Checking with Unified Visual, Textual, and Contextual Representations", "categories": ["cs.CL"], "comment": null, "summary": "The growing rate of multimodal misinformation, where claims are supported by\nboth text and images, poses significant challenges to fact-checking systems\nthat rely primarily on textual evidence. In this work, we have proposed a\nunified framework for fine-grained multimodal fact verification called\n\"MultiCheck\", designed to reason over structured textual and visual signals.\nOur architecture combines dedicated encoders for text and images with a fusion\nmodule that captures cross-modal relationships using element-wise interactions.\nA classification head then predicts the veracity of a claim, supported by a\ncontrastive learning objective that encourages semantic alignment between\nclaim-evidence pairs in a shared latent space. We evaluate our approach on the\nFactify 2 dataset, achieving a weighted F1 score of 0.84, substantially\noutperforming the baseline. These results highlight the effectiveness of\nexplicit multimodal reasoning and demonstrate the potential of our approach for\nscalable and interpretable fact-checking in complex, real-world scenarios.", "AI": {"tldr": "The paper introduces \"MultiCheck,\" a unified framework aimed at verifying multimodal misinformation using text-visual reasoning. Tests on Factify 2 data achieved superior fact-checking performance.", "motivation": "The study targets the challenge of tackling multimodal misinformation, emphasizing the need for systems capable of verifying claims involving both textual and visual components.", "method": "The \"MultiCheck\" framework utilizes encoders for text and images, a fusion module for cross-modal relationships, and contrastive learning to predict claim veracity by aligning semantic meanings in a shared embedding space.", "result": "Evaluations on the Factify 2 dataset revealed a weighted F1 score of 0.84, outperforming benchmark methods and confirming the efficacy of explicit multimodal reasoning.", "conclusion": "The findings underscore the importance of multimodal reasoning in enhancing fact-checking accuracy, promoting scalable solutions for real-world misinformation scenarios."}}
{"id": "2508.05173", "pdf": "https://arxiv.org/pdf/2508.05173", "abs": "https://arxiv.org/abs/2508.05173", "authors": ["Amichai Painsky"], "title": "Near Optimal Inference for the Best-Performing Algorithm", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Consider a collection of competing machine learning algorithms. Given their\nperformance on a benchmark of datasets, we would like to identify the best\nperforming algorithm. Specifically, which algorithm is most likely to rank\nhighest on a future, unseen dataset. A natural approach is to select the\nalgorithm that demonstrates the best performance on the benchmark. However, in\nmany cases the performance differences are marginal and additional candidates\nmay also be considered. This problem is formulated as subset selection for\nmultinomial distributions. Formally, given a sample from a countable alphabet,\nour goal is to identify a minimal subset of symbols that includes the most\nfrequent symbol in the population with high confidence. In this work, we\nintroduce a novel framework for the subset selection problem. We provide both\nasymptotic and finite-sample schemes that significantly improve upon currently\nknown methods. In addition, we provide matching lower bounds, demonstrating the\nfavorable performance of our proposed schemes.", "AI": {"tldr": "The paper introduces a novel method for subset selection to identify the best algorithm from a benchmark, improving upon existing methods with both asymptotic and finite-sample guarantees.", "motivation": "To address the challenge of selecting the best-performing machine learning algorithm on unseen datasets when performance differences are marginal.", "method": "A new framework for subset selection of multinomial distributions, which includes improved asymptotic and finite-sample schemes.", "result": "The proposed schemes outperform existing ones and are supported by matching lower bounds.", "conclusion": "The framework is effective and reliable for identifying high-performing candidates from benchmarks."}}
{"id": "2508.04811", "pdf": "https://arxiv.org/pdf/2508.04811", "abs": "https://arxiv.org/abs/2508.04811", "authors": ["Lin Jiang", "Yu Yang", "Guang Wang"], "title": "HCRide: Harmonizing Passenger Fairness and Driver Preference for Human-Centered Ride-Hailing", "categories": ["cs.LG", "cs.SI"], "comment": "9 pages,4 figures", "summary": "Order dispatch systems play a vital role in ride-hailing services, which\ndirectly influence operator revenue, driver profit, and passenger experience.\nMost existing work focuses on improving system efficiency in terms of operator\nrevenue, which may cause a bad experience for both passengers and drivers.\nHence, in this work, we aim to design a human-centered ride-hailing system by\nconsidering both passenger fairness and driver preference without compromising\nthe overall system efficiency. However, it is nontrivial to achieve this target\ndue to the potential conflicts between passenger fairness and driver preference\nsince optimizing one may sacrifice the other. To address this challenge, we\ndesign HCRide, a Human-Centered Ride-hailing system based on a novel\nmulti-agent reinforcement learning algorithm called Harmonization-oriented\nActor-Bi-Critic (Habic), which includes three major components (i.e., a\nmulti-agent competition mechanism, a dynamic Actor network, and a Bi-Critic\nnetwork) to optimize system efficiency and passenger fairness with driver\npreference consideration. We extensively evaluate our HCRide using two\nreal-world ride-hailing datasets from Shenzhen and New York City. Experimental\nresults show our HCRide effectively improves system efficiency by 2.02%,\nfairness by 5.39%, and driver preference by 10.21% compared to state-of-the-art\nbaselines.", "AI": {"tldr": "The paper introduces HCRide, a human-centered ride-hailing system that balances system efficiency, passenger fairness, and driver preference using a novel multi-agent reinforcement learning approach.", "motivation": "The motivation is to address the shortcomings of current ride-hailing systems that prioritize operator revenue at the expense of passenger and driver experiences.", "method": "The authors propose HCRide, a system built on the Harmonization-oriented Actor-Bi-Critic (Habic) algorithm with a multi-agent competition mechanism, dynamic Actor network, and Bi-Critic network.", "result": "HCRide improves system efficiency by 2.02%, passenger fairness by 5.39%, and driver preference by 10.21%, as tested on datasets from Shenzhen and New York City.", "conclusion": "HCRide successfully balances passenger fairness and driver preference while maintaining overall system efficiency, improving ride-hailing services for all stakeholders."}}
{"id": "2508.05145", "pdf": "https://arxiv.org/pdf/2508.05145", "abs": "https://arxiv.org/abs/2508.05145", "authors": ["Sebastiano Dissegna", "Chiara Di Francescomarino", "Massimiliano Ronzani"], "title": "Graph-based Event Log Repair", "categories": ["cs.AI"], "comment": null, "summary": "The quality of event logs in Process Mining is crucial when applying any form\nof analysis to them. In real-world event logs, the acquisition of data can be\nnon-trivial (e.g., due to the execution of manual activities and related manual\nrecording or to issues in collecting, for each event, all its attributes), and\noften may end up with events recorded with some missing information. Standard\napproaches to the problem of trace (or log) reconstruction either require the\navailability of a process model that is used to fill missing values by\nleveraging different reasoning techniques or employ a Machine Learning/Deep\nLearning model to restore the missing values by learning from similar cases. In\nrecent years, a new type of Deep Learning model that is capable of handling\ninput data encoded as graphs has emerged, namely Graph Neural Networks. Graph\nNeural Network models, and even more so Heterogeneous Graph Neural Networks,\noffer the advantage of working with a more natural representation of complex\nmulti-modal sequences like the execution traces in Process Mining, allowing for\nmore expressive and semantically rich encodings.\n  In this work, we focus on the development of a Heterogeneous Graph Neural\nNetwork model that, given a trace containing some incomplete events, will\nreturn the full set of attributes missing from those events. We evaluate our\nwork against a state-of-the-art approach leveraging autoencoders on two\nsynthetic logs and four real event logs, on different types of missing values.\nDifferent from state-of-the-art model-free approaches, which mainly focus on\nrepairing a subset of event attributes, the proposed approach shows very good\nperformance in reconstructing all different event attributes.", "AI": {"tldr": "This paper develops a Heterogeneous Graph Neural Network model to reconstruct missing event attributes in process mining traces, outperforming state-of-the-art autoencoder-based approaches in various scenarios.", "motivation": "The authors aim to address the challenge of missing information in real-world event logs, which affects the reliability of process mining analysis.", "method": "A Heterogeneous Graph Neural Network model is proposed to reconstruct missing event attributes by effectively representing and leveraging multi-modal execution trace data.", "result": "Experimental evaluation on synthetic and real-world logs demonstrates superior performance of the proposed model in reconstructing all types of missing event attributes compared to existing state-of-the-art techniques.", "conclusion": "The study illustrates the potential of Heterogeneous Graph Neural Networks for addressing missing data in complex event logs, suggesting broader applicability in process mining scenarios."}}
{"id": "2508.04889", "pdf": "https://arxiv.org/pdf/2508.04889", "abs": "https://arxiv.org/abs/2508.04889", "authors": ["Theia Henderson", "David R. Karger", "David D. Clark"], "title": "Graffiti: Enabling an Ecosystem of Personalized and Interoperable Social Applications", "categories": ["cs.SI", "cs.HC", "cs.SE"], "comment": "Accepted to The 38th Annual ACM Symposium on User Interface Software\n  and Technology (UIST '25), September 28-October 1, 2025, Busan, Republic of\n  Korea. 21 pages", "summary": "Most social applications, from Twitter to Wikipedia, have rigid\none-size-fits-all designs, but building new social applications is both\ntechnically challenging and results in applications that are siloed away from\nexisting communities. We present Graffiti, a system that can be used to build a\nwide variety of personalized social applications with relative ease that also\ninteroperate with each other. People can freely move between a plurality of\ndesigns -- each with its own aesthetic, feature set, and moderation -- all\nwithout losing their friends or data.\n  Our concept of total reification makes it possible for seemingly\ncontradictory designs, including conflicting moderation rules, to interoperate.\nConversely, our concept of channels prevents interoperation from occurring by\naccident, avoiding context collapse.\n  Graffiti applications interact through a minimal client-side API, which we\nshow admits at least two decentralized implementations. Above the API, we built\na Vue.js plugin, which we use to develop applications similar to Twitter,\nMessenger, and Wikipedia using only client-side code. Our case studies explore\nhow these and other novel applications interoperate, as well as the broader\necosystem that Graffiti enables.", "AI": {"tldr": "Graffiti is a system that enables personalized social apps to be created easily and to interoperate while retaining user data and connections.", "motivation": "Current social platforms have rigid designs, making it hard to build new apps that connect with existing communities. There\u2019s a need for systems allowing flexible and interoperable social tools.", "method": "The authors propose Graffiti, which relies on a client-side API with concepts like 'total reification' for conflicting design interoperability and 'channels' to avoid context collapse. Case studies are built using a Vue.js plugin.", "result": "Graffiti can support decentralized apps resembling Twitter, Messenger, and Wikipedia, showcasing its ability to create diverse and interoperable social platforms.", "conclusion": "Graffiti enables a dynamic and interoperable ecosystem for personalized social applications while maintaining user connections and preventing context collapse."}}
{"id": "2508.05208", "pdf": "https://arxiv.org/pdf/2508.05208", "abs": "https://arxiv.org/abs/2508.05208", "authors": ["Victor Ngo", "Rachel", "Ramchurn", "Roma Patel", "Alan Chamberlain", "Ayse Kucukyilmaz"], "title": "Dancing with a Robot: An Experimental Study of Child-Robot Interaction in a Performative Art Setting", "categories": ["cs.RO", "cs.PF"], "comment": "published by Springer", "summary": "This paper presents an evaluation of 18 children's in-the-wild experiences\nwith the autonomous robot arm performer NED (Never-Ending Dancer) within the\nThingamabobas installation, showcased across the UK. We detail NED's design,\nincluding costume, behaviour, and human interactions, all integral to the\ninstallation. Our observational analysis revealed three key challenges in\nchild-robot interactions: 1) Initiating and maintaining engagement, 2) Lack of\nrobot expressivity and reciprocity, and 3) Unmet expectations. Our findings\nshow that children are naturally curious, and adept at interacting with a\nrobotic art performer. However, our observations emphasise the critical need to\noptimise human-robot interaction (HRI) systems through careful consideration of\naudience's capabilities, perceptions, and expectations, within the performative\narts context, to enable engaging and meaningful experiences, especially for\nyoung audiences.", "AI": {"tldr": "The paper examines children's interactions with an autonomous robot arm, NED, in an art installation.", "motivation": "Understand the complexities of children's engagement with robotic performers in interactive arts.", "method": "Analysis of 18 children's interactions with NED in a real-world setting across the UK.", "result": "Identified challenges in engagement, expressivity, reciprocity, and expectation management.", "conclusion": "By optimizing HRI systems to match audience capabilities and perceptions, meaningful experiences for children can be fostered in performative art contexts."}}
{"id": "2508.04942", "pdf": "https://arxiv.org/pdf/2508.04942", "abs": "https://arxiv.org/abs/2508.04942", "authors": ["Phuoc-Nguyen Bui", "Khanh-Binh Nguyen", "Hyunseung Choo"], "title": "Accelerating Conditional Prompt Learning via Masked Image Modeling for Vision-Language Models", "categories": ["cs.CV"], "comment": "ACMMM-LAVA 2025, 10 pages, camera-ready version", "summary": "Vision-language models (VLMs) like CLIP excel in zero-shot learning but often\nrequire resource-intensive training to adapt to new tasks. Prompt learning\ntechniques, such as CoOp and CoCoOp, offer efficient adaptation but tend to\noverfit to known classes, limiting generalization to unseen categories. We\nintroduce ProMIM, a plug-and-play framework that enhances conditional prompt\nlearning by integrating masked image modeling (MIM) into existing VLM\npipelines. ProMIM leverages a simple yet effective masking strategy to generate\nrobust, instance-conditioned prompts, seamlessly augmenting methods like CoOp\nand CoCoOp without altering their core architectures. By masking only visible\nimage patches and using these representations to guide prompt generation,\nProMIM improves feature robustness and mitigates overfitting, all while\nintroducing negligible additional computational cost. Extensive experiments\nacross zero-shot and few-shot classification tasks demonstrate that ProMIM\nconsistently boosts generalization performance when plugged into existing\napproaches, providing a practical, lightweight solution for real-world\nvision-language applications.", "AI": {"tldr": "ProMIM is a framework that enhances prompt learning in vision-language models by using masked image modeling to improve generalization while being computationally efficient.", "motivation": "The need for better generalization in VLMs using lightweight methods, as existing approaches like CoOp and CoCoOp suffer from overfitting to known classes.", "method": "ProMIM integrates masked image modeling into VLM pipelines, masking visible image patches to generate instance-conditioned prompts, improving feature robustness without modifying core architectures.", "result": "ProMIM improves generalization performance in both zero-shot and few-shot classification tasks while adding minimal computational cost to existing prompt learning approaches.", "conclusion": "ProMIM offers a simple yet effective plug-and-play enhancement for VLM prompt learning, addressing overfitting and poor generalization in a lightweight manner."}}
{"id": "2508.05100", "pdf": "https://arxiv.org/pdf/2508.05100", "abs": "https://arxiv.org/abs/2508.05100", "authors": ["Yuhao Wang", "Ruiyang Ren", "Yucheng Wang", "Jing Liu", "Wayne Xin Zhao", "Hua Wu", "Haifeng Wang"], "title": "BEE-RAG: Balanced Entropy Engineering for Retrieval-Augmented Generation", "categories": ["cs.CL"], "comment": null, "summary": "With the rapid advancement of large language models (LLMs),\nretrieval-augmented generation (RAG) has emerged as a critical approach to\nsupplement the inherent knowledge limitations of LLMs. However, due to the\ntypically large volume of retrieved information, RAG tends to operate with long\ncontext lengths. From the perspective of entropy engineering, we identify\nunconstrained entropy growth and attention dilution due to long retrieval\ncontext as significant factors affecting RAG performance. In this paper, we\npropose the balanced entropy-engineered RAG (BEE-RAG) framework, which improves\nthe adaptability of RAG systems to varying context lengths through the\nprinciple of entropy invariance. By leveraging balanced context entropy to\nreformulate attention dynamics, BEE-RAG separates attention sensitivity from\ncontext length, ensuring a stable entropy level. Building upon this, we\nintroduce a zero-shot inference strategy for multi-importance estimation and a\nparameter-efficient adaptive fine-tuning mechanism to obtain the optimal\nbalancing factor for different settings. Extensive experiments across multiple\nRAG tasks demonstrate the effectiveness of BEE-RAG.", "AI": {"tldr": "The paper addresses performance issues in retrieval-augmented generation (RAG) caused by long context lengths, presenting the BEE-RAG framework to stabilize entropy dynamics and improve adaptability.", "motivation": "RAG frameworks face performance limitations due to unconstrained entropy growth and diluted attention when processing lengthy retrieval contexts.", "method": "The proposed BEE-RAG framework employs entropy invariance principles to stabilize entropy levels, introduces a zero-shot inference strategy for context importance estimation, and combines adaptive, parameter-efficient fine-tuning to optimize performance.", "result": "Experiments confirm that BEE-RAG enhances RAG tasks' effectiveness across various applications through improved attention dynamics and entropy management.", "conclusion": "BEE-RAG successfully improves adaptability and performance in RAG systems, addressing challenges imposed by long retrieval contexts."}}
{"id": "2508.05241", "pdf": "https://arxiv.org/pdf/2508.05241", "abs": "https://arxiv.org/abs/2508.05241", "authors": ["Wanting He", "Wenyuan Li", "Yunran Wei"], "title": "Periodic evaluation of defined-contribution pension fund: A dynamic risk measure approach", "categories": ["q-fin.RM", "stat.ML"], "comment": null, "summary": "This paper introduces an innovative framework for the periodic evaluation of\ndefined-contribution pension funds. The performance of the pension fund is\nevaluated not only at retirement, but also within the interim periods. In\ncontrast to the traditional literature, we set the dynamic risk measure as the\ncriterion and manage the tail risk of the pension fund dynamically. To\neffectively interact with the stochastic environment, a model-free\nreinforcement learning algorithm is proposed to search for optimal investment\nand insurance strategies. Using U.S. data, we calibrate pension members'\nmortality rates and enhance mortality projections through a Lee-Carter model.\nOur numerical results indicate that periodic evaluations lead to more\nrisk-averse strategies, while mortality improvements encourage more\nrisk-seeking behaviors.", "AI": {"tldr": "The paper proposes a dynamic evaluation framework for pension funds using reinforcement learning, integrating periodic assessments and dynamic risk management.", "motivation": "The authors aim to enhance pension fund evaluation by addressing interim performance, dynamic risk management, and mortality projections.", "method": "They utilize a model-free reinforcement learning algorithm, dynamic risk measures, and calibrate U.S. mortality rates with the Lee-Carter model.", "result": "Periodic evaluations foster risk-averse strategies, whereas improved mortality projections prompt risk-seeking behaviors.", "conclusion": "Dynamic approaches to pension fund assessments provide nuanced strategies influenced by mortality dynamics and risk evaluations."}}
{"id": "2508.04843", "pdf": "https://arxiv.org/pdf/2508.04843", "abs": "https://arxiv.org/abs/2508.04843", "authors": ["Xiao Shou"], "title": "Unified Flow Matching for Long Horizon Event Forecasting", "categories": ["cs.LG"], "comment": "7 pages", "summary": "Modeling long horizon marked event sequences is a fundamental challenge in\nmany real-world applications, including healthcare, finance, and user behavior\nmodeling. Existing neural temporal point process models are typically\nautoregressive, predicting the next event one step at a time, which limits\ntheir efficiency and leads to error accumulation in long-range forecasting. In\nthis work, we propose a unified flow matching framework for marked temporal\npoint processes that enables non-autoregressive, joint modeling of inter-event\ntimes and event types, via continuous and discrete flow matching. By learning\ncontinuous-time flows for both components, our method generates coherent long\nhorizon event trajectories without sequential decoding. We evaluate our model\non six real-world benchmarks and demonstrate significant improvements over\nautoregressive and diffusion-based baselines in both accuracy and generation\nefficiency.", "AI": {"tldr": "The paper introduces a unified flow matching framework for modeling marked temporal point processes, enabling accurate and efficient long horizon predictions without autoregressive decoding.", "motivation": "Address the limitations of autoregressive neural temporal point process models, which struggle with efficiency and error accumulation in long-range forecasting.", "method": "Proposes a non-autoregressive flow matching framework using continuous and discrete flow matching to jointly model inter-event times and event types, avoiding sequential decoding.", "result": "The model achieves substantial performance improvements in accuracy and generation efficiency compared to existing baseline methods across six real-world datasets.", "conclusion": "The unified flow matching approach successfully enhances long-horizon event sequence modeling, offering a more coherent and computationally efficient solution."}}
{"id": "2508.05197", "pdf": "https://arxiv.org/pdf/2508.05197", "abs": "https://arxiv.org/abs/2508.05197", "authors": ["Zhuohang Jiang", "Pangjing Wu", "Xu Yuan", "Wenqi Fan", "Qing Li"], "title": "QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": "The source code for our system is released in\n  https://github.com/jzzzzh/QA-Dragon", "summary": "Retrieval-Augmented Generation (RAG) has been introduced to mitigate\nhallucinations in Multimodal Large Language Models (MLLMs) by incorporating\nexternal knowledge into the generation process, and it has become a widely\nadopted approach for knowledge-intensive Visual Question Answering (VQA).\nHowever, existing RAG methods typically retrieve from either text or images in\nisolation, limiting their ability to address complex queries that require\nmulti-hop reasoning or up-to-date factual knowledge. To address this\nlimitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for\nKnowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to\nidentify the query's subject domain for domain-specific reasoning, along with a\nsearch router that dynamically selects optimal retrieval strategies. By\norchestrating both text and image search agents in a hybrid setup, our system\nsupports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle\ncomplex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM\nChallenge at KDD Cup 2025, where it significantly enhances the reasoning\nperformance of base models under challenging scenarios. Our framework achieves\nsubstantial improvements in both answer accuracy and knowledge overlap scores,\noutperforming baselines by 5.06% on the single-source task, 6.35% on the\nmulti-source task, and 5.03% on the multi-turn task.", "AI": {"tldr": "QA-Dragon proposes a novel approach to enhance multimodal VQA by utilizing a dynamic retrieval system combining both text and image-based knowledge sources, outperforming existing methods.", "motivation": "Existing Retrieval-Augmented Generation methods for Multimodal VQA struggle with complex queries requiring multi-hop reasoning or recent factual knowledge due to isolated text or image retrieval.", "method": "QA-Dragon employs a query-aware dynamic system using domain and search routers to identify the query domain and dynamically select retrieval strategies, combining both text and image sources for multimodal and multi-turn reasoning.", "result": "QA-Dragon significantly improves reasoning performance, achieving superior answer accuracy and knowledge overlap scores, outperforming baselines by 5.06% on single-source, 6.35% on multi-source, and 5.03% on multi-turn tasks.", "conclusion": "The proposed framework effectively tackles knowledge-intensive and complex VQA tasks, showcasing its capability in multimodal, multi-hop, and multi-turn reasoning through dynamic retrieval strategies."}}
{"id": "2508.05286", "pdf": "https://arxiv.org/pdf/2508.05286", "abs": "https://arxiv.org/abs/2508.05286", "authors": ["Katsiaryna Dzialets", "Aleksandra Makeeva", "Ilya Vlasov", "Anna Potriasaeva", "Aleksei Rostovskii", "Yaroslav Golubev", "Anastasiia Birillo"], "title": "Everything You Need to Know About CS Education: Open Results from a Survey of More Than 18,000 Participants", "categories": ["cs.CY", "cs.HC", "cs.SE"], "comment": "Accepted to CompEd'25, 7 pages, 1 figure", "summary": "Computer science education is a dynamic field with many aspects that\ninfluence the learner's path. While these aspects are usually studied in depth\nseparately, it is also important to carry out broader large-scale studies that\ntouch on many topics, because they allow us to put different results into each\nother's perspective. Past large-scale surveys have provided valuable insights,\nhowever, the emergence of new trends (e.g., AI), new learning formats (e.g.,\nin-IDE learning), and the increasing learner diversity highlight the need for\nan updated comprehensive study. To address this, we conducted a survey with\n18,032 learners from 173 countries, ensuring diverse representation and\nexploring a wide range of topics - formal education, learning formats, AI\nusage, challenges, motivation, and more. This paper introduces the results of\nthis survey as an open dataset, describes our methodology and the survey\nquestions, and highlights, as a motivating example, three possible research\ndirections within this data: challenges in learning, emerging formats, and\ninsights into the in-IDE format. The dataset aims to support further research\nand foster advancements in computer education.", "AI": {"tldr": "A large-scale survey of 18,032 computer science learners globally, presenting a dataset covering diverse education topics like AI usage and learning formats.", "motivation": "The paper addresses the need for an updated comprehensive study to understand trends, formats, and challenges in computer science education across diverse learners.", "method": "The authors conducted a survey of 18,032 participants from 173 countries, ensuring diverse representation to explore various learning topics and methodologies.", "result": "The survey results are compiled into an open dataset, encompassing topics such as formal education, AI usage, challenges, motivation, and emerging formats.", "conclusion": "This dataset provides opportunities for further research and advancement in computer science education by uncovering challenges and emerging educational trends."}}
{"id": "2508.05294", "pdf": "https://arxiv.org/pdf/2508.05294", "abs": "https://arxiv.org/abs/2508.05294", "authors": ["Sahar Salimpour", "Lei Fu", "Farhad Keramat", "Leonardo Militano", "Giovanni Toffetti", "Harry Edelman", "Jorge Pe\u00f1a Queralta"], "title": "Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Foundation models, including large language models (LLMs) and vision-language\nmodels (VLMs), have recently enabled novel approaches to robot autonomy and\nhuman-robot interfaces. In parallel, vision-language-action models (VLAs) or\nlarge behavior models (BLMs) are increasing the dexterity and capabilities of\nrobotic systems. This survey paper focuses on those words advancing towards\nagentic applications and architectures. This includes initial efforts exploring\nGPT-style interfaces to tooling, as well as more complex system where AI agents\nare coordinators, planners, perception actors, or generalist interfaces. Such\nagentic architectures allow robots to reason over natural language\ninstructions, invoke APIs, plan task sequences, or assist in operations and\ndiagnostics. In addition to peer-reviewed research, due to the fast-evolving\nnature of the field, we highlight and include community-driven projects, ROS\npackages, and industrial frameworks that show emerging trends. We propose a\ntaxonomy for classifying model integration approaches and present a comparative\nanalysis of the role that agents play in different solutions in today's\nliterature.", "AI": {"tldr": "The paper surveys foundation models enabling advanced robotics, focusing on agentic applications of language and behavior models, taxonomy, and trends.", "motivation": "Foundation models like LLMs and VLMs are transforming robot autonomy and human-robot interfaces. This study examines emerging agentic architectures for robotics.", "method": "The paper proposes a taxonomy, reviews both peer-reviewed and community-driven projects, and provides a comparative analysis of agents' roles.", "result": "Emerging trends in GPT-style interfaces, robot reasoning, API invocation, and task assistance are highlighted, along with a taxonomy categorizing model integrations.", "conclusion": "Agentic architectures in robotics offer revolutionary ways for task handling, diagnostics, and interaction, and their development is rapidly evolving."}}
{"id": "2508.04943", "pdf": "https://arxiv.org/pdf/2508.04943", "abs": "https://arxiv.org/abs/2508.04943", "authors": ["Zhu Xu", "Ting Lei", "Zhimin Li", "Guan Wang", "Qingchao Chen", "Yuxin Peng", "Yang liu"], "title": "TRKT: Weakly Supervised Dynamic Scene Graph Generation with Temporal-enhanced Relation-aware Knowledge Transferring", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Dynamic Scene Graph Generation (DSGG) aims to create a scene graph for each\nvideo frame by detecting objects and predicting their relationships. Weakly\nSupervised DSGG (WS-DSGG) reduces annotation workload by using an unlocalized\nscene graph from a single frame per video for training. Existing WS-DSGG\nmethods depend on an off-the-shelf external object detector to generate pseudo\nlabels for subsequent DSGG training. However, detectors trained on static,\nobject-centric images struggle in dynamic, relation-aware scenarios required\nfor DSGG, leading to inaccurate localization and low-confidence proposals. To\naddress the challenges posed by external object detectors in WS-DSGG, we\npropose a Temporal-enhanced Relation-aware Knowledge Transferring (TRKT)\nmethod, which leverages knowledge to enhance detection in relation-aware\ndynamic scenarios. TRKT is built on two key components:(1)Relation-aware\nknowledge mining: we first employ object and relation class decoders that\ngenerate category-specific attention maps to highlight both object regions and\ninteractive areas. Then we propose an Inter-frame Attention Augmentation\nstrategy that exploits optical flow for neighboring frames to enhance the\nattention maps, making them motion-aware and robust to motion blur. This step\nyields relation- and motion-aware knowledge mining for WS-DSGG. (2) we\nintroduce a Dual-stream Fusion Module that integrates category-specific\nattention maps into external detections to refine object localization and boost\nconfidence scores for object proposals. Extensive experiments demonstrate that\nTRKT achieves state-of-the-art performance on Action Genome dataset. Our code\nis avaliable at https://github.com/XZPKU/TRKT.git.", "AI": {"tldr": "The paper introduces \"Temporal-enhanced Relation-aware Knowledge Transferring\" (TRKT) to tackle issues in Weakly Supervised Dynamic Scene Graph Generation (WS-DSGG), improving object detection and relationship prediction in videos by leveraging relational and motion-aware features.", "motivation": "To address the limitations of existing WS-DSGG methods that rely on object detectors trained on static images, which fail to localize objects effectively and predict relationships accurately in dynamic video frames.", "method": "The authors propose the TRKT method, consisting of two key components: (1) Relation-aware knowledge mining using category-specific attention maps augmented by optical flow for motion-aware processing. (2) A Dual-stream Fusion Module that integrates these attention maps with external detector outputs to refine localization and confidence.", "result": "TRKT achieves state-of-the-art performance on the Action Genome dataset, showing enhanced accuracy in object and relationship detection across video frames.", "conclusion": "The proposed TRKT method significantly improves WS-DSGG tasks by addressing challenges of dynamic scenarios and elevating detection quality without heavy reliance on static pretrained detectors."}}
{"id": "2508.05128", "pdf": "https://arxiv.org/pdf/2508.05128", "abs": "https://arxiv.org/abs/2508.05128", "authors": ["Zihao Yi", "Delong Zeng", "Zhenqing Ling", "Haohao Luo", "Zhe Xu", "Wei Liu", "Jian Luan", "Wanxia Cao", "Ying Shen"], "title": "Attention Basin: Why Contextual Position Matters in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The performance of Large Language Models (LLMs) is significantly sensitive to\nthe contextual position of information in the input. To investigate the\nmechanism behind this positional bias, our extensive experiments reveal a\nconsistent phenomenon we term the attention basin: when presented with a\nsequence of structured items (e.g., retrieved documents or few-shot examples),\nmodels systematically assign higher attention to the items at the beginning and\nend of the sequence, while neglecting those in the middle. Crucially, our\nanalysis further reveals that allocating higher attention to critical\ninformation is key to enhancing model performance. Based on these insights, we\nintroduce Attention-Driven Reranking (AttnRank), a two-stage framework that (i)\nestimates a model's intrinsic positional attention preferences using a small\ncalibration set, and (ii) reorders retrieved documents or few-shot examples to\nalign the most salient content with these high-attention positions. AttnRank is\na model-agnostic, training-free, and plug-and-play method with minimal\ncomputational overhead. Experiments on multi-hop QA and few-shot in-context\nlearning tasks demonstrate that AttnRank achieves substantial improvements\nacross 10 large language models of varying architectures and scales, without\nmodifying model parameters or training procedures.", "AI": {"tldr": "LLMs show 'attention basin' behavior, focusing more on the start and end of input sequences, neglecting the middle; the proposed AttnRank method effectively reorders input to enhance model output.", "motivation": "The paper aims to address the positional bias in LLMs, where attention is unevenly distributed across input sequences, focusing primarily on the initial and final items.", "method": "The study introduces AttnRank, a framework that uses a small calibration set to determine a model's attention preferences and reorders input sequences to optimize attention distribution.", "result": "AttnRank significantly improves performance across 10 large language models by realigning key information without altering model training or parameters.", "conclusion": "Redistributing input to align with LLMs' natural attention patterns enhances their capabilities in multi-hop QA and few-shot tasks, providing a scalable and efficient solution."}}
{"id": "2508.05423", "pdf": "https://arxiv.org/pdf/2508.05423", "abs": "https://arxiv.org/abs/2508.05423", "authors": ["Yixuan Zhang", "Wenxin Zhang", "Hua Jiang", "Quyu Kong", "Feng Zhou"], "title": "Negative Binomial Variational Autoencoders for Overdispersed Latent Modeling", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Biological neurons communicate through spike trains, discrete, irregular\nbursts of activity that exhibit variability far beyond the modeling capacity of\nconventional variational autoencoders (VAEs). Recent work, such as the\nPoisson-VAE, makes a biologically inspired move by modeling spike counts using\nthe Poisson distribution. However, they impose a rigid constraint: equal mean\nand variance, which fails to reflect the true stochastic nature of neural\nactivity. In this work, we challenge this constraint and introduce NegBio-VAE,\na principled extension of the VAE framework that models spike counts using the\nnegative binomial distribution. This shift grants explicit control over\ndispersion, unlocking a broader and more accurate family of neural\nrepresentations. We further develop two ELBO optimization schemes and two\ndifferentiable reparameterization strategies tailored to the negative binomial\nsetting. By introducing one additional dispersion parameter, NegBio-VAE\ngeneralizes the Poisson latent model to a negative binomial formulation.\nEmpirical results demonstrate this minor yet impactful change leads to\nsignificant gains in reconstruction fidelity, highlighting the importance of\nexplicitly modeling overdispersion in spike-like activations.", "AI": {"tldr": "The paper introduces NegBio-VAE, a novel extension to VAEs that models neural spike counts using the negative binomial distribution instead of the Poisson distribution, offering improved reconstruction fidelity by accommodating the stochastic nature of neural activity.", "motivation": "Current VAEs and Poisson-VAE fail to effectively capture the high variability of biological neuron spike trains due to limitations such as the rigid mean-variance constraint imposed by the Poisson distribution.", "method": "NegBio-VAE uses the negative binomial distribution to model spike counts, providing explicit control over dispersion. It introduces tailored ELBO optimization schemes and reparameterization strategies to adapt to this new model.", "result": "Empirical studies demonstrate that NegBio-VAE achieves superior reconstruction fidelity compared to Poisson-VAE, proving the importance of explicitly modeling overdispersion.", "conclusion": "NegBio-VAE expands the VAE framework to better represent neural activity, showing that incorporating dispersion control improves the accuracy of neural representations and reconstruction performance."}}
{"id": "2508.04845", "pdf": "https://arxiv.org/pdf/2508.04845", "abs": "https://arxiv.org/abs/2508.04845", "authors": ["Robert Frenken", "Sidra Ghayour Bhatti", "Hanqin Zhang", "Qadeer Ahmed"], "title": "Multi-Stage Knowledge-Distilled VGAE and GAT for Robust Controller-Area-Network Intrusion Detection", "categories": ["cs.LG", "cs.AI"], "comment": "arXiv admin note: substantial text overlap with arXiv:2507.19686\n  Author note: This submission is an extension of the above work by the same\n  author", "summary": "The Controller Area Network (CAN) protocol is a standard for in-vehicle\ncommunication but remains susceptible to cyber-attacks due to its lack of\nbuilt-in security. This paper presents a multi-stage intrusion detection\nframework leveraging unsupervised anomaly detection and supervised graph\nlearning tailored for automotive CAN traffic. Our architecture combines a\nVariational Graph Autoencoder (VGAE) for structural anomaly detection with a\nKnowledge-Distilled Graph Attention Network (KD-GAT) for robust attack\nclassification. CAN bus activity is encoded as graph sequences to model\ntemporal and relational dependencies. The pipeline applies VGAE-based selective\nundersampling to address class imbalance, followed by GAT classification with\noptional score-level fusion. The compact student GAT achieves 96% parameter\nreduction compared to the teacher model while maintaining strong predictive\nperformance. Experiments on six public CAN intrusion datasets--Car-Hacking,\nCar-Survival, and can-train-and-test--demonstrate competitive accuracy and\nefficiency, with average improvements of 16.2% in F1-score over existing\nmethods, particularly excelling on highly imbalanced datasets with up to 55%\nF1-score improvements.", "AI": {"tldr": "This paper proposes a novel intrusion detection framework for CAN protocol traffic using unsupervised anomaly detection and supervised graph learning methods.", "motivation": "The CAN protocol is widely used in vehicles but lacks inherent security measures, making it vulnerable to cyber attacks.", "method": "The framework utilizes Variational Graph Autoencoder (VGAE) for anomaly detection, Knowledge-Distilled Graph Attention Network (KD-GAT) for attack classification, and encodes CAN bus activity as graph sequences.", "result": "The compact student GAT model significantly reduces parameters by 96%, achieves competitive accuracy, and improves F1-scores by an average of 16.2% across six public CAN intrusion datasets.", "conclusion": "The presented approach demonstrates superior performance for identifying and classifying attacks in imbalanced CAN datasets, thereby enhancing automotive cyber security."}}
{"id": "2508.05267", "pdf": "https://arxiv.org/pdf/2508.05267", "abs": "https://arxiv.org/abs/2508.05267", "authors": ["V\u00edtor N. Louren\u00e7o", "Mohnish Dubey", "Yunfei Bai", "Audrey Depeige", "Vivek Jain"], "title": "An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication", "categories": ["cs.AI"], "comment": "Accepted to publication at the 24th International Semantic Web\n  Conference Industry Track, ISWC 2025", "summary": "In large-scale maintenance organizations, identifying subject matter experts\nand managing communications across complex entities relationships poses\nsignificant challenges -- including information overload and longer response\ntimes -- that traditional communication approaches fail to address effectively.\nWe propose a novel framework that combines RDF graph databases with LLMs to\nprocess natural language queries for precise audience targeting, while\nproviding transparent reasoning through a planning-orchestration architecture.\nOur solution enables communication owners to formulate intuitive queries\ncombining concepts such as equipment, manufacturers, maintenance engineers, and\nfacilities, delivering explainable results that maintain trust in the system\nwhile improving communication efficiency across the organization.", "AI": {"tldr": "This paper presents a framework combining RDF graph databases and LLMs to enhance audience targeting and improve communication efficiency in large-scale maintenance organizations.", "motivation": "Traditional communication approaches are ineffective in addressing the information overload and response time issues caused by identifying experts and complex relationships in maintenance organizations.", "method": "The proposed framework integrates RDF graph databases and Large Language Models (LLMs) to process natural language queries for precise audience targeting. It employs a planning-orchestration architecture for reasoning.", "result": "The framework improves communication efficiency, enables intuitive query formulation, and delivers explainable results that foster user trust.", "conclusion": "This approach effectively addresses communication challenges in large-scale maintenance organizations through advanced audience targeting and transparent reasoning."}}
{"id": "2508.05298", "pdf": "https://arxiv.org/pdf/2508.05298", "abs": "https://arxiv.org/abs/2508.05298", "authors": ["Jian Gong", "Youwei Huang", "Bo Yuan", "Ming Zhu", "Juncheng Zhan", "Jinke Wang", "Hang Shu", "Mingyue Xiong", "Yanjun Ye", "Yufan Zu", "Yang Zhou", "Yihan Ding", "Xuannian Chen", "Xingyu Lu", "Runjie Ban", "Bingchao Huang", "Fusen Liu"], "title": "GhostShell: Streaming LLM Function Calls for Concurrent Embodied Programming", "categories": ["cs.RO"], "comment": "17 pages, 5 figures, conference", "summary": "We present GhostShell, a novel approach that leverages Large Language Models\n(LLMs) to enable streaming and concurrent behavioral programming for embodied\nsystems. In contrast to conventional methods that rely on pre-scheduled action\nsequences or behavior trees, GhostShell drives embodied systems to act\non-the-fly by issuing function calls incrementally as tokens are streamed from\nthe LLM. GhostShell features a streaming XML function token parser, a dynamic\nfunction interface mapper, and a multi-channel scheduler that orchestrates\nintra-channel synchronous and inter-channel asynchronous function calls,\nthereby coordinating serial-parallel embodied actions across multiple robotic\ncomponents as directed by the LLM. We evaluate GhostShell on our robot\nprototype COCO through comprehensive grounded experiments across 34 real-world\ninteraction tasks and multiple LLMs. The results demonstrate that our approach\nachieves state-of-the-art Behavioral Correctness Metric of 0.85 with Claude-4\nSonnet and up to 66X faster response times compared to LLM native function\ncalling APIs. GhostShell also proves effective in long-horizon multimodal\ntasks, demonstrating strong robustness and generalization.", "AI": {"tldr": "GhostShell is a novel LLM-enabled framework for real-time behavioral programming in robots, outperforming traditional methods in speed, accuracy, and adaptability during various tasks.", "motivation": "The paper addresses the limitations of conventional robotic behavioral programming methods, which depend on pre-scripted action sequences or behavior trees, and explores real-time decision-making through LLMs.", "method": "The researchers developed GhostShell, featuring a streaming XML function parser, dynamic function interface mapper, and a multi-channel scheduler to enable on-the-fly robotic decision-making based on streamed LLM outputs.", "result": "Experiments on the COCO robot prototype demonstrated a Behavioral Correctness Metric of 0.85 with Claude-4 Sonnet, significant speed-ups (up to 66X), and strong performance on long-horizon multimodal tasks.", "conclusion": "GhostShell achieves state-of-the-art results in both speed and behavioral accuracy and is robust enough to support complex interaction tasks, representing a groundbreaking approach for embodied systems."}}
{"id": "2508.04955", "pdf": "https://arxiv.org/pdf/2508.04955", "abs": "https://arxiv.org/abs/2508.04955", "authors": ["Stella Su", "Marc Harary", "Scott J. Rodig", "William Lotter"], "title": "AdvDINO: Domain-Adversarial Self-Supervised Representation Learning for Spatial Proteomics", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Self-supervised learning (SSL) has emerged as a powerful approach for\nlearning visual representations without manual annotations. However, the\nrobustness of standard SSL methods to domain shift -- systematic differences\nacross data sources -- remains uncertain, posing an especially critical\nchallenge in biomedical imaging where batch effects can obscure true biological\nsignals. We present AdvDINO, a domain-adversarial self-supervised learning\nframework that integrates a gradient reversal layer into the DINOv2\narchitecture to promote domain-invariant feature learning. Applied to a\nreal-world cohort of six-channel multiplex immunofluorescence (mIF) whole slide\nimages from non-small cell lung cancer patients, AdvDINO mitigates\nslide-specific biases to learn more robust and biologically meaningful\nrepresentations than non-adversarial baselines. Across $>5.46$ million mIF\nimage tiles, the model uncovers phenotype clusters with distinct proteomic\nprofiles and prognostic significance, and improves survival prediction in\nattention-based multiple instance learning. While demonstrated on mIF data,\nAdvDINO is broadly applicable to other imaging domains -- including radiology,\nremote sensing, and autonomous driving -- where domain shift and limited\nannotated data hinder model generalization and interpretability.", "AI": {"tldr": "This paper introduces AdvDINO, a domain-adversarial self-supervised learning method to enhance domain-invariant feature extraction in biomedical imaging, addressing domain shifts and batch effects.", "motivation": "Standard self-supervised learning struggles with domain shifts, which are prevalent in biomedical imaging and obscure true biological signals.", "method": "AdvDINO integrates a gradient reversal layer into the DINOv2 architecture to promote domain-invariant feature learning.", "result": "AdvDINO mitigates slide-specific biases, uncovers biologically significant phenotype clusters, enhances survival prediction, and demonstrates broad applicability beyond biomedical imaging.", "conclusion": "AdvDINO improves robustness and generalization in imaging domains affected by domain shift, making it valuable for applications like radiology and autonomous driving."}}
{"id": "2508.05132", "pdf": "https://arxiv.org/pdf/2508.05132", "abs": "https://arxiv.org/abs/2508.05132", "authors": ["Chang Hong", "Minghao Wu", "Qingying Xiao", "Yuchi Wang", "Xiang Wan", "Guangjun Yu", "Benyou Wang", "Yan Hu"], "title": "Towards Assessing Medical Ethics from Knowledge to Practice", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The integration of large language models into healthcare necessitates a\nrigorous evaluation of their ethical reasoning, an area current benchmarks\noften overlook. We introduce PrinciplismQA, a comprehensive benchmark with\n3,648 questions designed to systematically assess LLMs' alignment with core\nmedical ethics. Grounded in Principlism, our benchmark features a high-quality\ndataset. This includes multiple-choice questions curated from authoritative\ntextbooks and open-ended questions sourced from authoritative medical ethics\ncase study literature, all validated by medical experts. Our experiments reveal\na significant gap between models' ethical knowledge and their practical\napplication, especially in dynamically applying ethical principles to\nreal-world scenarios. Most LLMs struggle with dilemmas concerning Beneficence,\noften over-emphasizing other principles. Frontier closed-source models, driven\nby strong general capabilities, currently lead the benchmark. Notably, medical\ndomain fine-tuning can enhance models' overall ethical competence, but further\nprogress requires better alignment with medical ethical knowledge.\nPrinciplismQA offers a scalable framework to diagnose these specific ethical\nweaknesses, paving the way for more balanced and responsible medical AI.", "AI": {"tldr": "The paper introduces PrinciplismQA, a benchmark to evaluate large language models' (LLMs) ethical reasoning in healthcare. It highlights gaps in ethical application and provides metrics for improvement.", "motivation": "The paper aims to address the lack of systematic benchmarks for assessing the ethical reasoning capabilities of LLMs in healthcare contexts.", "method": "Researchers developed PrinciplismQA, comprising 3,648 questions based on medical ethics textbooks and case literature, validated by experts, for evaluating LLM alignment with medical ethical principles.", "result": "Experiments showed that LLMs often fail to apply ethical principles effectively, particularly in dilemmas involving Beneficence. Closed-source models outperform others, and fine-tuning improves ethical competence.", "conclusion": "PrinciplismQA provides a robust tool to identify ethical reasoning gaps in LLMs and emphasizes the need for better alignment between medical ethical knowledge and AI capabilities for responsible healthcare applications."}}
{"id": "2508.04853", "pdf": "https://arxiv.org/pdf/2508.04853", "abs": "https://arxiv.org/abs/2508.04853", "authors": ["Haoyu Zhang", "Shihao Zhang", "Ian Colbert", "Rayan Saab"], "title": "Provable Post-Training Quantization: Theoretical Analysis of OPTQ and Qronos", "categories": ["cs.LG", "cs.AI", "cs.IT", "cs.NA", "math.IT", "math.NA", "68T07, 68W25, 62M45, 68Q25"], "comment": null, "summary": "Post-training quantization (PTQ) has become a crucial tool for reducing the\nmemory and compute costs of modern deep neural networks, including large\nlanguage models (LLMs). Among PTQ algorithms, the OPTQ framework-also known as\nGPTQ-has emerged as a leading method due to its computational efficiency and\nstrong empirical performance. Despite its widespread adoption, however, OPTQ\nlacks rigorous quantitative theoretical guarantees. This paper presents the\nfirst quantitative error bounds for both deterministic and stochastic variants\nof OPTQ, as well as for Qronos, a recent related state-of-the-art PTQ\nalgorithm. We analyze how OPTQ's iterative procedure induces quantization error\nand derive non-asymptotic 2-norm error bounds that depend explicitly on the\ncalibration data and a regularization parameter that OPTQ uses. Our analysis\nprovides theoretical justification for several practical design choices,\nincluding the widely used heuristic of ordering features by decreasing norm, as\nwell as guidance for selecting the regularization parameter. For the stochastic\nvariant, we establish stronger infinity-norm error bounds, which enable control\nover the required quantization alphabet and are particularly useful for\ndownstream layers and nonlinearities. Finally, we extend our analysis to\nQronos, providing new theoretical bounds, for both its deterministic and\nstochastic variants, that help explain its empirical advantages.", "AI": {"tldr": "The paper provides the first mathematical error bounds for the widely used Post-training quantization methods OPTQ and Qronos, improving understanding and user guidance.", "motivation": "The need to assess the theoretical reliability of OPTQ and Qronos PTQ methods, which are widely utilized for reducing neural network costs but lack quantitative guarantees.", "method": "The authors derive non-asymptotic error bounds for deterministic and stochastic variants of OPTQ and Qronos by analyzing their quantization procedures against calibration data and regularization parameters.", "result": "They established 2-norm and infinity-norm error bounds for OPTQ and Qronos, offering insights on calibration heuristics and parameter selection to improve performance.", "conclusion": "The analysis provides theoretical justification for OPTQ design choices, guidance for parameterization, and new guarantees explaining Qronos's empirical performance advantages."}}
{"id": "2508.05311", "pdf": "https://arxiv.org/pdf/2508.05311", "abs": "https://arxiv.org/abs/2508.05311", "authors": ["Andrew Kiruluta"], "title": "A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "We propose a hybrid architecture that integrates decision tree-based symbolic\nreasoning with the generative capabilities of large language models (LLMs)\nwithin a coordinated multi-agent framework. Unlike prior approaches that\nloosely couple symbolic and neural modules, our design embeds decision trees\nand random forests as callable oracles within a unified reasoning system.\nTree-based modules enable interpretable rule inference and causal logic, while\nLLM agents handle abductive reasoning, generalization, and interactive\nplanning. A central orchestrator maintains belief state consistency and\nmediates communication across agents and external tools, enabling reasoning\nover both structured and unstructured inputs.\n  The system achieves strong performance on reasoning benchmarks. On\n\\textit{ProofWriter}, it improves entailment consistency by +7.2\\% through\nlogic-grounded tree validation. On GSM8k, it achieves +5.3\\% accuracy gains in\nmultistep mathematical problems via symbolic augmentation. On \\textit{ARC}, it\nboosts abstraction accuracy by +6.0\\% through integration of symbolic oracles.\nApplications in clinical decision support and scientific discovery show how the\nsystem encodes domain rules symbolically while leveraging LLMs for contextual\ninference and hypothesis generation. This architecture offers a robust,\ninterpretable, and extensible solution for general-purpose neuro-symbolic\nreasoning.", "AI": {"tldr": "This paper introduces a hybrid system that integrates decision trees and large language models (LLMs) into a unified multi-agent framework for improved reasoning tasks.", "motivation": "The motivation is to resolve limitations in prior neuro-symbolic systems by tightly integrating interpretable decision trees with the generative and reasoning capabilities of LLMs, addressing both structured and unstructured reasoning challenges.", "method": "The method involves embedding decision trees and random forests as callable oracles within a multi-agent framework. An orchestrator coordinates agents, maintains belief state consistency, and mediates communication, while decision trees enhance interpretability and causal reasoning, and LLMs handle abductive reasoning and generalization.", "result": "The proposed system outperforms baselines, showing +7.2% entailment consistency on ProofWriter, +5.3% accuracy gains on GSM8k mathematical problems, and +6.0% abstraction accuracy on ARC benchmarks. It also demonstrates applications in clinical decision-making and scientific research.", "conclusion": "The paper concludes that this hybrid architecture provides a robust, interpretable, and extensible framework for tackling general-purpose reasoning tasks by combining symbolic and neural approaches effectively."}}
{"id": "2508.05342", "pdf": "https://arxiv.org/pdf/2508.05342", "abs": "https://arxiv.org/abs/2508.05342", "authors": ["Shunlei Li", "Longsen Gao", "Jin Wang", "Chang Che", "Xi Xiao", "Jiuwen Cao", "Yingbai Hu", "Hamid Reza Karimi"], "title": "Information-Theoretic Graph Fusion with Vision-Language-Action Model for Policy Reasoning and Dual Robotic Control", "categories": ["cs.RO", "cs.AI"], "comment": "Journal under review", "summary": "Teaching robots dexterous skills from human videos remains challenging due to\nthe reliance on low-level trajectory imitation, which fails to generalize\nacross object types, spatial layouts, and manipulator configurations. We\npropose Graph-Fused Vision-Language-Action (GF-VLA), a framework that enables\ndual-arm robotic systems to perform task-level reasoning and execution directly\nfrom RGB and Depth human demonstrations. GF-VLA first extracts\nShannon-information-based cues to identify hands and objects with the highest\ntask relevance, then encodes these cues into temporally ordered scene graphs\nthat capture both hand-object and object-object interactions. These graphs are\nfused with a language-conditioned transformer that generates hierarchical\nbehavior trees and interpretable Cartesian motion commands. To improve\nexecution efficiency in bimanual settings, we further introduce a cross-hand\nselection policy that infers optimal gripper assignment without explicit\ngeometric reasoning. We evaluate GF-VLA on four structured dual-arm block\nassembly tasks involving symbolic shape construction and spatial\ngeneralization. Experimental results show that the information-theoretic scene\nrepresentation achieves over 95 percent graph accuracy and 93 percent subtask\nsegmentation, supporting the LLM planner in generating reliable and\nhuman-readable task policies. When executed by the dual-arm robot, these\npolicies yield 94 percent grasp success, 89 percent placement accuracy, and 90\npercent overall task success across stacking, letter-building, and geometric\nreconfiguration scenarios, demonstrating strong generalization and robustness\nacross diverse spatial and semantic variations.", "AI": {"tldr": "The paper introduces GF-VLA, a framework for dual-arm robots to adeptly interpret and replicate human tasks using RGB and Depth data, with notable accuracy in diverse tasks.", "motivation": "Developing robotic systems capable of task-level generalization by understanding human demonstrations without the limiting factors of simple trajectory imitation.", "method": "The method involves extracting key hand-object and object-object interactions to form scene graphs, integrating these with language-conditioned transformers to derive task policies, and employing a cross-hand selection policy for better dual-arm coordination.", "result": "GF-VLA achieved over 95% scene graph accuracy, 93% task segmentation, and 90% overall task success in challenging dual-arm robotic tasks, proving reliable across spatial and semantic variations.", "conclusion": "GF-VLA demonstrates the ability of robots to achieve high generalization and task success in structured manipulations, broadening the possibilities for practical robotic applications."}}
{"id": "2508.04962", "pdf": "https://arxiv.org/pdf/2508.04962", "abs": "https://arxiv.org/abs/2508.04962", "authors": ["Peng Zhang", "Songru Yang", "Jinsheng Sun", "Weiqing Li", "Zhiyong Su"], "title": "Open-world Point Cloud Semantic Segmentation: A Human-in-the-loop Framework", "categories": ["cs.CV", "cs.GR"], "comment": "To be published in IEEE Transactions on Circuits and Systems for\n  Video Technology", "summary": "Open-world point cloud semantic segmentation (OW-Seg) aims to predict point\nlabels of both base and novel classes in real-world scenarios. However,\nexisting methods rely on resource-intensive offline incremental learning or\ndensely annotated support data, limiting their practicality. To address these\nlimitations, we propose HOW-Seg, the first human-in-the-loop framework for\nOW-Seg. Specifically, we construct class prototypes, the fundamental\nsegmentation units, directly on the query data, avoiding the prototype bias\ncaused by intra-class distribution shifts between the support and query data.\nBy leveraging sparse human annotations as guidance, HOW-Seg enables\nprototype-based segmentation for both base and novel classes. Considering the\nlack of granularity of initial prototypes, we introduce a hierarchical\nprototype disambiguation mechanism to refine ambiguous prototypes, which\ncorrespond to annotations of different classes. To further enrich contextual\nawareness, we employ a dense conditional random field (CRF) upon the refined\nprototypes to optimize their label assignments. Through iterative human\nfeedback, HOW-Seg dynamically improves its predictions, achieving high-quality\nsegmentation for both base and novel classes. Experiments demonstrate that with\nsparse annotations (e.g., one-novel-class-one-click), HOW-Seg matches or\nsurpasses the state-of-the-art generalized few-shot segmentation (GFS-Seg)\nmethod under the 5-shot setting. When using advanced backbones (e.g.,\nStratified Transformer) and denser annotations (e.g., 10 clicks per sub-scene),\nHOW-Seg achieves 85.27% mIoU on S3DIS and 66.37% mIoU on ScanNetv2,\nsignificantly outperforming alternatives.", "AI": {"tldr": "HOW-Seg is a human-in-the-loop framework for open-world point cloud segmentation that refines class prototypes with sparse annotations, achieving state-of-the-art performance in generalized few-shot segmentation tasks.", "motivation": "Existing OW-Seg methods rely on resource-intensive training or heavily annotated data, which limits scalability and practicality. The goal is to develop an efficient approach that alleviates these constraints.", "method": "HOW-Seg constructs class prototypes directly from the query dataset, refines initial prototypes using a hierarchical prototype disambiguation mechanism, and applies a dense conditional random field for better contextual understanding. Iterative human feedback further enhances its predictions.", "result": "HOW-Seg outperforms state-of-the-art generalized few-shot segmentation methods. It achieves 85.27% mIoU on the S3DIS dataset and 66.37% mIoU on the ScanNetv2 dataset with sparse human annotations and advanced network backbones.", "conclusion": "The proposed HOW-Seg framework is efficient and scalable, demonstrating superior performance in OW-Seg tasks with minimal human intervention and achieving better results than existing methods."}}
{"id": "2508.05179", "pdf": "https://arxiv.org/pdf/2508.05179", "abs": "https://arxiv.org/abs/2508.05179", "authors": ["Catherine Kobus", "Fran\u00e7ois Lancelot", "Marion-C\u00e9cile Martin", "Nawal Ould Amer"], "title": "ATLANTIS at SemEval-2025 Task 3: Detecting Hallucinated Text Spans in Question Answering", "categories": ["cs.CL"], "comment": null, "summary": "This paper presents the contributions of the ATLANTIS team to SemEval-2025\nTask 3, focusing on detecting hallucinated text spans in question answering\nsystems. Large Language Models (LLMs) have significantly advanced Natural\nLanguage Generation (NLG) but remain susceptible to hallucinations, generating\nincorrect or misleading content. To address this, we explored methods both with\nand without external context, utilizing few-shot prompting with a LLM,\ntoken-level classification or LLM fine-tuned on synthetic data. Notably, our\napproaches achieved top rankings in Spanish and competitive placements in\nEnglish and German. This work highlights the importance of integrating relevant\ncontext to mitigate hallucinations and demonstrate the potential of fine-tuned\nmodels and prompt engineering.", "AI": {"tldr": "This paper tackles hallucinated text detection in QA systems using various methods, achieving top performance in multiple languages.", "motivation": "LLMs, despite advancements in NLG, often generate hallucinated content, necessitating effective detection methods.", "method": "The authors used few-shot prompting with LLMs, token-level classification, and fine-tuned LLMs on synthetic data.", "result": "Their approaches yielded top rankings in Spanish and competitive results in English and German, effectively detecting hallucinated spans.", "conclusion": "Integrating relevant context and employing fine-tuned models with prompt engineering are key strategies to mitigate hallucinations in LLMs."}}
{"id": "2508.05338", "pdf": "https://arxiv.org/pdf/2508.05338", "abs": "https://arxiv.org/abs/2508.05338", "authors": ["Brinnae Bent"], "title": "The Term 'Agent' Has Been Diluted Beyond Utility and Requires Redefinition", "categories": ["cs.AI", "cs.CY"], "comment": "Accepted to AIES 2025", "summary": "The term 'agent' in artificial intelligence has long carried multiple\ninterpretations across different subfields. Recent developments in AI\ncapabilities, particularly in large language model systems, have amplified this\nambiguity, creating significant challenges in research communication, system\nevaluation and reproducibility, and policy development. This paper argues that\nthe term 'agent' requires redefinition. Drawing from historical analysis and\ncontemporary usage patterns, we propose a framework that defines clear minimum\nrequirements for a system to be considered an agent while characterizing\nsystems along a multidimensional spectrum of environmental interaction,\nlearning and adaptation, autonomy, goal complexity, and temporal coherence.\nThis approach provides precise vocabulary for system description while\npreserving the term's historically multifaceted nature. After examining\npotential counterarguments and implementation challenges, we provide specific\nrecommendations for moving forward as a field, including suggestions for\nterminology standardization and framework adoption. The proposed approach\noffers practical tools for improving research clarity and reproducibility while\nsupporting more effective policy development.", "AI": {"tldr": "The term 'agent' in AI is ambiguous and needs redefining to improve research clarity, policy development, and evaluation practices.", "motivation": "The paper aims to address ambiguity in the definition of 'agent' in AI, which affects research communication, reproducibility, system evaluation, and policymaking.", "method": "The authors propose redefining 'agent' using a framework based on historical and contemporary usage, outlining requirements and characterizing systems along key interaction dimensions.", "result": "The paper provides a structured framework to clarify 'agent' terminology and offers practical recommendations for standardization and adoption.", "conclusion": "The redefinition enhances system descriptions while preserving the term's multifaceted nature, benefiting research clarity and policy advancement."}}
{"id": "2508.05359", "pdf": "https://arxiv.org/pdf/2508.05359", "abs": "https://arxiv.org/abs/2508.05359", "authors": ["Morten Roed Frederiksen", "Kasper St\u00f8y"], "title": "Affecta-Context: The Context-Guided Behavior Adaptation Framework", "categories": ["cs.RO"], "comment": "6 pages, Intelligent Autonomous Systems 18. IAS 2023", "summary": "This paper presents Affecta-context, a general framework to facilitate\nbehavior adaptation for social robots. The framework uses information about the\nphysical context to guide its behaviors in human-robot interactions. It\nconsists of two parts: one that represents encountered contexts and one that\nlearns to prioritize between behaviors through human-robot interactions. As\nphysical contexts are encountered the framework clusters them by their measured\nphysical properties. In each context, the framework learns to prioritize\nbetween behaviors to optimize the physical attributes of the robot's behavior\nin line with its current environment and the preferences of the users it\ninteracts with. This paper illlustrates the abilities of the Affecta-context\nframework by enabling a robot to autonomously learn the prioritization of\ndiscrete behaviors. This was achieved by training across 72 interactions in two\ndifferent physical contexts with 6 different human test participants. The paper\ndemonstrates the trained Affecta-context framework by verifying the robot's\nability to generalize over the input and to match its behaviors to a previously\nunvisited physical context.", "AI": {"tldr": "The paper introduces Affecta-context, a framework enabling social robots to adapt their behaviors based on physical contexts and user preferences.", "motivation": "To improve human-robot interaction by creating robots that can autonomously adapt to varying physical environments and user preferences.", "method": "The framework learns and clusters physical contexts through their measured properties and prioritizes robot behaviors to match these contexts using data from interactions with humans.", "result": "Through 72 interactions in two physical contexts involving 6 human participants, the framework demonstrated its ability to adapt behaviors and generalize to new physical contexts.", "conclusion": "The Affecta-context framework shows promise in enabling social robots to adapt behaviors autonomously across varying physical contexts, enhancing human-robot interaction experiences."}}
{"id": "2508.04968", "pdf": "https://arxiv.org/pdf/2508.04968", "abs": "https://arxiv.org/abs/2508.04968", "authors": ["Zhihao Guo", "Peng Wang", "Zidong Chen", "Xiangyu Kong", "Yan Lyu", "Guanyu Gao", "Liangxiu Han"], "title": "UGOD: Uncertainty-Guided Differentiable Opacity and Soft Dropout for Enhanced Sparse-View 3DGS", "categories": ["cs.CV", "cs.AI", "I.4.8; I.2.10; I.5.1"], "comment": "11 pages, 5 figures", "summary": "3D Gaussian Splatting (3DGS) has become a competitive approach for novel view\nsynthesis (NVS) due to its advanced rendering efficiency through 3D Gaussian\nprojection and blending. However, Gaussians are treated equally weighted for\nrendering in most 3DGS methods, making them prone to overfitting, which is\nparticularly the case in sparse-view scenarios. To address this, we investigate\nhow adaptive weighting of Gaussians affects rendering quality, which is\ncharacterised by learned uncertainties proposed. This learned uncertainty\nserves two key purposes: first, it guides the differentiable update of Gaussian\nopacity while preserving the 3DGS pipeline integrity; second, the uncertainty\nundergoes soft differentiable dropout regularisation, which strategically\ntransforms the original uncertainty into continuous drop probabilities that\ngovern the final Gaussian projection and blending process for rendering.\nExtensive experimental results over widely adopted datasets demonstrate that\nour method outperforms rivals in sparse-view 3D synthesis, achieving higher\nquality reconstruction with fewer Gaussians in most datasets compared to\nexisting sparse-view approaches, e.g., compared to DropGaussian, our method\nachieves 3.27\\% PSNR improvements on the MipNeRF 360 dataset.", "AI": {"tldr": "This paper introduces a method to enhance 3D Gaussian Splatting for novel view synthesis by applying adaptive Gaussian weighting through learned uncertainties, improving rendering quality, especially for sparse-view scenarios.", "motivation": "The paper aims to address the limitations of traditional 3D Gaussian Splatting methods, which tend to overfit in sparse-view settings due to treating all Gaussians equally during rendering.", "method": "The proposed method involves learned uncertainties for adaptive weighting of Gaussians, differentiable opacity adjustment, and soft dropout regularisation to manage Gaussian projections and blending effectively.", "result": "Extensive experiments show significant improvement in sparse-view 3D synthesis, achieving higher reconstruction quality and using fewer Gaussians. The method demonstrates a 3.27% PSNR improvement on the MipNeRF 360 dataset compared to previous methods such as DropGaussian.", "conclusion": "The paper concludes that employing adaptive Gaussian weighting through learned uncertainties enhances rendering quality in sparse-view scenarios, establishing a more efficient and accurate method for 3D Gaussian Splatting."}}
{"id": "2508.05234", "pdf": "https://arxiv.org/pdf/2508.05234", "abs": "https://arxiv.org/abs/2508.05234", "authors": ["Haonan Shangguan", "Xiaocui Yang", "Shi Feng", "Daling Wang", "Yifei Zhang", "Ge Yu"], "title": "Resource-Limited Joint Multimodal Sentiment Reasoning and Classification via Chain-of-Thought Enhancement and Distillation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The surge in rich multimodal content on social media platforms has greatly\nadvanced Multimodal Sentiment Analysis (MSA), with Large Language Models (LLMs)\nfurther accelerating progress in this field. Current approaches primarily\nleverage the knowledge and reasoning capabilities of parameter-heavy\n(Multimodal) LLMs for sentiment classification, overlooking autonomous\nmultimodal sentiment reasoning generation in resource-constrained environments.\nTherefore, we focus on the Resource-Limited Joint Multimodal Sentiment\nReasoning and Classification task, JMSRC, which simultaneously performs\nmultimodal sentiment reasoning chain generation and sentiment classification\nonly with a lightweight model. We propose a Multimodal Chain-of-Thought\nReasoning Distillation model, MulCoT-RD, designed for JMSRC that employs a\n\"Teacher-Assistant-Student\" distillation paradigm to address deployment\nconstraints in resource-limited environments. We first leverage a\nhigh-performance Multimodal Large Language Model (MLLM) to generate the initial\nreasoning dataset and train a medium-sized assistant model with a multi-task\nlearning mechanism. A lightweight student model is jointly trained to perform\nefficient multimodal sentiment reasoning generation and classification.\nExtensive experiments on four datasets demonstrate that MulCoT-RD with only 3B\nparameters achieves strong performance on JMSRC, while exhibiting robust\ngeneralization and enhanced interpretability.", "AI": {"tldr": "This paper introduces a lightweight model to perform multimodal sentiment reasoning and classification effectively using a novel distillation approach.", "motivation": "To address the lack of autonomous multimodal sentiment reasoning and classification in resource-constrained environments.", "method": "The paper proposes a \"Teacher-Assistant-Student\" distillation paradigm, where a large LLM generates reasoning data, a medium assistant model learns via multi-task learning, and a lightweight student model is jointly trained for sentiment tasks.", "result": "MulCoT-RD achieves strong performance on the JMSRC task using only 3B parameters, with robust generalization and improved interpretability across four datasets.", "conclusion": "The approach successfully integrates efficient reasoning and classification capabilities into a compact model suitable for resource-limited environments."}}
{"id": "2508.04882", "pdf": "https://arxiv.org/pdf/2508.04882", "abs": "https://arxiv.org/abs/2508.04882", "authors": ["Saman Pordanesh", "Pejman Shahsavari", "Hossein Ghadjari"], "title": "Hilbert Neural Operator: Operator Learning in the Analytic Signal Domain", "categories": ["cs.LG"], "comment": null, "summary": "Neural operators have emerged as a powerful, data-driven paradigm for\nlearning solution operators of partial differential equations (PDEs).\nState-of-the-art architectures, such as the Fourier Neural Operator (FNO), have\nachieved remarkable success by performing convolutions in the frequency domain,\nmaking them highly effective for a wide range of problems. However, this method\nhas some limitations, including the periodicity assumption of the Fourier\ntransform. In addition, there are other methods of analysing a signal, beyond\nphase and amplitude perspective, and provide us with other useful information\nto learn an effective network. We introduce the \\textbf{Hilbert Neural Operator\n(HNO)}, a new neural operator architecture to address some advantages by\nincorporating a strong inductive bias from signal processing. HNO operates by\nfirst mapping the input signal to its analytic representation via the Hilbert\ntransform, thereby making instantaneous amplitude and phase information\nexplicit features for the learning process. The core learnable operation -- a\nspectral convolution -- is then applied to this Hilbert-transformed\nrepresentation. We hypothesize that this architecture enables HNO to model\noperators more effectively for causal, phase-sensitive, and non-stationary\nsystems. We formalize the HNO architecture and provide the theoretical\nmotivation for its design, rooted in analytic signal theory.", "AI": {"tldr": "The paper introduces the Hilbert Neural Operator (HNO), a neural operator architecture based on the Hilbert transform, designed to overcome limitations of Fourier-based operators such as periodicity assumptions.", "motivation": "Addressing the limitations of existing neural operators, particularly the Fourier Neural Operator (FNO), like its reliance on periodicity and lack of other useful signal representations.", "method": "The architecture employs a Hilbert transform to create an analytic signal representation, explicitly capturing amplitude and phase as features. Spectral convolution is applied to this transformed representation.", "result": "HNO is hypothesized to perform better in handling causal, phase-sensitive, and non-stationary systems due to its design rooted in analytic signal theory.", "conclusion": "HNO presents an innovative use of signal processing principles in operator learning, offering a promising alternative to Fourier-based methods for certain types of systems."}}
{"id": "2508.05344", "pdf": "https://arxiv.org/pdf/2508.05344", "abs": "https://arxiv.org/abs/2508.05344", "authors": ["Asutosh Hota", "Jussi P. P. Jokinen"], "title": "NomicLaw: Emergent Trust and Strategic Argumentation in LLMs During Collaborative Law-Making", "categories": ["cs.AI"], "comment": null, "summary": "Recent advancements in large language models (LLMs) have extended their\ncapabilities from basic text processing to complex reasoning tasks, including\nlegal interpretation, argumentation, and strategic interaction. However,\nempirical understanding of LLM behavior in open-ended, multi-agent settings\nespecially those involving deliberation over legal and ethical dilemmas remains\nlimited. We introduce NomicLaw, a structured multi-agent simulation where LLMs\nengage in collaborative law-making, responding to complex legal vignettes by\nproposing rules, justifying them, and voting on peer proposals. We\nquantitatively measure trust and reciprocity via voting patterns and\nqualitatively assess how agents use strategic language to justify proposals and\ninfluence outcomes. Experiments involving homogeneous and heterogeneous LLM\ngroups demonstrate how agents spontaneously form alliances, betray trust, and\nadapt their rhetoric to shape collective decisions. Our results highlight the\nlatent social reasoning and persuasive capabilities of ten open-source LLMs and\nprovide insights into the design of future AI systems capable of autonomous\nnegotiation, coordination and drafting legislation in legal settings.", "AI": {"tldr": "NomicLaw demonstrates how LLMs engage in collaborative law-making, revealing latent social reasoning and persuasive capabilities.", "motivation": "To understand LLM behavior in multi-agent, deliberative legal settings.", "method": "NomicLaw simulation with structured legal vignettes, rule proposals, justification, and voting.", "result": "LLMs exhibited strategic behavior such as alliance formation, trust betrayal, and adaptive rhetoric.", "conclusion": "Findings offer insights for designing AI systems for autonomous legal negotiation and legislation drafting."}}
{"id": "2508.05368", "pdf": "https://arxiv.org/pdf/2508.05368", "abs": "https://arxiv.org/abs/2508.05368", "authors": ["Tong Hua", "Jiale Han", "Wei Ouyang"], "title": "A Multi-view Landmark Representation Approach with Application to GNSS-Visual-Inertial Odometry", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Invariant Extended Kalman Filter (IEKF) has been a significant technique in\nvision-aided sensor fusion. However, it usually suffers from high computational\nburden when jointly optimizing camera poses and the landmarks. To improve its\nefficiency and applicability for multi-sensor fusion, we present a multi-view\npose-only estimation approach with its application to GNSS-Visual-Inertial\nOdometry (GVIO) in this paper. Our main contribution is deriving a visual\nmeasurement model which directly associates landmark representation with\nmultiple camera poses and observations. Such a pose-only measurement is proven\nto be tightly-coupled between landmarks and poses, and maintain a perfect null\nspace that is independent of estimated poses. Finally, we apply the proposed\napproach to a filter based GVIO with a novel feature management strategy. Both\nsimulation tests and real-world experiments are conducted to demonstrate the\nsuperiority of the proposed method in terms of efficiency and accuracy.", "AI": {"tldr": "The paper introduces a pose-only estimation approach to optimize the efficiency of GNSS-Visual-Inertial Odometry (GVIO) systems, addressing the computational burden of IEKF.", "motivation": "To address the high computational burden inherent in IEKF when jointly optimizing camera poses and landmarks, and enhance the applicability in multi-sensor fusion scenarios.", "method": "Proposed a visual measurement model that directly links landmark representation to multiple camera poses and observations, allowing pose-only estimation. Applied the model within a filter-based GVIO framework, introducing a novel feature management strategy.", "result": "Simulation tests and real-world experiments validated the improved efficiency and accuracy of the proposed method.", "conclusion": "The approach is effective in reducing computational complexity while maintaining accuracy, offering improvements for GVIO systems in multi-sensor fusion applications."}}
