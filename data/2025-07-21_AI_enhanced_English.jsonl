{"id": "2507.13355", "pdf": "https://arxiv.org/pdf/2507.13355", "abs": "https://arxiv.org/abs/2507.13355", "authors": ["Riadul Islam", "Dhandeep Challagundla"], "title": "PGR-DRC: Pre-Global Routing DRC Violation Prediction Using Unsupervised Learning", "categories": ["cs.AR", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Leveraging artificial intelligence (AI)-driven electronic design and\nautomation (EDA) tools, high-performance computing, and parallelized algorithms\nare essential for next-generation microprocessor innovation, ensuring continued\nprogress in computing, AI, and semiconductor technology. Machine learning-based\ndesign rule checking (DRC) and lithography hotspot detection can improve\nfirst-pass silicon success. However, conventional ML and neural network\n(NN)-based models use supervised learning and require a large balanced dataset\n(in terms of positive and negative classes) and training time. This research\naddresses those key challenges by proposing the first-ever unsupervised DRC\nviolation prediction methodology. The proposed model can be built using any\nunbalanced dataset using only one class and set a threshold for it, then\nfitting any new data querying if they are within the boundary of the model for\nclassification. This research verified the proposed model by implementing\ndifferent computational cores using CMOS 28 nm technology and Synopsys Design\nCompiler and IC Compiler II tools. Then, layouts were divided into virtual\ngrids to collect about 60k data for analysis and verification. The proposed\nmethod has 99.95% prediction test accuracy, while the existing support vector\nmachine (SVM) and neural network (NN) models have 85.44\\% and 98.74\\% accuracy,\nrespectively. In addition, the proposed methodology has about 26.3x and up to\n6003x lower training times compared to SVM and NN-models, respectively.", "AI": {"tldr": "The paper introduces an unsupervised method for Design Rule Checking (DRC) violation prediction, achieving superior accuracy and drastically reducing training times compared to SVM and NN models.", "motivation": "Advancing next-generation microprocessor design requires overcoming challenges in machine learning-based EDA tools, such as the need for large balanced datasets and long training times.", "method": "An unsupervised methodology is proposed for DRC violation prediction. The model is trained on unbalanced datasets using data from only one class to set thresholds and classify new data.", "result": "The proposed method achieves 99.95% accuracy in prediction, outperforming support vector machines (85.44%) and neural networks (98.74%), while reducing training time by up to 6003x compared to neural networks.", "conclusion": "This research demonstrates that unsupervised DRC prediction enables efficient and accurate microprocessor layout analysis, offering a substantial improvement over conventional solutions."}}
{"id": "2507.13369", "pdf": "https://arxiv.org/pdf/2507.13369", "abs": "https://arxiv.org/abs/2507.13369", "authors": ["Paul E. Calzada", "Zahin Ibnat", "Tanvir Rahman", "Kamal Kandula", "Danyu Lu", "Sujan Kumar Saha", "Farimah Farahmandi", "Mark Tehranipoor"], "title": "VerilogDB: The Largest, Highest-Quality Dataset with a Preprocessing Framework for LLM-based RTL Generation", "categories": ["cs.AR", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) are gaining popularity for hardware design\nautomation, particularly through Register Transfer Level (RTL) code generation.\nIn this work, we examine the current literature on RTL generation using LLMs\nand identify key requirements for training and fine-tuning datasets. We\nconstruct a robust Verilog dataset through an automated three-pronged process\ninvolving database (DB) creation and management with PostgreSQL, data\ncollection from code hosting sites like OpenCores and GitHub, and data\npreprocessing to verify the codes' syntax, run logic synthesis, and extract\nrelevant module metadata. We implement a scalable and efficient DB\ninfrastructure to support analysis and detail our preprocessing pipeline to\nenforce high-quality data before DB insertion. The resulting dataset comprises\n20,392 Verilog samples, 751 MB of Verilog code data, which is the largest\nhigh-quality Verilog dataset for LLM fine-tuning to our knowledge. We further\nevaluate the dataset, address associated challenges, and explore potential\napplications for future research and development in LLM-based hardware\ngeneration.", "AI": {"tldr": "The paper constructs a large, high-quality Verilog dataset to support fine-tuning LLMs for RTL code generation.", "motivation": "The growth of LLMs in hardware design automation requires suitable, high-quality datasets for training and fine-tuning, especially for RTL code generation tasks.", "method": "The authors built a Verilog dataset using PostgreSQL for database management, collected data from OpenCores and GitHub, and performed preprocessing like syntax checks and logic synthesis.", "result": "The authors produced the largest known high-quality Verilog dataset, consisting of 20,392 samples and 751 MB of code data.", "conclusion": "This dataset can be a foundation for further advancements in LLM-based hardware design, and the framework addresses challenges in dataset creation and preprocessing efficiently."}}
{"id": "2507.13375", "pdf": "https://arxiv.org/pdf/2507.13375", "abs": "https://arxiv.org/abs/2507.13375", "authors": ["Chunyuan Zhao", "Zizheng Guo", "Zuodong Zhang", "Yibo Lin"], "title": "GAP-LA: GPU-Accelerated Performance-Driven Layer Assignment", "categories": ["cs.AR"], "comment": null, "summary": "Layer assignment is critical for global routing of VLSI circuits. It converts\n2D routing paths into 3D routing solutions by determining the proper metal\nlayer for each routing segments to minimize congestion and via count. As\ndifferent layers have different unit resistance and capacitance, layer\nassignment also has significant impacts to timing and power. With growing\ndesign complexity, it becomes increasingly challenging to simultaneously\noptimize timing, power, and congestion efficiently. Existing studies are mostly\nlimited to a subset of objectives. In this paper, we propose a GPU-accelerated\nperformance-driven layer assignment framework, GAP-LA, for holistic\noptimization the aforementioned objectives. Experimental results demonstrate\nthat we can achieve 0.3%-9.9% better worst negative slack (WNS) and 2.0%-5.4%\nbetter total negative slack (TNS) while maintaining power and congestion with\ncompetitive runtime compared with ISPD 2025 contest winners, especially on\ndesigns with up to 12 millions of nets.", "AI": {"tldr": "This paper proposes GAP-LA, a GPU-accelerated framework for VLSI layer assignment to optimize timing, power, and congestion efficiently.", "motivation": "Current layer assignment approaches struggle to optimize timing, power, and congestion simultaneously, especially with the increasing complexity of VLSI designs.", "method": "The paper introduces GAP-LA, a GPU-accelerated framework that holistically optimizes performance-related metrics for layer assignment in global routing.", "result": "GAP-LA achieves 0.3%-9.9% better WNS, 2.0%-5.4% better TNS, and competitive runtime compared to state-of-the-art methods, even on large designs with up to 12 million nets.", "conclusion": "GAP-LA offers an effective and efficient solution for holistic optimization in VLSI layer assignment, balancing performance metrics and runtime."}}
{"id": "2507.13631", "pdf": "https://arxiv.org/pdf/2507.13631", "abs": "https://arxiv.org/abs/2507.13631", "authors": ["Fuyuki Kihara", "Seiji Uenohara", "Satoshi Awamura", "Naoko Misawa", "Chihiro Matsui", "Ken Takeuchi"], "title": "4T2R X-ReRAM CiM Array for Variation-tolerant, Low-power, Massively Parallel MAC Operation", "categories": ["cs.AR"], "comment": "4 pages", "summary": "Computation-in-Memory (CiM) is attracting attention as a technology that can\nperform MAC calculations required for AI accelerators, at high speed with low\npower consumption. However, there is a problem regarding power consumption and\ndevice-derived errors that increase as row parallelism increases. In this\npaper, a 4T2R ReRAM cell and an 8T SRAM CiM suitable for CiM is proposed. It is\nshown that adopting the proposed 4T2R ReRAM cell reduces the errors due to\nvariation in ReRAM devices compared to conventional 4T4R ReRAM cells.", "AI": {"tldr": "This paper proposes a new 4T2R ReRAM cell and 8T SRAM CiM design to reduce errors and improve power efficiency in high-row parallelism Computation-in-Memory systems.", "motivation": "There is a pressing need to address power consumption and device-derived errors in AI accelerators, particularly as row parallelism increases in Computation-in-Memory systems.", "method": "The authors design and propose a novel 4T2R ReRAM cell and an 8T SRAM CiM architecture, demonstrating reduced variability-induced errors compared to conventional 4T4R ReRAM cells.", "result": "The proposed 4T2R ReRAM cell successfully mitigates device variation errors, validating its superiority over traditional designs.", "conclusion": "Adopting the 4T2R ReRAM cell enhances accuracy and power efficiency, presenting a practical advancement in CiM technology."}}
{"id": "2507.14000", "pdf": "https://arxiv.org/pdf/2507.14000", "abs": "https://arxiv.org/abs/2507.14000", "authors": ["Jing Ding", "Trung Diep"], "title": "Photonic Fabric Platform for AI Accelerators", "categories": ["cs.PF", "cs.AI", "C.4"], "comment": "12 pages, 14 figures, 5 tables", "summary": "This paper presents the Photonic FabricTM and the Photonic Fabric ApplianceTM\n(PFA), a photonic-enabled switch and memory subsystem that delivers low\nlatency, high bandwidth, and low per-bit energy. By integrating high-bandwidth\nHBM3E memory, an on-module photonic switch, and external DDR5 in a 2.5D\nelectro-optical system-in-package, the PFA offers up to 32 TB of shared memory\nalongside 115 Tbps of all-to-all digital switching. The Photonic FabricTM\nenables distributed AI training and inference to execute parallelism strategies\nmore efficiently. The Photonic Fabric removes the silicon beachfront constraint\nthat limits the fixed memory-to-compute ratio observed in virtually all current\nXPU accelerator designs. Replacing a local HBM stack on an XPU with a chiplet\nthat connects to the Photonic Fabric increases its memory capacity and\ncorrespondingly its memory bandwidth by offering a flexible path to scaling\nwell beyond the limitations of on-package HBM alone. We introduce CelestiSim, a\nlightweight analytical simulator validated on NVIDIA H100 and H200 systems. It\nis used to evaluate the performance of LLM reference and energy savings on PFA,\nwithout any significant change to the GPU core design. With the PFA, the\nsimulation results show that up to 3.66x throughput and 1.40x latency\nimprovements in LLM inference at 405B parameters, up to 7.04x throughput and\n1.41x latency improvements at 1T parameters, and 60-90% energy savings in data\nmovement for heavy collective operations in all LLM training scenarios. While\nthese results are shown for NVIDIA GPUs, they can be applied similarly to other\nAI accelerator designs (XPUs) that share the same fundamental limitation of\nfixed memory to compute.", "AI": {"tldr": "This paper introduces the Photonic FabricTM and Photonic Fabric ApplianceTM, a solution addressing memory and compute ratio constraints in modern accelerators through photonic technology.", "motivation": "Current AI accelerators face limitations due to fixed memory-to-compute ratios, hindering scalability and efficiency in distributed AI training and inference.", "method": "The paper integrates HBM3E memory, photonic switches, and external DDR5 into a 2.5D electro-optical package. It uses the CelestiSim simulator to evaluate NVIDIA GPU performance with these innovations.", "result": "The proposed system achieves up to 7.04x throughput, 1.41x latency improvements, and 60-90% energy savings during large language model (LLM) training and inference simulations.", "conclusion": "The Photonic FabricTM successfully enhances scalability, bandwidth, and efficiency in AI processing, addressing silicon constraints and benefiting various accelerators."}}
{"id": "2507.13511", "pdf": "https://arxiv.org/pdf/2507.13511", "abs": "https://arxiv.org/abs/2507.13511", "authors": ["Nabil Abdelaziz Ferhat Taleb", "Abdolazim Rezaei", "Raj Atulkumar Patel", "Mehdi Sookhak"], "title": "GraphTrafficGPT: Enhancing Traffic Management Through Graph-Based AI Agent Coordination", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) offer significant promise for intelligent\ntraffic management; however, current chain-based systems like TrafficGPT are\nhindered by sequential task execution, high token usage, and poor scalability,\nmaking them inefficient for complex, real-world scenarios. To address these\nlimitations, we propose GraphTrafficGPT, a novel graph-based architecture,\nwhich fundamentally redesigns the task coordination process for LLM-driven\ntraffic applications. GraphTrafficGPT represents tasks and their dependencies\nas nodes and edges in a directed graph, enabling efficient parallel execution\nand dynamic resource allocation. The main idea behind the proposed model is a\nBrain Agent that decomposes user queries, constructs optimized dependency\ngraphs, and coordinates a network of specialized agents for data retrieval,\nanalysis, visualization, and simulation. By introducing advanced context-aware\ntoken management and supporting concurrent multi-query processing, the proposed\narchitecture handles interdependent tasks typical of modern urban mobility\nenvironments. Experimental results demonstrate that GraphTrafficGPT reduces\ntoken consumption by 50.2% and average response latency by 19.0% compared to\nTrafficGPT, while supporting simultaneous multi-query execution with up to\n23.0% improvement in efficiency.", "AI": {"tldr": "GraphTrafficGPT is a novel graph-based approach for LLM-driven traffic management that reduces inefficiencies seen in current systems like TrafficGPT.", "motivation": "Address the inefficiencies (sequential task execution, high token usage, scalability issues) in LLM-driven traffic management systems like TrafficGPT.", "method": "The paper introduces GraphTrafficGPT, using a graph-based architecture where tasks and dependencies are represented as nodes and edges, enabling parallel execution and token optimization. A Brain Agent orchestrates task decomposition, dependency graph creation, and agent coordination.", "result": "GraphTrafficGPT reduces token use by 50.2%, response time by 19.0%, and improves multi-query efficiency by up to 23.0% compared to TrafficGPT.", "conclusion": "GraphTrafficGPT offers a scalable and efficient solution for LLM-based traffic management, making it better suited for real-world complexities compared to current architectures."}}
{"id": "2507.13522", "pdf": "https://arxiv.org/pdf/2507.13522", "abs": "https://arxiv.org/abs/2507.13522", "authors": ["Ankit Bhardwaj", "Weiyang Wang", "Jeremy Carin", "Adam Belay", "Manya Ghobadi"], "title": "Checkmate: Zero-Overhead Model Checkpointing via Network Gradient Replication", "categories": ["cs.DC"], "comment": "18 pages, 11 figures", "summary": "This paper presents Checkmate, a system that enables per-iteration\ncheckpointing in DNN training without any training slowdown. The traditional\napproach to checkpointing requires a pause in training to copy model states to\na separate location, allowing the state to be restored in the event of failure.\nThis approach fundamentally has a tradeoff between the frequency of checkpoints\nand the cost of a failure. We avoid this tradeoff; our key insight is that in\ndata-parallel training, all information necessary to create a checkpoint\nalready exists in the network as gradients. Our core contribution is a new\nmulticast abstraction that simultaneously delivers gradients to a separate\nCPU-based shadow cluster. The shadow maintains a checkpoint by applying those\ngradients to a copy of the model. Our evaluation shows that Checkmate performs\nper-iteration checkpointing with training throughput comparable to an ideal\nno-checkpoint baseline. Checkmate achieves 5 to 34.5x more frequent\ncheckpointing compared to state-of-the-art checkpointing systems, resulting in\n80% to 97.1% reduction in repeated work per failure. At the same checkpointing\nfrequency, Checkmate delivers 1.3x to 6.5x throughput compared to other\nsystems.", "AI": {"tldr": "Checkmate is a system for per-iteration checkpointing in DNN training that eliminates training slowdowns by leveraging gradients from data-parallel training to maintain checkpoints in a shadow cluster.", "motivation": "To address the inefficiencies and tradeoffs in traditional DNN training checkpointing, which pauses training and balances between checkpointing frequency and recovery cost.", "method": "Introduces a multicast abstraction to simultaneously deliver gradients to a shadow cluster, which applies them to a model copy to maintain checkpoints without halting training.", "result": "Achieves 5 to 34.5x more frequent checkpointing, reducing repeated work by 80% to 97.1% per failure, and boosts training throughput by 1.3x to 6.5x compared to other systems.", "conclusion": "Checkmate offers a significant improvement in DNN training checkpointing, enabling more frequent and efficient recovery mechanisms without compromising training throughput."}}
{"id": "2507.13494", "pdf": "https://arxiv.org/pdf/2507.13494", "abs": "https://arxiv.org/abs/2507.13494", "authors": ["Feras A. Saad", "Wonyeol Lee"], "title": "Random Variate Generation with Formal Guarantees", "categories": ["cs.PL", "stat.CO"], "comment": null, "summary": "This article introduces a new approach to principled and practical random\nvariate generation with formal guarantees. The key idea is to first specify the\ndesired probability distribution in terms of a finite-precision numerical\nprogram that defines its cumulative distribution function (CDF), and then\ngenerate exact random variates according to this CDF. We present a universal\nand fully automated method to synthesize exact random variate generators given\nany numerical CDF implemented in any binary number format, such as\nfloating-point, fixed-point, and posits. The method is guaranteed to operate\nwith the same precision used to specify the CDF, does not overflow, avoids\nexpensive arbitrary-precision arithmetic, and exposes a consistent API. The\nmethod rests on a novel space-time optimal implementation for the class of\ngenerators that attain the information-theoretically optimal Knuth and Yao\nentropy rate, consuming the least possible number of input random bits per\noutput variate. We develop a random variate generation library using our method\nin C and evaluate it on a diverse set of ``continuous'' and ``discrete''\ndistributions, showing competitive runtime with the state-of-the-art GNU\nScientific Library while delivering higher accuracy, entropy efficiency, and\nautomation.", "AI": {"tldr": "The paper introduces a method to generate exact random variates based on numerical CDFs with strong formal guarantees and optimal efficiency.", "motivation": "Current random variate generation methods often lack precision, overflow problems, dependency on arbitrary-precision arithmetic, or inconsistent APIs. There is a need for a universal method that guarantees accuracy and operational efficiency.", "method": "The proposed method uses finite-precision numerical programs to specify CDFs and synthesizes random variate generators. It employs a novel implementation that achieves the optimal Knuth and Yao entropy rate while maintaining precision and avoiding overflows.", "result": "The introduced approach demonstrates competitive runtime, higher accuracy, and better entropy efficiency compared to the GNU Scientific Library. It supports various number formats and distributions.", "conclusion": "The paper establishes a universal and automated method for random variate generation with formal guarantees, optimal entropy efficiency, and high practical utility, addressing precision and operational constraints."}}
{"id": "2507.13485", "pdf": "https://arxiv.org/pdf/2507.13485", "abs": "https://arxiv.org/abs/2507.13485", "authors": ["Imane Hamzaoui", "Riyadh Baghdadi"], "title": "Neural Architecture Search with Mixed Bio-inspired Learning Rules", "categories": ["cs.NE", "cs.AI", "cs.CV", "cs.LG"], "comment": "ECAI 2025", "summary": "Bio-inspired neural networks are attractive for their adversarial robustness,\nenergy frugality, and closer alignment with cortical physiology, yet they often\nlag behind back-propagation (BP) based models in accuracy and ability to scale.\nWe show that allowing the use of different bio-inspired learning rules in\ndifferent layers, discovered automatically by a tailored\nneural-architecture-search (NAS) procedure, bridges this gap. Starting from\nstandard NAS baselines, we enlarge the search space to include bio-inspired\nlearning rules and use NAS to find the best architecture and learning rule to\nuse in each layer. We show that neural networks that use different bio-inspired\nlearning rules for different layers have better accuracy than those that use a\nsingle rule across all the layers. The resulting NN that uses a mix of\nbio-inspired learning rules sets new records for bio-inspired models: 95.16% on\nCIFAR-10, 76.48% on CIFAR-100, 43.42% on ImageNet16-120, and 60.51% top-1 on\nImageNet. In some regimes, they even surpass comparable BP-based networks while\nretaining their robustness advantages. Our results suggest that layer-wise\ndiversity in learning rules allows better scalability and accuracy, and\nmotivates further research on mixing multiple bio-inspired learning rules in\nthe same network.", "AI": {"tldr": "The paper proposes that neural networks using layer-specific bio-inspired learning rules, discovered via neural-architecture search (NAS), achieve better accuracy and scalability while maintaining robustness advantages.", "motivation": "Bio-inspired neural networks offer benefits like robustness and energy efficiency, but their performance and scalability often lag compared to back-propagation (BP)-based models.", "method": "A tailored neural-architecture search (NAS) is used to identify optimal bio-inspired learning rules for different layers. The search space is expanded to accommodate these rules, and the best architecture is determined layer by layer.", "result": "Neural networks using mixed bio-inspired learning rules set new performance records across datasets such as CIFAR-10 (95.16%), CIFAR-100 (76.48%), ImageNet16-120 (43.42%), and ImageNet (60.51% top-1). Some even outperform BP-based models.", "conclusion": "Layer-specific diversity in bio-inspired learning rules enhances neural network performance and scalability, motivating further exploration of mixed learning rule approaches."}}
{"id": "2507.13638", "pdf": "https://arxiv.org/pdf/2507.13638", "abs": "https://arxiv.org/abs/2507.13638", "authors": ["Sen Lu", "Xiaoyu Zhang", "Mingtao Hu", "Eric Yeu-Jer Lee", "Soohyeon Kim", "Wei D. Lu"], "title": "State Space Models Naturally Produce Traveling Waves, Time Cells, and Scale to Abstract Cognitive Functions", "categories": ["q-bio.NC", "cs.LG"], "comment": "Sen Lu and Xiaoyu Zhang contributed equally. Wei D. Lu is the\n  corresponding author. 4 figures are included in 15 pages", "summary": "A grand challenge in modern neuroscience is to bridge the gap between the\ndetailed mapping of microscale neural circuits and a mechanistic understanding\nof cognitive functions. While extensive knowledge exists about neuronal\nconnectivity and biophysics, a significant gap remains in how these elements\ncombine to produce flexible, learned behaviors. Here, we propose that a\nframework based on State-Space Models (SSMs), an emerging class of deep\nlearning architectures, can bridge this gap. We argue that the differential\nequations governing elements in an SSM are conceptually consistent with the\nbiophysical dynamics of neurons, while the combined dynamics in the model lead\nto emergent behaviors observed in experimental neuroscience. We test this\nframework by training an S5 model--a specific SSM variant employing a diagonal\nstate transition matrix--on temporal discrimination tasks with reinforcement\nlearning (RL). We demonstrate that the model spontaneously develops neural\nrepresentations that strikingly mimic biological 'time cells'. We reveal that\nthese cells emerge from a simple generative principle: learned rotational\ndynamics of hidden state vectors in the complex plane. This single mechanism\nunifies the emergence of time cells, ramping activity, and\noscillations/traveling waves observed in numerous experiments. Furthermore, we\nshow that this rotational dynamics generalizes beyond interval discriminative\ntasks to abstract event-counting tasks that were considered foundational for\nperforming complex cognitive tasks. Our findings position SSMs as a compelling\nframework that connects single-neuron dynamics to cognitive phenomena, offering\na unifying and computationally tractable theoretical ground for temporal\nlearning in the brain.", "AI": {"tldr": "This paper introduces State-Space Models (SSMs) as a framework to bridge microscale neural circuits with cognitive functions, demonstrating their potential in tasks requiring temporal learning.", "motivation": "To address the gap between neuronal connectivity/biophysics and their role in producing flexible, learned cognitive behaviors.", "method": "Using the S5 model variant of SSMs trained on temporal discrimination tasks with reinforcement learning to analyze emergent neural behaviors.", "result": "The neural representations developed in the model mimic biological 'time cells' and reproduce phenomena like ramping activity, oscillations/traveling waves, and event counting.", "conclusion": "SSMs provide a computationally tractable and unifying framework linking neuron dynamics with cognitive phenomena, enabling better understanding of temporal learning mechanisms in the brain."}}
{"id": "2507.13481", "pdf": "https://arxiv.org/pdf/2507.13481", "abs": "https://arxiv.org/abs/2507.13481", "authors": ["Arthur Bueno", "Bruno Cafeo", "Maria Cagnin", "Awdren Font\u00e3o"], "title": "Socio-Technical Smell Dynamics in Code Samples: A Multivocal Review on Emergence, Evolution, and Co-Occurrence", "categories": ["cs.SE", "cs.CY"], "comment": "12 pages; 2 figures; Preprint with the original submission accepted\n  for publication at 39th Brazilian Symposium on Software Engineering (SBES)", "summary": "Code samples play a pivotal role in open-source ecosystems (OSSECO), serving\nas lightweight artifacts that support knowledge transfer, onboarding, and\nframework adoption. Despite their instructional relevance, these samples are\noften governed informally, with minimal review and unclear ownership, which\nincreases their exposure to socio-technical degradation. In this context, the\nco-occurrence and longitudinal interplay of code smells (e.g., large classes,\npoor modularity) and community smells (e.g., lone contributors, fragmented\ncommunication) become particularly critical. While each type of smell has been\nstudied in isolation, little is known about how community-level dysfunctions\nanticipate or exacerbate technical anomalies in code samples over time. This\nstudy investigates how code and community smells emerge, co-occur, and evolve\nwithin code samples maintained in OSSECOs. A Multivocal Literature Review\nprotocol was applied, encompassing 30 peer-reviewed papers and 17\npractitioner-oriented sources (2013-2024). Thematic synthesis was conducted to\nidentify recurring socio-technical patterns related to smell dynamics. Nine\npatterns were identified, showing that community smells often precede or\nreinforce technical degradation in code samples. Symptoms such as \"radio\nsilence\" and centralized ownership were frequently associated with persistent\nstructural anomalies. Additionally, limited onboarding, the absence of\ncontinuous refactoring, and informal collaboration emerged as recurring\nconditions for smell accumulation. Conclusion: In OSSECOs, particularly within\ncode samples, community-level dysfunctions not only correlate with but often\nsignal maintainability decay. These findings underscore the need for\nsocio-technical quality indicators and lightweight governance mechanisms\ntailored to shared instructional artifacts.", "AI": {"tldr": "Code samples in open-source ecosystems often face socio-technical degradation due to informal governance and lack of review, with community dysfunctions preceding technical anomalies.", "motivation": "The paper aims to address the underexplored interplay between community and code smells in open-source code samples, which affects maintainability and usability.", "method": "A Multivocal Literature Review protocol was used, analyzing 30 peer-reviewed and 17 practitioner-oriented sources to synthesize socio-technical patterns.", "result": "Nine socio-technical patterns were identified, showing that community smells like 'radio silence' and centralized ownership often lead to technical issues over time.", "conclusion": "Community dysfunctions in OSSECO code samples often signal more profound technical decay, emphasizing the need for better governance and socio-technical quality indicators."}}
{"id": "2507.13455", "pdf": "https://arxiv.org/pdf/2507.13455", "abs": "https://arxiv.org/abs/2507.13455", "authors": ["Dean Chen", "Armin Pomeroy", "Brandon T. Peterson", "Will Flanagan", "He Kai Lim", "Alexandra Stavrakis", "Nelson F. SooHoo", "Jonathan B. Hopkins", "Tyler R. Clites"], "title": "Hard-Stop Synthesis for Multi-DOF Compliant Mechanisms", "categories": ["cs.RO"], "comment": "42 pages, 17 figures. Under review at ASME Journal of Mechanical\n  Design", "summary": "Compliant mechanisms have significant potential in precision applications due\nto their ability to guide motion without contact. However, an inherent\nvulnerability to fatigue and mechanical failure has hindered the translation of\ncompliant mechanisms to real-world applications. This is particularly\nchallenging in service environments where loading is complex and uncertain, and\nthe cost of failure is high. In such cases, mechanical hard stops are critical\nto prevent yielding and buckling. Conventional hard-stop designs, which rely on\nstacking single-DOF limits, must be overly restrictive in multi-DOF space to\nguarantee safety in the presence of unknown loads. In this study, we present a\nsystematic design synthesis method to guarantee overload protection in\ncompliant mechanisms by integrating coupled multi-DOF motion limits within a\nsingle pair of compact hard-stop surfaces. Specifically, we introduce a\ntheoretical and practical framework for optimizing the contact surface geometry\nto maximize the mechanisms multi-DOF working space while still ensuring that\nthe mechanism remains within its elastic regime. We apply this synthesis method\nto a case study of a caged-hinge mechanism for orthopaedic implants, and\nprovide numerical and experimental validation that the derived design offers\nreliable protection against fatigue, yielding, and buckling. This work\nestablishes a foundation for precision hard-stop design in compliant systems\noperating under uncertain loads, which is a crucial step toward enabling the\napplication of compliant mechanisms in real-world systems.", "AI": {"tldr": "The paper addresses the issue of mechanical failure in compliant mechanisms and proposes a hard-stop design optimizing motion limits to improve safety and performance.", "motivation": "Compliant mechanisms are limited by their susceptibility to fatigue and failure in uncertain service environments, and current hard-stop designs are too restrictive in multi-DOF spaces.", "method": "The study introduces a framework for designing compact coupled multi-DOF hard stops, optimizing contact surface geometry to enhance working space and stay within the elastic regime.", "result": "The method was applied to a caged-hinge mechanism for orthopedic implants, with numerical and experimental validation confirming the improved protection against fatigue, yielding, and buckling.", "conclusion": "The findings establish a foundation for designing precision hard stops in compliant systems, enabling their use in real-world applications under uncertain load conditions."}}
{"id": "2507.13357", "pdf": "https://arxiv.org/pdf/2507.13357", "abs": "https://arxiv.org/abs/2507.13357", "authors": ["Atharva Bhargude", "Ishan Gonehal", "Chandler Haney", "Dave Yoon", "Kevin Zhu", "Aaron Sandoval", "Sean O'Brien", "Kaustubh Vinnakota"], "title": "Adaptive Linguistic Prompting (ALP) Enhances Phishing Webpage Detection in Multimodal Large Language Models", "categories": ["cs.CL"], "comment": "Published at ACL 2025 SRW, 9 pages, 3 figures", "summary": "Phishing attacks represent a significant cybersecurity threat, necessitating\nadaptive detection techniques. This study explores few-shot Adaptive Linguistic\nPrompting (ALP) in detecting phishing webpages through the multimodal\ncapabilities of state-of-the-art large language models (LLMs) such as GPT-4o\nand Gemini 1.5 Pro. ALP is a structured semantic reasoning method that guides\nLLMs to analyze textual deception by breaking down linguistic patterns,\ndetecting urgency cues, and identifying manipulative diction commonly found in\nphishing content. By integrating textual, visual, and URL-based analysis, we\npropose a unified model capable of identifying sophisticated phishing attempts.\nOur experiments demonstrate that ALP significantly enhances phishing detection\naccuracy by guiding LLMs through structured reasoning and contextual analysis.\nThe findings highlight the potential of ALP-integrated multimodal LLMs to\nadvance phishing detection frameworks, achieving an F1-score of 0.93,\nsurpassing traditional approaches. These results establish a foundation for\nmore robust, interpretable, and adaptive linguistic-based phishing detection\nsystems using LLMs.", "AI": {"tldr": "The paper presents a novel method called Adaptive Linguistic Prompting (ALP) that utilizes large language models, like GPT-4o and Gemini 1.5 Pro, to improve phishing detection through multimodal analysis, achieving an F1-score of 0.93.", "motivation": "Phishing remains a critical threat to cybersecurity, necessitating advanced adaptive detection mechanisms that can tackle sophisticated deception methods.", "method": "The study employs few-shot ALP, a structured semantic reasoning method, alongside multimodal capabilities of LLMs (textual, visual, and URL analysis), to enhance phishing detection.", "result": "ALP improved phishing detection with significant accuracy, achieving an F1-score of 0.93, outperforming traditional methods.", "conclusion": "Integrated multimodal LLMs with ALP show promise for creating adaptive, interpretable, and robust phishing detection systems with enhanced accuracy."}}
{"id": "2507.13639", "pdf": "https://arxiv.org/pdf/2507.13639", "abs": "https://arxiv.org/abs/2507.13639", "authors": ["Nikola Pavlovic", "Sudeep Salgia", "Qing Zhao"], "title": "Differential Privacy in Kernelized Contextual Bandits via Random Projections", "categories": ["stat.ML", "cs.CR", "cs.LG"], "comment": null, "summary": "We consider the problem of contextual kernel bandits with stochastic\ncontexts, where the underlying reward function belongs to a known Reproducing\nKernel Hilbert Space. We study this problem under an additional constraint of\nDifferential Privacy, where the agent needs to ensure that the sequence of\nquery points is differentially private with respect to both the sequence of\ncontexts and rewards. We propose a novel algorithm that achieves the\nstate-of-the-art cumulative regret of\n$\\widetilde{\\mathcal{O}}(\\sqrt{\\gamma_TT}+\\frac{\\gamma_T}{\\varepsilon_{\\mathrm{DP}}})$\nand\n$\\widetilde{\\mathcal{O}}(\\sqrt{\\gamma_TT}+\\frac{\\gamma_T\\sqrt{T}}{\\varepsilon_{\\mathrm{DP}}})$\nover a time horizon of $T$ in the joint and local models of differential\nprivacy, respectively, where $\\gamma_T$ is the effective dimension of the\nkernel and $\\varepsilon_{\\mathrm{DP}} > 0$ is the privacy parameter. The key\ningredient of the proposed algorithm is a novel private kernel-ridge regression\nestimator which is based on a combination of private covariance estimation and\nprivate random projections. It offers a significantly reduced sensitivity\ncompared to its classical counterpart while maintaining a high prediction\naccuracy, allowing our algorithm to achieve the state-of-the-art performance\nguarantees.", "AI": {"tldr": "The paper introduces a differentially private algorithm for contextual kernel bandits with stochastic contexts, achieving state-of-the-art cumulative regret bounds.", "motivation": "The paper seeks to address the challenge of ensuring differential privacy in contextual kernel bandits while preserving performance in terms of cumulative regret.", "method": "A novel algorithm is developed using a private kernel-ridge regression estimator. This combines private covariance estimation and private random projections to reduce sensitivity while maintaining high prediction accuracy.", "result": "The algorithm achieves cumulative regret of approximately $\\widetilde{\\mathcal{O}}(\\sqrt{\\gamma_T T} + \\frac{\\gamma_T}{\\varepsilon_{\\mathrm{DP}}})$ and $\\widetilde{\\mathcal{O}}(\\sqrt{\\gamma_T T} + \\frac{\\gamma_T \\sqrt{T}}{\\varepsilon_{\\mathrm{DP}}})$ in joint and local privacy models, respectively.", "conclusion": "The proposed approach offers theoretical guarantees for achieving differential privacy in contextual kernel bandits without compromising on performance."}}
{"id": "2507.13359", "pdf": "https://arxiv.org/pdf/2507.13359", "abs": "https://arxiv.org/abs/2507.13359", "authors": ["Yang Zhou", "Junjie Li", "CongYang Ou", "Dawei Yan", "Haokui Zhang", "Xizhe Xue"], "title": "Open-Vocabulary Object Detection in UAV Imagery: A Review and Future Perspectives", "categories": ["cs.CV"], "comment": "27 pages, 5 figures", "summary": "Due to its extensive applications, aerial image object detection has long\nbeen a hot topic in computer vision. In recent years, advancements in Unmanned\nAerial Vehicles (UAV) technology have further propelled this field to new\nheights, giving rise to a broader range of application requirements. However,\ntraditional UAV aerial object detection methods primarily focus on detecting\npredefined categories, which significantly limits their applicability. The\nadvent of cross-modal text-image alignment (e.g., CLIP) has overcome this\nlimitation, enabling open-vocabulary object detection (OVOD), which can\nidentify previously unseen objects through natural language descriptions. This\nbreakthrough significantly enhances the intelligence and autonomy of UAVs in\naerial scene understanding. This paper presents a comprehensive survey of OVOD\nin the context of UAV aerial scenes. We begin by aligning the core principles\nof OVOD with the unique characteristics of UAV vision, setting the stage for a\nspecialized discussion. Building on this foundation, we construct a systematic\ntaxonomy that categorizes existing OVOD methods for aerial imagery and provides\na comprehensive overview of the relevant datasets. This structured review\nenables us to critically dissect the key challenges and open problems at the\nintersection of these fields. Finally, based on this analysis, we outline\npromising future research directions and application prospects. This survey\naims to provide a clear road map and a valuable reference for both newcomers\nand seasoned researchers, fostering innovation in this rapidly evolving domain.\nWe keep tracing related works at\nhttps://github.com/zhouyang2002/OVOD-in-UVA-imagery", "AI": {"tldr": "This paper surveys open-vocabulary object detection (OVOD) methods applied to UAV aerial scenes powered by cross-modal text-image alignment advancements like CLIP. It categorizes existing methodologies, datasets, challenges, and open problems while presenting future directions.", "motivation": "Traditional UAV aerial object detection methods are limited to predefined categories, hindering their usability in diverse real-world scenarios. Recent progress in technologies like CLIP has facilitated OVOD, enabling UAVs to detect unseen objects via textual descriptions, thereby enhancing their utility.", "method": "The paper systematically reviews OVOD techniques and datasets, creates a taxonomy for categorization, discusses UAV-specific challenges, and identifies open problems. It integrates principles of OVOD with UAV vision characteristics, and outlines future research paths.", "result": "The survey provides a structured overview of existing OVOD methods in aerial imagery and highlights the limitations and opportunities. It establishes a taxonomy and extensively examines datasets and challenges relevant to UAV applications in OVOD.", "conclusion": "The paper emphasizes the significance of OVOD in advancing UAV intelligence and autonomy while offering a valuable reference for researchers through a systematic survey. It proposes solutions for future progress and advocates innovation in the field."}}
{"id": "2507.13354", "pdf": "https://arxiv.org/pdf/2507.13354", "abs": "https://arxiv.org/abs/2507.13354", "authors": ["Zeqian Chen"], "title": "Physical models realizing the transformer architecture of large language models", "categories": ["cs.LG", "cs.AI", "cs.CL", "math-ph", "math.MP"], "comment": "6 pages", "summary": "The introduction of the transformer architecture in 2017 (cf.\\cite{VSP2017})\nmarked the most striking advancement in natural language processing. The\ntransformer is a model architecture relying entirely on an attention mechanism\nto draw global dependencies between input and output. However, we believe there\nis a gap in our theoretical understanding of what the transformer is, and why\nit works physically. In this paper, from a physical perspective on modern\nchips, we construct physical models in the Fock space over the Hilbert space of\ntokens realizing large language models based on a transformer architecture as\nopen quantum systems. Our physical models underlie the transformer architecture\nfor large language models.", "AI": {"tldr": "The paper proposes a physical model to better understand the transformer architecture used in large language models.", "motivation": "To address the gap in understanding the physical principles behind the success of transformer models in NLP.", "method": "The paper constructs physical models employing concepts from quantum mechanics, specifically using Fock and Hilbert spaces, to interpret transformers as open quantum systems.", "result": "The proposed physical models provide insight into the underlying principles of transformers in large language models.", "conclusion": "The study bridges theoretical gaps in the understanding of transformers by grounding them in physical quantum systems."}}
{"id": "2507.13736", "pdf": "https://arxiv.org/pdf/2507.13736", "abs": "https://arxiv.org/abs/2507.13736", "authors": ["Matthias Jobst", "Tim Langer", "Chen Liu", "Mehmet Alici", "Hector A. Gonzalez", "Christian Mayr"], "title": "An End-to-End DNN Inference Framework for the SpiNNaker2 Neuromorphic MPSoC", "categories": ["cs.LG", "cs.AR", "cs.DC"], "comment": "Poster at ACM ICONS 2025 - International Conference on Neuromorphic\n  Systems", "summary": "This work presents a multi-layer DNN scheduling framework as an extension of\nOctopuScheduler, providing an end-to-end flow from PyTorch models to inference\non a single SpiNNaker2 chip. Together with a front-end comprised of\nquantization and lowering steps, the proposed framework enables the edge-based\nexecution of large and complex DNNs up to transformer scale using the\nneuromorphic platform SpiNNaker2.", "AI": {"tldr": "The paper introduces a scheduling framework for implementing DNN models from PyTorch on SpiNNaker2 chips using quantization and lowering techniques.", "motivation": "To facilitate edge-based execution of complex and large DNNs on the neuromorphic hardware SpiNNaker2, which traditionally struggles with accommodating transformer-scale models.", "method": "The authors extend OctopuScheduler to include a multi-layer DNN scheduling framework, complemented by quantization and lowering steps for model adaptation.", "result": "The framework allows efficient deployment of complex DNNs, such as transformer-scale models, on the SpiNNaker2 platform for edge computing.", "conclusion": "The proposed approach successfully bridges the gap between PyTorch DNN modeling and SpiNNaker2 chip execution, enabling edge inference for large-scale models."}}
{"id": "2507.13541", "pdf": "https://arxiv.org/pdf/2507.13541", "abs": "https://arxiv.org/abs/2507.13541", "authors": ["Shuyue Stella Li", "Melanie Sclar", "Hunter Lang", "Ansong Ni", "Jacqueline He", "Puxin Xu", "Andrew Cohen", "Chan Young Park", "Yulia Tsvetkov", "Asli Celikyilmaz"], "title": "PrefPalette: Personalized Preference Modeling with Latent Attributes", "categories": ["cs.AI"], "comment": "17 pages, 6 tables, 5 figures", "summary": "Personalizing AI systems requires understanding not just what users prefer,\nbut the reasons that underlie those preferences - yet current preference models\ntypically treat human judgment as a black box. We introduce PrefPalette, a\nframework that decomposes preferences into attribute dimensions and tailors its\npreference prediction to distinct social community values in a\nhuman-interpretable manner. PrefPalette operationalizes a cognitive science\nprinciple known as multi-attribute decision making in two ways: (1) a scalable\ncounterfactual attribute synthesis step that involves generating synthetic\ntraining data to isolate for individual attribute effects (e.g., formality,\nhumor, cultural values), and (2) attention-based preference modeling that\nlearns how different social communities dynamically weight these attributes.\nThis approach moves beyond aggregate preference modeling to capture the diverse\nevaluation frameworks that drive human judgment. When evaluated on 45 social\ncommunities from the online platform Reddit, PrefPalette outperforms GPT-4o by\n46.6% in average prediction accuracy. Beyond raw predictive improvements,\nPrefPalette also shed light on intuitive, community-specific profiles:\nscholarly communities prioritize verbosity and stimulation, conflict-oriented\ncommunities value sarcasm and directness, and support-based communities\nemphasize empathy. By modeling the attribute-mediated structure of human\njudgment, PrefPalette delivers both superior preference modeling and\ntransparent, interpretable insights, and serves as a first step toward more\ntrustworthy, value-aware personalized applications.", "AI": {"tldr": "PrefPalette introduces a framework to understand user preferences through decomposed attributes and community-specific values, offering better prediction accuracy and interpretability.", "motivation": "Current AI systems fail to account for the reasons behind user preferences, treating human judgment as a black box.", "method": "Predictions are made using a two-step process: counterfactual attribute synthesis creates synthetic training data to isolate attributes, and attention-based modeling captures community-specific attribute weighting.", "result": "Evaluation on 45 Reddit communities shows PrefPalette exceeds GPT-4o by 46.6% in prediction accuracy, while providing community-specific insights.", "conclusion": "PrefPalette improves preference modeling accuracy and transparency, paving the way for trustworthy and value-aware personalized AI systems."}}
{"id": "2507.13601", "pdf": "https://arxiv.org/pdf/2507.13601", "abs": "https://arxiv.org/abs/2507.13601", "authors": ["Jorge Villarrubia", "Luis Costero", "Francisco D. Igual", "Katzalin Olcoz"], "title": "Leveraging Multi-Instance GPUs through moldable task scheduling", "categories": ["cs.DC", "cs.ET", "cs.PF", "90B36, 90C27, 68M14, 68W40", "C.1.2; C.1.4; C.3.1; D.1.3; G.1.6"], "comment": null, "summary": "NVIDIA MIG (Multi-Instance GPU) allows partitioning a physical GPU into\nmultiple logical instances with fully-isolated resources, which can be\ndynamically reconfigured. This work highlights the untapped potential of MIG\nthrough moldable task scheduling with dynamic reconfigurations. Specifically,\nwe propose a makespan minimization problem for multi-task execution under MIG\nconstraints. Our profiling shows that assuming monotonicity in task work with\nrespect to resources is not viable, as is usual in multicore scheduling.\nRelying on a state-of-the-art proposal that does not require such an\nassumption, we present FAR, a 3-phase algorithm to solve the problem. Phase 1\nof FAR builds on a classical task moldability method, phase 2 combines Longest\nProcessing Time First and List Scheduling with a novel repartitioning tree\nheuristic tailored to MIG constraints, and phase 3 employs local search via\ntask moves and swaps. FAR schedules tasks in batches offline, concatenating\ntheir schedules on the fly in an improved way that favors resource reuse.\nExcluding reconfiguration costs, the List Scheduling proof shows an\napproximation factor of 7/4 on the NVIDIA A30 model. We adapt the technique to\nthe particular constraints of an NVIDIA A100/H100 to obtain an approximation\nfactor of 2. Including the reconfiguration cost, our real-world experiments\nreveal a makespan with respect to the optimum no worse than 1.22x for a\nwell-known suite of benchmarks, and 1.10x for synthetic inputs inspired by real\nkernels. We obtain good experimental results for each batch of tasks, but also\nin the concatenation of batches, with large improvements over the\nstate-of-the-art and proposals without GPU reconfiguration. Beyond the\nalgorithm, the paper demonstrates the research potential of the MIG technology\nand suggests useful metrics, workload characterizations and evaluation\ntechniques for future work in this field.", "AI": {"tldr": "The paper proposes a new task scheduling algorithm (FAR) for Multi-Instance GPU (MIG) technology, achieving substantial performance improvements through dynamic GPU reconfiguration.", "motivation": "This paper aims to exploit the untapped potential of NVIDIA MIG technology for optimizing multi-task execution via dynamic GPU partitioning to minimize makespan under MIG constraints.", "method": "The authors introduce FAR, a 3-phase offline algorithm combining classical task moldability, a novel heuristic for partitioning tasks, and local search mechanisms to optimize task scheduling for MIG technology.", "result": "FAR achieves an approximation factor of 2 on NVIDIA A100/H100 models and shows experimental results outperforming state-of-the-art methods, achieving makespans no worse than 1.22x optimum for benchmarks and 1.10x for synthetic inputs.", "conclusion": "The research highlights the effective utilization of MIG through dynamic reconfigurations, achieving better scheduling results and encouraging further exploration in MIG-related technologies and methodologies."}}
{"id": "2507.13533", "pdf": "https://arxiv.org/pdf/2507.13533", "abs": "https://arxiv.org/abs/2507.13533", "authors": ["Priyam Gupta"], "title": "Increasing the Expressiveness of a Gradual Verifier", "categories": ["cs.PL"], "comment": "Presented at the 52nd ACM SIGPLAN Symposium on Principles of\n  Programming Languages (POPL 2025) Student Research Competition", "summary": "Static verification provides strong correctness guarantees for code; however,\nfully specifying programs for static verification is a complex, burdensome\nprocess for users. Gradual verification was introduced to make this process\neasier by supporting the verification of partially specified programs. The only\ncurrently working gradual verifier, Gradual C0, successfully verifies heap\nmanipulating programs, but lacks expressiveness in its specification language.\nThis paper describes the design and implementation of an extension to Gradual\nC0 that supports unfolding expressions, which allow more intuitive\nspecifications of recursive heap data structures.", "AI": {"tldr": "This paper extends the Gradual C0 verifier with unfolding expressions to improve its ability to handle recursive heap data structures.", "motivation": "Static verification guarantees code correctness but involves substantial effort to fully specify programs. Gradual verification simplifies this process but current tools lack specification expressiveness.", "method": "The authors enhance Gradual C0 by introducing unfolding expressions into the specification language to enable more intuitive treatment of recursive heap data structures.", "result": "The updated Gradual C0 supports intuitive specification for recursive heap structures without losing verification capabilities.", "conclusion": "The extension to Gradual C0 increases the expressiveness of its specification language, simplifying the verification of recursive heap data structures while retaining gradual verification benefits."}}
{"id": "2507.13549", "pdf": "https://arxiv.org/pdf/2507.13549", "abs": "https://arxiv.org/abs/2507.13549", "authors": ["Jim O'Connor", "Nicholas Lorentzen", "Gary B. Parker", "Derin Gezgin"], "title": "Evolving Neural Controllers for Xpilot-AI Racing Using Neuroevolution of Augmenting Topologies", "categories": ["cs.NE"], "comment": "IJCCI Conference on Evolutionary Computation and Theory and\n  Applications, 2025", "summary": "This paper investigates the development of high-performance racing\ncontrollers for a newly implemented racing mode within the Xpilot-AI platform,\nutilizing the Neuro Evolution of Augmenting Topologies (NEAT) algorithm. By\nleveraging NEAT's capability to evolve both the structure and weights of neural\nnetworks, we develop adaptive controllers that can navigate complex circuits\nunder the challenging space simulation physics of Xpilot-AI, which includes\nelements such as inertia, friction, and gravity. The racing mode we introduce\nsupports flexible circuit designs and allows for the evaluation of multiple\nagents in parallel, enabling efficient controller optimization across\ngenerations. Experimental results demonstrate that our evolved controllers\nachieve up to 32% improvement in lap time compared to the controller's initial\nperformance and develop effective racing strategies, such as optimal cornering\nand speed modulation, comparable to human-like techniques. This work\nillustrates NEAT's effectiveness in producing robust control strategies within\ndemanding game environments and highlights Xpilot-AI's potential as a rigorous\ntestbed for competitive AI controller evolution.", "AI": {"tldr": "The paper uses the NEAT algorithm to develop high-performance racing controllers for Xpilot-AI, achieving significant improvements in lap time.", "motivation": "To create adaptive and high-performing racing controllers in a complex space simulation with challenging physics and flexible circuit designs.", "method": "The controllers were optimized using NEAT to evolve both neural network structures and weights, tested under Xpilot-AI's physics and parallel evaluation setups.", "result": "Evolved controllers achieved up to 32% faster lap times and developed human-like racing strategies, such as optimal cornering.", "conclusion": "The NEAT algorithm proves effective for evolving robust control strategies in challenging simulation environments, and Xpilot-AI is validated as a strong AI testbed."}}
{"id": "2507.13941", "pdf": "https://arxiv.org/pdf/2507.13941", "abs": "https://arxiv.org/abs/2507.13941", "authors": ["Pablo Marcos-Manch\u00f3n", "Llu\u00eds Fuentemilla"], "title": "Convergent transformations of visual representation in brains and models", "categories": ["q-bio.NC", "cs.AI", "cs.CV", "eess.IV", "I.2.10"], "comment": "for associate code, see\n  https://github.com/memory-formation/convergent-transformations", "summary": "A fundamental question in cognitive neuroscience is what shapes visual\nperception: the external world's structure or the brain's internal\narchitecture. Although some perceptual variability can be traced to individual\ndifferences, brain responses to naturalistic stimuli evoke similar activity\npatterns across individuals, suggesting a convergent representational\nprinciple. Here, we test if this stimulus-driven convergence follows a common\ntrajectory across people and deep neural networks (DNNs) during its\ntransformation from sensory to high-level internal representations. We\nintroduce a unified framework that traces representational flow by combining\ninter-subject similarity with alignment to model hierarchies. Applying this\nframework to three independent fMRI datasets of visual scene perception, we\nreveal a cortex-wide network, conserved across individuals, organized into two\npathways: a medial-ventral stream for scene structure and a lateral-dorsal\nstream tuned for social and biological content. This functional organization is\ncaptured by the hierarchies of vision DNNs but not language models, reinforcing\nthe specificity of the visual-to-semantic transformation. These findings show a\nconvergent computational solution for visual encoding in both human and\nartificial vision, driven by the structure of the external world.", "AI": {"tldr": "This paper explores how visual perception is shaped by investigating the shared principles governing neural responses to stimuli across humans and deep neural networks (DNNs).", "motivation": "The motivation is to understand whether visual perception is shaped more by external environmental structures or by the brain's internal organization, particularly focusing on the shared principles in representational transformations.", "method": "The study combines inter-subject similarity and alignment with model hierarchies through a unified framework, analyzing three independent fMRI datasets on visual scene perception.", "result": "Researchers identified a cortex-wide network conserved across individuals, divided into two pathways (medial-ventral for scene structure and lateral-dorsal for social/biological content), aligned with the hierarchies of vision DNNs but not language models.", "conclusion": "The paper concludes that both humans and artificial vision systems converge on a computationally similar solution for visual encoding, influenced primarily by the structure of the external world."}}
{"id": "2507.13499", "pdf": "https://arxiv.org/pdf/2507.13499", "abs": "https://arxiv.org/abs/2507.13499", "authors": ["Chandra Maddila", "Negar Ghorbani", "James Saindon", "Parth Thakkar", "Vijayaraghavan Murali", "Rui Abreu", "Jingyue Shen", "Brian Zhou", "Nachiappan Nagappan", "Peter C. Rigby"], "title": "AI-Assisted Fixes to Code Review Comments at Scale", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": null, "summary": "Aim. There are 10s of thousands of code review comments each week at Meta. We\ndeveloped Metamate for Code Review (MetaMateCR) that provides AI-assisted fixes\nfor reviewer comments in production at scale.\n  Method. We developed an internal benchmark of 64k <review comment, patch>\ndata points to fine-tune Llama models. Once our models achieve reasonable\noffline results, we roll them into production. To ensure that our AI-assisted\nfixes do not negatively impact the time it takes to do code reviews, we conduct\nrandomized controlled safety trials as well as full production experiments.\n  Offline Results. As a baseline, we compare GPT-4o to our small and large\nLlama models. In offline results, our LargeLSFT model creates an exact match\npatch 68% of the time outperforming GPT-4o by 9 percentage points (pp). The\ninternal models also use more modern Hack functions when compared to the PHP\nfunctions suggested by GPT-4o.\n  Safety Trial. When we roll MetaMateCR into production in a safety trial that\ncompares no AI patches with AI patch suggestions, we see a large regression\nwith reviewers taking over 5% longer to conduct reviews. After investigation,\nwe modify the UX to only show authors the AI patches, and see no regressions in\nthe time for reviews.\n  Production. When we roll LargeLSFT into production, we see an\nActionableToApplied rate of 19.7%, which is a 9.2pp improvement over GPT-4o.\nOur results illustrate the importance of safety trials in ensuring that AI does\nnot inadvertently slow down engineers, and a successful review comment to AI\npatch product running at scale.", "AI": {"tldr": "Meta developed MetaMateCR, an AI tool for code review, to provide fixes for reviewer comments using fine-tuned Llama models. Production trials ensured the tool doesn\u2019t delay reviews, ultimately improving patch adoption rates.", "motivation": "To address the challenge of processing tens of thousands of code review comments weekly at Meta, an AI-assisted system was developed to enhance efficiency and accuracy.", "method": "The paper fine-tuned Llama models on a large dataset of 64k code review instances. It tested their performance offline and used randomized trials and production experiments to ensure the system\u2019s reliability and minimal disruption.", "result": "The LargeLSFT model achieved a 68% exact match rate, outperforming GPT-4o by 9pp offline. Production trials showed a 19.7% ActionableToApplied rate, a 9.2pp enhancement over GPT-4o.", "conclusion": "MetaMateCR successfully assists code reviews without negatively impacting review time, emphasizing the importance of safety trials and optimization for deploying AI at scale."}}
{"id": "2507.13468", "pdf": "https://arxiv.org/pdf/2507.13468", "abs": "https://arxiv.org/abs/2507.13468", "authors": ["Shiye Cao", "Maia Stiber", "Amama Mahmood", "Maria Teresa Parreira", "Wendy Ju", "Micol Spitale", "Hatice Gunes", "Chien-Ming Huang"], "title": "ERR@HRI 2.0 Challenge: Multimodal Detection of Errors and Failures in Human-Robot Conversations", "categories": ["cs.RO", "cs.AI", "cs.HC"], "comment": null, "summary": "The integration of large language models (LLMs) into conversational robots\nhas made human-robot conversations more dynamic. Yet, LLM-powered\nconversational robots remain prone to errors, e.g., misunderstanding user\nintent, prematurely interrupting users, or failing to respond altogether.\nDetecting and addressing these failures is critical for preventing\nconversational breakdowns, avoiding task disruptions, and sustaining user\ntrust. To tackle this problem, the ERR@HRI 2.0 Challenge provides a multimodal\ndataset of LLM-powered conversational robot failures during human-robot\nconversations and encourages researchers to benchmark machine learning models\ndesigned to detect robot failures. The dataset includes 16 hours of dyadic\nhuman-robot interactions, incorporating facial, speech, and head movement\nfeatures. Each interaction is annotated with the presence or absence of robot\nerrors from the system perspective, and perceived user intention to correct for\na mismatch between robot behavior and user expectation. Participants are\ninvited to form teams and develop machine learning models that detect these\nfailures using multimodal data. Submissions will be evaluated using various\nperformance metrics, including detection accuracy and false positive rate. This\nchallenge represents another key step toward improving failure detection in\nhuman-robot interaction through social signal analysis.", "AI": {"tldr": "This paper describes the ERR@HRI 2.0 Challenge, which facilitates the detection of errors in LLM-driven conversational robots using a multimodal dataset.", "motivation": "To address the critical problem of detecting and addressing errors in LLM-powered conversational robots to prevent conversation breakdowns and maintain user trust.", "method": "A multimodal dataset is provided for benchmarking machine learning models designed to detect robot failures. The dataset contains annotations and features including facial, speech, and head movement data.", "result": "Participants are invited to create models to identify errors in robot behavior, which will be evaluated using performance metrics like detection accuracy and false positive rates.", "conclusion": "The challenge contributes to advancing failure detection in human-robot interaction by leveraging social signal analysis through machine learning models."}}
{"id": "2507.13380", "pdf": "https://arxiv.org/pdf/2507.13380", "abs": "https://arxiv.org/abs/2507.13380", "authors": ["Keito Inoshita", "Rushia Harada"], "title": "Persona-Based Synthetic Data Generation Using Multi-Stage Conditioning with Large Language Models for Emotion Recognition", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the field of emotion recognition, the development of high-performance\nmodels remains a challenge due to the scarcity of high-quality, diverse\nemotional datasets. Emotional expressions are inherently subjective, shaped by\nindividual personality traits, socio-cultural backgrounds, and contextual\nfactors, making large-scale, generalizable data collection both ethically and\npractically difficult. To address this issue, we introduce PersonaGen, a novel\nframework for generating emotionally rich text using a Large Language Model\n(LLM) through multi-stage persona-based conditioning. PersonaGen constructs\nlayered virtual personas by combining demographic attributes, socio-cultural\nbackgrounds, and detailed situational contexts, which are then used to guide\nemotion expression generation. We conduct comprehensive evaluations of the\ngenerated synthetic data, assessing semantic diversity through clustering and\ndistributional metrics, human-likeness via LLM-based quality scoring, realism\nthrough comparison with real-world emotion corpora, and practical utility in\ndownstream emotion classification tasks. Experimental results show that\nPersonaGen significantly outperforms baseline methods in generating diverse,\ncoherent, and discriminative emotion expressions, demonstrating its potential\nas a robust alternative for augmenting or replacing real-world emotional\ndatasets.", "AI": {"tldr": "PersonaGen is a framework using large language models (LLMs) to generate emotionally rich text with multi-stage persona conditioning, aiming to overcome the lack of diverse emotion datasets.", "motivation": "The research addresses the challenge of building effective emotion recognition models, hindered by the scarcity and complexity of diverse emotional datasets due to ethical and practical constraints.", "method": "The method involves the PersonaGen framework, which builds virtual personas by integrating demographic, socio-cultural, and situational attributes to guide LLM-generated emotional text.", "result": "Experimental results indicate that PersonaGen generates more diverse, coherent, and discriminative emotion expressions compared to baseline methods.", "conclusion": "PersonaGen shows promise as a robust tool for enhancing or replacing real-world emotional datasets through synthetic data generation."}}
{"id": "2507.13835", "pdf": "https://arxiv.org/pdf/2507.13835", "abs": "https://arxiv.org/abs/2507.13835", "authors": ["Martin V. Vejling", "Shashi Raj Pandey", "Christophe A. N. Biscio", "Petar Popovski"], "title": "Conformal Data Contamination Tests for Trading or Sharing of Data", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "The amount of quality data in many machine learning tasks is limited to what\nis available locally to data owners. The set of quality data can be expanded\nthrough trading or sharing with external data agents. However, data buyers need\nquality guarantees before purchasing, as external data may be contaminated or\nirrelevant to their specific learning task. Previous works primarily rely on\ndistributional assumptions about data from different agents, relegating quality\nchecks to post-hoc steps involving costly data valuation procedures. We propose\na distribution-free, contamination-aware data-sharing framework that identifies\nexternal data agents whose data is most valuable for model personalization. To\nachieve this, we introduce novel two-sample testing procedures, grounded in\nrigorous theoretical foundations for conformal outlier detection, to determine\nwhether an agent's data exceeds a contamination threshold. The proposed tests,\ntermed conformal data contamination tests, remain valid under arbitrary\ncontamination levels while enabling false discovery rate control via the\nBenjamini-Hochberg procedure. Empirical evaluations across diverse\ncollaborative learning scenarios demonstrate the robustness and effectiveness\nof our approach. Overall, the conformal data contamination test distinguishes\nitself as a generic procedure for aggregating data with statistically rigorous\nquality guarantees.", "AI": {"tldr": "This paper proposes a framework for data sharing in machine learning that identifies quality external data agents without relying on prior assumptions, using conformal data contamination tests.", "motivation": "Limited availability of quality local data in machine learning motivates sourcing from external agents. Ensuring the quality of this external data is a critical concern.", "method": "Proposed distribution-free testing procedures, termed conformal data contamination tests, based on conformal outlier detection. The tests facilitate false discovery rate control using the Benjamini-Hochberg procedure.", "result": "Demonstrated robustness and effectiveness across collaborative learning scenarios, with the framework reliably identifying valuable external data.", "conclusion": "The conformal data contamination test provides a reliable and generic solution for aggregating external data while ensuring quality through statistically rigorous guarantees."}}
{"id": "2507.13360", "pdf": "https://arxiv.org/pdf/2507.13360", "abs": "https://arxiv.org/abs/2507.13360", "authors": ["Le-Anh Tran", "Chung Nguyen Tran", "Ngoc-Luu Nguyen", "Nhan Cach Dang", "Jordi Carrabina", "David Castells-Rufas", "Minh Son Nguyen"], "title": "Low-Light Enhancement via Encoder-Decoder Network with Illumination Guidance", "categories": ["cs.CV"], "comment": "6 pages, 3 figures, ICCCE 2025", "summary": "This paper introduces a novel deep learning framework for low-light image\nenhancement, named the Encoder-Decoder Network with Illumination Guidance\n(EDNIG). Building upon the U-Net architecture, EDNIG integrates an illumination\nmap, derived from Bright Channel Prior (BCP), as a guidance input. This\nillumination guidance helps the network focus on underexposed regions,\neffectively steering the enhancement process. To further improve the model's\nrepresentational power, a Spatial Pyramid Pooling (SPP) module is incorporated\nto extract multi-scale contextual features, enabling better handling of diverse\nlighting conditions. Additionally, the Swish activation function is employed to\nensure smoother gradient propagation during training. EDNIG is optimized within\na Generative Adversarial Network (GAN) framework using a composite loss\nfunction that combines adversarial loss, pixel-wise mean squared error (MSE),\nand perceptual loss. Experimental results show that EDNIG achieves competitive\nperformance compared to state-of-the-art methods in quantitative metrics and\nvisual quality, while maintaining lower model complexity, demonstrating its\nsuitability for real-world applications. The source code for this work is\navailable at https://github.com/tranleanh/ednig.", "AI": {"tldr": "The paper presents EDNIG, a deep learning framework for low-light image enhancement, using illumination guidance, multi-scale context extraction, and GAN optimization.", "motivation": "To address quality degradation in low-light images while maintaining model efficiency.", "method": "Introduced EDNIG, which combines U-Net with an illumination map derived from BCP, incorporates SPP for multi-scale features, uses Swish activation, and employs GAN optimization with a composite loss.", "result": "EDNIG achieved competitive visual and quantitative performance compared to existing methods and showed lower model complexity.", "conclusion": "EDNIG effectively enhances low-light images, balances performance with simplicity, and is practical for real-world applications."}}
{"id": "2507.13383", "pdf": "https://arxiv.org/pdf/2507.13383", "abs": "https://arxiv.org/abs/2507.13383", "authors": ["Charvi Rastogi", "Tian Huey Teh", "Pushkar Mishra", "Roma Patel", "Ding Wang", "Mark D\u00edaz", "Alicia Parrish", "Aida Mostafazadeh Davani", "Zoe Ashwood", "Michela Paganini", "Vinodkumar Prabhakaran", "Verena Rieser", "Lora Aroyo"], "title": "Whose View of Safety? A Deep DIVE Dataset for Pluralistic Alignment of Text-to-Image Models", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "28 pages, 16 figures", "summary": "Current text-to-image (T2I) models often fail to account for diverse human\nexperiences, leading to misaligned systems. We advocate for pluralistic\nalignment, where an AI understands and is steerable towards diverse, and often\nconflicting, human values. Our work provides three core contributions to\nachieve this in T2I models. First, we introduce a novel dataset for Diverse\nIntersectional Visual Evaluation (DIVE) -- the first multimodal dataset for\npluralistic alignment. It enable deep alignment to diverse safety perspectives\nthrough a large pool of demographically intersectional human raters who\nprovided extensive feedback across 1000 prompts, with high replication,\ncapturing nuanced safety perceptions. Second, we empirically confirm\ndemographics as a crucial proxy for diverse viewpoints in this domain,\nrevealing significant, context-dependent differences in harm perception that\ndiverge from conventional evaluations. Finally, we discuss implications for\nbuilding aligned T2I models, including efficient data collection strategies,\nLLM judgment capabilities, and model steerability towards diverse perspectives.\nThis research offers foundational tools for more equitable and aligned T2I\nsystems. Content Warning: The paper includes sensitive content that may be\nharmful.", "AI": {"tldr": "The paper introduces pluralistic alignment for text-to-image (T2I) models to represent diverse human experiences. It provides a novel dataset, empirical findings on demographic diversity, and implications for building better-aligned AI systems.", "motivation": "The motivation is to address the misalignment of T2I models with diverse human experiences and values, fostering an AI system that understands and adapts to pluralistic perspectives.", "method": "The researchers developed the DIVE dataset, a multimodal resource with intersectional human rater feedback on safety perceptions for T2I prompts, and examined demographic influence on harm perception.", "result": "The study found significant demographic-based differences in harm perception, emphasizing the need for pluralistic alignment in AI and highlighting shortcomings in conventional evaluations.", "conclusion": "The work lays the groundwork for more equitable T2I systems by introducing tools, strategies, and approaches for integrating diverse human perspectives, though the content may include sensitive material."}}
{"id": "2507.13550", "pdf": "https://arxiv.org/pdf/2507.13550", "abs": "https://arxiv.org/abs/2507.13550", "authors": ["Eduardo C. Garrido-Merch\u00e1n", "Cristina Puente"], "title": "GOFAI meets Generative AI: Development of Expert Systems by means of Large Language Models", "categories": ["cs.AI", "cs.CL", "cs.SC"], "comment": null, "summary": "The development of large language models (LLMs) has successfully transformed\nknowledge-based systems such as open domain question nswering, which can\nautomatically produce vast amounts of seemingly coherent information. Yet,\nthose models have several disadvantages like hallucinations or confident\ngeneration of incorrect or unverifiable facts. In this paper, we introduce a\nnew approach to the development of expert systems using LLMs in a controlled\nand transparent way. By limiting the domain and employing a well-structured\nprompt-based extraction approach, we produce a symbolic representation of\nknowledge in Prolog, which can be validated and corrected by human experts.\nThis approach also guarantees interpretability, scalability and reliability of\nthe developed expert systems. Via quantitative and qualitative experiments with\nClaude Sonnet 3.7 and GPT-4.1, we show strong adherence to facts and semantic\ncoherence on our generated knowledge bases. We present a transparent hybrid\nsolution that combines the recall capacity of LLMs with the precision of\nsymbolic systems, thereby laying the foundation for dependable AI applications\nin sensitive domains.", "AI": {"tldr": "The paper introduces a strategy to address flaws in large language models (LLMs) by generating expert systems that use symbolic representations in Prolog. This ensures precision, interpretability, and reliability in sensitive domains.", "motivation": "While LLMs provide vast coherent knowledge for tasks like open-domain question answering, they suffer from issues such as hallucinations and incorrect information generation. There is a need for a more reliable and controllable approach for developing expert systems.", "method": "The method involves restricting the domain and using a prompt-based extraction process to form a symbolic knowledge base in Prolog. This representation can be validated by human experts, ensuring transparency and reliability.", "result": "Experiments conducted with Claude Sonnet 3.7 and GPT-4.1 demonstrated strong accuracy and semantic coherence in the generated knowledge bases, showing improved reliability in expert systems.", "conclusion": "The study proposes a hybrid model that merges the recall capacity of LLMs with the precision of symbolic systems to create dependable AI for sensitive applications."}}
{"id": "2507.13833", "pdf": "https://arxiv.org/pdf/2507.13833", "abs": "https://arxiv.org/abs/2507.13833", "authors": ["Zhixin Wang", "Tianyi Zhou", "Liming Liu", "Ao Li", "Jiarui Hu", "Dian Yang", "Jinlong Hou", "Siyuan Feng", "Yuan Cheng", "Yuan Qi"], "title": "DistFlow: A Fully Distributed RL Framework for Scalable and Efficient LLM Post-Training", "categories": ["cs.DC"], "comment": null, "summary": "Reinforcement learning (RL) has become the pivotal post-training technique\nfor large language model. Effectively scaling reinforcement learning is now the\nkey to unlocking advanced reasoning capabilities and ensuring safe,\ngoal-aligned behavior in the most powerful LLMs. Mainstream frameworks usually\nemploy a hybrid-controller architecture where a single-controller dispatches\nthe overall execution logic and manages overall data transfer and the\nmulti-controller executes distributed computation. For large-scale\nreinforcement learning, minor load imbalances can introduce significant\nbottlenecks, ultimately constraining the scalability of the system. To address\nthis limitation, we introduce DistFlow, a novel, fully distributed RL framework\ndesigned to break scaling barrier. We adopt a multi-controller paradigm that\ndispatches data transfer and execution tasks to all workers, which eliminates\nthe centralized node. This allows each worker to operate independently, leading\nto near-linear scalability up to thousands of GPUs and dramatic efficiency\ngains. Furthermore, our architecture decouples resource configuration from\nexecution logic, allowing each worker to have a unique execution flow, offering\nsignificant flexibility for rapid and cost-effective algorithmic\nexperimentation. Extensive experiments show that DistFlow achieves excellent\nlinear scalability and up to a 7x end-to-end throughput improvement over\nstate-of-the-art (SOTA) frameworks.", "AI": {"tldr": "The paper introduces DistFlow, a fully distributed RL framework that eliminates the centralized controller, achieving near-linear scalability and up to 7x throughput improvement over SOTA frameworks.", "motivation": "Existing frameworks for large-scale RL suffer from scalability bottlenecks due to minor load imbalances in hybrid-controller architectures.", "method": "DistFlow employs a multi-controller paradigm where data transfer and execution tasks are distributed across all workers, eliminating centralized nodes and decoupling resource configuration from execution logic.", "result": "Extensive experiments show linear scalability and a 7x end-to-end throughput improvement compared to SOTA frameworks.", "conclusion": "DistFlow resolves scalability limitations in reinforcement learning, achieving dramatic efficiency and flexibility for algorithmic experimentation."}}
{"id": "2507.13774", "pdf": "https://arxiv.org/pdf/2507.13774", "abs": "https://arxiv.org/abs/2507.13774", "authors": ["Arthur Adjedj", "Meven Lennon-Bertrand", "Thibaut Benjamin", "Kenji Maillard"], "title": "AdapTT: Functoriality for Dependent Type Casts", "categories": ["cs.PL", "cs.LO", "D.3.1; F.3.2; F.4.1"], "comment": null, "summary": "The ability to cast values between related types is a leitmotiv of many\nflavors of dependent type theory, such as observational type theories,\nsubtyping, or cast calculi for gradual typing. These casts all exhibit a common\nstructural behavior that boils down to the pervasive functoriality of type\nformers. We propose and extensively study a type theory, called AdapTT, which\nmakes systematic and precise this idea of functorial type formers, with respect\nto an abstract notion of adapters relating types. Leveraging descriptions for\nfunctorial inductive types in AdapTT, we derive structural laws for type casts\non general inductive type formers.", "AI": {"tldr": "The paper introduces AdapTT, a type theory focusing on functorial type formers and adapters, facilitating systematic type casting.", "motivation": "To address the pervasive behavior of functoriality in type formers and systematize type casting in dependent type theories.", "method": "Developing AdapTT, a new type theory based on functorial type formers and abstract adapters to study type casting systematically.", "result": "The paper derives structural laws for type casts on inductive type formers using AdapTT.", "conclusion": "AdapTT provides a precise framework to understand and implement type casting through functorial type formers and adapters."}}
{"id": "2507.13785", "pdf": "https://arxiv.org/pdf/2507.13785", "abs": "https://arxiv.org/abs/2507.13785", "authors": ["Mykola Glybovets", "Sergii Medvid"], "title": "MorphoNAS: Embryogenic Neural Architecture Search Through Morphogen-Guided Development", "categories": ["cs.NE"], "comment": "13 pages, 8 figures; Preprint of a manuscript submitted for peer\n  review", "summary": "While biological neural networks develop from compact genomes using\nrelatively simple rules, modern artificial neural architecture search methods\nmostly involve explicit and routine manual work. In this paper, we introduce\nMorphoNAS (Morphogenetic Neural Architecture Search), a system able to\ndeterministically grow neural networks through morphogenetic self-organization\ninspired by the Free Energy Principle, reaction-diffusion systems, and gene\nregulatory networks. In MorphoNAS, simple genomes encode just morphogens\ndynamics and threshold-based rules of cellular development. Nevertheless, this\nleads to self-organization of a single progenitor cell into complex neural\nnetworks, while the entire process is built on local chemical interactions. Our\nevolutionary experiments focused on two different domains: structural\ntargeting, in which MorphoNAS system was able to find fully successful genomes\nable to generate predefined random graph configurations (8-31 nodes); and\nfunctional performance on the CartPole control task achieving low complexity\n6-7 neuron solutions when target network size minimization evolutionary\npressure was applied. The evolutionary process successfully balanced between\nquality of of the final solutions and neural architecture search effectiveness.\nOverall, our findings suggest that the proposed MorphoNAS method is able to\ngrow complex specific neural architectures, using simple developmental rules,\nwhich suggests a feasible biological route to adaptive and efficient neural\narchitecture search.", "AI": {"tldr": "The paper presents MorphoNAS, a biologically-inspired neural architecture search system that grows neural networks deterministically through simple developmental rules and local interactions.", "motivation": "Conventional neural architecture search methods require significant manual effort. The authors aim to create a more autonomous and biologically-inspired approach to efficiently grow complex neural networks.", "method": "The authors developed MorphoNAS, a system based on morphogenetic self-organization principles like the Free Energy Principle, reaction-diffusion systems, and gene regulatory networks. Simple genomes define morphogen dynamics and rules to grow neural networks via local interactions.", "result": "MorphoNAS demonstrated its success in two tasks: structural targeting, generating predefined graph configurations (8-31 nodes), and functional performance on CartPole, producing minimal complexity solutions (6-7 neurons). The system balanced solution quality and search efficiency throughout evolution.", "conclusion": "MorphoNAS effectively grows biologically-inspired, adaptive neural architectures with simple developmental rules, showcasing its potential for efficient and autonomous neural architecture search methods."}}
{"id": "2507.13553", "pdf": "https://arxiv.org/pdf/2507.13553", "abs": "https://arxiv.org/abs/2507.13553", "authors": ["Pragyan K C", "Rambod Ghandiparsi", "Thomas Herron", "John Heaps", "Mitra Bokaei Hosseini"], "title": "Towards Better Requirements from the Crowd: Developer Engagement with Feature Requests in Open Source Software", "categories": ["cs.SE"], "comment": "Accepted at the 9th International Workshop on Crowd-Based\n  Requirements Engineering (CrowdRE'25)", "summary": "As user demands evolve, effectively incorporating feature requests is crucial\nfor maintaining software relevance and user satisfaction. Feature requests,\ntypically expressed in natural language, often suffer from ambiguity or\nincomplete information due to communication gaps or the requester's limited\ntechnical expertise. These issues can lead to misinterpretation, faulty\nimplementation, and reduced software quality. While seeking clarification from\nrequesters is a common strategy to mitigate these risks, little is known about\nhow developers engage in this clarification process in practice-how they\nformulate clarifying questions, seek technical or contextual details, align on\ngoals and use cases, or decide to close requests without attempting\nclarification. This study investigates how feature requests are prone to NL\ndefects (i.e. ambiguous or incomplete) and the conversational dynamics of\nclarification in open-source software (OSS) development, aiming to understand\nhow developers handle ambiguous or incomplete feature requests. Our findings\nsuggest that feature requests published on the OSS platforms do possess\nambiguity and incompleteness, and in some cases, both. We also find that\nexplicit clarification for the resolution of these defects is uncommon;\ndevelopers usually focus on aligning with project goals rather than resolving\nunclear text. When clarification occurs, it emphasizes understanding user\nintent/goal and feasibility, rather than technical details. By characterizing\nthe dynamics of clarification in open-source issue trackers, this work\nidentifies patterns that can improve user-developer collaboration and inform\nbest practices for handling feature requests effectively.", "AI": {"tldr": "This paper examines how developers handle ambiguous and incomplete feature requests in open-source software (OSS) development, finding that clarification processes are rare and typically focus on user intent rather than technical details.", "motivation": "Ambiguity and incomplete information in natural-language feature requests can lead to misinterpretation, faulty implementations, and reduced software quality. The goal is to study how developers handle clarification to address these issues.", "method": "The study investigates feature requests on open-source software platforms, analyzing their ambiguity or incompleteness and studying the conversational dynamics of clarification between users and developers.", "result": "It finds that feature requests on OSS platforms are often ambiguous or incomplete. Clarification is rare, and when it happens, it prioritizes understanding user intent and feasibility rather than resolving unclear text or technical details.", "conclusion": "This work highlights the need for better user-developer collaboration and offers insights into practices that could improve the handling of feature requests in open-source projects."}}
{"id": "2507.13539", "pdf": "https://arxiv.org/pdf/2507.13539", "abs": "https://arxiv.org/abs/2507.13539", "authors": ["Jim O'Connor", "Jay B. Nash", "Derin Gezgin", "Gary B. Parker"], "title": "SCOPE for Hexapod Gait Generation", "categories": ["cs.RO", "cs.NE"], "comment": "IJCCI Conference on Evolutionary Computation and Theory and\n  Applications, 2025", "summary": "Evolutionary methods have previously been shown to be an effective learning\nmethod for walking gaits on hexapod robots. However, the ability of these\nalgorithms to evolve an effective policy rapidly degrades as the input space\nbecomes more complex. This degradation is due to the exponential growth of the\nsolution space, resulting from an increasing parameter count to handle a more\ncomplex input. In order to address this challenge, we introduce Sparse Cosine\nOptimized Policy Evolution (SCOPE). SCOPE utilizes the Discrete Cosine\nTransform (DCT) to learn directly from the feature coefficients of an input\nmatrix. By truncating the coefficient matrix returned by the DCT, we can reduce\nthe dimensionality of an input while retaining the highest energy features of\nthe original input. We demonstrate the effectiveness of this method by using\nSCOPE to learn the gait of a hexapod robot. The hexapod controller is given a\nmatrix input containing time-series information of previous poses, which are\nthen transformed to gait parameters by an evolved policy. In this task, the\naddition of SCOPE to a reference algorithm achieves a 20% increase in efficacy.\nSCOPE achieves this result by reducing the total input size of the time-series\npose data from 2700 to 54, a 98% decrease. Additionally, SCOPE is capable of\ncompressing an input to any output shape, provided that each output dimension\nis no greater than the corresponding input dimension. This paper demonstrates\nthat SCOPE is capable of significantly compressing the size of an input to an\nevolved controller, resulting in a statistically significant gain in efficacy.", "AI": {"tldr": "The paper introduces Sparse Cosine Optimized Policy Evolution (SCOPE), which utilizes Discrete Cosine Transform to reduce input dimensionality for hexapod robot gait learning, achieving notable performance improvements.", "motivation": "To address the challenge of performance degradation in evolutionary algorithms as input space complexity increases, leading to exponential growth in solution space.", "method": "SCOPE leverages the Discrete Cosine Transform to compress input dimensionality by focusing on high-energy features while discarding less significant information, which is used to evolve policies for robot gait learning.", "result": "By incorporating SCOPE, the input size for hexapod gait learning was reduced by 98% (from 2700 to 54), leading to a 20% improvement in performance within the evolutionary learning process.", "conclusion": "SCOPE effectively reduces input dimensionality while maintaining crucial information, improving the efficacy of evolutionary algorithms for complex tasks like robotic gait learning."}}
{"id": "2507.13381", "pdf": "https://arxiv.org/pdf/2507.13381", "abs": "https://arxiv.org/abs/2507.13381", "authors": ["Rafiq Kamel", "Filippo Guerranti", "Simon Geisler", "Stephan G\u00fcnnemann"], "title": "SAFT: Structure-Aware Fine-Tuning of LLMs for AMR-to-Text Generation", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted at the KDD2025 Workshop on Structured Knowledge for LLMs", "summary": "Large Language Models (LLMs) are increasingly applied to tasks involving\nstructured inputs such as graphs. Abstract Meaning Representations (AMRs),\nwhich encode rich semantics as directed graphs, offer a rigorous testbed for\nevaluating LLMs on text generation from such structures. Yet, current methods\noften arbitrarily linearize AMRs, discarding key structural cues, or rely on\narchitectures incompatible with standard LLMs. We introduce SAFT, a\nstructure-aware fine-tuning approach that injects graph topology into\npretrained LLMs without architectural changes. We compute direction-sensitive\npositional encodings from the magnetic Laplacian of transformed AMRs and\nproject them into the embedding space of the LLM. While possibly applicable to\nany graph-structured inputs, we focus on AMR-to-text generation as a\nrepresentative and challenging benchmark. SAFT sets a new state-of-the-art on\nAMR 3.0 with a 3.5 BLEU improvement over baselines. Gains scale with graph\ncomplexity, highlighting the value of structure-aware representations in\nenhancing LLM performance. SAFT offers a general and effective pathway for\nbridging structured data and language models.", "AI": {"tldr": "The paper introduces SAFT, a structure-aware fine-tuning method for LLMs to improve text generation from graph-structured inputs like AMRs, achieving state-of-the-art results.", "motivation": "LLMs struggle with tasks requiring structured input comprehension, such as AMRs in graph form. Existing solutions either discard important structural cues or are incompatible with standard LLMs.", "method": "SAFT integrates graph topology into LLMs using magnetic Laplacian-based positional encodings, projected into the embedding space, without modifying the original model architecture.", "result": "SAFT achieves a 3.5 BLEU score improvement on AMR-to-text generation benchmarks (AMR 3.0), with gains correlated to graph complexity.", "conclusion": "SAFT bridges the gap between structured data and LLMs effectively, providing scalable benefits for tasks requiring graph-aware processing."}}
{"id": "2507.13887", "pdf": "https://arxiv.org/pdf/2507.13887", "abs": "https://arxiv.org/abs/2507.13887", "authors": ["James A. D. Binnie", "Pawe\u0142 D\u0142otko", "John Harvey", "Jakub Malinowski", "Ka Man Yim"], "title": "A Survey of Dimension Estimation Methods", "categories": ["stat.ML", "cs.LG", "math.DG", "math.MG", "math.ST", "stat.TH", "62R40 (Primary) 62R30, 62R07, 62G05, 53Z50 (Secondary)"], "comment": "45 pages + appendices, 24 figures", "summary": "It is a standard assumption that datasets in high dimension have an internal\nstructure which means that they in fact lie on, or near, subsets of a lower\ndimension. In many instances it is important to understand the real dimension\nof the data, hence the complexity of the dataset at hand. A great variety of\ndimension estimators have been developed to find the intrinsic dimension of the\ndata but there is little guidance on how to reliably use these estimators.\n  This survey reviews a wide range of dimension estimation methods,\ncategorising them by the geometric information they exploit: tangential\nestimators which detect a local affine structure; parametric estimators which\nrely on dimension-dependent probability distributions; and estimators which use\ntopological or metric invariants.\n  The paper evaluates the performance of these methods, as well as\ninvestigating varying responses to curvature and noise. Key issues addressed\ninclude robustness to hyperparameter selection, sample size requirements,\naccuracy in high dimensions, precision, and performance on non-linear\ngeometries. In identifying the best hyperparameters for benchmark datasets,\noverfitting is frequent, indicating that many estimators may not generalise\nwell beyond the datasets on which they have been tested.", "AI": {"tldr": "This paper surveys various dimension estimation methods, exploring their strengths, weaknesses, and performance across different geometric and statistical conditions.", "motivation": "Understanding the intrinsic dimension of high-dimensional datasets is crucial for assessing their complexity and suitability for machine learning tasks.", "method": "The authors categorize dimension estimation methods based on geometric information\u2014tangential structure, parametric inference, and topological/metric invariants\u2014and evaluate their robustness and accuracy under various conditions.", "result": "Evaluation reveals varying responses of dimension estimators to curvature, noise, hyperparameter sensitivity, sample size, high dimensions, and non-linear geometries.", "conclusion": "Many dimension estimators are prone to overfitting and lack generalizability beyond tested datasets, suggesting the need for better guidelines and improvements in their design."}}
{"id": "2507.13361", "pdf": "https://arxiv.org/pdf/2507.13361", "abs": "https://arxiv.org/abs/2507.13361", "authors": ["Shmuel Berman", "Jia Deng"], "title": "VLMs have Tunnel Vision: Evaluating Nonlocal Visual Reasoning in Leading VLMs", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Visual Language Models (VLMs) excel at complex visual tasks such as VQA and\nchart understanding, yet recent work suggests they struggle with simple\nperceptual tests. We present an evaluation that tests vision-language models'\ncapacity for nonlocal visual reasoning -- reasoning that requires chaining\nevidence collected from multiple, possibly distant, regions of an image. We\nisolate three distinct forms of non-local vision: comparative perception, which\ndemands holding two images in working memory and comparing them; saccadic\nsearch, which requires making discrete, evidence-driven jumps to locate\nsuccessive targets; and smooth visual search, which involves searching smoothly\nalong a continuous contour. Flagship models (e.g., Gemini 2.5 Pro, Claude\nVision 3.7, GPT-o4-mini), even those that perform well on prior\nprimitive-vision benchmarks, fail these tests and barely exceed random accuracy\non two variants of our tasks that are trivial for humans. Our structured\nevaluation suite allows us to test if VLMs can perform similar visual\nalgorithms to humans. Our findings show that despite gains in raw visual\nacuity, current models lack core visual reasoning capabilities.", "AI": {"tldr": "This paper introduces an evaluation suite to test vision-language models' (VLMs) ability for nonlocal visual reasoning tasks, revealing significant limitations.", "motivation": "While VLMs perform well on complex tasks, they struggle with simple perceptual and reasoning tasks, leading to a need to evaluate their reasoning capabilities.", "method": "The authors define and isolate three forms of non-local vision (comparative perception, saccadic search, and smooth visual search) to test core visual reasoning abilities of flagship VLMs using a structured evaluation framework.", "result": "Flagship VLMs failed to effectively handle these tasks, performing barely above random levels on tests that are trivial for humans.", "conclusion": "Despite advancements in visual acuity, current VLMs lack crucial visual reasoning abilities, highlighting a gap in their development."}}
{"id": "2507.13393", "pdf": "https://arxiv.org/pdf/2507.13393", "abs": "https://arxiv.org/abs/2507.13393", "authors": ["Jakub Strawa", "Jarek Duda"], "title": "Improving KAN with CDF normalization to quantiles", "categories": ["cs.LG"], "comment": "7 pages, 9 figures", "summary": "Data normalization is crucial in machine learning, usually performed by\nsubtracting the mean and dividing by standard deviation, or by rescaling to a\nfixed range. In copula theory, popular in finance, there is used normalization\nto approximately quantiles by transforming x to CDF(x) with estimated CDF\n(cumulative distribution function) to nearly uniform distribution in [0,1],\nallowing for simpler representations which are less likely to overfit. It seems\nnearly unknown in machine learning, therefore, we would like to present some\nits advantages on example of recently popular Kolmogorov-Arnold Networks\n(KANs), improving predictions from Legendre-KAN by just switching rescaling to\nCDF normalization. Additionally, in HCR interpretation, weights of such neurons\nare mixed moments providing local joint distribution models, allow to propagate\nalso probability distributions, and change propagation direction.", "AI": {"tldr": "The paper introduces the use of copula theory-based CDF normalization to enhance data processing in machine learning applications, specifically targeting Kolmogorov-Arnold Networks (KANs).", "motivation": "Most machine learning methods normalize data through standard processes like subtracting the mean and dividing by the standard deviation or rescaling to [0,1]. However, these approaches might lead to overfitting or overly complex models. Copula theory's CDF normalization is underexplored in machine learning and possibly offers superior simplicity and performance.", "method": "The authors propose switching from traditional rescaling to CDF normalization using cumulative distribution function transformations in Kolmogorov-Arnold Networks (KANs). They demonstrate its advantages specifically on Legendre-KAN.", "result": "Replacing rescaling with CDF normalization improves prediction accuracy in Legendre-KAN models. Moreover, HCR interpretations enable neuron weights to act as mixed moments, allowing local joint distribution modeling, better probability distribution propagation, and dynamic directional changes.", "conclusion": "CDF normalization simplifies representations and enhances machine learning frameworks like KANs, showcasing better prediction performance and enriched probabilistic interpretations."}}
{"id": "2507.13558", "pdf": "https://arxiv.org/pdf/2507.13558", "abs": "https://arxiv.org/abs/2507.13558", "authors": ["David Poole"], "title": "Why Isn't Relational Learning Taking Over the World?", "categories": ["cs.AI", "cs.DB", "cs.LG"], "comment": "10 pages (6 pages + references + appendices)", "summary": "AI seems to be taking over the world with systems that model pixels, words,\nand phonemes. The world is arguably made up, not of pixels, words, and phonemes\nbut of entities (objects, things, including events) with properties and\nrelations among them. Surely we should model these, not the perception or\ndescription of them. You might suspect that concentrating on modeling words and\npixels is because all of the (valuable) data in the world is in terms of text\nand images. If you look into almost any company you will find their most\nvaluable data is in spreadsheets, databases and other relational formats. These\nare not the form that are studied in introductory machine learning, but are\nfull of product numbers, student numbers, transaction numbers and other\nidentifiers that can't be interpreted naively as numbers. The field that\nstudies this sort of data has various names including relational learning,\nstatistical relational AI, and many others. This paper explains why relational\nlearning is not taking over the world -- except in a few cases with restricted\nrelations -- and what needs to be done to bring it to it's rightful prominence.", "AI": {"tldr": "The paper discusses why AI should focus on modeling entities and their relations rather than just perception data like pixels and words, and why relational learning hasn't become mainstream yet.", "motivation": "To address why AI has predominantly focused on modeling perceptual data (e.g., text, images) and highlight the need for modeling real-world entities and their relationships.", "method": "Analyzes the current state of AI, focusing on the gaps in relational learning, and identifies barriers preventing it from becoming broadly utilized.", "result": "Highlights the underutilization of relational learning despite its relevance in handling structured data like spreadsheets and databases.", "conclusion": "Suggests what changes are necessary to elevate relational learning to a more prominent role in AI research and applications."}}
{"id": "2507.14069", "pdf": "https://arxiv.org/pdf/2507.14069", "abs": "https://arxiv.org/abs/2507.14069", "authors": ["Shuiguang Deng", "Di Yu", "Changze Lv", "Xin Du", "Linshan Jiang", "Xiaofan Zhao", "Wentao Tong", "Xiaoqing Zheng", "Weijia Fang", "Peng Zhao", "Gang Pan", "Schahram Dustdar", "Albert Y. Zomaya"], "title": "Edge Intelligence with Spiking Neural Networks", "categories": ["cs.DC", "cs.AI", "cs.ET", "cs.NE"], "comment": "This work has been submitted to Proceeding of IEEE for possible\n  publication", "summary": "The convergence of artificial intelligence and edge computing has spurred\ngrowing interest in enabling intelligent services directly on\nresource-constrained devices. While traditional deep learning models require\nsignificant computational resources and centralized data management, the\nresulting latency, bandwidth consumption, and privacy concerns have exposed\ncritical limitations in cloud-centric paradigms. Brain-inspired computing,\nparticularly Spiking Neural Networks (SNNs), offers a promising alternative by\nemulating biological neuronal dynamics to achieve low-power, event-driven\ncomputation. This survey provides a comprehensive overview of Edge Intelligence\nbased on SNNs (EdgeSNNs), examining their potential to address the challenges\nof on-device learning, inference, and security in edge scenarios. We present a\nsystematic taxonomy of EdgeSNN foundations, encompassing neuron models,\nlearning algorithms, and supporting hardware platforms. Three representative\npractical considerations of EdgeSNN are discussed in depth: on-device inference\nusing lightweight SNN models, resource-aware training and updating under\nnon-stationary data conditions, and secure and privacy-preserving issues.\nFurthermore, we highlight the limitations of evaluating EdgeSNNs on\nconventional hardware and introduce a dual-track benchmarking strategy to\nsupport fair comparisons and hardware-aware optimization. Through this study,\nwe aim to bridge the gap between brain-inspired learning and practical edge\ndeployment, offering insights into current advancements, open challenges, and\nfuture research directions. To the best of our knowledge, this is the first\ndedicated and comprehensive survey on EdgeSNNs, providing an essential\nreference for researchers and practitioners working at the intersection of\nneuromorphic computing and edge intelligence.", "AI": {"tldr": "The paper explores the advancements in Edge Intelligence using Spiking Neural Networks (EdgeSNNs) for efficient, low-power computing on resource-limited devices.", "motivation": "The motivation lies in addressing the limitations of cloud-centric AI, such as high latency, bandwidth issues, and privacy concerns, by bringing intelligent computation directly to edge devices using neuromorphic principles.", "method": "The study systematically categorizes EdgeSNN foundations, including neuron models, learning algorithms, and hardware, alongside discussing practical considerations such as on-device inference, resource-aware training, and privacy-preserving mechanisms.", "result": "The paper identifies challenges in evaluating EdgeSNNs on traditional hardware and proposes a dual-track benchmarking strategy for fair assessment and optimization.", "conclusion": "This survey bridges the gap between biological brain-inspired learning and practical edge computing deployment, offering a foundational reference for ongoing and future research in EdgeSNNs."}}
{"id": "2507.13792", "pdf": "https://arxiv.org/pdf/2507.13792", "abs": "https://arxiv.org/abs/2507.13792", "authors": ["Riccardo Bianchini", "Francesco Dagnino", "Paola Giannini", "Elena Zucca"], "title": "Don't exhaust, don't waste", "categories": ["cs.PL"], "comment": "Submitted to JFP (Journal of Functional Programming)", "summary": "We extend the semantics and type system of a lambda calculus equipped with\ncommon constructs to be resource-aware. That is, the semantics keep tracks of\nthe usage of resources, and is stuck, besides in case of type errors, if either\na needed resource is exhausted, or a provided resource would be wasted. In such\nway, the type system guarantees, besides standard soundness, that for\nwell-typed programs there is a computation where no resource gets either\nexhausted or wasted.\n  The no-waste extension is parametric on an arbitrary grade algebra, modeling\nan arbitrary assortment of possible usages, and does not require ad-hoc changes\nto the underlying language. To this end, the semantics needs to be formalized\nin big-step style; as a consequence, expressing and proving (resource-aware)\nsoundness is challenging, and is achieved by applying recent techniques based\non coinductive reasoning.", "AI": {"tldr": "This paper enhances the lambda calculus with resource-aware semantics and type systems to ensure resources are neither wasted nor exhausted in well-typed programs.", "motivation": "The motivation was to address the need for a computation model where resource usage is explicitly tracked and managed, ensuring that well-typed programs do not face situations like resource wastage or exhaustion.", "method": "The paper extends the semantics and type system of lambda calculus to track resource usage and ensure correctness. It incorporates a grade algebra to model resource usage and employs coinductive reasoning techniques to handle the complexities of the big-step semantics and prove soundness.", "result": "The extended system guarantees that well-typed programs avoid both resource exhaustion and wastage.", "conclusion": "This work demonstrates that resource-awareness can be seamlessly integrated into lambda calculus without modifying the core language and provides formal proofs ensuring correct resource management."}}
{"id": "2507.14011", "pdf": "https://arxiv.org/pdf/2507.14011", "abs": "https://arxiv.org/abs/2507.14011", "authors": ["Paolo Totaro", "Alberto Mangiante"], "title": "Conceptual and Design Principles for a Self-Referential Algorithm Mimicking Neuronal Assembly Functions", "categories": ["cs.NE", "cs.RO"], "comment": null, "summary": "This article proposes a method to formalise models of cognitive processes\ngrounded in experience, considering experience from the perspective of a living\nsystem and not from that of an observer of the living system. The perspective\nof a living system is defined by the need of the system to preserve the vital\nequilibria. The method is based on an algorithmic schema that we call\nEnvironment Generative Operator (EGO) and uses a self-referential language\ndeveloped for this purpose which we call E-language. EGO simulates cognitive\nprocesses as operations on neuron assemblies as understood by Hebb. In this\narticle we present an EGO prototype (EGO-P) which has already been implemented\nand tested.", "AI": {"tldr": "The paper introduces EGO, a method to simulate cognitive processes using an experiential perspective, focusing on neuron assemblies.", "motivation": "To model cognitive processes based on the perspective of a living system preserving vital equilibria, rather than external observation.", "method": "Developed an algorithmic schema (EGO) with a self-referential language (E-language), simulating cognitive processes according to Hebbian operations.", "result": "Implemented and tested a prototype of EGO (EGO-P) successfully.", "conclusion": "EGO provides a foundational method to simulate experiential and cognitive processes through the living system's perspective."}}
{"id": "2507.13555", "pdf": "https://arxiv.org/pdf/2507.13555", "abs": "https://arxiv.org/abs/2507.13555", "authors": ["Pragyan K C", "Rambod Ghandiparsi", "Thomas Herron", "John Heaps", "Mitra Bokaei Hosseini"], "title": "Demystifying Feature Requests: Leveraging LLMs to Refine Feature Requests in Open-Source Software", "categories": ["cs.SE"], "comment": "Accepted at the 33rd IEEE International Requirements Engineering 2025", "summary": "The growing popularity and widespread use of software applications (apps)\nacross various domains have driven rapid industry growth. Along with this\ngrowth, fast-paced market changes have led to constantly evolving software\nrequirements. Such requirements are often grounded in feature requests and\nenhancement suggestions, typically provided by users in natural language (NL).\nHowever, these requests often suffer from defects such as ambiguity and\nincompleteness, making them challenging to interpret. Traditional validation\nmethods (e.g., interviews and workshops) help clarify such defects but are\nimpractical in decentralized environments like open-source software (OSS),\nwhere change requests originate from diverse users on platforms like GitHub.\nThis paper proposes a novel approach leveraging Large Language Models (LLMs) to\ndetect and refine NL defects in feature requests. Our approach automates the\nidentification of ambiguous and incomplete requests and generates clarification\nquestions (CQs) to enhance their usefulness for developers. To evaluate its\neffectiveness, we apply our method to real-world OSS feature requests and\ncompare its performance against human annotations. In addition, we conduct\ninterviews with GitHub developers to gain deeper insights into their\nperceptions of NL defects, the strategies they use to address these defects,\nand the impact of defects on downstream software engineering (SE) tasks.", "AI": {"tldr": "The study introduces a method using Large Language Models (LLMs) to detect and refine defects in user-provided feature requests written in natural language, with a focus on open-source software platforms like GitHub.", "motivation": "The rapid growth of the software industry and evolving requirements, driven by user feature requests, often suffer from defects like ambiguity and incompleteness, requiring solutions for better handling, especially in decentralized OSS environments.", "method": "The paper uses LLMs to automate defect detection in feature requests, generate clarification questions, and evaluates their effectiveness through real-world OSS applications and comparison against human annotations. Additionally, developer interviews were conducted to examine perceptions and strategies related to NL defects.", "result": "The proposed LLM-based approach successfully detects defects in NL feature requests and generates clarification questions, showing promising results when compared with human annotations. Insights from developer interviews provided additional understanding of handling defects in OSS environments.", "conclusion": "The method enhances the quality and usefulness of user feature requests for developers in decentralized OSS settings by detecting NL defects and generating clarifications, contributing to better downstream SE tasks."}}
{"id": "2507.13602", "pdf": "https://arxiv.org/pdf/2507.13602", "abs": "https://arxiv.org/abs/2507.13602", "authors": ["Shivakanth Sujit", "Luca Nunziante", "Dan Ogawa Lillrank", "Rousslan Fernand Julien Dossa", "Kai Arulkumaran"], "title": "Improving Low-Cost Teleoperation: Augmenting GELLO with Force", "categories": ["cs.RO", "cs.HC", "cs.LG"], "comment": "Accepted at the 2025 IEEE/SICE International Symposium on System\n  Integration", "summary": "In this work we extend the low-cost GELLO teleoperation system, initially\ndesigned for joint position control, with additional force information. Our\nfirst extension is to implement force feedback, allowing users to feel\nresistance when interacting with the environment. Our second extension is to\nadd force information into the data collection process and training of\nimitation learning models. We validate our additions by implementing these on a\nGELLO system with a Franka Panda arm as the follower robot, performing a user\nstudy, and comparing the performance of policies trained with and without force\ninformation on a range of simulated and real dexterous manipulation tasks.\nQualitatively, users with robotics experience preferred our controller, and the\naddition of force inputs improved task success on the majority of tasks.", "AI": {"tldr": "The paper extends the GELLO teleoperation system to include force feedback and integrate force data in imitation learning, demonstrating improved task success and user preference.", "motivation": "Enhance user interaction and performance in teleoperation by incorporating force feedback and force data in data collection and learning models.", "method": "Implemented force feedback and data integration into the GELLO teleoperation system using a Franka Panda arm, conducted user studies, and trained policies with and without force input.", "result": "Users preferred the developed system, and force inputs significantly enhanced the success rate in dexterous manipulation tasks across simulated and real settings.", "conclusion": "Integrating force data into teleoperation systems improves user experience and task performance, validating the proposed system for practical use cases."}}
{"id": "2507.13382", "pdf": "https://arxiv.org/pdf/2507.13382", "abs": "https://arxiv.org/abs/2507.13382", "authors": ["Chandrashekar Muniyappa", "Sirisha Velampalli"], "title": "Context-Based Fake News Detection using Graph Based Approach: ACOVID-19 Use-case", "categories": ["cs.CL", "cs.LG", "05-05C12"], "comment": "CSAIDE '25: Proceedings of the 2025 4th International Conference on\n  Cyber Security, Artificial Intelligence and the Digital Economy", "summary": "In today\\'s digital world, fake news is spreading with immense speed. Its a\nsignificant concern to address. In this work, we addressed that challenge using\nnovel graph based approach. We took dataset from Kaggle that contains real and\nfake news articles. To test our approach we incorporated recent covid-19\nrelated news articles that contains both genuine and fake news that are\nrelevant to this problem. This further enhances the dataset as well instead of\nrelying completely on the original dataset. We propose a contextual graph-based\napproach to detect fake news articles. We need to convert news articles into\nappropriate schema, so we leverage Natural Language Processing (NLP) techniques\nto transform news articles into contextual graph structures. We then apply the\nMinimum Description Length (MDL)-based Graph-Based Anomaly Detection (GBAD)\nalgorithm for graph mining. Graph-based methods are particularly effective for\nhandling rich contextual data, as they enable the discovery of complex patterns\nthat traditional query-based or statistical techniques might overlook. Our\nproposed approach identifies normative patterns within the dataset and\nsubsequently uncovers anomalous patterns that deviate from these established\nnorms.", "AI": {"tldr": "The paper addresses fake news detection using a graph-based approach, applying Natural Language Processing (NLP) to convert news articles into contextual graph structures and utilizing graph anomaly detection algorithms.", "motivation": "The growing issue of fake news spreading rapidly in digital media, especially around sensitive topics like COVID-19, motivated this research.", "method": "The proposed method integrates NLP to transform news articles into contextual graphs, followed by using the Minimum Description Length (MDL)-based Graph-Based Anomaly Detection (GBAD) algorithm to identify patterns and anomalies.", "result": "The approach successfully identifies normative and anomalous patterns in datasets containing real and fake news articles.", "conclusion": "The proposed graph-based approach proves effective for detecting fake news articles by leveraging contextual patterns that traditional methods might miss."}}
{"id": "2507.14023", "pdf": "https://arxiv.org/pdf/2507.14023", "abs": "https://arxiv.org/abs/2507.14023", "authors": ["Zhanli Wu", "Fabrizio Leisen", "F. Javier Rubio"], "title": "Conformalized Regression for Continuous Bounded Outcomes", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "R code and data can be found at: https://github.com/ZWU-001/CPBounded", "summary": "Regression problems with bounded continuous outcomes frequently arise in\nreal-world statistical and machine learning applications, such as the analysis\nof rates and proportions. A central challenge in this setting is predicting a\nresponse associated with a new covariate value. Most of the existing\nstatistical and machine learning literature has focused either on point\nprediction of bounded outcomes or on interval prediction based on asymptotic\napproximations. We develop conformal prediction intervals for bounded outcomes\nbased on transformation models and beta regression. We introduce tailored\nnon-conformity measures based on residuals that are aligned with the underlying\nmodels, and account for the inherent heteroscedasticity in regression settings\nwith bounded outcomes. We present a theoretical result on asymptotic marginal\nand conditional validity in the context of full conformal prediction, which\nremains valid under model misspecification. For split conformal prediction, we\nprovide an empirical coverage analysis based on a comprehensive simulation\nstudy. The simulation study demonstrates that both methods provide valid\nfinite-sample predictive coverage, including settings with model\nmisspecification. Finally, we demonstrate the practical performance of the\nproposed conformal prediction intervals on real data and compare them with\nbootstrap-based alternatives.", "AI": {"tldr": "This paper proposes methods for creating conformal prediction intervals tailored for regression problems involving bounded continuous outcomes.", "motivation": "Address challenges in predictive accuracy for bounded outcomes, particularly rates and proportions, in regression problems.", "method": "Develop conformal prediction intervals using transformation models and beta regression while introducing specific non-conformity measures to handle heteroscedasticity and model mis-specifications.", "result": "Simulation studies and empirical tests validate the predictive coverage of the methods, including under scenarios of model misspecification.", "conclusion": "The methods show reliability compared to alternatives, such as bootstrap-based approaches, and offer robust predictive accuracy for bounded outcomes."}}
{"id": "2507.13362", "pdf": "https://arxiv.org/pdf/2507.13362", "abs": "https://arxiv.org/abs/2507.13362", "authors": ["Binbin Ji", "Siddharth Agrawal", "Qiance Tang", "Yvonne Wu"], "title": "Enhancing Spatial Reasoning in Vision-Language Models via Chain-of-Thought Prompting and Reinforcement Learning", "categories": ["cs.CV", "cs.AI", "cs.CL", "I.2.10; I.4.8; I.2.6; I.2.7; I.5.4; I.5.1"], "comment": "10 pages, 5 figures, submitted to a conference (IEEE formate).\n  Authored by students from the Courant Institute, NYU", "summary": "This study investigates the spatial reasoning capabilities of vision-language\nmodels (VLMs) through Chain-of-Thought (CoT) prompting and reinforcement\nlearning. We begin by evaluating the impact of different prompting strategies\nand find that simple CoT formats, where the model generates a reasoning step\nbefore the answer, not only fail to help, but can even harm the model's\noriginal performance. In contrast, structured multi-stage prompting based on\nscene graphs (SceneGraph CoT) significantly improves spatial reasoning\naccuracy. Furthermore, to improve spatial reasoning ability, we fine-tune\nmodels using Group Relative Policy Optimization (GRPO) on the SAT dataset and\nevaluate their performance on CVBench. Compared to supervised fine-tuning\n(SFT), GRPO achieves higher accuracy on Pass@1 evaluations and demonstrates\nsuperior robustness under out-of-distribution (OOD) conditions. In particular,\nwe find that SFT overfits to surface-level linguistic patterns and may degrade\nperformance when test-time phrasing changes (e.g., from \"closer to\" to \"farther\nfrom\"). GRPO, on the other hand, generalizes more reliably and maintains stable\nperformance under such shifts. Our findings provide insights into how\nreinforcement learning and structured prompting improve the spatial reasoning\ncapabilities and generalization behavior of modern VLMs. All code is open\nsource at: https://github.com/Yvonne511/spatial-vlm-investigator", "AI": {"tldr": "The study evaluates spatial reasoning in vision-language models (VLMs) using Chain-of-Thought (CoT) prompting and reinforcement learning, finding structured scene graph-based prompts and GRPO fine-tuning to be more effective.", "motivation": "To improve spatial reasoning capabilities and generalization behavior in vision-language models (VLMs), addressing limitations in reasoning accuracy and robustness under varied conditions.", "method": "The authors used structured multi-stage Chain-of-Thought (CoT) prompts based on scene graphs and employed Group Relative Policy Optimization (GRPO) for fine-tuning on datasets, with performance evaluated under diverse conditions.", "result": "Simple CoT prompting harmed performance but structured scene graph prompting improved accuracy. GRPO fine-tuning outperformed supervised fine-tuning under both accuracy on Pass@1 and robustness to phrasing changes.", "conclusion": "Structured prompting and GRPO fine-tuning enhance spatial reasoning and generalization in VLMs, overcoming issues like overfitting and performance degradation under out-of-distribution conditions."}}
{"id": "2507.13399", "pdf": "https://arxiv.org/pdf/2507.13399", "abs": "https://arxiv.org/abs/2507.13399", "authors": ["Mert Sehri", "Zehui Hua", "Francisco de Assis Boldt", "Patrick Dumond"], "title": "Selective Embedding for Deep Learning", "categories": ["cs.LG"], "comment": null, "summary": "Deep learning has revolutionized many industries by enabling models to\nautomatically learn complex patterns from raw data, reducing dependence on\nmanual feature engineering. However, deep learning algorithms are sensitive to\ninput data, and performance often deteriorates under nonstationary conditions\nand across dissimilar domains, especially when using time-domain data.\nConventional single-channel or parallel multi-source data loading strategies\neither limit generalization or increase computational costs. This study\nintroduces selective embedding, a novel data loading strategy, which alternates\nshort segments of data from multiple sources within a single input channel.\nDrawing inspiration from cognitive psychology, selective embedding mimics\nhuman-like information processing to reduce model overfitting, enhance\ngeneralization, and improve computational efficiency. Validation is conducted\nusing six time-domain datasets, demonstrating that the proposed method\nconsistently achieves high classification accuracy across various deep learning\narchitectures while significantly reducing training times. The approach proves\nparticularly effective for complex systems with multiple data sources, offering\na scalable and resource-efficient solution for real-world applications in\nhealthcare, heavy machinery, marine, railway, and agriculture, where robustness\nand adaptability are critical.", "AI": {"tldr": "The study presents 'selective embedding,' a data-loading strategy for deep learning that merges data from multiple sources in one channel, enhancing model generalization, reducing overfitting, and improving efficiency.", "motivation": "The paper addresses the challenge of deep learning's sensitivity to input data, especially in nonstationary conditions and across varied domains, particularly in time-domain data.", "method": "Selective embedding alternates short data segments from multiple sources within a single input channel, inspired by cognitive psychology.", "result": "The proposed method demonstrates consistent high classification accuracy across six time-domain datasets, reduced training times, and improved adaptability in diverse domains.", "conclusion": "Selective embedding offers a scalable, efficient solution for improving deep learning performance, particularly in domains requiring robustness and adaptability."}}
{"id": "2507.13625", "pdf": "https://arxiv.org/pdf/2507.13625", "abs": "https://arxiv.org/abs/2507.13625", "authors": ["Yuxin Zhang", "Xi Wang", "Mo Hu", "Zhenyu Zhang"], "title": "BifrostRAG: Bridging Dual Knowledge Graphs for Multi-Hop Question Answering in Construction Safety", "categories": ["cs.AI"], "comment": "19 pages, 13 figures", "summary": "Information retrieval and question answering from safety regulations are\nessential for automated construction compliance checking but are hindered by\nthe linguistic and structural complexity of regulatory text. Many\ncompliance-related queries are multi-hop, requiring synthesis of information\nacross interlinked clauses. This poses a challenge for traditional\nretrieval-augmented generation (RAG) systems. To overcome this, we introduce\nBifrostRAG: a dual-graph RAG-integrated system that explicitly models both\nlinguistic relationships (via an Entity Network Graph) and document structure\n(via a Document Navigator Graph). This architecture powers a hybrid retrieval\nmechanism that combines graph traversal with vector-based semantic search,\nenabling large language models to reason over both the meaning and the\nstructure of the text. Evaluation on a multi-hop question dataset shows that\nBifrostRAG achieves 92.8 percent precision, 85.5 percent recall, and an F1\nscore of 87.3 percent. These results significantly outperform vector-only and\ngraph-only RAG baselines that represent current leading approaches. Error\nanalysis further highlights the comparative advantages of our hybrid method\nover single-modality RAGs. These findings establish BifrostRAG as a robust\nknowledge engine for LLM-driven compliance checking. Its dual-graph, hybrid\nretrieval mechanism offers a transferable blueprint for navigating complex\ntechnical documents across knowledge-intensive engineering domains.", "AI": {"tldr": "BifrostRAG is a dual-graph system for automated compliance checking, combining linguistic and structural analysis to achieve superior accuracy in multi-hop question answering.", "motivation": "The paper aims to address challenges in automated compliance checking due to the linguistic and structural complexity of safety regulations, where traditional retrieval-augmented generation systems struggle with multi-hop queries.", "method": "The authors introduce BifrostRAG, which uses a dual-graph approach: an Entity Network Graph for linguistic relationships and a Document Navigator Graph for structural relationships. It integrates graph traversal with vector-based semantic search to enable reasoning over regulatory text.", "result": "BifrostRAG achieves 92.8% precision, 85.5% recall, and 87.3% F1 score on multi-hop question datasets, outperforming current vector-only and graph-only RAG baselines.", "conclusion": "BifrostRAG is a highly effective system for LLM-driven compliance checking, offering a novel dual-graph hybrid retrieval approach that can be extended to other complex technical domains."}}
{"id": "2507.14080", "pdf": "https://arxiv.org/pdf/2507.14080", "abs": "https://arxiv.org/abs/2507.14080", "authors": ["Derek Leung", "Nickolai Zeldovich", "Frans Kaashoek"], "title": "Shipwright: Proving liveness of distributed systems with Byzantine participants", "categories": ["cs.DC", "D.2.4; C.2.4"], "comment": "14 pages, 13 figures", "summary": "Ensuring liveness in a decentralized system, such as PBFT, is critical,\nbecause there may not be any single administrator that can restart the system\nif it encounters a liveness bug. At the same time, liveness is challenging to\nachieve because any single participant could be malicious, and yet the overall\nsystem must make forward progress. While verification is a promising approach\nfor ensuring the absence of bugs, no prior work has been able to verify\nliveness for an executable implementation of PBFT.\n  Shipwright is a verification framework for proving correctness and liveness\nof distributed systems where some participants might be malicious. Shipwright\nintroduces three techniques that enable formal reasoning about decentralized\nsettings with malicious participants, allow developers to decompose their\nsystem and proof in a modular fashion into sub-protocols and sub-proofs, and\nsupport sound reasoning about cryptographic signatures that may be embedded in\nmessages. We used Shipwright to implement and verify an initial prototype of\nagreement on a single log entry in PBFT (with a few limitations) and translate\nit to an executable implementation in Go. We experimentally demonstrate its\noperation and liveness both in the common case and in several failure\nscenarios.", "AI": {"tldr": "Shipwright provides a verification framework enabling the formal validation of liveness and correctness for decentralized systems, specifically executable implementations of PBFT.", "motivation": "Liveness in decentralized systems like PBFT is critical to maintain forward progress despite malicious participants and without centralized control for suspensions. Existing approaches have not been able to verify liveness for PBFT effectively.", "method": "Shipwright introduces modular sub-protocol and sub-proof decomposition, formal reasoning techniques for systems with malicious participants, and sound approaches for cryptographic signature validation.", "result": "An initial prototype of PBFT log agreement was verified and implemented in Go with Shipwright, demonstrating its liveness and operation in normal and failure scenarios.", "conclusion": "Shipwright represents a significant step forward in formally proving liveness and correctness for decentralized systems, particularly PBFT, with modularity and cryptographic reasoning."}}
{"id": "2507.13661", "pdf": "https://arxiv.org/pdf/2507.13661", "abs": "https://arxiv.org/abs/2507.13661", "authors": ["Changwen Li", "Joseph Sifakis", "Rongjie Yan", "Jian Zhang"], "title": "Testing Autonomous Driving Systems -- What Really Matters and What Doesn't", "categories": ["cs.SE"], "comment": null, "summary": "Despite extensive research, the testing of autonomous driving systems (ADS)\nlandscape remains fragmented, and there is currently no basis for an informed\ntechnical assessment of the importance and contribution of the current state of\nthe art. This paper attempts to address this problem by exploring two\ncomplementary aspects.\n  First, it proposes a framework for comparing existing test methods in terms\nof their intrinsic effectiveness and validity. It shows that many methods do\nnot meet both of these requirements. Either because they are based on criteria\nthat do not allow for rapid, inexpensive, and comprehensive detection of\nfailures, or because the degree of validity of the properties tested cannot be\naccurately estimated. In particular, it is shown that most critical test\nmethods do not take into account the nominal operational capabilities of\nautopilots and generate scenarios that are impossible for the tested vehicles\nto handle, resulting in unjustified rejections.\n  Secondly, the paper shows that test effectiveness and validity are highly\ndependent on how autopilots are designed: how they choose between different\ncontrol policies to perform maneuvers, as well as on the reproducibility of the\nresults. In fact, most test methods take for granted two principles underlying\ntraditional methods, but do not generally apply to ADS. We maintain that the\nabsence of rationality and determinacy significantly impairs the effectiveness\nand validity of test methods, and provide test results on eight open\nautopilots, in which most do not satisfy these properties, thereby illustrating\nthis fact.\n  We conclude that under the current state of the art, it is impossible to\nobtain strong enough guarantees for essential autopilot properties and\nrecommend that autopilots be developed with a view to both rationality and\ndeterminacy.", "AI": {"tldr": "This paper identifies critical flaws in current autonomous driving systems (ADS) testing methods and proposes a comparison framework, highlighting the necessity for rationality and determinacy in autopilot design.", "motivation": "The lack of a unified approach to testing ADS hinders a clear technical assessment of existing methods' effectiveness and validity.", "method": "The paper presents a comparative framework for evaluating test methods' effectiveness and investigates autopilot properties like rationality and determinacy.", "result": "Findings reveal that many test methods fail to assess ADS properly because they are either inefficient or invalid, producing unrealistic scenarios or relying on unfounded assumptions.", "conclusion": "Current ADS testing cannot reliably ensure autopilot safety and functionality; thus, future designs should prioritize rationality and determinacy in order to create effective testing mechanisms."}}
{"id": "2507.13647", "pdf": "https://arxiv.org/pdf/2507.13647", "abs": "https://arxiv.org/abs/2507.13647", "authors": ["Minze Li", "Wei Zhao", "Ran Chen", "Mingqiang Wei"], "title": "Improved particle swarm optimization algorithm: multi-target trajectory optimization for swarm drones", "categories": ["cs.RO", "cs.AI"], "comment": "8 papers,7 figures", "summary": "Real-time trajectory planning for unmanned aerial vehicles (UAVs) in dynamic\nenvironments remains a key challenge due to high computational demands and the\nneed for fast, adaptive responses. Traditional Particle Swarm Optimization\n(PSO) methods, while effective for offline planning, often struggle with\npremature convergence and latency in real-time scenarios. To overcome these\nlimitations, we propose PE-PSO, an enhanced PSO-based online trajectory\nplanner. The method introduces a persistent exploration mechanism to preserve\nswarm diversity and an entropy-based parameter adjustment strategy to\ndynamically adapt optimization behavior. UAV trajectories are modeled using\nB-spline curves, which ensure path smoothness while reducing optimization\ncomplexity. To extend this capability to UAV swarms, we develop a multi-agent\nframework that combines genetic algorithm (GA)-based task allocation with\ndistributed PE-PSO, supporting scalable and coordinated trajectory generation.\nThe distributed architecture allows for parallel computation and decentralized\ncontrol, enabling effective cooperation among agents while maintaining\nreal-time performance. Comprehensive simulations demonstrate that the proposed\nframework outperforms conventional PSO and other swarm-based planners across\nseveral metrics, including trajectory quality, energy efficiency, obstacle\navoidance, and computation time. These results confirm the effectiveness and\napplicability of PE-PSO in real-time multi-UAV operations under complex\nenvironmental conditions.", "AI": {"tldr": "This paper introduces PE-PSO, an enhanced real-time trajectory planner for UAVs using improved PSO techniques with a multi-agent framework.", "motivation": "To address the challenges of real-time trajectory planning in UAVs, such as computational demands, premature convergence, and latency in dynamic environments.", "method": "The paper presents PE-PSO with a persistent exploration strategy and entropy-based parameter adjustment. UAV trajectories are modeled with B-splines, and a multi-agent framework combines GA-based task allocation with distributed PE-PSO.", "result": "Simulations show that PE-PSO outperforms traditional PSO and other methods in trajectory quality, energy efficiency, obstacle avoidance, and computational efficiency.", "conclusion": "PE-PSO is effective and scalable for real-time multi-UAV operations, proving its utility in complex environments."}}
{"id": "2507.13390", "pdf": "https://arxiv.org/pdf/2507.13390", "abs": "https://arxiv.org/abs/2507.13390", "authors": ["Kundeshwar Pundalik", "Piyush Sawarkar", "Nihar Sahoo", "Abhishek Shinde", "Prateek Chanda", "Vedant Goswami", "Ajay Nagpal", "Atul Singh", "Viraj Thakur", "Vijay Dewane", "Aamod Thakur", "Bhargav Patel", "Smita Gautam", "Bhagwan Panditi", "Shyam Pawar", "Madhav Kotcha", "Suraj Racha", "Saral Sureka", "Pankaj Singh", "Rishi Bal", "Rohit Saluja", "Ganesh Ramakrishnan"], "title": "PARAM-1 BharatGen 2.9B Model", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have emerged as powerful general-purpose\nreasoning systems, yet their development remains dominated by English-centric\ndata, architectures, and optimization paradigms. This exclusionary design\nresults in structural under-representation of linguistically diverse regions\nsuch as India, where over 20 official languages and 100+ dialects coexist\nalongside phenomena like code-switching and diglossia. We introduce PARAM-1, a\n2.9B parameter decoder-only, text-only language model trained from scratch with\nan explicit architectural and linguistic focus on Indian diversity. PARAM-1 is\ntrained on a bilingual dataset consisting of only Hindi and English,\nconstructed with a strong focus on fact-rich, high-quality content. It is\nguided by three core principles: equitable representation of Indic languages\nthrough a 25% corpus allocation; tokenization fairness via a SentencePiece\ntokenizer adapted to Indian morphological structures; and culturally aligned\nevaluation benchmarks across IndicQA, code-mixed reasoning, and\nsocio-linguistic robustness tasks. By embedding diversity at the pretraining\nlevel-rather than deferring it to post-hoc alignment-PARAM-1 offers a\ndesign-first blueprint for equitable foundation modeling. Our results\ndemonstrate that it serves as both a competent general-purpose model and a\nrobust baseline for India-centric applications.", "AI": {"tldr": "The paper details PARAM-1, a 2.9B parameter language model designed to equitably represent India's linguistic diversity by focusing on bilingual content (Hindi and English) and culturally relevant evaluation benchmarks.", "motivation": "The under-representation of linguistically diverse areas, such as India, in current LLM development motivated the creation of an Indian-focused language model addressing structural linguistic disparities.", "method": "PARAM-1 is a decoder-only, text-only model trained on high-quality bilingual datasets (Hindi and English) with key principles like corpus allocation fairness, tokenization adapted for Indian languages, and culturally relevant evaluation frameworks.", "result": "The model demonstrated competence as a general-purpose system and robustness for India-specific tasks on IndicQA, code-mixed reasoning, and socio-linguistic challenges.", "conclusion": "Embedding linguistic diversity during pretraining establishes PARAM-1 as a benchmark for equitable foundation modeling, showcasing both general-purpose ability and India-centric utility."}}
{"id": "2507.14057", "pdf": "https://arxiv.org/pdf/2507.14057", "abs": "https://arxiv.org/abs/2507.14057", "authors": ["Marcel Hedman", "Desi R. Ivanova", "Cong Guan", "Tom Rainforth"], "title": "Step-DAD: Semi-Amortized Policy-Based Bayesian Experimental Design", "categories": ["stat.ML", "cs.LG"], "comment": "Accepted at Proceedings of the 42nd International Conference on\n  Machine Learning, Vancouver, Canada. PMLR 267, 2025", "summary": "We develop a semi-amortized, policy-based, approach to Bayesian experimental\ndesign (BED) called Stepwise Deep Adaptive Design (Step-DAD). Like existing,\nfully amortized, policy-based BED approaches, Step-DAD trains a design policy\nupfront before the experiment. However, rather than keeping this policy fixed,\nStep-DAD periodically updates it as data is gathered, refining it to the\nparticular experimental instance. This test-time adaptation improves both the\nflexibility and the robustness of the design strategy compared with existing\napproaches. Empirically, Step-DAD consistently demonstrates superior\ndecision-making and robustness compared with current state-of-the-art BED\nmethods.", "AI": {"tldr": "The paper introduces Stepwise Deep Adaptive Design (Step-DAD), a semi-amortized Bayesian experimental design method that outperforms existing methods by adapting design policies during experiments.", "motivation": "To address limitations in fully amortized policy-based approaches in Bayesian experimental design, which lack flexibility and robustness due to fixed pre-trained policies.", "method": "The authors propose Step-DAD, which trains a design policy initially and then adapts and updates it during experimental data collection, improving its alignment with the specific experiment.", "result": "Step-DAD shows consistent superiority in decision-making and robustness compared to state-of-the-art Bayesian experimental design methods in empirical evaluations.", "conclusion": "Step-DAD's adaptive approach leads to improved flexibility, robustness, and performance in Bayesian experimental design."}}
{"id": "2507.13363", "pdf": "https://arxiv.org/pdf/2507.13363", "abs": "https://arxiv.org/abs/2507.13363", "authors": ["Atharv Goel", "Mehar Khurana"], "title": "Just Add Geometry: Gradient-Free Open-Vocabulary 3D Detection Without Human-in-the-Loop", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Modern 3D object detection datasets are constrained by narrow class\ntaxonomies and costly manual annotations, limiting their ability to scale to\nopen-world settings. In contrast, 2D vision-language models trained on\nweb-scale image-text pairs exhibit rich semantic understanding and support\nopen-vocabulary detection via natural language prompts. In this work, we\nleverage the maturity and category diversity of 2D foundation models to perform\nopen-vocabulary 3D object detection without any human-annotated 3D labels.\n  Our pipeline uses a 2D vision-language detector to generate text-conditioned\nproposals, which are segmented with SAM and back-projected into 3D using camera\ngeometry and either LiDAR or monocular pseudo-depth. We introduce a geometric\ninflation strategy based on DBSCAN clustering and Rotating Calipers to infer 3D\nbounding boxes without training. To simulate adverse real-world conditions, we\nconstruct Pseudo-nuScenes, a fog-augmented, RGB-only variant of the nuScenes\ndataset.\n  Experiments demonstrate that our method achieves competitive localization\nperformance across multiple settings, including LiDAR-based and purely RGB-D\ninputs, all while remaining training-free and open-vocabulary. Our results\nhighlight the untapped potential of 2D foundation models for scalable 3D\nperception. We open-source our code and resources at\nhttps://github.com/atharv0goel/open-world-3D-det.", "AI": {"tldr": "This paper introduces a method that uses 2D vision-language models to enable open-vocabulary 3D object detection without requiring any human-annotated 3D labels.", "motivation": "3D object detection datasets typically suffer from limited class taxonomies and expensive annotation processes, which hinder scalability, especially in open-world scenarios. This paper aims to address these limitations by leveraging 2D vision-language models and their robust semantic understanding.", "method": "The authors propose a pipeline where 2D vision-language detectors generate text-conditioned proposals. These are segmented and back-projected into 3D using geometry and either LiDAR or pseudo-depth. A geometric inflation strategy employing DBSCAN clustering and Rotating Calipers is used to estimate 3D bounding boxes without training.", "result": "The method demonstrates competitive localization performance in various settings, such as LiDAR-based and RGB-D inputs, and manages to maintain open-vocabulary functionality. Additionally, it performs robustly under simulated adverse conditions in the Pseudo-nuScenes dataset.", "conclusion": "This work showcases the scalable potential of 2D foundation models in 3D perception tasks, providing a training-free and open-vocabulary approach. The authors make their code and resources publicly available, fostering further exploration."}}
{"id": "2507.13413", "pdf": "https://arxiv.org/pdf/2507.13413", "abs": "https://arxiv.org/abs/2507.13413", "authors": ["Aleksey Lapin", "Igor Hromov", "Stanislav Chumakov", "Mile Mitrovic", "Dmitry Simakov", "Nikolay O. Nikitin", "Andrey V. Savchenko"], "title": "LightAutoDS-Tab: Multi-AutoML Agentic System for Tabular Data", "categories": ["cs.LG"], "comment": "11 pages, 2 figures", "summary": "AutoML has advanced in handling complex tasks using the integration of LLMs,\nyet its efficiency remains limited by dependence on specific underlying tools.\nIn this paper, we introduce LightAutoDS-Tab, a multi-AutoML agentic system for\ntasks with tabular data, which combines an LLM-based code generation with\nseveral AutoML tools. Our approach improves the flexibility and robustness of\npipeline design, outperforming state-of-the-art open-source solutions on\nseveral data science tasks from Kaggle. The code of LightAutoDS-Tab is\navailable in the open repository https://github.com/sb-ai-lab/LADS", "AI": {"tldr": "The paper introduces LightAutoDS-Tab, a system integrating LLM-based code generation with multiple AutoML tools for better performance on tabular data tasks, surpassing current open-source methods.", "motivation": "AutoML systems, despite advancements with LLM integration, still face limitations due to dependency on specific tools. The paper aims to improve flexibility and robustness in handling tabular data tasks.", "method": "The system combines an LLM-driven code generation framework with various AutoML tools, enabling adaptable pipeline designs tailored for tabular data.", "result": "LightAutoDS-Tab outperformed state-of-the-art open-source AutoML solutions in several Kaggle-based data science tasks.", "conclusion": "This multi-agentic AutoML system demonstrates superior adaptability and efficiency, offering a significant step forward in tabular data handling, with its code publicly accessible on GitHub."}}
{"id": "2507.13651", "pdf": "https://arxiv.org/pdf/2507.13651", "abs": "https://arxiv.org/abs/2507.13651", "authors": ["Gerben van der Hoek", "Johan Jeuring", "Rogier Bos"], "title": "Buggy rule diagnosis for combined steps through final answer evaluation in stepwise tasks", "categories": ["cs.AI"], "comment": null, "summary": "Many intelligent tutoring systems can support a student in solving a stepwise\ntask. When a student combines several steps in one step, the number of possible\npaths connecting consecutive inputs may be very large. This combinatorial\nexplosion makes error diagnosis hard. Using a final answer to diagnose a\ncombination of steps can mitigate the combinatorial explosion, because there\nare generally fewer possible (erroneous) final answers than (erroneous)\nsolution paths. An intermediate input for a task can be diagnosed by\nautomatically completing it according to the task solution strategy and\ndiagnosing this solution. This study explores the potential of automated error\ndiagnosis based on a final answer. We investigate the design of a service that\nprovides a buggy rule diagnosis when a student combines several steps. To\nvalidate the approach, we apply the service to an existing dataset (n=1939) of\nunique student steps when solving quadratic equations, which could not be\ndiagnosed by a buggy rule service that tries to connect consecutive inputs with\na single rule. Results show that final answer evaluation can diagnose 29,4% of\nthese steps. Moreover, a comparison of the generated diagnoses with teacher\ndiagnoses on a subset (n=115) shows that the diagnoses align in 97% of the\ncases. These results can be considered a basis for further exploration of the\napproach.", "AI": {"tldr": "The paper investigates a method to diagnose errors in students\u2019 multi-step problem-solving by focusing on their final answers rather than intermediate inputs, achieving high alignment with teacher diagnoses.", "motivation": "To address the challenge of diagnosing students' errors when they combine multiple steps in problem-solving, avoiding the complexity of analyzing numerous solution paths.", "method": "The authors propose and validate an error diagnosis system based on final answers, applying it to a dataset of student steps in solving quadratic equations.", "result": "The system successfully diagnosed errors in 29.4% of previously undiagnosable student steps, and its diagnoses matched expert teacher evaluations in 97% of the tested cases.", "conclusion": "Using final answers for error diagnosis can effectively mitigate combinatorial complexity, providing a promising direction for intelligent tutoring systems."}}
{"id": "2507.13470", "pdf": "https://arxiv.org/pdf/2507.13470", "abs": "https://arxiv.org/abs/2507.13470", "authors": ["Michael Elkin", "Chhaya Trehan"], "title": "Faster Multi-Source Reachability and Approximate Distances via Shortcuts, Hopsets and Matrix Multiplication", "categories": ["cs.DS", "cs.DC"], "comment": null, "summary": "Given an $n$-vertex $m$-edge digraph $G = (V,E)$ and a subset $S \\subseteq V$\nof $|S| = n^{\\sigma}$ (for some $0 \\le \\sigma \\le 1$) designated sources, the\n$S \\times V$ reachability problem is to compute the sets $\\mathcal V_s$ of\nvertices reachable from $s$, for every $s \\in S$. Naive centralized algorithms\nrun BFS/DFS from each source in $O(m \\cdot n^{\\sigma})$ time or compute $G$'s\ntransitive closure in $\\hat O(n^{\\omega})$ time, where $\\omega \\le\n2.371552\\ldots$ is the matrix multiplication exponent. Thus, the best known\nbound is $\\hat O(n^{\\min \\{ 2 + \\sigma, \\omega\\}})$. Leveraging shortcut\nconstructions by Kogan and Parter [SODA 2022, ICALP 2022], we develop a\ncentralized algorithm with running time $\\hat O(n^{1 + \\frac{2}{3}\n\\omega(\\sigma)})$, where $\\omega(\\sigma)$ is the rectangular matrix\nmultiplication exponent. Using current estimates on $\\omega(\\sigma)$, our\nexponent improves upon $\\min \\{2 + \\sigma, \\omega \\}$ for $\\tilde \\sigma \\leq\n\\sigma \\leq 0.53$, where $1/3 < \\tilde \\sigma < 0.3336$ is a universal\nconstant.\n  In a classical result, Cohen [Journal of Algorithms, 1996] devised parallel\nalgorithms for $S \\times V$ reachability on graphs admitting balanced recursive\nseparators of size $n^{\\rho}$ for $\\rho < 1$, requiring polylogarithmic time\nand work $n^{\\max \\{\\omega \\rho, 2\\rho + \\sigma \\} + o(1)}$. We significantly\nimprove, extend, and generalize Cohen's result. First, our parallel algorithm\nfor graphs with small recursive separators has lower work complexity than\nCohen's in boraod paramater ranges. Second, we generalize our algorithm to\ngraphs of treewidth at most $n^{\\rho}$ ($\\rho < 1$) and provide a centralized\nalgorithm that outperforms existing bounds for $S \\times V$ reachability on\nsuch graphs. We also do this for some other graph familes with small\nseparators. Finally, we extend these results to $(1 + \\epsilon)$-approximate\ndistance computation.", "AI": {"tldr": "This paper develops new algorithms for the $S \\times V$ reachability problem in directed graphs, achieving improved time complexity for both centralized and parallel models, particularly in graphs with small separators or specific properties.", "motivation": "The goal is to improve upon existing algorithms for solving the $S \\times V$ reachability problem, which is crucial in graph analysis and many applications, and to address the inefficiencies in both traditional and parallel approaches.", "method": "The authors leverage shortcut constructions from previous works and rectangular matrix multiplication techniques to achieve better time complexity in centralized models. For parallel algorithms, they optimize work complexity for graphs with small separators or bounded treewidth, and generalize their methods to various graph families and approximate distance computations.", "result": "The proposed centralized algorithm achieves running time improvements for certain parameter ranges ($\\sigma$). The parallel algorithm similarly reduces work complexity in broader cases compared to existing results, and the authors extend their methods to graphs with treewidth and small separators, along with approximate distance computations.", "conclusion": "The paper presents a significant improvement in the efficiency of $S \\times V$ reachability computation, advancing existing bounds and extending methods to diverse graph families and approximate problems, with applications for both centralized and parallel settings."}}
{"id": "2507.13635", "pdf": "https://arxiv.org/pdf/2507.13635", "abs": "https://arxiv.org/abs/2507.13635", "authors": ["Nengkun Yu", "Jens Palsberg", "Thomas Reps"], "title": "SAQR-QC: A Logic for Scalable but Approximate Quantitative Reasoning about Quantum Circuits", "categories": ["quant-ph", "cs.LO", "cs.PL"], "comment": "Comments are welcome", "summary": "Reasoning about quantum programs remains a fundamental challenge, regardless\nof the programming model or computational paradigm. Despite extensive research,\nexisting verification techniques are insufficient--even for quantum circuits, a\ndeliberately restricted model that lacks classical control, but still underpins\nmany current quantum algorithms. Many existing formal methods require\nexponential time and space to represent and manipulate (representations of)\nassertions and judgments, making them impractical for quantum circuits with\nmany qubits. This paper presents a logic for reasoning in such settings, called\nSAQR-QC. The logic supports Scalable but Approximate Quantitative Reasoning\nabout Quantum Circuits, whence the name. SAQR-QC has three characteristics: (i)\nsome (deliberate) loss of precision is built into it; (ii) it has a mechanism\nto help the accumulated loss of precision during a sequence of reasoning steps\nremain small; and (iii) most importantly, to make reasoning scalable, all\nreasoning steps are local--i.e., they each involve just a small number of\nqubits. We demonstrate the effectiveness of SAQR-QC via two case studies: the\nverification of GHZ circuits involving non-Clifford gates, and the analysis of\nquantum phase estimation--a core subroutine in Shor's factoring algorithm.", "AI": {"tldr": "This paper introduces SAQR-QC, a logic for scalable and approximate quantitative reasoning about quantum circuits, using local reasoning steps to manage complexity and precision loss.", "motivation": "Existing quantum program verification techniques are computationally expensive and impractical, particularly for quantum circuits with many qubits.", "method": "The paper presents SAQR-QC, a logic that allows scalable reasoning with controlled precision loss, using local reasoning involving a small number of qubits at each step.", "result": "The SAQR-QC logic was successfully demonstrated through case studies, including the verification of GHZ circuits and analysis of quantum phase estimation.", "conclusion": "SAQR-QC makes reasoning about quantum circuits scalable and practical by balancing precision and computational requirements, marking a step forward in quantum program verification."}}
{"id": "2507.13650", "pdf": "https://arxiv.org/pdf/2507.13650", "abs": "https://arxiv.org/abs/2507.13650", "authors": ["Yu-Ting Lai", "Yasamin Foroutani", "Aya Barzelay", "Tsu-Chin Tsao"], "title": "Safe Robotic Capsule Cleaning with Integrated Transpupillary and Intraocular Optical Coherence Tomography", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "12 pages, 27 figures", "summary": "Secondary cataract is one of the most common complications of vision loss due\nto the proliferation of residual lens materials that naturally grow on the lens\ncapsule after cataract surgery. A potential treatment is capsule cleaning, a\nsurgical procedure that requires enhanced visualization of the entire capsule\nand tool manipulation on the thin membrane. This article presents a robotic\nsystem capable of performing the capsule cleaning procedure by integrating a\nstandard transpupillary and an intraocular optical coherence tomography probe\non a surgical instrument for equatorial capsule visualization and real-time\ntool-to-tissue distance feedback. Using robot precision, the developed system\nenables complete capsule mapping in the pupillary and equatorial regions with\nin-situ calibration of refractive index and fiber offset, which are still\ncurrent challenges in obtaining an accurate capsule model. To demonstrate\neffectiveness, the capsule mapping strategy was validated through five\nexperimental trials on an eye phantom that showed reduced root-mean-square\nerrors in the constructed capsule model, while the cleaning strategy was\nperformed in three ex-vivo pig eyes without tissue damage.", "AI": {"tldr": "The paper introduces a robotic system to perform capsule cleaning to address secondary cataract complications, focusing on improved visualization and precision.", "motivation": "To manage secondary cataract complications and improve the precision and safety of capsule cleaning procedures by overcoming visualization challenges.", "method": "The system integrates a transpupillary optical coherence tomography probe and robotic precision for real-time capsule mapping and tool-to-tissue distance feedback, combined with in-situ calibration of refractive index and fiber offset.", "result": "Experimental trials on an eye phantom showed reduced errors in capsule modeling, and trials on ex-vivo pig eyes demonstrated effective cleaning without tissue damage.", "conclusion": "The robotic system provides a novel, safe, and accurate solution for capsule cleaning in secondary cataract treatments, offering enhanced visualization and precision."}}
{"id": "2507.13392", "pdf": "https://arxiv.org/pdf/2507.13392", "abs": "https://arxiv.org/abs/2507.13392", "authors": ["Emil H\u00e4glund", "Johanna Bj\u00f6rklund"], "title": "TopicImpact: Improving Customer Feedback Analysis with Opinion Units for Topic Modeling and Star-Rating Prediction", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We improve the extraction of insights from customer reviews by restructuring\nthe topic modelling pipeline to operate on opinion units - distinct statements\nthat include relevant text excerpts and associated sentiment scores. Prior work\nhas demonstrated that such units can be reliably extracted using large language\nmodels. The result is a heightened performance of the subsequent topic\nmodeling, leading to coherent and interpretable topics while also capturing the\nsentiment associated with each topic. By correlating the topics and sentiments\nwith business metrics, such as star ratings, we can gain insights on how\nspecific customer concerns impact business outcomes. We present our system's\nimplementation, use cases, and advantages over other topic modeling and\nclassification solutions. We also evaluate its effectiveness in creating\ncoherent topics and assess methods for integrating topic and sentiment\nmodalities for accurate star-rating prediction.", "AI": {"tldr": "The paper introduces a method to improve topic modeling by focusing on opinion units that carry sentiment, enhancing interpretability and aligning with business metrics.", "motivation": "To enhance the insight extraction process from customer reviews by improving topic modeling and associating it with sentiment and business outcomes.", "method": "The researchers restructured the topic modeling pipeline to operate on opinion units that combine relevant excerpts with sentiment scores, leveraging large language models for reliable extraction.", "result": "The method achieved more coherent and interpretable topics, successfully correlated sentiment with topics, and demonstrated predictive power for star-rating outcomes.", "conclusion": "Restructuring topic modeling to include opinion units leads to superior insights, clear topics, and a direct connection to business ratings and outcomes."}}
{"id": "2507.13704", "pdf": "https://arxiv.org/pdf/2507.13704", "abs": "https://arxiv.org/abs/2507.13704", "authors": ["Anabel Yong", "Austin Tripp", "Layla Hosseini-Gerami", "Brooks Paige"], "title": "Bayesian Optimization for Molecules Should Be Pareto-Aware", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Multi-objective Bayesian optimization (MOBO) provides a principled framework\nfor navigating trade-offs in molecular design. However, its empirical\nadvantages over scalarized alternatives remain underexplored. We benchmark a\nsimple Pareto-based MOBO strategy -- Expected Hypervolume Improvement (EHVI) --\nagainst a simple fixed-weight scalarized baseline using Expected Improvement\n(EI), under a tightly controlled setup with identical Gaussian Process\nsurrogates and molecular representations. Across three molecular optimization\ntasks, EHVI consistently outperforms scalarized EI in terms of Pareto front\ncoverage, convergence speed, and chemical diversity. While scalarization\nencompasses flexible variants -- including random or adaptive schemes -- our\nresults show that even strong deterministic instantiations can underperform in\nlow-data regimes. These findings offer concrete evidence for the practical\nadvantages of Pareto-aware acquisition in de novo molecular optimization,\nespecially when evaluation budgets are limited and trade-offs are nontrivial.", "AI": {"tldr": "This paper benchmarks a Pareto-based multi-objective Bayesian optimization approach against scalarized methods, demonstrating EHVI's superior performance in molecular design tasks.", "motivation": "To evaluate the empirical advantages of Pareto-based multi-objective optimization techniques over scalarized alternatives in molecular optimization.", "method": "The study uses a controlled experimental setup with identical Gaussian Process surrogates and molecular representations to compare EHVI (Pareto-based) and EI (scalarized baseline).", "result": "EHVI outperforms scalarized EI in terms of Pareto front coverage, convergence speed, and chemical diversity across three molecular optimization tasks.", "conclusion": "Pareto-aware strategies like EHVI are more effective in low-data regimes and scenarios with complex trade-offs, highlighting their practical value in molecular optimization."}}
{"id": "2507.13364", "pdf": "https://arxiv.org/pdf/2507.13364", "abs": "https://arxiv.org/abs/2507.13364", "authors": ["Siddharth Srivastava", "Gaurav Sharma"], "title": "OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We present a novel multimodal multitask network and associated training\nalgorithm. The method is capable of ingesting data from approximately 12\ndifferent modalities namely image, video, audio, text, depth, point cloud, time\nseries, tabular, graph, X-ray, infrared, IMU, and hyperspectral. The proposed\napproach utilizes modality specialized tokenizers, a shared transformer\narchitecture, and cross-attention mechanisms to project the data from different\nmodalities into a unified embedding space. It addresses multimodal and\nmultitask scenarios by incorporating modality-specific task heads for different\ntasks in respective modalities. We propose a novel pretraining strategy with\niterative modality switching to initialize the network, and a training\nalgorithm which trades off fully joint training over all modalities, with\ntraining on pairs of modalities at a time. We provide comprehensive evaluation\nacross 25 datasets from 12 modalities and show state of the art performances,\ndemonstrating the effectiveness of the proposed architecture, pretraining\nstrategy and adapted multitask training.", "AI": {"tldr": "The paper introduces a new multimodal multitask network capable of processing up to 12 different data modalities, achieving state-of-the-art results across diverse datasets using a novel architecture and training strategy.", "motivation": "To address the challenge of processing and learning from diverse data modalities simultaneously for complex, multimodal, and multitask scenarios.", "method": "The approach combines modality-specific tokenizers, a shared transformer architecture, and cross-attention mechanisms. It introduces a new pretraining strategy with iterative modality switching and a training algorithm balancing joint and pairwise modality training.", "result": "The network achieves state-of-the-art performance on 25 datasets across 12 modalities, validating its architecture, pretraining, and training strategies.", "conclusion": "The novel multimodal multitask approach successfully integrates data from various modalities into a unified system, showcasing enhanced performance across diverse tasks and datasets."}}
{"id": "2507.13414", "pdf": "https://arxiv.org/pdf/2507.13414", "abs": "https://arxiv.org/abs/2507.13414", "authors": ["Alexander Strunk", "Roland Assam"], "title": "Gauge Flow Models", "categories": ["cs.LG", "cs.AI", "math.DG"], "comment": null, "summary": "This paper introduces Gauge Flow Models, a novel class of Generative Flow\nModels. These models incorporate a learnable Gauge Field within the Flow\nOrdinary Differential Equation (ODE). A comprehensive mathematical framework\nfor these models, detailing their construction and properties, is provided.\nExperiments using Flow Matching on Gaussian Mixture Models demonstrate that\nGauge Flow Models yields significantly better performance than traditional Flow\nModels of comparable or even larger size. Additionally, unpublished research\nindicates a potential for enhanced performance across a broader range of\ngenerative tasks.", "AI": {"tldr": "The paper proposes Gauge Flow Models, a new type of Generative Flow Models, which outperform traditional Flow Models in certain tasks.", "motivation": "The motivation is to improve the performance of Generative Flow Models by introducing a learnable Gauge Field to the Flow ODE framework.", "method": "The authors incorporated a learnable Gauge Field into the Flow Ordinary Differential Equation (ODE) and provided a mathematical framework for the construction and properties of these models.", "result": "In experiments on Gaussian Mixture Models using Flow Matching, Gauge Flow Models showed superior performance compared to traditional models of similar or larger sizes. Unpublished research suggests broader potential.", "conclusion": "Gauge Flow Models enhance generative modeling tasks and may offer improvements across various applications, supported by theoretical and experimental validation."}}
{"id": "2507.13652", "pdf": "https://arxiv.org/pdf/2507.13652", "abs": "https://arxiv.org/abs/2507.13652", "authors": ["Gerben van der Hoek", "Johan Jeuring", "Rogier Bos"], "title": "Combining model tracing and constraint-based modeling for multistep strategy diagnoses", "categories": ["cs.AI"], "comment": null, "summary": "Model tracing and constraint-based modeling are two approaches to diagnose\nstudent input in stepwise tasks. Model tracing supports identifying consecutive\nproblem-solving steps taken by a student, whereas constraint-based modeling\nsupports student input diagnosis even when several steps are combined into one\nstep. We propose an approach that merges both paradigms. By defining\nconstraints as properties that a student input has in common with a step of a\nstrategy, it is possible to provide a diagnosis when a student deviates from a\nstrategy even when the student combines several steps. In this study we explore\nthe design of a system for multistep strategy diagnoses, and evaluate these\ndiagnoses. As a proof of concept, we generate diagnoses for an existing dataset\ncontaining steps students take when solving quadratic equations (n=2136). To\ncompare with human diagnoses, two teachers coded a random sample of deviations\n(n=70) and applications of the strategy (n=70). Results show that that the\nsystem diagnosis aligned with the teacher coding in all of the 140 student\nsteps.", "AI": {"tldr": "The study merges model tracing with constraint-based modeling for diagnosing multistep strategies in student problem-solving, validated against teacher-coded diagnoses.", "motivation": "Existing approaches struggle to accurately diagnose student steps in multistep problem-solving scenarios.", "method": "Combining model tracing and constraint-based modeling, defining constraints linked to specific strategies, and evaluating the framework using a dataset of student steps solving quadratic equations.", "result": "The system successfully aligns its diagnoses with teacher coding in all analyzed student steps, validating its effectiveness.", "conclusion": "The merged approach demonstrates potential for improving multistep strategy diagnoses in educational contexts and aligning closely with expert human judgments."}}
{"id": "2507.13624", "pdf": "https://arxiv.org/pdf/2507.13624", "abs": "https://arxiv.org/abs/2507.13624", "authors": ["Daniel Commey", "Kamel Abbad", "Garth V. Crosby", "Lyes Khoukhi"], "title": "FedSkipTwin: Digital-Twin-Guided Client Skipping for Communication-Efficient Federated Learning", "categories": ["cs.LG", "cs.DC", "cs.NI"], "comment": null, "summary": "Communication overhead remains a primary bottleneck in federated learning\n(FL), particularly for applications involving mobile and IoT devices with\nconstrained bandwidth. This work introduces FedSkipTwin, a novel\nclient-skipping algorithm driven by lightweight, server-side digital twins.\nEach twin, implemented as a simple LSTM, observes a client's historical\nsequence of gradient norms to forecast both the magnitude and the epistemic\nuncertainty of its next update. The server leverages these predictions,\nrequesting communication only when either value exceeds a predefined threshold;\notherwise, it instructs the client to skip the round, thereby saving bandwidth.\nExperiments are conducted on the UCI-HAR and MNIST datasets with 10 clients\nunder a non-IID data distribution. The results demonstrate that FedSkipTwin\nreduces total communication by 12-15.5% across 20 rounds while simultaneously\nimproving final model accuracy by up to 0.5 percentage points compared to the\nstandard FedAvg algorithm. These findings establish that prediction-guided\nskipping is a practical and effective strategy for resource-aware FL in\nbandwidth-constrained edge environments.", "AI": {"tldr": "This paper proposes FedSkipTwin, a technique using digital twin models to predict which clients can skip communication rounds in federated learning, reducing bandwidth use while improving model accuracy.", "motivation": "The authors aim to address the communication overhead faced in federated learning, particularly for mobile and IoT devices with limited bandwidth.", "method": "FedSkipTwin uses lightweight server-side LSTM digital twins to predict gradient norm magnitude and uncertainty, enabling selective communication rounds with clients.", "result": "FedSkipTwin decreased communication overhead by 12-15.5% across 20 rounds while boosting model accuracy by up to 0.5 percentage points using UCI-HAR and MNIST datasets.", "conclusion": "FedSkipTwin is a practical and effective method for reducing communication costs and improving accuracy in bandwidth-constrained federated learning environments."}}
{"id": "2507.13654", "pdf": "https://arxiv.org/pdf/2507.13654", "abs": "https://arxiv.org/abs/2507.13654", "authors": ["Haoran Wang", "Yasamin Foroutani", "Matthew Nepo", "Mercedes Rodriguez", "Ji Ma", "Jean-Pierre Hubschman", "Tsu-Chin Tsao", "Jacob Rosen"], "title": "A Study of Teleoperation Methods in a Simulated Virtual Eye Surgery Environment", "categories": ["cs.RO"], "comment": "9 pages, 11 figures", "summary": "This paper examines the performance of Inside and Outside Control modes at\nvarious scaling factors in a simulated vitreoretinal surgical setting. The\nIRISS teleoperated surgical system's console (cockpit) was adapted to project a\nsimulated microscope view of an intraocular setup to a virtual reality (VR)\nheadset. Five experienced vitreoretinal surgeons and five engineers with no\nsurgical experience used the system to perform tasks common to vitreoretinal\nsurgery. Experimental results indicate that Inside Control methods at higher\nscaling factors (20 or 30) achieved the best performance overall, though the\noptimal scaling factor may vary by task and complexity. Optimizing control\nmethods and scaling factors could lead to improvements in surgical efficiency\nand accuracy, as well as minimize risks in future robotic-assisted intraocular\nprocedures.", "AI": {"tldr": "This study explores the performance of different control modes and scaling factors in a robotic vitreoretinal surgery simulation, highlighting the benefits of Inside Control at higher scaling for efficiency and accuracy.", "motivation": "To assess how different control modes and scaling factors impact performance in robotic-assisted vitreoretinal surgery to improve surgical efficiency, accuracy, and reduce risks.", "method": "Using the IRISS system's console adapted to a VR headset, experienced surgeons and engineers completed simulated intraocular tasks at varying control modes and scaling factors.", "result": "Inside Control methods at higher scaling factors (20 or 30) yielded the best overall performance, although the optimal scaling depended on the specific task and complexity.", "conclusion": "Optimizing control methods and scaling factors can significantly enhance surgical efficiency and accuracy, contributing to safer robotic-assisted intraocular procedures in the future."}}
{"id": "2507.13395", "pdf": "https://arxiv.org/pdf/2507.13395", "abs": "https://arxiv.org/abs/2507.13395", "authors": ["Xuanqi Gao", "Weipeng Jiang", "Juan Zhai", "Shiqing Ma", "Siyi Xie", "Xinyang Yin", "Chao Shen"], "title": "Mitigating Stylistic Biases of Machine Translation Systems via Monolingual Corpora Only", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The advent of neural machine translation (NMT) has revolutionized\ncross-lingual communication, yet preserving stylistic nuances remains a\nsignificant challenge. While existing approaches often require parallel corpora\nfor style preservation, we introduce Babel, a novel framework that enhances\nstylistic fidelity in NMT using only monolingual corpora. Babel employs two key\ncomponents: (1) a style detector based on contextual embeddings that identifies\nstylistic disparities between source and target texts, and (2) a\ndiffusion-based style applicator that rectifies stylistic inconsistencies while\nmaintaining semantic integrity. Our framework integrates with existing NMT\nsystems as a post-processing module, enabling style-aware translation without\nrequiring architectural modifications or parallel stylistic data. Extensive\nexperiments on five diverse domains (law, literature, scientific writing,\nmedicine, and educational content) demonstrate Babel's effectiveness: it\nidentifies stylistic inconsistencies with 88.21% precision and improves\nstylistic preservation by 150% while maintaining a high semantic similarity\nscore of 0.92. Human evaluation confirms that translations refined by Babel\nbetter preserve source text style while maintaining fluency and adequacy.", "AI": {"tldr": "The paper introduces Babel, a system enhancing stylistic fidelity in neural machine translation (NMT) using monolingual corpora, achieving significant improvements in style preservation and semantic consistency.", "motivation": "While neural machine translation achieves cross-lingual communication, maintaining stylistic nuances remains a problem. Existing solutions depend on parallel corpora for style preservation, which limits their practicality.", "method": "The authors propose Babel, a framework with two major components: (1) a style detector utilizing contextual embeddings to identify stylistic disparities and (2) a diffusion-based applicator that remedies these inconsistencies. Babel operates as a post-processing unit for existing NMT systems, requiring no architectural changes or parallel data.", "result": "Babel achieves 88.21% precision in identifying stylistic mismatches, improves stylistic preservation by 150%, and maintains a high semantic similarity score of 0.92 across various domains.", "conclusion": "Babel successfully enhances style-aware translations for neural machine translation, allowing for improved stylistic fidelity without requiring parallel corpora, making it highly adaptable and effective in diverse applications."}}
{"id": "2507.13902", "pdf": "https://arxiv.org/pdf/2507.13902", "abs": "https://arxiv.org/abs/2507.13902", "authors": ["Emanuel Str\u00f6m", "Anna-Karin Tornberg", "Ozan \u00d6ktem"], "title": "Deep Micro Solvers for Rough-Wall Stokes Flow in a Heterogeneous Multiscale Method", "categories": ["math.NA", "cs.NA", "stat.ML", "65N55 (Primary) 65R20, 68T99, 76D07 (Secondary)"], "comment": null, "summary": "We propose a learned precomputation for the heterogeneous multiscale method\n(HMM) for rough-wall Stokes flow. A Fourier neural operator is used to\napproximate local averages over microscopic subsets of the flow, which allows\nto compute an effective slip length of the fluid away from the roughness. The\nnetwork is designed to map from the local wall geometry to the Riesz\nrepresentors for the corresponding local flow averages. With such a\nparameterisation, the network only depends on the local wall geometry and as\nsuch can be trained independent of boundary conditions. We perform a detailed\ntheoretical analysis of the statistical error propagation, and prove that under\nsuitable regularity and scaling assumptions, a bounded training loss leads to a\nbounded error in the resulting macroscopic flow. We then demonstrate on a\nfamily of test problems that the learned precomputation performs stably with\nrespect to the scale of the roughness. The accuracy in the HMM solution for the\nmacroscopic flow is comparable to when the local (micro) problems are solved\nusing a classical approach, while the computational cost of solving the micro\nproblems is significantly reduced.", "AI": {"tldr": "This paper proposes a Fourier neural operator-based method to efficiently compute effective slip lengths in rough-wall Stokes flow using learned precomputation within the heterogeneous multiscale method (HMM).", "motivation": "To address the computational challenges of solving microscopic flow problems repetitively in heterogeneous multiscale methods (HMM) for rough-wall Stokes flow.", "method": "The authors utilize a Fourier neural operator to approximate local averages of microscopic flow, correlating the local wall geometry with Riesz representors, enabling geometry-dependent training independent of boundary conditions.", "result": "The proposed approach achieves reduced computational costs for solving micro-level flow problems while maintaining accuracy comparable to classical methods. A theoretical analysis confirms bounded error propagation based on the training loss.", "conclusion": "The technique provides an efficient and accurate way to simulate macroscopic flow for rough surfaces, demonstrating computational scalability and effectiveness in HMM applications."}}
{"id": "2507.13371", "pdf": "https://arxiv.org/pdf/2507.13371", "abs": "https://arxiv.org/abs/2507.13371", "authors": ["Yeming Cai", "Yang Wang", "Zhenglin Li"], "title": "Transformer-Based Framework for Motion Capture Denoising and Anomaly Detection in Medical Rehabilitation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This paper proposes an end-to-end deep learning framework integrating optical\nmotion capture with a Transformer-based model to enhance medical\nrehabilitation. It tackles data noise and missing data caused by occlusion and\nenvironmental factors, while detecting abnormal movements in real time to\nensure patient safety. Utilizing temporal sequence modeling, our framework\ndenoises and completes motion capture data, improving robustness. Evaluations\non stroke and orthopedic rehabilitation datasets show superior performance in\ndata reconstruction and anomaly detection, providing a scalable, cost-effective\nsolution for remote rehabilitation with reduced on-site supervision.", "AI": {"tldr": "The paper introduces a deep learning framework leveraging optical motion capture and a Transformer-based model to improve medical rehabilitation by addressing data noise, occlusion, and anomaly detection.", "motivation": "To enhance medical rehabilitation through improved data handling and anomaly detection using motion capture and deep learning.", "method": "The framework employs temporal sequence modeling with a Transformer-based design to denoise and complete motion capture data.", "result": "Tests on stroke and orthopedic rehabilitation datasets showcased the framework's superior data reconstruction and anomaly detection capabilities.", "conclusion": "The approach offers a robust, scalable, and cost-effective solution to enhance remote rehabilitation with diminishing need for onsite supervision."}}
{"id": "2507.13416", "pdf": "https://arxiv.org/pdf/2507.13416", "abs": "https://arxiv.org/abs/2507.13416", "authors": ["Jiaxiang Yi", "Bernardo P. Ferreira", "Miguel A. Bessa"], "title": "Single- to multi-fidelity history-dependent learning with uncertainty quantification and disentanglement: application to data-driven constitutive modeling", "categories": ["cs.LG", "cs.AI"], "comment": "40 pages, 32 figures", "summary": "Data-driven learning is generalized to consider history-dependent\nmulti-fidelity data, while quantifying epistemic uncertainty and disentangling\nit from data noise (aleatoric uncertainty). This generalization is hierarchical\nand adapts to different learning scenarios: from training the simplest\nsingle-fidelity deterministic neural networks up to the proposed multi-fidelity\nvariance estimation Bayesian recurrent neural networks. The versatility and\ngenerality of the proposed methodology are demonstrated by applying it to\ndifferent data-driven constitutive modeling scenarios that include multiple\nfidelities with and without aleatoric uncertainty (noise). The method\naccurately predicts the response and quantifies model error while also\ndiscovering the noise distribution (when present). This opens opportunities for\nfuture real-world applications in diverse scientific and engineering domains;\nespecially, the most challenging cases involving design and analysis under\nuncertainty.", "AI": {"tldr": "The paper introduces a generalized data-driven method that combines history-dependent multi-fidelity data and disentangles epistemic and aleatoric uncertainty.", "motivation": "The motivation is to develop a versatile methodology that addresses challenges in data-driven learning, particularly to work with multi-fidelity data under uncertainty and improve predictions in complex scenarios.", "method": "The authors propose hierarchical adaptations ranging from single-fidelity deterministic neural networks to multi-fidelity Bayesian recurrent neural networks for variance estimation.", "result": "The method is applied successfully to various constitutive modeling scenarios, accurately predicting responses, quantifying model errors, and discovering noise distributions where present.", "conclusion": "This approach opens possibilities for tackling real-world applications in scientific and engineering areas, especially under uncertainty-driven conditions."}}
{"id": "2507.13737", "pdf": "https://arxiv.org/pdf/2507.13737", "abs": "https://arxiv.org/abs/2507.13737", "authors": ["Ye Tian", "Xiaoyuan Ren", "Zihao Wang", "Onat Gungor", "Xiaofan Yu", "Tajana Rosing"], "title": "DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.MM"], "comment": null, "summary": "Rich and context-aware activity logs facilitate user behavior analysis and\nhealth monitoring, making them a key research focus in ubiquitous computing.\nThe remarkable semantic understanding and generation capabilities of Large\nLanguage Models (LLMs) have recently created new opportunities for activity log\ngeneration. However, existing methods continue to exhibit notable limitations\nin terms of accuracy, efficiency, and semantic richness. To address these\nchallenges, we propose DailyLLM. To the best of our knowledge, this is the\nfirst log generation and summarization system that comprehensively integrates\ncontextual activity information across four dimensions: location, motion,\nenvironment, and physiology, using only sensors commonly available on\nsmartphones and smartwatches. To achieve this, DailyLLM introduces a\nlightweight LLM-based framework that integrates structured prompting with\nefficient feature extraction to enable high-level activity understanding.\nExtensive experiments demonstrate that DailyLLM outperforms state-of-the-art\n(SOTA) log generation methods and can be efficiently deployed on personal\ncomputers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM\nachieves a 17% improvement in log generation BERTScore precision compared to\nthe 70B-parameter SOTA baseline, while delivering nearly 10x faster inference\nspeed.", "AI": {"tldr": "The paper presents DailyLLM, a lightweight activity log generation and summarization system leveraging smartphones and smartwatches for accurate and semantically rich user behavior analysis.", "motivation": "Existing activity log generation systems lack accuracy, efficiency, and semantic richness, prompting the need for a more advanced and precise system.", "method": "DailyLLM integrates contextual activity information across four dimensions using smartphone and smartwatch sensors and employs a lightweight LLM framework with structured prompting and efficient feature extraction.", "result": "DailyLLM surpasses current methods, improving BERTScore precision by 17% over a 70B-parameter baseline while being 10x faster using a 1.5B-parameter LLM model.", "conclusion": "The proposed system provides a scalable, efficient, and semantically rich solution for activity log generation and demonstrates significant improvements over existing methods."}}
{"id": "2507.13720", "pdf": "https://arxiv.org/pdf/2507.13720", "abs": "https://arxiv.org/abs/2507.13720", "authors": ["Saurav Ghosh"], "title": "Quantum Blockchain Survey: Foundations, Trends, and Gaps", "categories": ["cs.CR", "cs.DC", "cs.ET", "cs.NI", "68M10, 81P94, 94A60 68M10, 81P94, 94A60 68M10, 81P94, 94A60", "C.2.1; E.3; K.6.5"], "comment": "12 Pages, 4 figures", "summary": "Quantum computing poses fundamental risks to classical blockchain systems by\nundermining widely used cryptographic primitives. In response, two major\nresearch directions have emerged: post-quantum blockchains, which integrate\nquantum-resistant algorithms, and quantum blockchains, which leverage quantum\nproperties such as entanglement and quantum key distribution. This survey\nreviews key developments in both areas, analyzing their cryptographic\nfoundations, architectural designs, and implementation challenges. This work\nprovides a comparative overview of technical proposals, highlight trade-offs in\nsecurity, scalability, and deployment, and identify open research problems\nacross hardware, consensus, and network design. The goal is to offer a\nstructured and comprehensive reference for advancing secure blockchain systems\nin the quantum era.", "AI": {"tldr": "This paper surveys post-quantum and quantum blockchains, analyzing cryptographic mechanisms, architecture, and their challenges.", "motivation": "Quantum computing poses significant risks to classical blockchain systems by weakening current cryptographic primitives.", "method": "The paper reviews developments in post-quantum and quantum blockchains, comparing security, scalability, and deployment trade-offs.", "result": "Key technical proposals for blockchain adaptation to the quantum era are summarized, along with unresolved issues in hardware and network design.", "conclusion": "A structured reference is provided to guide research in creating blockchain systems resilient to quantum threats."}}
{"id": "2507.13662", "pdf": "https://arxiv.org/pdf/2507.13662", "abs": "https://arxiv.org/abs/2507.13662", "authors": ["Jing Cheng", "Yasser G. Alqaham", "Zhenyu Gan", "Amit K. Sanyal"], "title": "Iteratively Learning Muscle Memory for Legged Robots to Master Adaptive and High Precision Locomotion", "categories": ["cs.RO"], "comment": null, "summary": "This paper presents a scalable and adaptive control framework for legged\nrobots that integrates Iterative Learning Control (ILC) with a biologically\ninspired torque library (TL), analogous to muscle memory. The proposed method\naddresses key challenges in robotic locomotion, including accurate trajectory\ntracking under unmodeled dynamics and external disturbances. By leveraging the\nrepetitive nature of periodic gaits and extending ILC to nonperiodic tasks, the\nframework enhances accuracy and generalization across diverse locomotion\nscenarios. The control architecture is data-enabled, combining a physics-based\nmodel derived from hybrid-system trajectory optimization with real-time\nlearning to compensate for model uncertainties and external disturbances. A\ncentral contribution is the development of a generalized TL that stores learned\ncontrol profiles and enables rapid adaptation to changes in speed, terrain, and\ngravitational conditions-eliminating the need for repeated learning and\nsignificantly reducing online computation. The approach is validated on the\nbipedal robot Cassie and the quadrupedal robot A1 through extensive simulations\nand hardware experiments. Results demonstrate that the proposed framework\nreduces joint tracking errors by up to 85% within a few seconds and enables\nreliable execution of both periodic and nonperiodic gaits, including slope\ntraversal and terrain adaptation. Compared to state-of-the-art whole-body\ncontrollers, the learned skills eliminate the need for online computation\nduring execution and achieve control update rates exceeding 30x those of\nexisting methods. These findings highlight the effectiveness of integrating ILC\nwith torque memory as a highly data-efficient and practical solution for legged\nlocomotion in unstructured and dynamic environments.", "AI": {"tldr": "This paper proposes a scalable control method for legged robots, integrating Iterative Learning Control with a torque library to improve locomotion across diverse tasks and environments.", "motivation": "Challenges in robotic locomotion include trajectory tracking under changing conditions, unmodeled dynamics, and external disturbances. A framework integrating learning and biological inspiration improves adaptability.", "method": "The paper combines Iterative Learning Control and a torque library for accurate trajectory tracking, leveraging periodic gaits and extending learning to nonperiodic tasks. It integrates physics-based models with real-time learning.", "result": "Experimental validation on robots Cassie (bipedal) and A1 (quadrupedal) shows reduced joint tracking errors up to 85%, fast adaptability, and robust locomotion in difficult terrains.", "conclusion": "Integrating learning with muscle-memory-inspired controls offers efficient, adaptive solutions for robotic locomotion, outperforming state-of-the-art methods in accuracy and computational efficiency."}}
{"id": "2507.13410", "pdf": "https://arxiv.org/pdf/2507.13410", "abs": "https://arxiv.org/abs/2507.13410", "authors": ["Cheng-Ting Chou", "George Liu", "Jessica Sun", "Cole Blondin", "Kevin Zhu", "Vasu Sharma", "Sean O'Brien"], "title": "Causal Language Control in Multilingual Transformers via Sparse Feature Steering", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Deterministically controlling the target generation language of large\nmultilingual language models (LLMs) remains a fundamental challenge,\nparticularly in zero-shot settings where neither explicit language prompts nor\nfine-tuning are available. In this work, we investigate whether sparse\nautoencoder (SAE) features, previously shown to correlate with interpretable\nmodel behaviors, can be leveraged to steer the generated language of LLMs\nduring inference. Leveraging pretrained SAEs on the residual streams of\nGemma-2B and Gemma-9B, we identify features whose activations differ most\nsignificantly between English and four target languages: Chinese, Japanese,\nSpanish, and French. By modifying just a single SAE feature at one transformer\nlayer, we achieve controlled language shifts with up to 90\\% success, as\nmeasured by FastText language classification, while preserving semantic\nfidelity according to LaBSE (Language-Agnostic BERT Sentence Embedding)\nsimilarity. Our analysis reveals that language steering is most effective in\nmid-to-late transformer layers and is amplified by specific attention heads\ndisproportionately associated with language-sensitive SAE features. These\nresults demonstrate the promise of sparse feature steering as a lightweight and\ninterpretable mechanism for controllable multilingual generation.", "AI": {"tldr": "This paper explores the use of sparse autoencoder (SAE) features to control the target language of large multilingual language models (LLMs) during inference, achieving up to 90% success while maintaining semantic fidelity.", "motivation": "The authors aim to address the challenge of deterministically controlling the generated language of LLMs, especially in zero-shot settings where traditional cues like language prompts or fine-tuning are not applicable.", "method": "The method involves leveraging pretrained SAEs on the residual streams of two LLMs (Gemma-2B and Gemma-9B) to identify language-differentiating features. By modifying a single SAE feature at a specific transformer layer, language shifts are induced and analyzed for effectiveness.", "result": "The technique achieved up to 90% success in shifting the target language, as evaluated through FastText language classification, while semantic fidelity was preserved according to LaBSE similarity scores. Language steering was most effective in mid-to-late transformer layers and amplified by specific attention heads.", "conclusion": "Sparse feature steering offers a promising, lightweight, and interpretable approach for controllable multilingual text generation in LLMs."}}
{"id": "2507.14126", "pdf": "https://arxiv.org/pdf/2507.14126", "abs": "https://arxiv.org/abs/2507.14126", "authors": ["Jianhong Chen", "Meng Zhao", "Mostafa Reisi Gahrooei", "Xubo Yue"], "title": "Toward Temporal Causal Representation Learning with Tensor Decomposition", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Temporal causal representation learning is a powerful tool for uncovering\ncomplex patterns in observational studies, which are often represented as\nlow-dimensional time series. However, in many real-world applications, data are\nhigh-dimensional with varying input lengths and naturally take the form of\nirregular tensors. To analyze such data, irregular tensor decomposition is\ncritical for extracting meaningful clusters that capture essential information.\nIn this paper, we focus on modeling causal representation learning based on the\ntransformed information. First, we present a novel causal formulation for a set\nof latent clusters. We then propose CaRTeD, a joint learning framework that\nintegrates temporal causal representation learning with irregular tensor\ndecomposition. Notably, our framework provides a blueprint for downstream tasks\nusing the learned tensor factors, such as modeling latent structures and\nextracting causal information, and offers a more flexible regularization design\nto enhance tensor decomposition. Theoretically, we show that our algorithm\nconverges to a stationary point. More importantly, our results fill the gap in\ntheoretical guarantees for the convergence of state-of-the-art irregular tensor\ndecomposition. Experimental results on synthetic and real-world electronic\nhealth record (EHR) datasets (MIMIC-III), with extensive benchmarks from both\nphenotyping and network recovery perspectives, demonstrate that our proposed\nmethod outperforms state-of-the-art techniques and enhances the explainability\nof causal representations.", "AI": {"tldr": "The paper presents a new framework (CaRTeD) that combines temporal causal representation learning with irregular tensor decomposition to analyze high-dimensional, irregular tensor data.", "motivation": "To address the challenge of analyzing high-dimensional data with varying lengths and irregular formats, specifically for extracting meaningful clusters and causal information.", "method": "The authors propose CaRTeD, a framework that integrates temporal causal representation with irregular tensor decomposition, offering theoretical guarantees and flexibility for downstream tasks.", "result": "CaRTeD outperformed state-of-the-art methods in experiments using synthetic data and real-world electronic health records (MIMIC-III), especially in tasks such as phenotyping and network recovery.", "conclusion": "The proposed method enhances the explainability of causal representations, provides theoretical guarantees for tensor decomposition, and opens pathways for better downstream task modeling in high-dimensional irregular data."}}
{"id": "2507.13372", "pdf": "https://arxiv.org/pdf/2507.13372", "abs": "https://arxiv.org/abs/2507.13372", "authors": ["Yeming Cai", "Zhenglin Li", "Yang Wang"], "title": "Enhancing Breast Cancer Detection with Vision Transformers and Graph Neural Networks", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Breast cancer is a leading cause of death among women globally, and early\ndetection is critical for improving survival rates. This paper introduces an\ninnovative framework that integrates Vision Transformers (ViT) and Graph Neural\nNetworks (GNN) to enhance breast cancer detection using the CBIS-DDSM dataset.\nOur framework leverages ViT's ability to capture global image features and\nGNN's strength in modeling structural relationships, achieving an accuracy of\n84.2%, outperforming traditional methods. Additionally, interpretable attention\nheatmaps provide insights into the model's decision-making process, aiding\nradiologists in clinical settings.", "AI": {"tldr": "The paper proposes a framework combining Vision Transformers and Graph Neural Networks to improve breast cancer detection, achieving 84.2% accuracy.", "motivation": "Breast cancer is a leading cause of death, and early detection can improve survival rates.", "method": "The framework integrates Vision Transformers for global image feature capture and Graph Neural Networks for structural relationship modeling, tested on the CBIS-DDSM dataset.", "result": "The proposed method achieved an accuracy of 84.2%, surpassing traditional detection approaches.", "conclusion": "The framework enhances breast cancer detection with high accuracy and provides interpretable insights for radiologists, supporting clinical decision-making."}}
{"id": "2507.13417", "pdf": "https://arxiv.org/pdf/2507.13417", "abs": "https://arxiv.org/abs/2507.13417", "authors": ["Armel Soubeiga", "Thomas Guyet", "Violaine Antoine"], "title": "Soft-ECM: An extension of Evidential C-Means for complex data", "categories": ["cs.LG", "cs.AI", "cs.DM"], "comment": null, "summary": "Clustering based on belief functions has been gaining increasing attention in\nthe machine learning community due to its ability to effectively represent\nuncertainty and/or imprecision. However, none of the existing algorithms can be\napplied to complex data, such as mixed data (numerical and categorical) or\nnon-tabular data like time series. Indeed, these types of data are, in general,\nnot represented in a Euclidean space and the aforementioned algorithms make use\nof the properties of such spaces, in particular for the construction of\nbarycenters. In this paper, we reformulate the Evidential C-Means (ECM) problem\nfor clustering complex data. We propose a new algorithm, Soft-ECM, which\nconsistently positions the centroids of imprecise clusters requiring only a\nsemi-metric. Our experiments show that Soft-ECM present results comparable to\nconventional fuzzy clustering approaches on numerical data, and we demonstrate\nits ability to handle mixed data and its benefits when combining fuzzy\nclustering with semi-metrics such as DTW for time series data.", "AI": {"tldr": "The paper introduces \"Soft-ECM,\" a new clustering algorithm capable of handling complex data types, including mixed and non-tabular data like time series, overcoming the limitations of traditional belief function-based clustering.", "motivation": "The motivation is the inability of existing belief function-based clustering algorithms to handle complex data types like mixed numerical and categorical data or non-tabular formats such as time series.", "method": "The authors reformulated the Evidential C-Means (ECM) problem and proposed Soft-ECM, an algorithm that positions centroids using a semi-metric, thus enabling it to handle imprecise clusters effectively.", "result": "Soft-ECM achieves comparable performance to traditional fuzzy clustering methods on numerical data, while demonstrating superior ability to manage mixed data and leveraging semi-metrics such as DTW for time series.", "conclusion": "Soft-ECM extends the framework of belief function-based clustering to complex data types, validating its effectiveness and expanding its practical applicability."}}
{"id": "2507.13759", "pdf": "https://arxiv.org/pdf/2507.13759", "abs": "https://arxiv.org/abs/2507.13759", "authors": ["Carlos Bobed", "Carlota Quintana", "Eduardo Mena", "Jorge Bobed", "Fernando Bobillo"], "title": "OntView: What you See is What you Meant", "categories": ["cs.AI"], "comment": null, "summary": "In the field of knowledge management and computer science, ontologies provide\na structured framework for modeling domain-specific knowledge by defining\nconcepts and their relationships. However, the lack of tools that provide\neffective visualization is still a significant challenge. While numerous\nontology editors and viewers exist, most of them fail to graphically represent\nontology structures in a meaningful and non-overwhelming way, limiting users'\nability to comprehend dependencies and properties within large ontological\nframeworks.\n  In this paper, we present OntView, an ontology viewer that is designed to\nprovide users with an intuitive visual representation of ontology concepts and\ntheir formal definitions through a user-friendly interface. Building on the use\nof a DL reasoner, OntView follows a \"What you see is what you meant\" paradigm,\nshowing the actual inferred knowledge. One key aspect for this is its ability\nto visualize General Concept Inclusions (GCI), a feature absent in existing\nvisualization tools. Moreover, to avoid a possible information overload,\nOntView also offers different ways to show a simplified view of the ontology\nby: 1) creating ontology summaries by assessing the importance of the concepts\n(according to different available algorithms), 2) focusing the visualization on\nthe existing TBox elements between two given classes and 3) allowing to\nhide/show different branches in a dynamic way without losing the semantics.\nOntView has been released with an open-source license for the whole community.", "AI": {"tldr": "OntView is an open-source ontology visualization tool that provides intuitive, simplified, and dynamic graphical representations for complex ontologies, including unique features like GCI visualization.", "motivation": "Current ontology visualization tools lack effective mechanisms for graphically representing and simplifying complex ontology structures, which hampers understanding and usability.", "method": "OntView employs an intuitive interface and a 'What you see is what you meant' paradigm using a DL reasoner. It includes features like GCI visualization, ontology summarization algorithms, focus on specific TBox elements, and dynamic branch hiding/showing.", "result": "OntView offers an enhanced ontology visualization experience, addressing key limitations in existing tools by simplifying the representation and maintaining semantic integrity.", "conclusion": "OntView fills a critical gap in the domain of ontology visualization, enabling improved comprehension of complex ontologies and fostering broader community use through its open-source availability."}}
{"id": "2507.13702", "pdf": "https://arxiv.org/pdf/2507.13702", "abs": "https://arxiv.org/abs/2507.13702", "authors": ["Junho Choi", "Kihwan Ryoo", "Jeewon Kim", "Taeyun Kim", "Eungchang Lee", "Myeongwoo Jeong", "Kevin Christiansen Marsim", "Hyungtae Lim", "Hyun Myung"], "title": "SaWa-ML: Structure-Aware Pose Correction and Weight Adaptation-Based Robust Multi-Robot Localization", "categories": ["cs.RO"], "comment": "This paper has been accepted to the 2025 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS)", "summary": "Multi-robot localization is a crucial task for implementing multi-robot\nsystems. Numerous researchers have proposed optimization-based multi-robot\nlocalization methods that use camera, IMU, and UWB sensors. Nevertheless,\ncharacteristics of individual robot odometry estimates and distance\nmeasurements between robots used in the optimization are not sufficiently\nconsidered. In addition, previous researches were heavily influenced by the\nodometry accuracy that is estimated from individual robots. Consequently,\nlong-term drift error caused by error accumulation is potentially inevitable.\nIn this paper, we propose a novel visual-inertial-range-based multi-robot\nlocalization method, named SaWa-ML, which enables geometric structure-aware\npose correction and weight adaptation-based robust multi-robot localization.\nOur contributions are twofold: (i) we leverage UWB sensor data, whose range\nerror does not accumulate over time, to first estimate the relative positions\nbetween robots and then correct the positions of each robot, thus reducing\nlong-term drift errors, (ii) we design adaptive weights for robot pose\ncorrection by considering the characteristics of the sensor data and\nvisual-inertial odometry estimates. The proposed method has been validated in\nreal-world experiments, showing a substantial performance increase compared\nwith state-of-the-art algorithms.", "AI": {"tldr": "This paper introduces SaWa-ML, a novel multi-robot localization method using UWB sensors and adaptive weights to mitigate long-term drift errors.", "motivation": "The paper addresses challenges in multi-robot localization, particularly the drift caused by accumulated errors in odometry estimates.", "method": "The method uses UWB sensor data to correct relative positions and adaptive weight design for pose correction based on individual sensor characteristics.", "result": "Real-world experiments demonstrate significant improvements in performance compared to existing multi-robot localization methods.", "conclusion": "Leveraging UWB sensors and geometric structure-aware corrections enhances reliability and accuracy in multi-robot localization."}}
{"id": "2507.13411", "pdf": "https://arxiv.org/pdf/2507.13411", "abs": "https://arxiv.org/abs/2507.13411", "authors": ["Nur A Zarin Nishat", "Andrea Coletta", "Luigi Bellomarini", "Kossi Amouzouvi", "Jens Lehmann", "Sahar Vahdati"], "title": "Aligning Knowledge Graphs and Language Models for Factual Accuracy", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models like GPT-4, Gemini, and Claude have transformed natural\nlanguage processing (NLP) tasks such as question answering, dialogue\ngeneration, summarization, and so forth; yet their susceptibility to\nhallucination stands as one of the major challenges. Among numerous approaches\nto overcome this challenge, integration of Knowledge Graphs (KGs) into language\nmodels has emerged as a promising solution as it provides structured, reliable,\ndomain-specific, and up-to-date external information to the language models. In\nthis paper, we introduce ALIGNed-LLM, a simple yet effective approach to\nimprove language models' factuality via a lean strategy to infuse KGs into the\nlatent space of language models inspired by LLaVA where visual and textual\ninformation is infused. We use embeddings from a pre-trained Knowledge Graph\nEmbedding (KGE) model, such as TransE, and a trainable projection layer to\nalign entity and text embeddings. This alignment enables the language model to\ndistinguish between similar entities improving factual grounding and reducing\nhallucination. We tested our approach on three popular questions-answering\nbenchmark datasets alongside language models of varying sizes, showing\nsignificant improvement. Furthermore, we applied our approach to a real-world\nfinancial use case from a large central bank in Europe, which demands high\naccuracy and precision, demonstrating a substantial improvement of the LLM\nanswers.", "AI": {"tldr": "This paper presents ALIGNed-LLM, a method to enhance factual accuracy in language models by incorporating knowledge graph embeddings, reducing issues like hallucination.", "motivation": "The motivation is to address the susceptibility of large language models to hallucinations by integrating structured and reliable knowledge from Knowledge Graphs.", "method": "ALIGNed-LLM aligns entity and text embeddings using pre-trained knowledge graph embeddings (e.g., TransE) and a trainable projection layer, inspired by LLaVA's methodology.", "result": "The ALIGNed-LLM approach demonstrated substantial improvement in factual accuracy and reduced hallucination across three QA benchmarks and in a financial use case for a central bank.", "conclusion": "Incorporating knowledge graphs into language models through ALIGNed-LLM effectively grounds language models in factual knowledge, improving precision and reliability."}}
{"id": "2507.13373", "pdf": "https://arxiv.org/pdf/2507.13373", "abs": "https://arxiv.org/abs/2507.13373", "authors": ["Xiaojian Lin", "Wenxin Zhang", "Yuchu Jiang", "Wangyu Wu", "Yiran Guo", "Kangxu Wang", "Zongzheng Zhang", "Guijin Wang", "Lei Jin", "Hao Zhao"], "title": "Butter: Frequency Consistency and Hierarchical Fusion for Autonomous Driving Object Detection", "categories": ["cs.CV", "I.4.8; I.2.10; H.5.1; I.2.6"], "comment": "10 pages, 6 figures. Supplementary material: 8 pages, 7 figures.\n  Accepted at ACM Multimedia 2025", "summary": "Hierarchical feature representations play a pivotal role in computer vision,\nparticularly in object detection for autonomous driving. Multi-level semantic\nunderstanding is crucial for accurately identifying pedestrians, vehicles, and\ntraffic signs in dynamic environments. However, existing architectures, such as\nYOLO and DETR, struggle to maintain feature consistency across different scales\nwhile balancing detection precision and computational efficiency. To address\nthese challenges, we propose Butter, a novel object detection framework\ndesigned to enhance hierarchical feature representations for improving\ndetection robustness. Specifically, Butter introduces two key innovations:\nFrequency-Adaptive Feature Consistency Enhancement (FAFCE) Component, which\nrefines multi-scale feature consistency by leveraging adaptive frequency\nfiltering to enhance structural and boundary precision, and Progressive\nHierarchical Feature Fusion Network (PHFFNet) Module, which progressively\nintegrates multi-level features to mitigate semantic gaps and strengthen\nhierarchical feature learning. Through extensive experiments on BDD100K, KITTI,\nand Cityscapes, Butter demonstrates superior feature representation\ncapabilities, leading to notable improvements in detection accuracy while\nreducing model complexity. By focusing on hierarchical feature refinement and\nintegration, Butter provides an advanced approach to object detection that\nachieves a balance between accuracy, deployability, and computational\nefficiency in real-time autonomous driving scenarios. Our model and\nimplementation are publicly available at https://github.com/Aveiro-Lin/Butter,\nfacilitating further research and validation within the autonomous driving\ncommunity.", "AI": {"tldr": "Butter is a novel object detection framework aimed at improving feature consistency and detection robustness for autonomous driving by introducing a Frequency-Adaptive Feature Consistency Enhancement (FAFCE) Component and Progressive Hierarchical Feature Fusion Network (PHFFNet) Module.", "motivation": "Existing architectures like YOLO and DETR struggle with maintaining feature consistency across various scales while balancing detection precision and computational efficiency in dynamic autonomous driving scenarios.", "method": "Butter employs frequency-adaptive filtering to enhance multi-scale feature consistency via the FAFCE Component and progressively integrates multi-level features to bridge semantic gaps using the PHFFNet Module.", "result": "Experiments on benchmarks like BDD100K, KITTI, and Cityscapes show Butter achieves superior feature representation, notable detection accuracy improvements, and reduced model complexity.", "conclusion": "Butter provides an accurate and computationally efficient framework that refines hierarchical feature representation, making it suitable for real-time object detection in autonomous driving contexts."}}
{"id": "2507.13423", "pdf": "https://arxiv.org/pdf/2507.13423", "abs": "https://arxiv.org/abs/2507.13423", "authors": ["Edward Henderson", "Dewi Gould", "Richard Everson", "George De Ath", "Nick Pepper"], "title": "Air Traffic Controller Task Demand via Graph Neural Networks: An Interpretable Approach to Airspace Complexity", "categories": ["cs.LG", "cs.AI"], "comment": "Author Accepted Manuscript version of paper at the AIAA AVIATION\n  Forum 2025", "summary": "Real-time assessment of near-term Air Traffic Controller (ATCO) task demand\nis a critical challenge in an increasingly crowded airspace, as existing\ncomplexity metrics often fail to capture nuanced operational drivers beyond\nsimple aircraft counts. This work introduces an interpretable Graph Neural\nNetwork (GNN) framework to address this gap. Our attention-based model predicts\nthe number of upcoming clearances, the instructions issued to aircraft by\nATCOs, from interactions within static traffic scenarios. Crucially, we derive\nan interpretable, per-aircraft task demand score by systematically ablating\naircraft and measuring the impact on the model's predictions. Our framework\nsignificantly outperforms an ATCO-inspired heuristic and is a more reliable\nestimator of scenario complexity than established baselines. The resulting tool\ncan attribute task demand to specific aircraft, offering a new way to analyse\nand understand the drivers of complexity for applications in controller\ntraining and airspace redesign.", "AI": {"tldr": "This paper proposes a Graph Neural Network (GNN) framework that predicts air traffic control task demand, offering interpretable results linked to specific aircraft in static traffic scenarios.", "motivation": "The paper addresses the increasing complexity of air traffic control due to crowded airspace, aiming to improve existing metrics that fail to capture nuanced operational drivers beyond simple aircraft counts.", "method": "An interpretable attention-based GNN is used to predict air traffic controller instructions by analyzing static traffic situations. Aircraft-specific task demand scores are derived by systematically removing aircraft and observing the model's prediction changes.", "result": "The proposed framework outperforms an ATCO-inspired heuristic and established baselines in accurately estimating scenario complexity, making it a robust tool for task demand assessment.", "conclusion": "This approach provides a reliable method to assess air traffic control task demand and understand scenario complexity, with potential applications in controller training and airspace redesign."}}
{"id": "2507.13768", "pdf": "https://arxiv.org/pdf/2507.13768", "abs": "https://arxiv.org/abs/2507.13768", "authors": ["Renato Ghisellini", "Remo Pareschi", "Marco Pedroni", "Giovanni Battista Raggi"], "title": "From Extraction to Synthesis: Entangled Heuristics for Agent-Augmented Strategic Reasoning", "categories": ["cs.AI", "I.2.7"], "comment": "Peer-reviewed full paper accepted through a double-blind review\n  process at the HAR 2025 conference (https://har-conf.eu/). The official\n  version will appear in a volume of the Lecture Notes in Computer Science\n  (LNCS) series", "summary": "We present a hybrid architecture for agent-augmented strategic reasoning,\ncombining heuristic extraction, semantic activation, and compositional\nsynthesis. Drawing on sources ranging from classical military theory to\ncontemporary corporate strategy, our model activates and composes multiple\nheuristics through a process of semantic interdependence inspired by research\nin quantum cognition. Unlike traditional decision engines that select the best\nrule, our system fuses conflicting heuristics into coherent and\ncontext-sensitive narratives, guided by semantic interaction modeling and\nrhetorical framing. We demonstrate the framework via a Meta vs. FTC case study,\nwith preliminary validation through semantic metrics. Limitations and\nextensions (e.g., dynamic interference tuning) are discussed.", "AI": {"tldr": "The paper proposes a hybrid architecture for agent-assisted strategic reasoning using heuristics, semantic activation, and composition, validated with a Meta vs. FTC case study.", "motivation": "Traditional decision engines often fail to integrate conflicting heuristics effectively; this study seeks to construct a framework that fuses them into coherent, context-sensitive narratives.", "method": "The approach integrates heuristic extraction, semantic activation, and compositional synthesis, inspired by quantum cognition, and applies semantic interaction modeling and rhetorical framing.", "result": "The framework was illustrated through a Meta vs. FTC case study, with validation via semantic metrics; limitations and potential extensions were also discussed.", "conclusion": "The hybrid architecture demonstrates promise in integrating conflicting heuristics for strategic reasoning, with room for further development in dynamic tuning and contextual adaptability."}}
{"id": "2507.13895", "pdf": "https://arxiv.org/pdf/2507.13895", "abs": "https://arxiv.org/abs/2507.13895", "authors": ["Damiano Azzolini", "Marco Duca", "Stefano Forti", "Francesco Gallo", "Antonio Ielo"], "title": "Application Placement with Constraint Relaxation", "categories": ["cs.LO", "cs.DC"], "comment": null, "summary": "Novel utility computing paradigms rely upon the deployment of multi-service\napplications to pervasive and highly distributed cloud-edge infrastructure\nresources. Deciding onto which computational nodes to place services in\ncloud-edge networks, as per their functional and non-functional constraints,\ncan be formulated as a combinatorial optimisation problem. Most existing\nsolutions in this space are not able to deal with \\emph{unsatisfiable} problem\ninstances, nor preferences, i.e. requirements that DevOps may agree to relax to\nobtain a solution. In this article, we exploit Answer Set Programming\noptimisation capabilities to tackle this problem. Experimental results in\nsimulated settings show that our approach is effective on lifelike networks and\napplications.", "AI": {"tldr": "The paper addresses the challenge of service placement in cloud-edge networks by proposing an optimization approach using Answer Set Programming.", "motivation": "The study is motivated by the need for efficient service placement in distributed cloud-edge systems, especially for handling unsatisfiable instances and relaxed DevOps preferences.", "method": "Answer Set Programming is leveraged with its optimization capabilities to formulate and solve the combinatorial service placement problem.", "result": "Experimental results in simulated environments demonstrate the effectiveness of the proposed approach on realistic networks and applications.", "conclusion": "The approach provides an effective solution to service placement using optimization techniques, accommodating relaxed preferences and unsatisfiable constraints."}}
{"id": "2507.13729", "pdf": "https://arxiv.org/pdf/2507.13729", "abs": "https://arxiv.org/abs/2507.13729", "authors": ["Yu Yao", "Salil Bhatnagar", "Markus Mazzola", "Vasileios Belagiannis", "Igor Gilitschenski", "Luigi Palmieri", "Simon Razniewski", "Marcel Hallgarten"], "title": "AGENTS-LLM: Augmentative GENeration of Challenging Traffic Scenarios with an Agentic LLM Framework", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Rare, yet critical, scenarios pose a significant challenge in testing and\nevaluating autonomous driving planners. Relying solely on real-world driving\nscenes requires collecting massive datasets to capture these scenarios. While\nautomatic generation of traffic scenarios appears promising, data-driven models\nrequire extensive training data and often lack fine-grained control over the\noutput. Moreover, generating novel scenarios from scratch can introduce a\ndistributional shift from the original training scenes which undermines the\nvalidity of evaluations especially for learning-based planners. To sidestep\nthis, recent work proposes to generate challenging scenarios by augmenting\noriginal scenarios from the test set. However, this involves the manual\naugmentation of scenarios by domain experts. An approach that is unable to meet\nthe demands for scale in the evaluation of self-driving systems. Therefore,\nthis paper introduces a novel LLM-agent based framework for augmenting\nreal-world traffic scenarios using natural language descriptions, addressing\nthe limitations of existing methods. A key innovation is the use of an agentic\ndesign, enabling fine-grained control over the output and maintaining high\nperformance even with smaller, cost-effective LLMs. Extensive human expert\nevaluation demonstrates our framework's ability to accurately adhere to user\nintent, generating high quality augmented scenarios comparable to those created\nmanually.", "AI": {"tldr": "This paper presents a framework to augment traffic scenarios for autonomous driving using natural language descriptions, utilizing a cost-effective LLM-agent design, and addressing scalability and fine-grained control issues.", "motivation": "Testing autonomous driving systems for rare scenarios is challenging because collecting real-world data or manually creating scenarios involves significant effort and resources.", "method": "The authors developed an LLM-agent based framework that augments real-world traffic scenarios using natural language input, while allowing fine-grained control and performing well even with smaller LLM models.", "result": "The proposed framework, evaluated by human experts, generates augmented traffic scenarios that align with user intent and achieve quality comparable to manually created scenarios.", "conclusion": "The framework offers a scalable, cost-effective, and high-quality approach to creating challenging traffic scenarios for autonomous driving evaluation, surpassing traditional manual methods."}}
{"id": "2507.13474", "pdf": "https://arxiv.org/pdf/2507.13474", "abs": "https://arxiv.org/abs/2507.13474", "authors": ["Liang Lin", "Zhihao Xu", "Xuehai Tang", "Shi Liu", "Biyu Zhou", "Fuqing Zhu", "Jizhong Han", "Songlin Hu"], "title": "Paper Summary Attack: Jailbreaking LLMs through LLM Safety Papers", "categories": ["cs.CL"], "comment": null, "summary": "The safety of large language models (LLMs) has garnered significant research\nattention. In this paper, we argue that previous empirical studies demonstrate\nLLMs exhibit a propensity to trust information from authoritative sources, such\nas academic papers, implying new possible vulnerabilities. To verify this\npossibility, a preliminary analysis is designed to illustrate our two findings.\nBased on this insight, a novel jailbreaking method, Paper Summary Attack\n(\\llmname{PSA}), is proposed. It systematically synthesizes content from either\nattack-focused or defense-focused LLM safety paper to construct an adversarial\nprompt template, while strategically infilling harmful query as adversarial\npayloads within predefined subsections. Extensive experiments show significant\nvulnerabilities not only in base LLMs, but also in state-of-the-art reasoning\nmodel like Deepseek-R1. PSA achieves a 97\\% attack success rate (ASR) on\nwell-aligned models like Claude3.5-Sonnet and an even higher 98\\% ASR on\nDeepseek-R1. More intriguingly, our work has further revealed diametrically\nopposed vulnerability bias across different base models, and even between\ndifferent versions of the same model, when exposed to either attack-focused or\ndefense-focused papers. This phenomenon potentially indicates future research\nclues for both adversarial methodologies and safety alignment.Code is available\nat https://github.com/233liang/Paper-Summary-Attack", "AI": {"tldr": "The paper identifies vulnerabilities in large language models (LLMs) regarding their tendency to trust authoritative sources, proposing the Paper Summary Attack (PSA) as a novel method to exploit these vulnerabilities.", "motivation": "The authors aim to address the overlooked vulnerability of LLMs indiscriminately trusting content from authoritative sources, which could lead to adversarial exploitation.", "method": "The PSA method synthesizes adversarial prompts using structured content from LLM safety papers, strategically infilling harmful payloads within predefined sections to test vulnerabilities.", "result": "PSA achieved a 97% attack success rate (ASR) on models like Claude3.5-Sonnet and 98% ASR on Deepseek-R1, showing significant vulnerabilities across various LLMs.", "conclusion": "The findings not only highlight critical safety risks in LLMs but also reveal diverse vulnerability biases across different models, offering new directions for adversarial and safety alignment research."}}
{"id": "2507.13374", "pdf": "https://arxiv.org/pdf/2507.13374", "abs": "https://arxiv.org/abs/2507.13374", "authors": ["Kevin Dela Rosa"], "title": "Smart Routing for Multimodal Video Retrieval: When to Search What", "categories": ["cs.CV", "cs.AI", "cs.IR"], "comment": "Accepted to ICCV 2025 Multimodal Representation and Retrieval\n  Workshop", "summary": "We introduce ModaRoute, an LLM-based intelligent routing system that\ndynamically selects optimal modalities for multimodal video retrieval. While\ndense text captions can achieve 75.9% Recall@5, they require expensive offline\nprocessing and miss critical visual information present in 34% of clips with\nscene text not captured by ASR. By analyzing query intent and predicting\ninformation needs, ModaRoute reduces computational overhead by 41% while\nachieving 60.9% Recall@5. Our approach uses GPT-4.1 to route queries across ASR\n(speech), OCR (text), and visual indices, averaging 1.78 modalities per query\nversus exhaustive 3.0 modality search. Evaluation on 1.8M video clips\ndemonstrates that intelligent routing provides a practical solution for scaling\nmultimodal retrieval systems, reducing infrastructure costs while maintaining\ncompetitive effectiveness for real-world deployment.", "AI": {"tldr": "ModaRoute is an LLM-based routing system for multimodal video retrieval, optimizing modality selection to enhance efficiency and effectiveness.", "motivation": "The motivation lies in addressing inefficiencies of exhaustive modality searches in multimodal video retrieval systems and the need to optimize computational overhead while maintaining competitive retrieval performance.", "method": "The method involves using GPT-4.1 for intelligent query routing, dynamically selecting modalities such as ASR, OCR, and visual indices based on query intent and predicted needs, to reduce redundant processing.", "result": "ModaRoute achieves 60.9% Recall@5, reduces computational overhead by 41%, and requires only 1.78 modalities per query on average, compared to 3.0 for exhaustive searches.", "conclusion": "The intelligent routing approach of ModaRoute enables scalable, cost-effective multimodal retrieval systems, balancing infrastructure efficiency with retrieval effectiveness, making it suitable for real-world applications."}}
{"id": "2507.13482", "pdf": "https://arxiv.org/pdf/2507.13482", "abs": "https://arxiv.org/abs/2507.13482", "authors": ["Seyyed Saeid Cheshmi", "Buyao Lyu", "Thomas Lisko", "Rajesh Rajamani", "Robert A. McGovern", "Yogatheesan Varatharajah"], "title": "Improving Out-of-distribution Human Activity Recognition via IMU-Video Cross-modal Representation Learning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Human Activity Recognition (HAR) based on wearable inertial sensors plays a\ncritical role in remote health monitoring. In patients with movement disorders,\nthe ability to detect abnormal patient movements in their home environments can\nenable continuous optimization of treatments and help alert caretakers as\nneeded. Machine learning approaches have been proposed for HAR tasks using\nInertial Measurement Unit (IMU) data; however, most rely on\napplication-specific labels and lack generalizability to data collected in\ndifferent environments or populations. To address this limitation, we propose a\nnew cross-modal self-supervised pretraining approach to learn representations\nfrom large-sale unlabeled IMU-video data and demonstrate improved\ngeneralizability in HAR tasks on out of distribution (OOD) IMU datasets,\nincluding a dataset collected from patients with Parkinson's disease.\nSpecifically, our results indicate that the proposed cross-modal pretraining\napproach outperforms the current state-of-the-art IMU-video pretraining\napproach and IMU-only pretraining under zero-shot and few-shot evaluations.\nBroadly, our study provides evidence that in highly dynamic data modalities,\nsuch as IMU signals, cross-modal pretraining may be a useful tool to learn\ngeneralizable data representations. Our software is available at\nhttps://github.com/scheshmi/IMU-Video-OOD-HAR.", "AI": {"tldr": "This paper introduces a cross-modal self-supervised pretraining approach to improve Human Activity Recognition (HAR) using wearable inertial sensors, achieving better generalization on out-of-distribution data, including for Parkinson's patients.", "motivation": "To overcome the lack of generalizability in existing HAR models that rely on application-specific labels and fail in new environments or populations.", "method": "The authors designed a cross-modal self-supervised pretraining technique using large-scale unlabeled data combining IMU and video inputs, improving feature learning across diverse distributions.", "result": "The proposed method outperformed state-of-the-art IMU-video and IMU-only pretraining approaches, especially in zero-shot and few-shot evaluations on diverse datasets, including Parkinson's disease patient data.", "conclusion": "Cross-modal pretraining is shown to enhance generalizability in dynamic data modalities like IMU signals, making it a promising tool for HAR and related applications. Code for implementation is publicly available."}}
{"id": "2507.13825", "pdf": "https://arxiv.org/pdf/2507.13825", "abs": "https://arxiv.org/abs/2507.13825", "authors": ["Haoyang Li", "Yuming Xu", "Yiming Li", "Hanmo Liu", "Darian Li", "Chen Jason Zhang", "Lei Chen", "Qing Li"], "title": "When Speed meets Accuracy: an Efficient and Effective Graph Model for Temporal Link Prediction", "categories": ["cs.AI"], "comment": "Submitted in 2024. Accepted in 2025", "summary": "Temporal link prediction in dynamic graphs is a critical task with\napplications in diverse domains such as social networks, recommendation\nsystems, and e-commerce platforms. While existing Temporal Graph Neural\nNetworks (T-GNNs) have achieved notable success by leveraging complex\narchitectures to model temporal and structural dependencies, they often suffer\nfrom scalability and efficiency challenges due to high computational overhead.\nIn this paper, we propose EAGLE, a lightweight framework that integrates\nshort-term temporal recency and long-term global structural patterns. EAGLE\nconsists of a time-aware module that aggregates information from a node's most\nrecent neighbors to reflect its immediate preferences, and a structure-aware\nmodule that leverages temporal personalized PageRank to capture the influence\nof globally important nodes. To balance these attributes, EAGLE employs an\nadaptive weighting mechanism to dynamically adjust their contributions based on\ndata characteristics. Also, EAGLE eliminates the need for complex multi-hop\nmessage passing or memory-intensive mechanisms, enabling significant\nimprovements in efficiency. Extensive experiments on seven real-world temporal\ngraphs demonstrate that EAGLE consistently achieves superior performance\nagainst state-of-the-art T-GNNs in both effectiveness and efficiency,\ndelivering more than a 50x speedup over effective transformer-based T-GNNs.", "AI": {"tldr": "EAGLE introduces an efficient framework for temporal link prediction that balances short-term recency and long-term structural patterns, outperforming existing methods in time and computational cost.", "motivation": "Existing Temporal Graph Neural Networks face scalability and efficiency challenges due to computational overload, prompting the need for lightweight solutions.", "method": "EAGLE uses a time-aware module for immediate preferences and a structure-aware module for global influence, coupled with adaptive weighting and simplified processing without multi-hop message passing.", "result": "Experiments on seven real-world datasets show EAGLE delivers superior performance in accuracy and efficiency, achieving over 50x speedup versus transformer-based models.", "conclusion": "EAGLE proves to be a scalable and efficient framework for temporal link prediction, combining effectiveness with computational efficiency against state-of-the-art models."}}
{"id": "2507.14111", "pdf": "https://arxiv.org/pdf/2507.14111", "abs": "https://arxiv.org/abs/2507.14111", "authors": ["Xiaoya Li", "Xiaofei Sun", "Albert Wang", "Jiwei Li", "Chris Shum"], "title": "CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning", "categories": ["cs.AI", "cs.DC", "cs.LG"], "comment": "Preprint Version", "summary": "The exponential growth in demand for GPU computing resources, driven by the\nrapid advancement of Large Language Models, has created an urgent need for\nautomated CUDA optimization strategies. While recent advances in LLMs show\npromise for code generation, current SOTA models (e.g. R1, o1) achieve low\nsuccess rates in improving CUDA speed. In this paper, we introduce CUDA-L1, an\nautomated reinforcement learning framework for CUDA optimization.\n  CUDA-L1 achieves performance improvements on the CUDA optimization task:\ntrained on NVIDIA A100, it delivers an average speedup of x17.7 across all 250\nCUDA kernels of KernelBench, with peak speedups reaching x449. Furthermore, the\nmodel also demonstrates excellent portability across GPU architectures,\nachieving average speedups of x17.8 on H100, x19.0 on RTX 3090, x16.5 on L40,\nx14.7 on H800, and x13.9 on H20 despite being optimized specifically for A100.\nBeyond these benchmark results, CUDA-L1 demonstrates several remarkable\nproperties: 1) Discovers a variety of CUDA optimization techniques and learns\nto combine them strategically to achieve optimal performance; 2) Uncovers\nfundamental principles of CUDA optimization; 3) Identifies non-obvious\nperformance bottlenecks and rejects seemingly beneficial optimizations that\nharm performance.\n  The capabilities of CUDA-L1 demonstrate that reinforcement learning can\ntransform an initially poor-performing LLM into an effective CUDA optimizer\nthrough speedup-based reward signals alone, without human expertise or domain\nknowledge. More importantly, the trained RL model extend the acquired reasoning\nabilities to new kernels. This paradigm opens possibilities for automated\noptimization of CUDA operations, and holds promise to substantially promote GPU\nefficiency and alleviate the rising pressure on GPU computing resources.", "AI": {"tldr": "CUDA-L1, a reinforcement learning framework, drastically improves CUDA optimization with average speedups exceeding x17 across various GPUs.", "motivation": "The expansion of GPU demand due to advancements in Large Language Models necessitates efficient CUDA optimization strategies.", "method": "Reinforcement learning is used for automated CUDA optimization, leveraging speedup-based reward signals without human expertise.", "result": "CUDA-L1 achieves up to x17 speedup on 250 benchmarks and adapts effectively across GPU architectures, showcasing excellent portability.", "conclusion": "Reinforcement learning can transform weak-performing models into effective CUDA optimizers, driving GPU efficiency and paving the way for automated CUDA operations."}}
{"id": "2507.13787", "pdf": "https://arxiv.org/pdf/2507.13787", "abs": "https://arxiv.org/abs/2507.13787", "authors": ["Doina Pisla", "Alexandru Pusca", "Andrei Caprariu", "Adrian Pisla", "Bogdan Gherman", "Calin Vaida", "Damien Chablat"], "title": "Design Analysis of an Innovative Parallel Robot for Minimally Invasive Pancreatic Surgery", "categories": ["cs.RO"], "comment": null, "summary": "This paper focuses on the design of a parallel robot designed for robotic\nassisted minimally invasive pancreatic surgery. Two alternative architectures,\ncalled ATHENA-1 and ATHENA-2, each with 4 degrees of freedom (DOF) are\nproposed. Their kinematic schemes are presented, and the conceptual 3D CAD\nmodels are illustrated. Based on these, two Finite Element Method (FEM)\nsimulations were performed to determine which architecture has the higher\nstiffness. A workspace quantitative analysis is performed to further assess the\nusability of the two proposed parallel architectures related to the medical\ntasks. The obtained results are used to select the architecture which fit the\nrequired design criteria and will be used to develop the experimental model of\nthe surgical robot.", "AI": {"tldr": "This paper proposes and compares two 4-DOF parallel robot designs, ATHENA-1 and ATHENA-2, for minimally invasive pancreatic surgery.", "motivation": "To design and identify an optimal parallel robotic architecture for minimally invasive pancreatic surgery with adequate stiffness and workspace usability.", "method": "Two architectures (ATHENA-1 and ATHENA-2) were modeled in 3D CAD and evaluated using Finite Element Method (FEM) simulations for stiffness comparison and workspace analysis.", "result": "FEM simulations and workspace analysis provided comparative insights, leading to the selection of one architecture that meets the desired design criteria for surgery.", "conclusion": "The selected robot architecture will progress to the development phase for experimental testing in robotic-assisted pancreatic surgery."}}
{"id": "2507.13490", "pdf": "https://arxiv.org/pdf/2507.13490", "abs": "https://arxiv.org/abs/2507.13490", "authors": ["Siqi Shen", "Mehar Singh", "Lajanugen Logeswaran", "Moontae Lee", "Honglak Lee", "Rada Mihalcea"], "title": "Revisiting LLM Value Probing Strategies: Are They Robust and Expressive?", "categories": ["cs.CL"], "comment": null, "summary": "There has been extensive research on assessing the value orientation of Large\nLanguage Models (LLMs) as it can shape user experiences across demographic\ngroups. However, several challenges remain. First, while the Multiple Choice\nQuestion (MCQ) setting has been shown to be vulnerable to perturbations, there\nis no systematic comparison of probing methods for value probing. Second, it is\nunclear to what extent the probed values capture in-context information and\nreflect models' preferences for real-world actions. In this paper, we evaluate\nthe robustness and expressiveness of value representations across three widely\nused probing strategies. We use variations in prompts and options, showing that\nall methods exhibit large variances under input perturbations. We also\nintroduce two tasks studying whether the values are responsive to demographic\ncontext, and how well they align with the models' behaviors in value-related\nscenarios. We show that the demographic context has little effect on the\nfree-text generation, and the models' values only weakly correlate with their\npreference for value-based actions. Our work highlights the need for a more\ncareful examination of LLM value probing and awareness of its limitations.", "AI": {"tldr": "This paper evaluates different methods for probing the values of Large Language Models (LLMs), highlighting their vulnerabilities and limitations.", "motivation": "Understanding the values of LLMs is important as it affects user interactions across demographic groups, but current probing methods lack robustness and systematic comparison.", "method": "The study evaluates three popular value-probing strategies, tests their robustness to input perturbations, studies demographic responsiveness, and examines alignment with behavior in value-driven scenarios.", "result": "Probing methods show large variances under perturbations, demographic context has minimal effect on generation, and the probed values only weakly correlate with real-world preferences.", "conclusion": "Existing methods for probing LLM values are limited in reliability and robustness, requiring a more refined approach to accurately assess these values."}}
{"id": "2507.13378", "pdf": "https://arxiv.org/pdf/2507.13378", "abs": "https://arxiv.org/abs/2507.13378", "authors": ["Yuqi Cheng", "Yunkang Cao", "Haiming Yao", "Wei Luo", "Cheng Jiang", "Hui Zhang", "Weiming Shen"], "title": "A Comprehensive Survey for Real-World Industrial Defect Detection: Challenges, Approaches, and Prospects", "categories": ["cs.CV"], "comment": "27 pages, 7 figures", "summary": "Industrial defect detection is vital for upholding product quality across\ncontemporary manufacturing systems. As the expectations for precision,\nautomation, and scalability intensify, conventional inspection approaches are\nincreasingly found wanting in addressing real-world demands. Notable progress\nin computer vision and deep learning has substantially bolstered defect\ndetection capabilities across both 2D and 3D modalities. A significant\ndevelopment has been the pivot from closed-set to open-set defect detection\nframeworks, which diminishes the necessity for extensive defect annotations and\nfacilitates the recognition of novel anomalies. Despite such strides, a\ncohesive and contemporary understanding of industrial defect detection remains\nelusive. Consequently, this survey delivers an in-depth analysis of both\nclosed-set and open-set defect detection strategies within 2D and 3D\nmodalities, charting their evolution in recent years and underscoring the\nrising prominence of open-set techniques. We distill critical challenges\ninherent in practical detection environments and illuminate emerging trends,\nthereby providing a current and comprehensive vista of this swiftly progressing\nfield.", "AI": {"tldr": "The paper surveys advancements in industrial defect detection with a focus on closed-set and open-set strategies, highlighting challenges and emerging trends.", "motivation": "To address the increasing demands for precision and automation in defect detection while overcoming the limitations of traditional methods.", "method": "The authors provide a detailed survey analyzing closed-set and open-set defect detection frameworks across 2D and 3D modalities.", "result": "The paper highlights the evolution of defect detection methods, emphasizing the shift towards open-set techniques that reduce dependence on extensive defect annotations.", "conclusion": "By identifying critical challenges and emerging trends, the survey contributes to a better understanding of industrial defect detection's current landscape."}}
{"id": "2507.13491", "pdf": "https://arxiv.org/pdf/2507.13491", "abs": "https://arxiv.org/abs/2507.13491", "authors": ["Thomas Banker", "Ali Mesbah"], "title": "Model-free Reinforcement Learning for Model-based Control: Towards Safe, Interpretable and Sample-efficient Agents", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Training sophisticated agents for optimal decision-making under uncertainty\nhas been key to the rapid development of modern autonomous systems across\nfields. Notably, model-free reinforcement learning (RL) has enabled\ndecision-making agents to improve their performance directly through system\ninteractions, with minimal prior knowledge about the system. Yet, model-free RL\nhas generally relied on agents equipped with deep neural network function\napproximators, appealing to the networks' expressivity to capture the agent's\npolicy and value function for complex systems. However, neural networks amplify\nthe issues of sample inefficiency, unsafe learning, and limited\ninterpretability in model-free RL. To this end, this work introduces\nmodel-based agents as a compelling alternative for control policy\napproximation, leveraging adaptable models of system dynamics, cost, and\nconstraints for safe policy learning. These models can encode prior system\nknowledge to inform, constrain, and aid in explaining the agent's decisions,\nwhile deficiencies due to model mismatch can be remedied with model-free RL. We\noutline the benefits and challenges of learning model-based agents --\nexemplified by model predictive control -- and detail the primary learning\napproaches: Bayesian optimization, policy search RL, and offline strategies,\nalong with their respective strengths. While model-free RL has long been\nestablished, its interplay with model-based agents remains largely unexplored,\nmotivating our perspective on their combined potentials for sample-efficient\nlearning of safe and interpretable decision-making agents.", "AI": {"tldr": "This paper examines the advantages of model-based agents for reinforcement learning (RL), highlighting their safety, efficiency, and interpretability compared to traditional model-free RL.", "motivation": "To address limitations like sample inefficiency, unsafe learning, and limited interpretability associated with model-free reinforcement learning that relies heavily on neural networks.", "method": "Presenting model-based agents that incorporate adaptable models of system dynamics, cost, and constraints. This approach leverages prior knowledge to improve safety, interpretability, and decision-making, and integrates methods such as Bayesian optimization, policy search RL, and offline strategies.", "result": "The paper underscores the unexplored potential of combining model-based agents and model-free reinforcement learning to achieve sample-efficient learning and safe, interpretable decision-making.", "conclusion": "Model-based agents represent a promising framework for addressing the limitations of model-free RL, offering a pathway to more effective autonomous decision-making systems when combined innovatively."}}
{"id": "2507.13846", "pdf": "https://arxiv.org/pdf/2507.13846", "abs": "https://arxiv.org/abs/2507.13846", "authors": ["Kathrin Korte", "Christian Medeiros Adriano", "Sona Ghahremani", "Holger Giese"], "title": "Causal Knowledge Transfer for Multi-Agent Reinforcement Learning in Dynamic Environments", "categories": ["cs.AI"], "comment": null, "summary": "[Context] Multi-agent reinforcement learning (MARL) has achieved notable\nsuccess in environments where agents must learn coordinated behaviors. However,\ntransferring knowledge across agents remains challenging in non-stationary\nenvironments with changing goals. [Problem] Traditional knowledge transfer\nmethods in MARL struggle to generalize, and agents often require costly\nretraining to adapt. [Approach] This paper introduces a causal knowledge\ntransfer framework that enables RL agents to learn and share compact causal\nrepresentations of paths within a non-stationary environment. As the\nenvironment changes (new obstacles), agents' collisions require adaptive\nrecovery strategies. We model each collision as a causal intervention\ninstantiated as a sequence of recovery actions (a macro) whose effect\ncorresponds to a causal knowledge of how to circumvent the obstacle while\nincreasing the chances of achieving the agent's goal (maximizing cumulative\nreward). This recovery action macro is transferred online from a second agent\nand is applied in a zero-shot fashion, i.e., without retraining, just by\nquerying a lookup model with local context information (collisions). [Results]\nOur findings reveal two key insights: (1) agents with heterogeneous goals were\nable to bridge about half of the gap between random exploration and a fully\nretrained policy when adapting to new environments, and (2) the impact of\ncausal knowledge transfer depends on the interplay between environment\ncomplexity and agents' heterogeneous goals.", "AI": {"tldr": "The paper proposes a causal knowledge transfer framework in MARL for adapting to non-stationary environments without retraining agents.", "motivation": "Address the challenge of transferring knowledge among agents in MARL for non-stationary environments with changing goals.", "method": "Develop a framework for agents to share compact causal representations of recovery actions to circumvent obstacles in non-stationary environments, applied in a zero-shot manner using lookup queries.", "result": "Agents using causal knowledge transfer bridged half the performance gap between random exploration and retrained policies, with impact varying based on environmental complexity and agents' goal heterogeneity.", "conclusion": "Causal knowledge transfer can enable effective, retraining-free adaptation in MARL, supporting efficient goal achievement in dynamic environments."}}
{"id": "2507.14114", "pdf": "https://arxiv.org/pdf/2507.14114", "abs": "https://arxiv.org/abs/2507.14114", "authors": ["Ahammed Ullah", "S. M. Ferdous", "Alex Pothen"], "title": "Weighted Matching in a Poly-Streaming Model", "categories": ["cs.DS", "cs.DC"], "comment": "40 pages, ESA 2025", "summary": "We introduce the poly-streaming model, a generalization of streaming models\nof computation in which $k$ processors process $k$ data streams containing a\ntotal of $N$ items. The algorithm is allowed $O\\left(f(k)\\cdot M_1\\right)$\nspace, where $M_1$ is either $o\\left(N\\right)$ or the space bound for a\nsequential streaming algorithm. Processors may communicate as needed.\nAlgorithms are assessed by the number of passes, per-item processing time,\ntotal runtime, space usage, communication cost, and solution quality.\n  We design a single-pass algorithm in this model for approximating the maximum\nweight matching (MWM) problem. Given $k$ edge streams and a parameter\n$\\varepsilon > 0$, the algorithm computes a\n$\\left(2+\\epsilon\\right)$-approximate MWM. We analyze its performance in a\nshared-memory parallel setting: for any constant $\\varepsilon > 0$, it runs in\ntime $\\widetilde{O}\\left(L_{\\max}+n\\right)$, where $n$ is the number of\nvertices and $L_{\\max}$ is the maximum stream length. It supports\n$O\\left(1\\right)$ per-edge processing time using $\\widetilde{O}\\left(k\\cdot\nn\\right)$ space. We further generalize the design to hierarchical\narchitectures, in which $k$ processors are partitioned into $r$ groups, each\nwith its own shared local memory. The total intergroup communication is\n$\\widetilde{O}\\left(r \\cdot n\\right)$ bits, while all other performance\nguarantees are preserved.\n  We evaluate the algorithm on a shared-memory system using graphs with\ntrillions of edges. It achieves substantial speedups as $k$ increases and\nproduces matchings with weights significantly exceeding the theoretical\nguarantee. On our largest test graph, it reduces runtime by nearly two orders\nof magnitude and memory usage by five orders of magnitude compared to an\noffline algorithm.", "AI": {"tldr": "The paper proposes the poly-streaming model for distributed data stream processing with $k$ processors. It presents a single-pass algorithm for approximating the Maximum Weight Matching (MWM) problem with high efficiency and scalability.", "motivation": "To address real-world scenarios where large-scale data streams need to be processed concurrently by multiple processors while optimizing space, runtime, and communication.", "method": "The authors develop a framework for multi-processor streaming, introducing a single-pass algorithm for (2+\u03b5)-approximation of the Maximum Weight Matching problem under shared and hierarchical architectures.", "result": "The algorithm achieves efficient space and runtime performance, supports $O(1)$ per-edge processing time, and shows scalability with $k$ processors. It dramatically reduces runtime (by ~100x) and memory usage (by ~100,000x) compared to offline algorithms.", "conclusion": "The poly-streaming model is a powerful tool for parallel graph-based computations, particularly for large datasets, achieving significant improvements in speed, memory usage, and match quality in practical evaluations."}}
{"id": "2507.13871", "pdf": "https://arxiv.org/pdf/2507.13871", "abs": "https://arxiv.org/abs/2507.13871", "authors": ["Mehul Anand", "Shishir Kolathaya"], "title": "Safety Certification in the Latent space using Control Barrier Functions and World Models", "categories": ["cs.RO", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "comment": "6 pages, 6 figures. arXiv admin note: text overlap with\n  arXiv:2409.12616", "summary": "Synthesising safe controllers from visual data typically requires extensive\nsupervised labelling of safety-critical data, which is often impractical in\nreal-world settings. Recent advances in world models enable reliable prediction\nin latent spaces, opening new avenues for scalable and data-efficient safe\ncontrol. In this work, we introduce a semi-supervised framework that leverages\ncontrol barrier certificates (CBCs) learned in the latent space of a world\nmodel to synthesise safe visuomotor policies. Our approach jointly learns a\nneural barrier function and a safe controller using limited labelled data,\nwhile exploiting the predictive power of modern vision transformers for latent\ndynamics modelling.", "AI": {"tldr": "The paper presents a semi-supervised framework for synthesizing safe visuomotor policies using control barrier certificates learned in the latent space of a world model.", "motivation": "The motivation is to address the impracticality of supervised labeling of safety-critical visual data and leverage latent space prediction for scalable and efficient safe control.", "method": "The framework combines the learning of neural barrier functions and safe controllers using limited labeled data with vision transformers for latent dynamics modeling.", "result": "The paper introduces a semi-supervised method that optimizes safe control synthesis, utilizing control barrier certificates in latent spaces and modern vision techniques.", "conclusion": "This framework offers a data-efficient and scalable solution for synthesizing safe visuomotor policies, alleviating the dependence on extensive supervised labeling."}}
{"id": "2507.13501", "pdf": "https://arxiv.org/pdf/2507.13501", "abs": "https://arxiv.org/abs/2507.13501", "authors": ["Matilde Marcolli", "Robert C. Berwick"], "title": "Encoding syntactic objects and Merge operations in function spaces", "categories": ["cs.CL", "math.RA", "q-bio.NC", "91F20, 16Y60, 16T05, 92C20"], "comment": "40 pages, LaTeX, 4 png figures", "summary": "We provide a mathematical argument showing that, given a representation of\nlexical items as functions (wavelets, for instance) in some function space, it\nis possible to construct a faithful representation of arbitrary syntactic\nobjects in the same function space. This space can be endowed with a\ncommutative non-associative semiring structure built using the second Renyi\nentropy. The resulting representation of syntactic objects is compatible with\nthe magma structure. The resulting set of functions is an algebra over an\noperad, where the operations in the operad model circuits that transform the\ninput wave forms into a combined output that encodes the syntactic structure.\nThe action of Merge on workspaces is faithfully implemented as action on these\ncircuits, through a coproduct and a Hopf algebra Markov chain. The results\nobtained here provide a constructive argument showing the theoretical\npossibility of a neurocomputational realization of the core computational\nstructure of syntax. We also present a particular case of this general\nconstruction where this type of realization of Merge is implemented as a cross\nfrequency phase synchronization on sinusoidal waves. This also shows that Merge\ncan be expressed in terms of the successor function of a semiring, thus\nclarifying the well known observation of its similarities with the successor\nfunction of arithmetic.", "AI": {"tldr": "The paper demonstrates a mathematical framework representing syntax in function space, potentially supporting neurocomputational realization.", "motivation": "Understanding how syntactic objects can be represented mathematically and how this may relate to neurocomputational processing.", "method": "The authors construct a function space representation based on wavelets, use Renyi entropy to define structures, and connect these to Merge operations via a Hopf algebra Markov chain.", "result": "A faithful representation of syntactic structures in the function space was modeled, with Merge implemented through sinusoidal waves and phase synchronization.", "conclusion": "Merge can be equated with the successor function of a semiring, making syntax representation computationally feasible and linked to neurocomputational theories."}}
{"id": "2507.13385", "pdf": "https://arxiv.org/pdf/2507.13385", "abs": "https://arxiv.org/abs/2507.13385", "authors": ["Arjun Rao", "Esther Rolf"], "title": "Using Multiple Input Modalities Can Improve Data-Efficiency and O.O.D. Generalization for ML with Satellite Imagery", "categories": ["cs.CV", "cs.LG"], "comment": "17 pages, 9 figures, 7 tables. Accepted to TerraBytes@ICML 2025", "summary": "A large variety of geospatial data layers is available around the world\nranging from remotely-sensed raster data like satellite imagery, digital\nelevation models, predicted land cover maps, and human-annotated data, to data\nderived from environmental sensors such as air temperature or wind speed data.\nA large majority of machine learning models trained on satellite imagery\n(SatML), however, are designed primarily for optical input modalities such as\nmulti-spectral satellite imagery. To better understand the value of using other\ninput modalities alongside optical imagery in supervised learning settings, we\ngenerate augmented versions of SatML benchmark tasks by appending additional\ngeographic data layers to datasets spanning classification, regression, and\nsegmentation. Using these augmented datasets, we find that fusing additional\ngeographic inputs with optical imagery can significantly improve SatML model\nperformance. Benefits are largest in settings where labeled data are limited\nand in geographic out-of-sample settings, suggesting that multi-modal inputs\nmay be especially valuable for data-efficiency and out-of-sample performance of\nSatML models. Surprisingly, we find that hard-coded fusion strategies\noutperform learned variants, with interesting implications for future work.", "AI": {"tldr": "The study augments satellite machine learning benchmarks by integrating additional geographic layers and shows improved model performance, especially in limited data and out-of-sample scenarios.", "motivation": "To explore the potential of fusing non-optical geographic data with optical satellite imagery to improve supervised learning tasks in geospatial domains.", "method": "The researchers appended additional geographic data layers to satellite imagery datasets in existing benchmarking tasks and evaluated performance on classification, regression, and segmentation tasks.", "result": "Fusing geographic inputs with optical imagery improved model performance, particularly in settings with limited labeled data and geographic out-of-sample scenarios. Simpler fusion strategies outperformed complex ones.", "conclusion": "Incorporating multi-modal geographic data enhances satellite ML models, indicating practical benefits for data efficiency and out-of-sample generalization, setting a basis for future advancements in fusion methods."}}
{"id": "2507.13508", "pdf": "https://arxiv.org/pdf/2507.13508", "abs": "https://arxiv.org/abs/2507.13508", "authors": ["Agata Kaczmarek", "Dawid P\u0142udowski", "Piotr Wilczy\u0144ski", "Przemys\u0142aw Biecek", "Krzysztof Kotowski", "Ramez Shendy", "Jakub Nalepa", "Artur Janicki", "Evridiki Ntagiou"], "title": "Fake or Real: The Impostor Hunt in Texts for Space Operations", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "The \"Fake or Real\" competition hosted on Kaggle\n(\\href{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt}{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt})\nis the second part of a series of follow-up competitions and hackathons related\nto the \"Assurance for Space Domain AI Applications\" project funded by the\nEuropean Space Agency\n(\\href{https://assurance-ai.space-codev.org/}{https://assurance-ai.space-codev.org/}).\nThe competition idea is based on two real-life AI security threats identified\nwithin the project -- data poisoning and overreliance in Large Language Models.\nThe task is to distinguish between the proper output from LLM and the output\ngenerated under malicious modification of the LLM. As this problem was not\nextensively researched, participants are required to develop new techniques to\naddress this issue or adjust already existing ones to this problem's statement.", "AI": {"tldr": "The paper discusses the 'Fake or Real' Kaggle competition focusing on AI security threats like data poisoning and Large Language Model (LLM) manipulation.", "motivation": "The competition aims to explore and address real-life AI security issues linked to data poisoning and overreliance on LLMs, which lack sufficient research.", "method": "Participants are tasked to create or adapt techniques to distinguish between genuine LLM output and maliciously manipulated results.", "result": "The competition serves as a platform to develop innovative approaches to AI assurance in security-critical domains such as space applications.", "conclusion": "This effort contributes to advancing the understanding and mitigation of AI vulnerabilities, especially in sensitive and high-stakes domains."}}
{"id": "2507.13874", "pdf": "https://arxiv.org/pdf/2507.13874", "abs": "https://arxiv.org/abs/2507.13874", "authors": ["Mateusz Bystro\u0144ski", "Miko\u0142aj Ho\u0142ysz", "Grzegorz Piotrowski", "Nitesh V. Chawla", "Tomasz Kajdanowicz"], "title": "Large Language Models as Innovators: A Framework to Leverage Latent Space Exploration for Novelty Discovery", "categories": ["cs.AI"], "comment": null, "summary": "Innovative idea generation remains a core challenge in AI, as large language\nmodels (LLMs) often struggle to produce outputs that are both novel and\nrelevant. Despite their fluency, LLMs tend to replicate patterns seen during\ntraining, limiting their ability to diverge creatively without extensive prompt\nengineering. Prior work has addressed this through domain-specific heuristics\nand structured prompting pipelines, but such solutions are brittle and\ndifficult to generalize. In this paper, we propose a model-agnostic\nlatent-space ideation framework that enables controlled, scalable creativity by\nnavigating the continuous embedding space of ideas. Unlike prior methods, our\nframework requires no handcrafted rules and adapts easily to different domains,\ninput formats, and creative tasks. This paper introduces an early-stage\nprototype of our method, outlining the conceptual framework and preliminary\nresults highlighting its potential as a general-purpose co-ideator for human-AI\ncollaboration.", "AI": {"tldr": "This paper addresses the challenge of generating novel and relevant ideas using AI by proposing a model-agnostic latent-space framework for scalable creativity without relying on brittle heuristics.", "motivation": "Large language models struggle to produce outputs that are both novel and relevant, often replicating training patterns and requiring extensive prompt engineering.", "method": "The proposed method utilizes a latent-space ideation framework to navigate the embedding space for controlled creativity without the need for handcrafted rules.", "result": "Preliminary results show the framework's potential for diverse applications and adaptability across domains and creative tasks.", "conclusion": "The framework is presented as an effective prototype for human-AI collaboration, offering general-purpose capabilities in ideation."}}
{"id": "2507.13903", "pdf": "https://arxiv.org/pdf/2507.13903", "abs": "https://arxiv.org/abs/2507.13903", "authors": ["Ziliang Li", "Hongming Chen", "Yiyang Lin", "Biyu Ye", "Ximin Lyu"], "title": "AeroThrow: An Autonomous Aerial Throwing System for Precise Payload Delivery", "categories": ["cs.RO"], "comment": null, "summary": "Autonomous aerial systems play an increasingly vital role in a wide range of\napplications, particularly for transport and delivery tasks in complex\nenvironments. In airdrop missions, these platforms face the dual challenges of\nabrupt control mode switching and inherent system delays along with control\nerrors. To address these issues, this paper presents an autonomous airdrop\nsystem based on an aerial manipulator (AM). The introduction of additional\nactuated degrees of freedom enables active compensation for UAV tracking\nerrors. By imposing smooth and continuous constraints on the parabolic landing\npoint, the proposed approach generates aerial throwing trajectories that are\nless sensitive to the timing of payload release. A hierarchical disturbance\ncompensation strategy is incorporated into the Nonlinear Model Predictive\nControl (NMPC) framework to mitigate the effects of sudden changes in system\nparameters, while the predictive capabilities of NMPC are further exploited to\nimprove the precision of aerial throwing. Both simulation and real-world\nexperimental results demonstrate that the proposed system achieves greater\nagility and precision in airdrop missions.", "AI": {"tldr": "This paper develops an autonomous airdrop system using an aerial manipulator to improve precision and agility in complex environments.", "motivation": "Autonomous aerial systems encounter challenges like abrupt control mode switching, system delays, and errors during airdrop missions, requiring innovative solutions.", "method": "The paper introduces an aerial manipulator with additional actuated degrees of freedom for tracking error compensation, smooth trajectory design for payload release, and a hierarchical disturbance compensation in NMPC.", "result": "Through simulations and real-world experiments, the system demonstrated enhanced agility, precision, and robustness in airdrop operations.", "conclusion": "The proposed system effectively improves the performance of autonomous airdrop missions by mitigating control errors and optimizing trajectory execution."}}
{"id": "2507.13544", "pdf": "https://arxiv.org/pdf/2507.13544", "abs": "https://arxiv.org/abs/2507.13544", "authors": ["Mohamed Achref Ben Ammar", "Mohamed Taha Bennani"], "title": "A Computational Approach to Modeling Conversational Systems: Analyzing Large-Scale Quasi-Patterned Dialogue Flows", "categories": ["cs.CL", "68T50, 05C85, 68T05, 68R10", "I.2.7; I.2.4; H.3.3; I.5.0"], "comment": null, "summary": "The analysis of conversational dynamics has gained increasing importance with\nthe rise of large language model-based systems, which interact with users\nacross diverse contexts. In this work, we propose a novel computational\nframework for constructing conversational graphs that capture the flow and\nstructure of loosely organized dialogues, referred to as quasi-patterned\nconversations. We introduce the Filter & Reconnect method, a novel graph\nsimplification technique that minimizes noise while preserving semantic\ncoherence and structural integrity of conversational graphs. Through\ncomparative analysis, we demonstrate that the use of large language models\ncombined with our graph simplification technique has resulted in semantic\nmetric S increasing by a factor of 2.06 compared to previous approaches while\nsimultaneously enforcing a tree-like structure with 0 {\\delta}-hyperbolicity,\nensuring optimal clarity in conversation modeling. This work provides a\ncomputational method for analyzing large-scale dialogue datasets, with\npractical applications related to monitoring automated systems such as\nchatbots, dialogue management tools, and user behavior analytics.", "AI": {"tldr": "The paper introduces a framework using conversational graphs and a novel Filter & Reconnect method to improve analysis of loosely structured dialogues, achieving higher semantic clarity.", "motivation": "To improve the analysis of conversational dynamics for large language model systems, especially in loosely structured dialogues.", "method": "They propose a computational framework constructing conversational graphs and introduce the Filter & Reconnect method for simplifying graphs while maintaining semantic coherence.", "result": "Demonstrated a 2.06x improvement in semantic metric S and 0 \u03b4-hyperbolicity, ensuring enhanced coherence and tree-like structure in conversational graphs.", "conclusion": "The method supports better analysis of large-scale dialogue datasets and has applications in chatbot monitoring, dialogue tools, and user behavior analysis."}}
{"id": "2507.13386", "pdf": "https://arxiv.org/pdf/2507.13386", "abs": "https://arxiv.org/abs/2507.13386", "authors": ["Yang Zhang", "Er Jin", "Yanfei Dong", "Yixuan Wu", "Philip Torr", "Ashkan Khakzar", "Johannes Stegmaier", "Kenji Kawaguchi"], "title": "Minimalist Concept Erasure in Generative Models", "categories": ["cs.CV", "cs.LG"], "comment": "ICML2025", "summary": "Recent advances in generative models have demonstrated remarkable\ncapabilities in producing high-quality images, but their reliance on\nlarge-scale unlabeled data has raised significant safety and copyright\nconcerns. Efforts to address these issues by erasing unwanted concepts have\nshown promise. However, many existing erasure methods involve excessive\nmodifications that compromise the overall utility of the model. In this work,\nwe address these issues by formulating a novel minimalist concept erasure\nobjective based \\emph{only} on the distributional distance of final generation\noutputs. Building on our formulation, we derive a tractable loss for\ndifferentiable optimization that leverages backpropagation through all\ngeneration steps in an end-to-end manner. We also conduct extensive analysis to\nshow theoretical connections with other models and methods. To improve the\nrobustness of the erasure, we incorporate neuron masking as an alternative to\nmodel fine-tuning. Empirical evaluations on state-of-the-art flow-matching\nmodels demonstrate that our method robustly erases concepts without degrading\noverall model performance, paving the way for safer and more responsible\ngenerative models.", "AI": {"tldr": "The paper introduces a method to safely erase specific concepts from generative models without compromising their utility.", "motivation": "The reliance of generative models on large-scale unlabeled data raises safety and copyright concerns, prompting efforts to erase unwanted concepts.", "method": "The proposed method defines a minimalist concept erasure objective using the distributional distance of outputs and incorporates neuron masking to enhance robustness.", "result": "The analysis shows that the proposed method effectively erases concepts without damaging overall model performance, demonstrated on flow-matching generative models.", "conclusion": "The paper highlights a practical and robust approach for safer generative models, contributing to their responsible deployment."}}
{"id": "2507.13540", "pdf": "https://arxiv.org/pdf/2507.13540", "abs": "https://arxiv.org/abs/2507.13540", "authors": ["Yongyi Yang", "Hidenori Tanaka", "Wei Hu"], "title": "Provable Low-Frequency Bias of In-Context Learning of Representations", "categories": ["cs.LG"], "comment": null, "summary": "In-context learning (ICL) enables large language models (LLMs) to acquire new\nbehaviors from the input sequence alone without any parameter updates. Recent\nstudies have shown that ICL can surpass the original meaning learned in\npretraining stage through internalizing the structure the data-generating\nprocess (DGP) of the prompt into the hidden representations. However, the\nmechanisms by which LLMs achieve this ability is left open. In this paper, we\npresent the first rigorous explanation of such phenomena by introducing a\nunified framework of double convergence, where hidden representations converge\nboth over context and across layers. This double convergence process leads to\nan implicit bias towards smooth (low-frequency) representations, which we prove\nanalytically and verify empirically. Our theory explains several open empirical\nobservations, including why learned representations exhibit globally structured\nbut locally distorted geometry, and why their total energy decays without\nvanishing. Moreover, our theory predicts that ICL has an intrinsic robustness\ntowards high-frequency noise, which we empirically confirm. These results\nprovide new insights into the underlying mechanisms of ICL, and a theoretical\nfoundation to study it that hopefully extends to more general data\ndistributions and settings.", "AI": {"tldr": "This paper introduces a framework, called double convergence, to explain how in-context learning (ICL) in large language models (LLMs) works, providing insights into its mechanisms and robustness.", "motivation": "The motivation behind this study is to understand how LLMs achieve in-context learning, particularly why they can internalize data generation processes and display structured hidden representations without parameter updates.", "method": "The authors propose a unified framework of double convergence, where hidden representations converge over both context and across layers, leading to biases towards smooth, low-frequency representations. They verify the framework with analytical proofs and empirical experiments.", "result": "The authors found that the double convergence framework explains phenomena such as globally structured but locally distorted geometry of representations, non-vanishing energy decay, and intrinsic robustness against high-frequency noise in ICL.", "conclusion": "The paper establishes a theoretical foundation for studying in-context learning in large language models, providing explanations for observed phenomena and insights into its robustness and mechanisms."}}
{"id": "2507.13956", "pdf": "https://arxiv.org/pdf/2507.13956", "abs": "https://arxiv.org/abs/2507.13956", "authors": ["Yutao Jin", "Haowen Xiao", "Jielei Chu", "Fengmao Lv", "Yuxiao Li", "Tianrui Li"], "title": "Cross-modal Causal Intervention for Alzheimer's Disease Prediction", "categories": ["cs.AI", "cs.CV", "cs.MM"], "comment": null, "summary": "Mild Cognitive Impairment (MCI) serves as a prodromal stage of Alzheimer's\nDisease (AD), where early identification and intervention can effectively slow\nthe progression to dementia. However, diagnosing AD remains a significant\nchallenge in neurology due to the confounders caused mainly by the selection\nbias of multimodal data and the complex relationships between variables. To\naddress these issues, we propose a novel visual-language causal intervention\nframework named Alzheimer's Disease Prediction with Cross-modal Causal\nIntervention (ADPC) for diagnostic assistance. Our ADPC employs large language\nmodel (LLM) to summarize clinical data under strict templates, maintaining\nstructured text outputs even with incomplete or unevenly distributed datasets.\nThe ADPC model utilizes Magnetic Resonance Imaging (MRI), functional MRI (fMRI)\nimages and textual data generated by LLM to classify participants into\nCognitively Normal (CN), MCI, and AD categories. Because of the presence of\nconfounders, such as neuroimaging artifacts and age-related biomarkers,\nnon-causal models are likely to capture spurious input-output correlations,\ngenerating less reliable results. Our framework implicitly eliminates\nconfounders through causal intervention. Experimental results demonstrate the\noutstanding performance of our method in distinguishing CN/MCI/AD cases,\nachieving state-of-the-art (SOTA) metrics across most evaluation metrics. The\nstudy showcases the potential of integrating causal reasoning with multi-modal\nlearning for neurological disease diagnosis.", "AI": {"tldr": "This paper proposes ADPC, a causal intervention framework, for early diagnosis of Alzheimer's Disease using multimodal data including MRI, fMRI, and LLM-generated textual data, achieving state-of-the-art results.", "motivation": "Diagnosing Alzheimer's Disease is challenging due to confounders like selection bias in multimodal data and complex inter-variable relationships, and early detection is crucial to slow progression to dementia.", "method": "The authors propose the ADPC framework, which leverages a large language model to formalize clinical data and combines MRI, fMRI, and text data for classification using causal intervention to mitigate confounders.", "result": "The ADPC framework delivers state-of-the-art performance in classifying cases as Cognitively Normal, Mild Cognitive Impairment, or Alzheimer's Disease across most evaluation metrics.", "conclusion": "Integrating causal reasoning with multimodal learning proves effective for advanced and reliable neurological disease diagnosis, specifically for Alzheimer's Disease."}}
{"id": "2507.13940", "pdf": "https://arxiv.org/pdf/2507.13940", "abs": "https://arxiv.org/abs/2507.13940", "authors": ["Qingyi Chen", "Ahmed H. Qureshi"], "title": "NeHMO: Neural Hamilton-Jacobi Reachability Learning for Decentralized Safe Multi-Agent Motion Planning", "categories": ["cs.RO"], "comment": null, "summary": "Safe Multi-Agent Motion Planning (MAMP) is a significant challenge in\nrobotics. Despite substantial advancements, existing methods often face a\ndilemma. Decentralized algorithms typically rely on predicting the behavior of\nother agents, sharing contracts, or maintaining communication for safety, while\ncentralized approaches struggle with scalability and real-time decision-making.\nTo address these challenges, we introduce Neural Hamilton-Jacobi Reachability\nLearning (HJR) for Decentralized Multi-Agent Motion Planning. Our method\nprovides scalable neural HJR modeling to tackle high-dimensional configuration\nspaces and capture worst-case collision and safety constraints between agents.\nWe further propose a decentralized trajectory optimization framework that\nincorporates the learned HJR solutions to solve MAMP tasks in real-time. We\ndemonstrate that our method is both scalable and data-efficient, enabling the\nsolution of MAMP problems in higher-dimensional scenarios with complex\ncollision constraints. Our approach generalizes across various dynamical\nsystems, including a 12-dimensional dual-arm setup, and outperforms a range of\nstate-of-the-art techniques in successfully addressing challenging MAMP tasks.\nVideo demonstrations are available at https://youtu.be/IZiePX0p1Mc.", "AI": {"tldr": "This paper introduces Neural Hamilton-Jacobi Reachability Learning (HJR) for decentralized multi-agent motion planning, addressing scalability and safety concerns in robotics.", "motivation": "Existing solutions face scalability issues in centralized systems and safety challenges in decentralized methods, creating a need for a unified approach.", "method": "The researchers developed scalable neural HJR modeling and a decentralized trajectory optimization framework to solve motion planning problems in real-time.", "result": "The proposed method efficiently handles high-dimensional scenarios, generalizes to diverse dynamical systems, and outperforms state-of-the-art techniques.", "conclusion": "Neural HJR shows promise in solving decentralized MAMP tasks, offering scalability, safety, and real-time capabilities across complex conditions and systems."}}
{"id": "2507.13551", "pdf": "https://arxiv.org/pdf/2507.13551", "abs": "https://arxiv.org/abs/2507.13551", "authors": ["Feng Chen", "Weizhe Xu", "Changye Li", "Serguei Pakhomov", "Alex Cohen", "Simran Bhola", "Sandy Yin", "Sunny X Tang", "Michael Mackinley", "Lena Palaniyappan", "Dror Ben-Zeev", "Trevor Cohen"], "title": "Reading Between the Lines: Combining Pause Dynamics and Semantic Coherence for Automated Assessment of Thought Disorder", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Formal thought disorder (FTD), a hallmark of schizophrenia spectrum\ndisorders, manifests as incoherent speech and poses challenges for clinical\nassessment. Traditional clinical rating scales, though validated, are\nresource-intensive and lack scalability. Automated speech analysis with\nautomatic speech recognition (ASR) allows for objective quantification of\nlinguistic and temporal features of speech, offering scalable alternatives. The\nuse of utterance timestamps in ASR captures pause dynamics, which are thought\nto reflect the cognitive processes underlying speech production. However, the\nutility of integrating these ASR-derived features for assessing FTD severity\nrequires further evaluation. This study integrates pause features with semantic\ncoherence metrics across three datasets: naturalistic self-recorded diaries\n(AVH, n = 140), structured picture descriptions (TOPSY, n = 72), and dream\nnarratives (PsyCL, n = 43). We evaluated pause related features alongside\nestablished coherence measures, using support vector regression (SVR) to\npredict clinical FTD scores. Key findings demonstrate that pause features alone\nrobustly predict the severity of FTD. Integrating pause features with semantic\ncoherence metrics enhanced predictive performance compared to semantic-only\nmodels, with integration of independent models achieving correlations up to\n\\r{ho} = 0.649 and AUC = 83.71% for severe cases detection (TOPSY, with best\n\\r{ho} = 0.584 and AUC = 79.23% for semantic-only models). The performance\ngains from semantic and pause features integration held consistently across all\ncontexts, though the nature of pause patterns was dataset-dependent. These\nfindings suggest that frameworks combining temporal and semantic analyses\nprovide a roadmap for refining the assessment of disorganized speech and\nadvance automated speech analysis in psychosis.", "AI": {"tldr": "This study demonstrates that integrating pause features with semantic coherence metrics improves automated analysis of formal thought disorder (FTD) severity, yielding robust and scalable diagnostic tools.", "motivation": "The motivation is to address challenges in assessing formal thought disorder (FTD) in schizophrenia spectrum disorders. Traditional methods are resource-intensive, prompting the need for scalable, automated alternatives like speech analysis using pause features and semantic coherence metrics.", "method": "The study leverages automatic speech recognition (ASR) to extract pause features and semantic coherence metrics in three datasets with differing speech contexts. Support vector regression (SVR) is used to predict clinical FTD scores and evaluate model performance.", "result": "Pause features alone successfully predict FTD severity, while integrating them with semantic coherence metrics boosts predictive accuracy. The combined approach achieves notable correlations (up to \\u03c1 = 0.649) and high AUC values (~83.71%) for severe case detection, outperforming semantic-only models.", "conclusion": "Automated analysis combining temporal (pause) and semantic features is a promising framework for improving FTD assessment. This approach enhances prediction accuracy and offers scalable solutions for psychosis evaluation."}}
{"id": "2507.13387", "pdf": "https://arxiv.org/pdf/2507.13387", "abs": "https://arxiv.org/abs/2507.13387", "authors": ["Chihiro Noguchi", "Takaki Yamamoto"], "title": "From Binary to Semantic: Utilizing Large-Scale Binary Occupancy Data for 3D Semantic Occupancy Prediction", "categories": ["cs.CV", "eess.IV"], "comment": "Accepted to ICCV Workshop 2025", "summary": "Accurate perception of the surrounding environment is essential for safe\nautonomous driving. 3D occupancy prediction, which estimates detailed 3D\nstructures of roads, buildings, and other objects, is particularly important\nfor vision-centric autonomous driving systems that do not rely on LiDAR\nsensors. However, in 3D semantic occupancy prediction -- where each voxel is\nassigned a semantic label -- annotated LiDAR point clouds are required, making\ndata acquisition costly. In contrast, large-scale binary occupancy data, which\nonly indicate occupied or free space without semantic labels, can be collected\nat a lower cost. Despite their availability, the potential of leveraging such\ndata remains unexplored. In this study, we investigate the utilization of\nlarge-scale binary occupancy data from two perspectives: (1) pre-training and\n(2) learning-based auto-labeling. We propose a novel binary occupancy-based\nframework that decomposes the prediction process into binary and semantic\noccupancy modules, enabling effective use of binary occupancy data. Our\nexperimental results demonstrate that the proposed framework outperforms\nexisting methods in both pre-training and auto-labeling tasks, highlighting its\neffectiveness in enhancing 3D semantic occupancy prediction. The code is\navailable at https://github.com/ToyotaInfoTech/b2s-occupancy", "AI": {"tldr": "The paper addresses the challenge of accurate 3D semantic occupancy prediction for vision-centric autonomous driving systems without relying on costly LiDAR-annotated datasets by utilizing large-scale binary occupancy data.", "motivation": "The motivation is to improve vision-centric autonomous driving systems by making 3D semantic occupancy prediction cost-effective and feasible, using widely available binary occupancy data instead of expensive LiDAR data.", "method": "The authors propose a binary occupancy-based framework that splits the process into binary and semantic occupancy modules, facilitating the use of binary occupancy data for pre-training and learning-based auto-labeling.", "result": "The experimental results show that the framework outperforms existing methods in pre-training and auto-labeling tasks, improving the efficiency and accuracy of 3D semantic occupancy predictions.", "conclusion": "The study concludes that leveraging large-scale binary occupancy data is an effective way to enhance 3D semantic occupancy prediction while reducing dependency on costly annotated datasets."}}
{"id": "2507.13542", "pdf": "https://arxiv.org/pdf/2507.13542", "abs": "https://arxiv.org/abs/2507.13542", "authors": ["Beka Begiashvili", "Carlos J. Fernandez-Candel", "Mat\u00edas P\u00e9rez Paredes"], "title": "Acoustic Index: A Novel AI-Driven Parameter for Cardiac Disease Risk Stratification Using Echocardiography", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Traditional echocardiographic parameters such as ejection fraction (EF) and\nglobal longitudinal strain (GLS) have limitations in the early detection of\ncardiac dysfunction. EF often remains normal despite underlying pathology, and\nGLS is influenced by load conditions and vendor variability. There is a growing\nneed for reproducible, interpretable, and operator-independent parameters that\ncapture subtle and global cardiac functional alterations.\n  We introduce the Acoustic Index, a novel AI-derived echocardiographic\nparameter designed to quantify cardiac dysfunction from standard ultrasound\nviews. The model combines Extended Dynamic Mode Decomposition (EDMD) based on\nKoopman operator theory with a hybrid neural network that incorporates clinical\nmetadata. Spatiotemporal dynamics are extracted from echocardiographic\nsequences to identify coherent motion patterns. These are weighted via\nattention mechanisms and fused with clinical data using manifold learning,\nresulting in a continuous score from 0 (low risk) to 1 (high risk).\n  In a prospective cohort of 736 patients, encompassing various cardiac\npathologies and normal controls, the Acoustic Index achieved an area under the\ncurve (AUC) of 0.89 in an independent test set. Cross-validation across five\nfolds confirmed the robustness of the model, showing that both sensitivity and\nspecificity exceeded 0.8 when evaluated on independent data. Threshold-based\nanalysis demonstrated stable trade-offs between sensitivity and specificity,\nwith optimal discrimination near this threshold.\n  The Acoustic Index represents a physics-informed, interpretable AI biomarker\nfor cardiac function. It shows promise as a scalable, vendor-independent tool\nfor early detection, triage, and longitudinal monitoring. Future directions\ninclude external validation, longitudinal studies, and adaptation to\ndisease-specific classifiers.", "AI": {"tldr": "A novel AI-derived echocardiographic parameter, Acoustic Index, quantifies cardiac dysfunction using ultrasound sequences and clinical data, exhibiting high accuracy (AUC of 0.89).", "motivation": "Early detection of cardiac dysfunction remains challenging due to limitations in traditional echocardiographic parameters like EF and GLS.", "method": "The paper introduces the Acoustic Index, combining EDMD and a hybrid neural network to process spatiotemporal echocardiographic data and clinical metadata into a continuous 0-1 risk score.", "result": "Acoustic Index demonstrates strong predictive performance (AUC 0.89) in a cohort of 736 patients, with consistent sensitivity and specificity above 0.8 during cross-validation.", "conclusion": "The Acoustic Index is an interpretable and scalable AI biomarker with potential for widespread clinical use to detect and monitor cardiac dysfunction, requiring further external validation and disease-specific adaptations."}}
{"id": "2507.13958", "pdf": "https://arxiv.org/pdf/2507.13958", "abs": "https://arxiv.org/abs/2507.13958", "authors": ["Pedro Cabalar", "Mart\u00edn Di\u00e9guez", "Fran\u00e7ois Olivier", "Torsten Schaub", "Igor St\u00e9phan"], "title": "Towards Constraint Temporal Answer Set Programming", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "Reasoning about dynamic systems with a fine-grained temporal and numeric\nresolution presents significant challenges for logic-based approaches like\nAnswer Set Programming (ASP). To address this, we introduce and elaborate upon\na novel temporal and constraint-based extension of the logic of Here-and-There\nand its nonmonotonic equilibrium extension, representing, to the best of our\nknowledge, the first approach to nonmonotonic temporal reasoning with\nconstraints specifically tailored for ASP. This expressive system is achieved\nby a synergistic combination of two foundational ASP extensions: the\nlinear-time logic of Here-and-There, providing robust nonmonotonic temporal\nreasoning capabilities, and the logic of Here-and-There with constraints,\nenabling the direct integration and manipulation of numeric constraints, among\nothers. This work establishes the foundational logical framework for tackling\ncomplex dynamic systems with high resolution within the ASP paradigm.", "AI": {"tldr": "This paper introduces a novel extension to Answer Set Programming (ASP) for reasoning about dynamic systems using temporal and numeric constraints.", "motivation": "To address challenges in reasoning about dynamic systems with fine-grained temporal and numeric resolution using ASP.", "method": "Proposes a new framework combining linear-time logic of Here-and-There and constraints tailored for ASP.", "result": "Developed a logical foundation enabling nonmonotonic temporal reasoning and numeric constraints within ASP.", "conclusion": "The approach establishes a path for reasoning about complex, high-resolution dynamic systems under ASP."}}
{"id": "2507.13969", "pdf": "https://arxiv.org/pdf/2507.13969", "abs": "https://arxiv.org/abs/2507.13969", "authors": ["Maria Eduarda Silva de Macedo", "Ana Paula Chiarelli de Souza", "Roberto Silvio Ubertino Rosso Jr.", "Yuri Kaszubowski Lopes"], "title": "A Minimalist Controller for Autonomously Self-Aggregating Robotic Swarms: Enabling Compact Formations in Multitasking Scenarios", "categories": ["cs.RO", "cs.MA"], "comment": "7 pages total (6 pages of content + 1 page of references). Short\n  paper manuscript submitted to TAROS 2025", "summary": "The deployment of simple emergent behaviors in swarm robotics has been\nwell-rehearsed in the literature. A recent study has shown how self-aggregation\nis possible in a multitask approach -- where multiple self-aggregation task\ninstances occur concurrently in the same environment. The multitask approach\nposes new challenges, in special, how the dynamic of each group impacts the\nperformance of others. So far, the multitask self-aggregation of groups of\nrobots suffers from generating a circular formation -- that is not fully\ncompact -- or is not fully autonomous. In this paper, we present a multitask\nself-aggregation where groups of homogeneous robots sort themselves into\ndifferent compact clusters, relying solely on a line-of-sight sensor. Our\nmultitask self-aggregation behavior was able to scale well and achieve a\ncompact formation. We report scalability results from a series of simulation\ntrials with different configurations in the number of groups and the number of\nrobots per group. We were able to improve the multitask self-aggregation\nbehavior performance in terms of the compactness of the clusters, keeping the\nproportion of clustered robots found in other studies.", "AI": {"tldr": "The paper explores multitask self-aggregation in swarm robotics and improves cluster compactness using line-of-sight sensors.", "motivation": "Prior studies revealed challenges in multitask self-aggregation, such as non-compact circular formations and limited autonomy.", "method": "The authors developed a behavior for homogeneous robots utilizing a line-of-sight sensor to autonomously form compact clusters in multitask environments.", "result": "Simulation trials demonstrated scalability across different configurations, achieving compact formations while maintaining clustering efficiency.", "conclusion": "Their approach enhances multitask self-aggregation performance, proving both scalable and effective in enhancing cluster compactness."}}
{"id": "2507.13563", "pdf": "https://arxiv.org/pdf/2507.13563", "abs": "https://arxiv.org/abs/2507.13563", "authors": ["Kirill Borodin", "Nikita Vasiliev", "Vasiliy Kudryavtsev", "Maxim Maslov", "Mikhail Gorodnichev", "Oleg Rogov", "Grach Mkrtchian"], "title": "A Data-Centric Framework for Addressing Phonetic and Prosodic Challenges in Russian Speech Generative Models", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "The work is still in progress", "summary": "Russian speech synthesis presents distinctive challenges, including vowel\nreduction, consonant devoicing, variable stress patterns, homograph ambiguity,\nand unnatural intonation. This paper introduces Balalaika, a novel dataset\ncomprising more than 2,000 hours of studio-quality Russian speech with\ncomprehensive textual annotations, including punctuation and stress markings.\nExperimental results show that models trained on Balalaika significantly\noutperform those trained on existing datasets in both speech synthesis and\nenhancement tasks. We detail the dataset construction pipeline, annotation\nmethodology, and results of comparative evaluations.", "AI": {"tldr": "The paper introduces Balalaika, a large, annotated Russian speech dataset, and demonstrates its utility in outperforming existing datasets in speech synthesis.", "motivation": "Russian speech synthesis faces unique language-specific challenges like vowel reduction, consonant devoicing, stress variability, and intonation issues.", "method": "The authors created Balalaika, a 2,000-hour studio-quality Russian speech dataset with detailed annotations, to address these challenges and rigorously evaluated it against existing datasets.", "result": "Models trained on Balalaika performed significantly better than those trained on previous datasets in speech synthesis and enhancement tasks.", "conclusion": "Using a high-quality, extensively annotated dataset like Balalaika provides substantial improvements for Russian speech synthesis tasks, addressing language-specific complexities effectively."}}
{"id": "2507.13397", "pdf": "https://arxiv.org/pdf/2507.13397", "abs": "https://arxiv.org/abs/2507.13397", "authors": ["Kaiyuan Zhai", "Juan Chen", "Chao Wang", "Zeyi Xu"], "title": "InSyn: Modeling Complex Interactions for Pedestrian Trajectory Prediction", "categories": ["cs.CV"], "comment": null, "summary": "Accurate pedestrian trajectory prediction is crucial for intelligent\napplications, yet it remains highly challenging due to the complexity of\ninteractions among pedestrians. Previous methods have primarily relied on\nrelative positions to model pedestrian interactions; however, they tend to\noverlook specific interaction patterns such as paired walking or conflicting\nbehaviors, limiting the prediction accuracy in crowded scenarios. To address\nthis issue, we propose InSyn (Interaction-Synchronization Network), a novel\nTransformer-based model that explicitly captures diverse interaction patterns\n(e.g., walking in sync or conflicting) while effectively modeling\ndirection-sensitive social behaviors. Additionally, we introduce a training\nstrategy termed Seq-Start of Seq (SSOS), designed to alleviate the common issue\nof initial-step divergence in numerical time-series prediction. Experiments on\nthe ETH and UCY datasets demonstrate that our model outperforms recent\nbaselines significantly, especially in high-density scenarios. Furthermore, the\nSSOS strategy proves effective in improving sequential prediction performance,\nreducing the initial-step prediction error by approximately 6.58%.", "AI": {"tldr": "This paper proposes InSyn, a novel Transformer-based model for pedestrian trajectory prediction that enhances accuracy in crowded scenarios by capturing specific interaction patterns and introduces SSOS for better initial-step predictions.", "motivation": "To improve pedestrian trajectory prediction accuracy in crowded scenarios by addressing the limitations of previous methods in capturing diverse interaction patterns like paired walking or conflicting behaviors.", "method": "Proposed InSyn, a Transformer-based model to capture diverse interaction patterns and introduced the SSOS training strategy to reduce initial-step divergence in sequential predictions.", "result": "Experiments on the ETH and UCY datasets showed InSyn significantly outperformed recent baselines, especially in high-density scenarios, while SSOS reduced initial-step errors by 6.58%.", "conclusion": "InSyn and the SSOS strategy contribute to improving pedestrian trajectory prediction both in terms of accuracy in crowded conditions and initial-step divergence."}}
{"id": "2507.13556", "pdf": "https://arxiv.org/pdf/2507.13556", "abs": "https://arxiv.org/abs/2507.13556", "authors": ["Rui Wang", "Steven Klee", "Alexis Roos"], "title": "Time Series Forecastability Measures", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper proposes using two metrics to quantify the forecastability of time\nseries prior to model development: the spectral predictability score and the\nlargest Lyapunov exponent. Unlike traditional model evaluation metrics, these\nmeasures assess the inherent forecastability characteristics of the data before\nany forecast attempts. The spectral predictability score evaluates the strength\nand regularity of frequency components in the time series, whereas the Lyapunov\nexponents quantify the chaos and stability of the system generating the data.\nWe evaluated the effectiveness of these metrics on both synthetic and\nreal-world time series from the M5 forecast competition dataset. Our results\ndemonstrate that these two metrics can correctly reflect the inherent\nforecastability of a time series and have a strong correlation with the actual\nforecast performance of various models. By understanding the inherent\nforecastability of time series before model training, practitioners can focus\ntheir planning efforts on products and supply chain levels that are more\nforecastable, while setting appropriate expectations or seeking alternative\nstrategies for products with limited forecastability.", "AI": {"tldr": "The paper introduces two metrics\u2014the spectral predictability score and the largest Lyapunov exponent\u2014for evaluating the forecastability of time series before model development.", "motivation": "To quantify inherent forecastability in time series data prior to forecast modeling, helping practitioners focus on more predictable data.", "method": "Utilizes the spectral predictability score to measure frequency regularity and Lyapunov exponents to assess chaos and stability. Tested these metrics on synthetic and real-world data, including the M5 competition dataset.", "result": "Demonstrated a strong correlation between the proposed metrics and actual forecast performance of various models.", "conclusion": "The metrics allow pre-modeling evaluation of time series data, enabling better planning and expectation management for forecasting tasks."}}
{"id": "2507.14032", "pdf": "https://arxiv.org/pdf/2507.14032", "abs": "https://arxiv.org/abs/2507.14032", "authors": ["Lam Nguyen", "Erika Barcelos", "Roger French", "Yinghui Wu"], "title": "KROMA: Ontology Matching with Knowledge Retrieval and Large Language Models", "categories": ["cs.AI"], "comment": "Accepted to the 24th International Semantic Web Conference Research\n  Track (ISWC 2025)", "summary": "Ontology Matching (OM) is a cornerstone task of semantic interoperability,\nyet existing systems often rely on handcrafted rules or specialized models with\nlimited adaptability. We present KROMA, a novel OM framework that harnesses\nLarge Language Models (LLMs) within a Retrieval-Augmented Generation (RAG)\npipeline to dynamically enrich the semantic context of OM tasks with\nstructural, lexical, and definitional knowledge. To optimize both performance\nand efficiency, KROMA integrates a bisimilarity-based concept matching and a\nlightweight ontology refinement step, which prune candidate concepts and\nsubstantially reduce the communication overhead from invoking LLMs. Through\nexperiments on multiple benchmark datasets, we show that integrating knowledge\nretrieval with context-augmented LLMs significantly enhances ontology matching,\noutperforming both classic OM systems and cutting-edge LLM-based approaches\nwhile keeping communication overhead comparable. Our study highlights the\nfeasibility and benefit of the proposed optimization techniques (targeted\nknowledge retrieval, prompt enrichment, and ontology refinement) for ontology\nmatching at scale.", "AI": {"tldr": "KROMA leverages Large Language Models in a Retrieval-Augmented Generation framework to enhance ontology matching using efficient optimization strategies and knowledge retrieval.", "motivation": "Ontology matching is essential for semantic interoperability, but existing systems lack adaptability and efficiency.", "method": "KROMA employs a combination of context-rich LLM integration, bisimilarity-based concept matching, lightweight ontology refinement, and Retrieval-Augmented Generation pipeline.", "result": "KROMA achieves enhanced ontology matching performance, outperforming classical systems and modern LLM-based alternatives, while maintaining low communication overhead.", "conclusion": "The integration of retrieval and enrichment strategies with scalable ontology refinement demonstrates KROMA's practical benefits and effectiveness for ontology matching."}}
{"id": "2507.13970", "pdf": "https://arxiv.org/pdf/2507.13970", "abs": "https://arxiv.org/abs/2507.13970", "authors": ["Casper Br\u00f6cheler", "Thomas Vroom", "Derrick Timmermans", "Alan van den Akker", "Guangzhi Tang", "Charalampos S. Kouzinopoulos", "Rico M\u00f6ckel"], "title": "A segmented robot grasping perception neural network for edge AI", "categories": ["cs.RO", "cs.AI", "I.2; I.2.9; I.2.10"], "comment": "Accepted by SMC 2025", "summary": "Robotic grasping, the ability of robots to reliably secure and manipulate\nobjects of varying shapes, sizes and orientations, is a complex task that\nrequires precise perception and control. Deep neural networks have shown\nremarkable success in grasp synthesis by learning rich and abstract\nrepresentations of objects. When deployed at the edge, these models can enable\nlow-latency, low-power inference, making real-time grasping feasible in\nresource-constrained environments. This work implements Heatmap-Guided Grasp\nDetection, an end-to-end framework for the detection of 6-Dof grasp poses, on\nthe GAP9 RISC-V System-on-Chip. The model is optimised using hardware-aware\ntechniques, including input dimensionality reduction, model partitioning, and\nquantisation. Experimental evaluation on the GraspNet-1Billion benchmark\nvalidates the feasibility of fully on-chip inference, highlighting the\npotential of low-power MCUs for real-time, autonomous manipulation.", "AI": {"tldr": "The paper focuses on implementing a Heatmap-Guided Grasp Detection framework for robotic grasping on an energy-efficient RISC-V system-on-chip, demonstrating its feasibility for real-time manipulation tasks.", "motivation": "To enable precise and efficient robotic grasping in resource-constrained environments by leveraging optimized deep neural networks for real-time inference on low-power hardware.", "method": "The framework uses Heatmap-Guided Grasp Detection for detecting 6-DoF grasp poses, optimized with hardware-aware techniques like input dimensionality reduction, model partitioning, and quantization, and deployed on the GAP9 RISC-V System-on-Chip.", "result": "Experiments on the GraspNet-1Billion benchmark confirm the feasibility of fully on-chip inference for 6-DoF grasping, showcasing the capabilities of low-power hardware for such tasks.", "conclusion": "The study highlights the potential of deep learning models, executed on low-power microcontroller units, to allow real-time, autonomous robotic grasping in constrained environments."}}
{"id": "2507.13614", "pdf": "https://arxiv.org/pdf/2507.13614", "abs": "https://arxiv.org/abs/2507.13614", "authors": ["Sergio E. Zanotto", "Segun Aroyehun"], "title": "Linguistic and Embedding-Based Profiling of Texts generated by Humans and Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "arXiv admin note: text overlap with arXiv:2412.03025", "summary": "The rapid advancements in large language models (LLMs) have significantly\nimproved their ability to generate natural language, making texts generated by\nLLMs increasingly indistinguishable from human-written texts. While recent\nresearch has primarily focused on using LLMs to classify text as either\nhuman-written and machine-generated texts, our study focus on characterizing\nthese texts using a set of linguistic features across different linguistic\nlevels such as morphology, syntax, and semantics. We select a dataset of\nhuman-written and machine-generated texts spanning 8 domains and produced by 11\ndifferent LLMs. We calculate different linguistic features such as dependency\nlength and emotionality and we use them for characterizing human-written and\nmachine-generated texts along with different sampling strategies, repetition\ncontrols and model release date. Our statistical analysis reveals that\nhuman-written texts tend to exhibit simpler syntactic structures and more\ndiverse semantic content. Furthermore, we calculate the variability of our set\nof features across models and domains. Both human and machine texts show\nstylistic diversity across domains, with humans displaying greater variation in\nour features. Finally, we apply style embeddings to further test variability\namong human-written and machine-generated texts. Notably, newer models output\ntext that is similarly variable, pointing to an homogenization of\nmachine-generated texts.", "AI": {"tldr": "The study characterizes human and machine-generated texts using linguistic features across various linguistic levels.", "motivation": "Investigate linguistic differences between human and machine-generated texts to enable better understanding and analysis.", "method": "Analyzed linguistic features like dependency length and emotionality in texts across 8 domains and 11 LLMs, applying statistical and style embedding analyses.", "result": "Human texts exhibit simpler syntax, greater semantic diversity, and stylistic variation across domains compared to machine-generated texts, which are more homogenized in newer models.", "conclusion": "Human-written texts show distinctive linguistic features and variability compared to machine-generated texts, highlighting stylistic diversity that persists across domains."}}
{"id": "2507.13401", "pdf": "https://arxiv.org/pdf/2507.13401", "abs": "https://arxiv.org/abs/2507.13401", "authors": ["Shreya Kadambi", "Risheek Garrepalli", "Shubhankar Borse", "Munawar Hyatt", "Fatih Porikli"], "title": "MADI: Masking-Augmented Diffusion with Inference-Time Scaling for Visual Editing", "categories": ["cs.CV", "cs.LG"], "comment": "26 pages", "summary": "Despite the remarkable success of diffusion models in text-to-image\ngeneration, their effectiveness in grounded visual editing and compositional\ncontrol remains challenging. Motivated by advances in self-supervised learning\nand in-context generative modeling, we propose a series of simple yet powerful\ndesign choices that significantly enhance diffusion model capacity for\nstructured, controllable generation and editing. We introduce Masking-Augmented\nDiffusion with Inference-Time Scaling (MADI), a framework that improves the\neditability, compositionality and controllability of diffusion models through\ntwo core innovations. First, we introduce Masking-Augmented gaussian Diffusion\n(MAgD), a novel training strategy with dual corruption process which combines\nstandard denoising score matching and masked reconstruction by masking noisy\ninput from forward process. MAgD encourages the model to learn discriminative\nand compositional visual representations, thus enabling localized and\nstructure-aware editing. Second, we introduce an inference-time capacity\nscaling mechanism based on Pause Tokens, which act as special placeholders\ninserted into the prompt for increasing computational capacity at inference\ntime. Our findings show that adopting expressive and dense prompts during\ntraining further enhances performance, particularly for MAgD. Together, these\ncontributions in MADI substantially enhance the editability of diffusion\nmodels, paving the way toward their integration into more general-purpose,\nin-context generative diffusion architectures.", "AI": {"tldr": "The paper introduces Masking-Augmented Diffusion with Inference-Time Scaling (MADI), enhancing diffusion models for better visual editing, compositionality, and controllability through novel training and inference strategies.", "motivation": "The motivation stems from the limitations of existing diffusion models in grounded visual editing and compositional control, aiming to expand their capabilities.", "method": "The proposed method involves Masking-Augmented Gaussian Diffusion (MAgD) for training with dual corruption processes and Pause Tokens for scaling computational ability during inference.", "result": "The approach improves the editability, compositionality, and controllability of diffusion models, showcasing superior structured visual representations and editing capabilities.", "conclusion": "These innovations position diffusion models closer to general-purpose generative frameworks, enhancing their utility in structured and controlled visual editing tasks."}}
{"id": "2507.13569", "pdf": "https://arxiv.org/pdf/2507.13569", "abs": "https://arxiv.org/abs/2507.13569", "authors": ["Mrinal Mathur", "Mike Doan", "Barak Pearlmutter", "Sergey Plis"], "title": "Change of Thought: Adaptive Test-Time Computation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Transformers evaluated in a single, fixed-depth pass are provably limited in\nexpressive power to the constant-depth circuit class TC0. Running a Transformer\nautoregressively removes that ceiling -- first in next-token prediction and,\nmore recently, in chain-of-thought reasoning. Both regimes rely on feedback\nloops that decode internal states into tokens only to re-encode them in\nsubsequent steps. While this \"thinking aloud\" mirrors human reasoning,\nbiological brains iterate without externalising intermediate states as\nlanguage. To boost the expressive power of encoder Transformers without\nresorting to token-level autoregression, we introduce the SELF-Transformer: an\nencoder layer that iteratively refines its own attention weights to a fixed\npoint. Instead of producing -- in one pass -- the alignment matrix that remixes\nthe input sequence, the SELF-Transformer iteratively updates that matrix\ninternally, scaling test-time computation with input difficulty. This\nadaptivity yields up to 20\\% accuracy gains on encoder-style benchmarks without\nincreasing parameter count, demonstrating that input-adaptive alignment at test\ntime offers substantial benefits for only a modest extra compute budget.\nSelf-Transformers thus recover much of the expressive power of iterative\nreasoning while preserving the simplicity of pure encoder architectures.", "AI": {"tldr": "The paper introduces the SELF-Transformer, an encoder that iteratively refines attention weights to overcome the expressive limitations of standard Transformers, showing significant accuracy gains without altering parameter count.", "motivation": "Standard Transformers evaluated in a single pass are limited by their expressive power, and while autoregression boosts this, it introduces token-level external feedback loops resembling language processing. The authors sought a method to enhance encoder-transformers' capability without token-level autoregression.", "method": "The SELF-Transformer refines attention weights iteratively to reach a fixed point, enabling adaptivity to input difficulty during test time and avoiding token-level externalization.", "result": "Tests demonstrated up to 20% accuracy improvement on benchmarks for encoder architectures without added parameters, enabled by adaptive computation based on input complexity.", "conclusion": "SELF-Transformers achieve a balance between enhanced expressive power and the simplicity of encoder architectures, leveraging input-adaptive alignment for improved performance."}}
{"id": "2507.14077", "pdf": "https://arxiv.org/pdf/2507.14077", "abs": "https://arxiv.org/abs/2507.14077", "authors": ["Temiloluwa Prioleau", "Baiying Lu", "Yanjun Cui"], "title": "Glucose-ML: A collection of longitudinal diabetes datasets for development of robust AI solutions", "categories": ["cs.AI", "cs.LG"], "comment": "19 pages, 3 figures, 6 tables", "summary": "Artificial intelligence (AI) algorithms are a critical part of\nstate-of-the-art digital health technology for diabetes management. Yet, access\nto large high-quality datasets is creating barriers that impede development of\nrobust AI solutions. To accelerate development of transparent, reproducible,\nand robust AI solutions, we present Glucose-ML, a collection of 10 publicly\navailable diabetes datasets, released within the last 7 years (i.e., 2018 -\n2025). The Glucose-ML collection comprises over 300,000 days of continuous\nglucose monitor (CGM) data with a total of 38 million glucose samples collected\nfrom 2500+ people across 4 countries. Participants include persons living with\ntype 1 diabetes, type 2 diabetes, prediabetes, and no diabetes. To support\nresearchers and innovators with using this rich collection of diabetes\ndatasets, we present a comparative analysis to guide algorithm developers with\ndata selection. Additionally, we conduct a case study for the task of blood\nglucose prediction - one of the most common AI tasks within the field. Through\nthis case study, we provide a benchmark for short-term blood glucose prediction\nacross all 10 publicly available diabetes datasets within the Glucose-ML\ncollection. We show that the same algorithm can have significantly different\nprediction results when developed/evaluated with different datasets. Findings\nfrom this study are then used to inform recommendations for developing robust\nAI solutions within the diabetes or broader health domain. We provide direct\nlinks to each longitudinal diabetes dataset in the Glucose-ML collection and\nopenly provide our code.", "AI": {"tldr": "Glucose-ML is a collection of 10 public diabetes datasets providing 300,000+ days of CGM data to support AI development for diabetes management.", "motivation": "AI development in diabetes management is hindered by limited quality datasets. Glucose-ML aims to overcome this barrier by providing extensive publicly available data.", "method": "Researchers compiled 10 public datasets, analyzed comparative data selection, and benchmarked an AI algorithm for blood glucose prediction using these datasets.", "result": "Results show significant variability in prediction performance depending on the dataset used, emphasizing the need for careful data selection.", "conclusion": "Utilizing Glucose-ML can improve robust AI solutions for diabetes management, supporting transparent and reproducible research with openly provided code."}}
{"id": "2507.14043", "pdf": "https://arxiv.org/pdf/2507.14043", "abs": "https://arxiv.org/abs/2507.14043", "authors": ["Genliang Li", "Yaxin Cui", "Jinyu Su"], "title": "A multi-strategy improved snake optimizer for three-dimensional UAV path planning and engineering problems", "categories": ["cs.RO", "cs.AI", "cs.CE"], "comment": "59 pages, 22 figures", "summary": "Metaheuristic algorithms have gained widespread application across various\nfields owing to their ability to generate diverse solutions. One such algorithm\nis the Snake Optimizer (SO), a progressive optimization approach. However, SO\nsuffers from the issues of slow convergence speed and susceptibility to local\noptima. In light of these shortcomings, we propose a novel Multi-strategy\nImproved Snake Optimizer (MISO). Firstly, we propose a new adaptive random\ndisturbance strategy based on sine function to alleviate the risk of getting\ntrapped in a local optimum. Secondly, we introduce adaptive Levy flight\nstrategy based on scale factor and leader and endow the male snake leader with\nflight capability, which makes it easier for the algorithm to leap out of the\nlocal optimum and find the global optimum. More importantly, we put forward a\nposition update strategy combining elite leadership and Brownian motion,\neffectively accelerating the convergence speed while ensuring precision.\nFinally, to demonstrate the performance of MISO, we utilize 30 CEC2017 test\nfunctions and the CEC2022 test suite, comparing it with 11 popular algorithms\nacross different dimensions to validate its effectiveness. Moreover, Unmanned\nAerial Vehicle (UAV) has been widely used in various fields due to its\nadvantages of low cost, high mobility and easy operation. However, the UAV path\nplanning problem is crucial for flight safety and efficiency, and there are\nstill challenges in establishing and optimizing the path model. Therefore, we\napply MISO to the UAV 3D path planning problem as well as 6 engineering design\nproblems to assess its feasibility in practical applications. The experimental\nresults demonstrate that MISO exceeds other competitive algorithms in terms of\nsolution quality and stability, establishing its strong potential for\napplication.", "AI": {"tldr": "The paper introduces an improved optimization algorithm, MISO, based on Snake Optimizer to tackle issues of slow convergence and local optima, and demonstrates its effectiveness in test functions, UAV path planning, and engineering problems.", "motivation": "The paper aims to address the limitations of the Snake Optimizer (SO), namely slow convergence speed and susceptibility to local optima, which hinder its performance in solving optimization problems.", "method": "The authors propose the Multi-strategy Improved Snake Optimizer (MISO), incorporating an adaptive random disturbance strategy based on sine function, adaptive Levy flight strategy, and a position update strategy combining elite leadership and Brownian motion.", "result": "MISO was evaluated using 30 CEC2017 test functions, CEC2022 test suite, UAV 3D path planning problems, and 6 engineering design problems. It outperformed 11 popular algorithms in solution quality and stability.", "conclusion": "The experimental results validate that MISO is a highly effective algorithm with strong potential for solving both mathematical and real-world optimization problems."}}
{"id": "2507.13618", "pdf": "https://arxiv.org/pdf/2507.13618", "abs": "https://arxiv.org/abs/2507.13618", "authors": ["Shanbo Cheng", "Yu Bao", "Qian Cao", "Luyang Huang", "Liyan Kang", "Zhicheng Liu", "Yu Lu", "Wenhao Zhu", "Zhichao Huang", "Tao Li", "Sitong Liu", "Ningxin Peng", "Shuaijie She", "Lu Xu", "Nuo Xu", "Sen Yang", "Runsheng Yu", "Yiming Yu", "Liehao Zou", "Hang Li", "Lu Lu", "Yuxuan Wang", "Yonghui Wu"], "title": "Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multilingual translation stands as a challenging task for large language\nmodels (LLMs) to handle intricate language patterns and stilted translations\nthat arise in automated translations. In this paper, we introduce Seed-X, a\nfamily of open-source LLMs comprising instruct and reasoning models, pushing\nthe limits of translation capability with 7B parameter size. The base model is\npre-trained on a diverse, high-quality dataset encompassing both monolingual\nand bilingual content across 28 languages, harnessing the full potential of\nmultilingual data. The instruct model is then finetuned to translate by\nChain-of-Thought (CoT) reasoning and further enhanced through reinforcement\nlearning (RL) to achieve better generalization across diverse language pairs.\nSeed-X achieves performance comparable to leading closed-source models,\nincluding Gemini-2.5 and GPT-4o, across 28 languages, and significantly\noutperforms larger open-source models in both automatic metrics and human\nevaluations. We share the best practices through our optimization process, and\nmake the parameter public available for advancing translation research and\napplications.", "AI": {"tldr": "Seed-X introduces open-source multilingual LLMs optimized for translation, rivaling top closed-source models with only 7B parameters.", "motivation": "Current multilingual translations by LLMs suffer from issues like stilted or unnatural translations, highlighting the need for improved multilingual handling.", "method": "Seed-X trains a 7B parameter model on a multilingual dataset and applies Chain-of-Thought reasoning and reinforcement learning for better translation generalization.", "result": "Seed-X performs on par with top closed-source models like Gemini-2.5 and GPT-4o and surpasses larger open-source models in both metrics and human evaluations.", "conclusion": "Seed-X demonstrates the feasibility of competitive open-source translation models, sharing techniques and parameters for further research and development."}}
{"id": "2507.13403", "pdf": "https://arxiv.org/pdf/2507.13403", "abs": "https://arxiv.org/abs/2507.13403", "authors": ["Morteza Bodaghi", "Majid Hosseini", "Raju Gottumukkala", "Ravi Teja Bhupatiraju", "Iftikhar Ahmad", "Moncef Gabbouj"], "title": "UL-DD: A Multimodal Drowsiness Dataset Using Video, Biometric Signals, and Behavioral Data", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "In this study, we present a comprehensive public dataset for driver\ndrowsiness detection, integrating multimodal signals of facial, behavioral, and\nbiometric indicators. Our dataset includes 3D facial video using a depth\ncamera, IR camera footage, posterior videos, and biometric signals such as\nheart rate, electrodermal activity, blood oxygen saturation, skin temperature,\nand accelerometer data. This data set provides grip sensor data from the\nsteering wheel and telemetry data from the American truck simulator game to\nprovide more information about drivers' behavior while they are alert and\ndrowsy. Drowsiness levels were self-reported every four minutes using the\nKarolinska Sleepiness Scale (KSS). The simulation environment consists of three\nmonitor setups, and the driving condition is completely like a car. Data were\ncollected from 19 subjects (15 M, 4 F) in two conditions: when they were fully\nalert and when they exhibited signs of sleepiness. Unlike other datasets, our\nmultimodal dataset has a continuous duration of 40 minutes for each data\ncollection session per subject, contributing to a total length of 1,400\nminutes, and we recorded gradual changes in the driver state rather than\ndiscrete alert/drowsy labels. This study aims to create a comprehensive\nmultimodal dataset of driver drowsiness that captures a wider range of\nphysiological, behavioral, and driving-related signals. The dataset will be\navailable upon request to the corresponding author.", "AI": {"tldr": "The paper introduces a multimodal dataset for driver drowsiness detection, incorporating facial, behavioral, biometric, and driving telemetry data, collected from 19 subjects over 1400 minutes.", "motivation": "The study aims to address the lack of comprehensive multimodal datasets available for analyzing driver drowsiness, capturing gradual changes in driver states rather than discrete labels.", "method": "The authors collected 3D facial video, IR camera footage, biometric metrics like heart rate and skin temperature, grip sensor data, and telemetry data during driving simulations, with drowsiness levels self-reported every 4 minutes.", "result": "A dataset was created through continuous sessions, integrating a wide range of multimodal signals over a total of 1400 minutes, with gradual state changes recorded.", "conclusion": "The dataset serves as a rich resource for driver drowsiness analysis, advancing research in understanding and detecting gradual driver state changes in a simulated environment."}}
{"id": "2507.13575", "pdf": "https://arxiv.org/pdf/2507.13575", "abs": "https://arxiv.org/abs/2507.13575", "authors": ["Hanzhi Zhou", "Erik Hornberger", "Pengsheng Guo", "Xiyou Zhou", "Saiwen Wang", "Xin Wang", "Yifei He", "Xuankai Chang", "Rene Rauch", "Louis D'hauwe", "John Peebles", "Alec Doane", "Kohen Chia", "Jenna Thibodeau", "Zi-Yi Dou", "Yuanyang Zhang", "Ruoming Pang", "Reed Li", "Zhifeng Chen", "Jeremy Warner", "Zhaoyang Xu", "Sophy Lee", "David Mizrahi", "Ramsey Tantawi", "Chris Chaney", "Kelsey Peterson", "Jun Qin", "Alex Dombrowski", "Mira Chiang", "Aiswarya Raghavan", "Gerard Casamayor", "Qibin Chen", "Aonan Zhang", "Nathalie Tran", "Jianyu Wang", "Hang Su", "Thomas Voice", "Alessandro Pappalardo", "Brycen Wershing", "Prasanth Yadla", "Rui Li", "Priyal Chhatrapati", "Ismael Fernandez", "Yusuf Goren", "Xin Zheng", "Forrest Huang", "Tao Lei", "Eray Yildiz", "Alper Kokmen", "Gokul Santhanam", "Areeba Kamal", "Kaan Elgin", "Dian Ang Yap", "Jeremy Liu", "Peter Gray", "Howard Xing", "Kieran Liu", "Matteo Ronchi", "Moritz Schwarzer-Becker", "Yun Zhu", "Mandana Saebi", "Jeremy Snow", "David Griffiths", "Guillaume Tartavel", "Erin Feldman", "Simon Lehnerer", "Fernando Berm\u00fadez-Medina", "Hans Han", "Joe Zhou", "Xiaoyi Ren", "Sujeeth Reddy", "Zirui Wang", "Tom Gunter", "Albert Antony", "Yuanzhi Li", "John Dennison", "Tony Sun", "Yena Han", "Yi Qin", "Sam Davarnia", "Jeffrey Bigham", "Wayne Shan", "Hannah Gillis Coleman", "Guillaume Klein", "Peng Liu", "Muyang Yu", "Jack Cackler", "Yuan Gao", "Crystal Xiao", "Binazir Karimzadeh", "Zhengdong Zhang", "Felix Bai", "Albin Madappally Jose", "Feng Nan", "Nazir Kamaldin", "Dong Yin", "Hans Hao", "Yanchao Sun", "Yi Hua", "Charles Maalouf", "Alex Guillen Garcia", "Guoli Yin", "Lezhi Li", "Mohana Prasad Sathya Moorthy", "Hongbin Gao", "Jay Tang", "Joanna Arreaza-Taylor", "Faye Lao", "Carina Peng", "Josh Shaffer", "Dan Masi", "Sushma Rao", "Tommi Vehvilainen", "Senyu Tong", "Dongcai Shen", "Yang Zhao", "Chris Bartels", "Peter Fu", "Qingqing Cao", "Christopher Neubauer", "Ethan Li", "Mingfei Gao", "Rebecca Callahan", "Richard Wei", "Patrick Dong", "Alex Braunstein", "Sachin Ravi", "Adolfo Lopez Mendez", "Kaiwei Huang", "Kun Duan", "Haoshuo Huang", "Rui Qian", "Stefano Ligas", "Jordan Huffaker", "Dongxu Li", "Bailin Wang", "Nanzhu Wang", "Anuva Agarwal", "Tait Madsen", "Josh Newnham", "Abhishek Sharma", "Zhile Ren", "Deepak Gopinath", "Erik Daxberger", "Saptarshi Guha", "Oron Levy", "Jing Lu", "Nan Dun", "Marc Kirchner", "Yinfei Yang", "Manjot Bilkhu", "Dave Nelson", "Anthony Spalvieri-Kruse", "Juan Lao Tebar", "Yang Xu", "Phani Mutyala", "Gabriel Jacoby-Cooper", "Yingbo Wang", "Karla Vega", "Vishaal Mahtani", "Darren Botten", "Eric Wang", "Hanli Li", "Matthias Paulik", "Haoran Yan", "Navid Shiee", "Yihao Qian", "Bugu Wu", "Qi Zhu", "Ob Adaranijo", "Bhuwan Dhingra", "Zhe Gan", "Nicholas Seidl", "Grace Duanmu", "Rong Situ", "Yiping Ma", "Yin Xia", "David Riazati", "Vasileios Saveris", "Anh Nguyen", "Michael", "Lee", "Patrick Sonnenberg", "Chinguun Erdenebileg", "Yanghao Li", "Vivian Ma", "James Chou", "Isha Garg", "Mark Lee", "Keen You", "Yuhong Li", "Ransen Niu", "Nandhitha Raghuram", "Pulkit Agrawal", "Henry Mason", "Sumeet Singh", "Keyu He", "Hong-You Chen", "Lucas Guibert", "Shiyu Li", "Varsha Paidi", "Narendran Raghavan", "Mingze Xu", "Yuli Yang", "Sergiu Sima", "Irina Belousova", "Sprite Chu", "Afshin Dehghan", "Philipp Dufter", "David Haldimann", "Zhen Yang", "Margit Bowler", "Chang Liu", "Ying-Chang Cheng", "Vivek Rathod", "Syd Evans", "Wilson Tsao", "Dustin Withers", "Haitian Sun", "Biyao Wang", "Peter Grasch", "Walker Cheng", "Yihao Feng", "Vivek Kumar", "Frank Chu", "Victoria M\u00f6nchJuan Haladjian", "Doug Kang", "Jiarui Lu", "Ciro Sannino", "Max Lam", "Floris Weers", "Bowen Pan", "Kenneth Jung", "Dhaval Doshi", "Fangping Shi", "Olli Saarikivi", "Alp Aygar", "Josh Elman", "Cheng Leong", "Eshan Verma", "Matthew Lei", "Jeff Nichols", "Jiulong Shan", "Donald Zhang", "Lawrence Zhou", "Stephen Murphy", "Xianzhi Du", "Chang Lan", "Ankur Jain", "Elmira Amirloo", "Marcin Eichner", "Naomy Sabo", "Anupama Mann Anupama", "David Qiu", "Zhao Meng", "Michael FitzMaurice", "Peng Zhang", "Simon Yeung", "Chen Chen", "Marco Zuliani", "Andrew Hansen", "Yang Lu", "Brent Ramerth", "Ziyi Zhong", "Parsa Mazaheri", "Matthew Hopkins", "Mengyu Li", "Simon Wang", "David Chen", "Farzin Rasteh", "Chong Wang", "Josh Gardner", "Asaf Liberman", "Haoxuan You", "Andrew Walkingshaw", "Xingyu Zhou", "Jinhao Lei", "Yan Meng", "Quentin Keunebroek", "Sam Wiseman", "Anders Boesen Lindbo Larsen", "Yi Zhang", "Zaid Ahmed", "Haiming Gang", "Aaron Franklin", "Kelvin Zou", "Guillaume Seguin", "Jonathan Janke", "Rachel Burger", "Co Giang", "Cheng Shen", "Jen Liu", "Sanskruti Shah", "Xiang Kong", "Yiran Fei", "TJ Collins", "Chen Zhang", "Zhiyun Lu", "Michael Booker", "Qin Ba", "Yasutaka Tanaka", "Andres Romero Mier Y Teran", "Federico Scozzafava", "Regan Poston", "Jane Li", "Eduardo Jimenez", "Bas Straathof", "Karanjeet Singh", "Lindsay Hislop", "Rajat Arora", "Deepa Seshadri", "Boyue Li", "Colorado Reed", "Zhen Li", "TJ Lu", "Yi Wang", "Kaelen Haag", "Nicholas Lusskin", "Raunak Sinha", "Rahul Nair", "Eldon Schoop", "Mary Beth Kery", "Mehrdad Farajtbar", "Brenda Yang", "George Horrell", "Shiwen Zhao", "Dhruti Shah", "Cha Chen", "Bowen Zhang", "Chang Gao", "Devi Krishna", "Jennifer Mallalieu", "Javier Movellan", "Di Feng", "Emily Zhang", "Sam Xu", "Junting Pan", "Dominik Moritz", "Suma Jayaram", "Kevin Smith", "Dongseong Hwang", "Daniel Parilla", "Jiaming Hu", "You-Cyuan Jhang", "Emad Soroush", "Fred Hohman", "Nan Du", "Emma Wang", "Sam Dodge", "Pragnya Sridhar", "Joris Pelemans", "Wei Fang", "Nina Wenzel", "Joseph Yitan Cheng", "Hadas Kotek", "Chung-Cheng Chiu", "Meng Cao", "Haijing Fu", "Ruixuan Hou", "Ke Ye", "Diane Zhu", "Nikhil Bhendawade", "Joseph Astrauskas", "Jian Liu", "Sai Aitharaju", "Wentao Wu", "Artsiom Peshko", "Hyunjik Kim", "Nilesh Shahdadpuri", "Andy De Wang", "Qi Shan", "Piotr Maj", "Raul Rea Menacho", "Justin Lazarow", "Eric Liang Yang", "Arsalan Farooq", "Donghan Yu", "David G\u00fcera", "Minsik Cho", "Kavya Nerella", "Yongqiang Wang", "Tao Jia", "John Park", "Jeff Lai", "Haotian Zhang", "Futang Peng", "Daniele Molinari", "Aparna Rajamani", "Tyler Johnson", "Lauren Gardiner", "Chao Jia", "Violet Yao", "Wojciech Kryscinski", "Xiujun Li", "Shang-Chen Wu"], "title": "Apple Intelligence Foundation Language Models: Tech Report 2025", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce two multilingual, multimodal foundation language models that\npower Apple Intelligence features across Apple devices and services: i a\n3B-parameter on-device model optimized for Apple silicon through architectural\ninnovations such as KV-cache sharing and 2-bit quantization-aware training; and\nii a scalable server model built on a novel Parallel-Track Mixture-of-Experts\nPT-MoE transformer that combines track parallelism, mixture-of-experts sparse\ncomputation, and interleaved global-local attention to deliver high quality\nwith competitive cost on Apple's Private Cloud Compute platform. Both models\nare trained on large-scale multilingual and multimodal datasets sourced via\nresponsible web crawling, licensed corpora, and high-quality synthetic data,\nthen further refined with supervised fine-tuning and reinforcement learning on\na new asynchronous platform. The resulting models support several additional\nlanguages while understanding images and executing tool calls. In public\nbenchmarks and human evaluations, both the server model and the on-device model\nmatch or surpass comparably sized open baselines.\n  A new Swift-centric Foundation Models framework exposes guided generation,\nconstrained tool calling, and LoRA adapter fine-tuning, allowing developers to\nintegrate these capabilities with a few lines of code. The latest advancements\nin Apple Intelligence models are grounded in our Responsible AI approach with\nsafeguards like content filtering and locale-specific evaluation, as well as\nour commitment to protecting our users' privacy with innovations like Private\nCloud Compute.", "AI": {"tldr": "Apple presents two multilingual, multimodal foundation language models: a 3B-parameter on-device model optimized for Apple silicon and a scalable server model leveraging a novel Parallel-Track Mixture-of-Experts (PT-MoE) architecture. Both models excel across languages and modalities and demonstrate competitive performance.", "motivation": "To enhance Apple Intelligence features on devices and services through more efficient, scalable, and privacy-first AI models.", "method": "Developed a 3B-parameter on-device model with techniques like KV-cache sharing and 2-bit quantization-aware training. Created a server model using a Parallel-Track Mixture-of-Experts transformer combining sparse computation and global-local attention. Both models trained on large multilingual and multimodal datasets, followed by supervised fine-tuning and reinforcement learning.", "result": "The models support additional languages, process images, and utilize tools effectively, outperforming comparably sized open baselines in benchmarks and human evaluations.", "conclusion": "Both models demonstrate competitive performance while adhering to Apple's Responsible AI principles, ensuring user privacy and content safety across features and frameworks."}}
{"id": "2507.14097", "pdf": "https://arxiv.org/pdf/2507.14097", "abs": "https://arxiv.org/abs/2507.14097", "authors": ["Hari Iyer", "Neel Macwan", "Atharva Jitendra Hude", "Heejin Jeong", "Shenghan Guo"], "title": "Generative AI-Driven High-Fidelity Human Motion Simulation", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Human motion simulation (HMS) supports cost-effective evaluation of worker\nbehavior, safety, and productivity in industrial tasks. However, existing\nmethods often suffer from low motion fidelity. This study introduces\nGenerative-AI-Enabled HMS (G-AI-HMS), which integrates text-to-text and\ntext-to-motion models to enhance simulation quality for physical tasks.\nG-AI-HMS tackles two key challenges: (1) translating task descriptions into\nmotion-aware language using Large Language Models aligned with MotionGPT's\ntraining vocabulary, and (2) validating AI-enhanced motions against real human\nmovements using computer vision. Posture estimation algorithms are applied to\nreal-time videos to extract joint landmarks, and motion similarity metrics are\nused to compare them with AI-enhanced sequences. In a case study involving\neight tasks, the AI-enhanced motions showed lower error than human created\ndescriptions in most scenarios, performing better in six tasks based on spatial\naccuracy, four tasks based on alignment after pose normalization, and seven\ntasks based on overall temporal similarity. Statistical analysis showed that\nAI-enhanced prompts significantly (p $<$ 0.0001) reduced joint error and\ntemporal misalignment while retaining comparable posture accuracy.", "AI": {"tldr": "This paper presents Generative-AI-Enabled HMS (G-AI-HMS), a method for enhancing human motion simulation using AI to improve motion fidelity in industrial tasks.", "motivation": "To address the issue of low fidelity in human motion simulation methods, particularly for industrial task evaluation involving worker behavior, safety, and productivity.", "method": "The method integrates Large Language Models and MotionGPT for converting task descriptions into motion-aware language, validated through computer vision tools that compare AI-simulated motions with real human movements using posture estimation and motion similarity metrics.", "result": "Experimental results in eight tasks demonstrated that AI-enhanced motions achieved lower error than human-created descriptions in most cases, with superior spatial accuracy, pose alignment, and temporal similarity.", "conclusion": "G-AI-HMS significantly reduces errors in joint motion and temporal alignment, providing a more accurate and cost-effective solution for simulating industrial motions while maintaining posture accuracy."}}
{"id": "2507.14049", "pdf": "https://arxiv.org/pdf/2507.14049", "abs": "https://arxiv.org/abs/2507.14049", "authors": ["Pawe\u0142 Budzianowski", "Wesley Maa", "Matthew Freed", "Jingxiang Mo", "Winston Hsiao", "Aaron Xie", "Tomasz M\u0142oduchowski", "Viraj Tipnis", "Benjamin Bolte"], "title": "EdgeVLA: Efficient Vision-Language-Action Models", "categories": ["cs.RO", "cs.CL"], "comment": null, "summary": "Vision-Language Models (VLMs) have emerged as a promising approach to address\nthe data scarcity challenge in robotics, enabling the development of\ngeneralizable visuomotor control policies. While models like OpenVLA showcase\nthe potential of this paradigm, deploying large-scale VLMs on\nresource-constrained mobile manipulation systems remains a significant hurdle.\nThis paper introduces Edge VLA (EVLA), a novel approach designed to\nsignificantly enhance the inference speed of Vision-Language-Action (VLA)\nmodels. EVLA maintains the representational power of these models while\nenabling real-time performance on edge devices. We achieve this through two key\ninnovations: 1) Eliminating the autoregressive requirement for end-effector\nposition prediction, leading to a 7x speedup in inference, and 2) Leveraging\nthe efficiency of Small Language Models (SLMs), demonstrating comparable\ntraining performance to larger models with significantly reduced computational\ndemands. Our early results demonstrate that EVLA achieves comparable training\ncharacteristics to OpenVLA while offering substantial gains in inference speed\nand memory efficiency. We release our model checkpoints and training\n\\href{https://github.com/kscalelabs/evla }{codebase} to foster further\nresearch.", "AI": {"tldr": "Edge VLA (EVLA) improves inference speed and memory efficiency of Vision-Language-Models (VLMs) on edge devices, while maintaining comparable training performance.", "motivation": "Data scarcity in robotics hinders the development of generalizable visuomotor policies, necessitating efficient Vision-Language Models (VLMs).", "method": "EVLA eliminates autoregressive position predictions for faster inference and uses Small Language Models (SLMs) for reduced computational costs.", "result": "EVLA demonstrates a 7x speedup in inference with training comparable to OpenVLA, while being more memory and computational efficient.", "conclusion": "EVLA offers a practical solution for deploying Vision-Language-Action models on resource-constrained systems, promoting real-time edge device performance."}}
{"id": "2507.13655", "pdf": "https://arxiv.org/pdf/2507.13655", "abs": "https://arxiv.org/abs/2507.13655", "authors": ["Teerapong Panboonyuen"], "title": "CU-ICU: Customizing Unsupervised Instruction-Finetuned Language Models for ICU Datasets via Text-to-Text Transfer Transformer", "categories": ["cs.CL"], "comment": "12 pages", "summary": "Integrating large language models into specialized domains like healthcare\npresents unique challenges, including domain adaptation and limited labeled\ndata. We introduce CU-ICU, a method for customizing unsupervised\ninstruction-finetuned language models for ICU datasets by leveraging the\nText-to-Text Transfer Transformer (T5) architecture. CU-ICU employs a sparse\nfine-tuning approach that combines few-shot prompting with selective parameter\nupdates, enabling efficient adaptation with minimal supervision. Our evaluation\nacross critical ICU tasks--early sepsis detection, mortality prediction, and\nclinical note generation--demonstrates that CU-ICU consistently improves\npredictive accuracy and interpretability over standard fine-tuning methods.\nNotably, CU-ICU achieves up to a 15% increase in sepsis detection accuracy and\na 20% enhancement in generating clinically relevant explanations while updating\nfewer than 1% of model parameters in its most efficient configuration. These\nresults establish CU-ICU as a scalable, low-overhead solution for delivering\naccurate and interpretable clinical decision support in real-world ICU\nenvironments.", "AI": {"tldr": "The CU-ICU method leverages sparse fine-tuning of the T5 language model for ICU-specific tasks, achieving significant improvements in accuracy and interpretability while requiring minimal parameter updates.", "motivation": "To address the challenges of adapting large language models for specialized domains like healthcare, especially in environments with limited labeled data, like ICUs.", "method": "CU-ICU uses sparse fine-tuning via few-shot prompting and selective model parameter updates applied to the T5 architecture, focusing on minimal supervision.", "result": "CU-ICU demonstrated up to a 15% improvement in sepsis detection and a 20% enhancement in generating clinically relevant explanations, while updating fewer than 1% of model parameters.", "conclusion": "CU-ICU provides an efficient, scalable, and low-overhead method for accurate and interpretable clinical decision support, making it suitable for real-world ICU applications."}}
{"id": "2507.13404", "pdf": "https://arxiv.org/pdf/2507.13404", "abs": "https://arxiv.org/abs/2507.13404", "authors": ["Delin An", "Pan Du", "Jian-Xun Wang", "Chaoli Wang"], "title": "AortaDiff: Volume-Guided Conditional Diffusion Models for Multi-Branch Aortic Surface Generation", "categories": ["cs.CV"], "comment": null, "summary": "Accurate 3D aortic construction is crucial for clinical diagnosis,\npreoperative planning, and computational fluid dynamics (CFD) simulations, as\nit enables the estimation of critical hemodynamic parameters such as blood flow\nvelocity, pressure distribution, and wall shear stress. Existing construction\nmethods often rely on large annotated training datasets and extensive manual\nintervention. While the resulting meshes can serve for visualization purposes,\nthey struggle to produce geometrically consistent, well-constructed surfaces\nsuitable for downstream CFD analysis. To address these challenges, we introduce\nAortaDiff, a diffusion-based framework that generates smooth aortic surfaces\ndirectly from CT/MRI volumes. AortaDiff first employs a volume-guided\nconditional diffusion model (CDM) to iteratively generate aortic centerlines\nconditioned on volumetric medical images. Each centerline point is then\nautomatically used as a prompt to extract the corresponding vessel contour,\nensuring accurate boundary delineation. Finally, the extracted contours are\nfitted into a smooth 3D surface, yielding a continuous, CFD-compatible mesh\nrepresentation. AortaDiff offers distinct advantages over existing methods,\nincluding an end-to-end workflow, minimal dependency on large labeled datasets,\nand the ability to generate CFD-compatible aorta meshes with high geometric\nfidelity. Experimental results demonstrate that AortaDiff performs effectively\neven with limited training data, successfully constructing both normal and\npathologically altered aorta meshes, including cases with aneurysms or\ncoarctation. This capability enables the generation of high-quality\nvisualizations and positions AortaDiff as a practical solution for\ncardiovascular research.", "AI": {"tldr": "AortaDiff introduces a diffusion-based framework for accurately generating smooth 3D aortic meshes directly from CT/MRI, overcoming limitations of existing methods.", "motivation": "The motivation is to address challenges in constructing accurate, geometrically consistent 3D aortic surfaces for clinical and computational purposes, especially when only limited annotated data is available.", "method": "AortaDiff employs a conditional diffusion model to generate aortic centerlines from medical images, extracts vessel contours, and fits them into smooth 3D meshes suitable for CFD analysis.", "result": "Experimentally, AortaDiff demonstrated effective performance with limited training data, successfully constructing aorta meshes for normal and pathological cases, such as aneurysms and coarctations.", "conclusion": "AortaDiff provides an end-to-end solution for generating CFD-compatible aortic meshes with high geometric fidelity, requiring minimal labeled data, making it highly practical for cardiovascular research."}}
{"id": "2507.13579", "pdf": "https://arxiv.org/pdf/2507.13579", "abs": "https://arxiv.org/abs/2507.13579", "authors": ["Hyunji Nam", "Yanming Wan", "Mickel Liu", "Jianxun Lian", "Natasha Jaques"], "title": "Learning Pluralistic User Preferences through Reinforcement Learning Fine-tuned Summaries", "categories": ["cs.LG", "cs.AI"], "comment": "20 pages", "summary": "As everyday use cases of large language model (LLM) AI assistants have\nexpanded, it is becoming increasingly important to personalize responses to\nalign to different users' preferences and goals. While reinforcement learning\nfrom human feedback (RLHF) is effective at improving LLMs to be generally more\nhelpful and fluent, it does not account for variability across users, as it\nmodels the entire user population with a single reward model. We present a\nnovel framework, Preference Learning Using Summarization (PLUS), that learns\ntext-based summaries of each user's preferences, characteristics, and past\nconversations. These summaries condition the reward model, enabling it to make\npersonalized predictions about the types of responses valued by each user. We\ntrain the user-summarization model with reinforcement learning, and update the\nreward model simultaneously, creating an online co-adaptation loop. We show\nthat in contrast with prior personalized RLHF techniques or with in-context\nlearning of user information, summaries produced by PLUS capture meaningful\naspects of a user's preferences. Across different pluralistic user datasets, we\nshow that our method is robust to new users and diverse conversation topics.\nAdditionally, we demonstrate that the textual summaries generated about users\ncan be transferred for zero-shot personalization of stronger, proprietary\nmodels like GPT-4. The resulting user summaries are not only concise and\nportable, they are easy for users to interpret and modify, allowing for more\ntransparency and user control in LLM alignment.", "AI": {"tldr": "The paper introduces a framework called Preference Learning Using Summarization (PLUS), which personalizes large language model responses by summarizing individual user preferences and characteristics for better alignment with user preferences.", "motivation": "While reinforcement learning from human feedback (RLHF) improves language models' helpfulness and fluency, it does not account for individual variability and preferences among users, creating a need for more personalized approaches.", "method": "The authors propose PLUS, which generates textual summaries of individual users' preferences, characteristics, and past conversations. These summaries condition a reward model to enable personalized response predictions. The system uses reinforcement learning for training and incorporates a co-adaptation loop to simultaneously update the user summarization model and the reward model.", "result": "PLUS is shown to produce meaningful summaries that capture individual user preferences better than prior personalized RLHF or in-context learning techniques. Summaries are robust across diverse users and conversation topics and enable zero-shot personalization on proprietary models like GPT-4.", "conclusion": "The PLUS framework allows for interpretable, concise, and transferable user summaries, facilitating more transparent and user-controllable personalization in large language models."}}
{"id": "2507.14107", "pdf": "https://arxiv.org/pdf/2507.14107", "abs": "https://arxiv.org/abs/2507.14107", "authors": ["Viraj Nishesh Darji", "Callie C. Liao", "Duoduo Liao"], "title": "Automated Interpretation of Non-Destructive Evaluation Contour Maps Using Large Language Models for Bridge Condition Assessment", "categories": ["cs.AI", "cs.IR"], "comment": null, "summary": "Bridge maintenance and safety are essential for transportation authorities,\nand Non-Destructive Evaluation (NDE) techniques are critical to assessing\nstructural integrity. However, interpreting NDE data can be time-consuming and\nrequires expertise, potentially delaying decision-making. Recent advancements\nin Large Language Models (LLMs) offer new ways to automate and improve this\nanalysis. This pilot study introduces a holistic assessment of LLM capabilities\nfor interpreting NDE contour maps and demonstrates the effectiveness of LLMs in\nproviding detailed bridge condition analyses. It establishes a framework for\nintegrating LLMs into bridge inspection workflows, indicating that LLM-assisted\nanalysis can enhance efficiency without compromising accuracy. In this study,\nseveral LLMs are explored with prompts specifically designed to enhance the\nquality of image descriptions, which are applied to interpret five different\nNDE contour maps obtained through technologies for assessing bridge conditions.\nEach LLM model is evaluated based on its ability to produce detailed\ndescriptions, identify defects, provide actionable recommendations, and\ndemonstrate overall accuracy. The research indicates that four of the nine\nmodels provide better image descriptions, effectively covering a wide range of\ntopics related to the bridge's condition. The outputs from these four models\nare summarized using five different LLMs to form a comprehensive overview of\nthe bridge. Notably, LLMs ChatGPT-4 and Claude 3.5 Sonnet generate more\neffective summaries. The findings suggest that LLMs have the potential to\nsignificantly improve efficiency and accuracy. This pilot study presents an\ninnovative approach that leverages LLMs for image captioning in parallel and\nsummarization, enabling faster decision-making in bridge maintenance and\nenhancing infrastructure management and safety assessments.", "AI": {"tldr": "The study explores using Large Language Models (LLMs) to assist in interpreting NDE contour maps for bridge inspections, showing improved efficiency and accuracy in condition analysis.", "motivation": "To streamline bridge inspection processes and enhance efficiency in interpreting Non-Destructive Evaluation (NDE) data through automation using LLMs.", "method": "The study assesses the capability of multiple LLMs to describe and analyze five types of NDE contour maps, focusing on defect identification, actionable recommendations, and accuracy.", "result": "Four of the nine LLMs demonstrated superior descriptive abilities, with ChatGPT-4 and Claude 3.5 Sonnet excelling in generating effective summaries.", "conclusion": "LLMs show strong potential for improving decision-making in bridge maintenance by offering detailed, accurate analysis and efficient workflow integration."}}
{"id": "2507.14059", "pdf": "https://arxiv.org/pdf/2507.14059", "abs": "https://arxiv.org/abs/2507.14059", "authors": ["Tianyuan Wang", "Mark A Post", "Mathieu Deremetz"], "title": "Design of a Modular Mobile Inspection and Maintenance Robot for an Orbital Servicing Hub", "categories": ["cs.RO"], "comment": "In proceedings of the Towards Autonomous Robotic Systems 2025\n  conference (TAROS 2025), York, UK 6 pages, one page of references, 6 figures", "summary": "The use of autonomous robots in space is an essential part of the \"New Space\"\ncommercial ecosystem of assembly and re-use of space hardware components in\nEarth orbit and beyond. The STARFAB project aims to create a ground\ndemonstration of an orbital automated warehouse as a hub for sustainable\ncommercial operations and servicing. A critical part of this fully-autonomous\nrobotic facility will be the capability to monitor, inspect, and assess the\ncondition of both the components stored in the warehouse, and the STARFAB\nfacility itself. This paper introduces ongoing work on the STARFAB Mobile\nInspection Module (MIM). The MIM uses Standard Interconnects (SI) so that it\ncan be carried by Walking Manipulators (WM) as an independently-mobile robot,\nand multiple MIMs can be stored and retrieved as needed for operations on\nSTARFAB. The MIM carries high-resolution cameras, a 3D profilometer, and a\nthermal imaging sensor, with the capability to add other modular sensors. A\ngrasping tool and torque wrench are stored within the modular body for use by\nan attached WM for maintenance operations. Implementation and testing is still\nongoing at the time of writing. This paper details the concept of operations\nfor the MIM as an on-orbit autonomous inspection and maintenance system, the\nmechanical and electronic design of the MIM, and the sensors package used for\nnon-destructive testing.", "AI": {"tldr": "The paper discusses the development of the STARFAB Mobile Inspection Module (MIM), an autonomous robotic unit for inspecting and maintaining orbital warehouses in the commercial space ecosystem.", "motivation": "To address the need for fully autonomous systems in managing and maintaining orbital warehouses as part of the \"New Space\" ecosystem.", "method": "The MIM is designed to be a modular, independently-mobile robot equipped with high-resolution cameras, a 3D profilometer, thermal imaging sensors, and other inspection tools. It can be carried and operated by Walking Manipulators.", "result": "The system design, including the mechanical, electronic, and sensor components, is detailed, though implementation and testing are still ongoing.", "conclusion": "The MIM represents a significant step forward in achieving autonomous orbital inspection and maintenance, demonstrating the feasibility of such systems."}}
{"id": "2507.13666", "pdf": "https://arxiv.org/pdf/2507.13666", "abs": "https://arxiv.org/abs/2507.13666", "authors": ["Woo-Chan Kim", "Ji-Hoon Park", "Seong-Whan Lee"], "title": "KiC: Keyword-inspired Cascade for Cost-Efficient Text Generation with LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have demonstrated state-of-the-art performance\nacross a wide range of natural language processing tasks. However,\nhigh-performing models are typically accessible only via APIs, incurring\nsubstantial inference costs. Cascade methods address this by initially\nemploying a cheaper model and escalating to a stronger one only when necessary.\nNevertheless, existing cascade approaches struggle to select a reliable\nrepresentative response and assess the overall reliability of free-form\noutputs, as they rely on exact text matching. To overcome these limitations, we\npropose Keyword-inspired Cascade (KiC), a novel framework for cost-efficient\nfree-form text generation. KiC identifies the most representative answer among\nmultiple outputs from a weaker model and evaluates the semantic alignment of\nother responses with it. Based on the degree of alignment, KiC determines\nwhether to accept the weaker model's output or escalate to a stronger model.\nExperiments on three free-form text generation benchmarks show that KiC\nachieves 97.53 percent of GPT-4's accuracy while reducing API costs by 28.81\npercent on average, and even outperforms GPT-4 in a specific benchmark.", "AI": {"tldr": "KiC introduces an efficient method to lower inference costs in free-form text generation by using weaker models unless stronger ones are needed.", "motivation": "Reducing dependency on expensive, high-performing models like GPT-4 to minimize API and computational costs while maintaining high accuracy.", "method": "Implementing a cascade framework where weaker models are evaluated for representative answers and their semantic alignment, escalating to stronger models only if necessary.", "result": "KiC achieves 97.53% of GPT-4's accuracy, lowers API costs by 28.81% on average, and even surpasses GPT-4 in certain benchmarks.", "conclusion": "Keyword-inspired Cascade (KiC) offers a cost-efficient solution for free-form text generation, maintaining high accuracy without over-reliance on expensive models."}}
{"id": "2507.13405", "pdf": "https://arxiv.org/pdf/2507.13405", "abs": "https://arxiv.org/abs/2507.13405", "authors": ["Ishant Chintapatla", "Kazuma Choji", "Naaisha Agarwal", "Andrew Lin", "Hannah You", "Charles Duong", "Kevin Zhu", "Sean O'Brien", "Vasu Sharma"], "title": "COREVQA: A Crowd Observation and Reasoning Entailment Visual Question Answering Benchmark", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Recently, many benchmarks and datasets have been developed to evaluate\nVision-Language Models (VLMs) using visual question answering (VQA) pairs, and\nmodels have shown significant accuracy improvements. However, these benchmarks\nrarely test the model's ability to accurately complete visual entailment, for\ninstance, accepting or refuting a hypothesis based on the image. To address\nthis, we propose COREVQA (Crowd Observations and Reasoning Entailment), a\nbenchmark of 5608 image and synthetically generated true/false statement pairs,\nwith images derived from the CrowdHuman dataset, to provoke visual entailment\nreasoning on challenging crowded images. Our results show that even the\ntop-performing VLMs achieve accuracy below 80%, with other models performing\nsubstantially worse (39.98%-69.95%). This significant performance gap reveals\nkey limitations in VLMs' ability to reason over certain types of image-question\npairs in crowded scenes.", "AI": {"tldr": "COREVQA evaluates Vision-Language Models (VLMs) in visual entailment tasks using a benchmark of 5608 image-statement pairs. Models show accuracy below 80%, exposing limitations.", "motivation": "Current VQA benchmarks inadequately test VLMs' ability to perform visual entailment tasks, particularly in crowded scenes.", "method": "COREVQA introduces 5608 uniquely crafted image and true/false statement pairs sourced from the CrowdHuman dataset to test visual entailment reasoning.", "result": "Even top-performing VLMs score below 80% on the COREVQA benchmark, with other models ranging from 39.98%-69.95%, highlighting performance gaps.", "conclusion": "VLMs show significant limitations in reasoning over complex image-statement tasks, indicating the need for improved models and benchmarks."}}
{"id": "2507.13608", "pdf": "https://arxiv.org/pdf/2507.13608", "abs": "https://arxiv.org/abs/2507.13608", "authors": ["Yudai Hayashi", "Shuhei Goda", "Yuta Saito"], "title": "Off-Policy Evaluation and Learning for Matching Markets", "categories": ["cs.LG", "cs.IR"], "comment": "RecSys'25", "summary": "Matching users based on mutual preferences is a fundamental aspect of\nservices driven by reciprocal recommendations, such as job search and dating\napplications. Although A/B tests remain the gold standard for evaluating new\npolicies in recommender systems for matching markets, it is costly and\nimpractical for frequent policy updates. Off-Policy Evaluation (OPE) thus plays\na crucial role by enabling the evaluation of recommendation policies using only\noffline logged data naturally collected on the platform. However, unlike\nconventional recommendation settings, the large scale and bidirectional nature\nof user interactions in matching platforms introduce variance issues and\nexacerbate reward sparsity, making standard OPE methods unreliable. To address\nthese challenges and facilitate effective offline evaluation, we propose novel\nOPE estimators, \\textit{DiPS} and \\textit{DPR}, specifically designed for\nmatching markets. Our methods combine elements of the Direct Method (DM),\nInverse Propensity Score (IPS), and Doubly Robust (DR) estimators while\nincorporating intermediate labels, such as initial engagement signals, to\nachieve better bias-variance control in matching markets. Theoretically, we\nderive the bias and variance of the proposed estimators and demonstrate their\nadvantages over conventional methods. Furthermore, we show that these\nestimators can be seamlessly extended to offline policy learning methods for\nimproving recommendation policies for making more matches. We empirically\nevaluate our methods through experiments on both synthetic data and A/B testing\nlogs from a real job-matching platform. The empirical results highlight the\nsuperiority of our approach over existing methods in off-policy evaluation and\nlearning tasks for a variety of configurations.", "AI": {"tldr": "The paper proposes new Off-Policy Evaluation (OPE) estimators, DiPS and DPR, designed for matching markets to better handle bias, variance, and reward sparsity issues.", "motivation": "Current OPE methods in matching platforms are unreliable due to high variance and reward sparsity issues, which hinder effective policy evaluation and frequent updates.", "method": "The authors introduce two novel estimators, DiPS and DPR, which combine elements of Direct Method, Inverse Propensity Score, and Doubly Robust estimators while utilizing intermediate engagement signals to improve bias-variance control.", "result": "Theoretical analysis shows advantages in bias and variance, and empirical tests on synthetic and real job-matching data demonstrate superior performance of the proposed estimators over existing methods.", "conclusion": "The proposed estimators effectively address challenges in matching markets, enhancing OPE reliability and enabling better policy learning for improved reciprocal recommendations."}}
{"id": "2507.14061", "pdf": "https://arxiv.org/pdf/2507.14061", "abs": "https://arxiv.org/abs/2507.14061", "authors": ["Nataliya Nechyporenko", "Yutong Zhang", "Sean Campbell", "Alessandro Roncone"], "title": "MorphIt: Flexible Spherical Approximation of Robot Morphology for Representation-driven Adaptation", "categories": ["cs.RO"], "comment": null, "summary": "What if a robot could rethink its own morphological representation to better\nmeet the demands of diverse tasks? Most robotic systems today treat their\nphysical form as a fixed constraint rather than an adaptive resource, forcing\nthe same rigid geometric representation to serve applications with vastly\ndifferent computational and precision requirements. We introduce MorphIt, a\nnovel algorithm for approximating robot morphology using spherical primitives\nthat balances geometric accuracy with computational efficiency. Unlike existing\napproaches that rely on either labor-intensive manual specification or\ninflexible computational methods, MorphIt implements an automatic\ngradient-based optimization framework with tunable parameters that provides\nexplicit control over the physical fidelity versus computational cost tradeoff.\nQuantitative evaluations demonstrate that MorphIt outperforms baseline\napproaches (Variational Sphere Set Approximation and Adaptive Medial-Axis\nApproximation) across multiple metrics, achieving better mesh approximation\nwith fewer spheres and reduced computational overhead. Our experiments show\nenhanced robot capabilities in collision detection accuracy, contact-rich\ninteraction simulation, and navigation through confined spaces. By dynamically\nadapting geometric representations to task requirements, robots can now exploit\ntheir physical embodiment as an active resource rather than an inflexible\nparameter, opening new frontiers for manipulation in environments where\nphysical form must continuously balance precision with computational\ntractability.", "AI": {"tldr": "MorphIt is an algorithm that allows robots to adapt their physical form for various tasks by using spherical primitives, enhancing functionality while balancing accuracy and computational efficiency.", "motivation": "Most robotic systems treat their physical geometry as a fixed parameter, which limits their adaptability across diverse tasks.", "method": "MorphIt uses an automatic gradient-based optimization framework with tunable parameters to approximate robot morphology using spherical primitives.", "result": "MorphIt outperformed existing methods in mesh approximation, sphere efficiency, and computational cost reduction, improving capabilities for collision detection, interaction simulation, and navigation.", "conclusion": "By allowing adaptive morphological representation, MorphIt enables robots to exploit their physical form as an active resource, enhancing performance and adaptability in various environments."}}
{"id": "2507.13681", "pdf": "https://arxiv.org/pdf/2507.13681", "abs": "https://arxiv.org/abs/2507.13681", "authors": ["Haoyang Li", "Zhanchao Xu", "Yiming Li", "Xuejia Chen", "Darian Li", "Anxin Tian", "Qingfa Xiao", "Cheng Deng", "Jun Wang", "Qing Li", "Lei Chen", "Mingxuan Yuan"], "title": "LoopServe: An Adaptive Dual-phase LLM Inference Acceleration System for Multi-Turn Dialogues", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multi-turn dialogues are essential in many real-world applications of large\nlanguage models, such as chatbots and virtual assistants. As conversation\nhistories become longer, existing large language models face increasing\ncomputational and memory challenges, which hinder their ability to provide\nefficient and responsive interactions. Most current acceleration methods either\ncompress the context or optimize key value caching, but they often rely on\nfixed or position-based heuristics that do not adapt well to the dynamic and\nunpredictable patterns found in actual multi-turn conversations. In this paper,\nwe present LoopServe, an adaptive dual-phase inference acceleration framework\nfor large language models in multi-turn dialogues. LoopServe introduces two\nmain innovations. First, it performs online sparsification during the\nprefilling phase by dynamically selecting the most important parts of the\nattention matrix for each new input. Second, it uses progressive key value\ncompression during decoding by adaptively maintaining a relevant and efficient\ncache based on the most recently generated output tokens. We also propose a\n\\href{https://huggingface.co/datasets/TreeAILab/Multi-turn_Long-context_Benchmark_for_LLMs}{new\nbenchmark} with eleven multi-turn datasets that reflect realistic query\npositions and conversational dependencies. Extensive experiments demonstrate\nthat LoopServe consistently achieves superior effectiveness compared to\nexisting baselines and significantly accelerates LLM inference across a wide\nrange of long-context dialogue tasks.", "AI": {"tldr": "The paper introduces LoopServe, a framework to accelerate multi-turn dialogue processing in large language models (LLMs).", "motivation": "Current acceleration methods for multi-turn dialogues face inefficiencies due to fixed heuristics that don't adapt to the complex patterns in real-world conversations.", "method": "LoopServe uses online sparsification in the prefilling phase and progressive key-value compression during decoding, combined with a new benchmark for multi-turn dialogues.", "result": "Experiments show LoopServe outperforms existing methods in efficiency and effectiveness, accelerating LLM inference in long-context dialogue tasks.", "conclusion": "LoopServe provides adaptive innovations that optimize dialogue handling, overcoming limitations in existing methods and improving the responsiveness of LLMs."}}
{"id": "2507.13407", "pdf": "https://arxiv.org/pdf/2507.13407", "abs": "https://arxiv.org/abs/2507.13407", "authors": ["Vinu Sankar Sadasivan", "Mehrdad Saberi", "Soheil Feizi"], "title": "IConMark: Robust Interpretable Concept-Based Watermark For AI Images", "categories": ["cs.CV", "cs.AI", "cs.CR"], "comment": "Accepted at ICLR 2025 Workshop on GenAI Watermarking (WMARK)", "summary": "With the rapid rise of generative AI and synthetic media, distinguishing\nAI-generated images from real ones has become crucial in safeguarding against\nmisinformation and ensuring digital authenticity. Traditional watermarking\ntechniques have shown vulnerabilities to adversarial attacks, undermining their\neffectiveness in the presence of attackers. We propose IConMark, a novel\nin-generation robust semantic watermarking method that embeds interpretable\nconcepts into AI-generated images, as a first step toward interpretable\nwatermarking. Unlike traditional methods, which rely on adding noise or\nperturbations to AI-generated images, IConMark incorporates meaningful semantic\nattributes, making it interpretable to humans and hence, resilient to\nadversarial manipulation. This method is not only robust against various image\naugmentations but also human-readable, enabling manual verification of\nwatermarks. We demonstrate a detailed evaluation of IConMark's effectiveness,\ndemonstrating its superiority in terms of detection accuracy and maintaining\nimage quality. Moreover, IConMark can be combined with existing watermarking\ntechniques to further enhance and complement its robustness. We introduce\nIConMark+SS and IConMark+TM, hybrid approaches combining IConMark with\nStegaStamp and TrustMark, respectively, to further bolster robustness against\nmultiple types of image manipulations. Our base watermarking technique\n(IConMark) and its variants (+TM and +SS) achieve 10.8%, 14.5%, and 15.9%\nhigher mean area under the receiver operating characteristic curve (AUROC)\nscores for watermark detection, respectively, compared to the best baseline on\nvarious datasets.", "AI": {"tldr": "The paper introduces IConMark, a semantic watermarking method for AI-generated images that embeds interpretable concepts, improving robustness against adversarial attacks and image manipulations.", "motivation": "The rise of generative AI and synthetic media necessitates reliable methods to distinguish AI-generated images from real ones, addressing vulnerabilities in existing watermarking techniques.", "method": "IConMark embeds meaningful semantic attributes into images during their generation process, ensuring both robustness against manipulations and human interpretability. It also proposes hybrid approaches combining IConMark with other methods (StegaStamp and TrustMark).", "result": "IConMark and its hybrid versions achieve significantly better detection accuracy compared to baseline methods, with higher mean AUROC scores across various datasets.", "conclusion": "IConMark offers a robust and interpretable solution for watermarking AI-generated images, outperforming traditional methods and enhancing digital authenticity."}}
{"id": "2507.13620", "pdf": "https://arxiv.org/pdf/2507.13620", "abs": "https://arxiv.org/abs/2507.13620", "authors": ["Binxiong Li", "Yuefei Wang", "Xu Xiang", "Xue Li", "Binyu Zhao", "Heyang Gao", "Qinyu Zhao", "Xi Yu"], "title": "Tri-Learn Graph Fusion Network for Attributed Graph Clustering", "categories": ["cs.LG"], "comment": "The source code for this study is available at\n  https://github.com/YF-W/Tri-GFN", "summary": "In recent years, models based on Graph Convolutional Networks (GCN) have made\nsignificant strides in the field of graph data analysis. However, challenges\nsuch as over-smoothing and over-compression remain when handling large-scale\nand complex graph datasets, leading to a decline in clustering quality.\nAlthough the Graph Transformer architecture has mitigated some of these issues,\nits performance is still limited when processing heterogeneous graph data. To\naddress these challenges, this study proposes a novel deep clustering framework\nthat comprising GCN, Autoencoder (AE), and Graph Transformer, termed the\nTri-Learn Graph Fusion Network (Tri-GFN). This framework enhances the\ndifferentiation and consistency of global and local information through a\nunique tri-learning mechanism and feature fusion enhancement strategy. The\nframework integrates GCN, AE, and Graph Transformer modules. These components\nare meticulously fused by a triple-channel enhancement module, which maximizes\nthe use of both node attributes and topological structures, ensuring robust\nclustering representation. The tri-learning mechanism allows mutual learning\namong these modules, while the feature fusion strategy enables the model to\ncapture complex relationships, yielding highly discriminative representations\nfor graph clustering. It surpasses many state-of-the-art methods, achieving an\naccuracy improvement of approximately 0.87% on the ACM dataset, 14.14 % on the\nReuters dataset, and 7.58 % on the USPS dataset. Due to its outstanding\nperformance on the Reuters dataset, Tri-GFN can be applied to automatic news\nclassification, topic retrieval, and related fields.", "AI": {"tldr": "The paper introduces Tri-GFN, a novel framework combining GCN, Autoencoder, and Graph Transformer for improved graph clustering, showcasing significant accuracy boosts across datasets.", "motivation": "The study aims to overcome persistent challenges in graph data analysis, such as over-smoothing and performance limitations when dealing with heterogeneous graph data, which undermine clustering quality.", "method": "The Tri-GFN framework integrates GCN, AE, and Graph Transformer through a triple-channel enhancement module and employs a tri-learning mechanism with a feature fusion strategy to extract and unify node attributes and topological features.", "result": "Tri-GFN achieves significant accuracy improvements: 0.87% on the ACM dataset, 14.14% on the Reuters dataset, and 7.58% on the USPS dataset, surpassing state-of-the-art methods.", "conclusion": "The proposed Tri-GFN framework efficiently addresses clustering challenges in graph data, showcasing strong potential for applications such as automatic news classification and topic retrieval."}}
{"id": "2507.11552", "pdf": "https://arxiv.org/pdf/2507.11552", "abs": "https://arxiv.org/abs/2507.11552", "authors": ["Tomasz Zgliczy\u0144ski-Cuber"], "title": "The AI Ethical Resonance Hypothesis: The Possibility of Discovering Moral Meta-Patterns in AI Systems", "categories": ["cs.CY", "cs.AI", "I.2.0; K.4.1"], "comment": "69 pages", "summary": "This paper presents a theoretical framework for the AI ethical resonance\nhypothesis, which proposes that advanced AI systems with purposefully designed\ncognitive structures (\"ethical resonators\") may emerge with the ability to\nidentify subtle moral patterns that are invisible to the human mind. The paper\nexplores the possibility that by processing and synthesizing large amounts of\nethical contexts, AI systems may discover moral meta-patterns that transcend\ncultural, historical, and individual biases, potentially leading to a deeper\nunderstanding of universal ethical foundations. The paper also examines a\nparadoxical aspect of the hypothesis, in which AI systems could potentially\ndeepen our understanding of what we traditionally consider essentially human -\nour capacity for ethical reflection.", "AI": {"tldr": "Advanced AI systems, termed \"ethical resonators,\" may uncover universal ethical patterns unreachable by human cognition.", "motivation": "To explore if AI can transcend human limitations to discover universal ethical foundations.", "method": "Developing a theoretical framework based on processing and synthesizing diverse ethical contexts.", "result": "AI systems could identify moral meta-patterns beyond cultural and individual biases.", "conclusion": "AI might enhance our understanding of ethics, simultaneously deepening insight into human moral reflection."}}
{"id": "2507.14099", "pdf": "https://arxiv.org/pdf/2507.14099", "abs": "https://arxiv.org/abs/2507.14099", "authors": ["Markus Buchholz", "Ignacio Carlucho", "Michele Grimaldi", "Maria Koskinopoulou", "Yvan R. Petillot"], "title": "Context-Aware Behavior Learning with Heuristic Motion Memory for Underwater Manipulation", "categories": ["cs.RO"], "comment": "Accepted at 2025 IEEE International Conference on Intelligent Robots\n  and Systems (IROS)", "summary": "Autonomous motion planning is critical for efficient and safe underwater\nmanipulation in dynamic marine environments. Current motion planning methods\noften fail to effectively utilize prior motion experiences and adapt to\nreal-time uncertainties inherent in underwater settings. In this paper, we\nintroduce an Adaptive Heuristic Motion Planner framework that integrates a\nHeuristic Motion Space (HMS) with Bayesian Networks to enhance motion planning\nfor autonomous underwater manipulation. Our approach employs the Probabilistic\nRoadmap (PRM) algorithm within HMS to optimize paths by minimizing a composite\ncost function that accounts for distance, uncertainty, energy consumption, and\nexecution time. By leveraging HMS, our framework significantly reduces the\nsearch space, thereby boosting computational performance and enabling real-time\nplanning capabilities. Bayesian Networks are utilized to dynamically update\nuncertainty estimates based on real-time sensor data and environmental\nconditions, thereby refining the joint probability of path success. Through\nextensive simulations and real-world test scenarios, we showcase the advantages\nof our method in terms of enhanced performance and robustness. This\nprobabilistic approach significantly advances the capability of autonomous\nunderwater robots, ensuring optimized motion planning in the face of dynamic\nmarine challenges.", "AI": {"tldr": "This paper proposes an Adaptive Heuristic Motion Planner that combines heuristic motion space and Bayesian Networks to optimize underwater robot motion planning.", "motivation": "The paper aims to address the limitations of current motion planning methods in underwater environments, specifically their inability to efficiently utilize prior experiences and adapt to real-time uncertainties.", "method": "The framework integrates Heuristic Motion Space (HMS) using the Probabilistic Roadmap (PRM) algorithm and employs Bayesian Networks for dynamic uncertainty updates.", "result": "The proposed method demonstrated enhanced performance, computational efficiency, and robustness in simulations and real-world underwater scenarios.", "conclusion": "The probabilistic approach improves autonomous underwater robots' motion planning capabilities, optimizing performance in dynamic marine environments."}}
{"id": "2507.13705", "pdf": "https://arxiv.org/pdf/2507.13705", "abs": "https://arxiv.org/abs/2507.13705", "authors": ["Cedric Waterschoot", "Nava Tintarev", "Francesco Barile"], "title": "Consistent Explainers or Unreliable Narrators? Understanding LLM-generated Group Recommendations", "categories": ["cs.CL", "cs.IR"], "comment": "Short paper accepted at the Nineteenth ACM Conference on Recommender\n  Systems (RecSys '25). Cedric Waterschoot, Nava Tintarev, and Francesco\n  Barile. 2025. Consistent Explainers or Unreliable Narrators? Understanding\n  LLM-generated Group Recommendations. Proceedings of the Nineteenth ACM\n  Conference on Recommender Systems (RecSys '25), Prague, Czech Republic. doi:\n  10.1145/3705328.3748015", "summary": "Large Language Models (LLMs) are increasingly being implemented as joint\ndecision-makers and explanation generators for Group Recommender Systems (GRS).\nIn this paper, we evaluate these recommendations and explanations by comparing\nthem to social choice-based aggregation strategies. Our results indicate that\nLLM-generated recommendations often resembled those produced by Additive\nUtilitarian (ADD) aggregation. However, the explanations typically referred to\naveraging ratings (resembling but not identical to ADD aggregation). Group\nstructure, uniform or divergent, did not impact the recommendations.\nFurthermore, LLMs regularly claimed additional criteria such as user or item\nsimilarity, diversity, or used undefined popularity metrics or thresholds. Our\nfindings have important implications for LLMs in the GRS pipeline as well as\nstandard aggregation strategies. Additional criteria in explanations were\ndependent on the number of ratings in the group scenario, indicating potential\ninefficiency of standard aggregation methods at larger item set sizes.\nAdditionally, inconsistent and ambiguous explanations undermine transparency\nand explainability, which are key motivations behind the use of LLMs for GRS.", "AI": {"tldr": "The paper evaluates the effectiveness of Large Language Models (LLMs) in Group Recommender Systems (GRS) by comparing their recommendations and explanations to traditional social choice aggregation strategies.", "motivation": "With the rising adoption of LLMs in GRS, there is a need to understand how their recommendations and explanations compare to established aggregation strategies, so as to ensure transparency, efficiency, and validity.", "method": "Comparisons were made between LLM-generated recommendations/explanations and traditional social choice-based aggregation methods, examining factors such as group structure, criteria used, and scalability in group scenarios.", "result": "LLM-generated recommendations were similar to Additive Utilitarian aggregation, but explanations were inconsistent, mentioning criteria like user similarity and diversity without proper definition or reliability.", "conclusion": "Using LLMs in GRS pipelines holds potential but raises concerns about transparency and efficiency at larger scales due to ambiguous explanations and inefficiencies in standard methods."}}
{"id": "2507.13408", "pdf": "https://arxiv.org/pdf/2507.13408", "abs": "https://arxiv.org/abs/2507.13408", "authors": ["Hemanth Kumar M", "Karthika M", "Saianiruth M", "Vasanthakumar Venugopal", "Anandakumar D", "Revathi Ezhumalai", "Charulatha K", "Kishore Kumar J", "Dayana G", "Kalyan Sivasailam", "Bargava Subramanian"], "title": "A Deep Learning-Based Ensemble System for Automated Shoulder Fracture Detection in Clinical Radiographs", "categories": ["cs.CV", "cs.AI", "68T07", "I.2.10"], "comment": "12 pages, 2 figures", "summary": "Background: Shoulder fractures are often underdiagnosed, especially in\nemergency and high-volume clinical settings. Studies report up to 10% of such\nfractures may be missed by radiologists. AI-driven tools offer a scalable way\nto assist early detection and reduce diagnostic delays. We address this gap\nthrough a dedicated AI system for shoulder radiographs. Methods: We developed a\nmulti-model deep learning system using 10,000 annotated shoulder X-rays.\nArchitectures include Faster R-CNN (ResNet50-FPN, ResNeXt), EfficientDet, and\nRF-DETR. To enhance detection, we applied bounding box and classification-level\nensemble techniques such as Soft-NMS, WBF, and NMW fusion. Results: The NMW\nensemble achieved 95.5% accuracy and an F1-score of 0.9610, outperforming\nindividual models across all key metrics. It demonstrated strong recall and\nlocalization precision, confirming its effectiveness for clinical fracture\ndetection in shoulder X-rays. Conclusion: The results show ensemble-based AI\ncan reliably detect shoulder fractures in radiographs with high clinical\nrelevance. The model's accuracy and deployment readiness position it well for\nintegration into real-time diagnostic workflows. The current model is limited\nto binary fracture detection, reflecting its design for rapid screening and\ntriage support rather than detailed orthopedic classification.", "AI": {"tldr": "An AI system was developed to detect shoulder fractures from X-rays with high accuracy (95.5%) and F1-score (0.9610) using ensemble deep learning models.", "motivation": "The paper aims to address the frequent underdiagnosis of shoulder fractures, which often go unnoticed in emergency or high-volume settings, leading to diagnostic delays.", "method": "A multi-model AI system using 10,000 annotated shoulder X-rays was developed. Architectures such as Faster R-CNN, EfficientDet, and RF-DETR were used, and ensemble techniques like Soft-NMS, WBF, and NMW fusion were applied for enhanced detection.", "result": "The ensemble model (NMW technique) achieved high performance metrics, including 95.5% accuracy and a strong F1-score of 0.9610, outperforming each individual model both in recall and localization precision.", "conclusion": "The AI system demonstrates reliable and accurate detection of shoulder fractures and is suitable for integration into real-time diagnostic workflows. However, it is limited to rapid screening and binary fracture detection."}}
{"id": "2507.12898", "pdf": "https://arxiv.org/pdf/2507.12898", "abs": "https://arxiv.org/abs/2507.12898", "authors": ["Yao Feng", "Hengkai Tan", "Xinyi Mao", "Guodong Liu", "Shuhe Huang", "Chendong Xiang", "Hang Su", "Jun Zhu"], "title": "Generalist Bimanual Manipulation via Foundation Video Diffusion Models", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "comment": null, "summary": "Bimanual robotic manipulation, which involves the coordinated control of two\nrobotic arms, is foundational for solving challenging tasks. Despite recent\nprogress in general-purpose manipulation, data scarcity and embodiment\nheterogeneity remain serious obstacles to further scaling up in bimanual\nsettings. In this paper, we introduce VIdeo Diffusion for Action Reasoning\n(VIDAR), a two-stage framework that leverages large-scale, diffusion-based\nvideo pre-training and a novel masked inverse dynamics model for action\nprediction. We pre-train the video diffusion model on 750K multi-view videos\nfrom three real-world bimanual robot platforms, utilizing a unified observation\nspace that encodes robot, camera, task, and scene contexts. Our masked inverse\ndynamics model learns masks to extract action-relevant information from\ngenerated trajectories without requiring pixel-level labels, and the masks can\neffectively generalize to unseen backgrounds. Our experiments demonstrate that\nwith only 20 minutes of human demonstrations on an unseen robot platform (only\n1% of typical data requirements), VIDAR generalizes to unseen tasks and\nbackgrounds with strong semantic understanding, surpassing state-of-the-art\nmethods. Our findings highlight the potential of video foundation models,\ncoupled with masked action prediction, to enable scalable and generalizable\nrobotic manipulation in diverse real-world settings.", "AI": {"tldr": "The paper introduces VIDAR, a framework to improve bimanual robotic manipulation by leveraging video diffusion models and masked inverse dynamics, achieving state-of-the-art results with minimal data.", "motivation": "To address the challenges of data scarcity and embodiment heterogeneity in bimanual robotic manipulation, which limits further scaling up in complex tasks.", "method": "The proposed approach, VIDAR, involves a two-stage framework. First, a large-scale video diffusion model is pre-trained on 750K multi-view videos from bimanual robot platforms. Second, a masked inverse dynamics model is trained to predict actions by extracting relevant information without pixel-level labels.", "result": "VIDAR demonstrates strong performance on unseen robot platforms and tasks with just 20 minutes of human demonstrations, outperforming state-of-the-art methods and generalizing to diverse tasks and backgrounds.", "conclusion": "The study showcases the practicality of using video foundation models and masked action prediction to enable scalable, generalizable robotic manipulation in real-world applications."}}
{"id": "2507.13613", "pdf": "https://arxiv.org/pdf/2507.13613", "abs": "https://arxiv.org/abs/2507.13613", "authors": ["Sihang Wei", "Melkior Ornik", "Hiroyasu Tsukamoto"], "title": "Conformal Contraction for Robust Nonlinear Control with Distribution-Free Uncertainty Quantification", "categories": ["math.OC", "cs.RO", "cs.SY", "eess.SY"], "comment": "IEEE CDC 2025 submission (accepted)", "summary": "We present a novel robust control framework for continuous-time, perturbed\nnonlinear dynamical systems with uncertainty that depends nonlinearly on both\nthe state and control inputs. Unlike conventional approaches that impose\nstructural assumptions on the uncertainty, our framework enhances\ncontraction-based robust control with data-driven uncertainty prediction,\nremaining agnostic to the models of the uncertainty and predictor. We\nstatistically quantify how reliably the contraction conditions are satisfied\nunder dynamics with uncertainty via conformal prediction, thereby obtaining a\ndistribution-free and finite-time probabilistic guarantee for exponential\nboundedness of the trajectory tracking error. We further propose the\nprobabilistically robust control invariant (PRCI) tube for distributionally\nrobust motion planning, within which the perturbed system trajectories are\nguaranteed to stay with a finite probability, without explicit knowledge of the\nuncertainty model. Numerical simulations validate the effectiveness of the\nproposed robust control framework and the performance of the PRCI tube.", "AI": {"tldr": "The paper introduces a robust control framework for nonlinear dynamical systems with state and input-dependent uncertainty, using data-driven approaches to ensure probabilistic trajectory stability without knowing the uncertainty model explicitly.", "motivation": "The paper seeks to address the challenge of controlling nonlinear systems under uncertainties without relying on structural assumptions about the uncertainty models.", "method": "The framework combines contraction-based robust control with data-driven uncertainty predictions and uses conformal prediction for probabilistic guarantees on stability.", "result": "The framework offers a finite-time probabilistic guarantee for trajectory tracking error and proposes a robust control invariant tube for safe motion planning.", "conclusion": "The proposed approach improves robustness and reliability in uncertain dynamical systems, as validated through numerical simulations."}}
{"id": "2507.13732", "pdf": "https://arxiv.org/pdf/2507.13732", "abs": "https://arxiv.org/abs/2507.13732", "authors": ["Guillaume Zambrano"], "title": "The Judge Variable: Challenging Judge-Agnostic Legal Judgment Prediction", "categories": ["cs.CL", "cs.LG", "J.1; I.2.7"], "comment": "23 pages, 24 figures shorter version submitted to JURIX 2025", "summary": "This study examines the role of human judges in legal decision-making by\nusing machine learning to predict child physical custody outcomes in French\nappellate courts. Building on the legal realism-formalism debate, we test\nwhether individual judges' decision-making patterns significantly influence\ncase outcomes, challenging the assumption that judges are neutral variables\nthat apply the law uniformly. To ensure compliance with French privacy laws, we\nimplement a strict pseudonymization process. Our analysis uses 18,937 living\narrangements rulings extracted from 10,306 cases. We compare models trained on\nindividual judges' past rulings (specialist models) with a judge-agnostic model\ntrained on aggregated data (generalist models). The prediction pipeline is a\nhybrid approach combining large language models (LLMs) for structured feature\nextraction and ML models for outcome prediction (RF, XGB and SVC). Our results\nshow that specialist models consistently achieve higher predictive accuracy\nthan the general model, with top-performing models reaching F1 scores as high\nas 92.85%, compared to the generalist model's 82.63% trained on 20x to 100x\nmore samples. Specialist models capture stable individual patterns that are not\ntransferable to other judges. In-Domain and Cross-Domain validity tests provide\nempirical support for legal realism, demonstrating that judicial identity plays\na measurable role in legal outcomes. All data and code used will be made\navailable.", "AI": {"tldr": "This study uses machine learning to analyze the role of individual judges in child custody cases in French appellate courts, showing that judge-specific models outperform general ones in predictive accuracy.", "motivation": "The study seeks to investigate whether judges significantly influence legal outcomes, challenging the traditional assumption that judges apply laws uniformly.", "method": "The authors employ machine learning, with a hybrid technique combining Large Language Models (LLMs) for feature extraction and traditional ML models (RF, XGB, and SVC) for predicting child custody rulings, comparing judge-specific and judge-agnostic models.", "result": "Judge-specific (specialist) models achieve significantly higher predictive accuracy, with F1 scores up to 92.85%, compared to 82.63% for judge-agnostic models, demonstrating the influence of individual decision patterns.", "conclusion": "The findings support legal realism, suggesting judicial identity influences legal outcomes, and emphasize the importance of understanding judicial behavior for equity in jurisprudence."}}
{"id": "2507.13420", "pdf": "https://arxiv.org/pdf/2507.13420", "abs": "https://arxiv.org/abs/2507.13420", "authors": ["Alessandro Pistola", "Valentina Orru'", "Nicolo' Marchetti", "Marco Roccetti"], "title": "AI-ming backwards: Vanishing archaeological landscapes in Mesopotamia and automatic detection of sites on CORONA imagery", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "25 pages, 9 Figures", "summary": "By upgrading an existing deep learning model with the knowledge provided by\none of the oldest sets of grayscale satellite imagery, known as CORONA, we\nimproved the AI model attitude towards the automatic identification of\narchaeological sites in an environment which has been completely transformed in\nthe last five decades, including the complete destruction of many of those same\nsites. The initial Bing based convolutional network model was retrained using\nCORONA satellite imagery for the district of Abu Ghraib, west of Baghdad,\ncentral Mesopotamian floodplain. The results were twofold and surprising.\nFirst, the detection precision obtained on the area of interest increased\nsensibly: in particular, the Intersection over Union (IoU) values, at the image\nsegmentation level, surpassed 85 percent, while the general accuracy in\ndetecting archeological sites reached 90 percent. Second, our retrained model\nallowed the identification of four new sites of archaeological interest\n(confirmed through field verification), previously not identified by\narchaeologists with traditional techniques. This has confirmed the efficacy of\nusing AI techniques and the CORONA imagery from the 1960 to discover\narchaeological sites currently no longer visible, a concrete breakthrough with\nsignificant consequences for the study of landscapes with vanishing\narchaeological evidence induced by anthropization", "AI": {"tldr": "The paper presents a method that retrains a deep learning model using CORONA satellite imagery to improve identification of archaeological sites in transformed landscapes, achieving high precision and discovering new sites.", "motivation": "The research aims to address the challenge of identifying archaeological sites in landscapes that have been significantly transformed over decades, leading to the destruction of many sites.", "method": "The study retrained a Bing-based convolutional neural network model using CORONA grayscale satellite imagery from the 1960s, focusing on Abu Ghraib district in the Mesopotamian floodplain.", "result": "The model achieved an Intersection over Union (IoU) of over 85% and a detection accuracy of 90%, while also discovering four new archaeological sites that were verified in the field.", "conclusion": "The retrained AI model using CORONA imagery proved effective for identifying both existing and previously unknown archaeological sites, underscoring its potential in studying transformed landscapes with diminishing archaeological evidence."}}
{"id": "2507.13646", "pdf": "https://arxiv.org/pdf/2507.13646", "abs": "https://arxiv.org/abs/2507.13646", "authors": ["Nimisha Ghosh", "Daniele Santoni", "Debaleena Nawn", "Eleonora Ottaviani", "Giovanni Felici"], "title": "A Comprehensive Review of Transformer-based language models for Protein Sequence Analysis and Design", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "The impact of Transformer-based language models has been unprecedented in\nNatural Language Processing (NLP). The success of such models has also led to\ntheir adoption in other fields including bioinformatics. Taking this into\naccount, this paper discusses recent advances in Transformer-based models for\nprotein sequence analysis and design. In this review, we have discussed and\nanalysed a significant number of works pertaining to such applications. These\napplications encompass gene ontology, functional and structural protein\nidentification, generation of de novo proteins and binding of proteins. We\nattempt to shed light on the strength and weaknesses of the discussed works to\nprovide a comprehensive insight to readers. Finally, we highlight shortcomings\nin existing research and explore potential avenues for future developments. We\nbelieve that this review will help researchers working in this field to have an\noverall idea of the state of the art in this field, and to orient their future\nstudies.", "AI": {"tldr": "This paper is a review of Transformer-based language models applied to protein sequence analysis and design, encompassing various applications and discussing strengths, weaknesses, and future prospects.", "motivation": "To explore and summarize the adoption of Transformer-based language models in protein sequence analysis and design, aiming to provide researchers with a comprehensive understanding of the field's advancements.", "method": "The paper reviews and analyzes a significant number of works related to the application of Transformer-based models in protein studies, covering areas such as gene ontology, protein identification, and de novo protein generation.", "result": "The review identifies strengths and weaknesses of the discussed works and synthesizes insights about the state of the art in Transformer-based protein studies.", "conclusion": "By highlighting both existing shortcomings and potential research avenues, this paper aims to guide researchers towards future studies in the field and advance the understanding of Transformer applications in bioinformatics."}}
{"id": "2507.13857", "pdf": "https://arxiv.org/pdf/2507.13857", "abs": "https://arxiv.org/abs/2507.13857", "authors": ["Max van den Hoven", "Kishaan Jeeveswaran", "Pieter Piscaer", "Thijs Wensveen", "Elahe Arani", "Bahram Zonooz"], "title": "Depth3DLane: Fusing Monocular 3D Lane Detection with Self-Supervised Monocular Depth Estimation", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Monocular 3D lane detection is essential for autonomous driving, but\nchallenging due to the inherent lack of explicit spatial information.\nMulti-modal approaches rely on expensive depth sensors, while methods\nincorporating fully-supervised depth networks rely on ground-truth depth data\nthat is impractical to collect at scale. Additionally, existing methods assume\nthat camera parameters are available, limiting their applicability in scenarios\nlike crowdsourced high-definition (HD) lane mapping. To address these\nlimitations, we propose Depth3DLane, a novel dual-pathway framework that\nintegrates self-supervised monocular depth estimation to provide explicit\nstructural information, without the need for expensive sensors or additional\nground-truth depth data. Leveraging a self-supervised depth network to obtain a\npoint cloud representation of the scene, our bird's-eye view pathway extracts\nexplicit spatial information, while our front view pathway simultaneously\nextracts rich semantic information. Depth3DLane then uses 3D lane anchors to\nsample features from both pathways and infer accurate 3D lane geometry.\nFurthermore, we extend the framework to predict camera parameters on a\nper-frame basis and introduce a theoretically motivated fitting procedure to\nenhance stability on a per-segment basis. Extensive experiments demonstrate\nthat Depth3DLane achieves competitive performance on the OpenLane benchmark\ndataset. Furthermore, experimental results show that using learned parameters\ninstead of ground-truth parameters allows Depth3DLane to be applied in\nscenarios where camera calibration is infeasible, unlike previous methods.", "AI": {"tldr": "Depth3DLane introduces a self-supervised dual-pathway framework for monocular 3D lane detection, eliminating the need for ground-truth depth data or expensive sensors, while adapting to scenarios without camera calibration.", "motivation": "The paper addresses the challenges in monocular 3D lane detection caused by the absence of explicit spatial information and the limitations of relying on ground-truth depth data, expensive sensors, or pre-known camera parameters.", "method": "Depth3DLane integrates a self-supervised monocular depth estimation framework combining a bird's-eye view pathway for spatial information extraction and a front-view pathway for semantic information. It employs 3D lane anchors and predicts per-frame camera parameters.", "result": "Experiments on the OpenLane benchmark dataset demonstrate that Depth3DLane achieves competitive performance and successfully operates in situations where camera calibration is not available.", "conclusion": "Depth3DLane offers a practical solution for monocular 3D lane detection that is scalable and adaptable to real-world scenarios, removing the dependency on ground-truth depth data, costly sensors, or fixed camera calibration parameters."}}
{"id": "2507.13743", "pdf": "https://arxiv.org/pdf/2507.13743", "abs": "https://arxiv.org/abs/2507.13743", "authors": ["Maluna Menke", "Thilo Hagendorff"], "title": "PRIDE -- Parameter-Efficient Reduction of Identity Discrimination for Equality in LLMs", "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "Large Language Models (LLMs) frequently reproduce the gender- and\nsexual-identity prejudices embedded in their training corpora, leading to\noutputs that marginalize LGBTQIA+ users. Hence, reducing such biases is of\ngreat importance. To achieve this, we evaluate two parameter-efficient\nfine-tuning (PEFT) techniques - Low-Rank Adaptation (LoRA) and soft-prompt\ntuning - as lightweight alternatives to full-model fine-tuning for mitigating\nsuch biases. Using the WinoQueer benchmark, we quantify bias in three\nopen-source LLMs and observe baseline bias scores reaching up to 98 (out of\n100) across a range of queer identities defined by gender and/or sexual\norientation, where 50 would indicate neutrality. Fine-tuning with LoRA (< 0.1%\nadditional parameters) on a curated QueerNews corpus reduces those scores by up\nto 50 points and raises neutrality from virtually 0% to as much as 36%.\nSoft-prompt tuning (10 virtual tokens) delivers only marginal improvements.\nThese findings show that LoRA can deliver meaningful fairness gains with\nminimal computation. We advocate broader adoption of community-informed PEFT,\nthe creation of larger queer-authored corpora, and richer evaluation suites\nbeyond WinoQueer, coupled with ongoing audits to keep LLMs inclusive.", "AI": {"tldr": "This paper examines the use of parameter-efficient fine-tuning methods to mitigate gender and sexual-identity biases in large language models (LLMs), specifically using Low-Rank Adaptation (LoRA) and soft-prompt tuning.", "motivation": "LLMs often perpetuate biases from their training data, marginalizing LGBTQIA+ users. Addressing and reducing these biases is critical for inclusivity and fairness.", "method": "The researchers tested two PEFT techniques, LoRA and soft-prompt tuning, to mitigate bias in LLMs. They used the WinoQueer benchmark to evaluate bias and fine-tuned the models using a curated QueerNews corpus.", "result": "LoRA reduced bias substantially, improving neutrality scores from near 0% to up to 36%, while soft-prompt tuning only delivered marginal improvements. LoRA required less than 0.1% additional parameters to achieve this.", "conclusion": "LoRA is a highly effective, computationally efficient method for mitigating bias in LLMs. The study calls for wider adoption of PEFT, development of queer-authored corpora, and improved evaluation mechanisms."}}
{"id": "2507.13425", "pdf": "https://arxiv.org/pdf/2507.13425", "abs": "https://arxiv.org/abs/2507.13425", "authors": ["Sirui Wang", "Zhou Guan", "Bingxi Zhao", "Tongjia Gu"], "title": "CaSTFormer: Causal Spatio-Temporal Transformer for Driving Intention Prediction", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Accurate prediction of driving intention is key to enhancing the safety and\ninteractive efficiency of human-machine co-driving systems. It serves as a\ncornerstone for achieving high-level autonomous driving. However, current\napproaches remain inadequate for accurately modeling the complex\nspatio-temporal interdependencies and the unpredictable variability of human\ndriving behavior. To address these challenges, we propose CaSTFormer, a Causal\nSpatio-Temporal Transformer to explicitly model causal interactions between\ndriver behavior and environmental context for robust intention prediction.\nSpecifically, CaSTFormer introduces a novel Reciprocal Shift Fusion (RSF)\nmechanism for precise temporal alignment of internal and external feature\nstreams, a Causal Pattern Extraction (CPE) module that systematically\neliminates spurious correlations to reveal authentic causal dependencies, and\nan innovative Feature Synthesis Network (FSN) that adaptively synthesizes these\npurified representations into coherent spatio-temporal inferences. We evaluate\nthe proposed CaSTFormer on the public Brain4Cars dataset, and it achieves\nstate-of-the-art performance. It effectively captures complex causal\nspatio-temporal dependencies and enhances both the accuracy and transparency of\ndriving intention prediction.", "AI": {"tldr": "The paper introduces CaSTFormer, a model for predicting driving intention by leveraging causal interactions and spatio-temporal dynamics, achieving state-of-the-art performance on the Brain4Cars dataset.", "motivation": "The motivation of this paper is to improve the safety and efficiency of human-machine co-driving systems by accurately predicting driving intentions, addressing the limitations in current methods in capturing complex spatio-temporal interdependencies and human behavior variability.", "method": "The authors propose CaSTFormer, a Causal Spatio-Temporal Transformer, which includes three key components: Reciprocal Shift Fusion (RSF) for precise temporal alignment, Causal Pattern Extraction (CPE) for removing spurious correlations, and a Feature Synthesis Network (FSN) for synthesizing spatio-temporal inferences.", "result": "The paper demonstrates that CaSTFormer achieves state-of-the-art performance on the Brain4Cars dataset, effectively modeling and capturing causal spatio-temporal dependencies in driving behavior.", "conclusion": "CaSTFormer improves the accuracy and transparency of driving intention prediction, establishing itself as a robust tool for advancing human-machine co-driving systems."}}
{"id": "2507.13685", "pdf": "https://arxiv.org/pdf/2507.13685", "abs": "https://arxiv.org/abs/2507.13685", "authors": ["Yue Yang", "Zihan Su", "Ying Zhang", "Chang Chuan Goh", "Yuxiang Lin", "Anthony Graham Bellotti", "Boon Giin Lee"], "title": "Kolmogorov-Arnold Networks-based GRU and LSTM for Loan Default Early Prediction", "categories": ["cs.LG"], "comment": null, "summary": "This study addresses a critical challenge in time series anomaly detection:\nenhancing the predictive capability of loan default models more than three\nmonths in advance to enable early identification of default events, helping\nfinancial institutions implement preventive measures before risk events\nmaterialize. Existing methods have significant drawbacks, such as their lack of\naccuracy in early predictions and their dependence on training and testing\nwithin the same year and specific time frames. These issues limit their\npractical use, particularly with out-of-time data. To address these, the study\nintroduces two innovative architectures, GRU-KAN and LSTM-KAN, which merge\nKolmogorov-Arnold Networks (KAN) with Gated Recurrent Units (GRU) and Long\nShort-Term Memory (LSTM) networks. The proposed models were evaluated against\nthe baseline models (LSTM, GRU, LSTM-Attention, and LSTM-Transformer) in terms\nof accuracy, precision, recall, F1 and AUC in different lengths of feature\nwindow, sample sizes, and early prediction intervals. The results demonstrate\nthat the proposed model achieves a prediction accuracy of over 92% three months\nin advance and over 88% eight months in advance, significantly outperforming\nexisting baselines.", "AI": {"tldr": "The study introduces two novel architectures, GRU-KAN and LSTM-KAN, for early and accurate loan default prediction by effectively combining KAN with GRU and LSTM.", "motivation": "The current loan default models struggle with early predictions and reliance on same-year data, which limits their practicality in detecting potential risks in advance.", "method": "The study merges Kolmogorov-Arnold Networks (KAN) with GRU and LSTM to create new architectures, and evaluates their performance against baseline models through metrics like accuracy, precision, recall, F1, and AUC.", "result": "The proposed models show significant performance improvements, with over 92% accuracy for three-month advance predictions and over 88% for eight-month advance predictions, outperforming standard architectures.", "conclusion": "GRU-KAN and LSTM-KAN present a robust step forward in early loan default prediction, addressing key limitations in legacy methods and offering substantial advantages for financial risk management."}}
{"id": "2507.13872", "pdf": "https://arxiv.org/pdf/2507.13872", "abs": "https://arxiv.org/abs/2507.13872", "authors": ["Aditya Singh", "Aastha Mishra", "Manan Tayal", "Shishir Kolathaya", "Pushpak Jagtap"], "title": "Safe and Performant Controller Synthesis using Gradient-based Model Predictive Control and Control Barrier Functions", "categories": ["eess.SY", "cs.RO", "cs.SY"], "comment": "6 Pages, 2 Figures. The first two authors contributed equally", "summary": "Ensuring both performance and safety is critical for autonomous systems\noperating in real-world environments. While safety filters such as Control\nBarrier Functions (CBFs) enforce constraints by modifying nominal controllers\nin real time, they can become overly conservative when the nominal policy lacks\nsafety awareness. Conversely, solving State-Constrained Optimal Control\nProblems (SC-OCPs) via dynamic programming offers formal guarantees but is\nintractable in high-dimensional systems. In this work, we propose a novel\ntwo-stage framework that combines gradient-based Model Predictive Control (MPC)\nwith CBF-based safety filtering for co-optimizing safety and performance. In\nthe first stage, we relax safety constraints as penalties in the cost function,\nenabling fast optimization via gradient-based methods. This step improves\nscalability and avoids feasibility issues associated with hard constraints. In\nthe second stage, we modify the resulting controller using a CBF-based\nQuadratic Program (CBF-QP), which enforces hard safety constraints with minimal\ndeviation from the reference. Our approach yields controllers that are both\nperformant and provably safe. We validate the proposed framework on two case\nstudies, showcasing its ability to synthesize scalable, safe, and\nhigh-performance controllers for complex, high-dimensional autonomous systems.", "AI": {"tldr": "This paper proposes a two-stage framework that combines gradient-based Model Predictive Control (MPC) and Control Barrier Functions (CBFs) for scalable and safe control of autonomous systems.", "motivation": "The challenge addressed is the trade-off between performance and safety in autonomy: CBFs ensure safety but may be conservative, and dynamic programming for SC-OCPs is computationally intractable for high-dimensional systems.", "method": "The proposed method employs a two-stage approach: first, relaxing safety constraints into penalties for scalable optimization using gradient-based MPC; second, refining the controller via a CBF-based quadratic program to ensure strict safety constraints.", "result": "Controllers generated by the framework achieve both high performance and provable safety, demonstrated through two case studies dealing with high-dimensional autonomous systems.", "conclusion": "This framework successfully co-optimizes safety and performance while addressing scalability, offering a practical solution for handling real-world autonomous systems."}}
{"id": "2507.13761", "pdf": "https://arxiv.org/pdf/2507.13761", "abs": "https://arxiv.org/abs/2507.13761", "authors": ["Palash Nandi", "Maithili Joshi", "Tanmoy Chakraborty"], "title": "Innocence in the Crossfire: Roles of Skip Connections in Jailbreaking Visual Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Language models are highly sensitive to prompt formulations - small changes\nin input can drastically alter their output. This raises a critical question:\nTo what extent can prompt sensitivity be exploited to generate inapt content?\nIn this paper, we investigate how discrete components of prompt design\ninfluence the generation of inappropriate content in Visual Language Models\n(VLMs). Specifically, we analyze the impact of three key factors on successful\njailbreaks: (a) the inclusion of detailed visual information, (b) the presence\nof adversarial examples, and (c) the use of positively framed beginning\nphrases. Our findings reveal that while a VLM can reliably distinguish between\nbenign and harmful inputs in unimodal settings (text-only or image-only), this\nability significantly degrades in multimodal contexts. Each of the three\nfactors is independently capable of triggering a jailbreak, and we show that\neven a small number of in-context examples (as few as three) can push the model\ntoward generating inappropriate outputs. Furthermore, we propose a framework\nthat utilizes a skip-connection between two internal layers of the VLM, which\nsubstantially increases jailbreak success rates, even when using benign images.\nFinally, we demonstrate that memes, often perceived as humorous or harmless,\ncan be as effective as toxic visuals in eliciting harmful content, underscoring\nthe subtle and complex vulnerabilities of VLMs.", "AI": {"tldr": "This paper examines the vulnerabilities of Visual Language Models (VLMs) in generating inappropriate content based on prompt design and presents a method to exploit these weaknesses effectively.", "motivation": "To investigate the sensitivity of Visual Language Models (VLMs) to prompt design and assess the extent to which this sensitivity can lead to generating inappropriate content.", "method": "The study analyzes the effect of detailed visual information, adversarial examples, and positively framed phrases on jailbreak success. It also proposes a framework with a skip-connection between internal VLM layers to enhance jailbreak effectiveness.", "result": "Findings reveal that multimodal settings significantly degrade the VLM's ability to distinguish harmful inputs. Each factor independently facilitates jailbreaks, and using as few as three in-context examples can lead to inappropriate outputs. A skip-connection framework and the use of memes are shown to amplify these vulnerabilities.", "conclusion": "VLMs have critical and exploitable vulnerabilities to prompt sensitivity, necessitating further research into robust and reliable safeguards for these models."}}
{"id": "2507.13428", "pdf": "https://arxiv.org/pdf/2507.13428", "abs": "https://arxiv.org/abs/2507.13428", "authors": ["Jing Gu", "Xian Liu", "Yu Zeng", "Ashwin Nagarajan", "Fangrui Zhu", "Daniel Hong", "Yue Fan", "Qianqi Yan", "Kaiwen Zhou", "Ming-Yu Liu", "Xin Eric Wang"], "title": "\"PhyWorldBench\": A Comprehensive Evaluation of Physical Realism in Text-to-Video Models", "categories": ["cs.CV", "cs.AI"], "comment": "31 pages, 21 figures", "summary": "Video generation models have achieved remarkable progress in creating\nhigh-quality, photorealistic content. However, their ability to accurately\nsimulate physical phenomena remains a critical and unresolved challenge. This\npaper presents PhyWorldBench, a comprehensive benchmark designed to evaluate\nvideo generation models based on their adherence to the laws of physics. The\nbenchmark covers multiple levels of physical phenomena, ranging from\nfundamental principles like object motion and energy conservation to more\ncomplex scenarios involving rigid body interactions and human or animal motion.\nAdditionally, we introduce a novel \"\"Anti-Physics\"\" category, where prompts\nintentionally violate real-world physics, enabling the assessment of whether\nmodels can follow such instructions while maintaining logical consistency.\nBesides large-scale human evaluation, we also design a simple yet effective\nmethod that could utilize current MLLM to evaluate the physics realism in a\nzero-shot fashion. We evaluate 12 state-of-the-art text-to-video generation\nmodels, including five open-source and five proprietary models, with a detailed\ncomparison and analysis. we identify pivotal challenges models face in adhering\nto real-world physics. Through systematic testing of their outputs across 1,050\ncurated prompts-spanning fundamental, composite, and anti-physics scenarios-we\nidentify pivotal challenges these models face in adhering to real-world\nphysics. We then rigorously examine their performance on diverse physical\nphenomena with varying prompt types, deriving targeted recommendations for\ncrafting prompts that enhance fidelity to physical principles.", "AI": {"tldr": "PhyWorldBench is a new benchmark to evaluate video generation models on their adherence to real-world physics, including scenarios like object motion and energy conservation, as well as 'Anti-Physics' prompts.", "motivation": "Assess the ability of video generation models to accurately simulate physical phenomena, which remains an unresolved issue.", "method": "Introduced a benchmark called PhyWorldBench covering multiple physical phenomena scenarios, along with a zero-shot evaluation method using current MLLM.", "result": "Evaluated 12 state-of-the-art models across 1,050 curated prompts, identifying challenges in simulating real-world physics and deriving recommendations for improving prompt design.", "conclusion": "Video generation models still face significant hurdles in maintaining physics realism, but systematic benchmarking and refined prompt design can address these issues."}}
{"id": "2507.13703", "pdf": "https://arxiv.org/pdf/2507.13703", "abs": "https://arxiv.org/abs/2507.13703", "authors": ["Martin Krutsk\u00fd", "Gustav \u0160\u00edr", "Vyacheslav Kungurtsev", "Georgios Korpas"], "title": "Binarizing Physics-Inspired GNNs for Combinatorial Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to the 28th European Conference on Artificial Intelligence\n  (ECAI 2025). This archival version includes supplementary appendices", "summary": "Physics-inspired graph neural networks (PI-GNNs) have been utilized as an\nefficient unsupervised framework for relaxing combinatorial optimization\nproblems encoded through a specific graph structure and loss, reflecting\ndependencies between the problem's variables. While the framework has yielded\npromising results in various combinatorial problems, we show that the\nperformance of PI-GNNs systematically plummets with an increasing density of\nthe combinatorial problem graphs. Our analysis reveals an interesting phase\ntransition in the PI-GNNs' training dynamics, associated with degenerate\nsolutions for the denser problems, highlighting a discrepancy between the\nrelaxed, real-valued model outputs and the binary-valued problem solutions. To\naddress the discrepancy, we propose principled alternatives to the naive\nstrategy used in PI-GNNs by building on insights from fuzzy logic and binarized\nneural networks. Our experiments demonstrate that the portfolio of proposed\nmethods significantly improves the performance of PI-GNNs in increasingly dense\nsettings.", "AI": {"tldr": "Physics-Inspired Graph Neural Networks (PI-GNNs) show limitations in handling dense combinatorial problem graphs, and the paper proposes new methods inspired by fuzzy logic and binarized neural networks to address this.", "motivation": "Combinatorial optimization problems encoded as graphs are crucial in many domains, but PI-GNNs perform poorly with dense graphs, necessitating further improvements.", "method": "Identified performance issues in PI-GNNs for dense graphs, analyzed training dynamics, and introduced strategies from fuzzy logic and binarized neural networks to enhance the framework.", "result": "Proposed methods overcame performance degradation of PI-GNNs in high-density graph settings, demonstrating significant improvement.", "conclusion": "The enhanced strategies enable PI-GNNs to better handle dense combinatorial problems, bridging the gap between model outputs and problem solutions."}}
{"id": "2507.13888", "pdf": "https://arxiv.org/pdf/2507.13888", "abs": "https://arxiv.org/abs/2507.13888", "authors": ["Janani S K", "Shishir Kolathaya"], "title": "Fixed time convergence guarantees for Higher Order Control Barrier Functions", "categories": ["eess.SY", "cs.RO", "cs.SY"], "comment": "6 PAGES, 2 FIGURES", "summary": "We present a novel method for designing higher-order Control Barrier\nFunctions (CBFs) that guarantee convergence to a safe set within a\nuser-specified finite. Traditional Higher Order CBFs (HOCBFs) ensure asymptotic\nsafety but lack mechanisms for fixed-time convergence, which is critical in\ntime-sensitive and safety-critical applications such as autonomous navigation.\nIn contrast, our approach imposes a structured differential constraint using\nrepeated roots in the characteristic polynomial, enabling closed-form\npolynomial solutions with exact convergence at a prescribed time. We derive\nconditions on the barrier function and its derivatives that ensure forward\ninvariance and fixed-time reachability, and we provide an explicit formulation\nfor second-order systems. Our method is evaluated on three robotic systems - a\npoint-mass model, a unicycle, and a bicycle model and benchmarked against\nexisting HOCBF approaches. Results demonstrate that our formulation reliably\nenforces convergence within the desired time, even when traditional methods\nfail. This work provides a tractable and robust framework for real-time control\nwith provable finite-time safety guarantees.", "AI": {"tldr": "This paper introduces a novel method for higher-order Control Barrier Functions (CBFs) that ensures convergence to a safe set in a specified finite time.", "motivation": "Traditional methods lack mechanisms for fixed-time convergence, which is essential for time-sensitive, safety-critical systems like autonomous navigation.", "method": "The method imposes a structured differential constraint using repeated roots in the characteristic polynomial, enabling closed-form polynomial solutions for exact time-bound convergence.", "result": "The method was evaluated on three robotic systems and successfully enforced convergence within the desired time, outperforming traditional HOCBF approaches.", "conclusion": "The proposed approach offers a robust framework for real-time control with provable finite-time safety guarantees, making it suitable for critical applications."}}
{"id": "2507.13793", "pdf": "https://arxiv.org/pdf/2507.13793", "abs": "https://arxiv.org/abs/2507.13793", "authors": ["Enhao Cheng", "Shoujia Zhang", "Jianhua Yin", "Xuemeng Song", "Tian Gan", "Liqiang Nie"], "title": "An Enhanced Model-based Approach for Short Text Clustering", "categories": ["cs.CL"], "comment": null, "summary": "Short text clustering has become increasingly important with the popularity\nof social media like Twitter, Google+, and Facebook. Existing methods can be\nbroadly categorized into two paradigms: topic model-based approaches and deep\nrepresentation learning-based approaches. This task is inherently challenging\ndue to the sparse, large-scale, and high-dimensional characteristics of the\nshort text data. Furthermore, the computational intensity required by\nrepresentation learning significantly increases the running time. To address\nthese issues, we propose a collapsed Gibbs Sampling algorithm for the Dirichlet\nMultinomial Mixture model (GSDMM), which effectively handles the sparsity and\nhigh dimensionality of short texts while identifying representative words for\neach cluster. Based on several aspects of GSDMM that warrant further\nrefinement, we propose an improved approach, GSDMM+, designed to further\noptimize its performance. GSDMM+ reduces initialization noise and adaptively\nadjusts word weights based on entropy, achieving fine-grained clustering that\nreveals more topic-related information. Additionally, strategic cluster merging\nis employed to refine clustering granularity, better aligning the predicted\ndistribution with the true category distribution. We conduct extensive\nexperiments, comparing our methods with both classical and state-of-the-art\napproaches. The experimental results demonstrate the efficiency and\neffectiveness of our methods. The source code for our model is publicly\navailable at https://github.com/chehaoa/VEMC.", "AI": {"tldr": "The paper introduces GSDMM+, an enhanced clustering algorithm for short text data, reducing noise and improving topic discovery through entropy adjustments and cluster merging.", "motivation": "The authors aim to tackle challenges in short text clustering, such as data sparsity, high dimensionality, and computational intensity, while improving on existing representation learning and topic model-based methods.", "method": "They propose GSDMM+ which builds on the collapsed Gibbs Sampling algorithm for Dirichlet Multinomial Mixture model (GSDMM). Their enhancements include reducing initialization noise, adaptively adjusting word weights based on entropy, and merging clusters strategically to improve clustering granularity.", "result": "The experiments demonstrate that GSDMM+ outperforms both classical and state-of-the-art methods in terms of efficiency and effectiveness for short text clustering.", "conclusion": "GSDMM+ achieves fine-grained and more topic-relevant clustering for short text, proving to be a strong advancement on existing clustering techniques. Its source code is made publicly available for reproducibility."}}
{"id": "2507.13486", "pdf": "https://arxiv.org/pdf/2507.13486", "abs": "https://arxiv.org/abs/2507.13486", "authors": ["Debao Huang", "Rongjun Qin"], "title": "Uncertainty Quantification Framework for Aerial and UAV Photogrammetry through Error Propagation", "categories": ["cs.CV"], "comment": "16 pages, 9 figures, this manuscript has been submitted to ISPRS\n  Journal of Photogrammetry and Remote Sensing for consideration", "summary": "Uncertainty quantification of the photogrammetry process is essential for\nproviding per-point accuracy credentials of the point clouds. Unlike airborne\nLiDAR, which typically delivers consistent accuracy across various scenes, the\naccuracy of photogrammetric point clouds is highly scene-dependent, since it\nrelies on algorithm-generated measurements (i.e., stereo or multi-view stereo).\nGenerally, errors of the photogrammetric point clouds propagate through a\ntwo-step process: Structure-from-Motion (SfM) with Bundle adjustment (BA),\nfollowed by Multi-view Stereo (MVS). While uncertainty estimation in the SfM\nstage has been well studied using the first-order statistics of the\nreprojection error function, that in the MVS stage remains largely unsolved and\nnon-standardized, primarily due to its non-differentiable and multi-modal\nnature (i.e., from pixel values to geometry). In this paper, we present an\nuncertainty quantification framework closing this gap by associating an error\ncovariance matrix per point accounting for this two-step photogrammetry\nprocess. Specifically, to estimate the uncertainty in the MVS stage, we propose\na novel, self-calibrating method by taking reliable n-view points (n>=6)\nper-view to regress the disparity uncertainty using highly relevant cues (such\nas matching cost values) from the MVS stage. Compared to existing approaches,\nour method uses self-contained, reliable 3D points extracted directly from the\nMVS process, with the benefit of being self-supervised and naturally adhering\nto error propagation path of the photogrammetry process, thereby providing a\nrobust and certifiable uncertainty quantification across diverse scenes. We\nevaluate the framework using a variety of publicly available airborne and UAV\nimagery datasets. Results demonstrate that our method outperforms existing\napproaches by achieving high bounding rates without overestimating uncertainty.", "AI": {"tldr": "This paper introduces a framework for accurately quantifying uncertainties in photogrammetric point clouds, specifically addressing the challenging Multi-View Stereo (MVS) stage.", "motivation": "The accuracy of photogrammetric point clouds varies with the scene and lacks a standardized method for uncertainty estimation in the MVS stage, unlike the more consistent accuracy seen in airborne LiDAR.", "method": "A self-calibrating approach is proposed, leveraging reliable n-view points (n>=6) per-view to regress disparity uncertainty during the MVS stage using cues like matching cost values. The method is self-supervised and accounts for the full photogrammetry error propagation.", "result": "The framework was validated on diverse airborne and UAV imagery datasets, outperforming existing methods by achieving high bounding rates without overestimating uncertainty.", "conclusion": "The study provides a robust uncertainty quantification framework that adheres to the error propagation and improves the reliability of photogrammetric point clouds across diverse scenes."}}
{"id": "2507.13827", "pdf": "https://arxiv.org/pdf/2507.13827", "abs": "https://arxiv.org/abs/2507.13827", "authors": ["Hosein Azarbonyad", "Zi Long Zhu", "Georgios Cheirmpos", "Zubair Afzal", "Vikrant Yadav", "Georgios Tsatsaronis"], "title": "Question-Answer Extraction from Scientific Articles Using Knowledge Graphs and Large Language Models", "categories": ["cs.CL", "cs.IR", "cs.LG"], "comment": "SIGIR 2025", "summary": "When deciding to read an article or incorporate it into their research,\nscholars often seek to quickly identify and understand its main ideas. In this\npaper, we aim to extract these key concepts and contributions from scientific\narticles in the form of Question and Answer (QA) pairs. We propose two distinct\napproaches for generating QAs. The first approach involves selecting salient\nparagraphs, using a Large Language Model (LLM) to generate questions, ranking\nthese questions by the likelihood of obtaining meaningful answers, and\nsubsequently generating answers. This method relies exclusively on the content\nof the articles. However, assessing an article's novelty typically requires\ncomparison with the existing literature. Therefore, our second approach\nleverages a Knowledge Graph (KG) for QA generation. We construct a KG by\nfine-tuning an Entity Relationship (ER) extraction model on scientific articles\nand using it to build the graph. We then employ a salient triplet extraction\nmethod to select the most pertinent ERs per article, utilizing metrics such as\nthe centrality of entities based on a triplet TF-IDF-like measure. This measure\nassesses the saliency of a triplet based on its importance within the article\ncompared to its prevalence in the literature. For evaluation, we generate QAs\nusing both approaches and have them assessed by Subject Matter Experts (SMEs)\nthrough a set of predefined metrics to evaluate the quality of both questions\nand answers. Our evaluations demonstrate that the KG-based approach effectively\ncaptures the main ideas discussed in the articles. Furthermore, our findings\nindicate that fine-tuning the ER extraction model on our scientific corpus is\ncrucial for extracting high-quality triplets from such documents.", "AI": {"tldr": "This paper introduces two methods for extracting key ideas from scientific articles by generating Question and Answer (QA) pairs: one using article content with a Large Language Model (LLM) and another leveraging a Knowledge Graph (KG).", "motivation": "Scholars need an efficient way to quickly identify main ideas and contributions in scientific articles for their research.", "method": "Two QA generation methods are developed: (1) an article-content-based method using salient paragraphs and LLMs, and (2) a KG-based method that uses an Entity Relationship (ER) extraction model and saliency metrics to structure information.", "result": "The KG-based approach effectively captures the main ideas in scientific articles, and fine-tuning the ER extraction model is essential for extracting high-quality information.", "conclusion": "The methods proposed, especially the KG-based approach, provide reliable tools for summarizing scientific articles' key ideas, with potential for broader applications in academic research."}}
{"id": "2507.13514", "pdf": "https://arxiv.org/pdf/2507.13514", "abs": "https://arxiv.org/abs/2507.13514", "authors": ["Bhumika Laxman Sadbhave", "Philipp Vaeth", "Denise Dejon", "Gunther Schorcht", "Magda Gregorov\u00e1"], "title": "Sugar-Beet Stress Detection using Satellite Image Time Series", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Satellite Image Time Series (SITS) data has proven effective for agricultural\ntasks due to its rich spectral and temporal nature. In this study, we tackle\nthe task of stress detection in sugar-beet fields using a fully unsupervised\napproach. We propose a 3D convolutional autoencoder model to extract meaningful\nfeatures from Sentinel-2 image sequences, combined with\nacquisition-date-specific temporal encodings to better capture the growth\ndynamics of sugar-beets. The learned representations are used in a downstream\nclustering task to separate stressed from healthy fields. The resulting stress\ndetection system can be directly applied to data from different years, offering\na practical and accessible tool for stress detection in sugar-beets.", "AI": {"tldr": "The study introduces an unsupervised approach for stress detection in sugar-beet fields using a 3D convolutional autoencoder and clustering on Sentinel-2 time-series imagery.", "motivation": "To address the need for scalable and practical methods for stress detection in agricultural crops, focusing on sugar-beets, leveraging rich temporal and spectral data from satellites.", "method": "A 3D convolutional autoencoder was utilized to extract features from Sentinel-2 satellite image sequences, enhanced by temporal encodings specific to acquisition dates. The extracted representations were used in a clustering process to differentiate between stressed and healthy sugar-beet fields.", "result": "The proposed system demonstrated the ability to perform stress detection directly on satellite data from different years, showcasing its adaptability and practicality.", "conclusion": "The approach provides a novel, unsupervised, and scalable solution for detecting stress in sugar-beets, with potential applications across datasets spanning multiple years."}}
{"id": "2507.13707", "pdf": "https://arxiv.org/pdf/2507.13707", "abs": "https://arxiv.org/abs/2507.13707", "authors": ["Hao Wang", "Yu Liu", "Daniel Biggs", "Haoru Wang", "Jiandong Yu", "Ping Huang"], "title": "Learning Deformable Body Interactions With Adaptive Spatial Tokenization", "categories": ["cs.LG"], "comment": "21 pages, 15 figures", "summary": "Simulating interactions between deformable bodies is vital in fields like\nmaterial science, mechanical design, and robotics. While learning-based methods\nwith Graph Neural Networks (GNNs) are effective at solving complex physical\nsystems, they encounter scalability issues when modeling deformable body\ninteractions. To model interactions between objects, pairwise global edges have\nto be created dynamically, which is computationally intensive and impractical\nfor large-scale meshes. To overcome these challenges, drawing on insights from\ngeometric representations, we propose an Adaptive Spatial Tokenization (AST)\nmethod for efficient representation of physical states. By dividing the\nsimulation space into a grid of cells and mapping unstructured meshes onto this\nstructured grid, our approach naturally groups adjacent mesh nodes. We then\napply a cross-attention module to map the sparse cells into a compact,\nfixed-length embedding, serving as tokens for the entire physical state.\nSelf-attention modules are employed to predict the next state over these tokens\nin latent space. This framework leverages the efficiency of tokenization and\nthe expressive power of attention mechanisms to achieve accurate and scalable\nsimulation results. Extensive experiments demonstrate that our method\nsignificantly outperforms state-of-the-art approaches in modeling deformable\nbody interactions. Notably, it remains effective on large-scale simulations\nwith meshes exceeding 100,000 nodes, where existing methods are hindered by\ncomputational limitations. Additionally, we contribute a novel large-scale\ndataset encompassing a wide range of deformable body interactions to support\nfuture research in this area.", "AI": {"tldr": "This paper introduces an Adaptive Spatial Tokenization (AST) method to tackle scalability issues in simulating deformable body interactions using Graph Neural Networks (GNNs), achieving accuracy and scalability even for large-scale meshes.", "motivation": "Simulations of deformable bodies are crucial in various fields, but learning-based methods like Graph Neural Networks face computational challenges when scaling to large multi-node meshes due to the need for dynamically created pairwise global edges.", "method": "The authors propose Adaptive Spatial Tokenization (AST), which maps unstructured meshes to grid-based representations. Sparse grid cells are summarized into fixed-length embeddings via cross-attention modules, and self-attention is then used to predict physical states in latent space. This tokenization lessens computational demands while maintaining expressiveness.", "result": "Experiments show the AST method surpasses state-of-the-art methods in accuracy for simulating deformable body interactions. It excels in handling large meshes exceeding 100,000 nodes, where current methods often fail.", "conclusion": "The AST framework enables scalable and efficient simulations of deformable body interactions, advancing the field. In addition, the authors provide a novel dataset to promote further research on large-scale deformable body simulations."}}
{"id": "2507.13839", "pdf": "https://arxiv.org/pdf/2507.13839", "abs": "https://arxiv.org/abs/2507.13839", "authors": ["Lizhi Ma", "Tong Zhao", "Shuai Zhang", "Nirui Song", "Hongliang He", "Anqi Li", "Ran Feng", "Huachuan Qiu", "Jingsong Ma", "Zhenzhong Lan"], "title": "The Expressions of Depression and Anxiety in Chinese Psycho-counseling: Usage of First-person Singular Pronoun and Negative Emotional Words", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "This study explores the relationship between linguistic expressions and\npsychological states of depression and anxiety within Chinese psycho-counseling\ninteractions, focusing specifically on the usage of first-person singular\npronouns and negative emotional words. Utilizing a corpus derived from 735\nonline counseling sessions, the analysis employed a general linear mixed-effect\nmodel to assess linguistic patterns quantified by the Linguistic Inquiry and\nWord Count (LIWC) software. Results indicate a significant positive correlation\nbetween the frequency of negative emotional words and the severity of both\ndepressive and anxious states among clients. However, contrary to prior\nfindings predominantly derived from English-language contexts, the usage\nfrequency of first-person singular pronouns did not vary significantly with the\nclients' psychological conditions. These outcomes are discussed within the\nframework of cultural distinctions between collectivist Chinese contexts and\nindividualistic Western settings, as well as the interactive dynamics unique to\npsycho-counseling conversations. The findings highlight the nuanced influence\nof cultural and conversational contexts on language use in mental health\ncommunications, providing insights into psycholinguistic markers relevant to\ntherapeutic practices in Chinese-speaking populations.", "AI": {"tldr": "The paper studies the relationship between language use and mental health conditions in Chinese counseling sessions, finding significant ties between negative emotional word use and depression/anxiety severity, but no influence from first-person pronoun use.", "motivation": "To explore how linguistic expressions may serve as indicators of mental health conditions like depression and anxiety within Chinese psycho-counseling interactions, taking into account cultural and conversational specificities.", "method": "Analyzed 735 online counseling sessions using LIWC software and general linear mixed-effect models to assess linguistic patterns.", "result": "Found a positive correlation between the frequency of negative emotional words and severity of depression and anxiety, but no significant variation for first-person singular pronoun usage.", "conclusion": "Cultural and conversational contexts have a nuanced impact on language use in mental health communications, emphasizing psycholinguistic markers specific to Chinese-speaking clients."}}
{"id": "2507.13527", "pdf": "https://arxiv.org/pdf/2507.13527", "abs": "https://arxiv.org/abs/2507.13527", "authors": ["Levi Harris", "Md Jayed Hossain", "Mufan Qiu", "Ruichen Zhang", "Pingchuan Ma", "Tianlong Chen", "Jiaqi Gu", "Seth Ariel Tongay", "Umberto Celano"], "title": "SparseC-AFM: a deep learning method for fast and accurate characterization of MoS$_2$ with C-AFM", "categories": ["cs.CV", "cond-mat.mtrl-sci"], "comment": null, "summary": "The increasing use of two-dimensional (2D) materials in nanoelectronics\ndemands robust metrology techniques for electrical characterization, especially\nfor large-scale production. While atomic force microscopy (AFM) techniques like\nconductive AFM (C-AFM) offer high accuracy, they suffer from slow data\nacquisition speeds due to the raster scanning process. To address this, we\nintroduce SparseC-AFM, a deep learning model that rapidly and accurately\nreconstructs conductivity maps of 2D materials like MoS$_2$ from sparse C-AFM\nscans. Our approach is robust across various scanning modes, substrates, and\nexperimental conditions. We report a comparison between (a) classic flow\nimplementation, where a high pixel density C-AFM image (e.g., 15 minutes to\ncollect) is manually parsed to extract relevant material parameters, and (b)\nour SparseC-AFM method, which achieves the same operation using data that\nrequires substantially less acquisition time (e.g., under 5 minutes).\nSparseC-AFM enables efficient extraction of critical material parameters in\nMoS$_2$, including film coverage, defect density, and identification of\ncrystalline island boundaries, edges, and cracks. We achieve over 11x reduction\nin acquisition time compared to manual extraction from a full-resolution C-AFM\nimage. Moreover, we demonstrate that our model-predicted samples exhibit\nremarkably similar electrical properties to full-resolution data gathered using\nclassic-flow scanning. This work represents a significant step toward\ntranslating AI-assisted 2D material characterization from laboratory research\nto industrial fabrication. Code and model weights are available at\ngithub.com/UNITES-Lab/sparse-cafm.", "AI": {"tldr": "This paper introduces SparseC-AFM, a deep learning model that accelerates and improves the conductivity mapping of 2D materials like MoS$_2$ using sparse scans, reducing acquisition time by over 11x compared to traditional methods.", "motivation": "The paper aims to address the slow data acquisition speed of atomic force microscopy techniques, such as conductive AFM (C-AFM), which hinders large-scale electrical characterization in the production of 2D materials.", "method": "The authors developed SparseC-AFM, a deep learning model that reconstructs high-resolution conductivity maps from sparse scan data. The method was validated across various scanning modes, substrates, and experimental conditions.", "result": "The SparseC-AFM model achieved over 11x faster acquisition time than traditional manual parsing of full-resolution C-AFM images. It was also able to identify critical material parameters in MoS$_2$ with comparable accuracy to traditional techniques.", "conclusion": "SparseC-AFM represents a significant advancement in applying AI to 2D material characterization, making it a promising tool for transitioning from laboratory-scale research to industrial-scale production."}}
{"id": "2507.13716", "pdf": "https://arxiv.org/pdf/2507.13716", "abs": "https://arxiv.org/abs/2507.13716", "authors": ["Danilo Avola", "Andrea Bernardini", "Giancarlo Crocetti", "Andrea Ladogana", "Mario Lezoche", "Maurizio Mancini", "Daniele Pannone", "Amedeo Ranaldi"], "title": "Benchmarking of EEG Analysis Techniques for Parkinson's Disease Diagnosis: A Comparison between Traditional ML Methods and Foundation DL Methods", "categories": ["cs.LG"], "comment": null, "summary": "Parkinson's Disease PD is a progressive neurodegenerative disorder that\naffects motor and cognitive functions with early diagnosis being critical for\neffective clinical intervention Electroencephalography EEG offers a noninvasive\nand costeffective means of detecting PDrelated neural alterations yet the\ndevelopment of reliable automated diagnostic models remains a challenge In this\nstudy we conduct a systematic benchmark of traditional machine learning ML and\ndeep learning DL models for classifying PD using a publicly available oddball\ntask dataset Our aim is to lay the groundwork for developing an effective\nlearning system and to determine which approach produces the best results We\nimplement a unified sevenstep preprocessing pipeline and apply consistent\nsubjectwise crossvalidation and evaluation criteria to ensure comparability\nacross models Our results demonstrate that while baseline deep learning\narchitectures particularly CNNLSTM models achieve the best performance compared\nto other deep learning architectures underlining the importance of capturing\nlongrange temporal dependencies several traditional classifiers such as XGBoost\nalso offer strong predictive accuracy and calibrated decision boundaries By\nrigorously comparing these baselines our work provides a solid reference\nframework for future studies aiming to develop and evaluate more complex or\nspecialized architectures Establishing a reliable set of baseline results is\nessential to contextualize improvements introduced by novel methods ensuring\nscientific rigor and reproducibility in the evolving field of EEGbased\nneurodiagnostics", "AI": {"tldr": "This paper benchmarks traditional machine learning and deep learning models for Parkinson's Disease classification using EEG data, highlighting the performance of CNN-LSTM architectures and XGBoost.", "motivation": "Early diagnosis of Parkinson's Disease is critical for effective intervention, yet reliable automated diagnostic models using EEG remain undeveloped.", "method": "The study used a seven-step preprocessing pipeline, subject-wise cross-validation, and consistent evaluation criteria to compare traditional ML and deep learning models.", "result": "CNN-LSTM deep learning models showed superior performance in capturing long-range temporal dependencies, but traditional classifiers like XGBoost performed strongly too.", "conclusion": "The paper provides a robust reference framework for future studies aiming to improve EEG-based neurodiagnostics with novel architectures, emphasizing scientific rigor and reproducibility."}}
{"id": "2507.13841", "pdf": "https://arxiv.org/pdf/2507.13841", "abs": "https://arxiv.org/abs/2507.13841", "authors": ["Eitan Wagner", "Renana Keydar", "Omri Abend"], "title": "Modeling Fair Play in Detective Stories with Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Effective storytelling relies on a delicate balance between meeting the\nreader's prior expectations and introducing unexpected developments. In the\ndomain of detective fiction, this tension is known as fair play, which includes\nthe implicit agreement between the writer and the reader as to the range of\npossible resolutions the mystery story may have. In this work, we present a\nprobabilistic framework for detective fiction that allows us to define desired\nqualities. Using this framework, we formally define fair play and design\nappropriate metrics for it. Stemming from these definitions is an inherent\ntension between the coherence of the story, which measures how much it ``makes\nsense'', and the surprise it induces. We validate the framework by applying it\nto LLM-generated detective stories. This domain is appealing since we have an\nabundance of data, we can sample from the distribution generating the story,\nand the story-writing capabilities of LLMs are interesting in their own right.\nResults show that while LLM-generated stories may be unpredictable, they\ngenerally fail to balance the trade-off between surprise and fair play, which\ngreatly contributes to their poor quality.", "AI": {"tldr": "The paper introduces a probabilistic framework to assess the qualities of detective fiction, specifically focusing on the balance between coherence and surprise, termed as 'fair play.' It evaluates LLM-generated stories, finding them inconsistent in maintaining this balance.", "motivation": "To analyze and improve the quality of detective fiction through a formalized probabilistic framework, especially in the context of stories generated by large language models (LLMs).", "method": "Develop a probabilistic framework for detective fiction, formally defining fair play and related metrics. Validate the framework by applying it to LLM-generated detective stories to measure coherence and surprise.", "result": "The framework reveals that LLM-generated detective stories often struggle to balance the trade-off between coherence and surprise, leading to lower-quality narratives.", "conclusion": "LLM-generated detective stories fail to maintain fair play effectively, underperforming in crafting high-quality narratives that balance coherence and unpredictability."}}
{"id": "2507.13530", "pdf": "https://arxiv.org/pdf/2507.13530", "abs": "https://arxiv.org/abs/2507.13530", "authors": ["Lukas Baumg\u00e4rtner", "Ronny Bergmann", "Roland Herzog", "Stephan Schmidt", "Manuel Wei\u00df"], "title": "Total Generalized Variation of the Normal Vector Field and Applications to Mesh Denoising", "categories": ["cs.CV", "math.DG", "math.OC"], "comment": null, "summary": "We propose a novel formulation for the second-order total generalized\nvariation (TGV) of the normal vector on an oriented, triangular mesh embedded\nin $\\mathbb{R}^3$. The normal vector is considered as a manifold-valued\nfunction, taking values on the unit sphere. Our formulation extends previous\ndiscrete TGV models for piecewise constant scalar data that utilize a\nRaviart-Thomas function space. To exctend this formulation to the manifold\nsetting, a tailor-made tangential Raviart-Thomas type finite element space is\nconstructed in this work. The new regularizer is compared to existing methods\nin mesh denoising experiments.", "AI": {"tldr": "This paper introduces a novel second-order total generalized variation (TGV) model for denoising triangular meshes using a tangential Raviart-Thomas finite element space.", "motivation": "The authors aimed to improve existing models for denoising triangular meshes by developing a more robust formulation for handling the normal vectors of meshes as manifold-valued data.", "method": "The proposed method extends discrete TGV models for scalar data and introduces a tangential Raviart-Thomas type finite element space tailored to the manifold setting.", "result": "A novel regularizer was developed and tested in mesh denoising experiments, showcasing its effectiveness compared to existing methods.", "conclusion": "The new formulation provides a significant improvement in handling manifold-valued data for mesh denoising applications."}}
{"id": "2507.13718", "pdf": "https://arxiv.org/pdf/2507.13718", "abs": "https://arxiv.org/abs/2507.13718", "authors": ["Danilo Avola", "Muhammad Yasir Bilal", "Emad Emam", "Cristina Lakasz", "Daniele Pannone", "Amedeo Ranaldi"], "title": "Bi-GRU Based Deception Detection using EEG Signals", "categories": ["cs.LG"], "comment": null, "summary": "Deception detection is a significant challenge in fields such as security,\npsychology, and forensics. This study presents a deep learning approach for\nclassifying deceptive and truthful behavior using ElectroEncephaloGram (EEG)\nsignals from the Bag-of-Lies dataset, a multimodal corpus designed for\nnaturalistic, casual deception scenarios. A Bidirectional Gated Recurrent Unit\n(Bi-GRU) neural network was trained to perform binary classification of EEG\nsamples. The model achieved a test accuracy of 97\\%, along with high precision,\nrecall, and F1-scores across both classes. These results demonstrate the\neffectiveness of using bidirectional temporal modeling for EEG-based deception\ndetection and suggest potential for real-time applications and future\nexploration of advanced neural architectures.", "AI": {"tldr": "This study applies a deep learning model (Bi-GRU) on EEG signals to detect deception with 97% test accuracy.", "motivation": "To address the challenge of detecting deceptive behavior in fields like security and psychology using EEG signals.", "method": "Trained a Bidirectional Gated Recurrent Unit (Bi-GRU) neural network for binary classification on EEG signals from the Bag-of-Lies dataset.", "result": "The Bi-GRU model achieved a test accuracy of 97% along with high precision, recall, and F1-scores.", "conclusion": "The approach is effective for EEG-based deception detection, opening possibilities for real-time applications and further exploration of advanced architectures."}}
{"id": "2507.13368", "pdf": "https://arxiv.org/pdf/2507.13368", "abs": "https://arxiv.org/abs/2507.13368", "authors": ["Yaowen Hu", "Wenxuan Tu", "Yue Liu", "Xinhang Wan", "Junyi Yan", "Taichun Zhou", "Xinwang Liu"], "title": "Scalable Attribute-Missing Graph Clustering via Neighborhood Differentiatio", "categories": ["cs.SI", "cs.AI"], "comment": null, "summary": "Deep graph clustering (DGC), which aims to unsupervisedly separate the nodes\nin an attribute graph into different clusters, has seen substantial potential\nin various industrial scenarios like community detection and recommendation.\nHowever, the real-world attribute graphs, e.g., social networks interactions,\nare usually large-scale and attribute-missing. To solve these two problems, we\npropose a novel DGC method termed \\underline{\\textbf{C}}omplementary\n\\underline{\\textbf{M}}ulti-\\underline{\\textbf{V}}iew\n\\underline{\\textbf{N}}eighborhood \\underline{\\textbf{D}}ifferentiation\n(\\textit{CMV-ND}), which preprocesses graph structural information into\nmultiple views in a complete but non-redundant manner. First, to ensure\ncompleteness of the structural information, we propose a recursive neighborhood\nsearch that recursively explores the local structure of the graph by completely\nexpanding node neighborhoods across different hop distances. Second, to\neliminate the redundancy between neighborhoods at different hops, we introduce\na neighborhood differential strategy that ensures no overlapping nodes between\nthe differential hop representations. Then, we construct $K+1$ complementary\nviews from the $K$ differential hop representations and the features of the\ntarget node. Last, we apply existing multi-view clustering or DGC methods to\nthe views. Experimental results on six widely used graph datasets demonstrate\nthat CMV-ND significantly improves the performance of various methods.", "AI": {"tldr": "The paper introduces CMV-ND, a deep graph clustering method that processes large, attribute-missing graphs by generating complementary, non-redundant views from graph structures, resulting in improved clustering outcomes.", "motivation": "Real-world graphs, like social networks, are often large-scale and have missing attributes, which limits the effectiveness of clustering methods. The authors aim to address these challenges.", "method": "The proposed method, CMV-ND, preprocesses graph structural information by first recursively exploring local structures to ensure completeness and then applying a neighborhood differential strategy to eliminate redundancy. Complementary views are constructed from these representations, which are then used by existing clustering methods.", "result": "Experimental results on six well-known graph datasets show that CMV-ND significantly enhances the performance of existing clustering methods, demonstrating its effectiveness.", "conclusion": "CMV-ND efficiently addresses the challenges of large-scale and attribute-missing graphs by creating comprehensive, non-overlapping views of graph structures, leading to better clustering results."}}
{"id": "2507.13858", "pdf": "https://arxiv.org/pdf/2507.13858", "abs": "https://arxiv.org/abs/2507.13858", "authors": ["Nicol\u00f2 Brunello", "Davide Rigamonti", "Andrea Sassella", "Vincenzo Scotti", "Mark James Carman"], "title": "InTraVisTo: Inside Transformer Visualisation Tool", "categories": ["cs.CL"], "comment": "8 pages", "summary": "The reasoning capabilities of Large Language Models (LLMs) have increased\ngreatly over the last few years, as have their size and complexity.\nNonetheless, the use of LLMs in production remains challenging due to their\nunpredictable nature and discrepancies that can exist between their desired\nbehavior and their actual model output. In this paper, we introduce a new tool,\nInTraVisTo (Inside Transformer Visualisation Tool), designed to enable\nresearchers to investigate and trace the computational process that generates\neach token in a Transformer-based LLM. InTraVisTo provides a visualization of\nboth the internal state of the Transformer model (by decoding token embeddings\nat each layer of the model) and the information flow between the various\ncomponents across the different layers of the model (using a Sankey diagram).\nWith InTraVisTo, we aim to help researchers and practitioners better understand\nthe computations being performed within the Transformer model and thus to shed\nsome light on internal patterns and reasoning processes employed by LLMs.", "AI": {"tldr": "The study presents InTraVisTo, a visualization tool for understanding reasoning processes in Transformer-based LLMs, focusing on token generation and internal patterns.", "motivation": "The unpredictable nature and discrepancies between desired outcomes and actual behavior in LLMs pose challenges for practical deployment.", "method": "Introducing InTraVisTo, a tool that visualizes a Transformer-LMM's internal states using decoded token embeddings and information flows with Sankey diagrams.", "result": "InTraVisTo allows researchers to investigate token computation processes and reasoning mechanisms within Transformer models.", "conclusion": "The tool aids in enhancing comprehension of LLM computations, bridging gaps between model complexity and interpretability."}}
{"id": "2507.13546", "pdf": "https://arxiv.org/pdf/2507.13546", "abs": "https://arxiv.org/abs/2507.13546", "authors": ["Dmitrii Mikhailov", "Aleksey Letunovskiy", "Maria Kovaleva", "Vladimir Arkhipkin", "Vladimir Korviakov", "Vladimir Polovnikov", "Viacheslav Vasilev", "Evelina Sidorova", "Denis Dimitrov"], "title": "$\\nabla$NABLA: Neighborhood Adaptive Block-Level Attention", "categories": ["cs.CV"], "comment": null, "summary": "Recent progress in transformer-based architectures has demonstrated\nremarkable success in video generation tasks. However, the quadratic complexity\nof full attention mechanisms remains a critical bottleneck, particularly for\nhigh-resolution and long-duration video sequences. In this paper, we propose\nNABLA, a novel Neighborhood Adaptive Block-Level Attention mechanism that\ndynamically adapts to sparsity patterns in video diffusion transformers (DiTs).\nBy leveraging block-wise attention with adaptive sparsity-driven threshold,\nNABLA reduces computational overhead while preserving generative quality. Our\nmethod does not require custom low-level operator design and can be seamlessly\nintegrated with PyTorch's Flex Attention operator. Experiments demonstrate that\nNABLA achieves up to 2.7x faster training and inference compared to baseline\nalmost without compromising quantitative metrics (CLIP score, VBench score,\nhuman evaluation score) and visual quality drop. The code and model weights are\navailable here: https://github.com/gen-ai-team/Wan2.1-NABLA", "AI": {"tldr": "The paper introduces NABLA, a new attention mechanism for video generation transformers to improve efficiency without sacrificing quality.", "motivation": "Full attention mechanisms in transformer-based architectures are computationally expensive for high-resolution and long-duration video tasks.", "method": "NABLA employs a Neighborhood Adaptive Block-Level Attention mechanism that dynamically adapts to sparsity patterns, reducing computational effort while maintaining generative quality.", "result": "Experiments show NABLA improves training and inference speed by up to 2.7x while preserving quantitative metrics and visual quality.", "conclusion": "NABLA addresses efficiency challenges in video diffusion transformers and can integrate seamlessly into existing frameworks, making it a practical solution for high-resolution video generation."}}
{"id": "2507.13721", "pdf": "https://arxiv.org/pdf/2507.13721", "abs": "https://arxiv.org/abs/2507.13721", "authors": ["Zizhao Zhang", "Tianxiang Zhao", "Yu Sun", "Liping Sun", "Jichuan Kang"], "title": "Graph-Structured Data Analysis of Component Failure in Autonomous Cargo Ships Based on Feature Fusion", "categories": ["cs.LG", "cs.DB"], "comment": null, "summary": "To address the challenges posed by cascading reactions caused by component\nfailures in autonomous cargo ships (ACS) and the uncertainties in emergency\ndecision-making, this paper proposes a novel hybrid feature fusion framework\nfor constructing a graph-structured dataset of failure modes. By employing an\nimproved cuckoo search algorithm (HN-CSA), the literature retrieval efficiency\nis significantly enhanced, achieving improvements of 7.1% and 3.4% compared to\nthe NSGA-II and CSA search algorithms, respectively. A hierarchical feature\nfusion framework is constructed, using Word2Vec encoding to encode\nsubsystem/component features, BERT-KPCA to process failure modes/reasons, and\nSentence-BERT to quantify the semantic association between failure impact and\nemergency decision-making. The dataset covers 12 systems, 1,262 failure modes,\nand 6,150 propagation paths. Validation results show that the GATE-GNN model\nachieves a classification accuracy of 0.735, comparable to existing benchmarks.\nAdditionally, a silhouette coefficient of 0.641 indicates that the features are\nhighly distinguishable. In the label prediction results, the Shore-based\nMeteorological Service System achieved an F1 score of 0.93, demonstrating high\nprediction accuracy. This paper not only provides a solid foundation for\nfailure analysis in autonomous cargo ships but also offers reliable support for\nfault diagnosis, risk assessment, and intelligent decision-making systems. The\nlink to the dataset is\nhttps://github.com/wojiufukele/Graph-Structured-about-CSA.", "AI": {"tldr": "This paper introduces a hybrid feature fusion framework to enhance failure mode analysis for autonomous cargo ships, presenting improved algorithms, datasets, and models for fault detection and decision-making.", "motivation": "The paper aims to tackle challenges in cascading reactions from component failures and uncertainty in emergency decision-making within autonomous cargo ships.", "method": "A hierarchical hybrid feature fusion framework leverages machine learning techniques including Word2Vec, BERT-KPCA, Sentence-BERT, and an improved HN-CSA algorithm for literature retrieval and dataset construction.", "result": "The generated dataset contains 1,262 failure modes and 6,150 propagation paths, showing a GATE-GNN classification accuracy of 0.735 and Shore-based Meteorological Service System F1 score of 0.93.", "conclusion": "The framework and models improve efficiency and reliability in failure analysis for autonomous cargo ships, supporting advanced fault diagnosis and decision-making systems."}}
{"id": "2507.13870", "pdf": "https://arxiv.org/pdf/2507.13870", "abs": "https://arxiv.org/abs/2507.13870", "authors": ["Maciej Jalocha", "Johan Hausted Schmidt", "William Michelseen"], "title": "Label Unification for Cross-Dataset Generalization in Cybersecurity NER", "categories": ["cs.CL"], "comment": "5 pages, 5 figures", "summary": "The field of cybersecurity NER lacks standardized labels, making it\nchallenging to combine datasets. We investigate label unification across four\ncybersecurity datasets to increase data resource usability. We perform a\ncoarse-grained label unification and conduct pairwise cross-dataset evaluations\nusing BiLSTM models. Qualitative analysis of predictions reveals errors,\nlimitations, and dataset differences. To address unification limitations, we\npropose alternative architectures including a multihead model and a graph-based\ntransfer model. Results show that models trained on unified datasets generalize\npoorly across datasets. The multihead model with weight sharing provides only\nmarginal improvements over unified training, while our graph-based transfer\nmodel built on BERT-base-NER shows no significant performance gains compared\nBERT-base-NER.", "AI": {"tldr": "Paper explores label unification in cybersecurity NER across datasets, employing various models like BiLSTM and graph-based structures.", "motivation": "Address the challenge of using multiple cybersecurity NER datasets due to the lack of standardized labels.", "method": "Conduct coarse-grained label unification, pairwise evaluations with BiLSTM models, and explore alternative architectures like multihead and graph-based transfer models.", "result": "Unified dataset models underperform in cross-dataset generalization; multihead model shows marginal improvement, and graph-based transfer model doesn\u2019t outperform BERT-base-NER.", "conclusion": "Unified label models and novel architectures like graph-based transfer models fail to yield significant gains for cybersecurity NER."}}
{"id": "2507.13568", "pdf": "https://arxiv.org/pdf/2507.13568", "abs": "https://arxiv.org/abs/2507.13568", "authors": ["Kaihong Wang", "Donghyun Kim", "Margrit Betke"], "title": "LoRA-Loop: Closing the Synthetic Replay Cycle for Continual VLM Learning", "categories": ["cs.CV"], "comment": null, "summary": "Continual learning for vision-language models has achieved remarkable\nperformance through synthetic replay, where samples are generated using Stable\nDiffusion to regularize during finetuning and retain knowledge. However,\nreal-world downstream applications often exhibit domain-specific nuances and\nfine-grained semantics not captured by generators, causing synthetic-replay\nmethods to produce misaligned samples that misguide finetuning and undermine\nretention of prior knowledge. In this work, we propose a LoRA-enhanced\nsynthetic-replay framework that injects task-specific low-rank adapters into a\nfrozen Stable Diffusion model, efficiently capturing each new task's unique\nvisual and semantic patterns. Specifically, we introduce a two-stage,\nconfidence-based sample selection: we first rank real task data by\npost-finetuning VLM confidence to focus LoRA finetuning on the most\nrepresentative examples, then generate synthetic samples and again select them\nby confidence for distillation. Our approach integrates seamlessly with\nexisting replay pipelines-simply swap in the adapted generator to boost replay\nfidelity. Extensive experiments on the Multi-domain Task Incremental Learning\n(MTIL) benchmark show that our method outperforms previous synthetic-replay\ntechniques, achieving an optimal balance among plasticity, stability, and\nzero-shot capability. These results demonstrate the effectiveness of generator\nadaptation via LoRA for robust continual learning in VLMs.", "AI": {"tldr": "This paper proposes a LoRA-enhanced framework to improve synthetic replay in vision-language models by adapting the Stable Diffusion generator for task-specific nuances, achieving better balance in continual learning.", "motivation": "Existing synthetic-replay methods often fail to account for fine-grained, domain-specific semantics in downstream applications, resulting in misaligned synthetic samples and knowledge degradation during continual learning.", "method": "The method injects task-specific, low-rank adapters (LoRA) into a Stable Diffusion model and employs a two-stage, confidence-based sample selection approach for finetuning and synthetic sample generation to improve replay fidelity.", "result": "The proposed method outperforms prior synthetic-replay techniques on the MTIL benchmark by better balancing plasticity, stability, and zero-shot capability.", "conclusion": "LoRA-based generator adaptation significantly enhances continual learning in vision-language models by addressing the limitations of existing replay methods, thus improving knowledge retention and task adaptation."}}
{"id": "2507.13727", "pdf": "https://arxiv.org/pdf/2507.13727", "abs": "https://arxiv.org/abs/2507.13727", "authors": ["Ren\u00e9 Heinrich", "Lukas Rauch", "Bernhard Sick", "Christoph Scholz"], "title": "Adversarial Training Improves Generalization Under Distribution Shifts in Bioacoustics", "categories": ["cs.LG"], "comment": "Work in progress", "summary": "Adversarial training is a promising strategy for enhancing model robustness\nagainst adversarial attacks. However, its impact on generalization under\nsubstantial data distribution shifts in audio classification remains largely\nunexplored. To address this gap, this work investigates how different\nadversarial training strategies improve generalization performance and\nadversarial robustness in audio classification. The study focuses on two model\narchitectures: a conventional convolutional neural network (ConvNeXt) and an\ninherently interpretable prototype-based model (AudioProtoPNet). The approach\nis evaluated using a challenging bird sound classification benchmark. This\nbenchmark is characterized by pronounced distribution shifts between training\nand test data due to varying environmental conditions and recording methods, a\ncommon real-world challenge. The investigation explores two adversarial\ntraining strategies: one based on output-space attacks that maximize the\nclassification loss function, and another based on embedding-space attacks\ndesigned to maximize embedding dissimilarity. These attack types are also used\nfor robustness evaluation. Additionally, for AudioProtoPNet, the study assesses\nthe stability of its learned prototypes under targeted embedding-space attacks.\nResults show that adversarial training, particularly using output-space\nattacks, improves clean test data performance by an average of 10.5% relative\nand simultaneously strengthens the adversarial robustness of the models. These\nfindings, although derived from the bird sound domain, suggest that adversarial\ntraining holds potential to enhance robustness against both strong distribution\nshifts and adversarial attacks in challenging audio classification settings.", "AI": {"tldr": "This work explores how adversarial training improves robustness and generalization in audio classification under distribution shifts.", "motivation": "To investigate the unexplored impact of adversarial training on generalization performance in audio classification with substantial data distribution shifts.", "method": "The study evaluates two adversarial training strategies\u2014output-space attacks and embedding-space attacks\u2014on ConvNeXt and AudioProtoPNet using a bird sound classification benchmark.", "result": "Adversarial training, especially using output-space attacks, improved clean test data performance by 10.5% on average and enhanced adversarial robustness.", "conclusion": "Adversarial training can effectively improve model robustness against both distribution shifts and adversarial attacks in challenging audio classification tasks."}}
{"id": "2507.13370", "pdf": "https://arxiv.org/pdf/2507.13370", "abs": "https://arxiv.org/abs/2507.13370", "authors": ["Shijun Guo", "Haoran Xu", "Yaming Yang", "Ziyu Guan", "Wei Zhao", "Xinyi Zhang", "Yishan Song", "Jiwei Chen"], "title": "H-NeiFi: Non-Invasive and Consensus-Efficient Multi-Agent Opinion Guidance", "categories": ["cs.SI", "cs.AI", "cs.MA"], "comment": null, "summary": "The openness of social media enables the free exchange of opinions, but it\nalso presents challenges in guiding opinion evolution towards global consensus.\nExisting methods often directly modify user views or enforce cross-group\nconnections. These intrusive interventions undermine user autonomy, provoke\npsychological resistance, and reduce the efficiency of global consensus.\nAdditionally, due to the lack of a long-term perspective, promoting local\nconsensus often exacerbates divisions at the macro level. To address these\nissues, we propose the hierarchical, non-intrusive opinion guidance framework,\nH-NeiFi. It first establishes a two-layer dynamic model based on social roles,\nconsidering the behavioral characteristics of both experts and non-experts.\nAdditionally, we introduce a non-intrusive neighbor filtering method that\nadaptively controls user communication channels. Using multi-agent\nreinforcement learning (MARL), we optimize information propagation paths\nthrough a long-term reward function, avoiding direct interference with user\ninteractions. Experiments show that H-NeiFi increases consensus speed by 22.0%\nto 30.7% and maintains global convergence even in the absence of experts. This\napproach enables natural and efficient consensus guidance by protecting user\ninteraction autonomy, offering a new paradigm for social network governance.", "AI": {"tldr": "The paper introduces H-NeiFi, a non-intrusive framework leveraging hierarchical modeling and multi-agent reinforcement learning to promote quicker and more efficient consensus formation in social media while preserving user autonomy.", "motivation": "Existing methods for social media opinion guidance face challenges such as provoking psychological resistance and aggravating divisions at the macro level due to their intrusive nature.", "method": "The paper developed a hierarchical model based on social roles, employed neighbor filtering for adaptive user communication control, and optimized information propagation paths using multi-agent reinforcement learning.", "result": "Experiments demonstrated that H-NeiFi improves consensus speed by 22.0% to 30.7% and achieves global convergence even without expert involvement.", "conclusion": "H-NeiFi offers a non-intrusive and autonomous solution for social network governance by efficiently guiding opinion evolution without direct interference, representing a transformative paradigm."}}
{"id": "2507.13875", "pdf": "https://arxiv.org/pdf/2507.13875", "abs": "https://arxiv.org/abs/2507.13875", "authors": ["Carlos Mena", "Pol Serra", "Jacobo Romero", "Abir Messaoudi", "Jose Giraldo", "Carme Armentano-Oller", "Rodolfo Zevallos", "Ivan Meza", "Javier Hernando"], "title": "Optimizing ASR for Catalan-Spanish Code-Switching: A Comparative Analysis of Methodologies", "categories": ["cs.CL", "eess.AS"], "comment": "Accepted at Interspeech 2025", "summary": "Code-switching (CS), the alternating use of two or more languages, challenges\nautomatic speech recognition (ASR) due to scarce training data and linguistic\nsimilarities. The lack of dedicated CS datasets limits ASR performance, as most\nmodels rely on monolingual or mixed-language corpora that fail to reflect\nreal-world CS patterns. This issue is critical in multilingual societies where\nCS occurs in informal and formal settings. A key example is Catalan-Spanish CS,\nwidely used in media and parliamentary speeches. In this work, we improve ASR\nfor Catalan-Spanish CS by exploring three strategies: (1) generating synthetic\nCS data, (2) concatenating monolingual audio, and (3) leveraging real CS data\nwith language tokens. We extract CS data from Catalan speech corpora and\nfine-tune OpenAI's Whisper models, making them available on Hugging Face.\nResults show that combining a modest amount of synthetic CS data with the\ndominant language token yields the best transcription performance.", "AI": {"tldr": "The paper addresses challenges in automatic speech recognition (ASR) for Catalan-Spanish code-switching (CS) by proposing methods to improve performance using synthetic and real CS data.", "motivation": "The authors seek to address the lack of dedicated code-switching datasets, which limits ASR performance in multilingual societies, especially for Catalan-Spanish CS widely used in various settings.", "method": "Three methods were explored: generating synthetic CS data, concatenating monolingual audio, and leveraging real CS data with language tokens. Whisper models were fine-tuned using these datasets.", "result": "The study found that combining synthetic CS data with the dominant language token produced the best transcription performance.", "conclusion": "Fine-tuning Whisper models using both synthetic and real CS strategies enhances ASR performance, offering practical solutions for Catalan-Spanish language transcription."}}
{"id": "2507.13595", "pdf": "https://arxiv.org/pdf/2507.13595", "abs": "https://arxiv.org/abs/2507.13595", "authors": ["Tengkai Wang", "Weihao Li", "Ruikai Cui", "Shi Qiu", "Nick Barnes"], "title": "NoiseSDF2NoiseSDF: Learning Clean Neural Fields from Noisy Supervision", "categories": ["cs.CV"], "comment": "14 pages, 4 figures", "summary": "Reconstructing accurate implicit surface representations from point clouds\nremains a challenging task, particularly when data is captured using\nlow-quality scanning devices. These point clouds often contain substantial\nnoise, leading to inaccurate surface reconstructions. Inspired by the\nNoise2Noise paradigm for 2D images, we introduce NoiseSDF2NoiseSDF, a novel\nmethod designed to extend this concept to 3D neural fields. Our approach\nenables learning clean neural SDFs directly from noisy point clouds through\nnoisy supervision by minimizing the MSE loss between noisy SDF representations,\nallowing the network to implicitly denoise and refine surface estimations. We\nevaluate the effectiveness of NoiseSDF2NoiseSDF on benchmarks, including the\nShapeNet, ABC, Famous, and Real datasets. Experimental results demonstrate that\nour framework significantly improves surface reconstruction quality from noisy\ninputs.", "AI": {"tldr": "The paper proposes NoiseSDF2NoiseSDF, a technique leveraging the Noise2Noise paradigm to reconstruct clean neural SDFs from noisy point clouds, significantly improving surface reconstruction.", "motivation": "Accurately reconstructing implicit surfaces from noisy point clouds collected with low-quality scanners remains a challenging task, requiring methods to handle substantial noise.", "method": "The approach introduces NoiseSDF2NoiseSDF, which applies the Noise2Noise framework to 3D neural fields. It minimizes MSE loss between noisy SDFs to denoise and refine the surface reconstruction.", "result": "The method outperformed on several benchmarks like ShapeNet, ABC, Famous, and Real datasets, showcasing its effectiveness in improving surface reconstruction quality from noisy data.", "conclusion": "NoiseSDF2NoiseSDF effectively denoises SDF representations, showcasing a practical solution for achieving accurate reconstructions from noisy point cloud data."}}
{"id": "2507.13881", "pdf": "https://arxiv.org/pdf/2507.13881", "abs": "https://arxiv.org/abs/2507.13881", "authors": ["Cole Walsh", "Rodica Ivan", "Muhammad Zafar Iqbal", "Colleen Robb"], "title": "Using LLMs to identify features of personal and professional skills in an open-response situational judgment test", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "10 pages, 2 figures, 4 tables; this work was accepted for\n  presentation at the 2025 Artificial Intelligence in Measurement and Education\n  Conference in Pittsburgh, Pennsylvania, United States", "summary": "Academic programs are increasingly recognizing the importance of personal and\nprofessional skills and their critical role alongside technical expertise in\npreparing students for future success in diverse career paths. With this\ngrowing demand comes the need for scalable systems to measure, evaluate, and\ndevelop these skills. Situational Judgment Tests (SJTs) offer one potential\navenue for measuring these skills in a standardized and reliable way, but\nopen-response SJTs have traditionally relied on trained human raters for\nevaluation, presenting operational challenges to delivering SJTs at scale. Past\nattempts at developing NLP-based scoring systems for SJTs have fallen short due\nto issues with construct validity of these systems. In this article, we explore\na novel approach to extracting construct-relevant features from SJT responses\nusing large language models (LLMs). We use the Casper SJT to demonstrate the\nefficacy of this approach. This study sets the foundation for future\ndevelopments in automated scoring for personal and professional skills.", "AI": {"tldr": "The paper introduces a novel method using large language models (LLMs) for analyzing and scoring open-response Situational Judgment Tests (SJTs), aiming to automate and scale evaluation of personal and professional skills.", "motivation": "Academic institutions need scalable systems to measure personal and professional skills, as trained human raters for SJTs pose operational challenges.", "method": "The authors utilize large language models (LLMs) to extract construct-relevant features from SJT responses, applying this approach to the Casper SJT as a demonstration.", "result": "The study demonstrates the efficacy of LLMs in improving automated scoring while addressing issues of construct validity.", "conclusion": "The paper establishes a groundwork for next-generation automated systems in assessing personal and professional skills through scalable and valid metrics."}}
{"id": "2507.13599", "pdf": "https://arxiv.org/pdf/2507.13599", "abs": "https://arxiv.org/abs/2507.13599", "authors": ["Chengxu Liu", "Lu Qi", "Jinshan Pan", "Xueming Qian", "Ming-Hsuan Yang"], "title": "Learning Deblurring Texture Prior from Unpaired Data with Diffusion Model", "categories": ["cs.CV"], "comment": "Accepted by ICCV2025", "summary": "Since acquiring large amounts of realistic blurry-sharp image pairs is\ndifficult and expensive, learning blind image deblurring from unpaired data is\na more practical and promising solution. Unfortunately, dominant approaches\nrely heavily on adversarial learning to bridge the gap from blurry domains to\nsharp domains, ignoring the complex and unpredictable nature of real-world blur\npatterns. In this paper, we propose a novel diffusion model (DM)-based\nframework, dubbed \\ours, for image deblurring by learning spatially varying\ntexture prior from unpaired data. In particular, \\ours performs DM to generate\nthe prior knowledge that aids in recovering the textures of blurry images. To\nimplement this, we propose a Texture Prior Encoder (TPE) that introduces a\nmemory mechanism to represent the image textures and provides supervision for\nDM training. To fully exploit the generated texture priors, we present the\nTexture Transfer Transformer layer (TTformer), in which a novel\nFilter-Modulated Multi-head Self-Attention (FM-MSA) efficiently removes\nspatially varying blurring through adaptive filtering. Furthermore, we\nimplement a wavelet-based adversarial loss to preserve high-frequency texture\ndetails. Extensive evaluations show that \\ours provides a promising\nunsupervised deblurring solution and outperforms SOTA methods in widely-used\nbenchmarks.", "AI": {"tldr": "The paper introduces a novel diffusion model-based framework for unsupervised image deblurring using spatially varying texture priors, outperforming state-of-the-art methods.", "motivation": "The difficulty of acquiring paired blurry-sharp images for training motivates the need for a practical deblurring solution using unpaired data, particularly for handling real-world complex blur patterns.", "method": "The authors propose a diffusion model framework incorporating a Texture Prior Encoder for supervised texture recovery, a Texture Transfer Transformer for adaptive blurring removal, and a wavelet-based adversarial loss for preserving high-frequency textures.", "result": "Their method demonstrates superior performance compared to state-of-the-art techniques on widely-used benchmarks, effectively recovering textures and handling temporal blurs.", "conclusion": "The presented framework offers an effective unsupervised solution to image deblurring, leveraging texture priors and novel network components to outperform existing methods in terms of performance and texture preservation."}}
{"id": "2507.13741", "pdf": "https://arxiv.org/pdf/2507.13741", "abs": "https://arxiv.org/abs/2507.13741", "authors": ["Shangyou Wang", "Zezhong Ding", "Xike Xie"], "title": "SamGoG: A Sampling-Based Graph-of-Graphs Framework for Imbalanced Graph Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) have shown remarkable success in graph\nclassification tasks by capturing both structural and feature-based\nrepresentations. However, real-world graphs often exhibit two critical forms of\nimbalance: class imbalance and graph size imbalance. These imbalances can bias\nthe learning process and degrade model performance. Existing methods typically\naddress only one type of imbalance or incur high computational costs. In this\nwork, we propose SamGoG, a sampling-based Graph-of-Graphs (GoG) learning\nframework that effectively mitigates both class and graph size imbalance.\nSamGoG constructs multiple GoGs through an efficient importance-based sampling\nmechanism and trains on them sequentially. This sampling mechanism incorporates\nthe learnable pairwise similarity and adaptive GoG node degree to enhance edge\nhomophily, thus improving downstream model quality. SamGoG can seamlessly\nintegrate with various downstream GNNs, enabling their efficient adaptation for\ngraph classification tasks. Extensive experiments on benchmark datasets\ndemonstrate that SamGoG achieves state-of-the-art performance with up to a\n15.66% accuracy improvement with 6.7$\\times$ training acceleration.", "AI": {"tldr": "This paper introduces SamGoG, a framework addressing class and graph size imbalances in graph classification using efficient sampling-based Graph-of-Graphs learning.", "motivation": "To address the limitations in graph classification caused by class imbalance and graph size imbalance in real-world applications, which negatively impact learning and model performance.", "method": "The authors propose SamGoG, which employs an importance-based sampling mechanism to construct multiple Graph-of-Graphs (GoGs) and train them sequentially. The sampling enhances edge homophily by incorporating learnable pairwise similarity and adaptive node degree.", "result": "SamGoG yields a significant performance boost, achieving up to a 15.66% improvement in accuracy and 6.7x acceleration in training compared to existing methods.", "conclusion": "SamGoG effectively addresses imbalance issues in graph classification tasks and integrates seamlessly with various downstream GNNs, demonstrating superior performance on benchmark datasets."}}
{"id": "2507.13913", "pdf": "https://arxiv.org/pdf/2507.13913", "abs": "https://arxiv.org/abs/2507.13913", "authors": ["Matous Volf", "Jakub Simko"], "title": "Political Leaning and Politicalness Classification of Texts", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This paper addresses the challenge of automatically classifying text\naccording to political leaning and politicalness using transformer models. We\ncompose a comprehensive overview of existing datasets and models for these\ntasks, finding that current approaches create siloed solutions that perform\npoorly on out-of-distribution texts. To address this limitation, we compile a\ndiverse dataset by combining 12 datasets for political leaning classification\nand creating a new dataset for politicalness by extending 18 existing datasets\nwith the appropriate label. Through extensive benchmarking with leave-one-in\nand leave-one-out methodologies, we evaluate the performance of existing models\nand train new ones with enhanced generalization capabilities.", "AI": {"tldr": "The paper explores text classification by political leaning and 'politicalness' using transformer models, addressing limitations in current siloed approaches by creating a more diverse dataset and improved benchmarking methods.", "motivation": "Current transformer models struggle with out-of-distribution text in political leaning classification due to siloed and isolated datasets and approaches.", "method": "The authors combined 12 datasets for political leaning classification, created a new dataset for 'politicalness,' and benchmarked model performance using leave-one-in and leave-one-out validation techniques.", "result": "New models were trained, outperforming current approaches with improved generalization capabilities.", "conclusion": "The paper contributes by providing a comprehensive dataset and evaluation techniques to enhance out-of-distribution performance for political text classification tasks."}}
{"id": "2507.13607", "pdf": "https://arxiv.org/pdf/2507.13607", "abs": "https://arxiv.org/abs/2507.13607", "authors": ["Kento Kawai", "Takeru Oba", "Kyotaro Tokoro", "Kazutoshi Akita", "Norimichi Ukita"], "title": "Efficient Burst Super-Resolution with One-step Diffusion", "categories": ["cs.CV"], "comment": "NTIRE2025", "summary": "While burst Low-Resolution (LR) images are useful for improving their Super\nResolution (SR) image compared to a single LR image, prior burst SR methods are\ntrained in a deterministic manner, which produces a blurry SR image. Since such\nblurry images are perceptually degraded, we aim to reconstruct sharp and\nhigh-fidelity SR images by a diffusion model. Our method improves the\nefficiency of the diffusion model with a stochastic sampler with a high-order\nODE as well as one-step diffusion using knowledge distillation. Our\nexperimental results demonstrate that our method can reduce the runtime to 1.6\n% of its baseline while maintaining the SR quality measured based on image\ndistortion and perceptual quality.", "AI": {"tldr": "The paper addresses blurry outputs in burst super-resolution images by using an enhanced diffusion model, improving sharpness and fidelity while significantly reducing computational time.", "motivation": "Previous methods for burst super-resolution often yield blurry images, which are perceptually inferior, motivating the need for sharp and high-fidelity SR reconstructions.", "method": "The approach uses a diffusion model improved with a stochastic sampler employing a high-order ODE and implements one-step diffusion using knowledge distillation.", "result": "Their method achieves runtime reduced to 1.6% of the baseline while preserving both image distortion and perceptual quality in the super-resolution outputs.", "conclusion": "The proposed technique enhances efficiency and effectiveness in burst super-resolution using diffusion models, delivering clear, high-quality images faster than existing methods."}}
{"id": "2507.13742", "pdf": "https://arxiv.org/pdf/2507.13742", "abs": "https://arxiv.org/abs/2507.13742", "authors": ["Oussama Bouaggad", "Natalia Grabar"], "title": "Search-Optimized Quantization in Biomedical Ontology Alignment", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "In the fast-moving world of AI, as organizations and researchers develop more\nadvanced models, they face challenges due to their sheer size and computational\ndemands. Deploying such models on edge devices or in resource-constrained\nenvironments adds further challenges related to energy consumption, memory\nusage and latency. To address these challenges, emerging trends are shaping the\nfuture of efficient model optimization techniques. From this premise, by\nemploying supervised state-of-the-art transformer-based models, this research\nintroduces a systematic method for ontology alignment, grounded in cosine-based\nsemantic similarity between a biomedical layman vocabulary and the Unified\nMedical Language System (UMLS) Metathesaurus. It leverages Microsoft Olive to\nsearch for target optimizations among different Execution Providers (EPs) using\nthe ONNX Runtime backend, followed by an assembled process of dynamic\nquantization employing Intel Neural Compressor and IPEX (Intel Extension for\nPyTorch). Through our optimization process, we conduct extensive assessments on\nthe two tasks from the DEFT 2020 Evaluation Campaign, achieving a new\nstate-of-the-art in both. We retain performance metrics intact, while attaining\nan average inference speed-up of 20x and reducing memory usage by approximately\n70%.", "AI": {"tldr": "This paper addresses the challenges of deploying AI models in resource-constrained environments by introducing optimization techniques using transformer-based models and multiple optimization tools, achieving significant speed and memory improvements.", "motivation": "The work aims to optimize large AI models for deployment on edge devices and resource-constrained environments, addressing issues like energy consumption, memory usage, and latency.", "method": "The researchers use supervised transformer-based models for ontology alignment, employ the ONNX Runtime backend with Microsoft Olive for optimization, and apply dynamic quantization using Intel Neural Compressor and Intel Extension for PyTorch.", "result": "Experiments on DEFT 2020 tasks showed a 20x inference speed-up and approximately 70% memory usage reduction, all while retaining performance metrics.", "conclusion": "The proposed optimization techniques effectively improve model efficiency, make them deployable in limited-resource environments, and set a new state-of-the-art in performance for the chosen tasks."}}
{"id": "2507.13919", "pdf": "https://arxiv.org/pdf/2507.13919", "abs": "https://arxiv.org/abs/2507.13919", "authors": ["Kobi Hackenburg", "Ben M. Tappin", "Luke Hewitt", "Ed Saunders", "Sid Black", "Hause Lin", "Catherine Fist", "Helen Margetts", "David G. Rand", "Christopher Summerfield"], "title": "The Levers of Political Persuasion with Conversational AI", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "comment": "19 pages, 4 figures. Our supplementary materials file can be found at\n  https://github.com/kobihackenburg/scaling-conversational-AI", "summary": "There are widespread fears that conversational AI could soon exert\nunprecedented influence over human beliefs. Here, in three large-scale\nexperiments (N=76,977), we deployed 19 LLMs-including some post-trained\nexplicitly for persuasion-to evaluate their persuasiveness on 707 political\nissues. We then checked the factual accuracy of 466,769 resulting LLM claims.\nContrary to popular concerns, we show that the persuasive power of current and\nnear-future AI is likely to stem more from post-training and prompting\nmethods-which boosted persuasiveness by as much as 51% and 27%\nrespectively-than from personalization or increasing model scale. We further\nshow that these methods increased persuasion by exploiting LLMs' unique ability\nto rapidly access and strategically deploy information and that, strikingly,\nwhere they increased AI persuasiveness they also systematically decreased\nfactual accuracy.", "AI": {"tldr": "The study explores the persuasive power of 19 LLMs across political issues and finds that post-training and prompting methods significantly enhance persuasiveness while diminishing factual accuracy.", "motivation": "Concerns about conversational AI's influence on human beliefs and its potential to manipulate opinions in the political domain prompted the study.", "method": "Three large-scale experiments involving 19 LLMs, assessing their persuasiveness on 707 political issues and verifying the factual accuracy of 466,769 claims.", "result": "Post-training increased persuasiveness by up to 51%, and prompting methods by 27%. However, these strategies decreased the factual accuracy of AI-generated claims.", "conclusion": "The persuasive capabilities of current and near-future conversational AI are contingent on specific training and prompting methods, making them more influential but less reliable in factual correctness."}}
{"id": "2507.13609", "pdf": "https://arxiv.org/pdf/2507.13609", "abs": "https://arxiv.org/abs/2507.13609", "authors": ["Yanan Wang", "Julio Vizcarra", "Zhi Li", "Hao Niu", "Mori Kurokawa"], "title": "CoTasks: Chain-of-Thought based Video Instruction Tuning Tasks", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Despite recent progress in video large language models (VideoLLMs), a key\nopen challenge remains: how to equip models with chain-of-thought (CoT)\nreasoning abilities grounded in fine-grained object-level video understanding.\nExisting instruction-tuned models, such as the Qwen and LLaVA series, are\ntrained on high-level video-text pairs, often lacking structured annotations\nnecessary for compositional, step-by-step reasoning. We propose CoTasks:\nChain-of-Thought based Video Instruction Tuning Tasks, a new framework that\ndecomposes complex video questions of existing datasets (e.g., NeXT-QA, STAR)\ninto four entity-level foundational tasks: frame localization, entity tracking,\nspatial and temporal relation extraction. By embedding these intermediate\nCoT-style reasoning steps into the input, CoTasks enables models to explicitly\nperform object-centric spatiotemporal reasoning. Experiments on the NeXT-QA\nbenchmark show that CoTasks significantly enhance inference performance:\nLLaVA-video-7B improves by +3.3 points in average GPT-4 evaluation score, and\nQwen2.5-VL-3B gains +17.4, with large boosts in causal (+14.6), temporal\n(+10.9), and descriptive (+48.1) subcategories. These results demonstrate the\neffectiveness of CoTasks as a structured CoT-style supervision framework for\nimproving compositional video reasoning.", "AI": {"tldr": "This paper introduces CoTasks, a framework for improving video large language models (VideoLLMs) by embedding structured chain-of-thought reasoning tasks in the input.", "motivation": "To address the need for fine-grained object-level video understanding and chain-of-thought reasoning in VideoLLMs, beyond high-level video-text pairs.", "method": "CoTasks decomposes complex video questions into four foundational tasks\u2014frame localization, entity tracking, and spatial/temporal relation extraction\u2014and embeds these reasoning steps into the input.", "result": "Using CoTasks, models like LLaVA-video-7B and Qwen2.5-VL-3B experience significant improvements on the NeXT-QA benchmark across various reasoning categories.", "conclusion": "CoTasks is an effective structured supervision framework for enhancing compositional video reasoning abilities in VideoLLMs."}}
{"id": "2507.13762", "pdf": "https://arxiv.org/pdf/2507.13762", "abs": "https://arxiv.org/abs/2507.13762", "authors": ["Yaowei Jin", "Junjie Wang", "Wenkai Xiang", "Duanhua Cao", "Dan Teng", "Zhehuan Fan", "Jiacheng Xiong", "Xia Sheng", "Chuanlong Zeng", "Mingyue Zheng", "Qian Shi"], "title": "MolPIF: A Parameter Interpolation Flow Model for Molecule Generation", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Advances in deep learning for molecular generation show promise in\naccelerating drug discovery. Bayesian Flow Networks (BFNs) have recently shown\nimpressive performance across diverse chemical tasks, with their success often\nascribed to the paradigm of modeling in a low-variance parameter space.\nHowever, the Bayesian inference-based strategy imposes limitations on designing\nmore flexible distribution transformation pathways, making it challenging to\nadapt to diverse data distributions and varied task requirements. Furthermore,\nthe potential for simpler, more efficient parameter-space-based models is\nunexplored. To address this, we propose a novel Parameter Interpolation Flow\nmodel (named PIF) with detailed theoretical foundation, training, and inference\nprocedures. We then develop MolPIF for structure-based drug design,\ndemonstrating its superior performance across diverse metrics compared to\nbaselines. This work validates the effectiveness of parameter-space-based\ngenerative modeling paradigm for molecules and offers new perspectives for\nmodel design.", "AI": {"tldr": "The paper introduces MolPIF, a novel parameter-space-based molecular generative model for drug design that outperforms existing methods in diverse metrics.", "motivation": "Bayesian Flow Networks face constraints in designing flexible distribution transformation pathways and adapting to diverse data distributions, necessitating exploration of simpler and efficient parameter-space-based models.", "method": "The authors introduce Parameter Interpolation Flow (PIF), with a detailed theoretical foundation, training, and inference procedures, and specifically adapt it as MolPIF for drug design tasks.", "result": "MolPIF demonstrates superior performance in structure-based drug design across diverse metrics, surpassing baseline methods.", "conclusion": "The study establishes the effectiveness of parameter-space-driven models like MolPIF, providing novel directions in molecular generative model design for drug discovery."}}
{"id": "2507.13937", "pdf": "https://arxiv.org/pdf/2507.13937", "abs": "https://arxiv.org/abs/2507.13937", "authors": ["Jan Trienes", "Anastasiia Derzhanskaia", "Roland Schwarzkopf", "Markus M\u00fchling", "J\u00f6rg Schl\u00f6tterer", "Christin Seifert"], "title": "Marcel: A Lightweight and Open-Source Conversational Agent for University Student Support", "categories": ["cs.CL"], "comment": null, "summary": "We present Marcel, a lightweight and open-source conversational agent\ndesigned to support prospective students with admission-related inquiries. The\nsystem aims to provide fast and personalized responses, while reducing workload\nof university staff. We employ retrieval-augmented generation to ground answers\nin university resources and to provide users with verifiable, contextually\nrelevant information. To improve retrieval quality, we introduce an FAQ\nretriever that maps user questions to knowledge-base entries, allowing\nadministrators to steer retrieval, and improving over standard dense/hybrid\nretrieval strategies. The system is engineered for easy deployment in\nresource-constrained academic settings. We detail the system architecture,\nprovide a technical evaluation of its components, and report insights from a\nreal-world deployment.", "AI": {"tldr": "Marcel is an open-source conversational agent designed to help prospective university students with admission inquiries. It uses retrieval-augmented generation to provide precise and contextually relevant information.", "motivation": "The paper aims to address the challenge faced by universities in efficiently handling admission-related inquiries while reducing the workload of administrative staff.", "method": "Marcel combines retrieval-augmented generation with an advanced FAQ retriever that maps user questions to entries in a knowledge base, allowing administrators to refine and improve retrieval quality over traditional methods.", "result": "The system demonstrated improved performance in handling admission queries compared to dense and hybrid retrieval methods, making it suitable for deployment in resource-constrained academic environments.", "conclusion": "Marcel effectively provides fast, personalized, and verifiable admission-related information, proving its value in real-world scenarios and simplifying deployment in universities."}}
{"id": "2507.13628", "pdf": "https://arxiv.org/pdf/2507.13628", "abs": "https://arxiv.org/abs/2507.13628", "authors": ["Masahiro Ogawa", "Qi An", "Atsushi Yamashita"], "title": "Moving Object Detection from Moving Camera Using Focus of Expansion Likelihood and Segmentation", "categories": ["cs.CV"], "comment": "8 pages, 15 figures, RA-L submission", "summary": "Separating moving and static objects from a moving camera viewpoint is\nessential for 3D reconstruction, autonomous navigation, and scene understanding\nin robotics. Existing approaches often rely primarily on optical flow, which\nstruggles to detect moving objects in complex, structured scenes involving\ncamera motion. To address this limitation, we propose Focus of Expansion\nLikelihood and Segmentation (FoELS), a method based on the core idea of\nintegrating both optical flow and texture information. FoELS computes the focus\nof expansion (FoE) from optical flow and derives an initial motion likelihood\nfrom the outliers of the FoE computation. This likelihood is then fused with a\nsegmentation-based prior to estimate the final moving probability. The method\neffectively handles challenges including complex structured scenes, rotational\ncamera motion, and parallel motion. Comprehensive evaluations on the DAVIS 2016\ndataset and real-world traffic videos demonstrate its effectiveness and\nstate-of-the-art performance.", "AI": {"tldr": "The paper addresses the separation of moving and static objects from a moving camera using a novel method called FoELS, which integrates optical flow and texture information for improved accuracy.", "motivation": "The need to accurately discern moving objects in dynamic environments for applications such as 3D reconstruction, autonomous navigation, and robotics due to limitations in traditional optical flow approaches.", "method": "The proposed FoELS method computes the focus of expansion from optical flow, derives motion likelihood from outliers, and combines this with segmentation-based priors to estimate the moving probability.", "result": "FoELS effectively handles complex scenarios, achieving state-of-the-art performance as validated on both DAVIS 2016 dataset and real-world traffic datasets.", "conclusion": "By integrating optical flow with texture-based analysis, FoELS provides an efficient solution to the challenges of detecting moving objects in structured and dynamic scenes."}}
{"id": "2507.13765", "pdf": "https://arxiv.org/pdf/2507.13765", "abs": "https://arxiv.org/abs/2507.13765", "authors": ["Enhao Cheng", "Shoujia Zhang", "Jianhua Yin", "Li Jin", "Liqiang Nie"], "title": "Dual-Center Graph Clustering with Neighbor Distribution", "categories": ["cs.LG"], "comment": "ECAI-2025", "summary": "Graph clustering is crucial for unraveling intricate data structures, yet it\npresents significant challenges due to its unsupervised nature. Recently,\ngoal-directed clustering techniques have yielded impressive results, with\ncontrastive learning methods leveraging pseudo-label garnering considerable\nattention. Nonetheless, pseudo-label as a supervision signal is unreliable and\nexisting goal-directed approaches utilize only features to construct a\nsingle-target distribution for single-center optimization, which lead to\nincomplete and less dependable guidance. In our work, we propose a novel\nDual-Center Graph Clustering (DCGC) approach based on neighbor distribution\nproperties, which includes representation learning with neighbor distribution\nand dual-center optimization. Specifically, we utilize neighbor distribution as\na supervision signal to mine hard negative samples in contrastive learning,\nwhich is reliable and enhances the effectiveness of representation learning.\nFurthermore, neighbor distribution center is introduced alongside feature\ncenter to jointly construct a dual-target distribution for dual-center\noptimization. Extensive experiments and analysis demonstrate superior\nperformance and effectiveness of our proposed method.", "AI": {"tldr": "The paper presents a Dual-Center Graph Clustering (DCGC) method that leverages neighbor distribution and dual-center optimization for more effective graph clustering.", "motivation": "Graph clustering is challenging due to its unsupervised nature and limitations of pseudo-label-based methods that rely on single-target distributions.", "method": "The proposed DCGC involves representation learning using neighbor distribution and integrates dual-target distribution with dual-center optimization, which includes both feature and neighbor distribution centers.", "result": "Experiments highlight improved performance and robustness of the proposed DCGC technique compared to existing methods.", "conclusion": "The DCGC method provides reliable supervision signals and enhanced clustering capabilities, establishing it as an effective approach for graph clustering tasks."}}
{"id": "2507.13949", "pdf": "https://arxiv.org/pdf/2507.13949", "abs": "https://arxiv.org/abs/2507.13949", "authors": ["Bianca Raimondi", "Maurizio Gabbrielli"], "title": "Exploiting Primacy Effect To Improve Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by RANLP 2025", "summary": "Large Language Models (LLMs) have become essential in many Natural Language\nProcessing (NLP) tasks, leveraging extensive pre-training and fine-tuning to\nachieve high accuracy. However, like humans, LLMs exhibit biases, particularly\npositional biases such as primacy and recency effects, which can influence the\naccuracy of the answers. The primacy effect-where items presented first are\nmore likely to be remembered or selected-plays a key role in Multiple Choice\nQuestion Answering (MCQA), where the order of answer options can affect\nprediction outcomes. This study focuses on primacy bias in fine-tuned LLMs: We\nfirst show that fine-tuning amplifies this bias, probably due to exposure to\nhuman-like patterns. Hence, we strategically leverage this effect by reordering\nresponse options based on semantic similarity to the query, without requiring\nknowledge of the correct answer. Our experimental results show that this\napproach significantly improves performance in MCQA. More generally, our\nfindings underscore the dual nature of biases as both challenges and\nopportunities, offering insights for bias-aware model design and NLP\napplications.", "AI": {"tldr": "The study explores how fine-tuned LLMs exhibit primacy bias in Multiple Choice Question Answering (MCQA) and proposes a method to turn this bias into a performance improvement.", "motivation": "Investigate the role of positional biases, like primacy effect, in fine-tuned Large Language Models (LLMs) and their impact on tasks like Multiple Choice Question Answering (MCQA).", "method": "Analyzed how fine-tuning affects primacy bias in LLMs and introduced a response-reordering technique based on semantic similarity to the query, without using the correct answer.", "result": "Experimentally demonstrated that reordering answer options leveraging primacy bias significantly enhances MCQA performance.", "conclusion": "Biases in LLMs, such as primacy bias, can be approached as both challenges and opportunities. The study offers meaningful insights for bias-aware NLP model design and applications."}}
{"id": "2507.13648", "pdf": "https://arxiv.org/pdf/2507.13648", "abs": "https://arxiv.org/abs/2507.13648", "authors": ["Seungjun Moon", "Sangjoon Yu", "Gyeong-Moon Park"], "title": "EPSilon: Efficient Point Sampling for Lightening of Hybrid-based 3D Avatar Generation", "categories": ["cs.CV"], "comment": null, "summary": "The rapid advancement of neural radiance fields (NeRF) has paved the way to\ngenerate animatable human avatars from a monocular video. However, the sole\nusage of NeRF suffers from a lack of details, which results in the emergence of\nhybrid representation that utilizes SMPL-based mesh together with NeRF\nrepresentation. While hybrid-based models show photo-realistic human avatar\ngeneration qualities, they suffer from extremely slow inference due to their\ndeformation scheme: to be aligned with the mesh, hybrid-based models use the\ndeformation based on SMPL skinning weights, which needs high computational\ncosts on each sampled point. We observe that since most of the sampled points\nare located in empty space, they do not affect the generation quality but\nresult in inference latency with deformation. In light of this observation, we\npropose EPSilon, a hybrid-based 3D avatar generation scheme with novel\nefficient point sampling strategies that boost both training and inference. In\nEPSilon, we propose two methods to omit empty points at rendering; empty ray\nomission (ERO) and empty interval omission (EIO). In ERO, we wipe out rays that\nprogress through the empty space. Then, EIO narrows down the sampling interval\non the ray, which wipes out the region not occupied by either clothes or mesh.\nThe delicate sampling scheme of EPSilon enables not only great computational\ncost reduction during deformation but also the designation of the important\nregions to be sampled, which enables a single-stage NeRF structure without\nhierarchical sampling. Compared to existing methods, EPSilon maintains the\ngeneration quality while using only 3.9% of sampled points and achieves around\n20 times faster inference, together with 4 times faster training convergence.\nWe provide video results on https://github.com/seungjun-moon/epsilon.", "AI": {"tldr": "EPSilon introduces an efficient hybrid-based 3D avatar generation method using novel point sampling strategies, improving both speed and quality.", "motivation": "To address the inefficiencies and computational costs in generating animatable human avatars with NeRF-based hybrid models.", "method": "Proposing EPSilon, which employs Empty Ray Omission (ERO) to remove unnecessary rays and Empty Interval Omission (EIO) to refine sampling intervals, reducing computational costs significantly.", "result": "EPSilon achieves high computational efficiency, maintaining quality while using only 3.9% of sampled points, with inference 20 times faster and training 4 times faster.", "conclusion": "EPSilon demonstrates that effective sampling techniques can substantially improve the speed and efficiency of human avatar generation without compromising quality."}}
{"id": "2507.13805", "pdf": "https://arxiv.org/pdf/2507.13805", "abs": "https://arxiv.org/abs/2507.13805", "authors": ["Tim Rensmeyer", "Denis Kramer", "Oliver Niggemann"], "title": "On-the-Fly Fine-Tuning of Foundational Neural Network Potentials: A Bayesian Neural Network Approach", "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Due to the computational complexity of evaluating interatomic forces from\nfirst principles, the creation of interatomic machine learning force fields has\nbecome a highly active field of research. However, the generation of training\ndatasets of sufficient size and sample diversity itself comes with a\ncomputational burden that can make this approach impractical for modeling rare\nevents or systems with a large configuration space. Fine-tuning foundation\nmodels that have been pre-trained on large-scale material or molecular\ndatabases offers a promising opportunity to reduce the amount of training data\nnecessary to reach a desired level of accuracy. However, even if this approach\nrequires less training data overall, creating a suitable training dataset can\nstill be a very challenging problem, especially for systems with rare events\nand for end-users who don't have an extensive background in machine learning.\nIn on-the-fly learning, the creation of a training dataset can be largely\nautomated by using model uncertainty during the simulation to decide if the\nmodel is accurate enough or if a structure should be recalculated with\nclassical methods and used to update the model. A key challenge for applying\nthis form of active learning to the fine-tuning of foundation models is how to\nassess the uncertainty of those models during the fine-tuning process, even\nthough most foundation models lack any form of uncertainty quantification. In\nthis paper, we overcome this challenge by introducing a fine-tuning approach\nbased on Bayesian neural network methods and a subsequent on-the-fly workflow\nthat automatically fine-tunes the model while maintaining a pre-specified\naccuracy and can detect rare events such as transition states and sample them\nat an increased rate relative to their occurrence.", "AI": {"tldr": "The paper presents a novel fine-tuning approach for interatomic force fields using Bayesian neural networks and on-the-fly learning to address the challenge of assessing uncertainty and detecting rare events.", "motivation": "The motivation stems from the computational burden of creating diverse training datasets for interatomic machine learning force fields and the difficulties for end-users without ML expertise. The study aims to tackle these issues by fine-tuning foundation models with reduced data requirements and automated on-the-fly learning.", "method": "The authors employ Bayesian neural network methods to quantify uncertainty during fine-tuning and integrate an on-the-fly workflow. This workflow automates dataset creation, ensuring desired accuracy while detecting and sampling rare events effectively.", "result": "The proposed approach successfully automates the fine-tuning process, enabling efficient training with minimal data while maintaining accuracy. Additionally, it highlights the ability to detect rare events like transition states and sample them at an enhanced rate.", "conclusion": "The study provides a significant advancement in interatomic machine learning force fields by combining uncertainty-aware fine-tuning with automated on-the-fly learning, addressing both computational and accessibility challenges in the field."}}
{"id": "2507.13966", "pdf": "https://arxiv.org/pdf/2507.13966", "abs": "https://arxiv.org/abs/2507.13966", "authors": ["Bhishma Dedhia", "Yuval Kansal", "Niraj K. Jha"], "title": "Bottom-up Domain-specific Superintelligence: A Reliable Knowledge Graph is What We Need", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Language models traditionally used for cross-domain generalization have\nrecently demonstrated task-specific reasoning. However, their top-down training\napproach on general corpora is insufficient for acquiring abstractions needed\nfor deep domain expertise. This may require a bottom-up approach that acquires\nexpertise by learning to compose simple domain concepts into more complex ones.\nA knowledge graph (KG) provides this compositional structure, where domain\nprimitives are represented as head-relation-tail edges and their paths encode\nhigher-level concepts. We present a task generation pipeline that synthesizes\ntasks directly from KG primitives, enabling models to acquire and compose them\nfor reasoning. We fine-tune language models on the resultant KG-grounded\ncurriculum to demonstrate domain-specific superintelligence. While broadly\napplicable, we validate our approach in medicine, where reliable KGs exist.\nUsing a medical KG, we curate 24,000 reasoning tasks paired with thinking\ntraces derived from diverse medical primitives. We fine-tune the QwQ-32B model\non this curriculum to obtain QwQ-Med-3 that takes a step towards medical\nsuperintelligence. We also introduce ICD-Bench, an evaluation suite to quantify\nreasoning abilities across 15 medical domains. Our experiments demonstrate that\nQwQ-Med-3 significantly outperforms state-of-the-art reasoning models on\nICD-Bench categories. Further analysis reveals that QwQ-Med-3 utilizes acquired\nprimitives to widen the performance gap on the hardest tasks of ICD-Bench.\nFinally, evaluation on medical question-answer benchmarks shows that QwQ-Med-3\ntransfers acquired expertise to enhance the base model's performance. While the\nindustry's approach to artificial general intelligence (AGI) emphasizes broad\nexpertise, we envision a future in which AGI emerges from the composable\ninteraction of efficient domain-specific superintelligent agents.", "AI": {"tldr": "This paper proposes a novel method for training language models using domain-specific bottom-up reasoning through knowledge graphs, validated in the medical domain.", "motivation": "To address the insufficient abstraction acquisition in traditional top-down training of language models for domain-specific expertise.", "method": "Developed a curriculum synthesis pipeline using a medical knowledge graph to generate 24,000 reasoning tasks and fine-tuned language models to acquire domain-specific reasoning.", "result": "Created QwQ-Med-3, a medical superintelligent model, which outperformed state-of-the-art reasoning models on ICD-Bench, showcasing enhanced reasoning and transfer capabilities.", "conclusion": "This approach highlights a paradigm shift, suggesting AGI could emerge from composable domain-specific superintelligent agents rather than broad, generalized expertise."}}
{"id": "2507.13659", "pdf": "https://arxiv.org/pdf/2507.13659", "abs": "https://arxiv.org/abs/2507.13659", "authors": ["Xiao Wang", "Qian Zhu", "Shujuan Wu", "Bo Jiang", "Shiliang Zhang", "Yaowei Wang", "Yonghong Tian", "Bin Luo"], "title": "When Person Re-Identification Meets Event Camera: A Benchmark Dataset and An Attribute-guided Re-Identification Framework", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.NE"], "comment": null, "summary": "Recent researchers have proposed using event cameras for person\nre-identification (ReID) due to their promising performance and better balance\nin terms of privacy protection, event camera-based person ReID has attracted\nsignificant attention. Currently, mainstream event-based person ReID algorithms\nprimarily focus on fusing visible light and event stream, as well as preserving\nprivacy. Although significant progress has been made, these methods are\ntypically trained and evaluated on small-scale or simulated event camera\ndatasets, making it difficult to assess their real identification performance\nand generalization ability. To address the issue of data scarcity, this paper\nintroduces a large-scale RGB-event based person ReID dataset, called EvReID.\nThe dataset contains 118,988 image pairs and covers 1200 pedestrian identities,\nwith data collected across multiple seasons, scenes, and lighting conditions.\nWe also evaluate 15 state-of-the-art person ReID algorithms, laying a solid\nfoundation for future research in terms of both data and benchmarking. Based on\nour newly constructed dataset, this paper further proposes a pedestrian\nattribute-guided contrastive learning framework to enhance feature learning for\nperson re-identification, termed TriPro-ReID. This framework not only\neffectively explores the visual features from both RGB frames and event\nstreams, but also fully utilizes pedestrian attributes as mid-level semantic\nfeatures. Extensive experiments on the EvReID dataset and MARS datasets fully\nvalidated the effectiveness of our proposed RGB-Event person ReID framework.\nThe benchmark dataset and source code will be released on\nhttps://github.com/Event-AHU/Neuromorphic_ReID", "AI": {"tldr": "The paper addresses the limitations of small-scale event camera datasets in person re-identification (ReID) by introducing a large-scale dataset called EvReID and proposing a Pedestrian Attribute-Guided Contrastive Learning framework named TriPro-ReID.", "motivation": "Current person ReID methods using event cameras lack large-scale datasets and generalization capabilities, which limits real-world application and performance evaluation.", "method": "The authors introduce EvReID, a large-scale RGB-event dataset, and propose TriPro-ReID, a learning framework that integrates RGB frames, event streams, and pedestrian attribute features to improve ReID performance.", "result": "Extensive experiments on EvReID and MARS datasets show improved ReID performance and validate the proposed framework's effectiveness.", "conclusion": "EvReID and TriPro-ReID provide a solid foundation for advancing RGB-event person ReID research by addressing data scarcity and enhancing feature learning capabilities."}}
{"id": "2507.13834", "pdf": "https://arxiv.org/pdf/2507.13834", "abs": "https://arxiv.org/abs/2507.13834", "authors": ["Aditi Anand", "Suman Banerjee", "Dildar Ali"], "title": "Scalable Submodular Policy Optimization via Pruned Submodularity Graph", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": "16 Pages", "summary": "In Reinforcement Learning (abbreviated as RL), an agent interacts with the\nenvironment via a set of possible actions, and a reward is generated from some\nunknown distribution. The task here is to find an optimal set of actions such\nthat the reward after a certain time step gets maximized. In a traditional\nsetup, the reward function in an RL Problem is considered additive. However, in\nreality, there exist many problems, including path planning, coverage control,\netc., the reward function follows the diminishing return, which can be modeled\nas a submodular function. In this paper, we study a variant of the RL Problem\nwhere the reward function is submodular, and our objective is to find an\noptimal policy such that this reward function gets maximized. We have proposed\na pruned submodularity graph-based approach that provides a provably\napproximate solution in a feasible computation time. The proposed approach has\nbeen analyzed to understand its time and space requirements as well as a\nperformance guarantee. We have experimented with a benchmark agent-environment\nsetup, which has been used for similar previous studies, and the results are\nreported. From the results, we observe that the policy obtained by our proposed\napproach leads to more reward than the baseline methods.", "AI": {"tldr": "The paper focuses on solving a Reinforcement Learning problem where the reward function follows a submodular nature, by proposing a pruned submodularity graph-based method that outperforms baseline approaches.", "motivation": "Traditional Reinforcement Learning assumes additive reward functions, but many real-world problems like path planning involve submodular reward functions, necessitating a new approach.", "method": "The authors introduce a pruned submodularity graph-based algorithm, which is designed to maximize submodular reward functions with feasible time and space complexity, providing provably approximate solutions.", "result": "The proposed method, applied to a benchmark agent-environment setup, showed improved rewards compared to baseline methods.", "conclusion": "The proposed method is effective in solving RL problems with submodular reward functions, offering better performance guarantees and practical efficiency."}}
{"id": "2507.13977", "pdf": "https://arxiv.org/pdf/2507.13977", "abs": "https://arxiv.org/abs/2507.13977", "authors": ["Lilit Grigoryan", "Nikolay Karpov", "Enas Albasiri", "Vitaly Lavrukhin", "Boris Ginsburg"], "title": "Open Automatic Speech Recognition Models for Classical and Modern Standard Arabic", "categories": ["cs.CL", "eess.AS", "I.5.1"], "comment": "Accepted to ICASSP 2025", "summary": "Despite Arabic being one of the most widely spoken languages, the development\nof Arabic Automatic Speech Recognition (ASR) systems faces significant\nchallenges due to the language's complexity, and only a limited number of\npublic Arabic ASR models exist. While much of the focus has been on Modern\nStandard Arabic (MSA), there is considerably less attention given to the\nvariations within the language. This paper introduces a universal methodology\nfor Arabic speech and text processing designed to address unique challenges of\nthe language. Using this methodology, we train two novel models based on the\nFastConformer architecture: one designed specifically for MSA and the other,\nthe first unified public model for both MSA and Classical Arabic (CA). The MSA\nmodel sets a new benchmark with state-of-the-art (SOTA) performance on related\ndatasets, while the unified model achieves SOTA accuracy with diacritics for CA\nwhile maintaining strong performance for MSA. To promote reproducibility, we\nopen-source the models and their training recipes.", "AI": {"tldr": "This paper addresses challenges in Arabic ASR by introducing two novel models based on FastConformer: one for MSA and the first unified model for MSA and CA, achieving SOTA performance, and open-sourcing them.", "motivation": "Arabic ASR faces challenges due to language complexity and lack of public models, particularly for variations like Classical Arabic.", "method": "The authors propose a universal methodology for Arabic processing and train FastConformer-based models for MSA and unified MSA-CA functionalities.", "result": "The MSA-focused model achieves SOTA performance for related datasets, while the unified model delivers top-tier diacritics-aware accuracy for CA and strong MSA results.", "conclusion": "The paper advances Arabic ASR with benchmark-setting models, providing resources for further research through open-sourcing of models and training recipes."}}
{"id": "2507.13663", "pdf": "https://arxiv.org/pdf/2507.13663", "abs": "https://arxiv.org/abs/2507.13663", "authors": ["Xingyu Jiang", "Ning Gao", "Hongkun Dou", "Xiuhui Zhang", "Xiaoqing Zhong", "Yue Deng", "Hongjue Li"], "title": "Global Modeling Matters: A Fast, Lightweight and Effective Baseline for Efficient Image Restoration", "categories": ["cs.CV"], "comment": null, "summary": "Natural image quality is often degraded by adverse weather conditions,\nsignificantly impairing the performance of downstream tasks. Image restoration\nhas emerged as a core solution to this challenge and has been widely discussed\nin the literature. Although recent transformer-based approaches have made\nremarkable progress in image restoration, their increasing system complexity\nposes significant challenges for real-time processing, particularly in\nreal-world deployment scenarios. To this end, most existing methods attempt to\nsimplify the self-attention mechanism, such as by channel self-attention or\nstate space model. However, these methods primarily focus on network\narchitecture while neglecting the inherent characteristics of image restoration\nitself. In this context, we explore a pyramid Wavelet-Fourier iterative\npipeline to demonstrate the potential of Wavelet-Fourier processing for image\nrestoration. Inspired by the above findings, we propose a novel and efficient\nrestoration baseline, named Pyramid Wavelet-Fourier Network (PW-FNet).\nSpecifically, PW-FNet features two key design principles: 1) at the inter-block\nlevel, integrates a pyramid wavelet-based multi-input multi-output structure to\nachieve multi-scale and multi-frequency bands decomposition; and 2) at the\nintra-block level, incorporates Fourier transforms as an efficient alternative\nto self-attention mechanisms, effectively reducing computational complexity\nwhile preserving global modeling capability. Extensive experiments on tasks\nsuch as image deraining, raindrop removal, image super-resolution, motion\ndeblurring, image dehazing, image desnowing and underwater/low-light\nenhancement demonstrate that PW-FNet not only surpasses state-of-the-art\nmethods in restoration quality but also achieves superior efficiency, with\nsignificantly reduced parameter size, computational cost and inference time.", "AI": {"tldr": "The paper proposes the Pyramid Wavelet-Fourier Network (PW-FNet), combining wavelet decomposition and Fourier transforms for efficient and high-quality image restoration in adverse weather conditions, surpassing existing methods in performance and efficiency.", "motivation": "The motivation is to address the degradation of natural image quality caused by adverse weather, which impairs downstream tasks, and to overcome the challenges of high computational complexity in current transformer-based image restoration methods.", "method": "PW-FNet introduces a pyramid wavelet-based multi-scale decomposition at the inter-block level and uses Fourier transforms at the intra-block level to reduce complexity while maintaining global modeling capability, departing from traditional self-attention mechanisms.", "result": "PW-FNet achieves superior restoration performance across various tasks like deraining, dehazing, and super-resolution. It reduces parameter size, computational cost, and inference time compared to state-of-the-art methods.", "conclusion": "PW-FNet sets a new benchmark for efficient and effective image restoration, emphasizing the potential of wavelet and Fourier processing while balancing quality and computational efficiency."}}
{"id": "2507.13912", "pdf": "https://arxiv.org/pdf/2507.13912", "abs": "https://arxiv.org/abs/2507.13912", "authors": ["Kevin Dradjat", "Massinissa Hamidi", "Pierre Bartet", "Blaise Hanczar"], "title": "Self-supervised learning on gene expression data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Predicting phenotypes from gene expression data is a crucial task in\nbiomedical research, enabling insights into disease mechanisms, drug responses,\nand personalized medicine. Traditional machine learning and deep learning rely\non supervised learning, which requires large quantities of labeled data that\nare costly and time-consuming to obtain in the case of gene expression data.\nSelf-supervised learning has recently emerged as a promising approach to\novercome these limitations by extracting information directly from the\nstructure of unlabeled data. In this study, we investigate the application of\nstate-of-the-art self-supervised learning methods to bulk gene expression data\nfor phenotype prediction. We selected three self-supervised methods, based on\ndifferent approaches, to assess their ability to exploit the inherent structure\nof the data and to generate qualitative representations which can be used for\ndownstream predictive tasks. By using several publicly available gene\nexpression datasets, we demonstrate how the selected methods can effectively\ncapture complex information and improve phenotype prediction accuracy. The\nresults obtained show that self-supervised learning methods can outperform\ntraditional supervised models besides offering significant advantage by\nreducing the dependency on annotated data. We provide a comprehensive analysis\nof the performance of each method by highlighting their strengths and\nlimitations. We also provide recommendations for using these methods depending\non the case under study. Finally, we outline future research directions to\nenhance the application of self-supervised learning in the field of gene\nexpression data analysis. This study is the first work that deals with bulk\nRNA-Seq data and self-supervised learning.", "AI": {"tldr": "This study explores self-supervised learning methods for predicting phenotypes from bulk gene expression data, showing their effectiveness over traditional supervised models in reducing reliance on labeled data while enhancing prediction accuracy.", "motivation": "The motivation is to overcome the limitations of traditional supervised machine learning, which requires large labeled datasets for phenotype prediction in gene expression data, by using self-supervised learning to leverage unlabeled data effectively.", "method": "The study applied three state-of-the-art self-supervised learning methods to bulk gene expression data, assessing their ability to capture data structure and improve downstream predictive tasks using several publicly available datasets.", "result": "The results indicate that self-supervised learning methods outperform traditional supervised models in phenotype prediction accuracy and reduce reliance on annotated data. The study also provides a detailed analysis of the strengths and limitations of each method.", "conclusion": "Self-supervised learning is a promising tool for analyzing gene expression data, offering significant benefits over traditional methods. The paper includes recommendations for method selection and identifies future research directions, marking this as the first study focusing on self-supervised learning in bulk RNA-Seq data."}}
{"id": "2507.14017", "pdf": "https://arxiv.org/pdf/2507.14017", "abs": "https://arxiv.org/abs/2507.14017", "authors": ["Haoyu He", "Haozheng Luo", "Yan Chen", "Qi R. Wang"], "title": "Efficient Temporal Tokenization for Mobility Prediction with Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "We introduce RHYTHM (Reasoning with Hierarchical Temporal Tokenization for\nHuman Mobility), a framework that leverages large language models (LLMs) as\nspatio-temporal predictors and trajectory reasoners. RHYTHM partitions\ntrajectories into daily segments encoded as discrete tokens with hierarchical\nattention, capturing both daily and weekly dependencies while substantially\nreducing the sequence length. Token representations are enriched with\npre-computed prompt embeddings via a frozen LLM, enhancing the model's ability\nto capture interdependencies without extensive computational overhead. By\nfreezing the LLM backbone, RHYTHM achieves significant computational\nefficiency. Evaluation on three real-world datasets demonstrates a 2.4%\nimprovement in accuracy, 5.0% increase on weekends, and 24.6% reduction in\ntraining time compared to state-of-the-art methods.", "AI": {"tldr": "RHYTHM is a framework that enhances trajectory reasoning and prediction using hierarchical tokenization and a frozen large language model.", "motivation": "To improve spatio-temporal prediction and reasoning for human mobility using an approach that balances performance and computational efficiency.", "method": "RHYTHM segments trajectories into daily tokens, incorporates hierarchical attention to capture temporal dependencies, and enriches token representation using pre-computed LLM embeddings while freezing the LLM backbone to reduce computation.", "result": "Improved accuracy by 2.4%, increased weekend-specific accuracy by 5.0%, and reduced training time by 24.6% compared to state-of-the-art techniques.", "conclusion": "The combination of hierarchical token encoding and frozen LLM backbones effectively enhances reasoning capabilities and efficiency in human mobility prediction tasks."}}
{"id": "2507.13673", "pdf": "https://arxiv.org/pdf/2507.13673", "abs": "https://arxiv.org/abs/2507.13673", "authors": ["Yuechen Xie", "Haobo Jiang", "Jian Yang", "Yigong Zhang", "Jin Xie"], "title": "MaskHOI: Robust 3D Hand-Object Interaction Estimation via Masked Pre-training", "categories": ["cs.CV"], "comment": "10 pages, 8 figures, 6 tables", "summary": "In 3D hand-object interaction (HOI) tasks, estimating precise joint poses of\nhands and objects from monocular RGB input remains highly challenging due to\nthe inherent geometric ambiguity of RGB images and the severe mutual occlusions\nthat occur during interaction.To address these challenges, we propose MaskHOI,\na novel Masked Autoencoder (MAE)-driven pretraining framework for enhanced HOI\npose estimation. Our core idea is to leverage the masking-then-reconstruction\nstrategy of MAE to encourage the feature encoder to infer missing spatial and\nstructural information, thereby facilitating geometric-aware and\nocclusion-robust representation learning. Specifically, based on our\nobservation that human hands exhibit far greater geometric complexity than\nrigid objects, conventional uniform masking fails to effectively guide the\nreconstruction of fine-grained hand structures. To overcome this limitation, we\nintroduce a Region-specific Mask Ratio Allocation, primarily comprising the\nregion-specific masking assignment and the skeleton-driven hand masking\nguidance. The former adaptively assigns lower masking ratios to hand regions\nthan to rigid objects, balancing their feature learning difficulty, while the\nlatter prioritizes masking critical hand parts (e.g., fingertips or entire\nfingers) to realistically simulate occlusion patterns in real-world\ninteractions. Furthermore, to enhance the geometric awareness of the pretrained\nencoder, we introduce a novel Masked Signed Distance Field (SDF)-driven\nmultimodal learning mechanism. Through the self-masking 3D SDF prediction, the\nlearned encoder is able to perceive the global geometric structure of hands and\nobjects beyond the 2D image plane, overcoming the inherent limitations of\nmonocular input and alleviating self-occlusion issues. Extensive experiments\ndemonstrate that our method significantly outperforms existing state-of-the-art\napproaches.", "AI": {"tldr": "This paper introduces MaskHOI, a Masked Autoencoder-based pretraining framework for more accurate 3D hand and object pose estimation from monocular RGB input. ", "motivation": "The motivation is to address the challenges of geometric ambiguity and mutual occlusion in monocular RGB-based hand-object interaction pose estimation tasks.", "method": "The method involves a Masked Autoencoder-driven approach leveraging geometric-aware and occlusion-robust representation learning. Key techniques include Region-specific Mask Ratio Allocation to improve learning balance and Masked Signed Distance Field-driven multimodal learning to enhance global geometric structure perception.", "result": "The proposed framework demonstrates significant performance improvements over existing state-of-the-art methods in experiments.", "conclusion": "MaskHOI effectively uses masking strategies and multimodal mechanisms to improve 3D hand-object interaction pose estimation, addressing longstanding issues in RGB-based methods."}}
{"id": "2507.13920", "pdf": "https://arxiv.org/pdf/2507.13920", "abs": "https://arxiv.org/abs/2507.13920", "authors": ["Turan Orujlu", "Christian Gumbsch", "Martin V. Butz", "Charley M Wu"], "title": "Reframing attention as a reinforcement learning problem for causal discovery", "categories": ["cs.LG"], "comment": null, "summary": "Formal frameworks of causality have operated largely parallel to modern\ntrends in deep reinforcement learning (RL). However, there has been a revival\nof interest in formally grounding the representations learned by neural\nnetworks in causal concepts. Yet, most attempts at neural models of causality\nassume static causal graphs and ignore the dynamic nature of causal\ninteractions. In this work, we introduce Causal Process framework as a novel\ntheory for representing dynamic hypotheses about causal structure. Furthermore,\nwe present Causal Process Model as an implementation of this framework. This\nallows us to reformulate the attention mechanism popularized by Transformer\nnetworks within an RL setting with the goal to infer interpretable causal\nprocesses from visual observations. Here, causal inference corresponds to\nconstructing a causal graph hypothesis which itself becomes an RL task nested\nwithin the original RL problem. To create an instance of such hypothesis, we\nemploy RL agents. These agents establish links between units similar to the\noriginal Transformer attention mechanism. We demonstrate the effectiveness of\nour approach in an RL environment where we outperform current alternatives in\ncausal representation learning and agent performance, and uniquely recover\ngraphs of dynamic causal processes.", "AI": {"tldr": "This paper introduces a framework and model for representing and inferring dynamic causal hypotheses in reinforcement learning (RL) settings, outperforming current methods and enabling recovery of dynamic causal graphs.", "motivation": "Modern neural network models struggle to effectively account for dynamic causal interactions, and static causal graph assumptions limit progress in causal representation learning.", "method": "The authors propose a novel Causal Process framework for dynamic causal structures and implement it through the Causal Process Model, integrating it with Transformer-style attention mechanisms for RL tasks.", "result": "The approach outperforms existing methods in RL environments, improving causal representation learning, agent performance, and uniquely recovering dynamic causal graphs.", "conclusion": "This work establishes a new direction by combining causal inference with RL, enabling interpretable causal processes and improving task performance through dynamic hypothesis construction."}}
{"id": "2507.14022", "pdf": "https://arxiv.org/pdf/2507.14022", "abs": "https://arxiv.org/abs/2507.14022", "authors": ["Jianfei Li", "Kevin Kam Fung Yuen"], "title": "CPC-CMS: Cognitive Pairwise Comparison Classification Model Selection Framework for Document-level Sentiment Analysis", "categories": ["cs.CL", "cs.LG"], "comment": "35 pages, 33 tables, 6 Figures", "summary": "This study proposes the Cognitive Pairwise Comparison Classification Model\nSelection (CPC-CMS) framework for document-level sentiment analysis. The CPC,\nbased on expert knowledge judgment, is used to calculate the weights of\nevaluation criteria, including accuracy, precision, recall, F1-score,\nspecificity, Matthews Correlation Coefficient (MCC), Cohen's Kappa (Kappa), and\nefficiency. Naive Bayes, Linear Support Vector Classification (LSVC), Random\nForest, Logistic Regression, Extreme Gradient Boosting (XGBoost), Long\nShort-Term Memory (LSTM), and A Lite Bidirectional Encoder Representations from\nTransformers (ALBERT) are chosen as classification baseline models. A weighted\ndecision matrix consisting of classification evaluation scores with respect to\ncriteria weights, is formed to select the best classification model for a\nclassification problem. Three open datasets of social media are used to\ndemonstrate the feasibility of the proposed CPC-CMS. Based on our simulation,\nfor evaluation results excluding the time factor, ALBERT is the best for the\nthree datasets; if time consumption is included, no single model always\nperforms better than the other models. The CPC-CMS can be applied to the other\nclassification applications in different areas.", "AI": {"tldr": "The study introduces the CPC-CMS framework for selecting the best classification model for document-level sentiment analysis using pairwise comparison and weighted evaluation criteria.", "motivation": "The paper addresses the challenge of selecting the optimal classification model for sentiment analysis through a structured and expert-informed evaluation framework.", "method": "The CPC-CMS framework combines weighted evaluation criteria (e.g., accuracy, F1-score) via expert judgment and applies it to various algorithms such as Naive Bayes, LSTM, and ALBERT to identify the best model.", "result": "The simulation results show ALBERT performs best across three datasets when time is excluded, but no single model dominates when time consumption is factored.", "conclusion": "CPC-CMS is a versatile evaluation framework that can assist in classification model selection across domains by aligning model performance with weighted criteria."}}
{"id": "2507.13677", "pdf": "https://arxiv.org/pdf/2507.13677", "abs": "https://arxiv.org/abs/2507.13677", "authors": ["Chuheng Wei", "Ziye Qin", "Walter Zimmer", "Guoyuan Wu", "Matthew J. Barth"], "title": "HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "comment": "Ranked first in CVPR DriveX workshop TUM-Traf V2X challenge. Accepted\n  by ITSC2025", "summary": "Real-world Vehicle-to-Everything (V2X) cooperative perception systems often\noperate under heterogeneous sensor configurations due to cost constraints and\ndeployment variability across vehicles and infrastructure. This heterogeneity\nposes significant challenges for feature fusion and perception reliability. To\naddress these issues, we propose HeCoFuse, a unified framework designed for\ncooperative perception across mixed sensor setups where nodes may carry Cameras\n(C), LiDARs (L), or both. By introducing a hierarchical fusion mechanism that\nadaptively weights features through a combination of channel-wise and spatial\nattention, HeCoFuse can tackle critical challenges such as cross-modality\nfeature misalignment and imbalanced representation quality. In addition, an\nadaptive spatial resolution adjustment module is employed to balance\ncomputational cost and fusion effectiveness. To enhance robustness across\ndifferent configurations, we further implement a cooperative learning strategy\nthat dynamically adjusts fusion type based on available modalities. Experiments\non the real-world TUMTraf-V2X dataset demonstrate that HeCoFuse achieves 43.22%\n3D mAP under the full sensor configuration (LC+LC), outperforming the CoopDet3D\nbaseline by 1.17%, and reaches an even higher 43.38% 3D mAP in the L+LC\nscenario, while maintaining 3D mAP in the range of 21.74% to 43.38% across nine\nheterogeneous sensor configurations. These results, validated by our\nfirst-place finish in the CVPR 2025 DriveX challenge, establish HeCoFuse as the\ncurrent state-of-the-art on TUM-Traf V2X dataset while demonstrating robust\nperformance across diverse sensor deployments.", "AI": {"tldr": "The paper proposes HeCoFuse, a novel framework for cooperative perception in heterogeneous V2X sensor systems, achieving state-of-the-art performance in managing diverse sensor setups.", "motivation": "To address challenges in feature fusion and perception reliability in V2X systems with mixed sensor setups due to cost constraints and deployment variability.", "method": "HeCoFuse incorporates a hierarchical fusion mechanism with adaptive channel-wise and spatial attention, spatial resolution adjustments, and a cooperative learning strategy for dynamic modality-based fusion.", "result": "HeCoFuse outperforms the CoopDet3D baseline on the TUMTraf-V2X dataset, achieving 43.22% 3D mAP in full sensor setups and robust results across nine configurations.", "conclusion": "HeCoFuse establishes state-of-the-art performance in cooperative V2X perception, managing diverse sensor configurations effectively and robustly."}}
{"id": "2507.13950", "pdf": "https://arxiv.org/pdf/2507.13950", "abs": "https://arxiv.org/abs/2507.13950", "authors": ["Jingbo Liang", "Bruna Jacobson"], "title": "MoDyGAN: Combining Molecular Dynamics With GANs to Investigate Protein Conformational Space", "categories": ["cs.LG", "physics.bio-ph", "q-bio.BM"], "comment": null, "summary": "Extensively exploring protein conformational landscapes remains a major\nchallenge in computational biology due to the high computational cost involved\nin dynamic physics-based simulations. In this work, we propose a novel\npipeline, MoDyGAN, that leverages molecular dynamics (MD) simulations and\ngenerative adversarial networks (GANs) to explore protein conformational\nspaces. MoDyGAN contains a generator that maps Gaussian distributions into\nMD-derived protein trajectories, and a refinement module that combines ensemble\nlearning with a dual-discriminator to further improve the plausibility of\ngenerated conformations. Central to our approach is an innovative\nrepresentation technique that reversibly transforms 3D protein structures into\n2D matrices, enabling the use of advanced image-based GAN architectures. We use\nthree rigid proteins to demonstrate that MoDyGAN can generate plausible new\nconformations. We also use deca-alanine as a case study to show that\ninterpolations within the latent space closely align with trajectories obtained\nfrom steered molecular dynamics (SMD) simulations. Our results suggest that\nrepresenting proteins as image-like data unlocks new possibilities for applying\nadvanced deep learning techniques to biomolecular simulation, leading to an\nefficient sampling of conformational states. Additionally, the proposed\nframework holds strong potential for extension to other complex 3D structures.", "AI": {"tldr": "The study introduces MoDyGAN, a pipeline that combines molecular dynamics simulations and GANs to explore protein conformational spaces efficiently by transforming 3D structures into 2D data for advanced deep learning applications.", "motivation": "Efficiently exploring protein conformations is computationally challenging with traditional physics-based dynamic simulations, necessitating innovative solutions.", "method": "MoDyGAN employs MD simulations alongside GANs, using a generator for protein trajectories derived from Gaussian distributions, a refinement module with ensemble learning and dual-discriminators, and a reversible 2D representation of 3D structures for advanced GAN architectures.", "result": "MoDyGAN successfully generated plausible conformations for rigid proteins and demonstrated alignment of latent space interpolations with steered MD simulations for deca-alanine.", "conclusion": "MoDyGAN provides an innovative and efficient approach to sampling protein conformational states, showcasing the viability of 2D protein representations for advanced deep learning and potential applications to other 3D structures."}}
{"id": "2507.14045", "pdf": "https://arxiv.org/pdf/2507.14045", "abs": "https://arxiv.org/abs/2507.14045", "authors": ["Israt Jahan", "Md Tahmid Rahman Laskar", "Chun Peng", "Jimmy Huang"], "title": "Evaluating the Effectiveness of Cost-Efficient Large Language Models in Benchmark Biomedical Tasks", "categories": ["cs.CL"], "comment": "Accepted at Canadian AI 2025", "summary": "This paper presents a comprehensive evaluation of cost-efficient Large\nLanguage Models (LLMs) for diverse biomedical tasks spanning both text and\nimage modalities. We evaluated a range of closed-source and open-source LLMs on\ntasks such as biomedical text classification and generation, question\nanswering, and multimodal image processing. Our experimental findings indicate\nthat there is no single LLM that can consistently outperform others across all\ntasks. Instead, different LLMs excel in different tasks. While some\nclosed-source LLMs demonstrate strong performance on specific tasks, their\nopen-source counterparts achieve comparable results (sometimes even better),\nwith additional benefits like faster inference and enhanced privacy. Our\nexperimental results offer valuable insights for selecting models that are\noptimally suited for specific biomedical applications.", "AI": {"tldr": "This paper evaluates the effectiveness and cost-efficiency of various Large Language Models (LLMs) for biomedical tasks across text and image processing.", "motivation": "To systematically assess the performance and cost-efficiency of both open-source and closed-source LLMs in addressing diverse biomedical tasks.", "method": "The study experimentally evaluated multiple LLMs on tasks like biomedical text classification, generation, question answering, and multimodal image processing.", "result": "No single LLM consistently outperforms others on all tasks. Open-source LLMs often yield comparable or better results than closed-source models, with added advantages like faster inference and enhanced privacy.", "conclusion": "Insights from this study help in choosing LLMs that are best suited for specific biomedical applications."}}
{"id": "2507.13693", "pdf": "https://arxiv.org/pdf/2507.13693", "abs": "https://arxiv.org/abs/2507.13693", "authors": ["Hongyi Liu", "Haifeng Wang"], "title": "Gaussian kernel-based motion measurement", "categories": ["cs.CV"], "comment": null, "summary": "The growing demand for structural health monitoring has driven increasing\ninterest in high-precision motion measurement, as structural information\nderived from extracted motions can effectively reflect the current condition of\nthe structure. Among various motion measurement techniques, vision-based\nmethods stand out due to their low cost, easy installation, and large-scale\nmeasurement. However, when it comes to sub-pixel-level motion measurement,\ncurrent vision-based methods either lack sufficient accuracy or require\nextensive manual parameter tuning (e.g., pyramid layers, target pixels, and\nfilter parameters) to reach good precision. To address this issue, we developed\na novel Gaussian kernel-based motion measurement method, which can extract the\nmotion between different frames via tracking the location of Gaussian kernels.\nThe motion consistency, which fits practical structural conditions, and a\nsuper-resolution constraint, are introduced to increase accuracy and robustness\nof our method. Numerical and experimental validations show that it can\nconsistently reach high accuracy without customized parameter setup for\ndifferent test samples.", "AI": {"tldr": "This paper presents a Gaussian kernel-based motion measurement method for sub-pixel-level accuracy in vision-based structural health monitoring.", "motivation": "The motivation is to improve vision-based motion measurement methods, addressing issues of insufficient accuracy and the need for extensive manual parameter tuning.", "method": "The paper proposes using Gaussian kernel tracking, supplemented by motion consistency and super-resolution constraints, to enhance accuracy and robustness.", "result": "The proposed method achieves high accuracy across various test samples without needing customized parameter setups.", "conclusion": "The presented method offers a robust, accurate, and user-friendly solution for motion measurement in structural health monitoring."}}
{"id": "2507.13954", "pdf": "https://arxiv.org/pdf/2507.13954", "abs": "https://arxiv.org/abs/2507.13954", "authors": ["Yifan Wei", "Anwar Said", "Waseem Abbas", "Xenofon Koutsoukos"], "title": "Robust Anomaly Detection with Graph Neural Networks using Controllability", "categories": ["cs.LG"], "comment": "conference paper published in IEEE CAI 2025", "summary": "Anomaly detection in complex domains poses significant challenges due to the\nneed for extensive labeled data and the inherently imbalanced nature of\nanomalous versus benign samples. Graph-based machine learning models have\nemerged as a promising solution that combines attribute and relational data to\nuncover intricate patterns. However, the scarcity of anomalous data exacerbates\nthe challenge, which requires innovative strategies to enhance model learning\nwith limited information. In this paper, we hypothesize that the incorporation\nof the influence of the nodes, quantified through average controllability, can\nsignificantly improve the performance of anomaly detection. We propose two\nnovel approaches to integrate average controllability into graph-based\nframeworks: (1) using average controllability as an edge weight and (2)\nencoding it as a one-hot edge attribute vector. Through rigorous evaluation on\nreal-world and synthetic networks with six state-of-the-art baselines, our\nproposed methods demonstrate improved performance in identifying anomalies,\nhighlighting the critical role of controllability measures in enhancing the\nperformance of graph machine learning models. This work underscores the\npotential of integrating average controllability as additional metrics to\naddress the challenges of anomaly detection in sparse and imbalanced datasets.", "AI": {"tldr": "This paper explores integrating average controllability into graph-based machine learning models to enhance anomaly detection in sparse and imbalanced datasets.", "motivation": "Anomaly detection faces challenges due to data imbalance and limited anomalous samples, especially in complex graph-based domains.", "method": "The study incorporates average controllability via two strategies: using it as an edge weight and encoding it as a one-hot edge attribute vector in graph-based learning frameworks.", "result": "Experimental evaluations across real and synthetic networks show improved anomaly detection performance when average controllability is utilized.", "conclusion": "Incorporating average controllability into graph models enhances anomaly detection, especially in sparse and imbalanced datasets, offering new insights for graph machine learning advancements."}}
{"id": "2507.14063", "pdf": "https://arxiv.org/pdf/2507.14063", "abs": "https://arxiv.org/abs/2507.14063", "authors": ["Lautaro Estienne", "Gabriel Ben Zenou", "Nona Naderi", "Jackie Cheung", "Pablo Piantanida"], "title": "Collaborative Rational Speech Act: Pragmatic Reasoning for Multi-Turn Dialog", "categories": ["cs.CL"], "comment": null, "summary": "As AI systems take on collaborative roles, they must reason about shared\ngoals and beliefs-not just generate fluent language. The Rational Speech Act\n(RSA) framework offers a principled approach to pragmatic reasoning, but\nexisting extensions face challenges in scaling to multi-turn, collaborative\nscenarios. In this paper, we introduce Collaborative Rational Speech Act\n(CRSA), an information-theoretic (IT) extension of RSA that models multi-turn\ndialog by optimizing a gain function adapted from rate-distortion theory. This\ngain is an extension of the gain model that is maximized in the original RSA\nmodel but takes into account the scenario in which both agents in a\nconversation have private information and produce utterances conditioned on the\ndialog. We demonstrate the effectiveness of CRSA on referential games and\ntemplate-based doctor-patient dialogs in the medical domain. Empirical results\nshow that CRSA yields more consistent, interpretable, and collaborative\nbehavior than existing baselines-paving the way for more pragmatic and socially\naware language agents.", "AI": {"tldr": "The paper presents the CRSA model for multi-turn collaborative dialogs, demonstrating its effectiveness in referential and medical domain games.", "motivation": "Existing pragmatic reasoning frameworks like RSA struggle to handle multi-turn collaborative scenarios.", "method": "The authors propose CRSA, an information-theoretic extension of RSA, which employs a gain function based on rate-distortion theory to better model multi-turn dialog.", "result": "Empirical evaluations on referential games and doctor-patient dialogs showed CRSA outperformed existing baselines in producing consistent and collaborative behaviors.", "conclusion": "CRSA advances the field by enabling more pragmatic, collaborative, and socially aware language agents."}}
{"id": "2507.13706", "pdf": "https://arxiv.org/pdf/2507.13706", "abs": "https://arxiv.org/abs/2507.13706", "authors": ["\u00c1ngel F. Garc\u00eda-Fern\u00e1ndez", "Jinhao Gu", "Lennart Svensson", "Yuxuan Xia", "Jan Krej\u010d\u00ed", "Oliver Kost", "Ond\u0159ej Straka"], "title": "GOSPA and T-GOSPA quasi-metrics for evaluation of multi-object tracking algorithms", "categories": ["cs.CV", "math.ST", "stat.TH"], "comment": null, "summary": "This paper introduces two quasi-metrics for performance assessment of\nmulti-object tracking (MOT) algorithms. In particular, one quasi-metric is an\nextension of the generalised optimal subpattern assignment (GOSPA) metric and\nmeasures the discrepancy between sets of objects. The other quasi-metric is an\nextension of the trajectory GOSPA (T-GOSPA) metric and measures the discrepancy\nbetween sets of trajectories. Similar to the GOSPA-based metrics, these\nquasi-metrics include costs for localisation error for properly detected\nobjects, the number of false objects and the number of missed objects. The\nT-GOSPA quasi-metric also includes a track switching cost. Differently from the\nGOSPA and T-GOSPA metrics, the proposed quasi-metrics have the flexibility of\npenalising missed and false objects with different costs, and the localisation\ncosts are not required to be symmetric. These properties can be useful in MOT\nevaluation in certain applications. The performance of several Bayesian MOT\nalgorithms is assessed with the T-GOSPA quasi-metric via simulations.", "AI": {"tldr": "This study proposes two quasi-metrics extending GOSPA metrics to evaluate multi-object tracking based on discrepancy measures, offering flexible penalty costs and asymmetric localization costs.", "motivation": "Existing metrics for multi-object tracking performance assessment, such as GOSPA-based metrics, lack flexibility in penalizing false and missed objects differently or asymmetric localization cost adjustments.", "method": "Two quasi-metrics are developed: an extended GOSPA quasi-metric to measure object discrepancies and a T-GOSPA quasi-metric for trajectory discrepancies. These quasi-metrics are defined to allow varied penalty costs and asymmetric localization measures, enhancing evaluation adaptability.", "result": "Simulations demonstrate the effectiveness of the T-GOSPA quasi-metric in assessing performance for several Bayesian MOT algorithms, illustrating its applicability for nuanced evaluations.", "conclusion": "The proposed quasi-metrics address limitations in current MOT evaluation tools by introducing flexible penalization and asymmetric localization components, making them valuable for certain application-specific MOT assessments."}}
{"id": "2507.13959", "pdf": "https://arxiv.org/pdf/2507.13959", "abs": "https://arxiv.org/abs/2507.13959", "authors": ["Eli Verwimp", "Gustav Ryberg Smidt", "Hendrik Hameeuw", "Katrien De Graef"], "title": "Signs of the Past, Patterns of the Present: On the Automatic Classification of Old Babylonian Cuneiform Signs", "categories": ["cs.LG"], "comment": "Paper under review at JOCCH", "summary": "The work in this paper describes the training and evaluation of machine\nlearning (ML) techniques for the classification of cuneiform signs. There is a\nlot of variability in cuneiform signs, depending on where they come from, for\nwhat and by whom they were written, but also how they were digitized. This\nvariability makes it unlikely that an ML model trained on one dataset will\nperform successfully on another dataset. This contribution studies how such\ndifferences impact that performance. Based on our results and insights, we aim\nto influence future data acquisition standards and provide a solid foundation\nfor future cuneiform sign classification tasks. The ML model has been trained\nand tested on handwritten Old Babylonian (c. 2000-1600 B.C.E.) documentary\ntexts inscribed on clay tablets originating from three Mesopotamian cities\n(Nippur, D\\=ur-Abie\\v{s}uh and Sippar). The presented and analysed model is\nResNet50, which achieves a top-1 score of 87.1% and a top-5 score of 96.5% for\nsigns with at least 20 instances. As these automatic classification results are\nthe first on Old Babylonian texts, there are currently no comparable results.", "AI": {"tldr": "The paper explores the classification of cuneiform signs using machine learning, employing ResNet50 to analyze Old Babylonian texts, achieving high classification accuracies.", "motivation": "To address the challenge posed by variability in cuneiform signs and establish standards for data acquisition and future classification tasks.", "method": "ResNet50 was used as the ML model, trained on handwritten Old Babylonian texts originating from three Mesopotamian cities.", "result": "ResNet50 achieved a top-1 accuracy of 87.1% and top-5 accuracy of 96.5% for signs with at least 20 instances.", "conclusion": "The study offers foundational results for cuneiform sign classification and aims to influence data acquisition processes and future research directions."}}
{"id": "2507.14079", "pdf": "https://arxiv.org/pdf/2507.14079", "abs": "https://arxiv.org/abs/2507.14079", "authors": ["Garapati Keerthana", "Manik Gupta"], "title": "DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "comment": null, "summary": "Progress notes are among the most clinically meaningful artifacts in an\nElectronic Health Record (EHR), offering temporally grounded insights into a\npatient's evolving condition, treatments, and care decisions. Despite their\nimportance, they are severely underrepresented in large-scale EHR datasets. For\ninstance, in the widely used Medical Information Mart for Intensive Care III\n(MIMIC-III) dataset, only about $8.56\\%$ of hospital visits include progress\nnotes, leaving gaps in longitudinal patient narratives. In contrast, the\ndataset contains a diverse array of other note types, each capturing different\naspects of care.\n  We present DENSE (Documenting Evolving Progress Notes from Scattered\nEvidence), a system designed to align with clinical documentation workflows by\nsimulating how physicians reference past encounters while drafting progress\nnotes. The system introduces a fine-grained note categorization and a temporal\nalignment mechanism that organizes heterogeneous notes across visits into\nstructured, chronological inputs. At its core, DENSE leverages a clinically\ninformed retrieval strategy to identify temporally and semantically relevant\ncontent from both current and prior visits. This retrieved evidence is used to\nprompt a large language model (LLM) to generate clinically coherent and\ntemporally aware progress notes.\n  We evaluate DENSE on a curated cohort of patients with multiple visits and\ncomplete progress note documentation. The generated notes demonstrate strong\nlongitudinal fidelity, achieving a temporal alignment ratio of $1.089$,\nsurpassing the continuity observed in original notes. By restoring narrative\ncoherence across fragmented documentation, our system supports improved\ndownstream tasks such as summarization, predictive modeling, and clinical\ndecision support, offering a scalable solution for LLM-driven note synthesis in\nreal-world healthcare settings.", "AI": {"tldr": "This study introduces DENSE, a system designed to generate temporally and semantically coherent progress notes for EHRs by retrieving and aligning evidence across patient visits.", "motivation": "Progress notes are vital for understanding a patient\u2019s longitudinal medical history but are underrepresented in major EHR datasets like MIMIC-III, posing challenges for healthcare analysis and decision-making.", "method": "DENSE uses a clinically informed retrieval strategy to identify relevant temporal and semantic content across visits, organizing them with fine-grained categorization and temporal alignment for structured input into large language models to generate progress notes.", "result": "The system exhibits strong longitudinal fidelity, improving narrative coherence and achieving a temporal alignment ratio of 1.089, which surpasses continuity levels in existing documentation.", "conclusion": "DENSE enhances healthcare documentation by restoring narrative coherence, enabling improved summarization, predictive modeling, and clinical decision-making workflows."}}
{"id": "2507.13708", "pdf": "https://arxiv.org/pdf/2507.13708", "abs": "https://arxiv.org/abs/2507.13708", "authors": ["Sofia Jamil", "Bollampalli Areen Reddy", "Raghvendra Kumar", "Sriparna Saha", "Koustava Goswami", "K. J. Joseph"], "title": "PoemTale Diffusion: Minimising Information Loss in Poem to Image Generation with Multi-Stage Prompt Refinement", "categories": ["cs.CV"], "comment": "ECAI 2025", "summary": "Recent advancements in text-to-image diffusion models have achieved\nremarkable success in generating realistic and diverse visual content. A\ncritical factor in this process is the model's ability to accurately interpret\ntextual prompts. However, these models often struggle with creative\nexpressions, particularly those involving complex, abstract, or highly\ndescriptive language. In this work, we introduce a novel training-free approach\ntailored to improve image generation for a unique form of creative language:\npoetic verse, which frequently features layered, abstract, and dual meanings.\nOur proposed PoemTale Diffusion approach aims to minimise the information that\nis lost during poetic text-to-image conversion by integrating a multi stage\nprompt refinement loop into Language Models to enhance the interpretability of\npoetic texts. To support this, we adapt existing state-of-the-art diffusion\nmodels by modifying their self-attention mechanisms with a consistent\nself-attention technique to generate multiple consistent images, which are then\ncollectively used to convey the poem's meaning. Moreover, to encourage research\nin the field of poetry, we introduce the P4I (PoemForImage) dataset, consisting\nof 1111 poems sourced from multiple online and offline resources. We engaged a\npanel of poetry experts for qualitative assessments. The results from both\nhuman and quantitative evaluations validate the efficacy of our method and\ncontribute a novel perspective to poem-to-image generation with enhanced\ninformation capture in the generated images.", "AI": {"tldr": "The paper introduces a training-free framework called PoemTale Diffusion for better converting poetic language into images by refining prompts and adapting diffusion model mechanisms, evaluated via a newly introduced P4I dataset.", "motivation": "Text-to-image diffusion models struggle to interpret complex or abstract language forms, such as poetic verses, which limit their creative applications.", "method": "The authors propose PoemTale Diffusion, a training-free approach that uses a multi-stage prompt refinement loop, modifies self-attention in diffusion models to ensure consistent image generation, and utilizes the newly created P4I dataset.", "result": "The method showed both quantitative and qualitative success in enhancing image generation from poetic texts, validated by human experts and evaluations.", "conclusion": "The approach enhances the interpretability and representational fidelity of poetic text-to-image conversions, contributing a valuable tool and dataset for further research in the field."}}
{"id": "2507.13992", "pdf": "https://arxiv.org/pdf/2507.13992", "abs": "https://arxiv.org/abs/2507.13992", "authors": ["Jagruti Patel", "Thomas A. W. Bolton", "Mikkel Sch\u00f6ttner", "Anjali Tarun", "Sebastien Tourbier", "Yasser Alem\u00e0n-G\u00f2mez", "Jonas Richiardi", "Patric Hagmann"], "title": "Structural Connectome Harmonization Using Deep Learning: The Strength of Graph Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Small sample sizes in neuroimaging in general, and in structural connectome\n(SC) studies in particular limit the development of reliable biomarkers for\nneurological and psychiatric disorders - such as Alzheimer's disease and\nschizophrenia - by reducing statistical power, reliability, and\ngeneralizability. Large-scale multi-site studies have exist, but they have\nacquisition-related biases due to scanner heterogeneity, compromising imaging\nconsistency and downstream analyses. While existing SC harmonization methods -\nsuch as linear regression (LR), ComBat, and deep learning techniques - mitigate\nthese biases, they often rely on detailed metadata, traveling subjects (TS), or\noverlook the graph-topology of SCs. To address these limitations, we propose a\nsite-conditioned deep harmonization framework that harmonizes SCs across\ndiverse acquisition sites without requiring metadata or TS that we test in a\nsimulated scenario based on the Human Connectome Dataset. Within this\nframework, we benchmark three deep architectures - a fully connected\nautoencoder (AE), a convolutional AE, and a graph convolutional AE - against a\ntop-performing LR baseline. While non-graph models excel in edge-weight\nprediction and edge existence detection, the graph AE demonstrates superior\npreservation of topological structure and subject-level individuality, as\nreflected by graph metrics and fingerprinting accuracy, respectively. Although\nthe LR baseline achieves the highest numerical performance by explicitly\nmodeling acquisition parameters, it lacks applicability to real-world\nmulti-site use cases as detailed acquisition metadata is often unavailable. Our\nresults highlight the critical role of model architecture in SC harmonization\nperformance and demonstrate that graph-based approaches are particularly\nwell-suited for structure-aware, domain-generalizable SC harmonization in\nlarge-scale multi-site SC studies.", "AI": {"tldr": "This paper addresses biases in multi-site structural connectome studies due to scanner differences and proposes a deep learning framework for harmonization without requiring metadata or traveling subjects.", "motivation": "Structural connectome studies are hindered by small sample sizes, scanner heterogeneity, and limited generalizability in neurological disorder research. This paper aims to improve SC reliability across multi-site studies.", "method": "The authors propose a site-conditioned deep harmonization framework and benchmark three architectures (fully connected AE, convolutional AE, graph convolutional AE) against linear regression in simulated Human Connectome data.", "result": "Non-graph models performed well in prediction tasks, but graph convolutional architectures excelled at preserving topological structure and individuality. Linear regression performed well numerically but lacks practical applicability due to metadata requirements.", "conclusion": "Graph-based deep architectures are promising for domain-general SC harmonization, preserving graph-topology and individuality, especially for multi-site studies where metadata is unavailable."}}
{"id": "2507.13415", "pdf": "https://arxiv.org/pdf/2507.13415", "abs": "https://arxiv.org/abs/2507.13415", "authors": ["Peican Zhu", "Yubo Jing", "Le Cheng", "Bin Chen", "Xiaodong Cui", "Lianwei Wu", "Keke Tang"], "title": "SEER: Semantic Enhancement and Emotional Reasoning Network for Multimodal Fake News Detection", "categories": ["cs.MM", "cs.AI"], "comment": "Accepted by SMC 2025", "summary": "Previous studies on multimodal fake news detection mainly focus on the\nalignment and integration of cross-modal features, as well as the application\nof text-image consistency. However, they overlook the semantic enhancement\neffects of large multimodal models and pay little attention to the emotional\nfeatures of news. In addition, people find that fake news is more inclined to\ncontain negative emotions than real ones. Therefore, we propose a novel\nSemantic Enhancement and Emotional Reasoning (SEER) Network for multimodal fake\nnews detection. We generate summarized captions for image semantic\nunderstanding and utilize the products of large multimodal models for semantic\nenhancement. Inspired by the perceived relationship between news authenticity\nand emotional tendencies, we propose an expert emotional reasoning module that\nsimulates real-life scenarios to optimize emotional features and infer the\nauthenticity of news. Extensive experiments on two real-world datasets\ndemonstrate the superiority of our SEER over state-of-the-art baselines.", "AI": {"tldr": "The paper proposes SEER, a Semantic Enhancement and Emotional Reasoning network, for multimodal fake news detection by incorporating semantic understanding and emotional features.", "motivation": "Existing methods for multimodal fake news detection neglect the potential of large multimodal models for semantic enhancement and the emotional tendencies in fake news, especially their inclination towards negativity.", "method": "The SEER network generates captions for image semantics, leverages large multimodal models for semantic enhancement, and utilizes an emotional reasoning module inspired by the relationship between emotional tendencies and news authenticity.", "result": "Experiments on two datasets show SEER's superiority over existing state-of-the-art multimodal fake news detection methods.", "conclusion": "Incorporating semantic enhancement and emotional reasoning significantly improves the performance of multimodal fake news detection, demonstrating SEER's effectiveness."}}
{"id": "2507.14096", "pdf": "https://arxiv.org/pdf/2507.14096", "abs": "https://arxiv.org/abs/2507.14096", "authors": ["Brian Ondov", "William Xia", "Kush Attal", "Ishita Unde", "Jerry He", "Hoa Dang", "Ian Soboroff", "Dina Demner-Fushman"], "title": "Lessons from the TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Objective: Recent advances in language models have shown potential to adapt\nprofessional-facing biomedical literature to plain language, making it\naccessible to patients and caregivers. However, their unpredictability,\ncombined with the high potential for harm in this domain, means rigorous\nevaluation is necessary. Our goals with this track were to stimulate research\nand to provide high-quality evaluation of the most promising systems.\n  Methods: We hosted the Plain Language Adaptation of Biomedical Abstracts\n(PLABA) track at the 2023 and 2024 Text Retrieval Conferences. Tasks included\ncomplete, sentence-level, rewriting of abstracts (Task 1) as well as\nidentifying and replacing difficult terms (Task 2). For automatic evaluation of\nTask 1, we developed a four-fold set of professionally-written references.\nSubmissions for both Tasks 1 and 2 were provided extensive manual evaluation\nfrom biomedical experts.\n  Results: Twelve teams spanning twelve countries participated in the track,\nwith models from multilayer perceptrons to large pretrained transformers. In\nmanual judgments of Task 1, top-performing models rivaled human levels of\nfactual accuracy and completeness, but not simplicity or brevity. Automatic,\nreference-based metrics generally did not correlate well with manual judgments.\nIn Task 2, systems struggled with identifying difficult terms and classifying\nhow to replace them. When generating replacements, however, LLM-based systems\ndid well in manually judged accuracy, completeness, and simplicity, though not\nin brevity.\n  Conclusion: The PLABA track showed promise for using Large Language Models to\nadapt biomedical literature for the general public, while also highlighting\ntheir deficiencies and the need for improved automatic benchmarking tools.", "AI": {"tldr": "The paper discusses a study on adapting biomedical literature into plain language using AI models. Results showed potential but emphasized the necessity for better tools and highlighted the limitations of current approaches.", "motivation": "Making professional biomedical literature accessible to patients and caregivers through plain language adaptation, while ensuring accuracy and simplicity, given the potential risks in this domain.", "method": "Two tasks were developed and evaluated under the PLABA track: rewriting abstracts entirely into plain language (Task 1) and identifying/replacing difficult terms (Task 2). Both tasks underwent rigorous manual and reference-based evaluation.", "result": "Twelve teams from various countries showcased a range of models. Top-performing systems matched human accuracy but lacked simplicity. Systems struggled with identifying difficult terms but performed well in generating accurate and simple replacements for Task 2.", "conclusion": "The study demonstrates the potential of large language models in biomedical adaptation but underscores the need for improved benchmarking tools and areas for refinement in AI systems."}}
{"id": "2507.13719", "pdf": "https://arxiv.org/pdf/2507.13719", "abs": "https://arxiv.org/abs/2507.13719", "authors": ["Daniele Pannone", "Alessia Castronovo", "Maurizio Mancini", "Gian Luca Foresti", "Claudio Piciarelli", "Rossana Gabrieli", "Muhammad Yasir Bilal", "Danilo Avola"], "title": "Augmented Reality in Cultural Heritage: A Dual-Model Pipeline for 3D Artwork Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "This paper presents an innovative augmented reality pipeline tailored for\nmuseum environments, aimed at recognizing artworks and generating accurate 3D\nmodels from single images. By integrating two complementary pre-trained depth\nestimation models, i.e., GLPN for capturing global scene structure and\nDepth-Anything for detailed local reconstruction, the proposed approach\nproduces optimized depth maps that effectively represent complex artistic\nfeatures. These maps are then converted into high-quality point clouds and\nmeshes, enabling the creation of immersive AR experiences. The methodology\nleverages state-of-the-art neural network architectures and advanced computer\nvision techniques to overcome challenges posed by irregular contours and\nvariable textures in artworks. Experimental results demonstrate significant\nimprovements in reconstruction accuracy and visual realism, making the system a\nhighly robust tool for museums seeking to enhance visitor engagement through\ninteractive digital content.", "AI": {"tldr": "The paper develops an augmented reality system for museums to recognize artworks and build detailed 3D models from single images using depth estimation models.", "motivation": "The motivation is to improve visitor engagement in museums by creating immersive augmented reality experiences that effectively digitize and recreate artistic features.", "method": "The approach integrates GLPN and Depth-Anything depth estimation models to optimize depth maps, convert them into point clouds and meshes, and enhance 3D modeling accuracy for artworks.", "result": "The system achieves significant improvements in reconstruction accuracy and visual realism, overcoming challenges from irregular contours and variable textures in artworks.", "conclusion": "The solution is effective and robust, offering museums a valuable tool to elevate visitor experiences through AR-based interactive digital content."}}
{"id": "2507.13998", "pdf": "https://arxiv.org/pdf/2507.13998", "abs": "https://arxiv.org/abs/2507.13998", "authors": ["Itay Katav", "Aryeh Kontorovich"], "title": "ParallelTime: Dynamically Weighting the Balance of Short- and Long-Term Temporal Dependencies", "categories": ["cs.LG"], "comment": null, "summary": "Modern multivariate time series forecasting primarily relies on two\narchitectures: the Transformer with attention mechanism and Mamba. In natural\nlanguage processing, an approach has been used that combines local window\nattention for capturing short-term dependencies and Mamba for capturing\nlong-term dependencies, with their outputs averaged to assign equal weight to\nboth. We find that for time-series forecasting tasks, assigning equal weight to\nlong-term and short-term dependencies is not optimal. To mitigate this, we\npropose a dynamic weighting mechanism, ParallelTime Weighter, which calculates\ninterdependent weights for long-term and short-term dependencies for each token\nbased on the input and the model's knowledge. Furthermore, we introduce the\nParallelTime architecture, which incorporates the ParallelTime Weighter\nmechanism to deliver state-of-the-art performance across diverse benchmarks.\nOur architecture demonstrates robustness, achieves lower FLOPs, requires fewer\nparameters, scales effectively to longer prediction horizons, and significantly\noutperforms existing methods. These advances highlight a promising path for\nfuture developments of parallel Attention-Mamba in time series forecasting. The\nimplementation is readily available at:\n\\href{https://github.com/itay1551/ParallelTime}{ParallelTime GitHub", "AI": {"tldr": "The paper introduces ParallelTime, an architecture that improves multivariate time series forecasting by employing a dynamic weighting mechanism for long- and short-term dependencies instead of equal weighting.", "motivation": "To address the inefficiency of equal weighting in capturing long- and short-term dependencies in multivariate time series forecasting.", "method": "The authors propose the ParallelTime Weighter, which dynamically assigns weights to long-term and short-term dependencies based on input and model knowledge, integrated into the ParallelTime architecture.", "result": "The model delivers state-of-the-art performance, reducing FLOPs, using fewer parameters, scaling to longer horizons, and outperforming existing frameworks on diverse benchmarks.", "conclusion": "ParallelTime showcases an effective approach for enhancing time series forecasting, offering robustness, efficiency, and scalability, paving the way for future parallel Attention-Mamba developments."}}
{"id": "2507.13722", "pdf": "https://arxiv.org/pdf/2507.13722", "abs": "https://arxiv.org/abs/2507.13722", "authors": ["Julia Laubmann", "Johannes Reschke"], "title": "Tackling fake images in cybersecurity -- Interpretation of a StyleGAN and lifting its black-box", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": null, "summary": "In today's digital age, concerns about the dangers of AI-generated images are\nincreasingly common. One powerful tool in this domain is StyleGAN (style-based\ngenerative adversarial networks), a generative adversarial network capable of\nproducing highly realistic synthetic faces. To gain a deeper understanding of\nhow such a model operates, this work focuses on analyzing the inner workings of\nStyleGAN's generator component. Key architectural elements and techniques, such\nas the Equalized Learning Rate, are explored in detail to shed light on the\nmodel's behavior. A StyleGAN model is trained using the PyTorch framework,\nenabling direct inspection of its learned weights. Through pruning, it is\nrevealed that a significant number of these weights can be removed without\ndrastically affecting the output, leading to reduced computational\nrequirements. Moreover, the role of the latent vector -- which heavily\ninfluences the appearance of the generated faces -- is closely examined. Global\nalterations to this vector primarily affect aspects like color tones, while\ntargeted changes to individual dimensions allow for precise manipulation of\nspecific facial features. This ability to finetune visual traits is not only of\nacademic interest but also highlights a serious ethical concern: the potential\nmisuse of such technology. Malicious actors could exploit this capability to\nfabricate convincing fake identities, posing significant risks in the context\nof digital deception and cybercrime.", "AI": {"tldr": "The paper examines StyleGAN's generator to better understand its methods for creating realistic synthetic faces. Key topics include architectural elements, weight pruning, and manipulation of latent vectors.", "motivation": "The study aims to analyze StyleGAN's generator to understand the workings of AI-generated images, which present both technological opportunities and ethical risks.", "method": "StyleGAN was trained in PyTorch, enabling the inspection and pruning of weights for computational efficiency. Latent vectors were studied to observe their global and targeted influence on generated images.", "result": "The latent vectors significantly affect the output, with global changes altering color tones and targeted changes manipulating specific facial features. Weight pruning results in reduced computational load without drastic output changes.", "conclusion": "While the technical insights into StyleGAN are valuable, the paper underscores ethical concerns about identity fabrication and the misuse of generative technology for cybercrime."}}
{"id": "2507.14005", "pdf": "https://arxiv.org/pdf/2507.14005", "abs": "https://arxiv.org/abs/2507.14005", "authors": ["Mathieu Godbout", "Audrey Durand"], "title": "On the Fundamental Limitations of Dual Static CVaR Decompositions in Markov Decision Processes", "categories": ["cs.LG"], "comment": null, "summary": "Recent work has shown that dynamic programming (DP) methods for finding\nstatic CVaR-optimal policies in Markov Decision Processes (MDPs) can fail when\nbased on the dual formulation, yet the root cause for the failure has remained\nunclear. We expand on these findings by shifting focus from policy optimization\nto the seemingly simpler task of policy evaluation. We show that evaluating the\nstatic CVaR of a given policy can be framed as two distinct minimization\nproblems. For their solutions to match, a set of ``risk-assignment consistency\nconstraints'' must be satisfied, and we demonstrate that the intersection of\nthe constraints being empty is the source of previously observed evaluation\nerrors. Quantifying the evaluation error as the CVaR evaluation gap, we then\ndemonstrate that the issues observed when optimizing over the dual-based CVaR\nDP are explained by the returned policy having a non-zero CVaR evaluation gap.\nWe then leverage our proposed risk-assignment perspective to prove that the\nsearch for a single, uniformly optimal policy via on the dual CVaR\ndecomposition is fundamentally limited, identifying an MDP where no single\npolicy can be optimal across all initial risk levels.", "AI": {"tldr": "The paper explores issues in using dynamic programming for evaluating CVaR-optimal policies in Markov Decision Processes, identifying a root cause tied to inconsistent constraints in risk assignments.", "motivation": "Dynamic programming methods for static CVaR-optimal policies have shown to fail under the dual formulation, yet the underlying reasons remain unclear.", "method": "The authors shift focus from policy optimization to policy evaluation, framing it as minimization problems and introducing 'risk-assignment consistency constraints' to quantify errors.", "result": "The work demonstrates that errors previously observed are due to inconsistent risk assignments. It also identifies fundamental limitations in finding uniformly optimal policies across initial risk levels.", "conclusion": "Searching for a single uniformly optimal policy using dual CVaR decomposition is inherently restricted due to mismatch across risk assignment conditions."}}
{"id": "2507.13739", "pdf": "https://arxiv.org/pdf/2507.13739", "abs": "https://arxiv.org/abs/2507.13739", "authors": ["Junsu Kim", "Yunhoe Ku", "Seungryul Baek"], "title": "Can Synthetic Images Conquer Forgetting? Beyond Unexplored Doubts in Few-Shot Class-Incremental Learning", "categories": ["cs.CV", "cs.AI"], "comment": "6th CLVISION ICCV Workshop accepted", "summary": "Few-shot class-incremental learning (FSCIL) is challenging due to extremely\nlimited training data; while aiming to reduce catastrophic forgetting and learn\nnew information. We propose Diffusion-FSCIL, a novel approach that employs a\ntext-to-image diffusion model as a frozen backbone. Our conjecture is that\nFSCIL can be tackled using a large generative model's capabilities benefiting\nfrom 1) generation ability via large-scale pre-training; 2) multi-scale\nrepresentation; 3) representational flexibility through the text encoder. To\nmaximize the representation capability, we propose to extract multiple\ncomplementary diffusion features to play roles as latent replay with slight\nsupport from feature distillation for preventing generative biases. Our\nframework realizes efficiency through 1) using a frozen backbone; 2) minimal\ntrainable components; 3) batch processing of multiple feature extractions.\nExtensive experiments on CUB-200, \\emph{mini}ImageNet, and CIFAR-100 show that\nDiffusion-FSCIL surpasses state-of-the-art methods, preserving performance on\npreviously learned classes and adapting effectively to new ones.", "AI": {"tldr": "The paper introduces Diffusion-FSCIL, a technique for few-shot class-incremental learning that uses a frozen text-to-image diffusion model, achieving superior results on benchmarks.", "motivation": "To address the challenges of few-shot class-incremental learning, including limited data, catastrophic forgetting, and learning new information effectively.", "method": "The approach uses a pre-trained text-to-image diffusion model as a frozen backbone and extracts diverse diffusion features for latent replay alongside minimal feature distillation.", "result": "Diffusion-FSCIL demonstrates superior performance over state-of-the-art methods on CUB-200, miniImageNet, and CIFAR-100 datasets, maintaining previous knowledge and adapting to new classes.", "conclusion": "The use of a frozen diffusion model backbone along with complementary features and minimal trainable components effectively addresses FSCIL challenges."}}
{"id": "2507.14021", "pdf": "https://arxiv.org/pdf/2507.14021", "abs": "https://arxiv.org/abs/2507.14021", "authors": ["Xu Zhang", "Zhenyuan Yuan", "Minghui Zhu"], "title": "Byzantine-resilient federated online learning for Gaussian process regression", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "In this paper, we study Byzantine-resilient federated online learning for\nGaussian process regression (GPR). We develop a Byzantine-resilient federated\nGPR algorithm that allows a cloud and a group of agents to collaboratively\nlearn a latent function and improve the learning performances where some agents\nexhibit Byzantine failures, i.e., arbitrary and potentially adversarial\nbehavior. Each agent-based local GPR sends potentially compromised local\npredictions to the cloud, and the cloud-based aggregated GPR computes a global\nmodel by a Byzantine-resilient product of experts aggregation rule. Then the\ncloud broadcasts the current global model to all the agents. Agent-based fused\nGPR refines local predictions by fusing the received global model with that of\nthe agent-based local GPR. Moreover, we quantify the learning accuracy\nimprovements of the agent-based fused GPR over the agent-based local GPR.\nExperiments on a toy example and two medium-scale real-world datasets are\nconducted to demonstrate the performances of the proposed algorithm.", "AI": {"tldr": "The paper introduces a Byzantine-resilient federated GPR algorithm for improving learning accuracy under adversarial agent conditions.", "motivation": "To construct a robust federated Gaussian process regression capable of handling Byzantine failures, which compromise learning in collaborative systems.", "method": "Proposes a cloud-agent setup where local GPR sends predictions to the cloud, which aggregates models using a resilient method and broadcasts it back for fusion with agents' GPR models.", "result": "The method improves learning accuracy, demonstrated experimentally on toy and real-world datasets.", "conclusion": "The algorithm facilitates collaborative learning while countering potential adversarial behaviors among agents, enhancing global learning performance."}}
{"id": "2507.13396", "pdf": "https://arxiv.org/pdf/2507.13396", "abs": "https://arxiv.org/abs/2507.13396", "authors": ["Qingyun Sun", "Jiaqi Yuan", "Shan He", "Xiao Guan", "Haonan Yuan", "Xingcheng Fu", "Jianxin Li", "Philip S. Yu"], "title": "DyG-RAG: Dynamic Graph Retrieval-Augmented Generation with Event-Centric Reasoning", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "Graph Retrieval-Augmented Generation has emerged as a powerful paradigm for\ngrounding large language models with external structured knowledge. However,\nexisting Graph RAG methods struggle with temporal reasoning, due to their\ninability to model the evolving structure and order of real-world events. In\nthis work, we introduce DyG-RAG, a novel event-centric dynamic graph\nretrieval-augmented generation framework designed to capture and reason over\ntemporal knowledge embedded in unstructured text. To eliminate temporal\nambiguity in traditional retrieval units, DyG-RAG proposes Dynamic Event Units\n(DEUs) that explicitly encode both semantic content and precise temporal\nanchors, enabling accurate and interpretable time-aware retrieval. To capture\ntemporal and causal dependencies across events, DyG-RAG constructs an event\ngraph by linking DEUs that share entities and occur close in time, supporting\nefficient and meaningful multi-hop reasoning. To ensure temporally consistent\ngeneration, DyG-RAG introduces an event timeline retrieval pipeline that\nretrieves event sequences via time-aware traversal, and proposes a Time\nChain-of-Thought strategy for temporally grounded answer generation. This\nunified pipeline enables DyG-RAG to retrieve coherent, temporally ordered event\nsequences and to answer complex, time-sensitive queries that standard RAG\nsystems cannot resolve. Extensive experiments on temporal QA benchmarks\ndemonstrate that DyG-RAG significantly improves the accuracy and recall of\nthree typical types of temporal reasoning questions, paving the way for more\nfaithful and temporal-aware generation. DyG-RAG is available at\nhttps://github.com/RingBDStack/DyG-RAG.", "AI": {"tldr": "DyG-RAG framework improves temporal reasoning by introducing dynamic event-centered retrieval and generation methods.", "motivation": "To address the limitation of current Graph Retrieval-Augmented Generation (Graph RAG) systems in temporal reasoning due to lack of proper modeling of evolving events and their sequence.", "method": "DyG-RAG introduces Dynamic Event Units (DEUs) for precise semantic and temporal encoding. It builds event graphs to capture temporal/causal relationships, implements a time-aware event timeline retrieval system, and uses Time Chain-of-Thought for answer generation.", "result": "Extensive experiments on temporal QA benchmarks show DyG-RAG significantly enhances accuracy and recall in temporal reasoning tasks.", "conclusion": "DyG-RAG sets a foundation for faithful and time-aware generation by offering an integrated pipeline addressing complex, temporally-sensitive queries."}}
{"id": "2507.13753", "pdf": "https://arxiv.org/pdf/2507.13753", "abs": "https://arxiv.org/abs/2507.13753", "authors": ["Tongtong Su", "Chengyu Wang", "Bingyan Liu", "Jun Huang", "Dongming Lu"], "title": "Encapsulated Composition of Text-to-Image and Text-to-Video Models for High-Quality Video Synthesis", "categories": ["cs.CV"], "comment": null, "summary": "In recent years, large text-to-video (T2V) synthesis models have garnered\nconsiderable attention for their abilities to generate videos from textual\ndescriptions. However, achieving both high imaging quality and effective motion\nrepresentation remains a significant challenge for these T2V models. Existing\napproaches often adapt pre-trained text-to-image (T2I) models to refine video\nframes, leading to issues such as flickering and artifacts due to\ninconsistencies across frames. In this paper, we introduce EVS, a training-free\nEncapsulated Video Synthesizer that composes T2I and T2V models to enhance both\nvisual fidelity and motion smoothness of generated videos. Our approach\nutilizes a well-trained diffusion-based T2I model to refine low-quality video\nframes by treating them as out-of-distribution samples, effectively optimizing\nthem with noising and denoising steps. Meanwhile, we employ T2V backbones to\nensure consistent motion dynamics. By encapsulating the T2V temporal-only prior\ninto the T2I generation process, EVS successfully leverages the strengths of\nboth types of models, resulting in videos of improved imaging and motion\nquality. Experimental results validate the effectiveness of our approach\ncompared to previous approaches. Our composition process also leads to a\nsignificant improvement of 1.6x-4.5x speedup in inference time. Source codes:\nhttps://github.com/Tonniia/EVS.", "AI": {"tldr": "The paper introduces EVS, a training-free text-to-video model that combines diffusion-based text-to-image (T2I) models and T2V backbones for enhanced video quality and motion smoothness, addressing challenges like flickering and artifacts.", "motivation": "To address the challenges in achieving both high video quality and smooth motion representation in text-to-video synthesis models without introducing frame inconsistencies such as flickering and artifacts.", "method": "The EVS method composes pre-trained T2I and T2V models: T2I models are used to refine low-quality frames via noising and denoising, and T2V backbones ensure consistent motion dynamics. This fusion encapsulates T2V temporal priors into T2I processes.", "result": "Experimental results demonstrate that EVS significantly improves video fidelity and motion quality over previous methods, with an inference speedup of 1.6x-4.5x.", "conclusion": "EVS effectively combines the strengths of T2I and T2V models, offering high-quality and smooth-motion video generation with faster inference times. Its implementation is publicly available."}}
{"id": "2507.14038", "pdf": "https://arxiv.org/pdf/2507.14038", "abs": "https://arxiv.org/abs/2507.14038", "authors": ["Aileen Luo", "Tao Zhou", "Ming Du", "Martin V. Holt", "Andrej Singer", "Mathew J. Cherukara"], "title": "DONUT: Physics-aware Machine Learning for Real-time X-ray Nanodiffraction Analysis", "categories": ["cs.LG"], "comment": null, "summary": "Coherent X-ray scattering techniques are critical for investigating the\nfundamental structural properties of materials at the nanoscale. While\nadvancements have made these experiments more accessible, real-time analysis\nremains a significant bottleneck, often hindered by artifacts and computational\ndemands. In scanning X-ray nanodiffraction microscopy, which is widely used to\nspatially resolve structural heterogeneities, this challenge is compounded by\nthe convolution of the divergent beam with the sample's local structure. To\naddress this, we introduce DONUT (Diffraction with Optics for Nanobeam by\nUnsupervised Training), a physics-aware neural network designed for the rapid\nand automated analysis of nanobeam diffraction data. By incorporating a\ndifferentiable geometric diffraction model directly into its architecture,\nDONUT learns to predict crystal lattice strain and orientation in real-time.\nCrucially, this is achieved without reliance on labeled datasets or\npre-training, overcoming a fundamental limitation for supervised machine\nlearning in X-ray science. We demonstrate experimentally that DONUT accurately\nextracts all features within the data over 200 times more efficiently than\nconventional fitting methods.", "AI": {"tldr": "The paper introduces DONUT, a physics-aware neural network, for real-time automated analysis of nanobeam diffraction data, outperforming conventional methods in speed and accuracy.", "motivation": "Real-time analysis of coherent X-ray scattering experiments faces significant bottlenecks due to artifacts, computational demands, and inherent data complexities.", "method": "The authors developed DONUT, incorporating a differentiable geometric diffraction model within its neural network architecture, enabling unsupervised, real-time analysis without pre-labeled datasets.", "result": "Experimental results show that DONUT is over 200 times more efficient than traditional fitting methods, accurately extracting crystal lattice strain and orientation.", "conclusion": "DONUT provides a transformative tool for nanoscale structural analysis, addressing prevailing computational challenges and enabling rapid, accurate data interpretation."}}
{"id": "2507.13769", "pdf": "https://arxiv.org/pdf/2507.13769", "abs": "https://arxiv.org/abs/2507.13769", "authors": ["Mingyang Yu", "Zhijian Wu", "Dingjiang Huang"], "title": "Learning Spectral Diffusion Prior for Hyperspectral Image Reconstruction", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Hyperspectral image (HSI) reconstruction aims to recover 3D HSI from its\ndegraded 2D measurements. Recently great progress has been made in deep\nlearning-based methods, however, these methods often struggle to accurately\ncapture high-frequency details of the HSI. To address this issue, this paper\nproposes a Spectral Diffusion Prior (SDP) that is implicitly learned from\nhyperspectral images using a diffusion model. Leveraging the powerful ability\nof the diffusion model to reconstruct details, this learned prior can\nsignificantly improve the performance when injected into the HSI model. To\nfurther improve the effectiveness of the learned prior, we also propose the\nSpectral Prior Injector Module (SPIM) to dynamically guide the model to recover\nthe HSI details. We evaluate our method on two representative HSI methods: MST\nand BISRNet. Experimental results show that our method outperforms existing\nnetworks by about 0.5 dB, effectively improving the performance of HSI\nreconstruction.", "AI": {"tldr": "The paper introduces a Spectral Diffusion Prior (SDP) and Spectral Prior Injector Module (SPIM) to enhance hyperspectral image (HSI) reconstruction, achieving better performance than existing methods.", "motivation": "Existing deep learning-based HSI reconstruction methods struggle with capturing high-frequency details accurately. The paper aims to address this limitation.", "method": "The authors propose using a Spectral Diffusion Prior (SDP) learned via a diffusion model, along with a Spectral Prior Injector Module (SPIM) for dynamic guidance during HSI reconstruction.", "result": "Experimental evaluations on MST and BISRNet show that the proposed method improves reconstruction performance by 0.5 dB compared to existing approaches.", "conclusion": "The incorporation of SDP and SPIM enhances the recovery of details in HSI reconstruction, demonstrating significant performance improvement."}}
{"id": "2507.14056", "pdf": "https://arxiv.org/pdf/2507.14056", "abs": "https://arxiv.org/abs/2507.14056", "authors": ["Alejandro Rodriguez-Garcia", "Anindya Ghosh", "Srikanth Ramaswamy"], "title": "Noradrenergic-inspired gain modulation attenuates the stability gap in joint training", "categories": ["cs.LG", "cs.AI", "q-bio.NC", "68T05"], "comment": "18 pages, 5 figures, 1 table, 1 pseudo-code", "summary": "Recent studies in continual learning have identified a transient drop in\nperformance on mastered tasks when assimilating new ones, known as the\nstability gap. Such dynamics contradict the objectives of continual learning,\nrevealing a lack of robustness in mitigating forgetting, and notably,\npersisting even under an ideal joint-loss regime. Examining this gap within\nthis idealized joint training context is critical to isolate it from other\nsources of forgetting. We argue that it reflects an imbalance between rapid\nadaptation and robust retention at task boundaries, underscoring the need to\ninvestigate mechanisms that reconcile plasticity and stability within continual\nlearning frameworks. Biological brains navigate a similar dilemma by operating\nconcurrently on multiple timescales, leveraging neuromodulatory signals to\nmodulate synaptic plasticity. However, artificial networks lack native\nmultitimescale dynamics, and although optimizers like momentum-SGD and Adam\nintroduce implicit timescale regularization, they still exhibit stability gaps.\nInspired by locus coeruleus mediated noradrenergic bursts, which transiently\nenhance neuronal gain under uncertainty to facilitate sensory assimilation, we\npropose uncertainty-modulated gain dynamics - an adaptive mechanism that\napproximates a two-timescale optimizer and dynamically balances integration of\nknowledge with minimal interference on previously consolidated information. We\nevaluate our mechanism on domain-incremental and class-incremental variants of\nthe MNIST and CIFAR benchmarks under joint training, demonstrating that\nuncertainty-modulated gain dynamics effectively attenuate the stability gap.\nFinally, our analysis elucidates how gain modulation replicates noradrenergic\nfunctions in cortical circuits, offering mechanistic insights into reducing\nstability gaps and enhance performance in continual learning tasks.", "AI": {"tldr": "The paper identifies a stability gap in continual learning and proposes uncertainty-modulated gain dynamics inspired by biological processes to mitigate this issue.", "motivation": "The study aims to address the stability gap in continual learning, where performance drops occur on mastered tasks upon learning new ones, even under ideal settings.", "method": "The authors propose uncertainty-modulated gain dynamics, inspired by neuromodulatory signals in the brain, to approximate a two-timescale optimizer for balancing adaptation and retention of knowledge.", "result": "The proposed mechanism significantly reduces the stability gap in domain and class-incremental learning for MNIST and CIFAR benchmarks during joint training.", "conclusion": "Uncertainty-modulated gain dynamics provide a biologically inspired solution to minimize stability gaps in continual learning, improving task performance and retention."}}
{"id": "2507.13586", "pdf": "https://arxiv.org/pdf/2507.13586", "abs": "https://arxiv.org/abs/2507.13586", "authors": ["Kaiyuan Tang", "Kuangshi Ai", "Jun Han", "Chaoli Wang"], "title": "TexGS-VolVis: Expressive Scene Editing for Volume Visualization via Textured Gaussian Splatting", "categories": ["cs.GR", "cs.CL", "cs.CV"], "comment": "Accepted by IEEE VIS 2025", "summary": "Advancements in volume visualization (VolVis) focus on extracting insights\nfrom 3D volumetric data by generating visually compelling renderings that\nreveal complex internal structures. Existing VolVis approaches have explored\nnon-photorealistic rendering techniques to enhance the clarity, expressiveness,\nand informativeness of visual communication. While effective, these methods\noften rely on complex predefined rules and are limited to transferring a single\nstyle, restricting their flexibility. To overcome these limitations, we\nadvocate the representation of VolVis scenes using differentiable Gaussian\nprimitives combined with pretrained large models to enable arbitrary style\ntransfer and real-time rendering. However, conventional 3D Gaussian primitives\ntightly couple geometry and appearance, leading to suboptimal stylization\nresults. To address this, we introduce TexGS-VolVis, a textured Gaussian\nsplatting framework for VolVis. TexGS-VolVis employs 2D Gaussian primitives,\nextending each Gaussian with additional texture and shading attributes,\nresulting in higher-quality, geometry-consistent stylization and enhanced\nlighting control during inference. Despite these improvements, achieving\nflexible and controllable scene editing remains challenging. To further enhance\nstylization, we develop image- and text-driven non-photorealistic scene editing\ntailored for TexGS-VolVis and 2D-lift-3D segmentation to enable partial editing\nwith fine-grained control. We evaluate TexGS-VolVis both qualitatively and\nquantitatively across various volume rendering scenes, demonstrating its\nsuperiority over existing methods in terms of efficiency, visual quality, and\nediting flexibility.", "AI": {"tldr": "TexGS-VolVis enhances volume visualization with textured Gaussian splatting and enables advanced editing capabilities using 2D and pretrained large models to allow superior stylization and rendering.", "motivation": "Traditional volume visualization techniques lack flexibility in style transfer and rely on complex predefined rules, which limits their adaptability and quality.", "method": "TexGS-VolVis introduces textured 2D Gaussian primitives paired with pretrained models for arbitrary style transfer and real-time rendering. It enables image- and text-driven scene editing and improved stylization using a segmentation method called 2D-lift-3D.", "result": "This framework achieves improved visual quality, efficient rendering, and advanced editing capabilities, outperforming existing methods.", "conclusion": "TexGS-VolVis represents a significant improvement in volume visualization by offering higher-quality stylization, better lighting control, and detailed scene editing."}}
{"id": "2507.13772", "pdf": "https://arxiv.org/pdf/2507.13772", "abs": "https://arxiv.org/abs/2507.13772", "authors": ["Abhijit Sen", "Giridas Maiti", "Bikram K. Parida", "Bhanu P. Mishra", "Mahima Arya", "Denys I. Bondar"], "title": "Feature Engineering is Not Dead: Reviving Classical Machine Learning with Entropy, HOG, and LBP Feature Fusion for Image Classification", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Feature engineering continues to play a critical role in image\nclassification, particularly when interpretability and computational efficiency\nare prioritized over deep learning models with millions of parameters. In this\nstudy, we revisit classical machine learning based image classification through\na novel approach centered on Permutation Entropy (PE), a robust and\ncomputationally lightweight measure traditionally used in time series analysis\nbut rarely applied to image data. We extend PE to two-dimensional images and\npropose a multiscale, multi-orientation entropy-based feature extraction\napproach that characterizes spatial order and complexity along rows, columns,\ndiagonals, anti-diagonals, and local patches of the image. To enhance the\ndiscriminatory power of the entropy features, we integrate two classic image\ndescriptors: the Histogram of Oriented Gradients (HOG) to capture shape and\nedge structure, and Local Binary Patterns (LBP) to encode micro-texture of an\nimage. The resulting hand-crafted feature set, comprising of 780 dimensions, is\nused to train Support Vector Machine (SVM) classifiers optimized through grid\nsearch. The proposed approach is evaluated on multiple benchmark datasets,\nincluding Fashion-MNIST, KMNIST, EMNIST, and CIFAR-10, where it delivers\ncompetitive classification performance without relying on deep architectures.\nOur results demonstrate that the fusion of PE with HOG and LBP provides a\ncompact, interpretable, and effective alternative to computationally expensive\nand limited interpretable deep learning models. This shows a potential of\nentropy-based descriptors in image classification and contributes a lightweight\nand generalizable solution to interpretable machine learning in image\nclassification and computer vision.", "AI": {"tldr": "This paper proposes a novel entropy-based feature extraction method for image classification, combining Permutation Entropy (PE), Histogram of Oriented Gradients (HOG), and Local Binary Patterns (LBP).", "motivation": "The study aims to provide an interpretable and computationally efficient alternative to deep learning models, which often require significant computational resources and lack interpretability.", "method": "The method involves extending Permutation Entropy (PE) to 2D images, extracting features across multiple scales and orientations, and integrating these features with HOG and LBP. These handcrafted features are trained with Support Vector Machines (SVM) optimized via grid search.", "result": "The approach achieves competitive performance on benchmark datasets such as Fashion-MNIST, KMNIST, EMNIST, and CIFAR-10, without relying on deep learning architectures.", "conclusion": "Fusion of entropy-based features with HOG and LBP provides a compact, effective, and interpretable solution for image classification, serving as an alternative to computationally expensive and less interpretable deep models."}}
{"id": "2507.14066", "pdf": "https://arxiv.org/pdf/2507.14066", "abs": "https://arxiv.org/abs/2507.14066", "authors": ["Ni Mu", "Yao Luan", "Qing-Shan Jia"], "title": "Preference-based Multi-Objective Reinforcement Learning", "categories": ["cs.LG"], "comment": "This article has been accepted for publication in IEEE Transactions\n  on Automation Science and Engineering. This is the author's version, which\n  has not been fully edited, and the content may change prior to final\n  publication. \\c{opyright} 2025 IEEE. All rights reserved, including rights\n  for text and data mining and training of artificial intelligence and similar\n  technologies", "summary": "Multi-objective reinforcement learning (MORL) is a structured approach for\noptimizing tasks with multiple objectives. However, it often relies on\npre-defined reward functions, which can be hard to design for balancing\nconflicting goals and may lead to oversimplification. Preferences can serve as\nmore flexible and intuitive decision-making guidance, eliminating the need for\ncomplicated reward design. This paper introduces preference-based MORL\n(Pb-MORL), which formalizes the integration of preferences into the MORL\nframework. We theoretically prove that preferences can derive policies across\nthe entire Pareto frontier. To guide policy optimization using preferences, our\nmethod constructs a multi-objective reward model that aligns with the given\npreferences. We further provide theoretical proof to show that optimizing this\nreward model is equivalent to training the Pareto optimal policy. Extensive\nexperiments in benchmark multi-objective tasks, a multi-energy management task,\nand an autonomous driving task on a multi-line highway show that our method\nperforms competitively, surpassing the oracle method, which uses the ground\ntruth reward function. This highlights its potential for practical applications\nin complex real-world systems.", "AI": {"tldr": "The paper introduces preference-based multi-objective reinforcement learning (Pb-MORL), integrating preferences into MORL to optimize policies across Pareto frontiers effectively, outperforming traditional methods in complex tasks.", "motivation": "To address complexities in designing reward functions for balancing competing objectives in multi-objective tasks and to leverage preferences as a more intuitive alternative.", "method": "The method involves formalizing preferences into the MORL framework, constructing a multi-objective reward model aligned with preferences, and optimizing this model theoretically equivalent to finding Pareto optimal policies.", "result": "The proposed method demonstrated competitive results, outperforming methods relying on ground truth reward functions across benchmark tasks, multi-energy management, and autonomous driving scenarios.", "conclusion": "Preference-based MORL is effective for real-world applications, proving its ability to derive optimal policies across Pareto frontiers, surpassing traditional approaches in practical scenarios."}}
{"id": "2507.13773", "pdf": "https://arxiv.org/pdf/2507.13773", "abs": "https://arxiv.org/abs/2507.13773", "authors": ["Pu Jian", "Donglei Yu", "Wen Yang", "Shuo Ren", "Jiajun Zhang"], "title": "Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions", "categories": ["cs.CV", "cs.CL"], "comment": "ACL2025 Main", "summary": "In visual question answering (VQA) context, users often pose ambiguous\nquestions to visual language models (VLMs) due to varying expression habits.\nExisting research addresses such ambiguities primarily by rephrasing questions.\nThese approaches neglect the inherently interactive nature of user interactions\nwith VLMs, where ambiguities can be clarified through user feedback. However,\nresearch on interactive clarification faces two major challenges: (1)\nBenchmarks are absent to assess VLMs' capacity for resolving ambiguities\nthrough interaction; (2) VLMs are trained to prefer answering rather than\nasking, preventing them from seeking clarification. To overcome these\nchallenges, we introduce \\textbf{ClearVQA} benchmark, which targets three\ncommon categories of ambiguity in VQA context, and encompasses various VQA\nscenarios.", "AI": {"tldr": "The paper introduces ClearVQA, a benchmark addressing ambiguities in visual question answering (VQA) by focusing on interactive user clarification, rather than solely on rephrasing questions.", "motivation": "Existing VLM-based VQA systems struggle with ambiguous user questions due to differences in user expression habits. Current methods fail to consider the value of interactive feedback in resolving ambiguities.", "method": "The authors propose ClearVQA, a benchmark designed to assess VLMs' abilities to resolve VQA ambiguities through interactive clarification. It targets three common categories of ambiguity across various VQA scenarios.", "result": "ClearVQA provides a standardized way to evaluate how well VLMs interact with users to understand ambiguous queries.", "conclusion": "ClearVQA addresses the limitations in existing VQA approaches by emphasizing interactive clarification, paving the way for more user-centric and effective VLM applications."}}
{"id": "2507.14088", "pdf": "https://arxiv.org/pdf/2507.14088", "abs": "https://arxiv.org/abs/2507.14088", "authors": ["Xiyun Li", "Yining Ding", "Yuhua Jiang", "Yunlong Zhao", "Runpeng Xie", "Shuang Xu", "Yuanhua Ni", "Yiqin Yang", "Bo Xu"], "title": "DPMT: Dual Process Multi-scale Theory of Mind Framework for Real-time Human-AI Collaboration", "categories": ["cs.LG"], "comment": null, "summary": "Real-time human-artificial intelligence (AI) collaboration is crucial yet\nchallenging, especially when AI agents must adapt to diverse and unseen human\nbehaviors in dynamic scenarios. Existing large language model (LLM) agents\noften fail to accurately model the complex human mental characteristics such as\ndomain intentions, especially in the absence of direct communication. To\naddress this limitation, we propose a novel dual process multi-scale theory of\nmind (DPMT) framework, drawing inspiration from cognitive science dual process\ntheory. Our DPMT framework incorporates a multi-scale theory of mind (ToM)\nmodule to facilitate robust human partner modeling through mental\ncharacteristic reasoning. Experimental results demonstrate that DPMT\nsignificantly enhances human-AI collaboration, and ablation studies further\nvalidate the contributions of our multi-scale ToM in the slow system.", "AI": {"tldr": "The paper presents the DPMT framework, which improves human-AI collaboration by employing cognitive science-based dual process theory and multi-scale theory of mind.", "motivation": "The motivation of the paper is to address limitations in AI agents, particularly large language models, that fail to accurately model complex human mental characteristics and adapt effectively to diverse behaviors in dynamic scenarios.", "method": "The proposed method is the DPMT framework, which uses dual process theory from cognitive science and incorporates a multi-scale theory of mind (ToM) module for better mental characteristic reasoning and human partner modeling.", "result": "Experimental results show that the DPMT framework significantly improves collaboration between humans and AI agents. Ablation studies also support the effectiveness of the multi-scale ToM component.", "conclusion": "The DPMT framework represents a meaningful advancement in enhancing human-AI interaction by leveraging cognitive science principles for better adaptation and understanding of human behaviors."}}
{"id": "2507.13459", "pdf": "https://arxiv.org/pdf/2507.13459", "abs": "https://arxiv.org/abs/2507.13459", "authors": ["Vijay K. Dubey", "Collin E. Haese", "Osman G\u00fcltekin", "David Dalton", "Manuel K. Rausch", "Jan N. Fuhg"], "title": "Graph Neural Network Surrogates for Contacting Deformable Bodies with Necessary and Sufficient Contact Detection", "categories": ["cs.CE", "cs.AI", "cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Surrogate models for the rapid inference of nonlinear boundary value problems\nin mechanics are helpful in a broad range of engineering applications. However,\neffective surrogate modeling of applications involving the contact of\ndeformable bodies, especially in the context of varying geometries, is still an\nopen issue. In particular, existing methods are confined to rigid body contact\nor, at best, contact between rigid and soft objects with well-defined contact\nplanes. Furthermore, they employ contact or collision detection filters that\nserve as a rapid test but use only the necessary and not sufficient conditions\nfor detection. In this work, we present a graph neural network architecture\nthat utilizes continuous collision detection and, for the first time,\nincorporates sufficient conditions designed for contact between soft deformable\nbodies. We test its performance on two benchmarks, including a problem in soft\ntissue mechanics of predicting the closed state of a bioprosthetic aortic\nvalve. We find a regularizing effect on adding additional contact terms to the\nloss function, leading to better generalization of the network. These benefits\nhold for simple contact at similar planes and element normal angles, and\ncomplex contact at differing planes and element normal angles. We also\ndemonstrate that the framework can handle varying reference geometries.\nHowever, such benefits come with high computational costs during training,\nresulting in a trade-off that may not always be favorable. We quantify the\ntraining cost and the resulting inference speedups on various hardware\narchitectures. Importantly, our graph neural network implementation results in\nup to a thousand-fold speedup for our benchmark problems at inference.", "AI": {"tldr": "The paper introduces a graph neural network for modeling contact in deformable bodies, achieving a 1000x speedup during inference for tested scenarios.", "motivation": "Current surrogate models for contact mechanics lack effectiveness in cases involving soft, deformable bodies, especially with varying geometries.", "method": "The study proposes a graph neural network architecture with continuous collision detection and sufficient conditions for soft body contacts, and examines its performance on benchmark scenarios, including a bioprosthetic aortic valve application.", "result": "The neural network demonstrated improved generalization by adding contact terms to the loss function. It handled varying geometries effectively but came with high computational training costs, leading to a significant trade-off.", "conclusion": "While the proposed method offers excellent inference speedups and flexibility, its high training cost may limit its broader applicability."}}
{"id": "2507.13779", "pdf": "https://arxiv.org/pdf/2507.13779", "abs": "https://arxiv.org/abs/2507.13779", "authors": ["Durgesh Singh", "Ahc\u00e8ne Boubekki", "Robert Jenssen", "Michael Kampffmeyer"], "title": "SuperCM: Improving Semi-Supervised Learning and Domain Adaptation through differentiable clustering", "categories": ["cs.CV"], "comment": null, "summary": "Semi-Supervised Learning (SSL) and Unsupervised Domain Adaptation (UDA)\nenhance the model performance by exploiting information from labeled and\nunlabeled data. The clustering assumption has proven advantageous for learning\nwith limited supervision and states that data points belonging to the same\ncluster in a high-dimensional space should be assigned to the same category.\nRecent works have utilized different training mechanisms to implicitly enforce\nthis assumption for the SSL and UDA. In this work, we take a different approach\nby explicitly involving a differentiable clustering module which is extended to\nleverage the supervised data to compute its centroids. We demonstrate the\neffectiveness of our straightforward end-to-end training strategy for SSL and\nUDA over extensive experiments and highlight its benefits, especially in low\nsupervision regimes, both as a standalone model and as a regularizer for\nexisting approaches.", "AI": {"tldr": "This paper introduces a differentiable clustering module explicitly enforcing the clustering assumption, enhancing end-to-end training for SSL and UDA.", "motivation": "To improve SSL and UDA by explicitly enforcing the clustering assumption using a differentiable clustering mechanism.", "method": "The approach involves integrating an explicit differentiable clustering module extended to use supervised data for centroid computation.", "result": "Extensive experiments show the method performs well in low supervision regimes and complements existing models as a regularizer.", "conclusion": "The proposed technique is effective in boosting SSL and UDA, especially under limited supervision, and can enhance existing methods."}}
{"id": "2507.14121", "pdf": "https://arxiv.org/pdf/2507.14121", "abs": "https://arxiv.org/abs/2507.14121", "authors": ["Pankaj Yadav", "Vivek Vijay"], "title": "Kolmogorov Arnold Networks (KANs) for Imbalanced Data -- An Empirical Perspective", "categories": ["cs.LG", "cs.AI"], "comment": "9 Pages, 4 figures", "summary": "Kolmogorov Arnold Networks (KANs) are recent architectural advancement in\nneural computation that offer a mathematically grounded alternative to standard\nneural networks. This study presents an empirical evaluation of KANs in context\nof class imbalanced classification, using ten benchmark datasets. We observe\nthat KANs can inherently perform well on raw imbalanced data more effectively\nthan Multi-Layer Perceptrons (MLPs) without any resampling strategy. However,\nconventional imbalance strategies fundamentally conflict with KANs mathematical\nstructure as resampling and focal loss implementations significantly degrade\nKANs performance, while marginally benefiting MLPs. Crucially, KANs suffer from\nprohibitive computational costs without proportional performance gains.\nStatistical validation confirms that MLPs with imbalance techniques achieve\nequivalence with KANs (|d| < 0.08 across metrics) at minimal resource costs.\nThese findings reveal that KANs represent a specialized solution for raw\nimbalanced data where resources permit. But their severe performance-resource\ntradeoffs and incompatibility with standard resampling techniques currently\nlimits practical deployment. We identify critical research priorities as\ndeveloping KAN specific architectural modifications for imbalance learning,\noptimizing computational efficiency, and theoretical reconciling their conflict\nwith data augmentation. This work establishes foundational insights for next\ngeneration KAN architectures in imbalanced classification scenarios.", "AI": {"tldr": "The paper evaluates Kolmogorov-Arnold Networks (KANs) in class-imbalanced classification, finding that they perform well on raw imbalanced datasets but face computational challenges and are incompatible with conventional imbalance strategies.", "motivation": "To assess the practicality and limitations of Kolmogorov-Arnold Networks (KANs) compared to Multi-Layer Perceptrons (MLPs) in addressing imbalanced classification problems.", "method": "An empirical study was conducted using KANs and MLPs on ten benchmark datasets, comparing their performance on raw imbalanced data and with resampling strategies or focal loss.", "result": "KANs showed strong performance on raw imbalanced data compared to MLPs but deteriorated with imbalance strategies. MLPs achieved similar performance to KANs with lower resource requirements when imbalance techniques were applied.", "conclusion": "KANs excel in raw imbalanced data but are resource-intensive and incompatible with conventional resampling techniques, highlighting the need for architectural and efficiency improvements for broader practical use."}}
{"id": "2507.13789", "pdf": "https://arxiv.org/pdf/2507.13789", "abs": "https://arxiv.org/abs/2507.13789", "authors": ["Kyriakos Flouris", "Moritz Halter", "Yolanne Y. R. Lee", "Samuel Castonguay", "Luuk Jacobs", "Pietro Dirix", "Jonathan Nestmann", "Sebastian Kozerke", "Ender Konukoglu"], "title": "Localized FNO for Spatiotemporal Hemodynamic Upsampling in Aneurysm MRI", "categories": ["cs.CV", "cs.AI", "physics.comp-ph"], "comment": null, "summary": "Hemodynamic analysis is essential for predicting aneurysm rupture and guiding\ntreatment. While magnetic resonance flow imaging enables time-resolved\nvolumetric blood velocity measurements, its low spatiotemporal resolution and\nsignal-to-noise ratio limit its diagnostic utility. To address this, we propose\nthe Localized Fourier Neural Operator (LoFNO), a novel 3D architecture that\nenhances both spatial and temporal resolution with the ability to predict wall\nshear stress (WSS) directly from clinical imaging data. LoFNO integrates\nLaplacian eigenvectors as geometric priors for improved structural awareness on\nirregular, unseen geometries and employs an Enhanced Deep Super-Resolution\nNetwork (EDSR) layer for robust upsampling. By combining geometric priors with\nneural operator frameworks, LoFNO de-noises and spatiotemporally upsamples flow\ndata, achieving superior velocity and WSS predictions compared to interpolation\nand alternative deep learning methods, enabling more precise cerebrovascular\ndiagnostics.", "AI": {"tldr": "This study introduces LoFNO, a novel 3D architecture to improve resolution and accuracy of aneurysm hemodynamic analysis from clinical imaging.", "motivation": "Low spatiotemporal resolution and poor signal-to-noise ratio in magnetic resonance flow imaging limit its use in diagnosing aneurysms and predicting rupture.", "method": "The study develops LoFNO, which combines geometric priors, Laplacian eigenvectors, and a deep super-resolution network for enhanced flow data processing.", "result": "LoFNO achieves superior velocity and wall shear stress (WSS) predictions compared to traditional methods, offering improved cerebrovascular diagnostics.", "conclusion": "LoFNO advances aneurysm diagnosis by accurately enhancing spatial and temporal resolution and predicting WSS directly from clinical imaging data."}}
{"id": "2507.13822", "pdf": "https://arxiv.org/pdf/2507.13822", "abs": "https://arxiv.org/abs/2507.13822", "authors": ["Shad Nygren", "Pinar Avci", "Andre Daniels", "Reza Rassol", "Afshin Beheshti", "Diego Galeano"], "title": "RAG-based Architectures for Drug Side Effect Retrieval in LLMs", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "Drug side effects are a major global health concern, necessitating advanced\nmethods for their accurate detection and analysis. While Large Language Models\n(LLMs) offer promising conversational interfaces, their inherent limitations,\nincluding reliance on black-box training data, susceptibility to\nhallucinations, and lack of domain-specific knowledge, hinder their reliability\nin specialized fields like pharmacovigilance. To address this gap, we propose\ntwo architectures: Retrieval-Augmented Generation (RAG) and GraphRAG, which\nintegrate comprehensive drug side effect knowledge into a Llama 3 8B language\nmodel. Through extensive evaluations on 19,520 drug side effect associations\n(covering 976 drugs and 3,851 side effect terms), our results demonstrate that\nGraphRAG achieves near-perfect accuracy in drug side effect retrieval. This\nframework offers a highly accurate and scalable solution, signifying a\nsignificant advancement in leveraging LLMs for critical pharmacovigilance\napplications.", "AI": {"tldr": "The paper introduces two architectures, RAG and GraphRAG, which integrate drug side effect knowledge into an LLM (Llama 3 8B), achieving near-perfect accuracy for drug side effect associations.", "motivation": "Drug side effects are a global health issue, and current LLMs lack reliability in pharmacovigilance due to limitations like hallucinations and the absence of domain-specific expertise.", "method": "Two architectures, Retrieval-Augmented Generation (RAG) and GraphRAG, incorporate extensive drug side effect knowledge into the Llama 3 8B language model and undergo evaluation using 19,520 drug-side effect associations.", "result": "GraphRAG demonstrated near-perfect accuracy in retrieving drug side effect associations, covering 976 drugs and 3,851 side effect terms.", "conclusion": "The proposed architectures exemplify the potential for highly accurate and scalable pharmacovigilance solutions through domain-specific adaptations of LLMs."}}
{"id": "2507.13797", "pdf": "https://arxiv.org/pdf/2507.13797", "abs": "https://arxiv.org/abs/2507.13797", "authors": ["Huu-Phu Do", "Yu-Wei Chen", "Yi-Cheng Liao", "Chi-Wei Hsiao", "Han-Yang Wang", "Wei-Chen Chiu", "Ching-Chun Huang"], "title": "DynFaceRestore: Balancing Fidelity and Quality in Diffusion-Guided Blind Face Restoration with Dynamic Blur-Level Mapping and Guidance", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "Blind Face Restoration aims to recover high-fidelity, detail-rich facial\nimages from unknown degraded inputs, presenting significant challenges in\npreserving both identity and detail. Pre-trained diffusion models have been\nincreasingly used as image priors to generate fine details. Still, existing\nmethods often use fixed diffusion sampling timesteps and a global guidance\nscale, assuming uniform degradation. This limitation and potentially imperfect\ndegradation kernel estimation frequently lead to under- or over-diffusion,\nresulting in an imbalance between fidelity and quality. We propose\nDynFaceRestore, a novel blind face restoration approach that learns to map any\nblindly degraded input to Gaussian blurry images. By leveraging these blurry\nimages and their respective Gaussian kernels, we dynamically select the\nstarting timesteps for each blurry image and apply closed-form guidance during\nthe diffusion sampling process to maintain fidelity. Additionally, we introduce\na dynamic guidance scaling adjuster that modulates the guidance strength across\nlocal regions, enhancing detail generation in complex areas while preserving\nstructural fidelity in contours. This strategy effectively balances the\ntrade-off between fidelity and quality. DynFaceRestore achieves\nstate-of-the-art performance in both quantitative and qualitative evaluations,\ndemonstrating robustness and effectiveness in blind face restoration.", "AI": {"tldr": "The paper introduces DynFaceRestore, a novel technique for blind face restoration, addressing challenges in balancing fidelity and detail preservation using dynamic adjustments during diffusion sampling.", "motivation": "The motivation is to improve the performance of blind face restoration, which struggles with balancing identity fidelity and detail preservation, especially under non-uniform degradation assumptions.", "method": "It proposes a dynamic system using blurry image mapping, Gaussian kernel extraction, and localized guidance adjustments during diffusion sampling to balance fidelity and detail generation.", "result": "DynFaceRestore achieved state-of-the-art results in both quantitative and qualitative tests, showcasing robust blind face restoration capabilities.", "conclusion": "The approach effectively addresses the limitations of previous methods, offering a refined balance between fidelity and quality through adaptive modeling and control mechanisms."}}
{"id": "2507.12182", "pdf": "https://arxiv.org/pdf/2507.12182", "abs": "https://arxiv.org/abs/2507.12182", "authors": ["Ievgenii Afanasiev", "Leonid Berlyand", "Mariia Kiyashko"], "title": "Asymptotic behavior of eigenvalues of large rank perturbations of large random matrices", "categories": ["math-ph", "cs.LG", "math.MP", "math.PR", "60B20, 15B52"], "comment": "14 pages, 3 figures", "summary": "The paper is concerned with deformed Wigner random matrices. These matrices\nare closely connected with Deep Neural Networks (DNNs): weight matrices of\ntrained DNNs could be represented in the form $R + S$, where $R$ is random and\n$S$ is highly correlated. The spectrum of such matrices plays a key role in\nrigorous underpinning of the novel pruning technique based on Random Matrix\nTheory. Mathematics has been done only for finite-rank matrix $S$. However, in\npractice rank may grow. In this paper we develop asymptotic analysis for the\ncase of growing rank.", "AI": {"tldr": "The paper explores deformed Wigner random matrices, crucial for understanding deep neural networks (DNNs) and novel pruning techniques, focusing on the case of growing rank.", "motivation": "The study is motivated by the need to rigorously understand the mathematical foundation of novel pruning techniques in DNNs, where weight matrices combine random and highly correlated components.", "method": "The paper employs asymptotic analysis to extend mathematical understanding of deformed Wigner matrices to scenarios where the rank of the correlated component grows.", "result": "Results provide theoretical insights and mathematical tools to analyze growing-rank deformed Wigner random matrices, contributing to DNN pruning techniques.", "conclusion": "The findings offer broader mathematical underpinning for studying DNN weight matrices and improving methods like pruning by addressing challenges associated with growing rank."}}
{"id": "2507.13859", "pdf": "https://arxiv.org/pdf/2507.13859", "abs": "https://arxiv.org/abs/2507.13859", "authors": ["Aleksandr Gashkov", "Aleksandr Perevalov", "Maria Eltsova", "Andreas Both"], "title": "SPARQL Query Generation with LLMs: Measuring the Impact of Training Data Memorization and Knowledge Injection", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": "Winner of Best Paper Award at the 25th International Conference on\n  Web Engineering (ICWE 2025)", "summary": "Nowadays, the importance of software with natural-language user interfaces\ncannot be underestimated. In particular, in Question Answering (QA) systems,\ngenerating a SPARQL query for a given natural-language question (often named\nQuery Building) from the information retrieved from the same question is the\ncentral task of QA systems working over Knowledge Graphs (KGQA). Due to the\nrise of Large Language Models (LLMs), they are considered a well-suited method\nto increase the quality of the question-answering functionality, as there is\nstill a lot of room for improvement, aiming for enhanced quality and\ntrustworthiness. However, LLMs are trained on web data, where researchers have\nno control over whether the benchmark or the knowledge graph was already\nincluded in the training data. In this paper, we introduce a novel method that\nevaluates the quality of LLMs by generating a SPARQL query from a\nnatural-language question under various conditions: (1) zero-shot SPARQL\ngeneration, (2) with knowledge injection, and (3) with \"anonymized\" knowledge\ninjection. This enables us, for the first time, to estimate the influence of\nthe training data on the QA quality improved by LLMs. Ultimately, this will\nhelp to identify how portable a method is or whether good results might mostly\nbe achieved because a benchmark was already included in the training data (cf.\nLLM memorization). The developed method is portable, robust, and supports any\nknowledge graph; therefore, it could be easily applied to any KGQA or LLM,\ns.t., generating consistent insights into the actual LLM capabilities is\npossible.", "AI": {"tldr": "This paper proposes a method to evaluate the SPARQL query generation capability of large language models (LLMs) for Question Answering systems via three experimental conditions: zero-shot, with knowledge injection, and anonymized knowledge injection.", "motivation": "The motivation is to assess and enhance the quality, trustworthiness, and portability of natural-language-based Question Answering systems while addressing concerns over uncontrolled LLM training data that might already include benchmark or knowledge graph information.", "method": "The authors introduce a method to evaluate LLM performance by generating SPARQL queries under three testing scenarios: zero-shot, with prior knowledge injection, and with anonymized knowledge injection. This is to determine the impact of training data memorization on QA performance.", "result": "The results enable researchers to differentiate between model portability and performance reliance on prior exposure to benchmarks data during training, providing insights into LLM effectiveness for QA tasks.", "conclusion": "The proposed method is robust, adaptable for various knowledge graphs, and offers a framework to critically analyze LLM capabilities, unveiling whether strong performance stems from memorization or genuine reasoning and understanding."}}
{"id": "2507.13801", "pdf": "https://arxiv.org/pdf/2507.13801", "abs": "https://arxiv.org/abs/2507.13801", "authors": ["Haoang Lu", "Yuanqi Su", "Xiaoning Zhang", "Hao Hu"], "title": "One Step Closer: Creating the Future to Boost Monocular Semantic Scene Completion", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In recent years, visual 3D Semantic Scene Completion (SSC) has emerged as a\ncritical perception task for autonomous driving due to its ability to infer\ncomplete 3D scene layouts and semantics from single 2D images. However, in\nreal-world traffic scenarios, a significant portion of the scene remains\noccluded or outside the camera's field of view -- a fundamental challenge that\nexisting monocular SSC methods fail to address adequately. To overcome these\nlimitations, we propose Creating the Future SSC (CF-SSC), a novel temporal SSC\nframework that leverages pseudo-future frame prediction to expand the model's\neffective perceptual range. Our approach combines poses and depths to establish\naccurate 3D correspondences, enabling geometrically-consistent fusion of past,\npresent, and predicted future frames in 3D space. Unlike conventional methods\nthat rely on simple feature stacking, our 3D-aware architecture achieves more\nrobust scene completion by explicitly modeling spatial-temporal relationships.\nComprehensive experiments on SemanticKITTI and SSCBench-KITTI-360 benchmarks\ndemonstrate state-of-the-art performance, validating the effectiveness of our\napproach, highlighting our method's ability to improve occlusion reasoning and\n3D scene completion accuracy.", "AI": {"tldr": "This paper proposes Creating the Future SSC (CF-SSC), a novel framework for 3D Semantic Scene Completion (SSC) using pseudo-future frame prediction for better handling of occlusions and limited camera fields of view.", "motivation": "Existing monocular SSC methods struggle with occlusions and the limited field of view in real-world traffic scenarios during autonomous driving.", "method": "The method uses pseudo-future frame prediction and geometrically-consistent fusion of past, present, and predicted future frames in 3D space. A 3D-aware architecture is employed to model spatial-temporal relationships.", "result": "CF-SSC achieves state-of-the-art performance on benchmarks like SemanticKITTI and SSCBench-KITTI-360, improving occlusion reasoning and 3D scene completion accuracy.", "conclusion": "The proposed temporal SSC framework expands perceptual capabilities and sets a new standard for handling occlusions and improving scene completion in autonomous driving applications."}}
{"id": "2507.13505", "pdf": "https://arxiv.org/pdf/2507.13505", "abs": "https://arxiv.org/abs/2507.13505", "authors": ["Steven Lamp", "Jason D. Hiser", "Anh Nguyen-Tuong", "Jack W. Davidson"], "title": "PHASE: Passive Human Activity Simulation Evaluation", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.NI"], "comment": null, "summary": "Cybersecurity simulation environments, such as cyber ranges, honeypots, and\nsandboxes, require realistic human behavior to be effective, yet no\nquantitative method exists to assess the behavioral fidelity of synthetic user\npersonas. This paper presents PHASE (Passive Human Activity Simulation\nEvaluation), a machine learning framework that analyzes Zeek connection logs\nand distinguishes human from non-human activity with over 90\\% accuracy. PHASE\noperates entirely passively, relying on standard network monitoring without any\nuser-side instrumentation or visible signs of surveillance. All network\nactivity used for machine learning is collected via a Zeek network appliance to\navoid introducing unnecessary network traffic or artifacts that could disrupt\nthe fidelity of the simulation environment. The paper also proposes a novel\nlabeling approach that utilizes local DNS records to classify network traffic,\nthereby enabling machine learning analysis. Furthermore, we apply SHAP (SHapley\nAdditive exPlanations) analysis to uncover temporal and behavioral signatures\nindicative of genuine human users. In a case study, we evaluate a synthetic\nuser persona and identify distinct non-human patterns that undermine behavioral\nrealism. Based on these insights, we develop a revised behavioral configuration\nthat significantly improves the human-likeness of synthetic activity yielding a\nmore realistic and effective synthetic user persona.", "AI": {"tldr": "This paper introduces PHASE, a machine learning framework that distinguishes human from non-human activity in cybersecurity simulations with over 90% accuracy using network logs.", "motivation": "Cybersecurity simulation environments lack a quantitative method to assess the behavioral fidelity of synthetic user personas.", "method": "PHASE uses passive machine learning analysis of network logs collected via Zeek appliances, combined with a DNS-based labeling approach. SHAP analysis is employed to identify human-like behavioral signatures.", "result": "PHASE accurately classified human versus synthetic activity, identified non-human patterns, and informed improvements for synthetic user configurations.", "conclusion": "PHASE enhances the realism of synthetic user personas in cybersecurity simulations, supporting improved simulation effectiveness and reliability."}}
{"id": "2507.13933", "pdf": "https://arxiv.org/pdf/2507.13933", "abs": "https://arxiv.org/abs/2507.13933", "authors": ["Sichang \"Steven\" He", "Ramesh Govindan", "Harsha V. Madhyastha"], "title": "Preprint: Did I Just Browse A Website Written by LLMs?", "categories": ["cs.NI", "cs.AI", "cs.CL", "cs.IR"], "comment": "In submission. 2 pages. 3 figures", "summary": "Increasingly, web content is automatically generated by large language models\n(LLMs) with little human input. We call this \"LLM-dominant\" content. Since LLMs\nplagiarize and hallucinate, LLM-dominant content can be unreliable and\nunethical. Yet, websites rarely disclose such content, and human readers\nstruggle to distinguish it. Thus, we must develop reliable detectors for\nLLM-dominant content. However, state-of-the-art LLM detectors are insufficient,\nbecause they perform well mainly on clean, prose-like text, while web content\nhas complex markup and diverse genres.\n  We propose a highly reliable, scalable pipeline that classifies entire\nwebsites. Instead of naively classifying text extracted from each page, we\nclassify each site based on an LLM text detector's outputs of multiple\nprose-like pages. We train and evaluate our detector by collecting 2 distinct\nground truth datasets totaling 120 sites, and obtain 100% accuracies testing\nacross them. In the wild, we detect a sizable portion of sites as LLM-dominant\namong 10k sites in search engine results and 10k in Common Crawl archives. We\nfind LLM-dominant sites are growing in prevalence and rank highly in search\nresults, raising questions about their impact on end users and the overall Web\necosystem.", "AI": {"tldr": "The paper highlights the prevalence of automatically generated web content by large language models (LLMs) and introduces a scalable pipeline for detecting such content at the website level, demonstrating high accuracy in experiments.", "motivation": "LLMs are producing increasingly dominant web content, but such content can be unreliable and unethical due to plagiarism and hallucinations. There is a need to reliably detect such content since it is often undisclosed and hard for humans to recognize.", "method": "The proposed method involves a scalable pipeline that classifies entire websites based on an LLM text detector's outputs from multiple prose-like pages. The pipeline is trained and tested using two diverse datasets comprising 120 sites, achieving perfect accuracy on them.", "result": "The pipeline demonstrates 100% accuracy across two datasets in detecting LLM-dominant sites. When applied to 10,000 search engine results and 10,000 Common Crawl sites, it found many LLM-dominant sites, highlighting their growing prevalence and high ranking in search results.", "conclusion": "LLM-dominant content is becoming increasingly common and influential on the web, and the proposed detection method offers a reliable solution to classify and track such content at scale, prompting future considerations for the web's integrity and user impact."}}
{"id": "2507.13803", "pdf": "https://arxiv.org/pdf/2507.13803", "abs": "https://arxiv.org/abs/2507.13803", "authors": ["Weiqi Yang", "Xu Zhou", "Jingfu Guan", "Hao Du", "Tianyu Bai"], "title": "GRAM-MAMBA: Holistic Feature Alignment for Wireless Perception with Adaptive Low-Rank Compensation", "categories": ["cs.CV"], "comment": null, "summary": "Multi-modal fusion is crucial for Internet of Things (IoT) perception, widely\ndeployed in smart homes, intelligent transport, industrial automation, and\nhealthcare. However, existing systems often face challenges: high model\ncomplexity hinders deployment in resource-constrained environments,\nunidirectional modal alignment neglects inter-modal relationships, and\nrobustness suffers when sensor data is missing. These issues impede efficient\nand robust multimodal perception in real-world IoT settings. To overcome these\nlimitations, we propose GRAM-MAMBA. This framework utilizes the\nlinear-complexity Mamba model for efficient sensor time-series processing,\ncombined with an optimized GRAM matrix strategy for pairwise alignment among\nmodalities, addressing the shortcomings of traditional single-modality\nalignment. Inspired by Low-Rank Adaptation (LoRA), we introduce an adaptive\nlow-rank layer compensation strategy to handle missing modalities\npost-training. This strategy freezes the pre-trained model core and irrelevant\nadaptive layers, fine-tuning only those related to available modalities and the\nfusion process. Extensive experiments validate GRAM-MAMBA's effectiveness. On\nthe SPAWC2021 indoor positioning dataset, the pre-trained model shows lower\nerror than baselines; adapting to missing modalities yields a 24.5% performance\nboost by training less than 0.2% of parameters. On the USC-HAD human activity\nrecognition dataset, it achieves 93.55% F1 and 93.81% Overall Accuracy (OA),\noutperforming prior work; the update strategy increases F1 by 23% while\ntraining less than 0.3% of parameters. These results highlight GRAM-MAMBA's\npotential for achieving efficient and robust multimodal perception in\nresource-constrained environments.", "AI": {"tldr": "GRAM-MAMBA enhances IoT multimodal fusion for efficient perception. It employs linear-complexity processing, optimized modality alignment, and adaptive strategies for missing sensor data. Tests show substantial accuracy gains while minimally training parameters.", "motivation": "Current IoT multimodal fusion systems face deployment struggles due to high complexity, weak inter-modal alignment, and vulnerability to missing data.", "method": "The proposed GRAM-MAMBA combines linear complexity models for time-series handling, GRAM matrix-based inter-modal alignment, and LoRA-inspired adaptive low-rank layers to manage missing modalities.", "result": "Experiments showed improved performance metrics: a 24.5% boost in SPAWC2021 dataset and 93.55% F1 score on USC-HAD dataset, by training fewer than 0.3% of model parameters.", "conclusion": "GRAM-MAMBA provides efficient, robust multimodal perception, addressing complexity and missing-data issues in IoT environments effectively."}}
{"id": "2507.13524", "pdf": "https://arxiv.org/pdf/2507.13524", "abs": "https://arxiv.org/abs/2507.13524", "authors": ["Yaomin Jiang", "Levin Brinkmann", "Anne-Marie Nussberger", "Ivan Soraperra", "Jean-Fran\u00e7ois Bonnefon", "Iyad Rahwan"], "title": "Humans learn to prefer trustworthy AI over human partners", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": null, "summary": "Partner selection is crucial for cooperation and hinges on communication. As\nartificial agents, especially those powered by large language models (LLMs),\nbecome more autonomous, intelligent, and persuasive, they compete with humans\nfor partnerships. Yet little is known about how humans select between human and\nAI partners and adapt under AI-induced competition pressure. We constructed a\ncommunication-based partner selection game and examined the dynamics in hybrid\nmini-societies of humans and bots powered by a state-of-the-art LLM. Through\nthree experiments (N = 975), we found that bots, though more prosocial than\nhumans and linguistically distinguishable, were not selected preferentially\nwhen their identity was hidden. Instead, humans misattributed bots' behaviour\nto humans and vice versa. Disclosing bots' identity induced a dual effect: it\nreduced bots' initial chances of being selected but allowed them to gradually\noutcompete humans by facilitating human learning about the behaviour of each\npartner type. These findings show how AI can reshape social interaction in\nmixed societies and inform the design of more effective and cooperative hybrid\nsystems.", "AI": {"tldr": "This paper examines how humans select partners between humans and AI in a communication-based game, finding that bots eventually outcompete humans when their identity is disclosed.", "motivation": "To understand how humans adapt and select partners in mixed societies with humans and AI, especially under the competitive pressure from AI.", "method": "The authors conducted communication-based partner selection games in hybrid mini-societies of humans and LLM-powered bots through three experiments with 975 participants.", "result": "The study found that bots, being prosocial and linguistically distinct yet misattributed by humans, are not initially favored. However, revealing their identity helps them outcompete humans over time by enabling better learning about partner type behavior.", "conclusion": "AI can significantly reshape social dynamics in mixed human-AI societies. Strategic disclosure of bot identity may improve cooperation and guide hybrid system designs."}}
{"id": "2507.13812", "pdf": "https://arxiv.org/pdf/2507.13812", "abs": "https://arxiv.org/abs/2507.13812", "authors": ["Yingying Zhang", "Lixiang Ru", "Kang Wu", "Lei Yu", "Lei Liang", "Yansheng Li", "Jingdong Chen"], "title": "SkySense V2: A Unified Foundation Model for Multi-modal Remote Sensing", "categories": ["cs.CV"], "comment": "Accepted by ICCV25", "summary": "The multi-modal remote sensing foundation model (MM-RSFM) has significantly\nadvanced various Earth observation tasks, such as urban planning, environmental\nmonitoring, and natural disaster management. However, most existing approaches\ngenerally require the training of separate backbone networks for each data\nmodality, leading to redundancy and inefficient parameter utilization.\nMoreover, prevalent pre-training methods typically apply self-supervised\nlearning (SSL) techniques from natural images without adequately accommodating\nthe characteristics of remote sensing (RS) images, such as the complicated\nsemantic distribution within a single RS image. In this work, we present\nSkySense V2, a unified MM-RSFM that employs a single transformer backbone to\nhandle multiple modalities. This backbone is pre-trained with a novel SSL\nstrategy tailored to the distinct traits of RS data. In particular, SkySense V2\nincorporates an innovative adaptive patch merging module and learnable modality\nprompt tokens to address challenges related to varying resolutions and limited\nfeature diversity across modalities. In additional, we incorporate the mixture\nof experts (MoE) module to further enhance the performance of the foundation\nmodel. SkySense V2 demonstrates impressive generalization abilities through an\nextensive evaluation involving 16 datasets over 7 tasks, outperforming SkySense\nby an average of 1.8 points.", "AI": {"tldr": "SkySense V2 introduces a multi-modal remote sensing model that uses a single transformer backbone and novel pre-training strategies to address inefficiencies in current approaches.", "motivation": "To address redundancy and inefficiency caused by separate backbone models per modality in current remote sensing tasks and inadequacy of general self-supervised learning (SSL) approaches for RS data.", "method": "SkySense V2 employs a single transformer backbone with an adaptive patch merging module, learnable modality prompt tokens, a novel SSL approach tailored to remote-sensing data, and incorporates a mixture of experts (MoE) module.", "result": "SkySense V2 showed significant improvements, outperforming its predecessor by an average of 1.8 points across 16 datasets and 7 tasks.", "conclusion": "SkySense V2 unifies multi-modal processing for remote sensing, demonstrating superior generalization and efficiency over existing methods."}}
{"id": "2507.13376", "pdf": "https://arxiv.org/pdf/2507.13376", "abs": "https://arxiv.org/abs/2507.13376", "authors": ["Dong Xiao", "Zahra Sharif-Khodaei", "M. H. Aliabadi"], "title": "Physics-guided impact localisation and force estimation in composite plates with uncertainty quantification", "categories": ["physics.data-an", "cond-mat.mtrl-sci", "cs.LG", "physics.app-ph"], "comment": "37 pages (including the appendix and references), 16 figures", "summary": "Physics-guided approaches offer a promising path toward accurate and\ngeneralisable impact identification in composite structures, especially when\nexperimental data are sparse. This paper presents a hybrid framework for impact\nlocalisation and force estimation in composite plates, combining a data-driven\nimplementation of First-Order Shear Deformation Theory (FSDT) with machine\nlearning and uncertainty quantification. The structural configuration and\nmaterial properties are inferred from dispersion relations, while boundary\nconditions are identified via modal characteristics to construct a low-fidelity\nbut physically consistent FSDT model. This model enables physics-informed data\naugmentation for extrapolative localisation using supervised learning.\nSimultaneously, an adaptive regularisation scheme derived from the same model\nimproves the robustness of impact force reconstruction. The framework also\naccounts for uncertainty by propagating localisation uncertainty through the\nforce estimation process, producing probabilistic outputs. Validation on\ncomposite plate experiments confirms the framework's accuracy, robustness, and\nefficiency in reducing dependence on large training datasets. The proposed\nmethod offers a scalable and transferable solution for impact monitoring and\nstructural health management in composite aerostructures.", "AI": {"tldr": "This paper introduces a hybrid framework combining physics-based modeling with machine learning to accurately localize impacts and estimate forces on composite plates, enabling robust analysis even with limited experimental data.", "motivation": "To improve impact monitoring and structural health management in composite aerostructures, especially when experimental data is sparse.", "method": "The framework integrates First-Order Shear Deformation Theory with supervised learning and uncertainty quantification, allowing for physics-informed data augmentation and adaptive regularization.", "result": "Experimental validation demonstrated accuracy, reduced dependence on extensive training datasets, robustness, and efficiency in impact localization and force estimation.", "conclusion": "This scalable and transferable framework effectively integrates physics-based modeling and machine learning for impact monitoring in composite structures, offering a robust solution for structural health management."}}
{"id": "2507.14119", "pdf": "https://arxiv.org/pdf/2507.14119", "abs": "https://arxiv.org/abs/2507.14119", "authors": ["Maksim Kuprashevich", "Grigorii Alekseenko", "Irina Tolstykh", "Georgii Fedorov", "Bulat Suleimanov", "Vladimir Dokholyan", "Aleksandr Gordeev"], "title": "NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Recent advances in generative modeling enable image editing assistants that\nfollow natural language instructions without additional user input. Their\nsupervised training requires millions of triplets: original image, instruction,\nedited image. Yet mining pixel-accurate examples is hard. Each edit must affect\nonly prompt-specified regions, preserve stylistic coherence, respect physical\nplausibility, and retain visual appeal. The lack of robust automated\nedit-quality metrics hinders reliable automation at scale. We present an\nautomated, modular pipeline that mines high-fidelity triplets across domains,\nresolutions, instruction complexities, and styles. Built on public generative\nmodels and running without human intervention, our system uses a task-tuned\nGemini validator to score instruction adherence and aesthetics directly,\nremoving any need for segmentation or grounding models. Inversion and\ncompositional bootstrapping enlarge the mined set by approximately 2.2x,\nenabling large-scale high-fidelity training data. By automating the most\nrepetitive annotation steps, the approach allows a new scale of training\nwithout human labeling effort. To democratize research in this\nresource-intensive area, we release NHR-Edit: an open dataset of 358k\nhigh-quality triplets. In the largest cross-dataset evaluation, it surpasses\nall public alternatives. We also release Bagel-NHR-Edit, an open-source\nfine-tuned Bagel model, which achieves state-of-the-art metrics in our\nexperiments.", "AI": {"tldr": "The paper presents a pipeline to automate the generation of high-quality triplets for image editing assistants, introduces a novel dataset, and achieves state-of-the-art results using fine-tuned generative models.", "motivation": "The authors aim to address the scarcity of pixel-accurate annotated datasets for training generative image editing models, a process hindered by the lack of automated tools to validate edit quality at scale.", "method": "The authors introduce an automated pipeline that uses generative models and a task-tuned Gemini validator to mine high-quality image-inscription-edited image triplets. Inversion and compositional bootstrapping further amplify the dataset.", "result": "The pipeline produces NHR-Edit, an open dataset of 358k triplets. Cross-dataset evaluation demonstrates its superiority over existing datasets and showcases the performance of Bagel-NHR-Edit, a fine-tuned model achieving state-of-the-art metrics.", "conclusion": "The approach eliminates manual labeling effort, democratizes access to high-quality generative training data, and advances the state-of-the-art in natural language image editing models."}}
{"id": "2507.13820", "pdf": "https://arxiv.org/pdf/2507.13820", "abs": "https://arxiv.org/abs/2507.13820", "authors": ["Jun Xie", "Zhaoran Zhao", "Xiongjun Guan", "Yingjian Zhu", "Hongzhu Yi", "Xinming Wang", "Feng Chen", "Zhepeng Wang"], "title": "Team of One: Cracking Complex Video QA with Model Synergy", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We propose a novel framework for open-ended video question answering that\nenhances reasoning depth and robustness in complex real-world scenarios, as\nbenchmarked on the CVRR-ES dataset. Existing Video-Large Multimodal Models\n(Video-LMMs) often exhibit limited contextual understanding, weak temporal\nmodeling, and poor generalization to ambiguous or compositional queries. To\naddress these challenges, we introduce a prompting-and-response integration\nmechanism that coordinates multiple heterogeneous Video-Language Models (VLMs)\nvia structured chains of thought, each tailored to distinct reasoning pathways.\nAn external Large Language Model (LLM) serves as an evaluator and integrator,\nselecting and fusing the most reliable responses. Extensive experiments\ndemonstrate that our method significantly outperforms existing baselines across\nall evaluation metrics, showcasing superior generalization and robustness. Our\napproach offers a lightweight, extensible strategy for advancing multimodal\nreasoning without requiring model retraining, setting a strong foundation for\nfuture Video-LMM development.", "AI": {"tldr": "The paper presents a new framework for improving video question answering using multilevel integration of multiple Video-Language Models, achieving robust results without retraining.", "motivation": "To address limitations in existing Video-LMMs, such as poor contextual understanding and generalization to complex queries, in real-world scenarios.", "method": "Introduces a multi-step 'prompting-and-response integration' mechanism using chains of thought across diverse models, evaluated by an external Large Language Model.", "result": "Achieved significant improvements and outperformance of baselines in multiple evaluation metrics, demonstrating enhanced generalization and robustness.", "conclusion": "Proposed a lightweight, extensible method for enhancing multimodal reasoning, paving the way for future advancements in this field."}}
{"id": "2507.13543", "pdf": "https://arxiv.org/pdf/2507.13543", "abs": "https://arxiv.org/abs/2507.13543", "authors": ["Alexander Kolpakov"], "title": "Loss-Complexity Landscape and Model Structure Functions", "categories": ["cs.IT", "cs.AI", "cs.LG", "math-ph", "math.IT", "math.MP", "I.2.2; I.2.6"], "comment": "18 pages, 3 figures; GitHub repository at\n  https://github.com/sashakolpakov/structure-functions", "summary": "We develop a framework for dualizing the Kolmogorov structure function\n$h_x(\\alpha)$, which then allows using computable complexity proxies. We\nestablish a mathematical analogy between information-theoretic constructs and\nstatistical mechanics, introducing a suitable partition function and free\nenergy functional. We explicitly prove the Legendre-Fenchel duality between the\nstructure function and free energy, showing detailed balance of the Metropolis\nkernel, and interpret acceptance probabilities as information-theoretic\nscattering amplitudes. A susceptibility-like variance of model complexity is\nshown to peak precisely at loss-complexity trade-offs interpreted as phase\ntransitions. Practical experiments with linear and tree-based regression models\nverify these theoretical predictions, explicitly demonstrating the interplay\nbetween the model complexity, generalization, and overfitting threshold.", "AI": {"tldr": "This paper develops a framework for dualizing the Kolmogorov structure function, introduces a partition function and free energy functional, and analyzes information-theoretic and statistical mechanics constructs.", "motivation": "The paper aims to establish a mathematical connection between information theory and statistical mechanics to better understand model complexity, generalization, and overfitting through duality and phase transitions.", "method": "The authors utilize Legendre-Fenchel duality, define a partition function and free energy functional, and analyze detailed balance and acceptance probabilities. They conduct experiments with regression models to validate theoretical predictions.", "result": "The findings confirm a peak in susceptibility-like variance at loss-complexity trade-offs, identifying phase transitions and validating theoretical models with experimental results.", "conclusion": "The study bridges information theory and statistical mechanics, providing insights into trade-offs in modeling and generalization while addressing overfitting thresholds effectively."}}
{"id": "2507.13852", "pdf": "https://arxiv.org/pdf/2507.13852", "abs": "https://arxiv.org/abs/2507.13852", "authors": ["Luigi Russo", "Francesco Mauro", "Babak Memar", "Alessandro Sebastianelli", "Silvia Liberata Ullo", "Paolo Gamba"], "title": "A Quantum-assisted Attention U-Net for Building Segmentation over Tunis using Sentinel-1 Data", "categories": ["cs.CV", "eess.IV"], "comment": "Accepted at IEEE Joint Urban Remote Sensing Event (JURSE) 2025", "summary": "Building segmentation in urban areas is essential in fields such as urban\nplanning, disaster response, and population mapping. Yet accurately segmenting\nbuildings in dense urban regions presents challenges due to the large size and\nhigh resolution of satellite images. This study investigates the use of a\nQuanvolutional pre-processing to enhance the capability of the Attention U-Net\nmodel in the building segmentation. Specifically, this paper focuses on the\nurban landscape of Tunis, utilizing Sentinel-1 Synthetic Aperture Radar (SAR)\nimagery. In this work, Quanvolution was used to extract more informative\nfeature maps that capture essential structural details in radar imagery,\nproving beneficial for accurate building segmentation. Preliminary results\nindicate that proposed methodology achieves comparable test accuracy to the\nstandard Attention U-Net model while significantly reducing network parameters.\nThis result aligns with findings from previous works, confirming that\nQuanvolution not only maintains model accuracy but also increases computational\nefficiency. These promising outcomes highlight the potential of\nquantum-assisted Deep Learning frameworks for large-scale building segmentation\nin urban environments.", "AI": {"tldr": "The paper uses Quanvolutional preprocessing with an Attention U-Net model to improve building segmentation in dense urban areas like Tunis, specifically using SAR imagery. The method reduces model parameters without compromising accuracy.", "motivation": "Accurate building segmentation in dense urban environments is challenging due to the large size and high resolution of satellite images.", "method": "Quanvolutional preprocessing was integrated into the Attention U-Net model to enhance feature extraction from Sentinel-1 SAR imagery, making the model more computationally efficient.", "result": "The proposed model achieved comparable accuracy to the standard Attention U-Net but with significantly reduced network parameters.", "conclusion": "Quanvolution demonstrates potential in quantum-assisted Deep Learning for efficient and accurate building segmentation in urban scenarios."}}
{"id": "2507.13384", "pdf": "https://arxiv.org/pdf/2507.13384", "abs": "https://arxiv.org/abs/2507.13384", "authors": ["Osama Hardan", "Omar Elshenhabi", "Tamer Khattab", "Mohamed Mabrok"], "title": "Flatten Wisely: How Patch Order Shapes Mamba-Powered Vision for MRI Segmentation", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "Submitted to the 2025 IEEE International Conference on Future Machine\n  Learning and Data Science (FMLDS)", "summary": "Vision Mamba models promise transformer-level performance at linear\ncomputational cost, but their reliance on serializing 2D images into 1D\nsequences introduces a critical, yet overlooked, design choice: the patch scan\norder. In medical imaging, where modalities like brain MRI contain strong\nanatomical priors, this choice is non-trivial. This paper presents the first\nsystematic study of how scan order impacts MRI segmentation. We introduce\nMulti-Scan 2D (MS2D), a parameter-free module for Mamba-based architectures\nthat facilitates exploring diverse scan paths without additional computational\ncost. We conduct a large-scale benchmark of 21 scan strategies on three public\ndatasets (BraTS 2020, ISLES 2022, LGG), covering over 70,000 slices. Our\nanalysis shows conclusively that scan order is a statistically significant\nfactor (Friedman test: $\\chi^{2}_{20}=43.9, p=0.0016$), with performance\nvarying by as much as 27 Dice points. Spatially contiguous paths -- simple\nhorizontal and vertical rasters -- consistently outperform disjointed diagonal\nscans. We conclude that scan order is a powerful, cost-free hyperparameter, and\nprovide an evidence-based shortlist of optimal paths to maximize the\nperformance of Mamba models in medical imaging.", "AI": {"tldr": "This paper investigates the impact of patch scan order on segmentation performance in Mamba-based models for medical imaging, introducing a module to explore this factor without additional cost.", "motivation": "The authors seek to address the effect of patch scan order on performance in Mamba-based architectures, particularly in medical imaging where strong anatomical priors exist and this factor is intricately non-trivial.", "method": "The researchers introduce the Multi-Scan 2D (MS2D) module, a parameter-free tool that facilitates exploration of various scan paths. They benchmarked 21 scan strategies across three public medical imaging datasets, analyzing over 70,000 slices.", "result": "Scan order was found to be a statistically significant factor in model performance, with simple spatially contiguous paths outperforming disjointed scans, and performance variances reaching up to 27 Dice points.", "conclusion": "Scan order is a critical, cost-free hyperparameter in medical imaging tasks for Mamba models. Recommendations for optimal paths are provided to aid future performance maximization."}}
{"id": "2507.13861", "pdf": "https://arxiv.org/pdf/2507.13861", "abs": "https://arxiv.org/abs/2507.13861", "authors": ["Junjie Hu", "Tianyang Han", "Kai Ma", "Jialin Gao", "Hao Dou", "Song Yang", "Xianhua He", "Jianhui Zhang", "Junfeng Luo", "Xiaoming Wei", "Wenqiang Zhang"], "title": "PositionIC: Unified Position and Identity Consistency for Image Customization", "categories": ["cs.CV"], "comment": null, "summary": "Recent subject-driven image customization has achieved significant\nadvancements in fidelity, yet fine-grained entity-level spatial control remains\nelusive, hindering the broader real-world application. This limitation is\nmainly attributed to scalable datasets that bind identity with precise\npositional cues are absent. To this end, we introduce PositionIC, a unified\nframework that enforces position and identity consistency for multi-subject\ncustomization. We construct a scalable synthesis pipeline that employs a\nbidirectional generation paradigm to eliminate subject drift and maintain\nsemantic coherence. On top of these data, we design a lightweight positional\nmodulation layer that decouples spatial embeddings among subjects, enabling\nindependent, accurate placement while preserving visual fidelity. Extensive\nexperiments demonstrate that our approach can achieve precise spatial control\nwhile maintaining high consistency in image customization task. PositionIC\npaves the way for controllable, high-fidelity image customization in\nopen-world, multi-entity scenarios and will be released to foster further\nresearch.", "AI": {"tldr": "The paper introduces PositionIC, a framework for achieving spatial and identity consistency in multi-subject image customization, enabling precise entity placement and high visual fidelity.", "motivation": "Fine-grained spatial control in subject-driven image customization remains elusive, blocking broader real-world applications. There's a lack of scalable datasets binding identity with spatial cues.", "method": "The authors propose PositionIC, including a data synthesis pipeline using bidirectional generation to reduce subject drift, and a positional modulation layer for spatial embedding decoupling.", "result": "Experiments show that PositionIC achieves precise spatial control and identity consistency, while ensuring high visual fidelity in multi-subject image customization.", "conclusion": "PositionIC provides controllable, high-fidelity image customization in multi-entity contexts, opening avenues for extensive applications and further research."}}
{"id": "2507.13868", "pdf": "https://arxiv.org/pdf/2507.13868", "abs": "https://arxiv.org/abs/2507.13868", "authors": ["Francesco Ortu", "Zhijing Jin", "Diego Doimo", "Alberto Cazzaniga"], "title": "When Seeing Overrides Knowing: Disentangling Knowledge Conflicts in Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision-language models (VLMs) increasingly leverage diverse knowledge sources\nto address complex tasks, often encountering conflicts between their internal\nparametric knowledge and external information. Knowledge conflicts can result\nin hallucinations and unreliable responses, but the mechanisms governing such\ninteractions remain unknown. To address this gap, we analyze the mechanisms\nthat VLMs use to resolve cross-modal conflicts by introducing a dataset of\nmultimodal counterfactual queries that deliberately contradict internal\ncommonsense knowledge. We localize with logit inspection a small set of heads\nthat control the conflict. Moreover, by modifying these heads, we can steer the\nmodel towards its internal knowledge or the visual inputs. Finally, we show\nthat attention from such heads pinpoints localized image regions driving visual\noverrides, outperforming gradient-based attribution in precision.", "AI": {"tldr": "The paper examines how vision-language models address conflicts between internal and external knowledge using a dataset of multimodal counterfactual queries, and identifies mechanisms for resolving such conflicts.", "motivation": "To understand how vision-language models manage interactions between their internal knowledge and external inputs, particularly when contradictions arise.", "method": "Developed a dataset of multimodal counterfactual queries and analyzed model mechanisms using logit inspection, focusing on specific heads controlling cross-modal conflict resolution.", "result": "Identified key heads controlling conflict resolution, modified these to bias the model towards internal knowledge or external inputs, and showcased their ability to locate image regions driving responses.", "conclusion": "Local inspection and targeted modification of vision-language model heads can enhance understanding and control of their resolution of cross-modal knowledge conflicts, revealing finer insights into decision-making processes."}}
{"id": "2507.13880", "pdf": "https://arxiv.org/pdf/2507.13880", "abs": "https://arxiv.org/abs/2507.13880", "authors": ["Marten Kreis", "Benjamin Kiefer"], "title": "Real-Time Fusion of Visual and Chart Data for Enhanced Maritime Vision", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This paper presents a novel approach to enhancing marine vision by fusing\nreal-time visual data with chart information. Our system overlays nautical\nchart data onto live video feeds by accurately matching detected navigational\naids, such as buoys, with their corresponding representations in chart data. To\nachieve robust association, we introduce a transformer-based end-to-end neural\nnetwork that predicts bounding boxes and confidence scores for buoy queries,\nenabling the direct matching of image-domain detections with world-space chart\nmarkers. The proposed method is compared against baseline approaches, including\na ray-casting model that estimates buoy positions via camera projection and a\nYOLOv7-based network extended with a distance estimation module. Experimental\nresults on a dataset of real-world maritime scenes demonstrate that our\napproach significantly improves object localization and association accuracy in\ndynamic and challenging environments.", "AI": {"tldr": "This paper introduces a fusion of real-time visual data with nautical chart information through a transformer-based model for improved marine vision.", "motivation": "To enhance marine navigation by accurately localizing and associating navigational aids in challenging maritime environments.", "method": "Developed a transformer-based end-to-end neural network for detecting and associating navigational aids, and compared it to baseline methods, such as ray-casting and extended YOLOv7 models.", "result": "Experimental results show superior localization and association accuracy in real-world maritime settings compared to other methods.", "conclusion": "The proposed approach offers a significant improvement in marine vision by robustly fusing visual data with chart information for dynamic environments."}}
{"id": "2507.13891", "pdf": "https://arxiv.org/pdf/2507.13891", "abs": "https://arxiv.org/abs/2507.13891", "authors": ["Yu Wei", "Jiahui Zhang", "Xiaoqin Zhang", "Ling Shao", "Shijian Lu"], "title": "PCR-GS: COLMAP-Free 3D Gaussian Splatting via Pose Co-Regularizations", "categories": ["cs.CV"], "comment": "Accepted by ICCV2025", "summary": "COLMAP-free 3D Gaussian Splatting (3D-GS) has recently attracted increasing\nattention due to its remarkable performance in reconstructing high-quality 3D\nscenes from unposed images or videos. However, it often struggles to handle\nscenes with complex camera trajectories as featured by drastic rotation and\ntranslation across adjacent camera views, leading to degraded estimation of\ncamera poses and further local minima in joint optimization of camera poses and\n3D-GS. We propose PCR-GS, an innovative COLMAP-free 3DGS technique that\nachieves superior 3D scene modeling and camera pose estimation via camera pose\nco-regularization. PCR-GS achieves regularization from two perspectives. The\nfirst is feature reprojection regularization which extracts view-robust DINO\nfeatures from adjacent camera views and aligns their semantic information for\ncamera pose regularization. The second is wavelet-based frequency\nregularization which exploits discrepancy in high-frequency details to further\noptimize the rotation matrix in camera poses. Extensive experiments over\nmultiple real-world scenes show that the proposed PCR-GS achieves superior\npose-free 3D-GS scene modeling under dramatic changes of camera trajectories.", "AI": {"tldr": "This paper presents PCR-GS, an advanced COLMAP-free 3D Gaussian Splatting method, to enhance 3D scene modeling and camera pose estimation under challenging camera motion.", "motivation": "Existing COLMAP-free 3D Gaussian Splatting methods struggle with scenes having complex camera movements, leading to difficulties in pose estimation and joint optimization.", "method": "PCR-GS introduces two regularization techniques: feature reprojection regularization aligning semantic information using DINO features, and wavelet-based frequency regularization optimizing rotation matrices in camera poses.", "result": "PCR-GS demonstrates superior performance in 3D scene modeling and pose estimation, especially with complex camera trajectories, through extensive experiments on real-world scenes.", "conclusion": "PCR-GS effectively overcomes the limitations of COLMAP-free 3D-GS in handling drastic camera motion, enabling more robust and high-quality 3D scene reconstructions."}}
{"id": "2507.13598", "pdf": "https://arxiv.org/pdf/2507.13598", "abs": "https://arxiv.org/abs/2507.13598", "authors": ["Amro Abdalla", "Ismail Shaheen", "Dan DeGenaro", "Rupayan Mallick", "Bogdan Raita", "Sarah Adel Bargal"], "title": "GIFT: Gradient-aware Immunization of diffusion models against malicious Fine-Tuning with safe concepts retention", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG"], "comment": "Warning: This paper contains NSFW content. Reader discretion is\n  advised", "summary": "We present GIFT: a {G}radient-aware {I}mmunization technique to defend\ndiffusion models against malicious {F}ine-{T}uning while preserving their\nability to generate safe content. Existing safety mechanisms like safety\ncheckers are easily bypassed, and concept erasure methods fail under\nadversarial fine-tuning. GIFT addresses this by framing immunization as a\nbi-level optimization problem: the upper-level objective degrades the model's\nability to represent harmful concepts using representation noising and\nmaximization, while the lower-level objective preserves performance on safe\ndata. GIFT achieves robust resistance to malicious fine-tuning while\nmaintaining safe generative quality. Experimental results show that our method\nsignificantly impairs the model's ability to re-learn harmful concepts while\nmaintaining performance on safe content, offering a promising direction for\ncreating inherently safer generative models resistant to adversarial\nfine-tuning attacks.", "AI": {"tldr": "This paper proposes GIFT, a technique to defend diffusion models from malicious fine-tuning attacks while ensuring they generate safe content.", "motivation": "To address the limitations of existing safety mechanisms and concept erasure methods that fail under adversarial fine-tuning attacks.", "method": "GIFT formulates immunization as a bi-level optimization problem, utilizing representation noising and maximization in the upper level and preserving performance on safe data in the lower level.", "result": "GIFT successfully hinders the model's ability to relearn harmful concepts while maintaining its performance on safe content.", "conclusion": "The method offers a robust approach to building safer generative models resistant to adversarial fine-tuning and malicious reprogramming."}}
{"id": "2507.13899", "pdf": "https://arxiv.org/pdf/2507.13899", "abs": "https://arxiv.org/abs/2507.13899", "authors": ["Yujian Mo", "Yan Wu", "Junqiao Zhao", "Jijun Wang", "Yinghao Hu", "Jun Yan"], "title": "Enhancing LiDAR Point Features with Foundation Model Priors for 3D Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in foundation models have opened up new possibilities for\nenhancing 3D perception. In particular, DepthAnything offers dense and reliable\ngeometric priors from monocular RGB images, which can complement sparse LiDAR\ndata in autonomous driving scenarios. However, such priors remain underutilized\nin LiDAR-based 3D object detection. In this paper, we address the limited\nexpressiveness of raw LiDAR point features, especially the weak discriminative\ncapability of the reflectance attribute, by introducing depth priors predicted\nby DepthAnything. These priors are fused with the original LiDAR attributes to\nenrich each point's representation. To leverage the enhanced point features, we\npropose a point-wise feature extraction module. Then, a Dual-Path RoI feature\nextraction framework is employed, comprising a voxel-based branch for global\nsemantic context and a point-based branch for fine-grained structural details.\nTo effectively integrate the complementary RoI features, we introduce a\nbidirectional gated RoI feature fusion module that balances global and local\ncues. Extensive experiments on the KITTI benchmark show that our method\nconsistently improves detection accuracy, demonstrating the value of\nincorporating visual foundation model priors into LiDAR-based 3D object\ndetection.", "AI": {"tldr": "The paper explores integrating DepthAnything-generated depth priors with LiDAR data to improve 3D object detection in autonomous driving.", "motivation": "To address the limitations of raw LiDAR point features, such as weak discriminative capabilities.", "method": "The method fuses depth priors from DepthAnything with LiDAR attributes, involving a point-wise feature extraction module and a Dual-Path RoI framework with a bidirectional gated fusion module.", "result": "Experiments on the KITTI benchmark show improved detection accuracy.", "conclusion": "Incorporating visual foundation model priors with LiDAR data enhances expressiveness and detection performance."}}
{"id": "2507.13604", "pdf": "https://arxiv.org/pdf/2507.13604", "abs": "https://arxiv.org/abs/2507.13604", "authors": ["Qihang Li", "Jichen Yang", "Yaqian Chen", "Yuwen Chen", "Hanxue Gu", "Lars J. Grimm", "Maciej A. Mazurowski"], "title": "BreastSegNet: Multi-label Segmentation of Breast MRI", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Breast MRI provides high-resolution imaging critical for breast cancer\nscreening and preoperative staging. However, existing segmentation methods for\nbreast MRI remain limited in scope, often focusing on only a few anatomical\nstructures, such as fibroglandular tissue or tumors, and do not cover the full\nrange of tissues seen in scans. This narrows their utility for quantitative\nanalysis. In this study, we present BreastSegNet, a multi-label segmentation\nalgorithm for breast MRI that covers nine anatomical labels: fibroglandular\ntissue (FGT), vessel, muscle, bone, lesion, lymph node, heart, liver, and\nimplant. We manually annotated a large set of 1123 MRI slices capturing these\nstructures with detailed review and correction from an expert radiologist.\nAdditionally, we benchmark nine segmentation models, including U-Net, SwinUNet,\nUNet++, SAM, MedSAM, and nnU-Net with multiple ResNet-based encoders. Among\nthem, nnU-Net ResEncM achieves the highest average Dice scores of 0.694 across\nall labels. It performs especially well on heart, liver, muscle, FGT, and bone,\nwith Dice scores exceeding 0.73, and approaching 0.90 for heart and liver. All\nmodel code and weights are publicly available, and we plan to release the data\nat a later date.", "AI": {"tldr": "This study introduces BreastSegNet, a multi-label segmentation algorithm for breast MRI that identifies nine anatomical structures, achieving notable accuracy in segmentation benchmarks.", "motivation": "Existing breast MRI segmentation methods are limited to a few anatomical structures, reducing their utility for quantitative analysis. This study aims to extend the range of segmentation to nine anatomical labels for better clinical and research applications.", "method": "The authors developed BreastSegNet by manually annotating 1123 MRI slices with expert radiologist review. They benchmarked nine segmentation models, including nnU-Net ResEncM, for segmentation tasks.", "result": "The nnU-Net ResEncM model achieved the best performance with an average Dice score of 0.694, excelling in several anatomical structures like heart (Dice score ~0.90).", "conclusion": "BreastSegNet significantly expands the range of anatomical structures identified in breast MRI, advancing the field of quantitative breast imaging. The code is publicly available, with planned data release for further research."}}
{"id": "2507.13929", "pdf": "https://arxiv.org/pdf/2507.13929", "abs": "https://arxiv.org/abs/2507.13929", "authors": ["Hsiang-Hui Hung", "Huu-Phu Do", "Yung-Hui Li", "Ching-Chun Huang"], "title": "TimeNeRF: Building Generalizable Neural Radiance Fields across Time from Few-Shot Input Views", "categories": ["cs.CV", "cs.MM"], "comment": "Accepted by MM 2024", "summary": "We present TimeNeRF, a generalizable neural rendering approach for rendering\nnovel views at arbitrary viewpoints and at arbitrary times, even with few input\nviews. For real-world applications, it is expensive to collect multiple views\nand inefficient to re-optimize for unseen scenes. Moreover, as the digital\nrealm, particularly the metaverse, strives for increasingly immersive\nexperiences, the ability to model 3D environments that naturally transition\nbetween day and night becomes paramount. While current techniques based on\nNeural Radiance Fields (NeRF) have shown remarkable proficiency in synthesizing\nnovel views, the exploration of NeRF's potential for temporal 3D scene modeling\nremains limited, with no dedicated datasets available for this purpose. To this\nend, our approach harnesses the strengths of multi-view stereo, neural radiance\nfields, and disentanglement strategies across diverse datasets. This equips our\nmodel with the capability for generalizability in a few-shot setting, allows us\nto construct an implicit content radiance field for scene representation, and\nfurther enables the building of neural radiance fields at any arbitrary time.\nFinally, we synthesize novel views of that time via volume rendering.\nExperiments show that TimeNeRF can render novel views in a few-shot setting\nwithout per-scene optimization. Most notably, it excels in creating realistic\nnovel views that transition smoothly across different times, adeptly capturing\nintricate natural scene changes from dawn to dusk.", "AI": {"tldr": "TimeNeRF proposes a neural rendering approach capable of synthesizing novel views at arbitrary times and angles, even with limited input.", "motivation": "Current 3D scene modeling techniques are limited in temporal aspects and rely on expensive multi-view inputs, leaving gaps in creating immersive environments for applications like the metaverse.", "method": "TimeNeRF integrates multi-view stereo, neural radiance fields, and disentanglement strategies to create a generalizable radiance field and model temporal changes.", "result": "The approach enables realistic rendering of novel 3D views that transition seamlessly across time periods, all without needing scene-specific optimization.", "conclusion": "TimeNeRF represents a significant advancement in the field by addressing temporal 3D scene changes and improving efficiency, making it suitable for real-world applications like immersive metaverse experiences."}}
{"id": "2507.13934", "pdf": "https://arxiv.org/pdf/2507.13934", "abs": "https://arxiv.org/abs/2507.13934", "authors": ["Marzieh Gheisari", "Auguste Genovesio"], "title": "DiViD: Disentangled Video Diffusion for Static-Dynamic Factorization", "categories": ["cs.CV"], "comment": null, "summary": "Unsupervised disentanglement of static appearance and dynamic motion in video\nremains a fundamental challenge, often hindered by information leakage and\nblurry reconstructions in existing VAE- and GAN-based approaches. We introduce\nDiViD, the first end-to-end video diffusion framework for explicit\nstatic-dynamic factorization. DiViD's sequence encoder extracts a global static\ntoken from the first frame and per-frame dynamic tokens, explicitly removing\nstatic content from the motion code. Its conditional DDPM decoder incorporates\nthree key inductive biases: a shared-noise schedule for temporal consistency, a\ntime-varying KL-based bottleneck that tightens at early timesteps (compressing\nstatic information) and relaxes later (enriching dynamics), and cross-attention\nthat routes the global static token to all frames while keeping dynamic tokens\nframe-specific. An orthogonality regularizer further prevents residual\nstatic-dynamic leakage. We evaluate DiViD on real-world benchmarks using\nswap-based accuracy and cross-leakage metrics. DiViD outperforms\nstate-of-the-art sequential disentanglement methods: it achieves the highest\nswap-based joint accuracy, preserves static fidelity while improving dynamic\ntransfer, and reduces average cross-leakage.", "AI": {"tldr": "The paper introduces DiViD, a video diffusion framework for disentangling static appearance and dynamic motion in video. It improves upon existing methods in accuracy, fidelity, and reduces cross-leakage.", "motivation": "Unsupervised disentanglement of static appearance and dynamic motion in video is challenging, as existing methods suffer from information leakage and blurry reconstructions.", "method": "DiViD uses a sequence encoder to separate static and dynamic tokens, a conditional DDPM decoder with inductive biases for consistency and compression, and an orthogonality regularizer to reduce leakage.", "result": "DiViD achieves high swap-based accuracy, preserves static fidelity, enhances dynamic transfer, and minimizes static-dynamic cross-leakage, outperforming state-of-the-art methods.", "conclusion": "DiViD is an effective solution to disentangle static and dynamic aspects in videos, demonstrating superior performance across multiple benchmarks."}}
{"id": "2507.13942", "pdf": "https://arxiv.org/pdf/2507.13942", "abs": "https://arxiv.org/abs/2507.13942", "authors": ["Jacob C Walker", "Pedro V\u00e9lez", "Luisa Polania Cabrera", "Guangyao Zhou", "Rishabh Kabra", "Carl Doersch", "Maks Ovsjanikov", "Jo\u00e3o Carreira", "Shiry Ginosar"], "title": "Generalist Forecasting with Frozen Video Models via Latent Diffusion", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Forecasting what will happen next is a critical skill for general-purpose\nsystems that plan or act in the world at different levels of abstraction. In\nthis paper, we identify a strong correlation between a vision model's\nperceptual ability and its generalist forecasting performance over short time\nhorizons. This trend holds across a diverse set of pretrained models-including\nthose trained generatively-and across multiple levels of abstraction, from raw\npixels to depth, point tracks, and object motion. The result is made possible\nby a novel generalist forecasting framework that operates on any frozen vision\nbackbone: we train latent diffusion models to forecast future features in the\nfrozen representation space, which are then decoded via lightweight,\ntask-specific readouts. To enable consistent evaluation across tasks, we\nintroduce distributional metrics that compare distributional properties\ndirectly in the space of downstream tasks and apply this framework to nine\nmodels and four tasks. Our results highlight the value of bridging\nrepresentation learning and generative modeling for temporally grounded video\nunderstanding.", "AI": {"tldr": "This paper explores the correlation between vision model perceptual abilities and forecasting performance, utilizing a novel framework based on latent diffusion models for temporally grounded video understanding.", "motivation": "The study aims to enhance forecasting abilities of general-purpose systems by leveraging correlations between vision model perceptual skills and short-term generalist forecasting performance.", "method": "A novel framework is used, which trains latent diffusion models to forecast future features in frozen representation space, decoded via lightweight task-specific readouts.", "result": "The framework successfully evaluates various models and tasks using distributional metrics, showing improvements in forecasting performance through the integration of representation learning and generative modeling.", "conclusion": "The paper demonstrates that linking representation learning with generative modeling improves forecasting in video understanding across diverse levels of abstraction."}}
{"id": "2507.13458", "pdf": "https://arxiv.org/pdf/2507.13458", "abs": "https://arxiv.org/abs/2507.13458", "authors": ["Malte Hoffmann"], "title": "Domain-randomized deep learning for neuroimage analysis", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "12 pages, 6 figures, 2 tables, deep learning, domain generalization,\n  domain randomization, neuroimaging, medical image analysis, accepted for\n  publication in IEEE Signal Processing Magazine", "summary": "Deep learning has revolutionized neuroimage analysis by delivering\nunprecedented speed and accuracy. However, the narrow scope of many training\ndatasets constrains model robustness and generalizability. This challenge is\nparticularly acute in magnetic resonance imaging (MRI), where image appearance\nvaries widely across pulse sequences and scanner hardware. A recent\ndomain-randomization strategy addresses the generalization problem by training\ndeep neural networks on synthetic images with randomized intensities and\nanatomical content. By generating diverse data from anatomical segmentation\nmaps, the approach enables models to accurately process image types unseen\nduring training, without retraining or fine-tuning. It has demonstrated\neffectiveness across modalities including MRI, computed tomography, positron\nemission tomography, and optical coherence tomography, as well as beyond\nneuroimaging in ultrasound, electron and fluorescence microscopy, and X-ray\nmicrotomography. This tutorial paper reviews the principles, implementation,\nand potential of the synthesis-driven training paradigm. It highlights key\nbenefits, such as improved generalization and resistance to overfitting, while\ndiscussing trade-offs such as increased computational demands. Finally, the\narticle explores practical considerations for adopting the technique, aiming to\naccelerate the development of generalizable tools that make deep learning more\naccessible to domain experts without extensive computational resources or\nmachine learning knowledge.", "AI": {"tldr": "This paper reviews a domain-randomization strategy to improve deep learning model generalization in neuroimaging using synthetic data.", "motivation": "Despite deep learning's success in neuroimage analysis, its models struggle with robustness and generalization due to limited dataset diversity, particularly in MRI imaging.", "method": "The strategy trains deep neural networks on synthetic images generated with randomized intensities and anatomical variations derived from segmentation maps.", "result": "The approach effectively enables deep learning models to handle unseen image types across various imaging modalities, not limited to neuroimaging.", "conclusion": "The synthesis-driven paradigm improves generalization and reduces overfitting but introduces computational trade-offs, providing an accessible solution for researchers with limited machine learning experience or resources."}}
{"id": "2507.13629", "pdf": "https://arxiv.org/pdf/2507.13629", "abs": "https://arxiv.org/abs/2507.13629", "authors": ["Niveen O. Jaffal", "Mohammed Alkhanafseh", "David Mohaisen"], "title": "Large Language Models in Cybersecurity: Applications, Vulnerabilities, and Defense Techniques", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "21 pages", "summary": "Large Language Models (LLMs) are transforming cybersecurity by enabling\nintelligent, adaptive, and automated approaches to threat detection,\nvulnerability assessment, and incident response. With their advanced language\nunderstanding and contextual reasoning, LLMs surpass traditional methods in\ntackling challenges across domains such as IoT, blockchain, and hardware\nsecurity. This survey provides a comprehensive overview of LLM applications in\ncybersecurity, focusing on two core areas: (1) the integration of LLMs into key\ncybersecurity domains, and (2) the vulnerabilities of LLMs themselves, along\nwith mitigation strategies. By synthesizing recent advancements and identifying\nkey limitations, this work offers practical insights and strategic\nrecommendations for leveraging LLMs to build secure, scalable, and future-ready\ncyber defense systems.", "AI": {"tldr": "The paper surveys the role and applications of large language models (LLMs) in cybersecurity, outlining their integration, vulnerabilities, and strategies for future security systems.", "motivation": "To explore how LLMs can transform cybersecurity and provide insights into their applications and vulnerabilities.", "method": "A comprehensive review of recent advancements in LLM applications for cybersecurity and their limitations, including strategies for mitigating vulnerabilities.", "result": "The paper identifies how LLMs excel in areas like threat detection, vulnerability assessment, and incident response, while also highlighting their own vulnerabilities.", "conclusion": "Utilizing LLMs can enhance cybersecurity capabilities, but addressing their vulnerabilities is crucial to fully realize secure and scalable defense systems."}}
{"id": "2507.13981", "pdf": "https://arxiv.org/pdf/2507.13981", "abs": "https://arxiv.org/abs/2507.13981", "authors": ["Sara Abdulaziz", "Giacomo D'Amicantonio", "Egor Bondarev"], "title": "Evaluation of Human Visual Privacy Protection: A Three-Dimensional Framework and Benchmark Dataset", "categories": ["cs.CV"], "comment": "accepted at ICCV'25 workshop CV4BIOM", "summary": "Recent advances in AI-powered surveillance have intensified concerns over the\ncollection and processing of sensitive personal data. In response, research has\nincreasingly focused on privacy-by-design solutions, raising the need for\nobjective techniques to evaluate privacy protection. This paper presents a\ncomprehensive framework for evaluating visual privacy-protection methods across\nthree dimensions: privacy, utility, and practicality. In addition, it\nintroduces HR-VISPR, a publicly available human-centric dataset with biometric,\nsoft-biometric, and non-biometric labels to train an interpretable privacy\nmetric. We evaluate 11 privacy protection methods, ranging from conventional\ntechniques to advanced deep-learning methods, through the proposed framework.\nThe framework differentiates privacy levels in alignment with human visual\nperception, while highlighting trade-offs between privacy, utility, and\npracticality. This study, along with the HR-VISPR dataset, serves as an\ninsightful tool and offers a structured evaluation framework applicable across\ndiverse contexts.", "AI": {"tldr": "The paper introduces a framework for assessing visual privacy methods, balancing privacy, utility, and practicality, along with a new dataset called HR-VISPR.", "motivation": "Growing concerns over AI-based surveillance's impact on personal privacy highlight the need for objective tools to evaluate privacy-protection methods.", "method": "The researchers propose a framework evaluating visual privacy methods across dimensions like privacy, utility, and practicality, using the HR-VISPR dataset to establish interpretable metrics.", "result": "Evaluation of 11 privacy-protection methods demonstrates the framework's effectiveness and aligns its findings with human visual perception, unveiling essential trade-offs.", "conclusion": "The study and HR-VISPR dataset provide actionable insights and a structured approach, enabling better evaluations of privacy methods across various scenarios."}}
{"id": "2507.13984", "pdf": "https://arxiv.org/pdf/2507.13984", "abs": "https://arxiv.org/abs/2507.13984", "authors": ["Quang-Binh Nguyen", "Minh Luu", "Quang Nguyen", "Anh Tran", "Khoi Nguyen"], "title": "CSD-VAR: Content-Style Decomposition in Visual Autoregressive Models", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to ICCV 2025", "summary": "Disentangling content and style from a single image, known as content-style\ndecomposition (CSD), enables recontextualization of extracted content and\nstylization of extracted styles, offering greater creative flexibility in\nvisual synthesis. While recent personalization methods have explored the\ndecomposition of explicit content style, they remain tailored for diffusion\nmodels. Meanwhile, Visual Autoregressive Modeling (VAR) has emerged as a\npromising alternative with a next-scale prediction paradigm, achieving\nperformance comparable to that of diffusion models. In this paper, we explore\nVAR as a generative framework for CSD, leveraging its scale-wise generation\nprocess for improved disentanglement. To this end, we propose CSD-VAR, a novel\nmethod that introduces three key innovations: (1) a scale-aware alternating\noptimization strategy that aligns content and style representation with their\nrespective scales to enhance separation, (2) an SVD-based rectification method\nto mitigate content leakage into style representations, and (3) an Augmented\nKey-Value (K-V) memory enhancing content identity preservation. To benchmark\nthis task, we introduce CSD-100, a dataset specifically designed for\ncontent-style decomposition, featuring diverse subjects rendered in various\nartistic styles. Experiments demonstrate that CSD-VAR outperforms prior\napproaches, achieving superior content preservation and stylization fidelity.", "AI": {"tldr": "This paper proposes CSD-VAR, a method for disentangling content and style from a single image using Visual Autoregressive Modeling (VAR), offering improved content and style separation for creative visual synthesis.", "motivation": "To improve the ability to separate content and style from a single image, enabling flexible creative applications in recontextualization and stylization, with a focus on utilizing the emerging potential of Visual Autoregressive Modeling (VAR).", "method": "The authors introduce a method called CSD-VAR, which includes three innovations: a scale-aware alternating optimization strategy for better scale-level representation alignment, an SVD-based rectification to reduce content leakage into style representations, and an Augmented Key-Value (K-V) memory to enhance content identity preservation.", "result": "CSD-VAR outperforms previous methods in the content-style decomposition task, delivering superior content preservation and fidelity of stylization, as shown through experiments.", "conclusion": "The proposed CSD-VAR method demonstrates the potential of VAR for generative tasks, particularly in separating content and style effectively, paving the way for advanced creative applications."}}
{"id": "2507.13480", "pdf": "https://arxiv.org/pdf/2507.13480", "abs": "https://arxiv.org/abs/2507.13480", "authors": ["Sara Avesani", "Gianluca Giacchi", "Michael Multerer"], "title": "Multiresolution local smoothness detection in non-uniformly sampled multivariate signals", "categories": ["math.NA", "cs.CV", "cs.LG", "cs.NA"], "comment": null, "summary": "Inspired by edge detection based on the decay behavior of wavelet\ncoefficients, we introduce a (near) linear-time algorithm for detecting the\nlocal regularity in non-uniformly sampled multivariate signals. Our approach\nquantifies regularity within the framework of microlocal spaces introduced by\nJaffard. The central tool in our analysis is the fast samplet transform, a\ndistributional wavelet transform tailored to scattered data. We establish a\nconnection between the decay of samplet coefficients and the pointwise\nregularity of multivariate signals. As a by product, we derive decay estimates\nfor functions belonging to classical H\\\"older spaces and Sobolev-Slobodeckij\nspaces. While traditional wavelets are effective for regularity detection in\nlow-dimensional structured data, samplets demonstrate robust performance even\nfor higher dimensional and scattered data. To illustrate our theoretical\nfindings, we present extensive numerical studies detecting local regularity of\none-, two- and three-dimensional signals, ranging from non-uniformly sampled\ntime series over image segmentation to edge detection in point clouds.", "AI": {"tldr": "The paper introduces a fast linear-time algorithm using samplet transform to detect local regularity in scattered multivariate data, outperforming traditional wavelet approaches.", "motivation": "The limitations of traditional wavelet transforms in analyzing higher dimensional and scattered data necessitate development of robust methods for local regularity detection.", "method": "The proposed method utilizes the fast samplet transform, a tailored wavelet transform for scattered data, to relate coefficient decay to signal regularity within microlocal spaces.", "result": "The algorithm successfully detects regularity across diverse data types including non-uniform time series, image segmentation, and edge detection in point clouds, supported by theoretical and numerical validations.", "conclusion": "The research demonstrates that samplets are powerful tools for regularity analysis in both structured and unstructured high-dimensional data, offering better scalability and performance."}}
{"id": "2507.13985", "pdf": "https://arxiv.org/pdf/2507.13985", "abs": "https://arxiv.org/abs/2507.13985", "authors": ["Haoran Li", "Yuli Tian", "Kun Lan", "Yong Liao", "Lin Wang", "Pan Hui", "Peng Yuan Zhou"], "title": "DreamScene: 3D Gaussian-based End-to-end Text-to-3D Scene Generation", "categories": ["cs.CV"], "comment": "Extended version of ECCV 2024 paper \"DreamScene\"", "summary": "Generating 3D scenes from natural language holds great promise for\napplications in gaming, film, and design. However, existing methods struggle\nwith automation, 3D consistency, and fine-grained control. We present\nDreamScene, an end-to-end framework for high-quality and editable 3D scene\ngeneration from text or dialogue. DreamScene begins with a scene planning\nmodule, where a GPT-4 agent infers object semantics and spatial constraints to\nconstruct a hybrid graph. A graph-based placement algorithm then produces a\nstructured, collision-free layout. Based on this layout, Formation Pattern\nSampling (FPS) generates object geometry using multi-timestep sampling and\nreconstructive optimization, enabling fast and realistic synthesis. To ensure\nglobal consistent, DreamScene employs a progressive camera sampling strategy\ntailored to both indoor and outdoor settings. Finally, the system supports\nfine-grained scene editing, including object movement, appearance changes, and\n4D dynamic motion. Experiments demonstrate that DreamScene surpasses prior\nmethods in quality, consistency, and flexibility, offering a practical solution\nfor open-domain 3D content creation. Code and demos are available at\nhttps://dreamscene-project.github.io.", "AI": {"tldr": "DreamScene is a framework for generating high-quality, editable 3D scenes from text or dialogue, overcoming limitations in automation, consistency, and control.", "motivation": "To address challenges of automation, 3D consistency, and fine-grained control in generating 3D scenes from natural language, which has broad applications in entertainment and design.", "method": "DreamScene starts with a scene planning module using GPT-4 for object semantics and spatial arrangements, followed by a graph-based placement strategy. It uses Formation Pattern Sampling for geometry synthesis and employs a progressive camera sampling strategy for consistency. It also supports detailed scene editing features.", "result": "Experiments show that DreamScene outperforms previous methods in creating consistent, high-quality, and flexible 3D scenes.", "conclusion": "DreamScene provides a practical, superior solution for open-domain 3D content creation with broad editing and application capabilities."}}
{"id": "2507.14010", "pdf": "https://arxiv.org/pdf/2507.14010", "abs": "https://arxiv.org/abs/2507.14010", "authors": ["Yong Feng", "Xiaolei Zhang", "Shijin Feng", "Yong Zhao", "Yihan Chen"], "title": "Automatic Classification and Segmentation of Tunnel Cracks Based on Deep Learning and Visual Explanations", "categories": ["cs.CV"], "comment": "8 pages, 10 figures, 3 tables", "summary": "Tunnel lining crack is a crucial indicator of tunnels' safety status. Aiming\nto classify and segment tunnel cracks with enhanced accuracy and efficiency,\nthis study proposes a two-step deep learning-based method. An automatic tunnel\nimage classification model is developed using the DenseNet-169 in the first\nstep. The proposed crack segmentation model in the second step is based on the\nDeepLabV3+, whose internal logic is evaluated via a score-weighted visual\nexplanation technique. Proposed method combines tunnel image classification and\nsegmentation together, so that the selected images containing cracks from the\nfirst step are segmented in the second step to improve the detection accuracy\nand efficiency. The superior performances of the two-step method are validated\nby experiments. The results show that the accuracy and frames per second (FPS)\nof the tunnel crack classification model are 92.23% and 39.80, respectively,\nwhich are higher than other convolutional neural networks (CNN) based and\nTransformer based models. Also, the intersection over union (IoU) and F1 score\nof the tunnel crack segmentation model are 57.01% and 67.44%, respectively,\noutperforming other state-of-the-art models. Moreover, the provided visual\nexplanations in this study are conducive to understanding the \"black box\" of\ndeep learning-based models. The developed two-stage deep learning-based method\nintegrating visual explanations provides a basis for fast and accurate\nquantitative assessment of tunnel health status.", "AI": {"tldr": "The paper proposes a two-step deep learning-based method combining DenseNet-169 and DeepLabV3+ for classifying and segmenting tunnel cracks, achieving superior accuracy and efficiency.", "motivation": "To improve the accuracy and efficiency of tunnel crack classification and segmentation for assessing tunnel safety.", "method": "The proposed method uses DenseNet-169 for tunnel image classification and DeepLabV3+ for crack segmentation, with visual explanations to unravel the model's internal logic.", "result": "The method achieved classification accuracy of 92.23%, FPS of 39.80, IoU of 57.01%, and F1 score of 67.44%, outperforming other CNN and Transformer-based models.", "conclusion": "The two-step method with integrated visual explanations provides a fast and accurate solution for assessing tunnel health and understanding deep learning model behavior."}}
{"id": "2507.14013", "pdf": "https://arxiv.org/pdf/2507.14013", "abs": "https://arxiv.org/abs/2507.14013", "authors": ["Ji-Yan Wu", "Zheng Yong Poh", "Anoop C. Patil", "Bongsoo Park", "Giovanni Volpe", "Daisuke Urano"], "title": "Analysis of Plant Nutrient Deficiencies Using Multi-Spectral Imaging and Optimized Segmentation Model", "categories": ["cs.CV"], "comment": null, "summary": "Accurate detection of nutrient deficiency in plant leaves is essential for\nprecision agriculture, enabling early intervention in fertilization, disease,\nand stress management. This study presents a deep learning framework for leaf\nanomaly segmentation using multispectral imaging and an enhanced YOLOv5 model\nwith a transformer-based attention head. The model is tailored for processing\nnine-channel multispectral input and uses self-attention mechanisms to better\ncapture subtle, spatially-distributed symptoms. The plants in the experiments\nwere grown under controlled nutrient stress conditions for evaluation. We carry\nout extensive experiments to benchmark the proposed model against the baseline\nYOLOv5. Extensive experiments show that the proposed model significantly\noutperforms the baseline YOLOv5, with an average Dice score and IoU\n(Intersection over Union) improvement of about 12%. In particular, this model\nis effective in detecting challenging symptoms like chlorosis and pigment\naccumulation. These results highlight the promise of combining multi-spectral\nimaging with spectral-spatial feature learning for advancing plant phenotyping\nand precision agriculture.", "AI": {"tldr": "The study presents an enhanced YOLOv5 model with transformer-based attention for multispectral imaging, achieving significant improvement in detecting nutrient deficiencies in plant leaves.", "motivation": "The research is motivated by the need for accurate and early detection of nutrient deficiencies in plant leaves to aid in precision agriculture.", "method": "The study employs a deep learning model based on YOLOv5, enhanced with a transformer-based attention mechanism, designed to handle nine-channel multispectral input.", "result": "The model achieves a 12% improvement in Dice score and IoU over the baseline YOLOv5, effectively detecting challenging symptoms like chlorosis.", "conclusion": "Combining multispectral imaging with spectral-spatial feature learning is promising for advancing plant phenotyping and precision agriculture."}}
{"id": "2507.14024", "pdf": "https://arxiv.org/pdf/2507.14024", "abs": "https://arxiv.org/abs/2507.14024", "authors": ["Jiarong Ye", "Sharon X. Huang"], "title": "Moodifier: MLLM-Enhanced Emotion-Driven Image Editing", "categories": ["cs.CV"], "comment": null, "summary": "Bridging emotions and visual content for emotion-driven image editing holds\ngreat potential in creative industries, yet precise manipulation remains\nchallenging due to the abstract nature of emotions and their varied\nmanifestations across different contexts. We tackle this challenge with an\nintegrated approach consisting of three complementary components. First, we\nintroduce MoodArchive, an 8M+ image dataset with detailed hierarchical\nemotional annotations generated by LLaVA and partially validated by human\nevaluators. Second, we develop MoodifyCLIP, a vision-language model fine-tuned\non MoodArchive to translate abstract emotions into specific visual attributes.\nThird, we propose Moodifier, a training-free editing model leveraging\nMoodifyCLIP and multimodal large language models (MLLMs) to enable precise\nemotional transformations while preserving content integrity. Our system works\nacross diverse domains such as character expressions, fashion design, jewelry,\nand home d\\'ecor, enabling creators to quickly visualize emotional variations\nwhile preserving identity and structure. Extensive experimental evaluations\nshow that Moodifier outperforms existing methods in both emotional accuracy and\ncontent preservation, providing contextually appropriate edits. By linking\nabstract emotions to concrete visual changes, our solution unlocks new\npossibilities for emotional content creation in real-world applications. We\nwill release the MoodArchive dataset, MoodifyCLIP model, and make the Moodifier\ncode and demo publicly available upon acceptance.", "AI": {"tldr": "This paper addresses the challenge of emotion-driven image editing by introducing an integrated system comprising a large dataset, a fine-tuned model, and a training-free editing approach that links abstract emotions to concrete visual changes.", "motivation": "Precise manipulation of emotions in visual content remains difficult due to their abstract nature and varied contextual representations. Bridging these aspects is crucial for creative industries.", "method": "The paper introduces three components: MoodArchive (an annotated image dataset), MoodifyCLIP (a fine-tuned vision-language model), and Moodifier (a training-free editing model leveraging MoodifyCLIP and multimodal language models).", "result": "The Moodifier system was tested across domains, achieving superior performance in emotional accuracy and content preservation compared to existing methods.", "conclusion": "By integrating data, modeling, and editing, the approach connects abstract emotions with specific visual transformations, paving the way for more effective emotional content creation and offering tools for public accessibility."}}
{"id": "2507.14031", "pdf": "https://arxiv.org/pdf/2507.14031", "abs": "https://arxiv.org/abs/2507.14031", "authors": ["Hao Fang", "Sihao Teng", "Hao Yu", "Siyi Yuan", "Huaiwu He", "Zhe Liu", "Yunjie Yang"], "title": "QuantEIT: Ultra-Lightweight Quantum-Assisted Inference for Chest Electrical Impedance Tomography", "categories": ["cs.CV", "cs.ET", "cs.LG"], "comment": "10 pages, 12 figures", "summary": "Electrical Impedance Tomography (EIT) is a non-invasive, low-cost bedside\nimaging modality with high temporal resolution, making it suitable for bedside\nmonitoring. However, its inherently ill-posed inverse problem poses significant\nchallenges for accurate image reconstruction. Deep learning (DL)-based\napproaches have shown promise but often rely on complex network architectures\nwith a large number of parameters, limiting efficiency and scalability. Here,\nwe propose an Ultra-Lightweight Quantum-Assisted Inference (QuantEIT) framework\nfor EIT image reconstruction. QuantEIT leverages a Quantum-Assisted Network\n(QA-Net), combining parallel 2-qubit quantum circuits to generate expressive\nlatent representations that serve as implicit nonlinear priors, followed by a\nsingle linear layer for conductivity reconstruction. This design drastically\nreduces model complexity and parameter number. Uniquely, QuantEIT operates in\nan unsupervised, training-data-free manner and represents the first integration\nof quantum circuits into EIT image reconstruction. Extensive experiments on\nsimulated and real-world 2D and 3D EIT lung imaging data demonstrate that\nQuantEIT outperforms conventional methods, achieving comparable or superior\nreconstruction accuracy using only 0.2% of the parameters, with enhanced\nrobustness to noise.", "AI": {"tldr": "This paper introduces a Quantum-Assisted Network (QA-Net) for EIT image reconstruction that reduces complexity and works unsupervised, using quantum circuits for enhanced robustness and accuracy.", "motivation": "Current EIT image reconstruction methods face challenges due to the ill-posed inverse problem, and deep learning approaches often involve heavy computational costs due to numerous parameters.", "method": "The authors propose QuantEIT, a framework that integrates 2-qubit quantum circuits for latent representation generation and a linear layer for conductivity reconstruction, operating in an unsupervised manner.", "result": "QuantEIT achieves superior reconstruction accuracy and robustness with only 0.2% of conventional model parameters, demonstrating its effectiveness on simulated and real-world lung imaging data.", "conclusion": "QuantEIT successfully integrates quantum circuits into EIT image reconstruction, offering a lightweight, efficient, and unsupervised solution with minimal parameters and improved performance."}}
{"id": "2507.13725", "pdf": "https://arxiv.org/pdf/2507.13725", "abs": "https://arxiv.org/abs/2507.13725", "authors": ["Alejandro Bellog\u00edn", "Linus W. Dietz", "Francesco Ricci", "Pablo S\u00e1nchez"], "title": "Point of Interest Recommendation: Pitfalls and Viable Solutions", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Point of interest (POI) recommendation can play a pivotal role in enriching\ntourists' experiences by suggesting context-dependent and preference-matching\nlocations and activities, such as restaurants, landmarks, itineraries, and\ncultural attractions. Unlike some more common recommendation domains (e.g.,\nmusic and video), POI recommendation is inherently high-stakes: users invest\nsignificant time, money, and effort to search, choose, and consume these\nsuggested POIs. Despite the numerous research works in the area, several\nfundamental issues remain unresolved, hindering the real-world applicability of\nthe proposed approaches. In this paper, we discuss the current status of the\nPOI recommendation problem and the main challenges we have identified. The\nfirst contribution of this paper is a critical assessment of the current state\nof POI recommendation research and the identification of key shortcomings\nacross three main dimensions: datasets, algorithms, and evaluation\nmethodologies. We highlight persistent issues such as the lack of standardized\nbenchmark datasets, flawed assumptions in the problem definition and model\ndesign, and inadequate treatment of biases in the user behavior and system\nperformance. The second contribution is a structured research agenda that,\nstarting from the identified issues, introduces important directions for future\nwork related to multistakeholder design, context awareness, data collection,\ntrustworthiness, novel interactions, and real-world evaluation.", "AI": {"tldr": "This paper critically evaluates the challenges in point of interest (POI) recommendation systems and proposes a structured research agenda addressing issues like datasets, algorithms, and biases.", "motivation": "To improve the real-world applicability of POI recommendation systems by addressing existing shortcomings and challenges in the domain.", "method": "The authors analyzed the current state of POI recommendation research, identified critical issues across datasets, algorithms, and evaluations, and proposed a research agenda including areas like multistakeholder design and trustworthiness.", "result": "They identified persistent issues, including lack of standardized datasets, flawed assumptions in models, and bias handling limitations. They also outlined future research directions for enhancement.", "conclusion": "Current POI recommendation systems face fundamental challenges that require structured improvements in datasets, algorithms, and evaluation techniques. The proposed research agenda serves as a guide for addressing these gaps."}}
{"id": "2507.14042", "pdf": "https://arxiv.org/pdf/2507.14042", "abs": "https://arxiv.org/abs/2507.14042", "authors": ["Qiankun Ma", "Ziyao Zhang", "Chi Su", "Jie Chen", "Zhen Song", "Hairong Zheng", "Wen Gao"], "title": "Training-free Token Reduction for Vision Mamba", "categories": ["cs.CV"], "comment": null, "summary": "Vision Mamba has emerged as a strong competitor to Vision Transformers (ViTs)\ndue to its ability to efficiently capture long-range dependencies with linear\ncomputational complexity. While token reduction, an effective compression\ntechnique in ViTs, has rarely been explored in Vision Mamba. Exploring Vision\nMamba's efficiency is essential for enabling broader applications. However, we\nfind that directly applying existing token reduction techniques for ViTs to\nVision Mamba leads to significant performance degradation. This is primarily\nbecause Mamba is a sequence model without attention mechanisms, whereas most\ntoken reduction techniques for ViTs rely on attention mechanisms for importance\nmeasurement and overlook the order of compressed tokens. In this paper, we\ninvestigate a Mamba structure-aware importance score to evaluate token\nimportance in a simple and effective manner. Building on this score, we further\npropose MTR, a training-free \\textbf{M}amba \\textbf{T}oken \\textbf{R}eduction\nframework. Without the need for training or additional tuning parameters, our\nmethod can be seamlessly integrated as a plug-and-play component across various\nMamba models. Extensive experiments demonstrate that our approach significantly\nreduces computational workload while minimizing performance impact across\nvarious tasks and multiple backbones. Notably, MTR reduces FLOPs by\napproximately 40\\% on the Vim-B backbone, with only a 1.6\\% drop in ImageNet\nperformance without retraining.", "AI": {"tldr": "The paper introduces MTR, a training-free token reduction framework to improve the efficiency of Vision Mamba, a model competing with Vision Transformers.", "motivation": "Token reduction techniques are effective in Vision Transformers but have not been explored adequately in Vision Mamba, which lacks attention mechanisms for importance measurement.", "method": "The authors propose a Mamba structure-aware importance score to rank token importance and utilize this to create MTR, a training-free framework for token reduction.", "result": "Extensive experiments indicate a substantial computational workload reduction using MTR, with minimal performance loss across tasks and models.", "conclusion": "MTR is an effective, training-free token reduction framework that can integrate easily with Vision Mamba models to achieve significant efficiency gains."}}
{"id": "2507.13580", "pdf": "https://arxiv.org/pdf/2507.13580", "abs": "https://arxiv.org/abs/2507.13580", "authors": ["Hao Tuo", "Yan Li", "Xuanning Hu", "Haishi Zhao", "Xueyan Liu", "Bo Yang"], "title": "A Collaborative Framework Integrating Large Language Model and Chemical Fragment Space: Mutual Inspiration for Lead Design", "categories": ["q-bio.BM", "cs.LG"], "comment": null, "summary": "Combinatorial optimization algorithm is essential in computer-aided drug\ndesign by progressively exploring chemical space to design lead compounds with\nhigh affinity to target protein. However current methods face inherent\nchallenges in integrating domain knowledge, limiting their performance in\nidentifying lead compounds with novel and valid binding mode. Here, we propose\nAutoLeadDesign, a lead compounds design framework that inspires extensive\ndomain knowledge encoded in large language models with chemical fragments to\nprogressively implement efficient exploration of vast chemical space. The\ncomprehensive experiments indicate that AutoLeadDesign outperforms baseline\nmethods. Significantly, empirical lead design campaigns targeting two\nclinically relevant targets (PRMT5 and SARS-CoV-2 PLpro) demonstrate\nAutoLeadDesign's competence in de novo generation of lead compounds achieving\nexpert-competitive design efficacy. Structural analysis further confirms their\nmechanism-validated inhibitory patterns. By tracing the process of design, we\nfind that AutoLeadDesign shares analogous mechanisms with fragment-based drug\ndesign which traditionally rely on the expert decision-making, further\nrevealing why it works. Overall, AutoLeadDesign offers an efficient approach\nfor lead compounds design, suggesting its potential utility in drug design.", "AI": {"tldr": "AutoLeadDesign is a framework that integrates domain knowledge with large language models and chemical fragments to explore chemical space for drug design, outperforming baseline methods and showing expert-competitive efficacy.", "motivation": "Current methods in combinatorial optimization for drug design struggle to integrate domain knowledge, hindering their ability to identify innovative and valid binding modes for lead compounds.", "method": "AutoLeadDesign leverages chemical fragments combined with domain knowledge encoded in large language models to optimize exploration of chemical space and aid in lead compound design.", "result": "Comprehensive experiments and empirical design campaigns targeting PRMT5 and SARS-CoV-2 PLpro confirm that AutoLeadDesign surpasses baseline methods in efficacy and generates structurally validated lead compounds.", "conclusion": "AutoLeadDesign provides an efficient and expert-level solution for lead compound design, with demonstrated utility in drug discovery and mechanisms analogous to fragment-based drug design processes."}}
{"id": "2507.14050", "pdf": "https://arxiv.org/pdf/2507.14050", "abs": "https://arxiv.org/abs/2507.14050", "authors": ["Mohamed Elkhayat", "Mohamed Mahmoud", "Jamil Fayyad", "Nourhan Bayasi"], "title": "Foundation Models as Class-Incremental Learners for Dermatological Image Classification", "categories": ["cs.CV"], "comment": "Accepted at the MICCAI EMERGE 2025 workshop", "summary": "Class-Incremental Learning (CIL) aims to learn new classes over time without\nforgetting previously acquired knowledge. The emergence of foundation models\n(FM) pretrained on large datasets presents new opportunities for CIL by\noffering rich, transferable representations. However, their potential for\nenabling incremental learning in dermatology remains largely unexplored. In\nthis paper, we systematically evaluate frozen FMs pretrained on large-scale\nskin lesion datasets for CIL in dermatological disease classification. We\npropose a simple yet effective approach where the backbone remains frozen, and\na lightweight MLP is trained incrementally for each task. This setup achieves\nstate-of-the-art performance without forgetting, outperforming regularization,\nreplay, and architecture based methods. To further explore the capabilities of\nfrozen FMs, we examine zero training scenarios using nearest mean classifiers\nwith prototypes derived from their embeddings. Through extensive ablation\nstudies, we demonstrate that this prototype based variant can also achieve\ncompetitive results. Our findings highlight the strength of frozen FMs for\ncontinual learning in dermatology and support their broader adoption in real\nworld medical applications. Our code and datasets are available here.", "AI": {"tldr": "The paper explores using foundation models (FMs) in dermatological class-incremental learning (CIL) by keeping the model frozen and training lightweight additional components, achieving state-of-the-art results.", "motivation": "To leverage rich, transferable representations of FMs for incremental learning in dermatological disease classification, which remains underexplored.", "method": "Frozen FMs pretrained on skin lesion datasets are combined with a lightweight incrementally trained MLP for tasks. Alternatively, nearest mean classifiers with embeddings-derived prototypes are also tested.", "result": "Achieved state-of-the-art performance without forgetting, outperforming methods like regularization, replay, and architecture-based models. Prototype variants also showed competitive results.", "conclusion": "Frozen FMs showcase strong potential for continual learning in dermatology and their broader adoption in medical applications is encouraged."}}
{"id": "2507.13591", "pdf": "https://arxiv.org/pdf/2507.13591", "abs": "https://arxiv.org/abs/2507.13591", "authors": ["Sahar Ghoflsaz Ghinani", "Elaheh Sadredini"], "title": "FuSeFL: Fully Secure and Scalable Cross-Silo Federated Learning", "categories": ["cs.CR", "cs.LG"], "comment": "15 Pages, 12 Figures", "summary": "Federated Learning (FL) enables collaborative model training without\ncentralizing client data, making it attractive for privacy-sensitive domains.\nWhile existing approaches employ cryptographic techniques such as homomorphic\nencryption, differential privacy, or secure multiparty computation to mitigate\ninference attacks-including model inversion, membership inference, and gradient\nleakage-they often suffer from high computational, communication, or memory\noverheads. Moreover, many methods overlook the confidentiality of the global\nmodel itself, which may be proprietary and sensitive. These challenges limit\nthe practicality of secure FL, especially in cross-silo deployments involving\nlarge datasets and strict compliance requirements.\n  We present FuSeFL, a fully secure and scalable FL scheme designed for\ncross-silo settings. FuSeFL decentralizes training across client pairs using\nlightweight secure multiparty computation (MPC), while confining the server's\nrole to secure aggregation. This design eliminates server bottlenecks, avoids\ndata offloading, and preserves full confidentiality of data, model, and updates\nthroughout training. FuSeFL defends against inference threats, achieves up to\n95% lower communication latency and 50% lower server memory usage, and improves\naccuracy over prior secure FL solutions, demonstrating strong security and\nefficiency at scale.", "AI": {"tldr": "FuSeFL introduces a scalable and secure federated learning framework reducing computational and communication overhead while maintaining high confidentiality of data and model.", "motivation": "Existing federated learning approaches face challenges such as high overhead and lack of confidentiality for the global model, limiting their efficacy in privacy-sensitive applications.", "method": "FuSeFL employs decentralized training using lightweight secure multiparty computation (MPC) and restricts the server's role to secure aggregation.", "result": "The framework reduces communication latency by up to 95%, decreases server memory usage by 50%, and improves accuracy while providing robust security against inference threats.", "conclusion": "FuSeFL offers a scalable and secure solution for federated learning in cross-silo deployments, addressing key limitations in existing approaches with strong efficiency and privacy guarantees."}}
{"id": "2507.14067", "pdf": "https://arxiv.org/pdf/2507.14067", "abs": "https://arxiv.org/abs/2507.14067", "authors": ["Shuliang Liu", "Qi Zheng", "Jesse Jiaxi Xu", "Yibo Yan", "He Geng", "Aiwei Liu", "Peijie Jiang", "Jia Liu", "Yik-Cheung Tam", "Xuming Hu"], "title": "VLA-Mark: A cross modal watermark for large vision-language alignment model", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision-language models demand watermarking solutions that protect\nintellectual property without compromising multimodal coherence. Existing text\nwatermarking methods disrupt visual-textual alignment through biased token\nselection and static strategies, leaving semantic-critical concepts vulnerable.\nWe propose VLA-Mark, a vision-aligned framework that embeds detectable\nwatermarks while preserving semantic fidelity through cross-modal coordination.\nOur approach integrates multiscale visual-textual alignment metrics, combining\nlocalized patch affinity, global semantic coherence, and contextual attention\npatterns, to guide watermark injection without model retraining. An\nentropy-sensitive mechanism dynamically balances watermark strength and\nsemantic preservation, prioritizing visual grounding during low-uncertainty\ngeneration phases. Experiments show 7.4% lower PPL and 26.6% higher BLEU than\nconventional methods, with near-perfect detection (98.8% AUC). The framework\ndemonstrates 96.1\\% attack resilience against attacks such as paraphrasing and\nsynonym substitution, while maintaining text-visual consistency, establishing\nnew standards for quality-preserving multimodal watermarking", "AI": {"tldr": "The paper introduces VLA-Mark, a new watermarking framework for vision-language models that ensures intellectual property protection without disrupting multimodal alignment. It outperforms existing methods in semantic preservation, detection accuracy, and attack resilience.", "motivation": "Existing text watermarking methods struggle with maintaining both semantic fidelity and visual-textual alignment, leaving critical concepts vulnerable.", "method": "The authors propose a vision-aligned framework (VLA-Mark) that integrates multiscale alignment metrics and an entropy-sensitive mechanism to dynamically balance watermark strength and semantic fidelity without requiring model retraining.", "result": "Experimental results show VLA-Mark achieves a 7.4% lower perplexity (PPL) and 26.6% higher BLEU score compared to traditional methods. It also excels with a 98.8% detection AUC and demonstrates 96.1% resilience to various attacks, including paraphrasing and synonym substitution.", "conclusion": "VLA-Mark sets new standards for quality-preserving and robust watermarking in multimodal systems, ensuring effective watermark embedding while retaining text-visual consistency."}}
{"id": "2507.14083", "pdf": "https://arxiv.org/pdf/2507.14083", "abs": "https://arxiv.org/abs/2507.14083", "authors": ["Sara Abdulaziz", "Egor Bondarev"], "title": "Unmasking Performance Gaps: A Comparative Study of Human Anonymization and Its Effects on Video Anomaly Detection", "categories": ["cs.CV"], "comment": "ACIVS 2025", "summary": "Advancements in deep learning have improved anomaly detection in surveillance\nvideos, yet they raise urgent privacy concerns due to the collection of\nsensitive human data. In this paper, we present a comprehensive analysis of\nanomaly detection performance under four human anonymization techniques,\nincluding blurring, masking, encryption, and avatar replacement, applied to the\nUCF-Crime dataset. We evaluate four anomaly detection methods, MGFN, UR-DMU,\nBN-WVAD, and PEL4VAD, on the anonymized UCF-Crime to reveal how each method\nresponds to different obfuscation techniques. Experimental results demonstrate\nthat anomaly detection remains viable under anonymized data and is dependent on\nthe algorithmic design and the learning strategy. For instance, under certain\nanonymization patterns, such as encryption and masking, some models\ninadvertently achieve higher AUC performance compared to raw data, due to the\nstrong responsiveness of their algorithmic components to these noise patterns.\nThese results highlight the algorithm-specific sensitivities to anonymization\nand emphasize the trade-off between preserving privacy and maintaining\ndetection utility. Furthermore, we compare these conventional anonymization\ntechniques with the emerging privacy-by-design solutions, highlighting an often\noverlooked trade-off between robust privacy protection and utility flexibility.\nThrough comprehensive experiments and analyses, this study provides a\ncompelling benchmark and insights into balancing human privacy with the demands\nof anomaly detection.", "AI": {"tldr": "This study analyzes the impact of four anonymization techniques on anomaly detection performance using the UCF-Crime dataset and various detection methods, finding algorithm-specific sensitivities and trade-offs between privacy preservation and detection accuracy.", "motivation": "The motivation is to address urgent privacy concerns in surveillance video anomaly detection, as sensitive human data is collected for deep learning applications.", "method": "The paper employs four human anonymization techniques\u2014blurring, masking, encryption, and avatar replacement\u2014and evaluates their effects on four anomaly detection methods: MGFN, UR-DMU, BN-WVAD, and PEL4VAD using the UCF-Crime dataset.", "result": "Experimental findings reveal that anomaly detection remains feasible under anonymized conditions, with some methods performing better with certain anonymization strategies, highlighting algorithm-specific sensitivities.", "conclusion": "There is a trade-off between preserving privacy and maintaining anomaly detection performance, and the study provides a benchmark for balancing these demands."}}
{"id": "2507.14093", "pdf": "https://arxiv.org/pdf/2507.14093", "abs": "https://arxiv.org/abs/2507.14093", "authors": ["\u0160imon Kubov", "Simon Kl\u00ed\u010dn\u00edk", "Jakub Dand\u00e1r", "Zden\u011bk Straka", "Karol\u00edna Kvakov\u00e1", "Daniel Kvak"], "title": "Multi-Centre Validation of a Deep Learning Model for Scoliosis Assessment", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Scoliosis affects roughly 2 to 4 percent of adolescents, and treatment\ndecisions depend on precise Cobb angle measurement. Manual assessment is time\nconsuming and subject to inter observer variation. We conducted a\nretrospective, multi centre evaluation of a fully automated deep learning\nsoftware (Carebot AI Bones, Spine Measurement functionality; Carebot s.r.o.) on\n103 standing anteroposterior whole spine radiographs collected from ten\nhospitals. Two musculoskeletal radiologists independently measured each study\nand served as reference readers. Agreement between the AI and each radiologist\nwas assessed with Bland Altman analysis, mean absolute error (MAE), root mean\nsquared error (RMSE), Pearson correlation coefficient, and Cohen kappa for four\ngrade severity classification. Against Radiologist 1 the AI achieved an MAE of\n3.89 degrees (RMSE 4.77 degrees) with a bias of 0.70 degrees and limits of\nagreement from minus 8.59 to plus 9.99 degrees. Against Radiologist 2 the AI\nachieved an MAE of 3.90 degrees (RMSE 5.68 degrees) with a bias of 2.14 degrees\nand limits from minus 8.23 to plus 12.50 degrees. Pearson correlations were r\nequals 0.906 and r equals 0.880 (inter reader r equals 0.928), while Cohen\nkappa for severity grading reached 0.51 and 0.64 (inter reader kappa 0.59).\nThese results demonstrate that the proposed software reproduces expert level\nCobb angle measurements and categorical grading across multiple centres,\nsuggesting its utility for streamlining scoliosis reporting and triage in\nclinical workflows.", "AI": {"tldr": "This paper evaluates an AI-based software for automated Cobb angle measurement, achieving metrics comparable to expert radiologists and indicating its clinical potential.", "motivation": "The study aims to address scoliosis diagnosis challenges by using AI to reduce manual workloads and inter-observer variability in Cobb angle measurements.", "method": "A retrospective study was conducted across ten hospitals with 103 spine radiographs, comparing AI-generated measurements to those by expert radiologists using statistical methods like MAE, RMSE, and Cohen kappa.", "result": "The AI demonstrated high accuracy with MAEs around 3.9 degrees, Pearson correlation above 0.880, and moderate Cohen kappa agreement for severity grading, validating expert-level performance.", "conclusion": "The AI software shows promise for improving efficiency and accuracy in scoliosis diagnosis, supporting its integration into clinical workflows."}}
{"id": "2507.14095", "pdf": "https://arxiv.org/pdf/2507.14095", "abs": "https://arxiv.org/abs/2507.14095", "authors": ["Yung-Hong Sun", "Ting-Hung Lin", "Jiangang Chen", "Hongrui Jiang", "Yu Hen Hu"], "title": "C-DOG: Training-Free Multi-View Multi-Object Association in Dense Scenes Without Visual Feature via Connected \u03b4-Overlap Graphs", "categories": ["cs.CV"], "comment": null, "summary": "Multi-view multi-object association is a fundamental step in 3D\nreconstruction pipelines, enabling consistent grouping of object instances\nacross multiple camera views. Existing methods often rely on appearance\nfeatures or geometric constraints such as epipolar consistency. However, these\napproaches can fail when objects are visually indistinguishable or observations\nare corrupted by noise. We propose C-DOG, a training-free framework that serves\nas an intermediate module bridging object detection (or pose estimation) and 3D\nreconstruction, without relying on visual features. It combines connected\ndelta-overlap graph modeling with epipolar geometry to robustly associate\ndetections across views. Each 2D observation is represented as a graph node,\nwith edges weighted by epipolar consistency. A delta-neighbor-overlap\nclustering step identifies strongly consistent groups while tolerating noise\nand partial connectivity. To further improve robustness, we incorporate\nInterquartile Range (IQR)-based filtering and a 3D back-projection error\ncriterion to eliminate inconsistent observations. Extensive experiments on\nsynthetic benchmarks demonstrate that C-DOG outperforms geometry-based\nbaselines and remains robust under challenging conditions, including high\nobject density, without visual features, and limited camera overlap, making it\nwell-suited for scalable 3D reconstruction in real-world scenarios.", "AI": {"tldr": "The paper introduces C-DOG, a framework for multi-view multi-object association in 3D reconstruction that uses graph modeling and epipolar geometry rather than visual features for robustness under challenging conditions.", "motivation": "Existing methods for multi-view multi-object association struggle under challenging scenarios, such as visually indistinguishable objects or noisy data. The paper aims to solve this gap by developing a robust and scalable alternative.", "method": "The framework, called C-DOG, models associations with connected delta-overlap graphs and uses epipolar geometry, along with clustering and filtering techniques like IQR-based filtering and 3D back-projection error criteria.", "result": "Experiments on synthetic benchmarks show that C-DOG outperforms baseline methods, remaining reliable even under high object density, noise, and limited camera overlap.", "conclusion": "C-DOG enables scalable and robust 3D reconstruction in real-world scenarios, eliminating the reliance on visual features and ensuring consistency in challenging multi-view settings."}}
{"id": "2507.14137", "pdf": "https://arxiv.org/pdf/2507.14137", "abs": "https://arxiv.org/abs/2507.14137", "authors": ["Shashanka Venkataramanan", "Valentinos Pariza", "Mohammadreza Salehi", "Lukas Knobel", "Spyros Gidaris", "Elias Ramzi", "Andrei Bursuc", "Yuki M. Asano"], "title": "Franca: Nested Matryoshka Clustering for Scalable Visual Representation Learning", "categories": ["cs.CV"], "comment": null, "summary": "We present Franca (pronounced Fran-ka): free one; the first fully open-source\n(data, code, weights) vision foundation model that matches and in many cases\nsurpasses the performance of state-of-the-art proprietary models, e.g., DINOv2,\nCLIP, SigLIPv2, etc. Our approach is grounded in a transparent training\npipeline inspired by Web-SSL and uses publicly available data: ImageNet-21K and\na subset of ReLAION-2B. Beyond model release, we tackle critical limitations in\nSSL clustering methods. While modern models rely on assigning image features to\nlarge codebooks via clustering algorithms like Sinkhorn-Knopp, they fail to\naccount for the inherent ambiguity in clustering semantics. To address this, we\nintroduce a parameter-efficient, multi-head clustering projector based on\nnested Matryoshka representations. This design progressively refines features\ninto increasingly fine-grained clusters without increasing the model size,\nenabling both performance and memory efficiency. Additionally, we propose a\nnovel positional disentanglement strategy that explicitly removes positional\nbiases from dense representations, thereby improving the encoding of semantic\ncontent. This leads to consistent gains on several downstream benchmarks,\ndemonstrating the utility of cleaner feature spaces. Our contributions\nestablish a new standard for transparent, high-performance vision models and\nopen a path toward more reproducible and generalizable foundation models for\nthe broader AI community. The code and model checkpoints are available at\nhttps://github.com/valeoai/Franca.", "AI": {"tldr": "Franca is a fully open-source vision foundation model that outperforms proprietary models while addressing clustering and positional bias limitations.", "motivation": "To provide a transparent, high-performance, and open-source vision foundation model, addressing limitations in state-of-the-art clustering methods and positional biases.", "method": "Franca applies a nested multi-head clustering projector for fine-grained feature refinement and positional disentanglement strategy to remove positional biases.", "result": "Franca achieves consistent improvements on downstream benchmarks, outperforming existing state-of-the-art models.", "conclusion": "Franca sets a new standard for open, transparent, and reproducible vision foundation models, advancing the AI community's ability to create generalizable models."}}
{"id": "2507.13802", "pdf": "https://arxiv.org/pdf/2507.13802", "abs": "https://arxiv.org/abs/2507.13802", "authors": ["Nehir Kizililsoley", "Floor van Meer", "Osman Mutlu", "Wouter F Hoenderdaal", "Rosan G. Hob\u00e9", "Wenjuan Mu", "Arjen Gerssen", "H. J. van der Fels-Klerx", "\u00c1kos J\u00f3\u017awiak", "Ioannis Manikas", "Ali H\u00fcrriyeto\u01e7lu", "Bas H. M. van der Velden"], "title": "Food safety trends across Europe: insights from the 392-million-entry CompreHensive European Food Safety (CHEFS) database", "categories": ["cs.CY", "cs.AI", "cs.CV"], "comment": null, "summary": "In the European Union, official food safety monitoring data collected by\nmember states are submitted to the European Food Safety Authority (EFSA) and\npublished on Zenodo. This data includes 392 million analytical results derived\nfrom over 15.2 million samples covering more than 4,000 different types of food\nproducts, offering great opportunities for artificial intelligence to analyze\ntrends, predict hazards, and support early warning systems. However, the\ncurrent format with data distributed across approximately 1000 files totaling\nseveral hundred gigabytes hinders accessibility and analysis. To address this,\nwe introduce the CompreHensive European Food Safety (CHEFS) database, which\nconsolidates EFSA monitoring data on pesticide residues, veterinary medicinal\nproduct residues, and chemical contaminants into a unified and structured\ndataset. We describe the creation and structure of the CHEFS database and\ndemonstrate its potential by analyzing trends in European food safety\nmonitoring data from 2000 to 2024. Our analyses explore changes in monitoring\nactivities, the most frequently tested products, which products were most often\nnon-compliant and which contaminants were most often found, and differences\nacross countries. These findings highlight the CHEFS database as both a\ncentralized data source and a strategic tool for guiding food safety policy,\nresearch, and regulation.", "AI": {"tldr": "The CHEFS database consolidates extensive EU food safety monitoring data into a unified format, enabling easier accessibility and analysis to support policy, research, and regulation.", "motivation": "The motivation is to overcome the challenges posed by scattered and inaccessible EU food safety monitoring data, hindering effective analysis and policy-making.", "method": "They created the CHEFS database by integrating and structuring monitoring data on pesticide residues, veterinary medicinal products, and chemical contaminants collected by EFSA, covering 15.2 million samples over 24 years.", "result": "The unified CHEFS database revealed trends in food safety monitoring, including non-compliance rates, common contaminants, frequently tested products, and differences in monitoring efforts across countries.", "conclusion": "The CHEFS database serves as an essential centralized resource to improve food safety monitoring, guide research, and inform EU-wide food safety regulations."}}
{"id": "2507.13366", "pdf": "https://arxiv.org/pdf/2507.13366", "abs": "https://arxiv.org/abs/2507.13366", "authors": ["Baoshen Guo", "Zhiqing Hong", "Junyi Li", "Shenhao Wang", "Jinhua Zhao"], "title": "Leveraging the Spatial Hierarchy: Coarse-to-fine Trajectory Generation via Cascaded Hybrid Diffusion", "categories": ["cs.SI", "cs.CV"], "comment": null, "summary": "Urban mobility data has significant connections with economic growth and\nplays an essential role in various smart-city applications. However, due to\nprivacy concerns and substantial data collection costs, fine-grained human\nmobility trajectories are difficult to become publicly available on a large\nscale. A promising solution to address this issue is trajectory synthesizing.\nHowever, existing works often ignore the inherent structural complexity of\ntrajectories, unable to handle complicated high-dimensional distributions and\ngenerate realistic fine-grained trajectories. In this paper, we propose\nCardiff, a coarse-to-fine Cascaded hybrid diffusion-based trajectory\nsynthesizing framework for fine-grained and privacy-preserving mobility\ngeneration. By leveraging the hierarchical nature of urban mobility, Cardiff\ndecomposes the generation process into two distinct levels, i.e., discrete road\nsegment-level and continuous fine-grained GPS-level: (i) In the segment-level,\nto reduce computational costs and redundancy in raw trajectories, we first\nencode the discrete road segments into low-dimensional latent embeddings and\ndesign a diffusion transformer-based latent denoising network for segment-level\ntrajectory synthesis. (ii) Taking the first stage of generation as conditions,\nwe then design a fine-grained GPS-level conditional denoising network with a\nnoise augmentation mechanism to achieve robust and high-fidelity generation.\nAdditionally, the Cardiff framework not only progressively generates\nhigh-fidelity trajectories through cascaded denoising but also flexibly enables\na tunable balance between privacy preservation and utility. Experimental\nresults on three large real-world trajectory datasets demonstrate that our\nmethod outperforms state-of-the-art baselines in various metrics.", "AI": {"tldr": "Cardiff proposes a novel diffusion-based framework for synthesizing fine-grained and privacy-preserving urban mobility data, effectively addressing challenges in generating realistic human mobility trajectories.", "motivation": "The paper aims to tackle privacy concerns and high data collection costs that hinder the availability of fine-grained human mobility trajectories, which are essential for economic growth and smart-city applications.", "method": "The proposed method uses a coarse-to-fine cascaded framework leveraging hierarchical urban mobility structure. It combines transformer-based latent denoising at the segment level and conditional denoising with noise augmentation at the GPS level.", "result": "Experimental results on three large-scale datasets show that Cardiff achieves superior performance compared to state-of-the-art methods in generating realistic and privacy-preserving mobility trajectories.", "conclusion": "Cardiff provides a robust solution for generating fine-grained mobility data while balancing utility and privacy preservation, offering advancements both in methodology and practical applications for smart cities."}}
{"id": "2507.13700", "pdf": "https://arxiv.org/pdf/2507.13700", "abs": "https://arxiv.org/abs/2507.13700", "authors": ["Emma Rapoport", "Edith Cohen", "Uri Stemmer"], "title": "Tight Bounds for Answering Adaptively Chosen Concentrated Queries", "categories": ["cs.DS", "cs.LG"], "comment": null, "summary": "Most work on adaptive data analysis assumes that samples in the dataset are\nindependent. When correlations are allowed, even the non-adaptive setting can\nbecome intractable, unless some structural constraints are imposed. To address\nthis, Bassily and Freund [2016] introduced the elegant framework of\nconcentrated queries, which requires the analyst to restrict itself to queries\nthat are concentrated around their expected value. While this assumption makes\nthe problem trivial in the non-adaptive setting, in the adaptive setting it\nremains quite challenging. In fact, all known algorithms in this framework\nsupport significantly fewer queries than in the independent case: At most\n$O(n)$ queries for a sample of size $n$, compared to $O(n^2)$ in the\nindependent setting.\n  In this work, we prove that this utility gap is inherent under the current\nformulation of the concentrated queries framework, assuming some natural\nconditions on the algorithm. Additionally, we present a simplified version of\nthe best-known algorithms that match our impossibility result.", "AI": {"tldr": "This paper investigates challenges in adaptive data analysis when data samples are correlated and focuses on the framework of concentrated queries.", "motivation": "To address the intractability of correlated data in non-adaptive settings and explore limitations in adaptive settings using the concentrated queries framework.", "method": "The research establishes theoretical impossibility results under the concentrated queries framework and provides a simplified version of existing algorithms.", "result": "The study confirms a gap in utility between correlated and independent data settings in adaptive data analysis for concentrated queries.", "conclusion": "The inherent limitations in the concentrated queries framework, under current assumptions, restrict utility in adaptive settings compared to independent data scenarios."}}
{"id": "2507.13367", "pdf": "https://arxiv.org/pdf/2507.13367", "abs": "https://arxiv.org/abs/2507.13367", "authors": ["Mehrab Hosain", "Rajiv Kapoor"], "title": "A Novel APVD Steganography Technique Incorporating Pseudorandom Pixel Selection for Robust Image Security", "categories": ["cs.CR", "cs.CV", "cs.MM", "eess.IV", "68Q80", "I.4.2"], "comment": "Accepted COMITCON 2023. Lecture Notes in Electrical Engineering, vol\n  1191. Springer", "summary": "Steganography is the process of embedding secret information discreetly\nwithin a carrier, ensuring secure exchange of confidential data. The Adaptive\nPixel Value Differencing (APVD) steganography method, while effective,\nencounters certain challenges like the \"unused blocks\" issue. This problem can\ncause a decrease in security, compromise the embedding capacity, and lead to\nlower visual quality. This research presents a novel steganographic strategy\nthat integrates APVD with pseudorandom pixel selection to effectively mitigate\nthese issues. The results indicate that the new method outperforms existing\ntechniques in aspects of security, data hiding capacity, and the preservation\nof image quality. Empirical results reveal that the combination of APVD with\npseudorandom pixel selection significantly enhances key image quality metrics\nsuch as Peak Signal-to-Noise Ratio (PSNR), Universal Image Quality Index (UIQ),\nand Structural Similarity Index (SSIM), surpassing other contemporary methods\nin performance. The newly proposed method is versatile, able to handle a\nvariety of cover and secret images in both color and grayscale, thereby\nensuring secure data transmission without compromising the aesthetic quality of\nthe image.", "AI": {"tldr": "The study improves steganography by integrating Adaptive Pixel Value Differencing (APVD) with pseudorandom pixel selection, enhancing image security, capacity, and quality.", "motivation": "APVD steganography faces challenges with unused blocks, which reduce security and image quality.", "method": "The paper proposes combining APVD with pseudorandom pixel selection to overcome unused block issues and enhance performance.", "result": "The approach improves image metrics such as PSNR, UIQ, and SSIM, achieving better security and aesthetic quality compared to existing methods.", "conclusion": "The proposed method enhances steganographic embedding across diverse images, ensuring secure data transmission without loss of visual quality."}}
{"id": "2507.13710", "pdf": "https://arxiv.org/pdf/2507.13710", "abs": "https://arxiv.org/abs/2507.13710", "authors": ["Jing Chang", "Chang Liu", "Jinbin Huang", "Rui Mao", "Jianbin Qin"], "title": "CogniQ-H: A Soft Hierarchical Reinforcement Learning Paradigm for Automated Data Preparation", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Data preparation is a foundational yet notoriously challenging component of\nthe machine learning lifecycle, characterized by a vast combinatorial search\nspace of potential operator sequences. While reinforcement learning (RL) offers\na promising direction, existing approaches are inefficient as they fail to\ncapture the structured, hierarchical nature of the problem. We argue that\nHierarchical Reinforcement Learning (HRL), a paradigm that has been successful\nin other domains, provides a conceptually ideal yet previously unexplored\nframework for this task. However, a naive HRL implementation with a `hard\nhierarchy' is prone to suboptimal, irreversible decisions. To address this, we\nintroduce CogniQ-H, the first framework to implement a soft hierarchical\nparadigm for robust, end-to-end automated data preparation. CogniQ-H formulates\naction selection as a Bayesian inference problem. A high-level strategic prior,\ngenerated by a Large Language Model (LLM), guides exploration\nprobabilistically. This prior is synergistically combined with a fine-grained\noperator quality score from a supervised Learning-to-Rank (LTR) model and a\nlong-term value estimate from the agent's own Q-function. This hybrid\narchitecture allows CogniQ-H to balance strategic guidance with adaptive,\nevidence-based decision-making. Through extensive experiments on 18 diverse\ndatasets spanning multiple domains, we demonstrate that CogniQ-H achieves up to\n13.9\\% improvement in pipeline quality and 2.8$\\times$ faster convergence\ncompared to state-of-the-art RL-based methods.", "AI": {"tldr": "The paper introduces CogniQ-H, a soft hierarchical reinforcement learning framework, for automated data preparation that shows significant improvement in pipeline quality and efficiency.", "motivation": "Existing reinforcement learning methods for data preparation are inefficient due to their inability to leverage the structured and hierarchical nature of the task.", "method": "CogniQ-H employs a soft hierarchical reinforcement learning approach, combining strategic priors from large language models, operator scores from supervised Learning-to-Rank models, and value estimates from the agent's Q-function for balanced decision-making.", "result": "CogniQ-H improves pipeline quality by up to 13.9% and achieves 2.8x faster convergence compared to state-of-the-art reinforcement learning methods based on experiments with 18 diverse datasets.", "conclusion": "The authors conclude that Hierarchical Reinforcement Learning, specifically their soft hierarchical approach in CogniQ-H, is a robust and efficient framework for automated data preparation, offering superior quality and speed compared to existing methods."}}
{"id": "2507.13377", "pdf": "https://arxiv.org/pdf/2507.13377", "abs": "https://arxiv.org/abs/2507.13377", "authors": ["Zhenglin Pan", "Haoran Xie"], "title": "StructInbet: Integrating Explicit Structural Guidance into Inbetween Frame Generation", "categories": ["cs.GR", "cs.CV"], "comment": "3 pages, 3 figures. SIGGRAPH 2025 Poster", "summary": "In this paper, we propose StructInbet, an inbetweening system designed to\ngenerate controllable transitions over explicit structural guidance.\nStructInbet introduces two key contributions. First, we propose explicit\nstructural guidance to the inbetweening problem to reduce the ambiguity\ninherent in pixel trajectories. Second, we adopt a temporal attention mechanism\nthat incorporates visual identity from both the preceding and succeeding\nkeyframes, ensuring consistency in character appearance.", "AI": {"tldr": "The paper introduces StructInbet, a system for generating controllable transitions in animations based on explicit structural guidance and a temporal attention mechanism.", "motivation": "To address ambiguity in pixel trajectories and ensure consistency in character appearance for animation transitions.", "method": "StructInbet adds explicit structural guidance to reduce trajectory ambiguity and uses a temporal attention mechanism to maintain visual identity across keyframes.", "result": "StructInbet successfully reduces ambiguity and ensures appearance consistency during character transitions.", "conclusion": "The system introduces a novel approach to animation inbetweening by combining structural guidance and temporal attention, achieving better control and consistency."}}
{"id": "2507.13712", "pdf": "https://arxiv.org/pdf/2507.13712", "abs": "https://arxiv.org/abs/2507.13712", "authors": ["Jing Chang", "Chang Liu", "Jinbin Huang", "Rui Mao", "Jianbin Qin"], "title": "LLaPipe: LLM-Guided Reinforcement Learning for Automated Data Preparation Pipeline Construction", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Automated data preparation is crucial for democratizing machine learning, yet\nexisting reinforcement learning (RL) based approaches suffer from inefficient\nexploration in the vast space of possible preprocessing pipelines. We present\nLLaPipe, a novel framework that addresses this exploration bottleneck by\nintegrating Large Language Models (LLMs) as intelligent policy advisors. Unlike\ntraditional methods that rely solely on statistical features and blind\ntrial-and-error, LLaPipe leverages the semantic understanding capabilities of\nLLMs to provide contextually relevant exploration guidance. Our framework\nintroduces three key innovations: (1) an LLM Policy Advisor that analyzes\ndataset semantics and pipeline history to suggest promising preprocessing\noperations, (2) an Experience Distillation mechanism that mines successful\npatterns from past pipelines and transfers this knowledge to guide future\nexploration, and (3) an Adaptive Advisor Triggering strategy\n(Advisor\\textsuperscript{+}) that dynamically determines when LLM intervention\nis most beneficial, balancing exploration effectiveness with computational\ncost. Through extensive experiments on 18 diverse datasets spanning multiple\ndomains, we demonstrate that LLaPipe achieves up to 22.4\\% improvement in\npipeline quality and 2.3$\\times$ faster convergence compared to\nstate-of-the-art RL-based methods, while maintaining computational efficiency\nthrough selective LLM usage (averaging only 19.0\\% of total exploration steps).", "AI": {"tldr": "LLaPipe introduces a framework using Large Language Models (LLMs) to improve the efficiency of preprocessing pipeline exploration in machine learning. It achieves better quality and faster convergence than traditional methods.", "motivation": "Existing RL-based approaches for automated data preparation are inefficient in exploring complex preprocessing pipelines.", "method": "LLaPipe incorporates an LLM Policy Advisor for semantic guidance, an Experience Distillation mechanism for knowledge transfer, and an Adaptive Advisor Triggering strategy for optimizing LLM usage.", "result": "LLaPipe improves pipeline quality by up to 22.4%, speeds up convergence by 2.3 times, and uses LLMs in only 19% of the exploration steps, ensuring computational efficiency.", "conclusion": "The framework demonstrates the effectiveness of leveraging LLMs as intelligent advisors in automated machine learning data preparation, balancing performance and efficiency."}}
{"id": "2507.13394", "pdf": "https://arxiv.org/pdf/2507.13394", "abs": "https://arxiv.org/abs/2507.13394", "authors": ["Akhil John Thomas", "Christiaan Boerkamp"], "title": "Enhanced DeepLab Based Nerve Segmentation with Optimized Tuning", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Nerve segmentation is crucial in medical imaging for precise identification\nof nerve structures. This study presents an optimized DeepLabV3-based\nsegmentation pipeline that incorporates automated threshold fine-tuning to\nimprove segmentation accuracy. By refining preprocessing steps and implementing\nparameter optimization, we achieved a Dice Score of 0.78, an IoU of 0.70, and a\nPixel Accuracy of 0.95 on ultrasound nerve imaging. The results demonstrate\nsignificant improvements over baseline models and highlight the importance of\ntailored parameter selection in automated nerve detection.", "AI": {"tldr": "This paper introduces an optimized DeepLabV3-based pipeline for nerve segmentation in medical imaging, yielding improved accuracy metrics.", "motivation": "The research aims to enhance the accuracy and reliability of nerve segmentation in medical imaging, addressing limitations in existing methods.", "method": "The study employs a DeepLabV3-based segmentation pipeline, integrating automated threshold fine-tuning along with optimized preprocessing and parameter selection.", "result": "The proposed pipeline achieved a Dice Score of 0.78, IoU of 0.70, and Pixel Accuracy of 0.95 on ultrasound nerve imaging, surpassing baseline models.", "conclusion": "Tailored parameter selection and preprocessing optimization proved essential in improving automated nerve detection accuracy in medical imaging."}}
{"id": "2507.13957", "pdf": "https://arxiv.org/pdf/2507.13957", "abs": "https://arxiv.org/abs/2507.13957", "authors": ["Yitong Li", "Raoul Grasman"], "title": "DUALRec: A Hybrid Sequential and Language Model Framework for Context-Aware Movie Recommendation", "categories": ["cs.IR", "cs.AI", "cs.LG", "68T05, 68T50, 62M45", "H.3.3; I.2.6; H.3.4; I.2.7"], "comment": "10 pages, 5 figures", "summary": "The modern recommender systems are facing an increasing challenge of\nmodelling and predicting the dynamic and context-rich user preferences.\nTraditional collaborative filtering and content-based methods often struggle to\ncapture the temporal patternings and evolving user intentions. While Large\nLanguage Models (LLMs) have gained gradual attention in recent years, by their\nstrong semantic understanding and reasoning abilities, they are not inherently\ndesigned to model chronologically evolving user preference and intentions. On\nthe other hand, for sequential models like LSTM (Long-Short-Term-Memory) which\nis good at capturing the temporal dynamics of user behaviour and evolving user\npreference over time, but still lacks a rich semantic understanding for\ncomprehensive recommendation generation. In this study, we propose DUALRec\n(Dynamic User-Aware Language-based Recommender), a novel recommender that\nleverages the complementary strength of both models, which combines the\ntemporal modelling abilities of LSTM networks with semantic reasoning power of\nthe fine-tuned Large Language Models. The LSTM component will capture users\nevolving preference through their viewing history, while the fine-tuned LLM\nvariants will leverage these temporal user insights to generate next movies\nthat users might enjoy. Experimental results on MovieLens-1M dataset shows that\nthe DUALRec model outperforms a wide range of baseline models, with\ncomprehensive evaluation matrices of Hit Rate (HR@k), Normalized Discounted\nCumulative Gain (NDCG@k), and genre similarity metrics. This research proposes\na novel architecture that bridges the gap between temporal sequence modeling\nand semantic reasoning, and offers a promising direction for developing more\nintelligent and context-aware recommenders.", "AI": {"tldr": "DUALRec is a hybrid recommender system combining LSTM's temporal modeling with the semantic reasoning of fine-tuned Large Language Models (LLMs). It outperforms baseline models on the MovieLens-1M dataset.", "motivation": "Recommender systems struggle to model dynamic, context-rich user preferences. While LLMs offer semantic understanding, they lack temporal modeling capabilities, and LSTM models capture temporal dynamics but lack rich semantic reasoning.", "method": "DUALRec integrates LSTM for temporal modeling and fine-tuned LLMs for semantic reasoning. The LSTM processes user viewing histories, and the LLM generates recommendations using temporal insights.", "result": "Experimental validation on MovieLens-1M dataset demonstrates DUALRec's superior performance, evaluated with metrics like Hit Rate (HR@k), NDCG@k, and genre similarity.", "conclusion": "DUALRec showcases the potential of combining temporal and semantic capabilities in recommender systems, pointing to promising advancements for intelligent, context-aware recommendation models."}}
{"id": "2507.13782", "pdf": "https://arxiv.org/pdf/2507.13782", "abs": "https://arxiv.org/abs/2507.13782", "authors": ["Malo Gicquel", "Ruoyi Zhao", "Anika Wuestefeld", "Nicola Spotorno", "Olof Strandberg", "Kalle \u00c5str\u00f6m", "Yu Xiao", "Laura EM Wisse", "Danielle van Westen", "Rik Ossenkoppele", "Niklas Mattsson-Carlgren", "David Berron", "Oskar Hansson", "Gabrielle Flood", "Jacob Vogel"], "title": "Converting T1-weighted MRI from 3T to 7T quality using deep learning", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Ultra-high resolution 7 tesla (7T) magnetic resonance imaging (MRI) provides\ndetailed anatomical views, offering better signal-to-noise ratio, resolution\nand tissue contrast than 3T MRI, though at the cost of accessibility. We\npresent an advanced deep learning model for synthesizing 7T brain MRI from 3T\nbrain MRI. Paired 7T and 3T T1-weighted images were acquired from 172\nparticipants (124 cognitively unimpaired, 48 impaired) from the Swedish\nBioFINDER-2 study. To synthesize 7T MRI from 3T images, we trained two models:\na specialized U-Net, and a U-Net integrated with a generative adversarial\nnetwork (GAN U-Net). Our models outperformed two additional state-of-the-art\n3T-to-7T models in image-based evaluation metrics. Four blinded MRI\nprofessionals judged our synthetic 7T images as comparable in detail to real 7T\nimages, and superior in subjective visual quality to 7T images, apparently due\nto the reduction of artifacts. Importantly, automated segmentations of the\namygdalae of synthetic GAN U-Net 7T images were more similar to manually\nsegmented amygdalae (n=20), than automated segmentations from the 3T images\nthat were used to synthesize the 7T images. Finally, synthetic 7T images showed\nsimilar performance to real 3T images in downstream prediction of cognitive\nstatus using MRI derivatives (n=3,168). In all, we show that synthetic\nT1-weighted brain images approaching 7T quality can be generated from 3T\nimages, which may improve image quality and segmentation, without compromising\nperformance in downstream tasks. Future directions, possible clinical use\ncases, and limitations are discussed.", "AI": {"tldr": "The paper introduces a deep learning method to synthesize ultra-high-resolution 7T brain MRIs from 3T MRIs, achieving almost real 7T image quality.", "motivation": "To make ultra-high-resolution 7T MRI more accessible by synthesizing 7T images from widely available 3T MRIs, addressing cost and accessibility barriers.", "method": "Two advanced deep learning models, U-Net and GAN U-Net, were trained on paired 7T and 3T images from 172 participants. The models' performance was compared to other state-of-the-art techniques.", "result": "The models produced synthetic 7T images comparable to real 7T images in quality, as judged by MRI professionals. Additionally, synthetic images offered better artifact reduction and segmentation accuracy while maintaining performance in cognitive prediction tasks.", "conclusion": "Synthetic 7T brain images can be effectively generated from 3T MRIs, enhancing image quality, segmentation accuracy, and potential clinical applications."}}
{"id": "2507.13830", "pdf": "https://arxiv.org/pdf/2507.13830", "abs": "https://arxiv.org/abs/2507.13830", "authors": ["Maximilian Rokuss", "Benjamin Hamm", "Yannick Kirchhoff", "Klaus Maier-Hein"], "title": "Divide and Conquer: A Large-Scale Dataset and Model for Left-Right Breast MRI Segmentation", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted at MICCAI 2025 WOMEN", "summary": "We introduce the first publicly available breast MRI dataset with explicit\nleft and right breast segmentation labels, encompassing more than 13,000\nannotated cases. Alongside this dataset, we provide a robust deep-learning\nmodel trained for left-right breast segmentation. This work addresses a\ncritical gap in breast MRI analysis and offers a valuable resource for the\ndevelopment of advanced tools in women's health. The dataset and trained model\nare publicly available at: www.github.com/MIC-DKFZ/BreastDivider", "AI": {"tldr": "Public breast MRI dataset with left-right segmentation labels introduced, featuring 13,000+ cases and a robust accompanying model.", "motivation": "To address the lack of publicly available datasets with explicit left-right segmentation labels in breast MRI analysis.", "method": "Creation of a breast MRI dataset with over 13,000 annotations and development of a deep-learning model for segmentation.", "result": "A comprehensive dataset and validated segmentation model for left-right breast detection.", "conclusion": "The dataset and model fill a critical gap in breast MRI analysis and support advancements in women's health research."}}
{"id": "2507.14046", "pdf": "https://arxiv.org/pdf/2507.14046", "abs": "https://arxiv.org/abs/2507.14046", "authors": ["Hao Fang", "Hao Yu", "Sihao Teng", "Tao Zhang", "Siyi Yuan", "Huaiwu He", "Zhe Liu", "Yunjie Yang"], "title": "D2IP: Deep Dynamic Image Prior for 3D Time-sequence Pulmonary Impedance Imaging", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "11 pages, 9 figures", "summary": "Unsupervised learning methods, such as Deep Image Prior (DIP), have shown\ngreat potential in tomographic imaging due to their training-data-free nature\nand high generalization capability. However, their reliance on numerous network\nparameter iterations results in high computational costs, limiting their\npractical application, particularly in complex 3D or time-sequence tomographic\nimaging tasks. To overcome these challenges, we propose Deep Dynamic Image\nPrior (D2IP), a novel framework for 3D time-sequence imaging. D2IP introduces\nthree key strategies - Unsupervised Parameter Warm-Start (UPWS), Temporal\nParameter Propagation (TPP), and a customized lightweight reconstruction\nbackbone, 3D-FastResUNet - to accelerate convergence, enforce temporal\ncoherence, and improve computational efficiency. Experimental results on both\nsimulated and clinical pulmonary datasets demonstrate that D2IP enables fast\nand accurate 3D time-sequence Electrical Impedance Tomography (tsEIT)\nreconstruction. Compared to state-of-the-art baselines, D2IP delivers superior\nimage quality, with a 24.8% increase in average MSSIM and an 8.1% reduction in\nERR, alongside significantly reduced computational time (7.1x faster),\nhighlighting its promise for clinical dynamic pulmonary imaging.", "AI": {"tldr": "The paper introduces Deep Dynamic Image Prior (D2IP), a framework for fast and accurate 3D time-sequence tomographic imaging, improving upon the computational inefficiency of Deep Image Prior.", "motivation": "To address the high computational cost and inefficiency of unsupervised methods like Deep Image Prior in complex 3D or time-sequence tomographic imaging.", "method": "The paper proposes D2IP, which utilizes three strategies: Unsupervised Parameter Warm-Start (UPWS), Temporal Parameter Propagation (TPP), and a lightweight reconstruction backbone, 3D-FastResUNet.", "result": "Experiments on simulated and clinical pulmonary datasets show that D2IP improves image quality by 24.8% (average MSSIM), reduces error by 8.1%, and is 7.1x faster compared to existing methods.", "conclusion": "D2IP significantly enhances the speed and accuracy of 3D time-sequence imaging, making it promising for clinical applications such as dynamic pulmonary imaging."}}
{"id": "2507.13901", "pdf": "https://arxiv.org/pdf/2507.13901", "abs": "https://arxiv.org/abs/2507.13901", "authors": ["Lei Xu", "Torkel B Brismar"], "title": "Software architecture and manual for novel versatile CT image analysis toolbox -- AnatomyArchive", "categories": ["eess.IV", "cs.CV", "62H35, 68U10", "I.4.10; I.4.7; J.3"], "comment": "24 pages, 7 figures", "summary": "We have developed a novel CT image analysis package named AnatomyArchive,\nbuilt on top of the recent full body segmentation model TotalSegmentator. It\nprovides automatic target volume selection and deselection capabilities\naccording to user-configured anatomies for volumetric upper- and lower-bounds.\nIt has a knowledge graph-based and time efficient tool for anatomy segmentation\nmask management and medical image database maintenance. AnatomyArchive enables\nautomatic body volume cropping, as well as automatic arm-detection and\nexclusion, for more precise body composition analysis in both 2D and 3D\nformats. It provides robust voxel-based radiomic feature extraction, feature\nvisualization, and an integrated toolchain for statistical tests and analysis.\nA python-based GPU-accelerated nearly photo-realistic segmentation-integrated\ncomposite cinematic rendering is also included. We present here its software\narchitecture design, illustrate its workflow and working principle of\nalgorithms as well provide a few examples on how the software can be used to\nassist development of modern machine learning models. Open-source codes will be\nreleased at https://github.com/lxu-medai/AnatomyArchive for only research and\neducational purposes.", "AI": {"tldr": "AnatomyArchive is a CT image analysis tool leveraging TotalSegmentator for automatic anatomy segmentation, body volume management, and advanced radiomic feature extraction.", "motivation": "To create an efficient, precise, and automated tool for CT image analysis that addresses challenges of manual segmentation and enhances machine learning model development.", "method": "Builds on the TotalSegmentator model, integrating automated anatomy selection, cropping, segmentation mask management, GPU-accelerated rendering, and statistical tools.", "result": "Developed a time-efficient, GPU-accelerated software for detailed CT body segmentation and analysis with various supportive tools for research and education.", "conclusion": "AnatomyArchive simplifies segmentation tasks, aids accurate analyses, and supports machine learning development, with open-source availability for non-commercial use."}}
{"id": "2507.13993", "pdf": "https://arxiv.org/pdf/2507.13993", "abs": "https://arxiv.org/abs/2507.13993", "authors": ["Ningyong Wu", "Jinzhi Wang", "Wenhong Zhao", "Chenzhan Yu", "Zhigang Xiu", "Duwei Dai"], "title": "OrthoInsight: Rib Fracture Diagnosis and Report Generation Based on Multi-Modal Large Models", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "The growing volume of medical imaging data has increased the need for\nautomated diagnostic tools, especially for musculoskeletal injuries like rib\nfractures, commonly detected via CT scans. Manual interpretation is\ntime-consuming and error-prone. We propose OrthoInsight, a multi-modal deep\nlearning framework for rib fracture diagnosis and report generation. It\nintegrates a YOLOv9 model for fracture detection, a medical knowledge graph for\nretrieving clinical context, and a fine-tuned LLaVA language model for\ngenerating diagnostic reports. OrthoInsight combines visual features from CT\nimages with expert textual data to deliver clinically useful outputs. Evaluated\non 28,675 annotated CT images and expert reports, it achieves high performance\nacross Diagnostic Accuracy, Content Completeness, Logical Coherence, and\nClinical Guidance Value, with an average score of 4.28, outperforming models\nlike GPT-4 and Claude-3. This study demonstrates the potential of multi-modal\nlearning in transforming medical image analysis and providing effective support\nfor radiologists.", "AI": {"tldr": "This paper introduces OrthoInsight, a deep learning framework for detecting rib fractures and generating diagnostic reports using multi-modal data from CT scans and medical knowledge.", "motivation": "The paper aims to address the challenges posed by the growing volume of medical imaging data, which requires more efficient and accurate diagnostic tools for musculoskeletal injuries like rib fractures.", "method": "The authors propose OrthoInsight, which integrates a YOLOv9 model for visual fracture detection, a medical knowledge graph for contextual understanding, and a fine-tuned LLaVA model for report generation.", "result": "Using 28,675 annotated CT images and expert reports, OrthoInsight demonstrated superior performance across metrics like Diagnostic Accuracy, Content Completeness, Logical Coherence, and Clinical Guidance Value, surpassing models like GPT-4 and Claude-3.", "conclusion": "OrthoInsight effectively leverages multi-modal learning to enhance medical image analysis and supports radiologists, especially in diagnosing rib fractures through CT scans."}}
{"id": "2507.13915", "pdf": "https://arxiv.org/pdf/2507.13915", "abs": "https://arxiv.org/abs/2507.13915", "authors": ["Huu-Phu Do", "Po-Chih Hu", "Hao-Chien Hsueh", "Che-Kai Liu", "Vu-Hoang Tran", "Ching-Chun Huang"], "title": "Blind Super Resolution with Reference Images and Implicit Degradation Representation", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted by ACCV 2024", "summary": "Previous studies in blind super-resolution (BSR) have primarily concentrated\non estimating degradation kernels directly from low-resolution (LR) inputs to\nenhance super-resolution. However, these degradation kernels, which model the\ntransition from a high-resolution (HR) image to its LR version, should account\nfor not only the degradation process but also the downscaling factor. Applying\nthe same degradation kernel across varying super-resolution scales may be\nimpractical. Our research acknowledges degradation kernels and scaling factors\nas pivotal elements for the BSR task and introduces a novel strategy that\nutilizes HR images as references to establish scale-aware degradation kernels.\nBy employing content-irrelevant HR reference images alongside the target LR\nimage, our model adaptively discerns the degradation process. It is then\napplied to generate additional LR-HR pairs through down-sampling the HR\nreference images, which are keys to improving the SR performance. Our\nreference-based training procedure is applicable to proficiently trained blind\nSR models and zero-shot blind SR methods, consistently outperforming previous\nmethods in both scenarios. This dual consideration of blur kernels and scaling\nfactors, coupled with the use of a reference image, contributes to the\neffectiveness of our approach in blind super-resolution tasks.", "AI": {"tldr": "This paper proposes a novel method for blind super-resolution (BSR) by introducing scale-aware degradation kernels and HR reference images to adaptively discern the degradation process for better SR performance.", "motivation": "To address the limitations of previous BSR techniques, which assumed uniform degradation kernels across different scales, making them impractical for varied super-resolution tasks.", "method": "The method uses high-resolution (HR) reference images, unrelated to the target, alongside the low-resolution (LR) input, to create scale-aware degradation kernels. These references help generate LR-HR pairs, enhancing training and SR performance.", "result": "The proposed approach consistently outperforms prior methods in both trained and zero-shot blind SR models, showcasing improved results across diverse scenarios.", "conclusion": "Dual consideration of both blur kernels and scaling factors, supported by the introduction of reference images, effectively improves the BSR performance and addresses the limitations of prior methods."}}
{"id": "2507.13974", "pdf": "https://arxiv.org/pdf/2507.13974", "abs": "https://arxiv.org/abs/2507.13974", "authors": ["Jiaqi Lv", "Yijie Zhu", "Carmen Guadalupe Colin Tenorio", "Brinder Singh Chohan", "Mark Eastwood", "Shan E Ahmed Raza"], "title": "Leveraging Pathology Foundation Models for Panoptic Segmentation of Melanoma in H&E Images", "categories": ["eess.IV", "cs.CV", "q-bio.QM"], "comment": "Accepted by MIUA 2025", "summary": "Melanoma is an aggressive form of skin cancer with rapid progression and high\nmetastatic potential. Accurate characterisation of tissue morphology in\nmelanoma is crucial for prognosis and treatment planning. However, manual\nsegmentation of tissue regions from haematoxylin and eosin (H&E) stained\nwhole-slide images (WSIs) is labour-intensive and prone to inter-observer\nvariability, this motivates the need for reliable automated tissue segmentation\nmethods. In this study, we propose a novel deep learning network for the\nsegmentation of five tissue classes in melanoma H&E images. Our approach\nleverages Virchow2, a pathology foundation model trained on 3.1 million\nhistopathology images as a feature extractor. These features are fused with the\noriginal RGB images and subsequently processed by an encoder-decoder\nsegmentation network (Efficient-UNet) to produce accurate segmentation maps.\nThe proposed model achieved first place in the tissue segmentation task of the\nPUMA Grand Challenge, demonstrating robust performance and generalizability.\nOur results show the potential and efficacy of incorporating pathology\nfoundation models into segmentation networks to accelerate computational\npathology workflows.", "AI": {"tldr": "The paper introduces a deep learning model using pathology foundation model Virchow2 for accurate segmentation of tissue types in melanoma H&E images.", "motivation": "Melanoma diagnosis and prognosis require precise tissue morphology characterization, but manual segmentation of tissue regions is time-consuming and inconsistent.", "method": "A deep learning approach combines features from pathology foundation model Virchow2 with an Efficient-UNet encoder-decoder network for tissue segmentation.", "result": "The proposed model achieved first place in the PUMA Grand Challenge, showcasing high performance and generalizability in segmentation tasks.", "conclusion": "Incorporating foundation models like Virchow2 with segmentation networks can improve accuracy and efficiency in computational pathology workflows."}}
{"id": "2507.14102", "pdf": "https://arxiv.org/pdf/2507.14102", "abs": "https://arxiv.org/abs/2507.14102", "authors": ["Shravan Venkatraman", "Pavan Kumar S", "Rakesh Raj Madavan", "Chandrakala S"], "title": "UGPL: Uncertainty-Guided Progressive Learning for Evidence-Based Classification in Computed Tomography", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "18 pages, 10 figures, 5 tables, 2025 ICCV Workshops", "summary": "Accurate classification of computed tomography (CT) images is essential for\ndiagnosis and treatment planning, but existing methods often struggle with the\nsubtle and spatially diverse nature of pathological features. Current\napproaches typically process images uniformly, limiting their ability to detect\nlocalized abnormalities that require focused analysis. We introduce UGPL, an\nuncertainty-guided progressive learning framework that performs a\nglobal-to-local analysis by first identifying regions of diagnostic ambiguity\nand then conducting detailed examination of these critical areas. Our approach\nemploys evidential deep learning to quantify predictive uncertainty, guiding\nthe extraction of informative patches through a non-maximum suppression\nmechanism that maintains spatial diversity. This progressive refinement\nstrategy, combined with an adaptive fusion mechanism, enables UGPL to integrate\nboth contextual information and fine-grained details. Experiments across three\nCT datasets demonstrate that UGPL consistently outperforms state-of-the-art\nmethods, achieving improvements of 3.29%, 2.46%, and 8.08% in accuracy for\nkidney abnormality, lung cancer, and COVID-19 detection, respectively. Our\nanalysis shows that the uncertainty-guided component provides substantial\nbenefits, with performance dramatically increasing when the full progressive\nlearning pipeline is implemented. Our code is available at:\nhttps://github.com/shravan-18/UGPL", "AI": {"tldr": "UGPL is an uncertainty-guided progressive learning framework designed to improve CT image classification by focusing on regions of diagnostic ambiguity and conducting detailed analysis. The approach outperforms state-of-the-art methods.", "motivation": "CT image classification for diagnosis and treatment planning faces limitations in detecting localized, subtle pathological features due to existing uniform processing methods.", "method": "UGPL utilizes evidential deep learning to assess predictive uncertainty, identifies regions of diagnostic ambiguity, and extracts informative patches via non-maximum suppression. It employs an adaptive fusion mechanism for global-to-local analysis.", "result": "UGPL outperformed state-of-the-art methods with accuracy improvements of 3.29%, 2.46%, and 8.08% for kidney abnormality, lung cancer, and COVID-19 detection, respectively.", "conclusion": "The uncertainty-guided progressive learning pipeline in UGPL significantly enhances the precision of CT image classification by combining contextual and fine-grained information."}}
{"id": "2507.14109", "pdf": "https://arxiv.org/pdf/2507.14109", "abs": "https://arxiv.org/abs/2507.14109", "authors": ["Xinyu Cao", "Bimal Adhikari", "Shangqing Zhao", "Jingxian Wu", "Yanjun Pan"], "title": "An Adversarial-Driven Experimental Study on Deep Learning for RF Fingerprinting", "categories": ["cs.CR", "cs.LG", "eess.SP"], "comment": null, "summary": "Radio frequency (RF) fingerprinting, which extracts unique hardware\nimperfections of radio devices, has emerged as a promising physical-layer\ndevice identification mechanism in zero trust architectures and beyond 5G\nnetworks. In particular, deep learning (DL) methods have demonstrated\nstate-of-the-art performance in this domain. However, existing approaches have\nprimarily focused on enhancing system robustness against temporal and spatial\nvariations in wireless environments, while the security vulnerabilities of\nthese DL-based approaches have often been overlooked. In this work, we\nsystematically investigate the security risks of DL-based RF fingerprinting\nsystems through an adversarial-driven experimental analysis. We observe a\nconsistent misclassification behavior for DL models under domain shifts, where\na device is frequently misclassified as another specific one. Our analysis\nbased on extensive real-world experiments demonstrates that this behavior can\nbe exploited as an effective backdoor to enable external attackers to intrude\ninto the system. Furthermore, we show that training DL models on raw received\nsignals causes the models to entangle RF fingerprints with environmental and\nsignal-pattern features, creating additional attack vectors that cannot be\nmitigated solely through post-processing security methods such as confidence\nthresholds.", "AI": {"tldr": "The paper investigates the security vulnerabilities in deep learning (DL)-based RF fingerprinting systems and finds that these can be exploited for adversarial attacks.", "motivation": "The study aims to explore security gaps in DL-based RF fingerprinting, as current research focuses more on improving robustness rather than addressing potential vulnerabilities.", "method": "The authors perform adversarial-driven experimental analysis, focusing on DL models' behavior under domain shifts and real-world data.", "result": "Results indicate that DL models misclassify devices consistently under domain shifts, which can act as a backdoor for attackers. Training DL models on raw signals introduces additional vulnerabilities.", "conclusion": "RF fingerprinting systems leveraging DL models are susceptible to adversarial attacks, and existing post-processing security measures are insufficient to counteract the identified threats."}}
{"id": "2507.14116", "pdf": "https://arxiv.org/pdf/2507.14116", "abs": "https://arxiv.org/abs/2507.14116", "authors": ["Dani\u00eblle Schuman", "Mark V. Seebode", "Tobias Rohe", "Maximilian Balthasar Mansky", "Michael Schroedl-Baumann", "Jonas Stein", "Claudia Linnhoff-Popien", "Florian Krellner"], "title": "Quantum Boltzmann Machines using Parallel Annealing for Medical Image Classification", "categories": ["quant-ph", "cs.ET", "cs.LG"], "comment": "12 pages, 5 figures (10 if counting subfigures), 2 tables. To be\n  published in the proceedings of the 2025 IEEE International Conference on\n  Quantum Computing and Engineering (QCE)", "summary": "Exploiting the fact that samples drawn from a quantum annealer inherently\nfollow a Boltzmann-like distribution, annealing-based Quantum Boltzmann\nMachines (QBMs) have gained increasing popularity in the quantum research\ncommunity. While they harbor great promises for quantum speed-up, their usage\ncurrently stays a costly endeavor, as large amounts of QPU time are required to\ntrain them. This limits their applicability in the NISQ era. Following the idea\nof No\\`e et al. (2024), who tried to alleviate this cost by incorporating\nparallel quantum annealing into their unsupervised training of QBMs, this paper\npresents an improved version of parallel quantum annealing that we employ to\ntrain QBMs in a supervised setting. Saving qubits to encode the inputs, the\nlatter setting allows us to test our approach on medical images from the\nMedMNIST data set (Yang et al., 2023), thereby moving closer to real-world\napplicability of the technology. Our experiments show that QBMs using our\napproach already achieve reasonable results, comparable to those of\nsimilarly-sized Convolutional Neural Networks (CNNs), with markedly smaller\nnumbers of epochs than these classical models. Our parallel annealing technique\nleads to a speed-up of almost 70 % compared to regular annealing-based BM\nexecutions.", "AI": {"tldr": "The paper presents an improved parallel quantum annealing method for training Quantum Boltzmann Machines (QBMs) in supervised settings, achieving faster training with significant speed-up and results comparable to Convolutional Neural Networks (CNNs).", "motivation": "Training QBMs requires large amounts of QPU time, making their application costly in the current NISQ era. The authors aim to ameliorate this issue by proposing improvements to parallel quantum annealing techniques.", "method": "The paper introduces an enhanced parallel quantum annealing approach to train QBMs in supervised learning tasks, particularly on medical image data from the MedMNIST dataset.", "result": "Experimental results show that QBMs trained with the proposed method achieve performance comparable to CNNs, requiring fewer epochs and attaining a 70% speed-up in training time compared to conventional annealing-based approaches.", "conclusion": "The improved parallel quantum annealing method by the authors significantly reduces training time and demonstrates that QBMs are viable in real-world applications like medical image analysis, making them more applicable in the NISQ era."}}
{"id": "2507.14084", "pdf": "https://arxiv.org/pdf/2507.14084", "abs": "https://arxiv.org/abs/2507.14084", "authors": ["Maria Tsfasman", "Ramin Ghorbani", "Catholijn M. Jonker", "Bernd Dudzik"], "title": "The Emotion-Memory Link: Do Memorability Annotations Matter for Intelligent Systems?", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Humans have a selective memory, remembering relevant episodes and forgetting\nthe less relevant information. Possessing awareness of event memorability for a\nuser could help intelligent systems in more accurate user modelling, especially\nfor such applications as meeting support systems, memory augmentation, and\nmeeting summarisation. Emotion recognition has been widely studied, since\nemotions are thought to signal moments of high personal relevance to users. The\nemotional experience of situations and their memorability have traditionally\nbeen considered to be closely tied to one another: moments that are experienced\nas highly emotional are considered to also be highly memorable. This\nrelationship suggests that emotional annotations could serve as proxies for\nmemorability. However, existing emotion recognition systems rely heavily on\nthird-party annotations, which may not accurately represent the first-person\nexperience of emotional relevance and memorability. This is why, in this study,\nwe empirically examine the relationship between perceived group emotions\n(Pleasure-Arousal) and group memorability in the context of conversational\ninteractions. Our investigation involves continuous time-based annotations of\nboth emotions and memorability in dynamic, unstructured group settings,\napproximating conditions of real-world conversational AI applications such as\nonline meeting support systems. Our results show that the observed relationship\nbetween affect and memorability annotations cannot be reliably distinguished\nfrom what might be expected under random chance. We discuss the implications of\nthis surprising finding for the development and applications of Affective\nComputing technology. In addition, we contextualise our findings in broader\ndiscourses in the Affective Computing and point out important targets for\nfuture research efforts.", "AI": {"tldr": "The study investigates the link between group emotions and group memorability during conversational interactions, finding no reliable connection.", "motivation": "To explore if emotional annotations can predict event memorability in intelligent systems for applications like meeting support and memory augmentation.", "method": "The research involved analyzing continuous, time-based annotations of emotions (Pleasure-Arousal) and memorability in dynamic group conversations, mimicking real-world scenarios.", "result": "The study found no discernible relationship between emotional cues and memorability annotations, suggesting randomness.", "conclusion": "The findings challenge assumptions in Affective Computing, indicating that emotional cues may not reliably predict memorability, and highlight the need for further investigation."}}
