{"id": "2507.22146", "pdf": "https://arxiv.org/pdf/2507.22146", "abs": "https://arxiv.org/abs/2507.22146", "authors": ["Joy Bose"], "title": "Pendulum Model of Spiking Neurons", "categories": ["cs.NE", "q-bio.NC", "C.1.3; I.5.1; I.6.3"], "comment": "5 pages, 2 figures, 1 table", "summary": "We propose a biologically inspired model of spiking neurons based on the\ndynamics of a damped, driven pendulum. Unlike traditional models such as the\nLeaky Integrate-and-Fire (LIF) neurons, the pendulum neuron incorporates\nsecond-order, nonlinear dynamics that naturally give rise to oscillatory\nbehavior and phase-based spike encoding. This model captures richer temporal\nfeatures and supports timing-sensitive computations critical for sequence\nprocessing and symbolic learning. We present an analysis of single-neuron\ndynamics and extend the model to multi-neuron layers governed by Spike-Timing\nDependent Plasticity (STDP) learning rules. We demonstrate practical\nimplementation with python code and with the Brian2 spiking neural simulator,\nand outline a methodology for deploying the model on neuromorphic hardware\nplatforms, using an approximation of the second-order equations. This framework\noffers a foundation for developing energy-efficient neural systems for\nneuromorphic computing and sequential cognition tasks.", "AI": {"tldr": "The paper introduces a novel spiking neuron model inspired by a damped, driven pendulum, offering richer temporal computations and phase-based spike encoding for tasks like sequence processing.", "motivation": "Standard spiking neuron models, like LIF, lack the capacity for oscillatory behavior and sophisticated timing-sensitive processing necessary for sequence-related and symbolic tasks.", "method": "The authors propose a second-order dynamic model of spiking neurons resembling a pendulum and analyze its dynamics, extend the framework with STDP learning rules, and showcase implementations using Python, Brian2, and neuromorphic hardware approximations.", "result": "The model captures complex temporal characteristics, performs timing-sensitive computations, and is deployable on energy-efficient neuromorphic platforms.", "conclusion": "The pendulum neuron model provides a biologically plausible, computationally rich, and energy-efficient approach for sequence processing and neuromorphic applications."}}
{"id": "2507.22221", "pdf": "https://arxiv.org/pdf/2507.22221", "abs": "https://arxiv.org/abs/2507.22221", "authors": ["Nasrin Akbari", "Mehdi Modarressi", "Alireza Khadem"], "title": "A Customized Memory-aware Architecture for Biological Sequence Alignment", "categories": ["cs.AR", "cs.ET", "n/a", "C.3"], "comment": "20 pages, 11 figures", "summary": "Sequence alignment is a fundamental process in computational biology which\nidentifies regions of similarity in biological sequences. With the exponential\ngrowth in the volume of data in bioinformatics databases, the time, processing\npower, and memory bandwidth for comparing a query sequence with the available\ndatabases grows proportionally. The sequence alignment algorithms often involve\nsimple arithmetic operations and feature high degrees of inherent fine-grained\nand coarse-grained parallelism. These features can be potentially exploited by\na massive parallel processor, such as a GPU, to increase throughput. In this\npaper, we show that the excessive memory bandwidth demand of the sequence\nalignment algorithms prevents exploiting the maximum achievable throughput on\nconventional parallel machines. We then propose a memory-aware architecture to\nreduce the bandwidth demand of the sequence alignment algorithms, effectively\npushing the memory wall to extract higher throughput. The design is integrated\nat the logic layer of an emerging 3D DRAM as a processing-in-memory\narchitecture to further increase the available bandwidth. The experimental\nresults show that the proposed architecture results in up to 2.4x speedup over\na GPU-based design. Moreover, by moving the computation closer to the memory,\npower consumption is reduced by 37%, on average.", "AI": {"tldr": "The paper proposes a processing-in-memory architecture to address memory bandwidth limitations in sequence alignment algorithms, achieving up to 2.4x speedup over GPU designs and 37% average power reduction.", "motivation": "The motivation is rooted in the challenges posed by the growth of bioinformatics data, which demands higher throughput while overcoming the memory bandwidth limitations of sequence alignment algorithms.", "method": "The method involves designing a memory-aware architecture integrated into the logic layer of 3D DRAM for processing-in-memory, optimizing bandwidth and computational efficiency.", "result": "Experimental results show the proposed architecture delivers up to 2.4x speed improvement over GPU-based designs and reduces power consumption by 37% on average.", "conclusion": "The study concludes that integrating computation closer to memory through processing-in-memory allows significant performance and power efficiency improvements in sequence alignment tasks."}}
{"id": "2507.22090", "pdf": "https://arxiv.org/pdf/2507.22090", "abs": "https://arxiv.org/abs/2507.22090", "authors": ["Sergii Kavun"], "title": "Hybrid activation functions for deep neural networks: S3 and S4 -- a novel approach to gradient flow optimization", "categories": ["cs.LG", "cs.AI", "cs.NE", "cs.NI", "68T07, 68T05, 65D10, 68Q32", "I.2.6; I.5.1; G.1.2; I.5.2"], "comment": "15 pages, 2 figures, 5 tables", "summary": "Activation functions are critical components in deep neural networks,\ndirectly influencing gradient flow, training stability, and model performance.\nTraditional functions like ReLU suffer from dead neuron problems, while sigmoid\nand tanh exhibit vanishing gradient issues. We introduce two novel hybrid\nactivation functions: S3 (Sigmoid-Softsign) and its improved version S4\n(smoothed S3). S3 combines sigmoid for negative inputs with softsign for\npositive inputs, while S4 employs a smooth transition mechanism controlled by a\nsteepness parameter k. We conducted comprehensive experiments across binary\nclassification, multi-class classification, and regression tasks using three\ndifferent neural network architectures. S4 demonstrated superior performance\ncompared to nine baseline activation functions, achieving 97.4% accuracy on\nMNIST, 96.0% on Iris classification, and 18.7 MSE on Boston Housing regression.\nThe function exhibited faster convergence (-19 for ReLU) and maintained stable\ngradient flow across network depths. Comparative analysis revealed S4's\ngradient range of [0.24, 0.59] compared to ReLU's 18% dead neurons in deep\nnetworks. The S4 activation function addresses key limitations of existing\nfunctions through its hybrid design and smooth transition mechanism. The\ntunable parameter k allows adaptation to different tasks and network depths,\nmaking S4 a versatile choice for deep learning applications. These findings\nsuggest that hybrid activation functions represent a promising direction for\nimproving neural network training dynamics.", "AI": {"tldr": "This paper introduces two new hybrid activation functions, S3 and S4, which address issues like dead neurons and vanishing gradients prevalent in traditional activation functions.", "motivation": "The traditional activation functions like ReLU, Sigmoid, and Tanh face significant issues such as dead neuron problems and vanishing gradients, hindering neural network performance.", "method": "The proposed hybrid activation function, S3, combines sigmoid for negative inputs and softsign for positive inputs, while its improved version, S4, incorporates a smooth transition mechanism regulated by a parameter k.", "result": "S4 demonstrated higher accuracy on tasks like MNIST (97.4%), Iris classification (96.0%), and better regression performance on Boston Housing (MSE 18.7). It outperformed nine baseline functions in training speed, convergence, and maintaining stable gradients.", "conclusion": "The findings suggest that S4's hybrid design and tunable parameter make it a versatile activation function that addresses key limitations of existing methods and improves neural network training dynamics."}}
{"id": "2507.22131", "pdf": "https://arxiv.org/pdf/2507.22131", "abs": "https://arxiv.org/abs/2507.22131", "authors": ["Theviyanthan Krishnamohan", "Paul Harvey"], "title": "OpenRASE: Service Function Chain Emulation", "categories": ["cs.NI", "cs.DC", "cs.NE"], "comment": "Accepted to IEEE SoftCom 2025", "summary": "Service Function Chains (SFCs) are one of the key enablers in providing\nprogrammable computer networks, paving the way for network autonomy. However,\nthis also introduces new challenges, such as resource allocation and\noptimisation related to their operation, requiring new algorithms to address\nthese challenges. Various tools have been used in the literature to evaluate\nthese algorithms. However, these tools suffer from inaccuracy, low fidelity,\nunscalability, inflexibility, or additional code requirements. This paper\nintroduces an emulator based on Mininet and Docker for SFCs called OpenRASE.\nThe goal of OpenRASE is to enable the exploration of resource allocation\nalgorithms for SFCs in a dynamic setting, allowing real CPU usage and latency\nto be measured. We describe the design and implementation of OpenRASE and\ndiscuss its characteristics. We also experimentally evaluate two different\nalgorithms to address the SFC resource allocation challenge, including an\nonline Genetic Algorithm, using OpenRASE to show its effectiveness and\npracticality for dynamic network conditions.", "AI": {"tldr": "The paper introduces OpenRASE, an SFC emulator for evaluating resource allocation algorithms in dynamic network settings.", "motivation": "To overcome limitations of existing tools used to evaluate resource allocation algorithms for Service Function Chains (SFCs), such as inaccuracy, inflexibility, and scalability.", "method": "An emulator named OpenRASE was designed and implemented using Mininet and Docker. It allows real-time measurement of CPU usage and latency to test resource allocation algorithms for SFCs.", "result": "OpenRASE was used to experimentally evaluate two resource allocation algorithms, including an online Genetic Algorithm, demonstrating its practical application and effectiveness in dynamic settings.", "conclusion": "OpenRASE is a practical and effective emulator for studying resource allocation algorithms in SFCs, addressing issues faced by prior tools."}}
{"id": "2507.22451", "pdf": "https://arxiv.org/pdf/2507.22451", "abs": "https://arxiv.org/abs/2507.22451", "authors": ["Alexander Batashev"], "title": "Dissecting RISC-V Performance: Practical PMU Profiling and Hardware-Agnostic Roofline Analysis on Emerging Platforms", "categories": ["cs.PF"], "comment": null, "summary": "As RISC-V architectures proliferate across embedded and high-performance\ndomains, developers face persistent challenges in performance optimization due\nto fragmented tooling, immature hardware features, and platform-specific\ndefects. This paper delivers a pragmatic methodology for extracting actionable\nperformance insights on RISC-V systems, even under constrained or unreliable\nhardware conditions. We present a workaround to circumvent hardware bugs in one\nof the popular RISC-V implementations, enabling robust event sampling. For\nmemory-compute bottleneck analysis, we introduce compiler-driven Roofline\ntooling that operates without hardware PMU dependencies, leveraging LLVM-based\ninstrumentation to derive operational intensity and throughput metrics directly\nfrom application IR. Our open source toolchain automates these workarounds,\nunifying PMU data correction and compiler-guided Roofline construction into a\nsingle workflow.", "AI": {"tldr": "A methodology to optimize performance on RISC-V systems using tooling to address hardware bugs and compiler-guided Roofline analysis.", "motivation": "RISC-V's increasing adoption faces issues like fragmented tools, immature features, and hardware defects, complicating performance optimization.", "method": "Proposes workarounds for hardware bugs and introduces LLVM-based Roofline tooling for operational intensity and throughput metrics.", "result": "Developed an open-source toolchain unifying corrected PMU data and Roofline analysis into a consolidated procedure.", "conclusion": "This approach facilitates actionable performance insights and efficient optimizations for challenging RISC-V hardware scenarios."}}
{"id": "2507.22440", "pdf": "https://arxiv.org/pdf/2507.22440", "abs": "https://arxiv.org/abs/2507.22440", "authors": ["Yiya Diao", "Changhe Li", "Sanyou Zeng", "Xinye Cai", "Wenjian Luo", "Shengxiang Yang", "Carlos A. Coello Coello"], "title": "Nearest-Better Network for Visualizing and Analyzing Combinatorial Optimization Problems: A Unified Tool", "categories": ["cs.AI", "cs.NE"], "comment": null, "summary": "The Nearest-Better Network (NBN) is a powerful method to visualize sampled\ndata for continuous optimization problems while preserving multiple landscape\nfeatures. However, the calculation of NBN is very time-consuming, and the\nextension of the method to combinatorial optimization problems is challenging\nbut very important for analyzing the algorithm's behavior. This paper provides\na straightforward theoretical derivation showing that the NBN network\nessentially functions as the maximum probability transition network for\nalgorithms. This paper also presents an efficient NBN computation method with\nlogarithmic linear time complexity to address the time-consuming issue. By\napplying this efficient NBN algorithm to the OneMax problem and the Traveling\nSalesman Problem (TSP), we have made several remarkable discoveries for the\nfirst time: The fitness landscape of OneMax exhibits neutrality, ruggedness,\nand modality features. The primary challenges of TSP problems are ruggedness,\nmodality, and deception. Two state-of-the-art TSP algorithms (i.e., EAX and\nLKH) have limitations when addressing challenges related to modality and\ndeception, respectively. LKH, based on local search operators, fails when there\nare deceptive solutions near global optima. EAX, which is based on a single\npopulation, can efficiently maintain diversity. However, when multiple\nattraction basins exist, EAX retains individuals within multiple basins\nsimultaneously, reducing inter-basin interaction efficiency and leading to\nalgorithm's stagnation.", "AI": {"tldr": "The paper introduces an efficient method to compute Nearest-Better Networks (NBN) and applies it to uncover insights into OneMax and TSP problems, highlighting challenges for specific algorithms.", "motivation": "Analyze algorithm behaviors by addressing computational inefficiency of Nearest-Better Networks and extending its application to combinatorial optimization problems.", "method": "Proposes a logarithmic linear time complexity algorithm for efficient computation of NBN and demonstrates it through application to OneMax and TSP.", "result": "Findings reveal that OneMax fitness landscapes exhibit neutrality, ruggedness, and modality. TSP challenges include ruggedness, modality, and deception, affecting algorithm performance like EAX and LKH.", "conclusion": "The efficient NBN algorithm provides novel insights into optimization problems, revealing challenges affecting algorithm efficacy and suggesting improvement areas."}}
{"id": "2507.22702", "pdf": "https://arxiv.org/pdf/2507.22702", "abs": "https://arxiv.org/abs/2507.22702", "authors": ["Hendrik Reiter", "Ahmad Rzgar Hamid", "Florian Schl\u00f6sser", "Mikkel Baun Kj\u00e6rgaard", "Wilhelm Hasselbring"], "title": "Ecoscape: Fault Tolerance Benchmark for Adaptive Remediation Strategies in Real-Time Edge ML", "categories": ["cs.PF"], "comment": null, "summary": "Edge computing offers significant advantages for realtime data processing\ntasks, such as object recognition, by reducing network latency and bandwidth\nusage. However, edge environments are susceptible to various types of fault. A\nremediator is an automated software component designed to adjust the\nconfiguration parameters of a software service dynamically. Its primary\nfunction is to maintain the services operational state within predefined\nService Level Objectives by applying corrective actions in response to\ndeviations from these objectives. Remediators can be implemented based on the\nKubernetes container orchestration tool by implementing remediation strategies\nsuch as rescheduling or adjusting application parameters. However, currently,\nthere is no method to compare these remediation strategies fairly. This paper\nintroduces Ecoscape, a comprehensive benchmark designed to evaluate the\nperformance of remediation strategies in fault-prone environments. Using Chaos\nEngineering techniques, Ecoscape simulates realistic fault scenarios and\nprovides a quantifiable score to assess the efficacy of different remediation\napproaches. In addition, it is configurable to support domain-specific Service\nLevel Objectives. We demonstrate the capabilities of Ecoscape in edge machine\nlearning inference, offering a clear framework to optimize fault tolerance in\nthese systems without needing a physical edge testbed.", "AI": {"tldr": "The paper presents Ecoscape, a benchmark to evaluate the effectiveness of remediation strategies in fault-prone edge computing environments.", "motivation": "The motivation is to address the lack of fair comparison methods for remediation strategies in edge environments that are prone to faults.", "method": "The authors developed Ecoscape, a benchmark utilizing Chaos Engineering techniques to simulate faults and measure remediation efficacy based on quantified scores.", "result": "Ecoscape was shown to be effective in evaluating remediation strategies for edge machine learning inference without requiring physical edge testbeds.", "conclusion": "Ecoscape provides a structured and configurable framework to optimize fault tolerance in edge computing systems, ensuring better handling of Service Level Objectives in fault-prone scenarios."}}
{"id": "2507.22159", "pdf": "https://arxiv.org/pdf/2507.22159", "abs": "https://arxiv.org/abs/2507.22159", "authors": ["Vanessa Rebecca Wiyono", "David Anugraha", "Ayu Purwarianti", "Genta Indra Winata"], "title": "IndoPref: A Multi-Domain Pairwise Preference Dataset for Indonesian", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint", "summary": "Over 200 million people speak Indonesian, yet the language remains\nsignificantly underrepresented in preference-based research for large language\nmodels (LLMs). Most existing multilingual datasets are derived from English\ntranslations, often resulting in content that lacks cultural and linguistic\nauthenticity. To address this gap, we introduce IndoPref, the first fully\nhuman-authored and multi-domain Indonesian preference dataset specifically\ndesigned to evaluate the naturalness and quality of LLM-generated text. All\nannotations are natively written in Indonesian and evaluated using\nKrippendorff's alpha, demonstrating strong inter-annotator agreement.\nAdditionally, we benchmark the dataset across multiple LLMs and assess the\noutput quality of each model.", "AI": {"tldr": "IndoPref is the first human-authored Indonesian preference dataset for evaluating LLM text quality.", "motivation": "Indonesian's underrepresentation in LLM preference research due to reliance on translations.", "method": "Created IndoPref, a multi-domain dataset with native Indonesian annotations evaluated for inter-annotator agreement.", "result": "High inter-annotator agreement (Krippendorff's alpha) and LLM benchmarking on the dataset.", "conclusion": "IndoPref addresses authenticity issues in multilingual datasets and provides quality benchmarks for Indonesian LLM research."}}
{"id": "2507.22074", "pdf": "https://arxiv.org/pdf/2507.22074", "abs": "https://arxiv.org/abs/2507.22074", "authors": ["Yangshu Yuan", "Heng Chen", "Xinyi Jiang", "Christian Ng", "Kexin Qiu"], "title": "CIMR: Contextualized Iterative Multimodal Reasoning for Robust Instruction Following in LVLMs", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "The rapid advancement of Large Language Models (LLMs) and Large\nVision-Language Models (LVLMs) has enhanced our ability to process and generate\nhuman language and visual information. However, these models often struggle\nwith complex, multi-step multi-modal instructions that require logical\nreasoning, dynamic feedback integration, and iterative self-correction. To\naddress this, we propose CIMR: Contextualized Iterative Multimodal Reasoning, a\nnovel framework that introduces a context-aware iterative reasoning and\nself-correction module. CIMR operates in two stages: initial reasoning and\nresponse generation, followed by iterative refinement using parsed multi-modal\nfeedback. A dynamic fusion module deeply integrates textual, visual, and\ncontextual features at each step. We fine-tune LLaVA-1.5-7B on the Visual\nInstruction Tuning (VIT) dataset and evaluate CIMR on the newly introduced\nMulti-modal Action Planning (MAP) dataset. CIMR achieves 91.5% accuracy,\noutperforming state-of-the-art models such as GPT-4V (89.2%), LLaVA-1.5\n(78.5%), MiniGPT-4 (75.3%), and InstructBLIP (72.8%), demonstrating the\nefficacy of its iterative reasoning and self-correction capabilities in complex\ntasks.", "AI": {"tldr": "CIMR enhances reasoning and self-correction abilities in multimodal tasks, outperforming existing models like GPT-4V and MiniGPT-4.", "motivation": "LLMs and LVLMs struggle with multi-step and complex multimodal instructions requiring iterative reasoning and feedback.", "method": "The proposed CIMR framework incorporates initial reasoning followed by iterative refinement using multimodal feedback and fine-tunes models on specific datasets.", "result": "CIMR achieved 91.5% accuracy on the Multi-modal Action Planning dataset, surpassing leading models such as GPT-4V and others.", "conclusion": "CIMR demonstrates effective iterative reasoning and self-correction for advanced multimodal tasks."}}
{"id": "2507.22069", "pdf": "https://arxiv.org/pdf/2507.22069", "abs": "https://arxiv.org/abs/2507.22069", "authors": ["Tobias Sesterhenn", "Ian Berlot-Attwell", "Janis Zenkner", "Christian Bartelt"], "title": "A Compute-Matched Re-Evaluation of TroVE on MATH", "categories": ["cs.PL", "cs.AI"], "comment": null, "summary": "Reusing established theorems and formulas is central to mathematical problem\nsolving, serving as essential building blocks for tackling increasingly complex\nchallenges. Recent work, TroVE, argues that code-generating Large Language\nModels (LLMs) can benefit similarly on the MATH benchmark by inducing and\nreusing higher-level toolboxes. By allocating computational budget across an\nensemble of three modes -- directly generating code, creating tools, and\nreusing tools -- TroVE claims to outperform a PRIMITIVE baseline that only\nperforms direct generation. However, recent analysis (Berlot-Attwell et al.,\n2024) casts doubt on these gains, noting that the tools created are often\ntrivial or rarely reused, suggesting that improvements may stem from\nself-consistency or self-correction. In this work, we re-evaluate TroVE on\nMATH, analyze the impact of each of its modes, and show that its benefit does\nnot come from these mechanisms, but simply from a higher computational budget\nspent for TroVE compared to PRIMITIVE. To this end, we also perform a small\ncorrection in the original implementation of TroVE's selection mechanism,\nboosting TroVE's performance on MATH by 3\\% in accuracy. After matching for\ncompute, the benefit of TroVE reduces to a marginal improvement of 1\\%,\nsuggesting that this toolbox approach does not provide a significant benefit on\nMATH.", "AI": {"tldr": "The paper re-evaluates the TroVE model, which combines direct code generation, tool creation, and reuse for mathematical problem-solving. It finds that the supposed advantage of this approach is mainly a result of higher computational budget rather than effective mechanisms.", "motivation": "To assess whether the use of toolboxes in the TroVE model truly improves mathematical problem-solving, as claimed, or if the gains are due to other factors.", "method": "The authors analyze the TroVE model's performance on the MATH benchmark, adjusting its implementation for improved accuracy and matching the computational budget with the baseline PRIMITIVE model.", "result": "Upon equalizing compute budgets, the performance advantage of TroVE diminishes to a marginal 1% improvement, indicating that the toolbox approach yields limited benefits.", "conclusion": "The toolbox framework in TroVE does not significantly enhance mathematical problem-solving performance on MATH, and its advantage stems mostly from computational resource allocation."}}
{"id": "2507.22149", "pdf": "https://arxiv.org/pdf/2507.22149", "abs": "https://arxiv.org/abs/2507.22149", "authors": ["Xianxuan Long", "Yao Fu", "Runchao Li", "Mu Sheng", "Haotian Yu", "Xiaotian Han", "Pan Li"], "title": "When Truthful Representations Flip Under Deceptive Instructions?", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) tend to follow maliciously crafted instructions\nto generate deceptive responses, posing safety challenges. How deceptive\ninstructions alter the internal representations of LLM compared to truthful\nones remains poorly understood beyond output analysis. To bridge this gap, we\ninvestigate when and how these representations ``flip'', such as from truthful\nto deceptive, under deceptive versus truthful/neutral instructions. Analyzing\nthe internal representations of Llama-3.1-8B-Instruct and Gemma-2-9B-Instruct\non a factual verification task, we find the model's instructed True/False\noutput is predictable via linear probes across all conditions based on the\ninternal representation. Further, we use Sparse Autoencoders (SAEs) to show\nthat the Deceptive instructions induce significant representational shifts\ncompared to Truthful/Neutral representations (which are similar), concentrated\nin early-to-mid layers and detectable even on complex datasets. We also\nidentify specific SAE features highly sensitive to deceptive instruction and\nuse targeted visualizations to confirm distinct truthful/deceptive\nrepresentational subspaces. % Our analysis pinpoints layer-wise and\nfeature-level correlates of instructed dishonesty, offering insights for LLM\ndetection and control. Our findings expose feature- and layer-level signatures\nof deception, offering new insights for detecting and mitigating instructed\ndishonesty in LLMs.", "AI": {"tldr": "This paper investigates how malicious instructions impact the internal representations of large language models (LLMs), using techniques like Sparse Autoencoders and linear probes to identify representational shifts, particularly under deceptive instructions.", "motivation": "The study aims to address safety concerns with LLMs by understanding how deceptive instructions affect their internal states beyond output-level analysis, which is currently underexplored.", "method": "The researchers analyze internal representations of two LLMs (Llama-3.1-8B-Instruct and Gemma-2-9B-Instruct) using a factual verification task. Methods include predicting model outputs using linear probes and analyzing representational shifts through Sparse Autoencoders across different instruction settings.", "result": "Deceptive instructions induce significant shifts in internal representations, concentrated in early-to-mid layers. While Truthful and Neutral instructions result in similar representations, specific Sparse Autoencoder features are highly sensitive to deception, showing distinct subspaces between truthful and deceptive instructions.", "conclusion": "This research identifies layer-wise and feature-level indicators of instructed dishonesty, providing insights to enhance detection and control of deceptive behaviors in LLMs."}}
{"id": "2507.22063", "pdf": "https://arxiv.org/pdf/2507.22063", "abs": "https://arxiv.org/abs/2507.22063", "authors": ["Wenjie Jacky Mo", "Qin Liu", "Xiaofei Wen", "Dongwon Jung", "Hadi Askari", "Wenxuan Zhou", "Zhe Zhao", "Muhao Chen"], "title": "RedCoder: Automated Multi-Turn Red Teaming for Code LLMs", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) for code generation (i.e., Code LLMs) have\ndemonstrated impressive capabilities in AI-assisted software development and\ntesting. However, recent studies have shown that these models are prone to\ngenerating vulnerable or even malicious code under adversarial settings.\nExisting red-teaming approaches rely on extensive human effort, limiting their\nscalability and practicality, and generally overlook the interactive nature of\nreal-world AI-assisted programming, which often unfolds over multiple turns. To\nbridge these gaps, we present RedCoder, a red-teaming agent that engages victim\nmodels in multi-turn conversation to elicit vulnerable code. The pipeline to\nconstruct RedCoder begins with a multi-agent gaming process that simulates\nadversarial interactions, yielding a set of prototype conversations and an\narsenal of reusable attack strategies. We then fine-tune an LLM on these\nprototype conversations to serve as the backbone of RedCoder. Once deployed,\nRedCoder autonomously engages Code LLMs in multi-turn conversations,\ndynamically retrieving relevant strategies from the arsenal to steer the\ndialogue toward vulnerability-inducing outputs. Experiments across multiple\nCode LLMs show that our approach outperforms prior single-turn and multi-turn\nred-team methods in inducing vulnerabilities in code generation, offering a\nscalable and effective tool for evaluating the security boundaries of modern\ncode-generation systems.", "AI": {"tldr": "The paper introduces RedCoder, a red-teaming agent that autonomously engages in multi-turn conversations to test and expose vulnerabilities in code generated by large language models (LLMs), outperforming existing methods.", "motivation": "The study addresses the challenge of identifying vulnerabilities or malicious outputs in code generated by LLMs under adversarial conditions. Prior approaches require extensive human effort and lack scalability, while also failing to consider the multi-turn interactive nature of real-world programming scenarios.", "method": "The authors developed RedCoder using a multi-agent gaming approach to generate prototype conversations and attack strategies. This was followed by fine-tuning an LLM on the simulated conversations to enable dynamic and autonomous multi-turn dialogues, retrieving relevant strategies from a pre-built arsenal to induce vulnerabilities in code outputs.", "result": "RedCoder outperformed prior single-turn and multi-turn methods in successfully inducing vulnerable code across multiple Code LLMs. It also demonstrated scalability and effectiveness as a security evaluation tool for code-generation systems.", "conclusion": "The study highlights the potential of RedCoder as a scalable, autonomous agent for stress-testing the security boundaries of code-generation LLMs, emphasizing its application in improving the safety of AI-assisted software development."}}
{"id": "2507.22099", "pdf": "https://arxiv.org/pdf/2507.22099", "abs": "https://arxiv.org/abs/2507.22099", "authors": ["Shuqing Li", "Qiang Chen", "Xiaoxue Ren", "Michael R. Lyu"], "title": "Runtime Failure Hunting for Physics Engine Based Software Systems: How Far Can We Go?", "categories": ["cs.CV", "cs.AI", "cs.MM", "cs.SE"], "comment": null, "summary": "Physics Engines (PEs) are fundamental software frameworks that simulate\nphysical interactions in applications ranging from entertainment to\nsafety-critical systems. Despite their importance, PEs suffer from physics\nfailures, deviations from expected physical behaviors that can compromise\nsoftware reliability, degrade user experience, and potentially cause critical\nfailures in autonomous vehicles or medical robotics. Current testing approaches\nfor PE-based software are inadequate, typically requiring white-box access and\nfocusing on crash detection rather than semantically complex physics failures.\nThis paper presents the first large-scale empirical study characterizing\nphysics failures in PE-based software. We investigate three research questions\naddressing the manifestations of physics failures, the effectiveness of\ndetection techniques, and developer perceptions of current detection practices.\nOur contributions include: (1) a taxonomy of physics failure manifestations;\n(2) a comprehensive evaluation of detection methods including deep learning,\nprompt-based techniques, and large multimodal models; and (3) actionable\ninsights from developer experiences for improving detection approaches. To\nsupport future research, we release PhysiXFails, code, and other materials at\nhttps://sites.google.com/view/physics-failure-detection.", "AI": {"tldr": "The paper studies physics failures in Physics Engines, developing a taxonomy, evaluating detection methods, and sharing developer insights.", "motivation": "Physics Engines are critical for simulations but suffer from physics failures that impact reliability, especially in safety-critical systems.", "method": "A large-scale empirical study was conducted, evaluating various detection methodologies like deep learning and prompt-based approaches.", "result": "Contributions include a taxonomy of physics failure manifestations, an evaluation of detection techniques, and insights from developers.", "conclusion": "The study offers tools and insights that address weaknesses in detecting physics failures in software using Physics Engines and promotes future research with publicly available resources."}}
{"id": "2507.22095", "pdf": "https://arxiv.org/pdf/2507.22095", "abs": "https://arxiv.org/abs/2507.22095", "authors": ["Nicola Apollonio", "Giovanni Franzina", "Giovanni Luca Torrisi"], "title": "Simulating Posterior Bayesian Neural Networks with Dependent Weights", "categories": ["stat.ML", "cs.LG", "math.PR", "68T07, 68W20, 60B10"], "comment": null, "summary": "In this paper we consider posterior Bayesian fully connected and feedforward\ndeep neural networks with dependent weights. Particularly, if the likelihood is\nGaussian, we identify the distribution of the wide width limit and provide an\nalgorithm to sample from the network. In the shallow case we explicitly compute\nthe distribution of the output, proving that it is a Gaussian mixture. All the\ntheoretical results are numerically validated.", "AI": {"tldr": "The paper analyzes Bayesian deep neural networks with dependent weights and explores their behavior under Gaussian likelihoods, presenting algorithms and numerical validations.", "motivation": "To better understand the behavior and distributional properties of deep neural networks with dependent weights, especially under Bayesian frameworks.", "method": "Introducing posterior Bayesian models for fully connected and feedforward networks, deriving theoretical distributions for wide-width networks, and performing numerical validations.", "result": "Wide-width networks are characterized under Gaussian likelihoods, with shallow networks proven to produce output as Gaussian mixtures. Results are validated through simulations.", "conclusion": "Bayesian dependent-weight neural networks exhibit Gaussian mixture properties in shallow configurations and show specific distributional behaviors as width increases, validated computationally."}}
{"id": "2507.22188", "pdf": "https://arxiv.org/pdf/2507.22188", "abs": "https://arxiv.org/abs/2507.22188", "authors": ["Ethan DeVries", "Jack Ferlazzo", "Mustafa Ugur", "Laura H. Blumenschein"], "title": "Deployment of Objects with a Soft Everting Robot", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "9 pages, 10 figures, This work has been submitted to the IEEE for\n  possible publication", "summary": "Soft everting robots present significant advantages over traditional rigid\nrobots, including enhanced dexterity, improved environmental interaction, and\nsafe navigation in unpredictable environments. While soft everting robots have\nbeen widely demonstrated for exploration type tasks, their potential to move\nand deploy payloads in such tasks has been less investigated, with previous\nwork focusing on sensors and tools for the robot. Leveraging the navigation\ncapabilities, and deployed body, of the soft everting robot to deliver payloads\nin hazardous areas, e.g. carrying a water bottle to a person stuck under\ndebris, would represent a significant capability in many applications. In this\nwork, we present an analysis of how soft everting robots can be used to deploy\nlarger, heavier payloads through the inside of the robot. We analyze both what\nobjects can be deployed and what terrain features they can be carried through.\nBuilding on existing models, we present methods to quantify the effects of\npayloads on robot growth and self-support, and develop a model to predict\npayload slip. We then experimentally quantify payload transport using soft\neverting robot with a variety of payload shapes, sizes, and weights and though\na series of tasks: steering, vertical transport, movement through holes, and\nmovement across gaps. Overall, the results show that we can transport payloads\nin a variety of shapes and up to 1.5kg in weight and that we can move through\ncircular apertures with as little as 0.01cm clearance around payloads, carry\nout discrete turns up to 135 degrees, and move across unsupported gaps of 1.15m\nin length.", "AI": {"tldr": "The paper explores the capability of soft everting robots to transport larger and heavier payloads effectively in various challenging terrains.", "motivation": "The authors aim to expand the utility of soft everting robots beyond exploratory tasks, studying their potential to safely deliver payloads in hazardous environments.", "method": "The paper develops models to quantify payload effects on robot growth, self-support, and predict payload slip. Researchers conducted experiments for payload transport across diverse shapes, sizes, and terrains.", "result": "Experiments demonstrated successful transport capabilities of payloads up to 1.5kg and navigation through tight apertures, steep turns, and unsupported gaps of 1.15m length.", "conclusion": "Soft everting robots are capable of carrying and delivering payloads efficiently under extreme conditions, thereby broadening their application potential."}}
{"id": "2507.22245", "pdf": "https://arxiv.org/pdf/2507.22245", "abs": "https://arxiv.org/abs/2507.22245", "authors": ["Igor Sfiligoi", "Emily A. Belli", "Jeff Candy"], "title": "Minimizing CGYRO HPC Communication Costs in Ensembles with XGYRO by Sharing the Collisional Constant Tensor Structure", "categories": ["cs.DC"], "comment": "3 pages, 3 figures, Accepted at ICPP25", "summary": "First-principles fusion plasma simulations are both compute and memory\nintensive, and CGYRO is no exception. The use of many HPC nodes to fit the\nproblem in the available memory thus results in significant communication\noverhead, which is hard to avoid for any single simulation. That said, most\nfusion studies are composed of ensembles of simulations, so we developed a new\ntool, named XGYRO, that executes a whole ensemble of CGYRO simulations as a\nsingle HPC job. By treating the ensemble as a unit, XGYRO can alter the global\nbuffer distribution logic and apply optimizations that are not feasible on any\nsingle simulation, but only on the ensemble as a whole. The main saving comes\nfrom the sharing of the collisional constant tensor structure, since its values\nare typically identical between parameter-sweep simulations. This data\nstructure dominates the memory consumption of CGYRO simulations, so\ndistributing it among the whole ensemble results in drastic memory savings for\neach simulation, which in turn results in overall lower communication overhead.", "AI": {"tldr": "The paper introduces XGYRO, a tool that optimizes memory and communication overhead for ensemble fusion plasma simulations by sharing data structures across simulations.", "motivation": "Fusion plasma simulations require high computational and memory resources, leading to bottlenecks such as significant communication overhead during multi-node usage. This is especially challenging when analyzing ensembles of simulations.", "method": "The authors developed XGYRO, which organizes and executes ensembles of CGYRO simulations as a single HPC job. This allows for global optimization, including memory-sharing strategies for data structures like collisional constant tensors.", "result": "The proposed approach drastically reduces memory consumption per simulation by sharing data structures across simulations in the ensemble, leading to lower communication overhead.", "conclusion": "XGYRO effectively tackles the inefficiencies in processing ensembles of fusion plasma simulations, enabling more efficient resource utilization and faster computations on high-performance computing environments."}}
{"id": "2507.22067", "pdf": "https://arxiv.org/pdf/2507.22067", "abs": "https://arxiv.org/abs/2507.22067", "authors": ["Yuang Cao", "Jiachen Zou", "Chen Wei", "Quanying Liu"], "title": "Dimensions of Vulnerability in Visual Working Memory: An AI-Driven Approach to Perceptual Comparison", "categories": ["q-bio.NC", "cs.AI"], "comment": "6 pages, 4 figures, experimental results presented in the paper,\n  accepted for virtual poster presentation at CogSci 2025", "summary": "Human memory exhibits significant vulnerability in cognitive tasks and daily\nlife. Comparisons between visual working memory and new perceptual input (e.g.,\nduring cognitive tasks) can lead to unintended memory distortions. Previous\nstudies have reported systematic memory distortions after perceptual\ncomparison, but understanding how perceptual comparison affects memory\ndistortions in real-world objects remains a challenge. Furthermore, identifying\nwhat visual features contribute to memory vulnerability presents a novel\nresearch question. Here, we propose a novel AI-driven framework that generates\nnaturalistic visual stimuli grounded in behaviorally relevant object dimensions\nto elicit similarity-induced memory biases. We use two types of stimuli --\nimage wheels created through dimension editing and dimension wheels generated\nby dimension activation values -- in three visual working memory (VWM)\nexperiments. These experiments assess memory distortions under three\nconditions: no perceptual comparison, perceptual comparison with image wheels,\nand perceptual comparison with dimension wheels. The results show that similar\ndimensions, like similar images, can also induce memory distortions.\nSpecifically, visual dimensions are more prone to distortion than semantic\ndimensions, indicating that the object dimensions of naturalistic visual\nstimuli play a significant role in the vulnerability of memory.", "AI": {"tldr": "The study investigates how perceptual comparisons affect memory distortions and reveals that visual dimensions are more prone to distortion than semantic dimensions.", "motivation": "To understand how perceptual comparisons influence memory distortions, particularly in real-world objects, and to identify the visual features contributing to memory vulnerabilities.", "method": "Developed an AI-driven framework to generate two types of stimuli -- image wheels and dimension wheels. Conducted three visual working memory experiments to test memory distortions under various perceptual comparison conditions.", "result": "Memory was distorted by similar dimensions and images, with visual dimensions being more vulnerable to distortion than semantic dimensions.", "conclusion": "Object dimensions in naturalistic visual stimuli significantly influence memory vulnerabilities, and perceptual comparisons with similar dimensions exacerbate these distortions."}}
{"id": "2507.22787", "pdf": "https://arxiv.org/pdf/2507.22787", "abs": "https://arxiv.org/abs/2507.22787", "authors": ["F. Gallavotti", "A. Zaccone"], "title": "Amorphous Solid Model of Vectorial Hopfield Neural Networks", "categories": ["cond-mat.dis-nn", "cond-mat.soft", "cond-mat.stat-mech", "cs.LG", "cs.NE"], "comment": null, "summary": "We present a vectorial extension of the Hopfield associative memory model\ninspired by the theory of amorphous solids, where binary neural states are\nreplaced by unit vectors $\\mathbf{s}_i \\in \\mathbb{R}^3$ on the sphere $S^2$.\nThe generalized Hebbian learning rule creates a block-structured weight matrix\nthrough outer products of stored pattern vectors, analogous to the Hessian\nmatrix structure in amorphous solids. We demonstrate that this model exhibits\nquantifiable structural properties characteristic of disordered materials:\nenergy landscapes with deep minima for stored patterns versus random\nconfigurations (energy gaps $\\sim 7$ units), strongly anisotropic correlations\nencoded in the weight matrix (anisotropy ratios $\\sim 10^2$), and\norder-disorder transitions controlled by the pattern density $\\gamma = P/(N\n\\cdot d)$. The enhanced memory capacity ($\\gamma_c \\approx 0.55$ for a\nfully-connected network) compared to binary networks ($\\gamma_c \\approx 0.138$)\nand the emergence of orientational correlations establish connections between\nassociative memory mechanisms and amorphous solid physics, particularly in\nsystems with continuous orientational degrees of freedom. We also unveil the\nscaling with the coordination number $Z$ of the memory capacity: $\\gamma_c \\sim\n(Z-6)$ from the isostatic point $Z_c =6$ of the 3D elastic network, which\nclosely mirrors the scaling of the shear modulus $G \\sim (Z-6)$ in 3D\ncentral-force spring networks.", "AI": {"tldr": "This paper introduces a modified Hopfield associative memory model using unit vectors, inspired by amorphous solids. It demonstrates enhanced memory capacity and structural similarities with disordered materials.", "motivation": "The authors sought to explore connections between neural associative memory models and amorphous solid physics, particularly focusing on systems with continuous orientational degrees of freedom.", "method": "A generalized Hebbian learning rule is applied, creating a block-structured weight matrix with stored patterns as unit vectors on a sphere. Various system properties and transitions were analyzed using energy landscape features, anisotropy correlations, and pattern density.", "result": "Enhancements in memory capacity ($\\gamma_c \\approx 0.55$) compared to binary networks ($\\gamma_c \\approx 0.138$), anisotropy ratios around $10^2$, energy gaps of $\\sim 7$ units, and connections to elastic network physics were identified.", "conclusion": "The findings establish a novel connection between associative memory models and amorphous solids, suggesting that mechanisms with continuous degrees of freedom enhance memory capacity and mimic structural physics behaviors."}}
{"id": "2507.22168", "pdf": "https://arxiv.org/pdf/2507.22168", "abs": "https://arxiv.org/abs/2507.22168", "authors": ["Kimberly Le Truong", "Riccardo Fogliato", "Hoda Heidari", "Zhiwei Steven Wu"], "title": "Persona-Augmented Benchmarking: Evaluating LLMs Across Diverse Writing Styles", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Current benchmarks for evaluating Large Language Models (LLMs) often do not\nexhibit enough writing style diversity, with many adhering primarily to\nstandardized conventions. Such benchmarks do not fully capture the rich variety\nof communication patterns exhibited by humans. Thus, it is possible that LLMs,\nwhich are optimized on these benchmarks, may demonstrate brittle performance\nwhen faced with \"non-standard\" input. In this work, we test this hypothesis by\nrewriting evaluation prompts using persona-based LLM prompting, a low-cost\nmethod to emulate diverse writing styles. Our results show that, even with\nidentical semantic content, variations in writing style and prompt formatting\nsignificantly impact the estimated performance of the LLM under evaluation.\nNotably, we identify distinct writing styles that consistently trigger either\nlow or high performance across a range of models and tasks, irrespective of\nmodel family, size, and recency. Our work offers a scalable approach to augment\nexisting benchmarks, improving the external validity of the assessments they\nprovide for measuring LLM performance across linguistic variations.", "AI": {"tldr": "Current benchmarks fail to evaluate Large Language Models (LLMs) against diverse writing styles, and this paper proposes a scalable approach using persona-based prompting to address this limitation.", "motivation": "Existing benchmarks mainly follow standardized conventions and do not represent the diverse communication patterns found in human language, leading to potentially fragile LLM performance when exposed to non-standard inputs.", "method": "The authors introduce persona-based LLM prompting, a cost-effective method to rewrite evaluation prompts in diverse writing styles while keeping semantic content consistent.", "result": "The study reveals that variations in writing style and prompt formatting strongly influence LLM performance and identifies distinct writing styles that yield consistently high or low results, regardless of model family, size, or recency.", "conclusion": "Incorporating stylistic diversity into benchmarks using this scalable method could improve the external validity of LLM evaluations and provide a better measure of their robustness across various linguistic patterns."}}
{"id": "2507.22075", "pdf": "https://arxiv.org/pdf/2507.22075", "abs": "https://arxiv.org/abs/2507.22075", "authors": ["Eman Ali", "Chetan Arora", "Muhammad Haris Khan"], "title": "Prototype-Guided Pseudo-Labeling with Neighborhood-Aware Consistency for Unsupervised Adaptation", "categories": ["cs.LG"], "comment": null, "summary": "In unsupervised adaptation for vision-language models such as CLIP,\npseudo-labels derived from zero-shot predictions often exhibit significant\nnoise, particularly under domain shifts or in visually complex scenarios.\nConventional pseudo-label filtering approaches, which rely on fixed confidence\nthresholds, tend to be unreliable in fully unsupervised settings. In this work,\nwe propose a novel adaptive pseudo-labeling framework that enhances CLIP's\nadaptation performance by integrating prototype consistency and\nneighborhood-based consistency. The proposed method comprises two key\ncomponents: PICS, which assesses pseudo-label accuracy based on in-class\nfeature compactness and cross-class feature separation; and NALR, which\nexploits semantic similarities among neighboring samples to refine\npseudo-labels dynamically. Additionally, we introduce an adaptive weighting\nmechanism that adjusts the influence of pseudo-labeled samples during training\naccording to their estimated correctness. Extensive experiments on 11 benchmark\ndatasets demonstrate that our method achieves state-of-the-art performance in\nunsupervised adaptation scenarios, delivering more accurate pseudo-labels while\nmaintaining computational efficiency.", "AI": {"tldr": "This paper introduces an adaptive pseudo-labeling framework for improving CLIP's adaptation using prototype and neighborhood consistency.", "motivation": "Address challenges posed by noisy pseudo-labels during unsupervised domain adaptation of vision-language models like CLIP.", "method": "Develop components focusing on prototype in-class/cross-class consistency (PICS), neighborhood refinement (NALR), and adaptive weighting of pseudo-label contributions based on confidence.", "result": "Extensive testing across 11 benchmarks shows state-of-the-art performance in generating accurate pseudo-labels while retaining efficiency.", "conclusion": "The proposed framework effectively addresses pseudo-label noise in unsupervised adaptation, significantly improving performance and robustness."}}
{"id": "2507.22065", "pdf": "https://arxiv.org/pdf/2507.22065", "abs": "https://arxiv.org/abs/2507.22065", "authors": ["Xiaotao Feng", "Xiaogang Zhu", "Kun Hu", "Jincheng Wang", "Yingjie Cao", "Guang Gong", "Jianfeng Pan"], "title": "Fuzzing: Randomness? Reasoning! Efficient Directed Fuzzing via Large Language Models", "categories": ["cs.SE", "cs.AI", "cs.CR", "cs.PL"], "comment": null, "summary": "Fuzzing is highly effective in detecting bugs due to the key contribution of\nrandomness. However, randomness significantly reduces the efficiency of\nfuzzing, causing it to cost days or weeks to expose bugs. Even though directed\nfuzzing reduces randomness by guiding fuzzing towards target buggy locations,\nthe dilemma of randomness still challenges directed fuzzers. Two critical\ncomponents, which are seeds and mutators, contain randomness and are closely\ntied to the conditions required for triggering bugs. Therefore, to address the\nchallenge of randomness, we propose to use large language models (LLMs) to\nremove the randomness in seeds and reduce the randomness in mutators. With\ntheir strong reasoning and code generation capabilities, LLMs can be used to\ngenerate reachable seeds that target pre-determined locations and to construct\nbug-specific mutators tailored for specific bugs. We propose RandLuzz, which\nintegrates LLMs and directed fuzzing, to improve the quality of seeds and\nmutators, resulting in efficient bug exposure. RandLuzz analyzes function call\nchain or functionality to guide LLMs in generating reachable seeds. To\nconstruct bug-specific mutators, RandLuzz uses LLMs to perform bug analysis,\nobtaining information such as bug causes and mutation suggestions, which\nfurther help generate code that performs bug-specific mutations. We evaluate\nRandLuzz by comparing it with four state-of-the-art directed fuzzers, AFLGo,\nBeacon, WindRanger, and SelectFuzz. With RandLuzz-generated seeds, the fuzzers\nachieve an average speedup ranging from 2.1$\\times$ to 4.8$\\times$ compared to\nusing widely-used initial seeds. Additionally, when evaluated on individual\nbugs, RandLuzz achieves up to a 2.7$\\times$ speedup compared to the\nsecond-fastest exposure. On 8 bugs, RandLuzz can even expose them within 60\nseconds.", "AI": {"tldr": "RandLuzz integrates large language models (LLMs) with directed fuzzing to improve seed and mutator quality, significantly accelerating bug detection in programs.", "motivation": "The inefficiency caused by randomness in fuzzing slows down bug detection, even in directed fuzzers. This randomness primarily stems from seed and mutator selection, which are critical to exposing bugs efficiently.", "method": "RandLuzz uses LLMs for generating targeted seeds and constructing bug-specific mutators. It guides LLMs with function call chains and bug analysis to reduce randomness in fuzzing. This leads to faster bug exposure.", "result": "RandLuzz outperforms four state-of-the-art fuzzers (AFLGo, Beacon, WindRanger, and SelectFuzz), achieving speedups from 2.1\u00d7 to 4.8\u00d7 on average and exposing some bugs in as little as 60 seconds.", "conclusion": "Integrating LLMs with directed fuzzing through RandLuzz can drastically improve the efficiency of bug detection by reducing randomness in seeds and mutators while maintaining high effectiveness."}}
{"id": "2507.22197", "pdf": "https://arxiv.org/pdf/2507.22197", "abs": "https://arxiv.org/abs/2507.22197", "authors": ["Matthieu Queloz"], "title": "Explainability Through Systematicity: The Hard Systematicity Challenge for Artificial Intelligence", "categories": ["cs.AI", "cs.CL", "cs.CY"], "comment": "39 pages; final, published version", "summary": "This paper argues that explainability is only one facet of a broader ideal\nthat shapes our expectations towards artificial intelligence (AI).\nFundamentally, the issue is to what extent AI exhibits systematicity--not\nmerely in being sensitive to how thoughts are composed of recombinable\nconstituents, but in striving towards an integrated body of thought that is\nconsistent, coherent, comprehensive, and parsimoniously principled. This richer\nconception of systematicity has been obscured by the long shadow of the\n\"systematicity challenge\" to connectionism, according to which network\narchitectures are fundamentally at odds with what Fodor and colleagues termed\n\"the systematicity of thought.\" I offer a conceptual framework for thinking\nabout \"the systematicity of thought\" that distinguishes four senses of the\nphrase. I use these distinctions to defuse the perceived tension between\nsystematicity and connectionism and show that the conception of systematicity\nthat historically shaped our sense of what makes thought rational,\nauthoritative, and scientific is more demanding than the Fodorian notion. To\ndetermine whether we have reason to hold AI models to this ideal of\nsystematicity, I then argue, we must look to the rationales for systematization\nand explore to what extent they transfer to AI models. I identify five such\nrationales and apply them to AI. This brings into view the \"hard systematicity\nchallenge.\" However, the demand for systematization itself needs to be\nregulated by the rationales for systematization. This yields a dynamic\nunderstanding of the need to systematize thought, which tells us how systematic\nwe need AI models to be and when.", "AI": {"tldr": "The paper examines the concept of systematicity in AI, arguing that it goes beyond mere explainability and introduces a richer framework for understanding the systematicity of thought, offering a new challenge for AI systems.", "motivation": "To address the long-standing tension between systematicity and connectionism in AI thought and to refine what systematicity means beyond the traditional Fodorian perspective.", "method": "The author develops a conceptual framework that identifies four senses of the systematicity of thought, contrasts them with the traditional 'systematicity challenge' to connectionism, and applies five rationales for systematization to evaluate AI models.", "result": "The study reframes the perceived conflict between systematicity and connectionism, introduces the 'hard systematicity challenge' for AI, and provides a dynamic guide to determine how much systematicity AI systems should exhibit.", "conclusion": "AI models need to strive towards systematicity in a nuanced and regulated manner, based on rationales for systematization, rather than adhering to a rigid or overly simplistic ideal."}}
{"id": "2507.22064", "pdf": "https://arxiv.org/pdf/2507.22064", "abs": "https://arxiv.org/abs/2507.22064", "authors": ["Michael Cohoon", "Debbie Furman"], "title": "Machine Learning Experiences: A story of learning AI for use in enterprise software testing that can be used by anyone", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "This paper details the machine learning (ML) journey of a group of people\nfocused on software testing. It tells the story of how this group progressed\nthrough a ML workflow (similar to the CRISP-DM process). This workflow consists\nof the following steps and can be used by anyone applying ML techniques to a\nproject: gather the data; clean the data; perform feature engineering on the\ndata; splitting the data into two sets, one for training and one for testing;\nchoosing a machine learning model; training the model; testing the model and\nevaluating the model performance. By following this workflow, anyone can\neffectively apply ML to any project that they are doing.", "AI": {"tldr": "The paper describes a machine learning workflow applied by a software testing team, detailing key steps for project implementation.", "motivation": "To document and share the team's progression through a machine learning workflow and provide a template for others.", "method": "The paper outlines a step-by-step ML implementation process including data gathering, cleaning, feature engineering, model training, and evaluation.", "result": "The described ML workflow was applied successfully, demonstrating its effectiveness.", "conclusion": "The workflow is a practical guide that can be replicated by anyone wishing to apply machine learning in their projects."}}
{"id": "2507.22100", "pdf": "https://arxiv.org/pdf/2507.22100", "abs": "https://arxiv.org/abs/2507.22100", "authors": ["Sicheng Zhang", "Binzhu Xie", "Zhonghao Yan", "Yuli Zhang", "Donghao Zhou", "Xiaofei Chen", "Shi Qiu", "Jiaqi Liu", "Guoyang Xie", "Zhichao Lu"], "title": "Trade-offs in Image Generation: How Do Different Dimensions Interact?", "categories": ["cs.CV"], "comment": "Accepted in ICCV 2025, Codebase: https://github.com/fesvhtr/TRIG", "summary": "Model performance in text-to-image (T2I) and image-to-image (I2I) generation\noften depends on multiple aspects, including quality, alignment, diversity, and\nrobustness. However, models' complex trade-offs among these dimensions have\nrarely been explored due to (1) the lack of datasets that allow fine-grained\nquantification of these trade-offs, and (2) the use of a single metric for\nmultiple dimensions. To bridge this gap, we introduce TRIG-Bench (Trade-offs in\nImage Generation), which spans 10 dimensions (Realism, Originality, Aesthetics,\nContent, Relation, Style, Knowledge, Ambiguity, Toxicity, and Bias), contains\n40,200 samples, and covers 132 pairwise dimensional subsets. Furthermore, we\ndevelop TRIGScore, a VLM-as-judge metric that automatically adapts to various\ndimensions. Based on TRIG-Bench and TRIGScore, we evaluate 14 models across T2I\nand I2I tasks. In addition, we propose the Relation Recognition System to\ngenerate the Dimension Trade-off Map (DTM) that visualizes the trade-offs among\nmodel-specific capabilities. Our experiments demonstrate that DTM consistently\nprovides a comprehensive understanding of the trade-offs between dimensions for\neach type of generative model. Notably, we show that the model's\ndimension-specific weaknesses can be mitigated through fine-tuning on DTM to\nenhance overall performance. Code is available at:\nhttps://github.com/fesvhtr/TRIG", "AI": {"tldr": "This paper introduces a benchmark (TRIG-Bench) and metric (TRIGScore) to evaluate trade-offs between multiple dimensions in image generation tasks, offering tools to diagnose and mitigate weaknesses in generative models.", "motivation": "To address the limited understanding of trade-offs among various performance dimensions in image generation models due to dataset and measurement gaps.", "method": "The researchers created TRIG-Bench, a dataset with 40,200 samples across 10 dimensions, and TRIGScore, a metric for automatic dimensional evaluation. They also developed a Dimension Trade-off Map to visualize generative model trade-offs.", "result": "TRIG-Bench, TRIGScore, and DTM successfully evaluated 14 models, providing insights into their dimensional weaknesses and trade-offs and confirming the usefulness of fine-tuning to improve model performance.", "conclusion": "A new framework (TRIG-Bench, TRIGScore, and DTM) enables a systematic understanding of generative model trade-offs, facilitating performance enhancement through targeted fine-tuning."}}
{"id": "2507.22170", "pdf": "https://arxiv.org/pdf/2507.22170", "abs": "https://arxiv.org/abs/2507.22170", "authors": ["Tavor Z. Baharav", "Phillip B. Nicol", "Rafael A. Irizarry", "Rong Ma"], "title": "Stacked SVD or SVD stacked? A Random Matrix Theory perspective on data integration", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH", "15A18, 62H25"], "comment": null, "summary": "Modern data analysis increasingly requires identifying shared latent\nstructure across multiple high-dimensional datasets. A commonly used model\nassumes that the data matrices are noisy observations of low-rank matrices with\na shared singular subspace. In this case, two primary methods have emerged for\nestimating this shared structure, which vary in how they integrate information\nacross datasets. The first approach, termed Stack-SVD, concatenates all the\ndatasets, and then performs a singular value decomposition (SVD). The second\napproach, termed SVD-Stack, first performs an SVD separately for each dataset,\nthen aggregates the top singular vectors across these datasets, and finally\ncomputes a consensus amongst them. While these methods are widely used, they\nhave not been rigorously studied in the proportional asymptotic regime, which\nis of great practical relevance in today's world of increasing data size and\ndimensionality. This lack of theoretical understanding has led to uncertainty\nabout which method to choose and limited the ability to fully exploit their\npotential. To address these challenges, we derive exact expressions for the\nasymptotic performance and phase transitions of these two methods and develop\noptimal weighting schemes to further improve both methods. Our analysis reveals\nthat while neither method uniformly dominates the other in the unweighted case,\noptimally weighted Stack-SVD dominates optimally weighted SVD-Stack. We extend\nour analysis to accommodate multiple shared components, and provide practical\nalgorithms for estimating optimal weights from data, offering theoretical\nguidance for method selection in practical data integration problems. Extensive\nnumerical simulations and semi-synthetic experiments on genomic data\ncorroborate our theoretical findings.", "AI": {"tldr": "The paper compares two approaches for extracting shared latent structures in noisy high-dimensional data\u2014Stack-SVD and SVD-Stack\u2014and introduces optimal weighting schemes and theoretical analyses to guide method selection.", "motivation": "To understand and choose between Stack-SVD and SVD-Stack methods for integrating high-dimensional datasets in practical applications, addressing the lack of theoretical insights in the proportional asymptotic regime.", "method": "Developed exact asymptotic performance metrics, phase transition expressions, and optimal weighting schemes for both methods, extending analyses to multiple components and offering practical algorithms for weight estimation.", "result": "Optimally weighted Stack-SVD surpasses optimally weighted SVD-Stack. Extensive simulations and experiments on genomic data validate theoretical findings.", "conclusion": "Weighted approaches improve the performance of both methods without uniform dominance in unweighted cases, providing theoretical foundations and practical guidance for data integration problems."}}
{"id": "2507.22345", "pdf": "https://arxiv.org/pdf/2507.22345", "abs": "https://arxiv.org/abs/2507.22345", "authors": ["Zhicheng Song", "Jinglan Xu", "Chunxin Zheng", "Yulin Li", "Zhihai Bi", "Jun Ma"], "title": "FLORES: A Reconfigured Wheel-Legged Robot for Enhanced Steering and Adaptability", "categories": ["cs.RO"], "comment": null, "summary": "Wheel-legged robots integrate the agility of legs for navigating rough\nterrains while harnessing the efficiency of wheels for smooth surfaces.\nHowever, most existing designs do not fully capitalize on the benefits of both\nlegged and wheeled structures, which limits overall system flexibility and\nefficiency. We present FLORES (reconfigured wheel-legged robot for enhanced\nsteering and adaptability), a novel wheel-legged robot design featuring a\ndistinctive front-leg configuration that sets it beyond standard design\napproaches. Specifically, FLORES replaces the conventional hip-roll degree of\nfreedom (DoF) of the front leg with hip-yaw DoFs, and this allows for efficient\nmovement on flat surfaces while ensuring adaptability when navigating complex\nterrains. This innovative design facilitates seamless transitions between\ndifferent locomotion modes (i.e., legged locomotion and wheeled locomotion) and\noptimizes the performance across varied environments. To fully exploit FLORES's\nmechanical capabilities, we develop a tailored reinforcement learning (RL)\ncontroller that adapts the Hybrid Internal Model (HIM) with a customized reward\nstructure optimized for our unique mechanical configuration. This framework\nenables the generation of adaptive, multi-modal locomotion strategies that\nfacilitate smooth transitions between wheeled and legged movements.\nFurthermore, our distinctive joint design enables the robot to exhibit novel\nand highly efficient locomotion gaits that capitalize on the synergistic\nadvantages of both locomotion modes. Through comprehensive experiments, we\ndemonstrate FLORES's enhanced steering capabilities, improved navigation\nefficiency, and versatile locomotion across various terrains. The open-source\nproject can be found at\nhttps://github.com/ZhichengSong6/FLORES-A-Reconfigured-Wheel-Legged-Robot-for-Enhanced-Steering-and-Adaptability.git.", "AI": {"tldr": "FLORES is a novel wheel-legged robot with enhanced adaptability and steering capabilities, featuring a unique front-leg configuration and reinforcement learning controller.", "motivation": "Existing wheel-legged robot designs lack integration of flexibility and efficiency for varied terrains.", "method": "FLORES employs innovative front-leg hip-yaw design and a tailored reinforcement learning controller for adaptive loco-motion.", "result": "Experiments show superior steering, terrain adaptability, and efficiency compared to conventional designs.", "conclusion": "FLORES demonstrates the potential of integrating reconfigured mechanics with advanced controllers for versatile robotics."}}
{"id": "2507.22294", "pdf": "https://arxiv.org/pdf/2507.22294", "abs": "https://arxiv.org/abs/2507.22294", "authors": ["Gregor von Laszewski", "Wesley Brewer", "Sean R. Wilkinson", "Andrew Shao", "J. P. Fleischer", "Harshad Pitkar", "Christine R. Kirkpatrick", "Geoffrey C. Fox"], "title": "Towards Experiment Execution in Support of Community Benchmark Workflows for HPC", "categories": ["cs.DC"], "comment": null, "summary": "A key hurdle is demonstrating compute resource capability with limited\nbenchmarks. We propose workflow templates as a solution, offering adaptable\ndesigns for specific scientific applications. Our paper identifies common usage\npatterns for these templates, drawn from decades of HPC experience, including\nrecent work with the MLCommons Science working group.\n  We found that focusing on simple experiment management tools within the\nbroader computational workflow improves adaptability, especially in education.\nThis concept, which we term benchmark carpentry, is validated by two\nindependent tools: Cloudmesh's Experiment Executor and Hewlett Packard\nEnterprise's SmartSim. Both frameworks, with significant functional overlap,\nhave been tested across various scientific applications, including conduction\ncloudmask, earthquake prediction, simulation-AI/ML interactions, and the\ndevelopment of computational fluid dynamics surrogates.", "AI": {"tldr": "The paper proposes workflow templates to demonstrate computational resource capabilities and validate its concept through tools like Cloudmesh's Experiment Executor and HPE's SmartSim in various scientific applications.", "motivation": "To address the challenge of demonstrating computational resource capability with limited benchmarks in scientific applications.", "method": "The paper identifies common usage patterns for adaptable workflow templates, derived from extensive HPC experience and validated through tools Cloudmesh's Experiment Executor and HPE's SmartSim.", "result": "The proposed workflow templates improve adaptability, especially in education, and were successfully tested on various scientific applications such as cloudmask conduction and earthquake prediction.", "conclusion": "Benchmark carpentry through workflow templates and simple experiment management tools improves adaptability and validates the frameworks' utility in scientific computational workflows."}}
{"id": "2507.22216", "pdf": "https://arxiv.org/pdf/2507.22216", "abs": "https://arxiv.org/abs/2507.22216", "authors": ["Andrew Kyle Lampinen", "Stephanie C. Y. Chan", "Yuxuan Li", "Katherine Hermann"], "title": "Representation biases: will we achieve complete understanding by analyzing representations?", "categories": ["q-bio.NC", "cs.LG"], "comment": null, "summary": "A common approach in neuroscience is to study neural representations as a\nmeans to understand a system -- increasingly, by relating the neural\nrepresentations to the internal representations learned by computational\nmodels. However, a recent work in machine learning (Lampinen, 2024) shows that\nlearned feature representations may be biased to over-represent certain\nfeatures, and represent others more weakly and less-consistently. For example,\nsimple (linear) features may be more strongly and more consistently represented\nthan complex (highly nonlinear) features. These biases could pose challenges\nfor achieving full understanding of a system through representational analysis.\nIn this perspective, we illustrate these challenges -- showing how feature\nrepresentation biases can lead to strongly biased inferences from common\nanalyses like PCA, regression, and RSA. We also present homomorphic encryption\nas a simple case study of the potential for strong dissociation between\npatterns of representation and computation. We discuss the implications of\nthese results for representational comparisons between systems, and for\nneuroscience more generally.", "AI": {"tldr": "Neural representations analysis may be biased, affecting computational and neuroscientific insights.", "motivation": "To understand biases in feature representations that could hinder interpreting neural and computational systems.", "method": "The paper illustrates biases using analyses such as PCA, regression, and RSA, and uses homomorphic encryption as a case study.", "result": "Feature representation biases lead to skewed inferences, demonstrating challenges in representational comparisons.", "conclusion": "Researchers should account for biases in representation to avoid flawed system interpretations."}}
{"id": "2507.22832", "pdf": "https://arxiv.org/pdf/2507.22832", "abs": "https://arxiv.org/abs/2507.22832", "authors": ["Maciej Satkiewicz"], "title": "Tapping into the Black Box: Uncovering Aligned Representations in Pretrained Neural Networks", "categories": ["cs.LG", "cs.CV", "cs.NE", "I.2.6; I.4.10"], "comment": "15 pages, 4 figures, preprint", "summary": "In this paper we argue that ReLU networks learn an implicit linear model we\ncan actually tap into. We describe that alleged model formally and show that we\ncan approximately pull its decision boundary back to the input space with\ncertain simple modification to the backward pass. The resulting gradients\n(called excitation pullbacks) reveal high-resolution input- and target-specific\nfeatures of remarkable perceptual alignment on a number of popular\nImageNet-pretrained deep architectures. This strongly suggests that neural\nnetworks do, in fact, rely on learned interpretable patterns that can be\nrecovered after training. Thus, our findings may have profound implications for\nknowledge discovery and the development of dependable artificial systems.", "AI": {"tldr": "The paper shows ReLU networks implicitly learn linear models and proposes a method to uncover their interpretable decision-making process using a modified backward pass.", "motivation": "Deep neural networks are often viewed as black boxes, and there's a desire to understand their decision-making processes in a more interpretable way.", "method": "The authors formalize an implicit linear model in ReLU networks, apply certain modifications to the backward pass, and introduce 'excitation pullbacks' to uncover target-specific input features.", "result": "Excitation pullbacks present perceptually aligned high-resolution features, indicating that neural networks rely on interpretable learned patterns.", "conclusion": "The study suggests neural networks learn interpretable patterns, which can be extracted post-training, advancing knowledge discovery and the development of trustworthy AI systems."}}
{"id": "2507.22187", "pdf": "https://arxiv.org/pdf/2507.22187", "abs": "https://arxiv.org/abs/2507.22187", "authors": ["Adam M. Morgan", "Adeen Flinker"], "title": "A Scalable Pipeline for Estimating Verb Frame Frequencies Using Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "We present an automated pipeline for estimating Verb Frame Frequencies\n(VFFs), the frequency with which a verb appears in particular syntactic frames.\nVFFs provide a powerful window into syntax in both human and machine language\nsystems, but existing tools for calculating them are limited in scale,\naccuracy, or accessibility. We use large language models (LLMs) to generate a\ncorpus of sentences containing 476 English verbs. Next, by instructing an LLM\nto behave like an expert linguist, we had it analyze the syntactic structure of\nthe sentences in this corpus. This pipeline outperforms two widely used\nsyntactic parsers across multiple evaluation datasets. Furthermore, it requires\nfar fewer resources than manual parsing (the gold-standard), thereby enabling\nrapid, scalable VFF estimation. Using the LLM parser, we produce a new VFF\ndatabase with broader verb coverage, finer-grained syntactic distinctions, and\nexplicit estimates of the relative frequencies of structural alternates\ncommonly studied in psycholinguistics. The pipeline is easily customizable and\nextensible to new verbs, syntactic frames, and even other languages. We present\nthis work as a proof of concept for automated frame frequency estimation, and\nrelease all code and data to support future research.", "AI": {"tldr": "This paper introduces an automated pipeline using large language models (LLMs) for calculating Verb Frame Frequencies (VFFs) with enhanced accuracy, scalability, and accessibility compared to existing methods.", "motivation": "Verb Frame Frequencies (VFFs) play a significant role in understanding syntax in both human and machine languages, but existing methods for calculating VFFs face limitations in scale, accuracy, or accessibility.", "method": "The authors leverage LLMs to generate a corpus of sentences for 476 English verbs and then analyze these sentences syntactically using LLMs trained to mimic expert linguists. This pipeline is benchmarked against widely used syntactic parsers.", "result": "The pipeline outperformed existing syntactic parsers in multiple evaluations and required fewer resources compared to manual parsing methods. It enabled the creation of an extensive VFF database with finer syntactic distinctions and broader verb coverage.", "conclusion": "This approach demonstrates the feasibility of automated VFF estimation using LLMs, offering high scalability and customization potential for various applications, including psycholinguistics and cross-linguistic studies."}}
{"id": "2507.22076", "pdf": "https://arxiv.org/pdf/2507.22076", "abs": "https://arxiv.org/abs/2507.22076", "authors": ["Mohammad Abdul Hafeez Khan", "Yash Jain", "Siddhartha Bhattacharyya", "Vibhav Vineet"], "title": "Test-time Prompt Refinement for Text-to-Image Models", "categories": ["cs.LG"], "comment": "Accepted to ICCV 2025, MARS2 Workshop. Total 14 pages, 12 figures and\n  3 tables", "summary": "Text-to-image (T2I) generation models have made significant strides but still\nstruggle with prompt sensitivity: even minor changes in prompt wording can\nyield inconsistent or inaccurate outputs. To address this challenge, we\nintroduce a closed-loop, test-time prompt refinement framework that requires no\nadditional training of the underlying T2I model, termed TIR. In our approach,\neach generation step is followed by a refinement step, where a pretrained\nmultimodal large language model (MLLM) analyzes the output image and the user's\nprompt. The MLLM detects misalignments (e.g., missing objects, incorrect\nattributes) and produces a refined and physically grounded prompt for the next\nround of image generation. By iteratively refining the prompt and verifying\nalignment between the prompt and the image, TIR corrects errors, mirroring the\niterative refinement process of human artists. We demonstrate that this\nclosed-loop strategy improves alignment and visual coherence across multiple\nbenchmark datasets, all while maintaining plug-and-play integration with\nblack-box T2I models.", "AI": {"tldr": "The paper introduces TIR, a test-time prompt refinement framework to improve text-to-image generation by iteratively correcting prompt misalignments without retraining the model.", "motivation": "Text-to-image models suffer from sensitivity to prompt wording, leading to inconsistent outputs. Addressing this issue can enhance their reliability and utility.", "method": "A closed-loop refinement framework, TIR, uses a pretrained multimodal large language model (MLLM) to analyze generated images and prompts, detect misalignments, and refine the prompts iteratively during the generation process.", "result": "TIR was tested across multiple benchmark datasets, showing improved alignment and visual coherence without requiring retraining of the underlying T2I model.", "conclusion": "The proposed framework effectively enhances the performance of T2I models, demonstrating its viability as a plug-and-play solution for prompt refinement."}}
{"id": "2507.22070", "pdf": "https://arxiv.org/pdf/2507.22070", "abs": "https://arxiv.org/abs/2507.22070", "authors": ["Y. Du"], "title": "Automated Test Data Generation for Enterprise Protobuf Systems: A Metaclass-Enhanced Statistical Approach", "categories": ["cs.SE", "cs.CE", "cs.PL"], "comment": "7 pages", "summary": "Large-scale enterprise systems utilizing Protocol Buffers (protobuf) present\nsignificant challenges for performance testing, particularly when targeting\nintermediate business interfaces with complex nested data structures.\nTraditional test data generation approaches are inadequate for handling the\nintricate hierarchical and graph-like structures inherent in enterprise\nprotobuf schemas. This paper presents a novel test data generation framework\nthat leverages Python's metaclass system for dynamic type enhancement and\nstatistical analysis of production logs for realistic value domain extraction.\nOur approach combines automatic schema introspection, statistical value\ndistribution analysis, and recursive descent algorithms for handling deeply\nnested structures. Experimental evaluation on three real-world enterprise\nsystems demonstrates up to 95\\% reduction in test data preparation time and\n80\\% improvement in test coverage compared to existing approaches. The\nframework successfully handles protobuf structures with up to 15 levels of\nnesting and generates comprehensive test suites containing over 100,000 test\ncases within seconds.", "AI": {"tldr": "The paper introduces a framework for efficient test data generation in enterprise systems using Protocol Buffers, achieving significant improvements in preparation time and test coverage.", "motivation": "Traditional methods struggle with the complexity of nested and hierarchical protobuf structures, leading to inefficiencies in performance testing.", "method": "The proposed framework utilizes Python's metaclass system, schema introspection, statistical value domain extraction from logs, and recursive descent algorithms for generating test data.", "result": "Experiments show a 95% reduction in data preparation time, 80% increase in test coverage, and capability to handle 15 levels of nesting.", "conclusion": "The framework is highly efficient, scalable, and effective in generating comprehensive test cases for complex protobuf structures in enterprise environments."}}
{"id": "2507.22281", "pdf": "https://arxiv.org/pdf/2507.22281", "abs": "https://arxiv.org/abs/2507.22281", "authors": ["Minsoo Kim", "Seung-won Hwang"], "title": "CoEx -- Co-evolving World-model and Exploration", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Planning in modern LLM agents relies on the utilization of LLM as an internal\nworld model, acquired during pretraining. However, existing agent designs fail\nto effectively assimilate new observations into dynamic updates of the world\nmodel. This reliance on the LLM's static internal world model is progressively\nprone to misalignment with the underlying true state of the world, leading to\nthe generation of divergent and erroneous plans. We introduce a hierarchical\nagent architecture, CoEx, in which hierarchical state abstraction allows LLM\nplanning to co-evolve with a dynamically updated model of the world. CoEx plans\nand interacts with the world by using LLM reasoning to orchestrate dynamic\nplans consisting of subgoals, and its learning mechanism continuously\nincorporates these subgoal experiences into a persistent world model in the\nform of a neurosymbolic belief state, comprising textual inferences and\ncode-based symbolic memory. We evaluate our agent across a diverse set of agent\nscenarios involving rich environments and complex tasks including ALFWorld,\nPDDL, and Jericho. Our experiments show that CoEx outperforms existing agent\nparadigms in planning and exploration.", "AI": {"tldr": "Modern LLM agents struggle to adapt their static world models to dynamic environments, leading to flawed plans. CoEx is introduced as a hierarchical architecture enabling adaptive planning and persistent world model updates, showing superior performance in complex scenarios.", "motivation": "Existing LLM agent designs fail to account for dynamically changing environments, leading to misaligned plans due to a reliance on static internal models.", "method": "The paper introduces CoEx, a hierarchical architecture leveraging state abstraction, LLM reasoning, and a neurosymbolic belief state for dynamic adaptation and persistent memory updates.", "result": "CoEx demonstrates superior planning and exploration capabilities compared to existing paradigms across diverse and complex tasks.", "conclusion": "Through its dynamic planning and belief state mechanism, CoEx bridges the gap between static world models and evolving environments, improving task performance."}}
{"id": "2507.22101", "pdf": "https://arxiv.org/pdf/2507.22101", "abs": "https://arxiv.org/abs/2507.22101", "authors": ["Umair Nawaz", "Muhammad Zaigham Zaheer", "Fahad Shahbaz Khan", "Hisham Cholakkal", "Salman Khan", "Rao Muhammad Anwer"], "title": "AI in Agriculture: A Survey of Deep Learning Techniques for Crops, Fisheries and Livestock", "categories": ["cs.CV"], "comment": null, "summary": "Crops, fisheries and livestock form the backbone of global food production,\nessential to feed the ever-growing global population. However, these sectors\nface considerable challenges, including climate variability, resource\nlimitations, and the need for sustainable management. Addressing these issues\nrequires efficient, accurate, and scalable technological solutions,\nhighlighting the importance of artificial intelligence (AI). This survey\npresents a systematic and thorough review of more than 200 research works\ncovering conventional machine learning approaches, advanced deep learning\ntechniques (e.g., vision transformers), and recent vision-language foundation\nmodels (e.g., CLIP) in the agriculture domain, focusing on diverse tasks such\nas crop disease detection, livestock health management, and aquatic species\nmonitoring. We further cover major implementation challenges such as data\nvariability and experimental aspects: datasets, performance evaluation metrics,\nand geographical focus. We finish the survey by discussing potential open\nresearch directions emphasizing the need for multimodal data integration,\nefficient edge-device deployment, and domain-adaptable AI models for diverse\nfarming environments. Rapid growth of evolving developments in this field can\nbe actively tracked on our project page:\nhttps://github.com/umair1221/AI-in-Agriculture", "AI": {"tldr": "The paper reviews over 200 studies on the use of AI in agriculture, highlighting its application in crop disease detection, livestock health, and aquatic monitoring, while analyzing challenges like data variability and proposing open research directions.", "motivation": "The paper aims to address the challenges faced by agriculture, fisheries, and livestock industries, such as climate variability, resource limitations, and sustainability, by exploring the role of AI as an efficient and scalable solution.", "method": "The authors conduct a systematic survey of more than 200 research works, focusing on conventional machine learning, advanced deep learning, and vision-language models in agricultural applications. They also review datasets, performance metrics, and implementation hurdles.", "result": "The survey provides a comprehensive overview of the state of AI in agriculture, identifying key applications, challenges like data variability, and gaps such as the need for multimodal data integration and edge-device deployment.", "conclusion": "AI offers transformative potential for agriculture, but further research is essential to overcome challenges like data variability and to develop domain-adaptable models for practical use in diverse farming environments."}}
{"id": "2507.22493", "pdf": "https://arxiv.org/pdf/2507.22493", "abs": "https://arxiv.org/abs/2507.22493", "authors": ["Xiaodong Feng", "Ling Guo", "Xiaoliang Wan", "Hao Wu", "Tao Zhou", "Wenwen Zhou"], "title": "LVM-GP: Uncertainty-Aware PDE Solver via coupling latent variable model and Gaussian process", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "We propose a novel probabilistic framework, termed LVM-GP, for uncertainty\nquantification in solving forward and inverse partial differential equations\n(PDEs) with noisy data. The core idea is to construct a stochastic mapping from\nthe input to a high-dimensional latent representation, enabling\nuncertainty-aware prediction of the solution. Specifically, the architecture\nconsists of a confidence-aware encoder and a probabilistic decoder. The encoder\nimplements a high-dimensional latent variable model based on a Gaussian process\n(LVM-GP), where the latent representation is constructed by interpolating\nbetween a learnable deterministic feature and a Gaussian process prior, with\nthe interpolation strength adaptively controlled by a confidence function\nlearned from data. The decoder defines a conditional Gaussian distribution over\nthe solution field, where the mean is predicted by a neural operator applied to\nthe latent representation, allowing the model to learn flexible\nfunction-to-function mapping. Moreover, physical laws are enforced as soft\nconstraints in the loss function to ensure consistency with the underlying PDE\nstructure. Compared to existing approaches such as Bayesian physics-informed\nneural networks (B-PINNs) and deep ensembles, the proposed framework can\nefficiently capture functional dependencies via merging a latent Gaussian\nprocess and neural operator, resulting in competitive predictive accuracy and\nrobust uncertainty quantification. Numerical experiments demonstrate the\neffectiveness and reliability of the method.", "AI": {"tldr": "The paper presents LVM-GP, a novel probabilistic framework for uncertainty quantification in solving PDEs with noisy data, integrating a Gaussian process and neural operator, and surpassing existing methods like B-PINNs in prediction accuracy and uncertainty handling.", "motivation": "To address the challenge of uncertainty quantification in solving forward and inverse PDEs using noisy data, improving upon existing methods like B-PINNs in terms of efficiency, accuracy, and robustness.", "method": "The framework uses a stochastic mapping via a confidence-aware encoder with a Gaussian process-based latent variable model and a probabilistic decoder. Soft constraints enforce physical law consistency, and a neural operator enables flexible function-to-function mappings.", "result": "Demonstrated improved predictive accuracy and reliable uncertainty quantification through numerical experiments, outperforming methods like B-PINNs and deep ensembles.", "conclusion": "LVM-GP effectively integrates probabilistic modeling and neural operators, achieving robust and accurate solutions to PDEs, making it a competitive and reliable solution compared to existing methods."}}
{"id": "2507.22356", "pdf": "https://arxiv.org/pdf/2507.22356", "abs": "https://arxiv.org/abs/2507.22356", "authors": ["W. Jacob Wagner", "Ahmet Soylemezoglu", "Katherine Driggs-Campbell"], "title": "In-Situ Soil-Property Estimation and Bayesian Mapping with a Simulated Compact Track Loader", "categories": ["cs.RO", "J.2"], "comment": "29 pages, 12 figures, 5 algorithms, ISTVS 2025", "summary": "Existing earthmoving autonomy is largely confined to highly controlled and\nwell-characterized environments due to the complexity of vehicle-terrain\ninteraction dynamics and the partial observability of the terrain resulting\nfrom unknown and spatially varying soil conditions. In this chapter, a a\nsoil-property mapping system is proposed to extend the environmental state, in\norder to overcome these restrictions and facilitate development of more robust\nautonomous earthmoving. A GPU accelerated elevation mapping system is extended\nto incorporate a blind mapping component which traces the movement of the blade\nthrough the terrain to displace and erode intersected soil, enabling separately\ntracking undisturbed and disturbed soil. Each interaction is approximated as a\nflat blade moving through a locally homogeneous soil, enabling modeling of\ncutting forces using the fundamental equation of earthmoving (FEE). Building\nupon our prior work on in situ soil-property estimation, a method is devised to\nextract approximate geometric parameters of the model given the uneven terrain,\nand an improved physics infused neural network (PINN) model is developed to\npredict soil properties and uncertainties of these estimates. A simulation of a\ncompact track loader (CTL) with a blade attachment is used to collect data to\ntrain the PINN model. Post-training, the model is leveraged online by the\nmapping system to track soil property estimates spatially as separate layers in\nthe map, with updates being performed in a Bayesian manner. Initial experiments\nshow that the system accurately highlights regions requiring higher relative\ninteraction forces, indicating the promise of this approach in enabling\nsoil-aware planning for autonomous terrain shaping.", "AI": {"tldr": "This paper introduces an advanced soil-property mapping system to enhance autonomous earthmoving by tracking disturbed and undisturbed soil layers using GPU-accelerated mapping and a physics-infused neural network.", "motivation": "The work is motivated by the limitations of current autonomous earthmoving systems, which struggle in complex and unknown terrain due to partial observability and variable soil conditions.", "method": "A GPU-accelerated elevation mapping system combined with a blind mapping component tracks soil dynamics. A physics-infused neural network (PINN) predicts soil properties using data from vehicle-soil interaction simulations, applying Bayesian updates in real-time.", "result": "The initial experiments validate the system's ability to pinpoint areas requiring higher interaction forces for terrain shaping, demonstrating promising results for soil-aware autonomous planning.", "conclusion": "The proposed system offers a powerful approach to improve autonomous earthmoving processes by accurately mapping and anticipating soil-property dynamics, paving the way for operational efficiency in diverse terrains."}}
{"id": "2507.22339", "pdf": "https://arxiv.org/pdf/2507.22339", "abs": "https://arxiv.org/abs/2507.22339", "authors": ["Zhuocheng Liu", "Zhishu Shen", "Qiushi Zheng", "Tiehua Zhang", "Zheng Lei", "Jiong Jin"], "title": "A Semi-Supervised Federated Learning Framework with Hierarchical Clustering Aggregation for Heterogeneous Satellite Networks", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Low Earth Orbit (LEO) satellites are emerging as key components of 6G\nnetworks, with many already deployed to support large-scale Earth observation\nand sensing related tasks. Federated Learning (FL) presents a promising\nparadigm for enabling distributed intelligence in these resource-constrained\nand dynamic environments. However, achieving reliable convergence, while\nminimizing both processing time and energy consumption, remains a substantial\nchallenge, particularly in heterogeneous and partially unlabeled satellite\nnetworks. To address this challenge, we propose a novel semi-supervised\nfederated learning framework tailored for LEO satellite networks with\nhierarchical clustering aggregation. To further reduce communication overhead,\nwe integrate sparsification and adaptive weight quantization techniques. In\naddition, we divide the FL clustering into two stages: satellite cluster\naggregation stage and Ground Stations (GSs) aggregation stage. The supervised\nlearning at GSs guides selected Parameter Server (PS) satellites, which in turn\nsupport fully unlabeled satellites during the federated training process.\nExtensive experiments conducted on a satellite network testbed demonstrate that\nour proposal can significantly reduce processing time (up to 3x) and energy\nconsumption (up to 4x) compared to other comparative methods while maintaining\nmodel accuracy.", "AI": {"tldr": "This paper proposes a novel semi-supervised federated learning framework for Low Earth Orbit (LEO) satellite networks to improve convergence, minimize processing time, and reduce energy consumption.", "motivation": "LEO satellites are increasingly central to 6G networks and supporting distributed tasks. However, utilizing Federated Learning in these dynamic, heterogeneous satellite networks comes with challenges like reliable convergence, processing time optimization, and energy efficiency.", "method": "The framework combines hierarchical clustering aggregation, sparsification, adaptive weight quantization, and hierarchical clustering in two stages: satellite cluster aggregation and ground station aggregation. Supervised learning at the ground stations guides the federated training process for Parameter Server satellites and fully unlabeled satellites.", "result": "The experimental results reveal significant improvements: processing time is reduced by up to 3x, and energy consumption is reduced by up to 4x compared to existing methods, all while maintaining model accuracy.", "conclusion": "The proposed semi-supervised federated learning framework is effective and efficient for LEO satellite networks, enabling distributed intelligence with enhanced performance metrics."}}
{"id": "2507.22313", "pdf": "https://arxiv.org/pdf/2507.22313", "abs": "https://arxiv.org/abs/2507.22313", "authors": ["Woojae Jeong", "Aditya Kommineni", "Kleanthis Avramidis", "Colin McDaniel", "Donald Berry", "Myzelle Hughes", "Thomas McGee", "Elsi Kaiser", "Dani Byrd", "Assal Habibi", "B. Rael Cahn", "Idan A. Blank", "Kristina Lerman", "Dimitrios Pantazis", "Sudarsana R. Kadiri", "Takfarinas Medani", "Shrikanth Narayanan", "Richard M. Leahy"], "title": "Decoding Neural Signatures of Semantic Evaluations in Depression and Suicidality", "categories": ["q-bio.NC", "cs.LG", "eess.SP"], "comment": null, "summary": "Depression and suicidality profoundly impact cognition and emotion, yet\nobjective neurophysiological biomarkers remain elusive. We investigated the\nspatiotemporal neural dynamics underlying affective semantic processing in\nindividuals with varying levels of clinical severity of depression and\nsuicidality using multivariate decoding of electroencephalography (EEG) data.\nParticipants (N=137) completed a sentence evaluation task involving emotionally\ncharged self-referential statements while EEG was recorded. We identified\nrobust, neural signatures of semantic processing, with peak decoding accuracy\nbetween 300-600 ms -- a window associated with automatic semantic evaluation\nand conflict monitoring. Compared to healthy controls, individuals with\ndepression and suicidality showed earlier onset, longer duration, and greater\namplitude decoding responses, along with broader cross-temporal generalization\nand increased activation of frontocentral and parietotemporal components. These\nfindings suggest altered sensitivity and impaired disengagement from\nemotionally salient content in the clinical groups, advancing our understanding\nof the neurocognitive basis of mental health and providing a principled basis\nfor developing reliable EEG-based biomarkers of depression and suicidality.", "AI": {"tldr": "This paper explores EEG-detected neural dynamics in emotional sentence evaluation tasks to identify biomarkers for depression and suicidality.", "motivation": "To address the lack of objective neurophysiological biomarkers for depression and suicidality by examining neural responses to emotional semantic content.", "method": "Using EEG data on 137 participants, the study employed multivariate decoding during emotional sentence evaluation tasks to analyze spatiotemporal neural dynamics tied to depression and suicidality.", "result": "People with depression and suicidality displayed earlier onset, longer duration, and intensified neural responses, along with broader activation in specific brain regions, compared to healthy controls.", "conclusion": "The findings highlight altered neural sensitivity and disengagement impairments in clinical groups, paving the way for EEG-based biomarkers of depression and suicidality."}}
{"id": "2507.22201", "pdf": "https://arxiv.org/pdf/2507.22201", "abs": "https://arxiv.org/abs/2507.22201", "authors": ["L. Toschi", "S. Torrisi", "A. Fronzetti Colladon"], "title": "The role of media memorability in facilitating startups' access to venture capital funding", "categories": ["cs.CL", "cs.SI", "physics.soc-ph", "I.2.7; J.4; H.4.0"], "comment": null, "summary": "Media reputation plays an important role in attracting venture capital\ninvestment. However, prior research has focused too narrowly on general media\nexposure, limiting our understanding of how media truly influences funding\ndecisions. As informed decision-makers, venture capitalists respond to more\nnuanced aspects of media content. We introduce the concept of media\nmemorability - the media's ability to imprint a startup's name in the memory of\nrelevant investors. Using data from 197 UK startups in the micro and\nnanotechnology sector (funded between 1995 and 2004), we show that media\nmemorability significantly influences investment outcomes. Our findings suggest\nthat venture capitalists rely on detailed cues such as a startup's\ndistinctiveness and connectivity within news semantic networks. This\ncontributes to research on entrepreneurial finance and media legitimation. In\npractice, startups should go beyond frequent media mentions to strengthen brand\nmemorability through more targeted, meaningful coverage highlighting their\nuniqueness and relevance within the broader industry conversation.", "AI": {"tldr": "The study explores how media memorability, beyond sheer media exposure, influences venture capital investment decisions for startups.", "motivation": "To address the gap in understanding how nuanced aspects of media content impact funding decisions by venture capitalists.", "method": "Analysis of 197 UK startups in the micro and nanotechnology sector, funded between 1995 and 2004, assessing their media memorability and its relation to investment outcomes.", "result": "Media memorability\u2014focused on the distinctiveness and connectivity of startups in semantic networks\u2014significantly influences venture capital investment decisions.", "conclusion": "Startups should prioritize meaningful media coverage to enhance memorability, emphasizing their distinctiveness and relevance within industry narratives to attract venture funding."}}
{"id": "2507.22079", "pdf": "https://arxiv.org/pdf/2507.22079", "abs": "https://arxiv.org/abs/2507.22079", "authors": ["Leo Guo", "Hirak Kansara", "Siamak F. Khosroshahi", "GuoQi Zhang", "Wei Tan"], "title": "Multi-fidelity Bayesian Data-Driven Design of Energy Absorbing Spinodoid Cellular Structures", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "comment": "data-driven design, multi-fidelity, Bayesian optimization, cellular\n  structures, energy absorption", "summary": "Finite element (FE) simulations of structures and materials are getting\nincreasingly more accurate, but also more computationally expensive as a\ncollateral result. This development happens in parallel with a growing demand\nof data-driven design. To reconcile the two, a robust and data-efficient\noptimization method called Bayesian optimization (BO) has been previously\nestablished as a technique to optimize expensive objective functions. In\nparallel, the mesh width of an FE model can be exploited to evaluate an\nobjective at a lower or higher fidelity (cost & accuracy) level. The\nmulti-fidelity setting applied to BO, called multi-fidelity BO (MFBO), has also\nseen previous success. However, BO and MFBO have not seen a direct comparison\nwith when faced with with a real-life engineering problem, such as metamaterial\ndesign for deformation and absorption qualities. Moreover, sampling quality and\nassessing design parameter sensitivity is often an underrepresented part of\ndata-driven design. This paper aims to address these shortcomings by employing\nSobol' samples with variance-based sensitivity analysis in order to reduce\ndesign problem complexity. Furthermore, this work describes, implements,\napplies and compares the performance BO with that MFBO when maximizing the\nenergy absorption (EA) problem of spinodoid cellular structures is concerned.\nThe findings show that MFBO is an effective way to maximize the EA of a\nspinodoid structure and is able to outperform BO by up to 11% across various\nhyperparameter settings. The results, which are made open-source, serve to\nsupport the utility of multi-fidelity techniques across expensive data-driven\ndesign problems.", "AI": {"tldr": "This paper explores and compares Bayesian Optimization (BO) and Multi-Fidelity Bayesian Optimization (MFBO) for maximizing energy absorption in spinodoid cellular structures, showing that MFBO outperforms BO by up to 11%.", "motivation": "To address the increasing computational expense of finite element simulations while responding to the growing demand for data-efficient design methods. It also aims to fill gaps in sensitivity analysis and sample quality representation in data-driven engineering.", "method": "The study employs Sobol' samples with variance-based sensitivity analysis to reduce problem complexity, and compares BO and MFBO performances for maximizing energy absorption in spinodoid structures using finite element analysis.", "result": "MFBO outperformed BO by up to 11% across various hyperparameter settings in optimizing the energy absorption of spinodoid structures.", "conclusion": "Multi-Fidelity Bayesian Optimization (MFBO) is an effective and superior approach for addressing expensive, data-driven design problems like energy absorption optimization in metamaterials. The results, available open-source, highlight the utility of multi-fidelity techniques."}}
{"id": "2507.22086", "pdf": "https://arxiv.org/pdf/2507.22086", "abs": "https://arxiv.org/abs/2507.22086", "authors": ["Honghua Dong", "Jiacheng Yang", "Xun Deng", "Yuhe Jiang", "Gennady Pekhimenko", "Fan Long", "Xujie Si"], "title": "TypyBench: Evaluating LLM Type Inference for Untyped Python Repositories", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": null, "summary": "Type inference for dynamic languages like Python is a persistent challenge in\nsoftware engineering. While large language models (LLMs) have shown promise in\ncode understanding, their type inference capabilities remain underexplored. We\nintroduce TypyBench, a benchmark designed to evaluate LLMs' type inference\nacross entire Python repositories. TypyBench features two novel metrics:\nTypeSim, which captures nuanced semantic relationships between predicted and\nground truth types, and TypeCheck, which assesses type consistency across\ncodebases. Our evaluation of various LLMs on a curated dataset of 50\nhigh-quality Python repositories reveals that, although LLMs achieve decent\nTypeSim scores, they struggle with complex nested types and exhibit significant\ntype consistency errors. These findings suggest that future research should\nshift focus from improving type similarity to addressing repository-level\nconsistency. TypyBench provides a foundation for this new direction, offering\ninsights into model performance across different type complexities and usage\ncontexts. Our code and data are available at\nhttps://github.com/typybench/typybench.", "AI": {"tldr": "The paper presents TypyBench, a benchmark for evaluating type inference capabilities of large language models (LLMs) in Python repositories, highlighting their struggles with type consistency and complex types.", "motivation": "The study aims to address the persistent challenge of type inference in dynamic programming languages like Python, leveraging the potential of LLMs.", "method": "The researchers developed TypyBench with two metrics, TypeSim and TypeCheck, to evaluate type inference in Python repositories. They also curated a dataset of 50 high-quality repositories.", "result": "The evaluation revealed LLMs performed adequately in semantic type similarity (TypeSim) but struggled with nested types and consistency (TypeCheck).", "conclusion": "The paper underscores the need for research to prioritize repository-level type consistency over type similarity, with TypyBench serving as a foundation for such efforts."}}
{"id": "2507.22326", "pdf": "https://arxiv.org/pdf/2507.22326", "abs": "https://arxiv.org/abs/2507.22326", "authors": ["Qun Ma", "Xiao Xue", "Ming Zhang", "Yifan Shen", "Zihan Zhao"], "title": "An Explainable Emotion Alignment Framework for LLM-Empowered Agent in Metaverse Service Ecosystem", "categories": ["cs.AI"], "comment": null, "summary": "Metaverse service is a product of the convergence between Metaverse and\nservice systems, designed to address service-related challenges concerning\ndigital avatars, digital twins, and digital natives within Metaverse. With the\nrise of large language models (LLMs), agents now play a pivotal role in\nMetaverse service ecosystem, serving dual functions: as digital avatars\nrepresenting users in the virtual realm and as service assistants (or NPCs)\nproviding personalized support. However, during the modeling of Metaverse\nservice ecosystems, existing LLM-based agents face significant challenges in\nbridging virtual-world services with real-world services, particularly\nregarding issues such as character data fusion, character knowledge\nassociation, and ethical safety concerns. This paper proposes an explainable\nemotion alignment framework for LLM-based agents in Metaverse Service\nEcosystem. It aims to integrate factual factors into the decision-making loop\nof LLM-based agents, systematically demonstrating how to achieve more\nrelational fact alignment for these agents. Finally, a simulation experiment in\nthe Offline-to-Offline food delivery scenario is conducted to evaluate the\neffectiveness of this framework, obtaining more realistic social emergence.", "AI": {"tldr": "This paper introduces an explainable emotion alignment framework to enhance large language model-based agents in the Metaverse service ecosystem, focusing on bridging virtual and real-world services through improved decision-making and alignment.", "motivation": "The motivation is to address challenges faced by LLM-based agents in Metaverse services, such as character data fusion, knowledge association, and ethical safety, which hinder seamless integration between virtual and real-world services.", "method": "The proposed method is an explainable emotion alignment framework designed to integrate factual factors into the decision-making loop of LLM-based agents. It demonstrates relational fact alignment and is evaluated through a simulation experiment.", "result": "The simulation experiment, based on an Offline-to-Offline food delivery scenario, shows that the framework enhances the realism and social emergence of agent interactions.", "conclusion": "The framework effectively improves the decision-making of LLM-based agents within the Metaverse service ecosystem, facilitating better integration of services and addressing key challenges."}}
{"id": "2507.22066", "pdf": "https://arxiv.org/pdf/2507.22066", "abs": "https://arxiv.org/abs/2507.22066", "authors": ["Dylan Manuel", "Paul Rad"], "title": "CodableLLM: Automating Decompiled and Source Code Mapping for LLM Dataset Generation", "categories": ["cs.SE", "cs.CR"], "comment": null, "summary": "The generation of large, high-quality datasets for code understanding and\ngeneration remains a significant challenge, particularly when aligning\ndecompiled binaries with their original source code. To address this, we\npresent CodableLLM, a Python framework designed to automate the creation and\ncuration of datasets by mapping decompiled functions to their corresponding\nsource functions. This process enhances the alignment between decompiled and\nsource code representations, facilitating the development of large language\nmodels (LLMs) capable of understanding and generating code across multiple\nabstraction levels. CodableLLM supports multiple programming languages and\nintegrates with existing decompilers and parsers to streamline dataset\ngeneration. This paper presents the design and implementation of CodableLLM,\nevaluates its performance in dataset creation, and compares it to existing\ntools in the field. The results demonstrate that CodableLLM offers a robust and\nefficient solution for generating datasets tailored for code-focused LLMS.", "AI": {"tldr": "The paper introduces CodableLLM, a Python framework that automates the creation of aligned datasets for decompiled and source code, aimed at improving code-focused LLMs.", "motivation": "The lack of high-quality datasets aligning decompiled binaries with source code limits the potential of LLMs in code understanding and generation.", "method": "CodableLLM automates the generation of datasets by integrating with decompilers and parsers, mapping decompiled functions to their corresponding source functions across programming languages.", "result": "CodableLLM outperforms existing tools in terms of robustness and efficiency in creating datasets tailored for code-centric LLMs.", "conclusion": "CodableLLM provides an effective solution to improve dataset quality for LLMs in coding, supporting advancements in cross-level code understanding and generation."}}
{"id": "2507.22136", "pdf": "https://arxiv.org/pdf/2507.22136", "abs": "https://arxiv.org/abs/2507.22136", "authors": ["Chaofei Qi", "Zhitai Liu", "Jianbin Qiu"], "title": "Color as the Impetus: Transforming Few-Shot Learner", "categories": ["cs.CV"], "comment": null, "summary": "Humans possess innate meta-learning capabilities, partly attributable to\ntheir exceptional color perception. In this paper, we pioneer an innovative\nviewpoint on few-shot learning by simulating human color perception mechanisms.\nWe propose the ColorSense Learner, a bio-inspired meta-learning framework that\ncapitalizes on inter-channel feature extraction and interactive learning. By\nstrategically emphasizing distinct color information across different channels,\nour approach effectively filters irrelevant features while capturing\ndiscriminative characteristics. Color information represents the most intuitive\nvisual feature, yet conventional meta-learning methods have predominantly\nneglected this aspect, focusing instead on abstract feature differentiation\nacross categories. Our framework bridges the gap via synergistic color-channel\ninteractions, enabling better intra-class commonality extraction and larger\ninter-class differences. Furthermore, we introduce a meta-distiller based on\nknowledge distillation, ColorSense Distiller, which incorporates prior teacher\nknowledge to augment the student network's meta-learning capacity. We've\nconducted comprehensive coarse/fine-grained and cross-domain experiments on\neleven few-shot benchmarks for validation. Numerous experiments reveal that our\nmethods have extremely strong generalization ability, robustness, and\ntransferability, and effortless handle few-shot classification from the\nperspective of color perception.", "AI": {"tldr": "This paper introduces the ColorSense Learner, a bio-inspired meta-learning framework emphasizing human-like color perception for few-shot learning, along with a ColorSense Distiller to enhance model performance.", "motivation": "To leverage human-like color perception mechanisms, which are often overlooked in conventional meta-learning, for improving feature extraction in few-shot learning.", "method": "The paper proposes a framework called ColorSense Learner that utilizes color-channel interactions to highlight important features for few-shot learning. In addition, a ColorSense Distiller uses knowledge distillation to enhance the framework's effectiveness.", "result": "The approach demonstrated strong generalizability, robustness, and transferability in few-shot learning experiments conducted across eleven benchmarks.", "conclusion": "Modeling human-inspired color perception into meta-learning significantly boosts performance in few-shot classification tasks by enhancing discriminative feature extraction across classes and channels."}}
{"id": "2507.22632", "pdf": "https://arxiv.org/pdf/2507.22632", "abs": "https://arxiv.org/abs/2507.22632", "authors": ["Elif Vural", "Huseyin Karaca"], "title": "A Unified Analysis of Generalization and Sample Complexity for Semi-Supervised Domain Adaptation", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Domain adaptation seeks to leverage the abundant label information in a\nsource domain to improve classification performance in a target domain with\nlimited labels. While the field has seen extensive methodological development,\nits theoretical foundations remain relatively underexplored. Most existing\ntheoretical analyses focus on simplified settings where the source and target\ndomains share the same input space and relate target-domain performance to\nmeasures of domain discrepancy. Although insightful, these analyses may not\nfully capture the behavior of modern approaches that align domains into a\nshared space via feature transformations. In this paper, we present a\ncomprehensive theoretical study of domain adaptation algorithms based on domain\nalignment. We consider the joint learning of domain-aligning feature\ntransformations and a shared classifier in a semi-supervised setting. We first\nderive generalization bounds in a broad setting, in terms of covering numbers\nof the relevant function classes. We then extend our analysis to characterize\nthe sample complexity of domain-adaptive neural networks employing maximum mean\ndiscrepancy (MMD) or adversarial objectives. Our results rely on a rigorous\nanalysis of the covering numbers of these architectures. We show that, for both\nMMD-based and adversarial models, the sample complexity admits an upper bound\nthat scales quadratically with network depth and width. Furthermore, our\nanalysis suggests that in semi-supervised settings, robustness to limited\nlabeled target data can be achieved by scaling the target loss proportionally\nto the square root of the number of labeled target samples. Experimental\nevaluation in both shallow and deep settings lends support to our theoretical\nfindings.", "AI": {"tldr": "This paper provides a theoretical study of domain adaptation algorithms based on feature alignment, analyzing sample complexity in semi-supervised settings and offering generalization bounds.", "motivation": "The authors aim to address gaps in the theoretical understanding of domain adaptation, particularly for modern approaches involving feature transformations and shared spaces.", "method": "The paper employs rigorous mathematical analysis, deriving generalization bounds and characterizing sample complexity for MMD-based and adversarial domain-adaptive neural networks.", "result": "The study finds that sample complexity scales quadratically with network depth and width, and suggests proportional scaling of target loss to optimize limited labeled target data in semi-supervised settings.", "conclusion": "This work deepens understanding of domain-adaptive algorithms' theoretical properties, providing insights into their behavior and guidance for their practical use."}}
{"id": "2507.22380", "pdf": "https://arxiv.org/pdf/2507.22380", "abs": "https://arxiv.org/abs/2507.22380", "authors": ["Yifei Chen", "Yuzhe Zhang", "Giovanni D'urso", "Nicholas Lawrance", "Brendan Tidd"], "title": "Improving Generalization Ability of Robotic Imitation Learning by Resolving Causal Confusion in Observations", "categories": ["cs.RO", "cs.LG"], "comment": "13 pages", "summary": "Recent developments in imitation learning have considerably advanced robotic\nmanipulation. However, current techniques in imitation learning can suffer from\npoor generalization, limiting performance even under relatively minor domain\nshifts. In this work, we aim to enhance the generalization capabilities of\ncomplex imitation learning algorithms to handle unpredictable changes from the\ntraining environments to deployment environments. To avoid confusion caused by\nobservations that are not relevant to the target task, we propose to explicitly\nlearn the causal relationship between observation components and expert\nactions, employing a framework similar to [6], where a causal structural\nfunction is learned by intervention on the imitation learning policy.\nDisentangling the feature representation from image input as in [6] is hard to\nsatisfy in complex imitation learning process in robotic manipulation, we\ntheoretically clarify that this requirement is not necessary in causal\nrelationship learning. Therefore, we propose a simple causal structure learning\nframework that can be easily embedded in recent imitation learning\narchitectures, such as the Action Chunking Transformer [31]. We demonstrate our\napproach using a simulation of the ALOHA [31] bimanual robot arms in Mujoco,\nand show that the method can considerably mitigate the generalization problem\nof existing complex imitation learning algorithms.", "AI": {"tldr": "The paper addresses the poor generalization in imitation learning for robotic manipulation by proposing a causal structure learning framework to improve robustness in domain shifts.", "motivation": "Enhancing generalization capabilities of imitation learning algorithms for robotic manipulation to handle unpredictable domain shifts.", "method": "They propose a causal structure learning framework involving intervention on imitation learning policies without requiring disentangled feature representations.", "result": "The framework is tested on simulations of bimanual robot arms in Mujoco, showing significant mitigation of generalization problems in imitation learning.", "conclusion": "Explicitly learning causal relationships can improve generalization in complex robotic manipulation tasks and can be seamlessly integrated into existing architectures."}}
{"id": "2507.22372", "pdf": "https://arxiv.org/pdf/2507.22372", "abs": "https://arxiv.org/abs/2507.22372", "authors": ["Grace Nansamba", "Evelyn Namugwanya", "David Boehme", "Dewi Yokelson", "Riley Shipley", "Derek Schafer", "Michael McKinsey", "Olga Pearce", "Anthony Skjellum"], "title": "Leveraging Caliper and Benchpark to Analyze MPI Communication Patterns: Insights from AMG2023, Kripke, and Laghos", "categories": ["cs.DC"], "comment": "10 pages, 6 figures", "summary": "We introduce ``communication regions'' into the widely used Caliper HPC\nprofiling tool. A communication region is an annotation enabling capture of\nmetrics about the data being communicated (including statistics of these\nmetrics), and metrics about the MPI processes involved in the communications,\nsomething not previously possible in Caliper. We explore the utility of\ncommunication regions with three representative modeling and simulation\napplications, AMG2023, Kripke, and Laghos, all part of the comprehensive\nBenchpark suite that includes Caliper annotations. Enhanced Caliper reveals\ndetailed communication behaviors. Using Caliper and Thicket in tandem, we\ncreate new visualizations of MPI communication patterns, including halo\nexchanges. Our findings reveal communication bottlenecks and detailed\nbehaviors, indicating significant utility of the special-regions addition to\nCaliper. The comparative scaling behavior of both CPU and GPU oriented systems\nare shown; we are able to look at different regions within a given application,\nand see how scalability and message-traffic metrics differ.", "AI": {"tldr": "The paper enhances the Caliper HPC profiling tool by introducing communication regions to capture detailed communication behaviors and visualize MPI patterns, offering insights such as communication bottlenecks.", "motivation": "To address the lack of detailed analysis and visualization capabilities for MPI communication patterns in existing HPC profiling tools, including Caliper.", "method": "The authors introduced communication regions into Caliper that enable capturing metrics about communicated data and MPI processes. They evaluated the tool's utility using applications from the Benchpark suite like AMG2023, Kripke, and Laghos.", "result": "The enhanced Caliper tool successfully identifies communication bottlenecks, visualizes MPI communication patterns, and differentiates scalability and message-traffic metrics for CPU and GPU-oriented systems.", "conclusion": "The addition of communication regions significantly enhances Caliper's ability to analyze and visualize detailed HPC communication behaviors, proving valuable for profiling and optimization."}}
{"id": "2507.22785", "pdf": "https://arxiv.org/pdf/2507.22785", "abs": "https://arxiv.org/abs/2507.22785", "authors": ["Jayanth R Taranath", "Salim M'Jahad"], "title": "An Uncertainty Principle for Probabilistic Computation in the Retina", "categories": ["q-bio.NC"], "comment": null, "summary": "We introduce a probabilistic model of early visual processing, beginning with\nthe interaction between a light wavefront and the retina. We argue that\nperception originates not with deterministic transduction, but with\nprobabilistic threshold crossings shaped by quantum photon arrival statistics\nand biological variability. We formalize this with an uncertainty relation, \\(\n\\Delta \\alpha \\cdot \\Delta t \\geq \\eta \\), through the transformation of light\ninto symbolic neural code through the layered retinal architecture. Our model\nis supported by previous experimental results, which show intrinsic variability\nin retinal responses even under fixed stimuli. We contrast this with a\nclassical null hypothesis of deterministic encoding and propose experiments to\nfurther test our uncertainty relation. By re-framing the retina as a\nprobabilistic measurement device, we lay the foundation for future models of\ncortical dynamics rooted in quantum-like computation. We are not claiming that\nthe brain could be working as a quantum-system, but rather putting forth the\nargument that the brain as a classical system could still implement\nquantum-inspired computations. We define quantum-inspired computation as a\nscheme that includes both probabilistic and time-sensitive computation, clearly\nseparating it from classically implementable probabilistic systems.", "AI": {"tldr": "The paper presents a probabilistic model of early visual processing that incorporates quantum-inspired computation principles and biological variability.", "motivation": "The paper aims to challenge the traditional deterministic view of retinal processing and establish a new framework based on probabilistic principles influenced by quantum photon statistics and intrinsic biological variability.", "method": "The authors develop a probabilistic model describing light's transformation into neural signals in the retina, formalized using an uncertainty relation. They base their approach on prior experimental findings and propose future experiments to test their hypotheses.", "result": "The model explains intrinsic variability in retinal responses to fixed stimuli and introduces a framework for integrating quantum-inspired computation into neural processing.", "conclusion": "By redefining the retina as a probabilistic measurement device, the study provides a basis for exploring cortical dynamics with quantum-inspired computational principles, bridging classical and probabilistic systems."}}
{"id": "2507.22209", "pdf": "https://arxiv.org/pdf/2507.22209", "abs": "https://arxiv.org/abs/2507.22209", "authors": ["Christian Clark", "Byung-Doh Oh", "William Schuler"], "title": "How Well Does First-Token Entropy Approximate Word Entropy as a Psycholinguistic Predictor?", "categories": ["cs.CL"], "comment": null, "summary": "Contextual entropy is a psycholinguistic measure capturing the anticipated\ndifficulty of processing a word just before it is encountered. Recent studies\nhave tested for entropy-related effects as a potential complement to well-known\neffects from surprisal. For convenience, entropy is typically estimated based\non a language model's probability distribution over a word's first subword\ntoken. However, this approximation results in underestimation and potential\ndistortion of true word entropy. To address this, we generate Monte Carlo (MC)\nestimates of word entropy that allow words to span a variable number of tokens.\nRegression experiments on reading times show divergent results between\nfirst-token and MC word entropy, suggesting a need for caution in using\nfirst-token approximations of contextual entropy.", "AI": {"tldr": "The paper explores entropy measures in language processing and finds that using a word's first-token for entropy estimates can lead to inaccuracies, proposing Monte Carlo methods for better estimates.", "motivation": "To address the inaccuracy and distortion in measuring word entropy using first-token probability distributions in psycholinguistics.", "method": "Monte Carlo (MC) methods were used to estimate word entropy by accounting for the variability in the number of tokens a word spans.", "result": "MC word entropy estimates led to divergent findings in regression experiments on reading times compared to first-token word entropy estimates.", "conclusion": "First-token approximations for contextual entropy are flawed, and Monte Carlo methods offer a better estimation mechanism for psycholinguistic research."}}
{"id": "2507.22082", "pdf": "https://arxiv.org/pdf/2507.22082", "abs": "https://arxiv.org/abs/2507.22082", "authors": ["Anuraj Maurya"], "title": "Shape Invariant 3D-Variational Autoencoder: Super Resolution in Turbulence flow", "categories": ["cs.LG", "cs.AI", "physics.flu-dyn"], "comment": null, "summary": "Deep learning provides a versatile suite of methods for extracting structured\ninformation from complex datasets, enabling deeper understanding of underlying\nfluid dynamic phenomena. The field of turbulence modeling, in particular,\nbenefits from the growing availability of high-dimensional data obtained\nthrough experiments, field observations, and large-scale simulations spanning\nmultiple spatio-temporal scales. This report presents a concise overview of\nboth classical and deep learningbased approaches to turbulence modeling. It\nfurther investigates two specific challenges at the intersection of fluid\ndynamics and machine learning: the integration of multiscale turbulence models\nwith deep learning architectures, and the application of deep generative models\nfor super-resolution reconstruction", "AI": {"tldr": "The paper discusses how deep learning enhances turbulence modeling by addressing challenges in multiscale integration and super-resolution tasks.", "motivation": "To leverage deep learning for understanding and modeling turbulence using high-dimensional data from experiments, observations, and simulations.", "method": "The paper reviews classical and deep learning approaches to turbulence modeling, focusing on multiscale integration and deep generative model application.", "result": "The paper identifies advancements and challenges in applying deep learning, specifically with multiscale models and super-resolution reconstruction.", "conclusion": "Deep learning serves as a valuable tool for turbulence modeling, unlocking new insights and addressing computational challenges in fluid dynamics."}}
{"id": "2507.22358", "pdf": "https://arxiv.org/pdf/2507.22358", "abs": "https://arxiv.org/abs/2507.22358", "authors": ["Hussein Mozannar", "Gagan Bansal", "Cheng Tan", "Adam Fourney", "Victor Dibia", "Jingya Chen", "Jack Gerrits", "Tyler Payne", "Matheus Kunzler Maldaner", "Madeleine Grunde-McLaughlin", "Eric Zhu", "Griffin Bassman", "Jacob Alber", "Peter Chang", "Ricky Loynd", "Friederike Niedtner", "Ece Kamar", "Maya Murad", "Rafah Hosn", "Saleema Amershi"], "title": "Magentic-UI: Towards Human-in-the-loop Agentic Systems", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "AI agents powered by large language models are increasingly capable of\nautonomously completing complex, multi-step tasks using external tools. Yet,\nthey still fall short of human-level performance in most domains including\ncomputer use, software development, and research. Their growing autonomy and\nability to interact with the outside world, also introduces safety and security\nrisks including potentially misaligned actions and adversarial manipulation. We\nargue that human-in-the-loop agentic systems offer a promising path forward,\ncombining human oversight and control with AI efficiency to unlock productivity\nfrom imperfect systems. We introduce Magentic-UI, an open-source web interface\nfor developing and studying human-agent interaction. Built on a flexible\nmulti-agent architecture, Magentic-UI supports web browsing, code execution,\nand file manipulation, and can be extended with diverse tools via Model Context\nProtocol (MCP). Moreover, Magentic-UI presents six interaction mechanisms for\nenabling effective, low-cost human involvement: co-planning, co-tasking,\nmulti-tasking, action guards, and long-term memory. We evaluate Magentic-UI\nacross four dimensions: autonomous task completion on agentic benchmarks,\nsimulated user testing of its interaction capabilities, qualitative studies\nwith real users, and targeted safety assessments. Our findings highlight\nMagentic-UI's potential to advance safe and efficient human-agent\ncollaboration.", "AI": {"tldr": "Magentic-UI is a human-centered system combining AI agents and user oversight for safer, efficient task execution and collaboration.", "motivation": "To address the limitations and risks of autonomous AI agents, including inefficiencies and safety issues in performing complex multi-step tasks.", "method": "Developing Magentic-UI, a flexible open-source interface allowing human-AI collaboration through interaction mechanisms such as co-planning and action guards.", "result": "Magentic-UI demonstrates improved human-AI collaboration via evaluations on task benchmarks, simulated and real user testing, and safety assessments.", "conclusion": "Human-controlled AI systems like Magentic-UI offer a promising solution for advancing safe, efficient collaboration between humans and AI agents."}}
{"id": "2507.22152", "pdf": "https://arxiv.org/pdf/2507.22152", "abs": "https://arxiv.org/abs/2507.22152", "authors": ["A. Piffer", "J. A. Buchner", "A. G. Gennari", "P. Grehten", "S. Sirin", "E. Ross", "I. Ezhov", "M. Rosier", "J. C. Peeken", "M. Piraud", "B. Menze", "A. Guerreiro St\u00fccklin", "A. Jakab", "F. Kofler"], "title": "Enhancing efficiency in paediatric brain tumour segmentation using a pathologically diverse single-center clinical dataset", "categories": ["cs.CV", "physics.med-ph"], "comment": "A. Jakab and F. Kofler have shared last authorship", "summary": "Background Brain tumours are the most common solid malignancies in children,\nencompassing diverse histological, molecular subtypes and imaging features and\noutcomes. Paediatric brain tumours (PBTs), including high- and low-grade\ngliomas (HGG, LGG), medulloblastomas (MB), ependymomas, and rarer forms, pose\ndiagnostic and therapeutic challenges. Deep learning (DL)-based segmentation\noffers promising tools for tumour delineation, yet its performance across\nheterogeneous PBT subtypes and MRI protocols remains uncertain. Methods A\nretrospective single-centre cohort of 174 paediatric patients with HGG, LGG,\nmedulloblastomas (MB), ependymomas, and other rarer subtypes was used. MRI\nsequences included T1, T1 post-contrast (T1-C), T2, and FLAIR. Manual\nannotations were provided for four tumour subregions: whole tumour (WT),\nT2-hyperintensity (T2H), enhancing tumour (ET), and cystic component (CC). A 3D\nnnU-Net model was trained and tested (121/53 split), with segmentation\nperformance assessed using the Dice similarity coefficient (DSC) and compared\nagainst intra- and inter-rater variability. Results The model achieved robust\nperformance for WT and T2H (mean DSC: 0.85), comparable to human annotator\nvariability (mean DSC: 0.86). ET segmentation was moderately accurate (mean\nDSC: 0.75), while CC performance was poor. Segmentation accuracy varied by\ntumour type, MRI sequence combination, and location. Notably, T1, T1-C, and T2\nalone produced results nearly equivalent to the full protocol. Conclusions DL\nis feasible for PBTs, particularly for T2H and WT. Challenges remain for ET and\nCC segmentation, highlighting the need for further refinement. These findings\nsupport the potential for protocol simplification and automation to enhance\nvolumetric assessment and streamline paediatric neuro-oncology workflows.", "AI": {"tldr": "This paper evaluates the use of a 3D nnU-Net deep learning model for segmenting paediatric brain tumours (PBTs) in MRI scans. The model achieves strong performance for certain tumour regions but struggles with others, suggesting the need for further refinement and potential simplification of MRI protocols.", "motivation": "To address the diagnostic and therapeutic challenges of paediatric brain tumours and evaluate the robustness of deep learning (DL)-based segmentation methods across various tumour subtypes and MRI protocols.", "method": "A retrospective study involving 174 paediatric patients and MRI scans. A 3D nnU-Net deep learning model was trained on annotated tumour subregions and evaluated using the Dice similarity coefficient (DSC) against human annotators.", "result": "The DL model performed well for whole tumour (WT) and T2-hyperintensity (T2H) regions (mean DSC: 0.85), moderately for enhancing tumour (ET) (mean DSC: 0.75), and poorly for cystic components (CC). Its performance varies by tumour type and MRI sequence, and a simplified protocol delivered near-equivalent results to a full protocol.", "conclusion": "Deep learning shows promise for PBT segmentation, especially for certain tumour subregions. Limitations in ET and CC segmentation highlight the need for further model refinement. Simplifying MRI protocols could streamline workflows in paediatric neuro-oncology."}}
{"id": "2507.22842", "pdf": "https://arxiv.org/pdf/2507.22842", "abs": "https://arxiv.org/abs/2507.22842", "authors": ["Biyi Fang", "Jean Utke", "Truong Vo", "Diego Klabjan"], "title": "Subgrid BoostCNN: Efficient Boosting of Convolutional Networks via Gradient-Guided Feature Selection", "categories": ["stat.ML", "cs.LG", "68T05, 68T45", "I.2.6; I.5.1; I.2.10"], "comment": "10 pages, 5 figures. Experimental results reported on CIFAR-10, SVHN,\n  and ImageNetSub datasets. arXiv admin note: substantial text overlap with\n  arXiv:2203.00761", "summary": "Convolutional Neural Networks (CNNs) have achieved remarkable success across\na wide range of machine learning tasks by leveraging hierarchical feature\nlearning through deep architectures. However, the large number of layers and\nmillions of parameters often make CNNs computationally expensive to train,\nrequiring extensive time and manual tuning to discover optimal architectures.\nIn this paper, we introduce a novel framework for boosting CNN performance that\nintegrates dynamic feature selection with the principles of BoostCNN. Our\napproach incorporates two key strategies: subgrid selection and importance\nsampling, to guide training toward informative regions of the feature space. We\nfurther develop a family of algorithms that embed boosting weights directly\ninto the network training process using a least squares loss formulation. This\nintegration not only alleviates the burden of manual architecture design but\nalso enhances accuracy and efficiency. Experimental results across several\nfine-grained classification benchmarks demonstrate that our boosted CNN\nvariants consistently outperform conventional CNNs in both predictive\nperformance and training speed.", "AI": {"tldr": "The paper proposes a framework, BoostCNN, that enhances CNN performance through dynamic feature selection and boosting weights.", "motivation": "Conventional CNNs require extensive time and manual effort due to their deep architectures and computational expense, limiting efficiency.", "method": "A novel framework using dynamic feature selection with subgrid selection, importance sampling, and embedding boosting weights via least squares loss formulation.", "result": "Boosted CNN variants surpass traditional CNNs in predictive accuracy and training speed across numerous classification benchmarks.", "conclusion": "The integration of dynamic selection and boosting effectively reduces manual design complexity while improving efficiency and performance."}}
{"id": "2507.22389", "pdf": "https://arxiv.org/pdf/2507.22389", "abs": "https://arxiv.org/abs/2507.22389", "authors": ["Kaustav Chakraborty", "Zeyuan Feng", "Sushant Veer", "Apoorva Sharma", "Wenhao Ding", "Sever Topan", "Boris Ivanovic", "Marco Pavone", "Somil Bansal"], "title": "Safety Evaluation of Motion Plans Using Trajectory Predictors as Forward Reachable Set Estimators", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "The advent of end-to-end autonomy stacks - often lacking interpretable\nintermediate modules - has placed an increased burden on ensuring that the\nfinal output, i.e., the motion plan, is safe in order to validate the safety of\nthe entire stack. This requires a safety monitor that is both complete (able to\ndetect all unsafe plans) and sound (does not flag safe plans). In this work, we\npropose a principled safety monitor that leverages modern multi-modal\ntrajectory predictors to approximate forward reachable sets (FRS) of\nsurrounding agents. By formulating a convex program, we efficiently extract\nthese data-driven FRSs directly from the predicted state distributions,\nconditioned on scene context such as lane topology and agent history. To ensure\ncompleteness, we leverage conformal prediction to calibrate the FRS and\nguarantee coverage of ground-truth trajectories with high probability. To\npreserve soundness in out-of-distribution (OOD) scenarios or under predictor\nfailure, we introduce a Bayesian filter that dynamically adjusts the FRS\nconservativeness based on the predictor's observed performance. We then assess\nthe safety of the ego vehicle's motion plan by checking for intersections with\nthese calibrated FRSs, ensuring the plan remains collision-free under plausible\nfuture behaviors of others. Extensive experiments on the nuScenes dataset show\nour approach significantly improves soundness while maintaining completeness,\noffering a practical and reliable safety monitor for learned autonomy stacks.", "AI": {"tldr": "This paper introduces a safety monitor for autonomous systems by leveraging trajectory predictors to ensure the motion plan is collision-free and safe.", "motivation": "Ensuring the safety of end-to-end autonomy stacks, which lack interpretable intermediate modules, requires a reliable safety monitor to validate their outputs.", "method": "The method involves approximating forward reachable sets (FRS) using trajectory predictors, using conformal prediction for calibration, and employing a Bayesian filter for dynamic adjustments in out-of-distribution scenarios.", "result": "Experiments on the nuScenes dataset demonstrate significant improvements in ensuring both the soundness and completeness of the safety monitoring system.", "conclusion": "The proposed approach provides a practical and reliable safety monitoring method for autonomous systems, ensuring safety through enhanced prediction and calibration methods."}}
{"id": "2507.22801", "pdf": "https://arxiv.org/pdf/2507.22801", "abs": "https://arxiv.org/abs/2507.22801", "authors": ["Shubhradeep Roy", "Suvarthi Sarkar", "Vivek Verma", "Aryabartta Sahu"], "title": "DSPE: Profit Maximization in Edge-Cloud Storage System using Dynamic Space Partitioning with Erasure Code", "categories": ["cs.DC"], "comment": null, "summary": "Edge Storage Systems have emerged as a critical enabler of low latency data\naccess in modern cloud networks by bringing storage and computation closer to\nend users. However, the limited storage capacity of edge servers poses\nsignificant challenges in handling high volume and latency sensitive data\naccess requests, particularly under dynamic workloads. In this work, we propose\na profit driven framework that integrates three key mechanisms which are\ncollaborative caching, erasure coding, and elastic storage partitioning. Unlike\ntraditional replication, erasure coding enables space efficient redundancy,\nallowing data to be reconstructed from any subset of K out of K plus M coded\nblocks. We dynamically partition each edge server s storage into private and\npublic regions. The private region is further subdivided among access points\nbased on their incoming request rates, enabling adaptive control over data\nlocality and ownership. We design a data placement and replacement policy that\ndetermines how and where to store or evict coded data blocks to maximize data\naccess within deadlines. While the private region serves requests from local\nAPs, the public region handles cooperative storage requests from neighboring\nservers. Our proposed Dynamic Space Partitioning and Elastic caching strategy\nis evaluated on both synthetic and real world traces from Netflix and Spotify.\nExperimental results show that our method improves overall system profitability\nby approximately 5 to 8% compared to state of the art approaches under varied\nworkload conditions.", "AI": {"tldr": "This paper proposes a profit-driven framework using collaborative caching, erasure coding, and elastic storage partitioning to improve data access in edge storage systems under dynamic workloads.", "motivation": "Edge storage's limited capacity complicates handling high volumes of latency-sensitive requests in dynamic cloud environments.", "method": "The paper combines collaborative caching, erasure coding, and dynamic private/public partitioning with adaptive data placement and replacement policies.", "result": "Dynamic Space Partitioning and Elastic caching improves system profitability by 5-8%, tested on synthetic and real-world traces.", "conclusion": "The proposed method enhances edge storage system efficiency under variable workloads, outperforming state-of-the-art approaches."}}
{"id": "2507.22219", "pdf": "https://arxiv.org/pdf/2507.22219", "abs": "https://arxiv.org/abs/2507.22219", "authors": ["Dongyub Jude Lee", "Zhenyi Ye", "Pengcheng He"], "title": "RL from Teacher-Model Refinement: Gradual Imitation Learning for Machine Translation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Preference-learning methods for machine translation (MT)--such as Direct\nPreference Optimization (DPO)--have achieved impressive gains but depend\nheavily on large, carefully curated triplet datasets and often struggle to\ngeneralize beyond their tuning domains. We propose Reinforcement Learning from\nTeacher-Model Refinement (RLfR), a novel framework that removes reliance on\nstatic triplets by leveraging continuous, high-quality feedback from an\nexternal teacher model (GPT-4o). RLfR frames each translation step as a\nmicro-tutorial: the actor generates a hypothesis, the teacher refines it, and\nthe actor is rewarded based on how closely it aligns with the teacher's\nrefinement. Guided by two complementary signals--(i) negative edit distance,\npromoting lexical and structural fidelity, and (ii) COMET score, ensuring\nsemantic adequacy--the actor progressively learns to emulate the teacher,\nmirroring a human learning process through incremental, iterative improvement.\nOn the FLORES-200 benchmark (English to and from German, Spanish, Chinese,\nKorean, and Japanese), RLfR consistently outperforms both MT-SFT and\npreference-based baselines, significantly improving COMET (semantic adequacy)\nand M-ETA (entity preservation) scores.", "AI": {"tldr": "This paper proposes RLfR, an innovative machine translation method that replaces static datasets with dynamic feedback from a teacher model (GPT-4) to achieve superior translation quality.", "motivation": "Current preference-learning methods heavily rely on static, curated datasets and struggle to generalize when applied outside tuning domains.", "method": "The paper introduces RLfR, where a teacher model refines translations and provides rewards based on alignment with its improvement, using edit distance and COMET scores as learning signals.", "result": "Experimental results on the FLORES-200 benchmark show RLfR surpasses common baselines (MT-SFT and preference-based approaches) by improving COMET and M-ETA scores.", "conclusion": "RLfR demonstrates how leveraging dynamic teacher feedback can enhance translation quality while mimicking human-like incremental learning."}}
{"id": "2507.22089", "pdf": "https://arxiv.org/pdf/2507.22089", "abs": "https://arxiv.org/abs/2507.22089", "authors": ["Harsh Nilesh Pathak", "Randy Paffenroth"], "title": "Principled Curriculum Learning using Parameter Continuation Methods", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this work, we propose a parameter continuation method for the optimization\nof neural networks. There is a close connection between parameter continuation,\nhomotopies, and curriculum learning. The methods we propose here are\ntheoretically justified and practically effective for several problems in deep\nneural networks. In particular, we demonstrate better generalization\nperformance than state-of-the-art optimization techniques such as ADAM for\nsupervised and unsupervised learning tasks.", "AI": {"tldr": "The paper introduces a parameter continuation method to optimize neural networks for improved generalization, outperforming ADAM.", "motivation": "To explore optimization alternatives for neural networks that achieve better generalization and performance than existing methods such as ADAM.", "method": "Developing and applying a parameter continuation technique, which builds on principles of homotopies and curriculum learning.", "result": "The proposed method demonstrates superior generalization performance compared to ADAM in supervised and unsupervised learning tasks.", "conclusion": "Parameter continuation methods offer both theoretical validity and practical advantages in neural network optimization, marking an improvement over traditional methods."}}
{"id": "2507.22359", "pdf": "https://arxiv.org/pdf/2507.22359", "abs": "https://arxiv.org/abs/2507.22359", "authors": ["Qianhong Guo", "Wei Xie", "Xiaofang Cai", "Enze Wang", "Shuoyoucheng Ma", "Kai Chen", "Xiaofeng Wang", "Baosheng Wang"], "title": "LLM-Crowdsourced: A Benchmark-Free Paradigm for Mutual Evaluation of Large Language Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Although large language models (LLMs) demonstrate remarkable capabilities\nacross various tasks, evaluating their capabilities remains a challenging task.\nExisting evaluation methods suffer from issues such as data contamination,\nblack-box operation, and subjective preference. These issues make it difficult\nto evaluate the LLMs' true capabilities comprehensively. To tackle these\nchallenges, we propose a novel benchmark-free evaluation paradigm,\nLLM-Crowdsourced. It utilizes LLMs to generate questions, answer independently,\nand evaluate mutually. This method integrates four key evaluation criteria:\ndynamic, transparent, objective, and professional, which existing evaluation\nmethods cannot satisfy simultaneously. Experiments on eight mainstream LLMs\nacross mathematics and programming verify the advantages of our method in\ndistinguishing LLM performance. Furthermore, our study reveals several novel\nfindings that are difficult for traditional methods to detect, including but\nnot limited to: (1) Gemini demonstrates the highest original and professional\nquestion-design capabilities among others; (2) Some LLMs exhibit\n''memorization-based answering'' by misrecognizing questions as familiar ones\nwith a similar structure; (3) LLM evaluation results demonstrate high\nconsistency (robustness).", "AI": {"tldr": "This paper proposes a new benchmark-free evaluation method for large language models (LLMs) by crowdsourcing their capabilities to assess themselves, addressing current evaluation challenges like data contamination, subjectivity, and black-box issues.", "motivation": "Existing methods for evaluating LLMs face difficulties such as lack of comprehensive benchmarks and issues like data contamination and subjectivity, preventing fair assessment.", "method": "The authors designed an evaluation paradigm called LLM-Crowdsourced, where LLMs generate, answer, and evaluate questions independently using criteria like transparency, objectivity, and professionalism.", "result": "The method was tested on eight major LLMs for mathematics and programming tasks, showing its effectiveness in distinguishing LLM performances while detecting unique behaviors like memorization-based answering.", "conclusion": "The LLM-Crowdsourced evaluation paradigm is dynamic, transparent, and objective, making it superior to traditional evaluation methods while highlighting novel findings about LLM behaviors."}}
{"id": "2507.22071", "pdf": "https://arxiv.org/pdf/2507.22071", "abs": "https://arxiv.org/abs/2507.22071", "authors": ["Niels Glodny"], "title": "Analyzing and Evaluating the Behavior of Git Diff and Merge", "categories": ["cs.SE"], "comment": "Bachelor's thesis", "summary": "Despite being widely used, the algorithms that enable collaboration with Git\nare not well understood. The diff and merge algorithms are particularly\ninteresting, as they could be applied in other contexts. In this thesis, I\ndocument the main functionalities of Git: how diffs are computed, how they are\nused to run merges, and how merges enable more complex operations. In the\nprocess, I show multiple unexpected behaviors in Git, including the following:\nThe histogram diff algorithm has pathological cases where a single-line change\ncan cause the entire rest of the file to be marked as changed. The default\nmerge strategy (ort) can result in merges requiring exponential time in the\nnumber of commits in the history. Merges and rebases are not commutative, and\neven when merges do not result in a conflict, the result is not specified but\ndepends on the diff algorithm used. And finally, sometimes when two sides of a\nmerge add different lines at the same position, the result is not a conflict,\nbut a merge containing both changes after each other, in arbitrary order.", "AI": {"tldr": "The paper examines Git's diff and merge algorithms, discovering unexpected behaviors like pathological cases and unpredictable merge outcomes.", "motivation": "Understanding Git's diff and merge algorithms to document their key functionalities and nuances for potential broader applications.", "method": "The paper investigates Git's diff computation, merge operations, and complex functionalities through systematic analysis.", "result": "It highlights behaviors like the histogram diff algorithm's sensitivity, exponential runtime in some merge strategies, and non-commutative operations leading to unpredictable outcomes.", "conclusion": "Git's diff and merge mechanisms have quirks and non-standard behaviors that need deeper comprehension for effective use and adaptation."}}
{"id": "2507.22194", "pdf": "https://arxiv.org/pdf/2507.22194", "abs": "https://arxiv.org/abs/2507.22194", "authors": ["Christian Ellis", "Maggie Wigness", "Craig Lennon", "Lance Fiondella"], "title": "Temporally Consistent Unsupervised Segmentation for Mobile Robot Perception", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Rapid progress in terrain-aware autonomous ground navigation has been driven\nby advances in supervised semantic segmentation. However, these methods rely on\ncostly data collection and labor-intensive ground truth labeling to train deep\nmodels. Furthermore, autonomous systems are increasingly deployed in\nunrehearsed, unstructured environments where no labeled data exists and\nsemantic categories may be ambiguous or domain-specific. Recent zero-shot\napproaches to unsupervised segmentation have shown promise in such settings but\ntypically operate on individual frames, lacking temporal consistency-a critical\nproperty for robust perception in unstructured environments. To address this\ngap we introduce Frontier-Seg, a method for temporally consistent unsupervised\nsegmentation of terrain from mobile robot video streams. Frontier-Seg clusters\nsuperpixel-level features extracted from foundation model\nbackbones-specifically DINOv2-and enforces temporal consistency across frames\nto identify persistent terrain boundaries or frontiers without human\nsupervision. We evaluate Frontier-Seg on a diverse set of benchmark\ndatasets-including RUGD and RELLIS-3D-demonstrating its ability to perform\nunsupervised segmentation across unstructured off-road environments.", "AI": {"tldr": "This paper introduces Frontier-Seg, an unsupervised segmentation method for terrain-aware navigation that ensures temporal consistency using mobile robot video streams.", "motivation": "Current autonomous navigation systems rely on supervised models requiring costly data labeling, making them infeasible for dynamic, unstructured environments without labeled data.", "method": "They use features extracted from DINOv2 backbones and introduce a clustering technique combined with temporal consistency enforcement to identify terrain boundaries across video frames.", "result": "Frontier-Seg's performance is validated on benchmark datasets like RUGD and RELLIS-3D, showing effective unsupervised segmentation in unstructured off-road scenarios.", "conclusion": "Frontier-Seg successfully addresses the challenge of unsupervised terrain segmentation in dynamic environments, reducing reliance on manually labeled data and improving real-world applicability."}}
{"id": "2507.22877", "pdf": "https://arxiv.org/pdf/2507.22877", "abs": "https://arxiv.org/abs/2507.22877", "authors": ["Daniel Claborne", "Javier Flores", "Samantha Erwin", "Luke Durell", "Rachel Richardson", "Ruby Fore", "Lisa Bramer"], "title": "Consistency of Feature Attribution in Deep Learning Architectures for Multi-Omics", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Machine and deep learning have grown in popularity and use in biological\nresearch over the last decade but still present challenges in interpretability\nof the fitted model. The development and use of metrics to determine features\ndriving predictions and increase model interpretability continues to be an open\narea of research. We investigate the use of Shapley Additive Explanations\n(SHAP) on a multi-view deep learning model applied to multi-omics data for the\npurposes of identifying biomolecules of interest. Rankings of features via\nthese attribution methods are compared across various architectures to evaluate\nconsistency of the method. We perform multiple computational experiments to\nassess the robustness of SHAP and investigate modeling approaches and\ndiagnostics to increase and measure the reliability of the identification of\nimportant features. Accuracy of a random-forest model fit on subsets of\nfeatures selected as being most influential as well as clustering quality using\nonly these features are used as a measure of effectiveness of the attribution\nmethod. Our findings indicate that the rankings of features resulting from SHAP\nare sensitive to the choice of architecture as well as different random\ninitializations of weights, suggesting caution when using attribution methods\non multi-view deep learning models applied to multi-omics data. We present an\nalternative, simple method to assess the robustness of identification of\nimportant biomolecules.", "AI": {"tldr": "This paper explores the use of Shapley Additive Explanations (SHAP) in multi-view deep learning models applied to multi-omics data for feature attribution but finds sensitivity in feature rankings due to factors like architecture and random initialization.", "motivation": "To address challenges in interpretability of machine and deep learning models in biological research, particularly for identifying key biomolecules in multi-omics data analysis.", "method": "The authors used SHAP on multi-view deep learning models to rank features and compared these rankings across architectures. They conducted computational experiments to evaluate SHAP's robustness and effectiveness using metrics like random forest accuracy and clustering quality.", "result": "The study found that SHAP's feature rankings are sensitive to the choice of model architecture and random weight initializations, raising concerns about the method's reliability in this context.", "conclusion": "While SHAP offers potential for feature attribution in complex models, its sensitivity to architectural variations demands caution. An alternative, simpler method for robustness assessment is presented."}}
{"id": "2507.22429", "pdf": "https://arxiv.org/pdf/2507.22429", "abs": "https://arxiv.org/abs/2507.22429", "authors": ["Erwin de Gelder", "Maren Buermann", "Olaf Op den Camp"], "title": "Comparing Normalizing Flows with Kernel Density Estimation in Estimating Risk of Automated Driving Systems", "categories": ["cs.RO", "cs.LG"], "comment": "Accepted for publication in proceedings of the 2025 IEEE\n  International Automated Vehicle Validation Conference", "summary": "The development of safety validation methods is essential for the safe\ndeployment and operation of Automated Driving Systems (ADSs). One of the goals\nof safety validation is to prospectively evaluate the risk of an ADS dealing\nwith real-world traffic. Scenario-based assessment is a widely-used approach,\nwhere test cases are derived from real-world driving data. To allow for a\nquantitative analysis of the system performance, the exposure of the scenarios\nmust be accurately estimated. The exposure of scenarios at parameter level is\nexpressed using a Probability Density Function (PDF). However, assumptions\nabout the PDF, such as parameter independence, can introduce errors, while\navoiding assumptions often leads to oversimplified models with limited\nparameters to mitigate the curse of dimensionality.\n  This paper considers the use of Normalizing Flows (NF) for estimating the PDF\nof the parameters. NF are a class of generative models that transform a simple\nbase distribution into a complex one using a sequence of invertible and\ndifferentiable mappings, enabling flexible, high-dimensional density estimation\nwithout restrictive assumptions on the PDF's shape. We demonstrate the\neffectiveness of NF in quantifying risk and risk uncertainty of an ADS,\ncomparing its performance with Kernel Density Estimation (KDE), a traditional\nmethod for non-parametric PDF estimation. While NF require more computational\nresources compared to KDE, NF is less sensitive to the curse of dimensionality.\nAs a result, NF can improve risk uncertainty estimation, offering a more\nprecise assessment of an ADS's safety.\n  This work illustrates the potential of NF in scenario-based safety. Future\nwork involves experimenting more with using NF for scenario generation and\noptimizing the NF architecture, transformation types, and training\nhyperparameters to further enhance their applicability.", "AI": {"tldr": "The paper explores the use of Normalizing Flows (NF) for estimating scenario exposure in safety validation of Automated Driving Systems (ADSs), showing improved accuracy compared to traditional kernel methods.", "motivation": "To improve the quantification of risk and risk uncertainty in Automated Driving Systems (ADS) by overcoming limitations of current methods for estimating scenario exposure from real-world driving data.", "method": "The authors propose using Normalizing Flows (NF), a type of generative model, for estimating the Probability Density Function (PDF) of scenario parameters. These models provide flexible, high-dimensional density estimation without restrictive assumptions about PDF shape.", "result": "NF showed improved performance over Kernel Density Estimation (KDE) in handling high-dimensional data, reducing the impact of dimensionality, and providing more accurate risk assessments for ADS.", "conclusion": "The study highlights the potential of NF in enhancing safety validation of ADSs by improving risk uncertainty estimation. Future work will explore further NF optimizations for scenario generation and parameter estimation."}}
{"id": "2507.19802", "pdf": "https://arxiv.org/pdf/2507.19802", "abs": "https://arxiv.org/abs/2507.19802", "authors": ["Ziyu Zhang", "Yuanhao Wei", "Joshua Engels", "Julian Shun"], "title": "CleANN: Efficient Full Dynamism in Graph-based Approximate Nearest Neighbor Search", "categories": ["cs.DB", "cs.DC", "cs.DS", "cs.IR"], "comment": null, "summary": "Approximate nearest neighbor search (ANNS) has become a quintessential\nalgorithmic problem for various other foundational data tasks for AI workloads.\nGraph-based ANNS indexes have superb empirical trade-offs in indexing cost,\nquery efficiency, and query approximation quality. Most existing graph-based\nindexes are designed for the static scenario, where there are no updates to the\ndata after the index is constructed. However, full dynamism (insertions,\ndeletions, and searches) is crucial to providing up-to-date responses in\napplications using vector databases. It is desirable that the index efficiently\nsupports updates and search queries concurrently. Existing dynamic graph-based\nindexes suffer from at least one of the following problems: (1) the query\nquality degrades as updates happen; and (2) the graph structure updates used to\nmaintain the index quality upon updates are global and thus expensive. To solve\nthese problems, we propose the CleANN system which consists of three main\ncomponents: (1) workload-aware linking of diverse search tree descendants to\ncombat distribution shift; (2)query-adaptive on-the-fly neighborhood\nconsolidation to efficiently handle deleted nodes; and (3) semi-lazy memory\ncleaning to clean up stale information in the data structure and reduce the\nwork spent by the first two components. We evaluate CleANN on 7 diverse\ndatasets on fully dynamic workloads and find that CleANN has query quality at\nleast as good as if the index had been built statically using the corresponding\ndata. In the in-memory setting using 56 hyper-threads, with all types of\nqueries running concurrently, at the same recall level, CleANN achieves 7-1200x\nthroughput improvement on million-scale real-world datasets. To the best of our\nknowledge, CleANN is the first concurrent ANNS index to achieve such efficiency\nwhile maintaining quality under full dynamism.", "AI": {"tldr": "The paper proposes CleANN, a novel dynamic graph-based approximate nearest neighbor search (ANNS) system. CleANN maintains high-quality query results efficiently despite concurrent insertions, deletions, and searches.", "motivation": "Dynamic ANNS systems are needed for applications requiring up-to-date responses. Existing methods suffer either from degraded query quality or expensive global updates.", "method": "CleANN integrates three components: workload-aware linking, query-adaptive neighborhood consolidation, and semi-lazy memory cleaning.", "result": "In tests on 7 diverse datasets, CleANN maintained query quality comparable to static indexes while achieving dramatically improved throughput (7-1200x) under fully dynamic workloads.", "conclusion": "CleANN represents a breakthrough in dynamic ANNS indexes, achieving high efficiency and query quality in concurrent and fully dynamic environments."}}
{"id": "2507.22286", "pdf": "https://arxiv.org/pdf/2507.22286", "abs": "https://arxiv.org/abs/2507.22286", "authors": ["Supantho Rakshit", "Adele Goldberg"], "title": "Meaning-infused grammar: Gradient Acceptability Shapes the Geometric Representations of Constructions in LLMs", "categories": ["cs.CL", "cs.AI", "68T50"], "comment": "5 pages, 3 figures, Accepted for publication at the Second\n  International Workshop on Construction Grammars and NLP at the 16th\n  International Conference for Computational Semantics (IWCS) 2025", "summary": "The usage-based constructionist (UCx) approach posits that language comprises\na network of learned form-meaning pairings (constructions) whose use is largely\ndetermined by their meanings or functions, requiring them to be graded and\nprobabilistic. This study investigates whether the internal representations in\nLarge Language Models (LLMs) reflect the proposed function-infused gradience.\nWe analyze the neural representations of the English dative constructions\n(Double Object and Prepositional Object) in Pythia-$1.4$B, using a dataset of\n$5000$ sentence pairs systematically varied for human-rated preference\nstrength. A macro-level geometric analysis finds that the separability between\nconstruction representations, as measured by Energy Distance or Jensen-Shannon\nDivergence, is systematically modulated by gradient preference strength. More\nprototypical exemplars of each construction occupy more distinct regions in the\nactivation space of LLMs. These results provide strong evidence that LLMs learn\nrich, meaning-infused, graded representations of constructions and offer\nsupport for geometric measures of basic constructionist principles in LLMs.", "AI": {"tldr": "This study evaluates whether Large Language Models (LLMs) capture meaning-based gradients in language, focusing on English dative constructions. The analysis reveals that LLMs possess gradient, meaningful representations of constructions.", "motivation": "Language is composed of constructions with meanings that guide their usage. The study aims to determine if LLMs represent these meaning-based, graded structures similarly to human cognition.", "method": "Using the English dative constructions, the neural representations in the Pythia-1.4B LLM were analyzed through geometric measures like Energy Distance and Jensen-Shannon Divergence based on a dataset of 5000 systematically varied sentences.", "result": "The analysis shows that LLMs encode constructions in a way modulated by preference strength, with more prototypical exemplars having more distinct neural representations in activation space.", "conclusion": "LLMs exhibit rich, graded, meaning-infused representations of linguistic constructions, and geometric measures can quantify constructionist principles in LLMs."}}
{"id": "2507.22365", "pdf": "https://arxiv.org/pdf/2507.22365", "abs": "https://arxiv.org/abs/2507.22365", "authors": ["ZhaoBin Li", "Mark Steyvers"], "title": "Beyond Accuracy: How AI Metacognitive Sensitivity improves AI-assisted Decision Making", "categories": ["cs.AI", "cs.HC"], "comment": "26 pages, 5 figures, submitted to Decision Analysis", "summary": "In settings where human decision-making relies on AI input, both the\npredictive accuracy of the AI system and the reliability of its confidence\nestimates influence decision quality. We highlight the role of AI metacognitive\nsensitivity -- its ability to assign confidence scores that accurately\ndistinguish correct from incorrect predictions -- and introduce a theoretical\nframework for assessing the joint impact of AI's predictive accuracy and\nmetacognitive sensitivity in hybrid decision-making settings. Our analysis\nidentifies conditions under which an AI with lower predictive accuracy but\nhigher metacognitive sensitivity can enhance the overall accuracy of human\ndecision making. Finally, a behavioral experiment confirms that greater AI\nmetacognitive sensitivity improves human decision performance. Together, these\nfindings underscore the importance of evaluating AI assistance not only by\naccuracy but also by metacognitive sensitivity, and of optimizing both to\nachieve superior decision outcomes.", "AI": {"tldr": "This paper emphasizes the importance of AI's metacognitive sensitivity, i.e., its accurate confidence assessments, in improving human decision-making in addition to its predictive accuracy.", "motivation": "The paper seeks to understand how AI confidence estimates, alongside its predictive accuracy, impact human decision-making quality in hybrid AI-human systems.", "method": "Introduces a theoretical framework, identifies conditions influencing AI-human joint decision accuracy, and validates findings through a behavioral experiment.", "result": "Finds that higher AI metacognitive sensitivity, even in scenarios with lower predictive accuracy, can enhance human decision-making performance.", "conclusion": "AI assistance is best evaluated and optimized by both predictive accuracy and metacognitive sensitivity to improve decision outcomes."}}
{"id": "2507.22080", "pdf": "https://arxiv.org/pdf/2507.22080", "abs": "https://arxiv.org/abs/2507.22080", "authors": ["Qiushi Sun", "Jinyang Gong", "Lei Li", "Qipeng Guo", "Fei Yuan"], "title": "CodeEvo: Interaction-Driven Synthesis of Code-centric Data through Hybrid and Iterative Feedback", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": "Work in progress", "summary": "Acquiring high-quality instruction-code pairs is essential for training Large\nLanguage Models (LLMs) for code generation. Manually curated data is expensive\nand inherently limited in scale, motivating the development of code-centric\nsynthesis methods. Yet, current approaches either focus on augmenting existing\ncode or rely on predefined heuristics, both lacking rigorous data validation,\nwhich results in synthetic data that is ungrounded, repetitive, or overly\nsimplistic. Inspired by collaborative programming practices, we propose\nCodeEvo, a framework that synthesizes code data through iterative interactions\nbetween two LLM agents: a Coder, which generates candidate code and test cases\nbased on given instructions, and a Reviewer, which guides the synthesis process\nby producing new instructions and feedback. We further introduce a hybrid\nfeedback mechanism that combines compiler determinism with the generative\nflexibility of agents, enabling automatic quality control throughout synthesis.\nExtensive experiments demonstrate that models fine-tuned on CodeEvo data\nsignificantly outperform established baselines across code generation\nbenchmarks with various difficulties. In-depth analyses further provide\ninsights from multiple perspectives into effective code-centric data synthesis.", "AI": {"tldr": "CodeEvo proposes a novel framework using iterative interactions between LLM agents to enhance the quality and effectiveness of instruction-code pair generation for training code generation models.", "motivation": "The paper aims to address the issues of limited scale and low quality in manually curated and existing synthetic instruction-code pair datasets for training Large Language Models (LLMs) for code generation.", "method": "CodeEvo leverages two LLM agents\u2014a Coder and a Reviewer\u2014that interact iteratively to produce and refine code and instructions. It introduces a hybrid feedback mechanism combining compiler determinism with agent generative flexibility for improving quality control.", "result": "Models trained on CodeEvo data achieve significant performance improvements over established baselines in various code generation benchmarks.", "conclusion": "CodeEvo showcases the effectiveness of iterative synthesis and hybrid feedback mechanisms for generating high-quality instruction-code pairs, paving the way for advancements in code-centric data synthesis methodologies."}}
{"id": "2507.22264", "pdf": "https://arxiv.org/pdf/2507.22264", "abs": "https://arxiv.org/abs/2507.22264", "authors": ["Shaoan Xie", "Lingjing Kong", "Yujia Zheng", "Yu Yao", "Zeyu Tang", "Eric P. Xing", "Guangyi Chen", "Kun Zhang"], "title": "SmartCLIP: Modular Vision-language Alignment with Identification Guarantees", "categories": ["cs.CV", "cs.AI"], "comment": "CVPR2025", "summary": "Contrastive Language-Image Pre-training (CLIP)~\\citep{radford2021learning}\nhas emerged as a pivotal model in computer vision and multimodal learning,\nachieving state-of-the-art performance at aligning visual and textual\nrepresentations through contrastive learning. However, CLIP struggles with\npotential information misalignment in many image-text datasets and suffers from\nentangled representation. On the one hand, short captions for a single image in\ndatasets like MSCOCO may describe disjoint regions in the image, leaving the\nmodel uncertain about which visual features to retain or disregard. On the\nother hand, directly aligning long captions with images can lead to the\nretention of entangled details, preventing the model from learning\ndisentangled, atomic concepts -- ultimately limiting its generalization on\ncertain downstream tasks involving short prompts.\n  In this paper, we establish theoretical conditions that enable flexible\nalignment between textual and visual representations across varying levels of\ngranularity. Specifically, our framework ensures that a model can not only\n\\emph{preserve} cross-modal semantic information in its entirety but also\n\\emph{disentangle} visual representations to capture fine-grained textual\nconcepts. Building on this foundation, we introduce \\ours, a novel approach\nthat identifies and aligns the most relevant visual and textual representations\nin a modular manner. Superior performance across various tasks demonstrates its\ncapability to handle information misalignment and supports our identification\ntheory. The code is available at https://github.com/Mid-Push/SmartCLIP.", "AI": {"tldr": "This paper addresses limitations in CLIP, such as misaligned and entangled image-text representations, proposing a framework and novel method to achieve better alignment and disentanglement, leading to improved performance.", "motivation": "Current CLIP models struggle with information misalignment in image-text datasets due to issues like short or long captions that either fail to fully represent or over-entangle visual features, limiting downstream application performance.", "method": "The authors develop a theoretical framework for flexible visual-text alignment and propose a new modular approach called \\ours, which identifies and aligns relevant visual and textual representations in a disentangled manner.", "result": "The proposed model achieves superior performance across various tasks, successfully addressing challenges of information misalignment and validating its theoretical identification method.", "conclusion": "The framework and \\ours approach enhance CLIP's ability to disentangle and align visual-textual data effectively, improving generalization across diverse tasks while addressing critical alignment issues."}}
{"id": "2507.18937", "pdf": "https://arxiv.org/pdf/2507.18937", "abs": "https://arxiv.org/abs/2507.18937", "authors": ["Takuya Inoue", "Takuya Kawabata"], "title": "CNN-based Surface Temperature Forecasts with Ensemble Numerical Weather Prediction over Medium-range Forecast Periods", "categories": ["physics.ao-ph", "cs.AI", "cs.LG", "stat.ML"], "comment": "32 pages, 10 figures", "summary": "This study proposes a method that integrates convolutional neural networks\n(CNNs) with ensemble numerical weather prediction (NWP) models, enabling\nsurface temperature forecasting at lead times beyond the short-range (five-day)\nforecast period. Owing to limited computational resources, operational\nmedium-range temperature forecasts typically rely on low-resolution NWP models,\nwhich are prone to systematic and random errors. To resolve these limitations,\nthe proposed method first reduces systematic errors through CNN-based\npost-processing (bias correction and spatial super-resolution) on each ensemble\nmember, reconstructing high-resolution temperature fields from low-resolution\nmodel outputs. Second, it reduces random errors through ensemble averaging of\nthe CNN-corrected members. This study also investigates whether the sequence of\nCNN correction and ensemble averaging affects the forecast accuracy. For\ncomparison with the proposed method, we additionally conducted experiments with\nthe CNN trained on ensemble-averaged forecasts. The first approach--CNN\ncorrection before ensemble averaging--consistently achieved higher accuracy\nthan the reverse approach. Although based on low-resolution ensemble forecasts,\nthe proposed method notably outperformed the high-resolution deterministic NWP\nmodels. These findings indicate that combining CNN-based correction with\nensemble averaging effectively reduces both the systematic and random errors in\nNWP model outputs. The proposed approach is a practical and scalable solution\nfor improving medium-range temperature forecasts, and is particularly valuable\nat operational centers with limited computational resources.", "AI": {"tldr": "This work presents a method combining CNNs with ensemble NWP models to improve medium-range temperature forecasting, addressing both systematic and random errors efficiently.", "motivation": "Operational medium-range temperature forecasts often rely on low-resolution NWP models, leading to systematic and random errors due to computational constraints.", "method": "The method applies CNN-based post-processing to correct systematic errors (bias correction, spatial super-resolution) and uses ensemble averaging to reduce random errors in NWP outputs.", "result": "CNN correction before ensemble averaging achieved higher accuracy than the reverse approach, and the method outperformed high-resolution deterministic NWP models while using low-resolution ensemble forecasts.", "conclusion": "The method is an effective, scalable solution for improving medium-range temperature forecasts, especially useful for operational centers with limited computational resources."}}
{"id": "2507.22433", "pdf": "https://arxiv.org/pdf/2507.22433", "abs": "https://arxiv.org/abs/2507.22433", "authors": ["Olaf Op den Camp", "Erwin de Gelder"], "title": "Operationalization of Scenario-Based Safety Assessment of Automated Driving Systems", "categories": ["cs.RO"], "comment": "Accepted for publication in proceedings of the 2025 IEEE\n  International Automated Vehicle Validation Conference", "summary": "Before introducing an Automated Driving System (ADS) on the road at scale,\nthe manufacturer must conduct some sort of safety assurance. To structure and\nharmonize the safety assurance process, the UNECE WP.29 Working Party on\nAutomated/Autonomous and Connected Vehicles (GRVA) is developing the New\nAssessment/Test Method (NATM) that indicates what steps need to be taken for\nsafety assessment of an ADS. In this paper, we will show how to practically\nconduct safety assessment making use of a scenario database, and what\nadditional steps must be taken to fully operationalize the NATM. In addition,\nwe will elaborate on how the use of scenario databases fits with methods\ndeveloped in the Horizon Europe projects that focus on safety assessment\nfollowing the NATM approach.", "AI": {"tldr": "The paper discusses methods for conducting safety assessments of Automated Driving Systems (ADS) using scenario databases in alignment with the UNECE WP.29 NATM framework.", "motivation": "To ensure the safe deployment of Automated Driving Systems at scale and standardize the safety assessment process globally, leveraging the guidelines of UNECE WP.29's NATM framework.", "method": "The paper proposes integrating scenario databases and enriching them with practices inspired by Horizon Europe projects to operationalize and enhance the NATM approach for ADS safety evaluations.", "result": "Effective utilization of scenario databases is demonstrated, and additional steps for fully operationalizing NATM in ADS safety assessments are identified.", "conclusion": "Scenario databases are vital tools for structuring ADS safety assessments under the NATM framework, and collaboration with Horizon Europe projects enhances their implementation."}}
{"id": "2507.22289", "pdf": "https://arxiv.org/pdf/2507.22289", "abs": "https://arxiv.org/abs/2507.22289", "authors": ["Galo Castillo-L\u00f3pez", "Ga\u00ebl de Chalendar", "Nasredine Semmar"], "title": "Intent Recognition and Out-of-Scope Detection using LLMs in Multi-party Conversations", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted for publication at SIGDIAL 2025", "summary": "Intent recognition is a fundamental component in task-oriented dialogue\nsystems (TODS). Determining user intents and detecting whether an intent is\nOut-of-Scope (OOS) is crucial for TODS to provide reliable responses. However,\ntraditional TODS require large amount of annotated data. In this work we\npropose a hybrid approach to combine BERT and LLMs in zero and few-shot\nsettings to recognize intents and detect OOS utterances. Our approach leverages\nLLMs generalization power and BERT's computational efficiency in such\nscenarios. We evaluate our method on multi-party conversation corpora and\nobserve that sharing information from BERT outputs to LLMs leads to system\nperformance improvement.", "AI": {"tldr": "This paper proposes a hybrid approach combining BERT and large language models (LLMs) for zero and few-shot intent recognition in task-oriented dialogue systems, focusing on Out-of-Scope (OOS) detection.", "motivation": "Traditional task-oriented dialogue systems require large amounts of annotated data for intent recognition and OOS detection, which can be resource-intensive.", "method": "The authors combine the generalization capabilities of LLMs with BERT's computational efficiency in a hybrid framework, sharing information between the two models for better performance.", "result": "Evaluation on multi-party conversation corpora shows that sharing outputs between BERT and LLMs improves the system's performance in intent recognition and OOS detection.", "conclusion": "The hybrid approach effectively enhances intent recognition and OOS detection, demonstrating the advantages of integrating LLMs and BERT in low-resource settings."}}
{"id": "2507.22174", "pdf": "https://arxiv.org/pdf/2507.22174", "abs": "https://arxiv.org/abs/2507.22174", "authors": ["Molly Wang"], "title": "Spatial-Temporal Reinforcement Learning for Network Routing with Non-Markovian Traffic", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning (RL) has become a well-established approach for\noptimizing packet routing in communication networks. Standard RL algorithms\ntypically are based on the Markov Decision Process (MDP), which assumes that\nthe current state of the environment provides all the necessary information for\nsystem evolution and decision-making. However, this Markovian assumption is\ninvalid in many practical scenarios, making the MDP and RL frameworks\ninadequate to produce the optimal solutions. Additionally, traditional RL\nalgorithms often employ function approximations (e.g., by neural networks) that\ndo not explicitly capture the spatial relationships inherent in environments\nwith complex network topologies. Communication networks are characterized by\ndynamic traffic patterns and arbitrary numbers of nodes and links, which\nfurther complicate the decision-making process. To address these challenges, we\npropose a spatial-temporal RL approach that integrates Graph Neural Networks\n(GNNs) and Recurrent Neural Networks (RNNs) to adequately capture the spatial\ndynamics regarding network topology and temporal traffic patterns,\nrespectively, to enhance routing decisions. Our evaluation demonstrates that\nthe proposed method outperforms and is more robust to changes in the network\ntopology when compared with traditional RL techniques.", "AI": {"tldr": "This paper proposes a spatial-temporal RL approach, integrating Graph Neural Networks (GNNs) and Recurrent Neural Networks (RNNs), to improve packet routing in communication networks with dynamic topologies and traffic patterns.", "motivation": "Standard RL methods for packet routing often fail in scenarios where the Markovian assumption does not hold and do not explicitly address spatial relationships within complex network topologies.", "method": "The approach combines GNNs for capturing spatial dynamics of the network topology and RNNs for addressing temporal traffic patterns, forming a spatial-temporal RL strategy.", "result": "The proposed method demonstrated superior performance and robustness compared to traditional RL algorithms, especially under dynamic network topology changes.", "conclusion": "Integrating spatial and temporal awareness into RL algorithms enhances decision-making for packet routing in communication networks, addressing limitations in traditional techniques."}}
