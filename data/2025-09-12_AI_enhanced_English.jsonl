{"id": "2509.08834", "pdf": "https://arxiv.org/pdf/2509.08834", "abs": "https://arxiv.org/abs/2509.08834", "authors": ["John T. Rickard", "William A. Dembski", "James Rickards"], "title": "An Interval Type-2 Version of Bayes Theorem Derived from Interval Probability Range Estimates Provided by Subject Matter Experts", "categories": ["cs.AI", "physics.comp-ph", "physics.data-an", "q-fin.CP"], "comment": "13 pages, 12 figures", "summary": "Bayesian inference is widely used in many different fields to test hypotheses\nagainst observations. In most such applications, an assumption is made of\nprecise input values to produce a precise output value. However, this is\nunrealistic for real-world applications. Often the best available information\nfrom subject matter experts (SMEs) in a given field is interval range estimates\nof the input probabilities involved in Bayes Theorem. This paper provides two\nkey contributions to extend Bayes Theorem to an interval type-2 (IT2) version.\nFirst, we develop an IT2 version of Bayes Theorem that uses a novel and\nconservative method to avoid potential inconsistencies in the input IT2 MFs\nthat otherwise might produce invalid output results. We then describe a novel\nand flexible algorithm for encoding SME-provided intervals into IT2 fuzzy\nmembership functions (MFs), which we can use to specify the input probabilities\nin Bayes Theorem. Our algorithm generalizes and extends previous work on this\nproblem that primarily addressed the encoding of intervals into word MFs for\nComputing with Words applications.", "AI": {"tldr": "The paper extends Bayes Theorem to handle interval type-2 fuzzy inputs for situations where precise input probabilities aren't available.", "motivation": "To address the unrealistic assumption of precise inputs in Bayesian inference by incorporating interval probabilistic estimates from subject matter experts.", "method": "Developed an interval type-2 version of Bayes Theorem and designed an algorithm to encode interval estimates from experts into fuzzy membership functions.", "result": "Proposed a conservative IT2 Bayesian inference method to ensure inconsistencies in input handling were avoided, along with a flexible algorithm for interval encoding.", "conclusion": "The extended Bayes Theorem approach accommodates imprecise input probabilities, making Bayesian inference more practical for real-world applications where interval data is provided by experts."}}
{"id": "2509.08847", "pdf": "https://arxiv.org/pdf/2509.08847", "abs": "https://arxiv.org/abs/2509.08847", "authors": ["Amna Hassan"], "title": "Automated Unity Game Template Generation from GDDs via NLP and Multi-Modal LLMs", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.SE"], "comment": null, "summary": "This paper presents a novel framework for automated game template generation\nby transforming Game Design Documents (GDDs) into functional Unity game\nprototypes using Natural Language Processing (NLP) and multi-modal Large\nLanguage Models (LLMs). We introduce an end-to-end system that parses GDDs,\nextracts structured game specifications, and synthesizes Unity-compatible C#\ncode that implements the core mechanics, systems, and architecture defined in\nthe design documentation. Our approach combines a fine-tuned LLaMA-3 model\nspecialized for Unity code generation with a custom Unity integration package\nthat streamlines the implementation process. Evaluation results demonstrate\nsignificant improvements over baseline models, with our fine-tuned model\nachieving superior performance (4.8/5.0 average score) compared to\nstate-of-the-art LLMs across compilation success, GDD adherence, best practices\nadoption, and code modularity metrics. The generated templates demonstrate high\nadherence to GDD specifications across multiple game genres. Our system\neffectively addresses critical gaps in AI-assisted game development,\npositioning LLMs as valuable tools in streamlining the transition from game\ndesign to implementation.", "AI": {"tldr": "The paper proposes an automated framework to convert Game Design Documents (GDDs) into Unity game prototypes using NLP and advanced LLMs.", "motivation": "Facilitate game development by bridging the gap between design documents and functional prototypes using AI.", "method": "An end-to-end system utilizing a fine-tuned LLaMA-3 model and custom Unity integration for parsing GDDs and generating Unity-compatible C# code.", "result": "The system outperforms baseline models with an average score of 4.8/5.0, demonstrating strong adherence to GDDs, better practices, and modularity across multiple game genres.", "conclusion": "AI-driven systems like this framework are effective tools to streamline the transition from game design to implementation, addressing gaps in automated game development workflows."}}
{"id": "2509.08970", "pdf": "https://arxiv.org/pdf/2509.08970", "abs": "https://arxiv.org/abs/2509.08970", "authors": ["Junyang Cai", "Serdar Kadioglu", "Bistra Dilkina"], "title": "Global Constraint LLM Agents for Text-to-Model Translation", "categories": ["cs.AI"], "comment": null, "summary": "Natural language descriptions of optimization or satisfaction problems are\nchallenging to translate into correct MiniZinc models, as this process demands\nboth logical reasoning and constraint programming expertise. We introduce a\nframework that addresses this challenge with an agentic approach: multiple\nspecialized large language model (LLM) agents decompose the modeling task by\nglobal constraint type. Each agent is dedicated to detecting and generating\ncode for a specific class of global constraint, while a final assembler agent\nintegrates these constraint snippets into a complete MiniZinc model. By\ndividing the problem into smaller, well-defined sub-tasks, each LLM handles a\nsimpler reasoning challenge, potentially reducing overall complexity. We\nconduct initial experiments with several LLMs and show better performance\nagainst baselines such as one-shot prompting and chain-of-thought prompting.\nFinally, we outline a comprehensive roadmap for future work, highlighting\npotential enhancements and directions for improvement.", "AI": {"tldr": "The paper proposes a framework for translating natural language descriptions into MiniZinc models using specialized LLM agents and demonstrates superior performance compared to baseline methods.", "motivation": "Translating optimization problems from natural language into MiniZinc models is difficult due to the need for logical reasoning and constraint programming skills.", "method": "The proposed framework uses multiple specialized LLM agents to address specific global constraint types and a final assembler agent to integrate outputs into a complete MiniZinc model.", "result": "Initial experiments indicate that the framework outperforms baseline approaches, such as one-shot prompting and chain-of-thought prompting.", "conclusion": "Segmenting the modeling task into simpler sub-tasks for specialized LLM agents reduces complexity and improves accuracy, providing a promising foundation for future improvements."}}
{"id": "2509.08972", "pdf": "https://arxiv.org/pdf/2509.08972", "abs": "https://arxiv.org/abs/2509.08972", "authors": ["Soheil Zibakhsh Shabgahi", "Pedram Aghazadeh", "Azalia Mirhosseini", "Farinaz Koushanfar"], "title": "ForTIFAI: Fending Off Recursive Training Induced Failure for AI Models", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The increasing reliance on generative AI models has accelerated the\ngeneration rate of synthetic data, with some projections suggesting that most\navailable new data for training could be machine-generated by 2030. This shift\nto a mainly synthetic content presents a critical challenge: repeated training\nin synthetic data leads to a phenomenon known as model collapse, where model\nperformance degrades over generations of training, eventually rendering the\nmodels ineffective. Although prior studies have explored the causes and\ndetection of model collapse, existing mitigation strategies remain limited.\n  In this paper, we identify model overconfidence in their self-generated data\nas a key driver of collapse. Building on this observation, we propose a\nconfidence-aware loss function that downweights high-confidence predictions\nduring training. We introduce a novel loss function we call Truncated Cross\nEntropy (TCE). We demonstrate that TCE significantly delays model collapse in\nrecursive training.\n  We provide a model-agnostic framework that links the loss function design to\nmodel collapse mitigation and validate our approach both theoretically and\nempirically, showing that it can extend the model's fidelity interval before\ncollapse by more than 2.3x. Finally, we show that our method generalizes across\nmodalities. These findings suggest that the design of loss functions provides a\nsimple yet powerful tool for preserving the quality of generative models in the\nera of increasing synthetic data.", "AI": {"tldr": "This paper addresses the issue of model collapse caused by repeated training on synthetic data in generative AI. It introduces the Truncated Cross Entropy (TCE) loss function to mitigate this by reducing model overconfidence, delaying collapse significantly.", "motivation": "The motivation arises from the growing dominance of synthetic data in AI training and the associated model collapse risk, which compromises model performance and reliability over generations.", "method": "The proposed method introduces a novel loss function, Truncated Cross Entropy (TCE), which downweights high-confidence predictions during training, in order to combat model overconfidence. The approach is validated both theoretically and empirically.", "result": "The TCE loss function was empirically shown to extend the fidelity interval of generative models before collapse by over 2.3 times, proving its efficacy in delaying model collapse.", "conclusion": "The paper concludes that loss function design, specifically TCE, offers a robust framework for preserving the integrity of generative models amidst increasing reliance on synthetic training data across modalities."}}
{"id": "2509.08969", "pdf": "https://arxiv.org/pdf/2509.08969", "abs": "https://arxiv.org/abs/2509.08969", "authors": ["Nima Karimian Kakolaki"], "title": "A Comparative Analysis of Identifier Schemes: UUIDv4, UUIDv7, and ULID for Distributed Systems", "categories": ["cs.DC", "cs.DB"], "comment": null, "summary": "Distributed systems require robust, scalable identifier schemes to ensure\ndata uniqueness and efficient indexing across multiple nodes. This paper\npresents a comprehensive analysis of the evolution of distributed identifiers,\ncomparing traditional auto-increment keys with UUIDv4, UUIDv7, and ULIDs. We\ncombine mathematical calculation of collision probabilities with empirical\nexperiments measuring generation speed and network transmission overhead in a\nsimulated distributed environment. Results demonstrate that ULIDs significantly\noutperform UUIDv4 and UUIDv7, reducing network overhead by 83.7% and increasing\ngeneration speed by 97.32%. statistical analysis further shows ULIDs offer a\n98.42% lower collision risk compared to UUIDv7, while maintaining negligible\ncollision probabilities even at high generation rates. These findings highlight\nULIDs as an optimal choice for high-performance distributed systems, providing\nefficient, time-ordered, and lexicographically sortable identifiers suitable\nfor scalable applications. All source code, datasets, and analysis scripts\nutilized in this research are publicly available in our dedicated repository at\nhttps://github.com/nimakarimiank/uids-comparison. This repository contains\ncomprehensive documentation of the experimental setup, including configuration\nfiles for the distributed environment, producer and consumer implementations,\nand message broker integration. Additionally, it provides the data scripts and\ndatasets. Researchers and practitioners are encouraged to explore the\nrepository for full reproducibility of the experiments and to facilitate\nfurther investigation or extension of the presented work.", "AI": {"tldr": "The paper evaluates distributed identifier schemes, finding ULIDs excel in performance, collision risks, and efficiency. Source code is provided for reproducibility.", "motivation": "To analyze and identify the most efficient, scalable, and low-collision distributed identifier scheme for distributed systems.", "method": "The study uses both mathematical collision probability calculations and empirical experiments in a simulated distributed environment to compare identifier schemes.", "result": "ULIDs reduced network overhead by 83.7%, increased generation speed by 97.32%, and exhibited 98.42% lower collision risk compared to UUIDv7, maintaining negligible collision risks even in high-generation scenarios.", "conclusion": "The paper concludes that ULIDs are optimal for distributed systems requiring high performance, time-ordering, and scalability, backed by reproducible experiments and public code resources."}}
{"id": "2509.08903", "pdf": "https://arxiv.org/pdf/2509.08903", "abs": "https://arxiv.org/abs/2509.08903", "authors": ["Alex Clay", "Ernesto Jim\u00e9nez-Ruiz", "Pranava Madhyastha"], "title": "Noise or Nuance: An Investigation Into Useful Information and Filtering For LLM Driven AKBC", "categories": ["cs.CL"], "comment": "8 pages, 1 figure, accepted to the ISWC 2025 LM-KBC Workshop", "summary": "RAG and fine-tuning are prevalent strategies for improving the quality of LLM\noutputs. However, in constrained situations, such as that of the 2025 LM-KBC\nchallenge, such techniques are restricted. In this work we investigate three\nfacets of the triple completion task: generation, quality assurance, and LLM\nresponse parsing. Our work finds that in this constrained setting: additional\ninformation improves generation quality, LLMs can be effective at filtering\npoor quality triples, and the tradeoff between flexibility and consistency with\nLLM response parsing is setting dependent.", "AI": {"tldr": "The paper explores strategies for triple completion tasks under constraints, finding that additional information improves generation, LLMs can filter poor data, and parsing effectiveness is context-dependent.", "motivation": "To address the limitations in constrained settings, like the LM-KBC challenge, where popular methods like RAG and fine-tuning cannot be applied.", "method": "Investigated triple completion tasks, focusing on generation, quality assurance, and LLM response parsing under restricted settings.", "result": "Additional data enhances generation; LLMs successfully filter low-quality triples; parsing trade-offs depend on flexibility and consistency based on the context.", "conclusion": "In constrained scenarios, leveraging additional information and tailoring parsing strategies can effectively enhance LLM-generated results."}}
{"id": "2509.09019", "pdf": "https://arxiv.org/pdf/2509.09019", "abs": "https://arxiv.org/abs/2509.09019", "authors": ["Mohit Tekriwal", "John Sarracino"], "title": "Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs", "categories": ["cs.PL"], "comment": null, "summary": "Scientific computing programs often undergo aggressive compiler optimization\nto achieve high performance and efficient resource utilization. While\nperformance is critical, we also need to ensure that these optimizations are\ncorrect. In this paper, we focus on a specific class of optimizations,\nfloating-point optimizations, notably due to fast math, at the LLVM IR level.\nWe present a preliminary work, which leverages the Verified LLVM framework in\nthe Rocq theorem prover, to prove the correctness of Fused-Multiply-Add (FMA)\noptimization for a basic block implementing the arithmetic expression $a * b +\nc$ . We then propose ways to extend this preliminary results by adding more\nprogram features and fast math floating-point optimizations.", "AI": {"tldr": "This paper uses the Verified LLVM framework to ensure the correctness of floating-point optimizations, focusing on Fused-Multiply-Add (FMA).", "motivation": "To ensure the correctness of aggressive floating-point optimizations applied by compilers for better performance.", "method": "The Verified LLVM framework in the Rocq theorem prover is used to formally prove the correctness of FMA optimization.", "result": "A correctness proof is presented for a specific optimization involving the arithmetic expression $a * b + c$ at the LLVM IR level.", "conclusion": "The authors propose extending this preliminary work to incorporate more program features and fast math optimizations."}}
{"id": "2509.08897", "pdf": "https://arxiv.org/pdf/2509.08897", "abs": "https://arxiv.org/abs/2509.08897", "authors": ["Davide Caffagni", "Sara Sarto", "Marcella Cornia", "Lorenzo Baraldi", "Rita Cucchiara"], "title": "Recurrence Meets Transformers for Universal Multimodal Retrieval", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "comment": null, "summary": "With the rapid advancement of multimodal retrieval and its application in\nLLMs and multimodal LLMs, increasingly complex retrieval tasks have emerged.\nExisting methods predominantly rely on task-specific fine-tuning of\nvision-language models and are limited to single-modality queries or documents.\nIn this paper, we propose ReT-2, a unified retrieval model that supports\nmultimodal queries, composed of both images and text, and searches across\nmultimodal document collections where text and images coexist. ReT-2 leverages\nmulti-layer representations and a recurrent Transformer architecture with\nLSTM-inspired gating mechanisms to dynamically integrate information across\nlayers and modalities, capturing fine-grained visual and textual details. We\nevaluate ReT-2 on the challenging M2KR and M-BEIR benchmarks across different\nretrieval configurations. Results demonstrate that ReT-2 consistently achieves\nstate-of-the-art performance across diverse settings, while offering faster\ninference and reduced memory usage compared to prior approaches. When\nintegrated into retrieval-augmented generation pipelines, ReT-2 also improves\ndownstream performance on Encyclopedic-VQA and InfoSeek datasets. Our source\ncode and trained models are publicly available at:\nhttps://github.com/aimagelab/ReT-2", "AI": {"tldr": "ReT-2 is a unified retrieval model supporting multimodal queries and documents. It achieves state-of-the-art performance with reduced memory and faster inference.", "motivation": "The paper addresses the limitations of current vision-language models, which rely on task-specific fine-tuning and are limited to single-modality queries or documents.", "method": "ReT-2 uses multi-layer representations and a recurrent Transformer architecture with LSTM-inspired gating to integrate visual and textual information dynamically.", "result": "ReT-2 demonstrates state-of-the-art performance on M2KR and M-BEIR benchmarks, with faster inference and reduced memory. It also improves downstream tasks like Encyclopedic-VQA and InfoSeek.", "conclusion": "ReT-2 is an efficient and effective multimodal retrieval model, enhancing both retrieval and downstream performance in LLM-related applications."}}
{"id": "2509.08859", "pdf": "https://arxiv.org/pdf/2509.08859", "abs": "https://arxiv.org/abs/2509.08859", "authors": ["Vincenzo Suriani", "Daniele Affinita", "Domenico D. Bloisi", "Daniele Nardi"], "title": "Multi Robot Coordination in Highly Dynamic Environments: Tackling Asymmetric Obstacles and Limited Communication", "categories": ["cs.RO", "cs.AI"], "comment": "The 19th International Conference on Intelligent Autonomous Systems\n  (IAS 19), 2025, Genoa", "summary": "Coordinating a fully distributed multi-agent system (MAS) can be challenging\nwhen the communication channel has very limited capabilities in terms of\nsending rate and packet payload. When the MAS has to deal with active obstacles\nin a highly partially observable environment, the communication channel\nacquires considerable relevance. In this paper, we present an approach to deal\nwith task assignments in extremely active scenarios, where tasks need to be\nfrequently reallocated among the agents participating in the coordination\nprocess. Inspired by market-based task assignments, we introduce a novel\ndistributed coordination method to orchestrate autonomous agents' actions\nefficiently in low communication scenarios. In particular, our algorithm takes\ninto account asymmetric obstacles. While in the real world, the majority of\nobstacles are asymmetric, they are usually treated as symmetric ones, thus\nlimiting the applicability of existing methods. To summarize, the presented\narchitecture is designed to tackle scenarios where the obstacles are active and\nasymmetric, the communication channel is poor and the environment is partially\nobservable. Our approach has been validated in simulation and in the real\nworld, using a team of NAO robots during official RoboCup competitions.\nExperimental results show a notable reduction in task overlaps in limited\ncommunication settings, with a decrease of 52% in the most frequent reallocated\ntask.", "AI": {"tldr": "This paper proposes a distributed coordination method for multi-agent systems operating in low-communication environments with active and asymmetric obstacles.", "motivation": "The study addresses challenges in coordinating multi-agent systems in environments with limited communication, high dynamics, asymmetric obstacles, and partial observability.", "method": "The authors introduced a market-based task assignment approach tailored for low-communication scenarios, accommodating asymmetric obstacles, and validated it using NAO robots in simulations and RoboCup competitions.", "result": "The proposed algorithm significantly reduces task overlaps in limited communication settings by 52%.", "conclusion": "The method effectively manages coordination challenges in poor communication environments, ensuring better task assignments and reduced overlaps in dynamic asymmetric settings."}}
{"id": "2509.08846", "pdf": "https://arxiv.org/pdf/2509.08846", "abs": "https://arxiv.org/abs/2509.08846", "authors": ["H. Martin Gillis", "Isaac Xu", "Thomas Trappenberg"], "title": "Uncertainty Estimation using Variance-Gated Distributions", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Evaluation of per-sample uncertainty quantification from neural networks is\nessential for decision-making involving high-risk applications. A common\napproach is to use the predictive distribution from Bayesian or approximation\nmodels and decompose the corresponding predictive uncertainty into epistemic\n(model-related) and aleatoric (data-related) components. However, additive\ndecomposition has recently been questioned. In this work, we propose an\nintuitive framework for uncertainty estimation and decomposition based on the\nsignal-to-noise ratio of class probability distributions across different model\npredictions. We introduce a variance-gated measure that scales predictions by a\nconfidence factor derived from ensembles. We use this measure to discuss the\nexistence of a collapse in the diversity of committee machines.", "AI": {"tldr": "This paper critiques conventional uncertainty decomposition in neural networks and proposes a new framework based on signal-to-noise ratio and ensembles.", "motivation": "The goal is to improve uncertainty quantification for applications with high stakes, as simple additive decomposition methods are now being questioned.", "method": "The authors present a framework leveraging the signal-to-noise ratio of class predictions and introduce a variance-gated measure that incorporates ensemble methods.", "result": "The variance-gated measure is shown to provide insights into committee machine diversity collapse, improving uncertainty quantification.", "conclusion": "This new framework offers a more intuitive and possibly accurate method for estimating and decomposing uncertainty in neural network predictions."}}
{"id": "2509.08843", "pdf": "https://arxiv.org/pdf/2509.08843", "abs": "https://arxiv.org/abs/2509.08843", "authors": ["Sidney Shapiro"], "title": "Pattern-Based File and Data Access with Python Glob: A Comprehensive Guide for Computational Research", "categories": ["cs.SE"], "comment": null, "summary": "Pattern-based file access is a fundamental but often under-documented aspect\nof computational research. The Python glob module provides a simple yet\npowerful way to search, filter, and ingest files using wildcard patterns,\nenabling scalable workflows across disciplines. This paper introduces glob as a\nversatile tool for data science, business analytics, and artificial\nintelligence applications. We demonstrate use cases including large-scale data\ningestion, organizational data analysis, AI dataset construction, and\nreproducible research practices. Through concrete Python examples with widely\nused libraries such as pandas,scikit-learn, and matplotlib, we show how glob\nfacilitates efficient file traversal and integration with analytical pipelines.\nBy situating glob within the broader context of reproducible research and data\nengineering, we highlight its role as a methodological building block. Our goal\nis to provide researchers and practitioners with a concise reference that\nbridges foundational concepts and applied practice, making glob a default\ncitation for file pattern matching in Python-based research workflows.", "AI": {"tldr": "This paper showcases the Python 'glob' module as a foundational tool for pattern-based file access in computational research, emphasizing its utility in scalable workflows.", "motivation": "Pattern-based file access is often under-documented, and this paper seeks to demonstrate how the Python glob module can address this gap by serving as a versatile tool across disciplines.", "method": "The authors provide use cases, practical examples, and integration strategies for leveraging the glob module in Python, using libraries like pandas, scikit-learn, and matplotlib.", "result": "Examples illustrate how the glob module facilitates efficient file traversal, improves integration into analytical workflows, and supports reproducible research workflows.", "conclusion": "The paper positions the Python glob module as a key methodological resource for file pattern matching, encouraging standardized use in Python-based computational research."}}
{"id": "2509.09078", "pdf": "https://arxiv.org/pdf/2509.09078", "abs": "https://arxiv.org/abs/2509.09078", "authors": ["Teresa Portone", "Bert Debusschere", "Samantha Yang", "Emiliano Islas-Quinones", "T. Patrick Xiao"], "title": "Scalable extensions to given-data Sobol' index estimators", "categories": ["stat.ML", "cs.LG", "stat.AP", "stat.CO"], "comment": null, "summary": "Given-data methods for variance-based sensitivity analysis have significantly\nadvanced the feasibility of Sobol' index computation for computationally\nexpensive models and models with many inputs. However, the limitations of\nexisting methods still preclude their application to models with an extremely\nlarge number of inputs. In this work, we present practical extensions to the\nexisting given-data Sobol' index method, which allow variance-based sensitivity\nanalysis to be efficiently performed on large models such as neural networks,\nwhich have $>10^4$ parameterizable inputs. For models of this size, holding all\ninput-output evaluations simultaneously in memory -- as required by existing\nmethods -- can quickly become impractical. These extensions also support\nnonstandard input distributions with many repeated values, which are not\namenable to equiprobable partitions employed by existing given-data methods.\n  Our extensions include a general definition of the given-data Sobol' index\nestimator with arbitrary partition, a streaming algorithm to process\ninput-output samples in batches, and a heuristic to filter out small indices\nthat are indistinguishable from zero indices due to statistical noise. We show\nthat the equiprobable partition employed in existing given-data methods can\nintroduce significant bias into Sobol' index estimates even at large sample\nsizes and provide numerical analyses that demonstrate why this can occur. We\nalso show that our streaming algorithm can achieve comparable accuracy and\nruntimes with lower memory requirements, relative to current methods which\nprocess all samples at once. We demonstrate our novel developments on two\napplication problems in neural network modeling.", "AI": {"tldr": "This paper introduces extensions to the Sobol' index computation methods for variance-based sensitivity analysis to handle extremely large models efficiently.", "motivation": "Current Sobol' index methods face limitations in applying to models with a vast number of inputs and preclude processing nonstandard input distributions or maintaining all input-output evaluations in memory.", "method": "The paper proposes a general definition for Sobol' index estimation with arbitrary partitions, a streaming algorithm for handling input-output samples in batches, and a heuristic for filtering noise-affected indices.", "result": "The proposed methods overcome memory constraints, demonstrate reduced bias compared to earlier equiprobable partition methods, and achieve comparable accuracy and runtimes.", "conclusion": "The extensions make Sobol' index computation feasible for large-scale models like neural networks ($>10^4$ inputs) with improved efficiency and reliability."}}
{"id": "2509.09178", "pdf": "https://arxiv.org/pdf/2509.09178", "abs": "https://arxiv.org/abs/2509.09178", "authors": ["Ayan Biswas", "Jimmy Jin"], "title": "Implementation of a 8-bit Wallace Tree Multiplier", "categories": ["cs.AR", "cs.SY", "eess.SY"], "comment": null, "summary": "Wallace tree multipliers are a parallel digital multiplier architecture\ndesigned to minimize the worst-case time complexity of the circuit depth\nrelative to the input size [1]. In particular, it seeks to perform long\nmultiplication in the binary sense, reducing as many partial products per stage\nas possible through full and half adders circuits, achieving O(log(n)) where n\n= bit length of input. This paper provides an overview of the design, progress\nand methodology in the final project of ECE 55900, consisting of the schematic\nand layout of a Wallace tree 8-bit input multiplier on the gpdk45 technology in\nCadence Virtuoso, as well as any design attempts prior to the final product.\nThis also includes our endeavors in designing the final MAC (Multiply\nAccumulate) unit with undefined targets, which we chose to implement as a 16\nbit combinational multiply-add.", "AI": {"tldr": "The paper focuses on the design and implementation of an 8-bit Wallace tree multiplier and a 16-bit MAC unit using gpdk45 technology in Cadence Virtuoso.", "motivation": "To optimize the circuit depth and improve computational efficiency of parallel multiplication through the Wallace tree architecture.", "method": "Design and layout of an 8-bit Wallace tree multiplier and a 16-bit MAC unit using Cadence Virtuoso with gpdk45 technology, leveraging full and half adders.", "result": "The paper succeeded in implementing the Wallace tree multiplier and MAC design, showcasing the reduction of circuit complexity and improved performance metrics.", "conclusion": "The study highlights the effectiveness of Wallace tree multipliers and their practical implementation in modern digital systems, extending to a MAC unit for further flexibility."}}
{"id": "2509.09420", "pdf": "https://arxiv.org/pdf/2509.09420", "abs": "https://arxiv.org/abs/2509.09420", "authors": ["Haochen Huang", "Shuzhang Zhong", "Zhe Zhang", "Shuangchen Li", "Dimin Niu", "Hongzhong Zheng", "Runsheng Wang", "Meng Li"], "title": "HD-MoE: Hybrid and Dynamic Parallelism for Mixture-of-Expert LLMs with 3D Near-Memory Processing", "categories": ["cs.PF"], "comment": "9 pages, 15 figures, International Conference on Computer-Aided\n  Design (ICCAD) 2025", "summary": "Large Language Models (LLMs) with Mixture-of-Expert (MoE) architectures\nachieve superior model performance with reduced computation costs, but at the\ncost of high memory capacity and bandwidth requirements. Near-Memory Processing\n(NMP) accelerators that stack memory directly on the compute through hybrid\nbonding have demonstrated high bandwidth with high energy efficiency, becoming\na promising architecture for MoE models. However, as NMP accelerators comprise\ndistributed memory and computation, how to map the MoE computation directly\ndetermines the LLM inference efficiency. Existing parallel mapping strategies,\nincluding Tensor Parallelism (TP) and Expert Parallelism (EP), suffer from\neither high communication costs or unbalanced computation utilization, leading\nto inferior efficiency. The dynamic routing mechanism of MoE LLMs further\naggravates the efficiency challenges. Therefore, in this paper, we propose\nHD-MoE to automatically optimize the MoE parallel computation across an NMP\naccelerator. HD-MoE features an offline automatic hybrid parallel mapping\nalgorithm and an online dynamic scheduling strategy to reduce the communication\ncosts while maximizing the computation utilization. With extensive experimental\nresults, we demonstrate that HD-MoE achieves a speedup ranging from 1.1x to\n1.8x over TP, 1.1x to 1.5x over EP, and 1.0x to 1.4x over the baseline Hybrid\nTP-EP with Compute-Balanced parallelism strategies.", "AI": {"tldr": "This paper proposes HD-MoE, an optimization method for efficiently mapping Mixture-of-Expert (MoE) Large Language Models (LLMs) onto Near-Memory Processing (NMP) accelerators.", "motivation": "Optimize the deployment of resource-efficient Mixture-of-Expert (MoE) LLMs on Near-Memory Processing (NMP) architectures, which face performance bottlenecks due to communication costs and unbalanced computation.", "method": "Propose HD-MoE, which includes an offline automatic hybrid parallel mapping algorithm and an online dynamic scheduling strategy to handle MoE computation on NMP accelerators efficiently.", "result": "HD-MoE achieves significant inference speedups, ranging from 1.1x to 1.8x against Tensor Parallelism (TP), 1.1x to 1.5x against Expert Parallelism (EP), and 1.0x to 1.4x over compute-balanced hybrid TP-EP strategies.", "conclusion": "HD-MoE effectively addresses communication and computation inefficiencies and establishes itself as an advanced mapping solution for MoE LLMs on NMP accelerators."}}
{"id": "2509.08986", "pdf": "https://arxiv.org/pdf/2509.08986", "abs": "https://arxiv.org/abs/2509.08986", "authors": ["Junbo Jacob Lian"], "title": "Time-Fair Benchmarking for Metaheuristics: A Restart-Fair Protocol for Fixed-Time Comparisons", "categories": ["cs.NE", "cs.PF", "stat.CO"], "comment": null, "summary": "Numerous purportedly improved metaheuristics claim superior performance based\non equivalent function evaluations (FEs), yet often conceal additional\ncomputational burdens in more intensive iterations, preprocessing stages, or\nhyperparameter tuning. This paper posits that wall-clock time, rather than\nsolely FEs, should serve as the principal budgetary constraint for equitable\ncomparisons. We formalize a fixed-time, restart-fair benchmarking protocol\nwherein each algorithm is allotted an identical wall-clock time budget per\nproblem instance, permitting unrestricted utilization of restarts, early\ntermination criteria, and internal adaptive mechanisms. We advocate for the\nadoption of anytime performance curves, expected running time (ERT) metrics,\nand performance profiles that employ time as the cost measure, all aimed at\npredefined targets. Furthermore, we introduce a concise, reproducible checklist\nto standardize reporting practices and mitigate undisclosed computational\noverheads. This approach fosters more credible and practically relevant\nevaluations of metaheuristic algorithms.", "AI": {"tldr": "The paper emphasizes the importance of using wall-clock time, not just function evaluations (FEs), for benchmarking metaheuristic algorithms, proposing a fixed-time benchmarking protocol and a standardized reporting checklist.", "motivation": "Issues with unfair comparison of metaheuristics arise when additional computational burdens (e.g., intensive iterations or preprocessing) are hidden, even when equivalent function evaluations (FEs) are claimed.", "method": "The paper formalizes a benchmarking approach that uses fixed wall-clock time budgets, allows for algorithm restarts and adaptive mechanisms, and introduces standardized metrics for performance evaluations.", "result": "The proposed protocol enables fairer and more reproducible metaheuristic evaluations by mitigating concealed overheads and emphasizing practical performance metrics.", "conclusion": "Shifting focus to time-based evaluations enhances the credibility and relevance of metaheuristic algorithm assessments. A standardized reporting checklist further improves reproducibility and transparency."}}
{"id": "2509.08831", "pdf": "https://arxiv.org/pdf/2509.08831", "abs": "https://arxiv.org/abs/2509.08831", "authors": ["Doai Ngo", "Mingxuan Sun", "Zhengji Zhang", "Ashwin G Ramayya", "Mark Schnitzer", "Zhe Zhao"], "title": "Path to Intelligence: Measuring Similarity between Human Brain and Large Language Model Beyond Language Task", "categories": ["q-bio.NC"], "comment": null, "summary": "Large language models (LLMs) have demonstrated human-like abilities in\nlanguage-based tasks. While language is a defining feature of human\nintelligence, it emerges from more fundamental neurophysical processes rather\nthan constituting the basis of intelligence itself. In this work, we study the\nsimilarity between LLM internal states and human brain activity in a\nsensory-motor task rooted in anticipatory and visuospatial behavior. These\nabilities are essential for cognitive performance that constitute human\nintelligence. We translate the sensory-motor task into natural language in\norder to replicate the process for LLMs. We extract hidden states from\npre-trained LLMs at key time steps and compare them to human intracranial EEG\nsignals. Our results reveal that LLM-derived reactions can be linearly mapped\nonto human neural activity. These findings suggest that LLMs, with a simple\nnatural language translation to make them understand temporal-relevant tasks,\ncan approximate human neurophysical behavior in experiments involving sensory\nstimulants. In all, our contribution is two-fold: (1) We demonstrate similarity\nbetween LLM and human brain activity beyond language-based tasks. (2) We\ndemonstrate that with such similarity, LLMs could help us understand human\nbrains by enabling us to study topics in neuroscience that are otherwise\nchallenging to tackle.", "AI": {"tldr": "The paper explores the similarities between human brain activity and the internal states of large language models (LLMs) during sensory-motor tasks, suggesting that LLMs can approximate human neurophysical behavior.", "motivation": "The authors aim to investigate whether LLM internal states exhibit similarities to human brain activity, particularly outside language-specific tasks, and assess LLMs' potential in studying neuroscience topics.", "method": "Researchers translated a sensory-motor task into natural language for LLMs, extracted their hidden states during key steps, and compared these states to human intracranial EEG signals to find correlations.", "result": "The study identified linear mappings between LLM reactions and human neural activity during sensory-motor tasks, demonstrating shared patterns of behavior between the two systems.", "conclusion": "LLMs show potential in aiding neuroscience research, as they can mimic human neurophysical responses beyond language domains when structured appropriately for tasks."}}
{"id": "2509.08989", "pdf": "https://arxiv.org/pdf/2509.08989", "abs": "https://arxiv.org/abs/2509.08989", "authors": ["Carina Newen", "Daniel Bodemer", "Sonja Glantz", "Emmanuel M\u00fcller", "Magdalena Wischnewski", "Lenka Schnaubert"], "title": "Uncertainty Awareness and Trust in Explainable AI- On Trust Calibration using Local and Global Explanations", "categories": ["cs.AI"], "comment": "9 pages, 6 figures, accepted but not yet published at ICDM2025", "summary": "Explainable AI has become a common term in the literature, scrutinized by\ncomputer scientists and statisticians and highlighted by psychological or\nphilosophical researchers. One major effort many researchers tackle is\nconstructing general guidelines for XAI schemes, which we derived from our\nstudy. While some areas of XAI are well studied, we focus on uncertainty\nexplanations and consider global explanations, which are often left out. We\nchose an algorithm that covers various concepts simultaneously, such as\nuncertainty, robustness, and global XAI, and tested its ability to calibrate\ntrust. We then checked whether an algorithm that aims to provide more of an\nintuitive visual understanding, despite being complicated to understand, can\nprovide higher user satisfaction and human interpretability.", "AI": {"tldr": "The paper investigates using an XAI algorithm covering uncertainty, robustness, and global explanations to improve trust and satisfaction.", "motivation": "To address the lesser-explored issues of uncertainty and global explanations in explainable AI while calibrating user trust and satisfaction.", "method": "The researchers selected an explainable algorithm capable of handling multiple concepts like uncertainty and global explanations and evaluated its visual intuitiveness and user satisfaction.", "result": "The algorithm demonstrated the potential to enhance trust, satisfaction, and interpretability, even if its workings are complex.", "conclusion": "XAI systems designed with a focus on uncertainty and global explanations can improve trust, user satisfaction, and interpretability."}}
{"id": "2509.09058", "pdf": "https://arxiv.org/pdf/2509.09058", "abs": "https://arxiv.org/abs/2509.09058", "authors": ["Ajay Kumar", "Praveen Rao", "Peter Sanders"], "title": "Optimizing the Variant Calling Pipeline Execution on Human Genomes Using GPU-Enabled Machines", "categories": ["cs.DC"], "comment": "To appear in 14th International Workshop on Parallel and AI-based\n  Bioinformatics and Biomedicine (ParBio), Philadelphia, 2025", "summary": "Variant calling is the first step in analyzing a human genome and aims to\ndetect variants in an individual's genome compared to a reference genome. Due\nto the computationally-intensive nature of variant calling, genomic data are\nincreasingly processed in cloud environments as large amounts of compute and\nstorage resources can be acquired with the pay-as-you-go pricing model. In this\npaper, we address the problem of efficiently executing a variant calling\npipeline for a workload of human genomes on graphics processing unit\n(GPU)-enabled machines. We propose a novel machine learning (ML)-based approach\nfor optimizing the workload execution to minimize the total execution time. Our\napproach encompasses two key techniques: The first technique employs ML to\npredict the execution times of different stages in a variant calling pipeline\nbased on the characteristics of a genome sequence. Using the predicted times,\nthe second technique generates optimal execution plans for the machines by\ndrawing inspiration from the flexible job shop scheduling problem. The plans\nare executed via careful synchronization across different machines. We\nevaluated our approach on a workload of publicly available genome sequences\nusing a testbed with different types of GPU hardware. We observed that our\napproach was effective in predicting the execution times of variant calling\npipeline stages using ML on features such as sequence size, read quality,\npercentage of duplicate reads, and average read length. In addition, our\napproach achieved 2X speedup (on an average) over a greedy approach that also\nused ML for predicting the execution times on the tested workload of sequences.\nFinally, our approach achieved 1.6X speedup (on an average) over a dynamic\napproach that executed the workload based on availability of resources without\nusing any ML-based time predictions.", "AI": {"tldr": "The paper introduces an ML-based approach to improve the efficiency of variant calling pipelines on GPU-enabled machines. The method effectively reduces the execution time compared to other approaches.", "motivation": "Human genome variant calling is computationally intensive, and optimizing its execution in cloud environments can significantly reduce cost and resource usage.", "method": "The authors use machine learning to predict the execution times of variant calling pipeline stages and optimize workload scheduling using concepts from the job shop scheduling problem.", "result": "The approach achieved a 2X speedup over a greedy ML-based approach and a 1.6X speedup over a dynamic resource-based approach on tested genome sequences.", "conclusion": "The proposed ML-based approach efficiently schedules workloads, reducing execution time significantly, and demonstrates the potential for broader applications in genomic data analysis."}}
{"id": "2509.08907", "pdf": "https://arxiv.org/pdf/2509.08907", "abs": "https://arxiv.org/abs/2509.08907", "authors": ["Imene Kolli", "Ario Saeid Vaghefi", "Chiara Colesanti Senni", "Shantam Raj", "Markus Leippold"], "title": "Automated Evidence Extraction and Scoring for Corporate Climate Policy Engagement: A Multilingual RAG Approach", "categories": ["cs.CL"], "comment": null, "summary": "InfluenceMap's LobbyMap Platform monitors the climate policy engagement of\nover 500 companies and 250 industry associations, assessing each entity's\nsupport or opposition to science-based policy pathways for achieving the Paris\nAgreement's goal of limiting global warming to 1.5{\\deg}C. Although\nInfluenceMap has made progress with automating key elements of the analytical\nworkflow, a significant portion of the assessment remains manual, making it\ntime- and labor-intensive and susceptible to human error. We propose an\nAI-assisted framework to accelerate the monitoring of corporate climate policy\nengagement by leveraging Retrieval-Augmented Generation to automate the most\ntime-intensive extraction of relevant evidence from large-scale textual data.\nOur evaluation shows that a combination of layout-aware parsing, the Nomic\nembedding model, and few-shot prompting strategies yields the best performance\nin extracting and classifying evidence from multilingual corporate documents.\nWe conclude that while the automated RAG system effectively accelerates\nevidence extraction, the nuanced nature of the analysis necessitates a\nhuman-in-the-loop approach where the technology augments, rather than replaces,\nexpert judgment to ensure accuracy.", "AI": {"tldr": "This paper proposed an AI-assisted framework to streamline corporate climate policy monitoring, reducing manual effort and improving evidence extraction from large-scale multilingual textual data using a Retrieval-Augmented Generation method.", "motivation": "Existing methods for monitoring corporate climate policy are time- and labor-intensive as they rely heavily on manual assessment, necessitating tools to streamline processes while maintaining accuracy.", "method": "The study utilized Retrieval-Augmented Generation (RAG) and tested techniques like layout-aware parsing, the Nomic embedding model, and few-shot prompting strategies for extracting and classifying data from multilingual corporate documents.", "result": "The proposed AI-assisted system significantly speeds up the evidence extraction process while demonstrating effective performance in handling multilingual textual data and maintaining the quality of analysis.", "conclusion": "Automating evidence extraction accelerates the analytical workflow, though human expertise remains essential to interpret nuanced insights, suggesting a hybrid human-in-the-loop system."}}
{"id": "2509.09059", "pdf": "https://arxiv.org/pdf/2509.09059", "abs": "https://arxiv.org/abs/2509.09059", "authors": ["Paulette Koronkevich", "William J. Bowman"], "title": "Dependent-Type-Preserving Memory Allocation", "categories": ["cs.PL"], "comment": "Submitted and received second place at the Student Research\n  Competition at Principles of Programming Languages 2022", "summary": "Dependently typed programming languages such as Coq, Agda, Idris, and F*,\nallow programmers to write detailed specifications of their programs and prove\ntheir programs meet these specifications. However, these specifications can be\nviolated during compilation since they are erased after type checking. External\nprograms linked with the compiled program can violate the specifications of the\noriginal program and change the behavior of the compiled program -- even when\ncompiled with a verified compiler. For example, since Coq does not allow\nexplicitly allocating memory, a programmer might link their Coq program with a\nC program that can allocate memory. Even if the Coq program is compiled with a\nverified compiler, the external C program can still violate the memory-safe\nspecification of the Coq program by providing an uninitialized pointer to\nmemory. This error could be ruled out by type checking in a language expressive\nenough to indicate whether memory is initialized versus uninitialized. Linking\nwith a program with an uninitialized pointer could be considered ill-typed, and\nour linking process could prevent linking with ill-typed programs. To\nfacilitate type checking during linking, we can use type-preserving\ncompilation, which preserves the types through the compilation process. In this\nongoing work, we develop a typed intermediate language that supports dependent\nmemory allocation, as well as a dependent-type-preserving compiler pass for\nmemory allocation.", "AI": {"tldr": "The paper identifies issues with dependently typed programming languages when linking with external programs, particularly memory safety. A typed intermediate language and a type-preserving compilation process are proposed to address these concerns.", "motivation": "Dependently typed languages lose their specifications after compilation, which can lead to violations when linking with external programs. The authors aim to minimize these specification violations, particularly for memory safety.", "method": "The authors propose a typed intermediate language and a dependent-type-preserving compiler pass specifically designed for memory allocation.", "result": "The work facilitates type checking during program linking, targeting errors like uninitialized memory pointers, which can undermine specifications.", "conclusion": "By preserving types through the compilation process, the approach ensures compatibility and eliminates ill-typed linking, improving the reliability of dependently typed languages."}}
{"id": "2509.08908", "pdf": "https://arxiv.org/pdf/2509.08908", "abs": "https://arxiv.org/abs/2509.08908", "authors": ["Rogerio Guimaraes", "Frank Xiao", "Pietro Perona", "Markus Marks"], "title": "Diffusion-Based Action Recognition Generalizes to Untrained Domains", "categories": ["cs.CV"], "comment": null, "summary": "Humans can recognize the same actions despite large context and viewpoint\nvariations, such as differences between species (walking in spiders vs.\nhorses), viewpoints (egocentric vs. third-person), and contexts (real life vs\nmovies). Current deep learning models struggle with such generalization. We\npropose using features generated by a Vision Diffusion Model (VDM), aggregated\nvia a transformer, to achieve human-like action recognition across these\nchallenging conditions. We find that generalization is enhanced by the use of a\nmodel conditioned on earlier timesteps of the diffusion process to highlight\nsemantic information over pixel level details in the extracted features. We\nexperimentally explore the generalization properties of our approach in\nclassifying actions across animal species, across different viewing angles, and\ndifferent recording contexts. Our model sets a new state-of-the-art across all\nthree generalization benchmarks, bringing machine action recognition closer to\nhuman-like robustness. Project page:\n$\\href{https://www.vision.caltech.edu/actiondiff/}{\\texttt{vision.caltech.edu/actiondiff}}$\nCode:\n$\\href{https://github.com/frankyaoxiao/ActionDiff}{\\texttt{github.com/frankyaoxiao/ActionDiff}}$", "AI": {"tldr": "The paper proposes using features generated by a Vision Diffusion Model (VDM), aggregated via a transformer, to achieve human-like action recognition across varying conditions. The method improves generalization and sets new state-of-the-art benchmarks.", "motivation": "Humans excel at recognizing actions across diverse conditions like species differences, viewing angles, and contexts, but deep learning models struggle with such generalizations. The study aims to address this gap.", "method": "The approach leverages features extracted by Vision Diffusion Models (VDMs) conditioned on earlier diffusion process timesteps, emphasizing semantic information. These features are aggregated via a transformer for improved action recognition.", "result": "Experimental validation demonstrated enhanced generalization across benchmarks including species variation, viewpoint differences, and recording contexts, achieving state-of-the-art performance.", "conclusion": "The proposed method significantly improves machine action recognition, advancing its robustness to human-like levels."}}
{"id": "2509.09024", "pdf": "https://arxiv.org/pdf/2509.09024", "abs": "https://arxiv.org/abs/2509.09024", "authors": ["Md Habib Ullah Khan", "Kaiyue Deng", "Ismail Mujtaba Khan", "Kelvin Fu"], "title": "Rapid Manufacturing of Lightweight Drone Frames Using Single-Tow Architected Composites", "categories": ["cs.RO", "physics.app-ph"], "comment": "23 pages, 5 figures", "summary": "The demand for lightweight and high-strength composite structures is rapidly\ngrowing in aerospace and robotics, particularly for optimized drone frames.\nHowever, conventional composite manufacturing methods struggle to achieve\ncomplex 3D architectures for weight savings and rely on assembling separate\ncomponents, which introduce weak points at the joints. Additionally,\nmaintaining continuous fiber reinforcement remains challenging, limiting\nstructural efficiency. In this study, we demonstrate the lightweight Face\nCentered Cubic (FFC) lattice structured conceptualization of drone frames for\nweight reduction and complex topology fabrication through 3D Fiber Tethering\n(3DFiT) using continuous single tow fiber ensuring precise fiber alignment,\neliminating weak points associated with traditional composite assembly.\nMechanical testing demonstrates that the fabricated drone frame exhibits a high\nspecific strength of around four to eight times the metal and thermoplastic,\noutperforming other conventional 3D printing methods. The drone frame weighs\nonly 260 g, making it 10% lighter than the commercial DJI F450 frame, enhancing\nstructural integrity and contributing to an extended flight time of three\nminutes, while flight testing confirms its stability and durability under\noperational conditions. The findings demonstrate the potential of single tow\nlattice truss-based drone frames, with 3DFiT serving as a scalable and\nefficient manufacturing method.", "AI": {"tldr": "This paper introduces 3D Fiber Tethering (3DFiT) for crafting lightweight lattice drone frames that are stronger, lighter, and more durable than conventional materials.", "motivation": "To address the limitations in traditional composite manufacturing methods in aerospace and robotics, including weak points in joins and challenges with fiber reinforcement.", "method": "The study develops Face Centered Cubic lattice drone frames using a new 3DFiT process which employs continuous single tow fiber alignment for precision and eliminating weak joints.", "result": "The drone frame crafted weighs 260 g, is 10% lighter than a commercial DJI F450 frame, offers 3 minutes of increased flight time, and has specific strength 4\u20138 times higher than traditional materials.", "conclusion": "Single tow lattice truss-based drone frames using 3DFiT are proven scalable, lightweight, and durable, suitable for aerospace and robotics applications."}}
{"id": "2509.08911", "pdf": "https://arxiv.org/pdf/2509.08911", "abs": "https://arxiv.org/abs/2509.08911", "authors": ["Weiyuan Gong", "Tongyang Li", "Xinzhao Wang", "Zhiyu Zhang"], "title": "Instance-Optimal Matrix Multiplicative Weight Update and Its Quantum Applications", "categories": ["cs.LG", "cs.AI", "cs.DS", "quant-ph", "stat.ML"], "comment": "47 pages", "summary": "The Matrix Multiplicative Weight Update (MMWU) is a seminal online learning\nalgorithm with numerous applications. Applied to the matrix version of the\nLearning from Expert Advice (LEA) problem on the $d$-dimensional spectraplex,\nit is well known that MMWU achieves the minimax-optimal regret bound of\n$O(\\sqrt{T\\log d})$, where $T$ is the time horizon. In this paper, we present\nan improved algorithm achieving the instance-optimal regret bound of\n$O(\\sqrt{T\\cdot S(X||d^{-1}I_d)})$, where $X$ is the comparator in the regret,\n$I_d$ is the identity matrix, and $S(\\cdot||\\cdot)$ denotes the quantum\nrelative entropy. Furthermore, our algorithm has the same computational\ncomplexity as MMWU, indicating that the improvement in the regret bound is\n``free''.\n  Technically, we first develop a general potential-based framework for matrix\nLEA, with MMWU being its special case induced by the standard exponential\npotential. Then, the crux of our analysis is a new ``one-sided'' Jensen's trace\ninequality built on a Laplace transform technique, which allows the application\nof general potential functions beyond exponential to matrix LEA. Our algorithm\nis finally induced by an optimal potential function from the vector LEA\nproblem, based on the imaginary error function.\n  Complementing the above, we provide a memory lower bound for matrix LEA, and\nexplore the applications of our algorithm in quantum learning theory. We show\nthat it outperforms the state of the art for learning quantum states corrupted\nby depolarization noise, random quantum states, and Gibbs states. In addition,\napplying our algorithm to linearized convex losses enables predicting nonlinear\nquantum properties, such as purity, quantum virtual cooling, and R\\'{e}nyi-$2$\ncorrelation.", "AI": {"tldr": "This paper presents an enhanced algorithm for the matrix version of Learning from Expert Advice (LEA), achieving improved instance-optimal regret bounds, while maintaining computational efficiency.", "motivation": "The motivation is to improve upon the minimax-optimal regret bound provided by the Matrix Multiplicative Weight Update (MMWU) algorithm and explore applications in quantum learning theory.", "method": "The authors develop a potential-based general framework for matrix LEA, utilize a new Jensen's trace inequality built on Laplace transform techniques, and adopt an optimal potential function inspired by the imaginary error function for vector LEA.", "result": "The algorithm achieves an instance-optimal regret bound of $O(\\sqrt{T\\cdot S(X||d^{-1}I_d)})$, improves upon MMWU without computational overhead, and shows superior performance in various quantum learning scenarios.", "conclusion": "The new algorithm improves regret bounds in matrix LEA for free computationally and has promising applications in quantum learning, enabling better handling of noisy and random quantum states as well as prediction of nonlinear quantum properties."}}
{"id": "2509.08857", "pdf": "https://arxiv.org/pdf/2509.08857", "abs": "https://arxiv.org/abs/2509.08857", "authors": ["Marcelino Garcia", "Renato Garcia", "Arthur Parizotto", "Andre Mendes", "Pedro Valle", "Ricardo Vilela", "Renato Balancieri", "Williamson Silva"], "title": "A Systematic Mapping Study on Chatbots in Programming Education", "categories": ["cs.SE", "cs.HC"], "comment": "18 pages, 1 figure, 3 tables", "summary": "Educational chatbots have gained prominence as support tools for teaching\nprogramming, particularly in introductory learning contexts. This paper\npresents a Systematic Mapping Study (SMS) that investigated how such agents\nhave been developed and applied in programming education. From an initial set\nof 3,216 publications, 54 studies were selected and analyzed based on five\nresearch subquestions, addressing chatbot types, programming languages used,\neducational content covered, interaction models, and application contexts. The\nresults reveal a predominance of chatbots designed for Python instruction,\nfocusing on fundamental programming concepts, and employing a wide variety of\npedagogical approaches and technological architectures. In addition to\nidentifying trends and gaps in the literature, this study provides insights to\ninform the development of new educational tools for programming instruction.", "AI": {"tldr": "A study analyzed 54 out of 3,216 publications on educational chatbots in programming education, revealing their focus on teaching Python and basic programming concepts.", "motivation": "To explore how educational chatbots are developed and applied for programming education, especially in introductory contexts.", "method": "Conducted a Systematic Mapping Study (SMS) analyzing 54 publications based on chatbot types, programming languages, educational content, interaction models, and application contexts.", "result": "Predominance of Python-focused chatbots that teach fundamental programming concepts using diverse pedagogical approaches and architectures.", "conclusion": "Trends in chatbot usage for programming education were identified, offering insights for creating innovative educational tools and addressing literary gaps."}}
{"id": "2509.09238", "pdf": "https://arxiv.org/pdf/2509.09238", "abs": "https://arxiv.org/abs/2509.09238", "authors": ["Thorbj\u00f8rn Mosekj\u00e6r Iversen", "Lars Car\u00f8e S\u00f8rensen", "Simon Faarvang Mathiesen", "Henrik Gordon Petersen"], "title": "Global Optimization of Stochastic Black-Box Functions with Arbitrary Noise Distributions using Wilson Score Kernel Density Estimation", "categories": ["stat.ML", "cs.LG", "cs.RO"], "comment": null, "summary": "Many optimization problems in robotics involve the optimization of\ntime-expensive black-box functions, such as those involving complex simulations\nor evaluation of real-world experiments. Furthermore, these functions are often\nstochastic as repeated experiments are subject to unmeasurable disturbances.\nBayesian optimization can be used to optimize such methods in an efficient\nmanner by deploying a probabilistic function estimator to estimate with a given\nconfidence so that regions of the search space can be pruned away.\nConsequently, the success of the Bayesian optimization depends on the function\nestimator's ability to provide informative confidence bounds. Existing function\nestimators require many function evaluations to infer the underlying confidence\nor depend on modeling of the disturbances. In this paper, it is shown that the\nconfidence bounds provided by the Wilson Score Kernel Density Estimator\n(WS-KDE) are applicable as excellent bounds to any stochastic function with an\noutput confined to the closed interval [0;1] regardless of the distribution of\nthe output. This finding opens up the use of WS-KDE for stable global\noptimization on a wider range of cost functions. The properties of WS-KDE in\nthe context of Bayesian optimization are demonstrated in simulation and applied\nto the problem of automated trap design for vibrational part feeders.", "AI": {"tldr": "The paper explores using the Wilson Score Kernel Density Estimator (WS-KDE) for Bayesian optimization of stochastic black-box functions, demonstrating its efficacy in simulations and vibrational part feeder design.", "motivation": "Optimizing stochastic black-box functions in robotics is challenging due to their time-expensive evaluations and susceptibility to unmeasurable disturbances.", "method": "The authors employ the Wilson Score Kernel Density Estimator (WS-KDE) to provide reliable confidence bounds for Bayesian optimization, effective for functions confined to [0,1], without requiring extensive evaluations or disturbance modeling.", "result": "WS-KDE is shown to be a robust confidence estimator for Bayesian optimization, extending its applicability for stable global optimization across more diverse cost functions.", "conclusion": "The study concludes that WS-KDE can enhance Bayesian optimization by providing stable and informative confidence bounds, making it suitable for a wider array of stochastic functions."}}
{"id": "2509.09505", "pdf": "https://arxiv.org/pdf/2509.09505", "abs": "https://arxiv.org/abs/2509.09505", "authors": ["Haoran Wu", "Can Xiao", "Jiayi Nie", "Xuan Guo", "Binglei Lou", "Jeffrey T. H. Wong", "Zhiwen Mo", "Cheng Zhang", "Przemyslaw Forys", "Wayne Luk", "Hongxiang Fan", "Jianyi Cheng", "Timothy M. Jones", "Rika Antonova", "Robert Mullins", "Aaron Zhao"], "title": "Combating the Memory Walls: Optimization Pathways for Long-Context Agentic LLM Inference", "categories": ["cs.AR"], "comment": null, "summary": "LLMs now form the backbone of AI agents for a diverse array of applications,\nincluding tool use, command-line agents, and web or computer use agents. These\nagentic LLM inference tasks are fundamentally different from chatbot-focused\ninference -- they often have much larger context lengths to capture complex,\nprolonged inputs, such as entire webpage DOMs or complicated tool call\ntrajectories. This, in turn, generates significant off-chip memory traffic for\nthe underlying hardware at the inference stage and causes the workload to be\nconstrained by two memory walls, namely the bandwidth and capacity memory\nwalls, preventing the on-chip compute units from achieving high utilization.\n  In this paper, we introduce PLENA, a hardware-software co-designed system\nthat applies three core optimization pathways to tackle these challenges. PLENA\nincludes an efficient hardware implementation of compute and memory units\nsupporting an asymmetric quantization scheme. PLENA also features a novel\nflattened systolic array architecture that has native support for\nFlashAttention to tackle these memory walls in the scenario of inference\nserving for long-context LLMs. Additionally, PLENA is developed with a complete\nstack, including a custom ISA, a compiler, a cycle-emulated simulator, and an\nautomated design space exploration flow. The simulated results show that PLENA\nachieves up to 8.5x higher utilization than existing accelerators, and delivers\n2.24x higher throughput than the A100 GPU and 3.85x higher throughput than the\nTPU v6e, under the same multiplier count and memory settings. The full PLENA\nsystem will also be open-sourced.", "AI": {"tldr": "PLENA, a hardware-software co-designed system, addresses memory bottlenecks in long-context LLM inference tasks, significantly boosting throughput compared to GPUs and TPUs.", "motivation": "The paper seeks to mitigate the challenges of off-chip memory traffic and memory walls in LLM inference workloads for applications requiring prolonged contexts, such as web agents and tool use.", "method": "PLENA integrates asymmetric quantization, a novel flattened systolic array architecture optimized for FlashAttention, and a complete stack including ISA, compiler, and design tools.", "result": "Simulated results show PLENA achieves up to 8.5x higher utilization, 2.24x higher throughput compared to the A100 GPU, and 3.85x higher throughput compared to the TPU v6e.", "conclusion": "PLENA addresses hardware inefficiencies in LLM inference workflows for long contexts, offering significant performance improvements and will be open-sourced for community use."}}
{"id": "2509.09529", "pdf": "https://arxiv.org/pdf/2509.09529", "abs": "https://arxiv.org/abs/2509.09529", "authors": ["Shangqing Shi", "Luoxiao Zhang", "Yuchen Yin", "Xiong Yang", "Hoileong Lee"], "title": "A modified RIME algorithm with covariance learning and diversity enhancement for numerical optimization", "categories": ["cs.NE", "cs.AI", "cs.CE"], "comment": "This is the author's preprint of the article published in Cluster\n  Computing (Springer): Shi, S., Zhang, L., Yin, Y. et al. A modified RIME\n  algorithm with covariance learning and diversity enhancement for numerical\n  optimization. Cluster Comput 28, 658 (2025). The final authenticated version\n  is available online at SpringerLink", "summary": "Metaheuristics are widely applied for their ability to provide more efficient\nsolutions. The RIME algorithm is a recently proposed physical-based\nmetaheuristic algorithm with certain advantages. However, it suffers from rapid\nloss of population diversity during optimization and is prone to fall into\nlocal optima, leading to unbalanced exploitation and exploration. To address\nthe shortcomings of RIME, this paper proposes a modified RIME with covariance\nlearning and diversity enhancement (MRIME-CD). The algorithm applies three\nstrategies to improve the optimization capability. First, a covariance learning\nstrategy is introduced in the soft-rime search stage to increase the population\ndiversity and balance the over-exploitation ability of RIME through the\nbootstrapping effect of dominant populations. Second, in order to moderate the\ntendency of RIME population to approach the optimal individual in the early\nsearch stage, an average bootstrapping strategy is introduced into the\nhard-rime puncture mechanism, which guides the population search through the\nweighted position of the dominant populations, thus enhancing the global search\nability of RIME in the early stage. Finally, a new stagnation indicator is\nproposed, and a stochastic covariance learning strategy is used to update the\nstagnant individuals in the population when the algorithm gets stagnant, thus\nenhancing the ability to jump out of the local optimal solution. The proposed\nMRIME-CD algorithm is subjected to a series of validations on the CEC2017 test\nset, the CEC2022 test set, and the experimental results are analyzed using the\nFriedman test, the Wilcoxon rank sum test, and the Kruskal Wallis test. The\nresults show that MRIME-CD can effectively improve the performance of basic\nRIME and has obvious superiorities in terms of solution accuracy, convergence\nspeed and stability.", "AI": {"tldr": "The paper introduces MRIME-CD, an enhanced version of the RIME metaheuristic algorithm, addressing issues like population diversity loss and local optima stagnation through new strategies to improve optimization performance.", "motivation": "The motivation behind the paper is to tackle the weaknesses of the original RIME algorithm, particularly its rapid loss of population diversity and tendency to fall into local optima, which hinder its exploitation and exploration capabilities.", "method": "MRIME-CD incorporates three strategies: covariance learning to assist diversity, bootstrapping for global search enhancement, and stochastic updates for stagnant individuals. It utilizes rigorous statistical tests for validation using datasets like CEC2017 and CEC2022.", "result": "The experimental validations highlight MRIME-CD's superior results compared to the original RIME, showing improved solution accuracy, faster convergence, and greater stability.", "conclusion": "MRIME-CD effectively resolves the limitations of RIME by improving overall optimization performance while maintaining balance between exploitation and exploration."}}
{"id": "2509.09213", "pdf": "https://arxiv.org/pdf/2509.09213", "abs": "https://arxiv.org/abs/2509.09213", "authors": ["Alireza Irandoost", "Amirreza Bahramani", "Roya Mohajeri", "Faezeh Shahdost-Fard", "Ali Ghazizadeh", "Mehdi Fardmanesh"], "title": "A novel cost-effective fabrication of a flexible neural probe for brain signal recording", "categories": ["q-bio.NC"], "comment": null, "summary": "This study introduces a novel, flexible, and implantable neural probe using a\ncost-effective microfabrication process based on a thin polyimide film.\nPolyimide film, known as Kapton, serves as a flexible substrate for\nmicroelectrodes, conductive tracks, and contact pads of the probe, which are\nmade from a thin film of gold (Au). SU-8 is used to cover the corresponding\ntracks for electrical isolation and to increase the stiffness of the probe for\nbetter implantation. To evaluate the performance of the fabricated probe,\nelectrochemical impedance spectroscopy (EIS) and artificial neural signal\nrecording have been used to characterize its properties. The microelectrode\ndimensions have been carefully chosen to provide low impedance characteristics,\nwhich are necessary for acquiring local field potential (LFP) signals. The in\nvivo LFP data have been obtained from a male zebra finch presented with\nauditory stimuli. By properly filtering the extracellular recordings and\nanalyzing the data, the obtained results have been validated by comparing them\nwith the signals acquired with a commercial neural electrode. Due to the use of\nKapton, SU-8, and Au materials with non-toxic and adaptable properties in the\nbody environment, the fabricated neural probe is considered a promising\nbiocompatible implantable neural probe that may pave the way for the\nfabrication of other neural implantable devices with commercial aims.", "AI": {"tldr": "The study presents a cost-effective, flexible neural probe using polyimide film, gold, and SU-8 materials, tested successfully for neural signal recording with zebra finch models.", "motivation": "The paper aims to develop a biocompatible, implantable neural probe using cost-effective materials and techniques to improve neural signal recording while being suitable for commercial applications.", "method": "The process uses microfabrication with polyimide film (Kapton) as the substrate, gold for electrodes and tracks, SU-8 for isolation and stiffness, followed by validation using electrochemical spectroscopy and in vivo neural signal recording.", "result": "The neural probe exhibited low impedance and successfully recorded local field potential signals, validated against commercial electrodes using auditory stimuli on zebra finches.", "conclusion": "The probe's biocompatibility and effective performance suggest its potential for medical applications and commercialization of flexible neural implantable devices."}}
{"id": "2509.09066", "pdf": "https://arxiv.org/pdf/2509.09066", "abs": "https://arxiv.org/abs/2509.09066", "authors": ["Haowei Yang", "Yushang Zhao", "Sitao Min", "Bo Su", "Chao Yao", "Wei Xu"], "title": "Instructional Prompt Optimization for Few-Shot LLM-Based Recommendations on Cold-Start Users", "categories": ["cs.AI"], "comment": null, "summary": "The cold-start user issue further compromises the effectiveness of\nrecommender systems in limiting access to the historical behavioral\ninformation. It is an effective pipeline to optimize instructional prompts on a\nfew-shot large language model (LLM) used in recommender tasks. We introduce a\ncontext-conditioned prompt formulation method P(u,\\ Ds)\\ \\rightarrow\\\nR\\widehat, where u is a cold-start user profile, Ds is a curated support set,\nand R\\widehat is the predicted ranked list of items. Based on systematic\nexperimentation with transformer-based autoregressive LLMs (BioGPT, LLaMA-2,\nGPT-4), we provide empirical evidence that optimal exemplar injection and\ninstruction structuring can significantly improve the precision@k and NDCG\nscores of such models in low-data settings. The pipeline uses token-level\nalignments and embedding space regularization with a greater semantic fidelity.\nOur findings not only show that timely composition is not merely syntactic but\nalso functional as it is in direct control of attention scales and decoder\nconduct through inference. This paper shows that prompt-based adaptation may be\nconsidered one of the ways to address cold-start recommendation issues in\nLLM-based pipelines.", "AI": {"tldr": "The paper explores addressing cold-start user issues in recommender systems by optimizing prompts in few-shot large language models, showing improvements in recommendation accuracy metrics.", "motivation": "Recommender systems face challenges in handling cold-start users due to limited historical data. Optimizing LLM-based prompts is proposed as a solution to enhance recommendations.", "method": "The authors propose a context-conditioned prompt formulation method using transformer-based LLMs with techniques like exemplar injection, token-level alignments, and embedding space regularization.", "result": "Systematic experimentation demonstrated improved precision@k and NDCG scores for LLMs in low-data settings through optimal prompt adjustments.", "conclusion": "Prompt-based adaptation for LLMs is an effective approach to mitigate cold-start recommendation issues, improving model functionality and attention control."}}
{"id": "2509.09094", "pdf": "https://arxiv.org/pdf/2509.09094", "abs": "https://arxiv.org/abs/2509.09094", "authors": ["Guochu Xiong", "Xiangzhong Luo", "Weichen Liu"], "title": "Coherence-Aware Task Graph Modeling for Realistic Application", "categories": ["cs.DC"], "comment": "Accepted by MEMOCODE'25, 10 pages", "summary": "As multicore systems continue to scale, cache coherence has emerged as a\ncritical determinant of system performance, with coherence behavior and task\nexecution closely intertwined, reshaping inter-task dependencies. Task graph\nmodeling provides a structured way to capture such dependencies and serves as\nthe foundation for many system-level design strategies. However, these\nstrategies typically rely on predefined task graphs, while many real-world\napplications lack explicit graphs and exhibit dynamic, data-dependent behavior,\nlimiting the effectiveness of static approaches. To address this, several task\ngraph modeling methods for realistic workloads have been developed. Yet, they\neither rely on implicit techniques that use application-specific features\nwithout producing explicit graphs, or they generate graphs tailored to fixed\nscheduling models, which limits generality. More importantly, they often\noverlook coherence interactions, creating a gap between design assumptions and\nactual runtime behavior. To overcome these limitations, we propose CoTAM, a\nCoherence-Aware Task Graph Modeling framework for realistic workloads that\nconstructs a unified task graph reflecting runtime behavior. CoTAM analyzes the\nimpact of coherence by decoupling its effects from overall execution,\nquantifies its influence through a learned weighting scheme, and infers\ninter-task dependencies for coherence-aware graph generation. Extensive\nexperiments show that CoTAM outperforms implicit methods, bridging the gap\nbetween dynamic workload behavior and existing designs while demonstrating the\nimportance of incorporating cache coherence into task graph modeling for\naccurate and generalizable system-level analysis.", "AI": {"tldr": "CoTAM is a novel framework to model task graphs for multicore systems, explicitly addressing cache coherence, a factor often overlooked in existing methods.", "motivation": "Static task graph approaches fail for dynamic, data-dependent behaviors in realistic workloads, and current methods inadequately address cache coherence.", "method": "CoTAM decouples coherence effects from execution, uses a learned weighting scheme to quantify its impact, and generates coherence-aware task graphs.", "result": "Extensive experiments prove CoTAM's efficiency, validating its ability to bridge the gap between workload behavior and system designs while modeling cache coherence interactions.", "conclusion": "CoTAM enhances accuracy and generality in system-level analysis by explicitly incorporating cache coherence into task graph modeling."}}
{"id": "2509.08920", "pdf": "https://arxiv.org/pdf/2509.08920", "abs": "https://arxiv.org/abs/2509.08920", "authors": ["Jinsong Chen"], "title": "Documents Are People and Words Are Items: A Psychometric Approach to Textual Data with Contextual Embeddings", "categories": ["cs.CL", "stat.AP", "stat.ME"], "comment": null, "summary": "This research introduces a novel psychometric method for analyzing textual\ndata using large language models. By leveraging contextual embeddings to create\ncontextual scores, we transform textual data into response data suitable for\npsychometric analysis. Treating documents as individuals and words as items,\nthis approach provides a natural psychometric interpretation under the\nassumption that certain keywords, whose contextual meanings vary significantly\nacross documents, can effectively differentiate documents within a corpus. The\nmodeling process comprises two stages: obtaining contextual scores and\nperforming psychometric analysis. In the first stage, we utilize natural\nlanguage processing techniques and encoder based transformer models to identify\ncommon keywords and generate contextual scores. In the second stage, we employ\nvarious types of factor analysis, including exploratory and bifactor models, to\nextract and define latent factors, determine factor correlations, and identify\nthe most significant words associated with each factor. Applied to the Wiki\nSTEM corpus, our experimental results demonstrate the method's potential to\nuncover latent knowledge dimensions and patterns within textual data. This\napproach not only enhances the psychometric analysis of textual data but also\nholds promise for applications in fields rich in textual information, such as\neducation, psychology, and law.", "AI": {"tldr": "This paper introduces a method for psychometric analysis of textual data using large language models, transforming documents into analyzable response data by creating contextual scores based on keywords.", "motivation": "The motivation is to develop a systematic approach for analyzing latent knowledge and patterns in textual data, addressing challenges in psychometric analysis using modern language model techniques.", "method": "Two stages are used: (1) deriving contextual scores from text using transformer models and NLP techniques, and (2) applying factor analysis methods to extract latent factors and identify key words tied to each factor.", "result": "Applying the method to the Wiki STEM corpus, the approach effectively uncovers latent knowledge dimensions and patterns, validating the technique's applicability.", "conclusion": "The paper concludes that this method enriches psychometric analysis of textual data and can be extended to diverse fields with abundant textual resources like education and law."}}
{"id": "2509.08910", "pdf": "https://arxiv.org/pdf/2509.08910", "abs": "https://arxiv.org/abs/2509.08910", "authors": ["Tung Vu", "Lam Nguyen", "Quynh Dao"], "title": "PromptGuard: An Orchestrated Prompting Framework for Principled Synthetic Text Generation for Vulnerable Populations using LLMs with Enhanced Safety, Fairness, and Controllability", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The proliferation of Large Language Models (LLMs) in real-world applications\nposes unprecedented risks of generating harmful, biased, or misleading\ninformation to vulnerable populations including LGBTQ+ individuals, single\nparents, and marginalized communities. While existing safety approaches rely on\npost-hoc filtering or generic alignment techniques, they fail to proactively\nprevent harmful outputs at the generation source. This paper introduces\nPromptGuard, a novel modular prompting framework with our breakthrough\ncontribution: VulnGuard Prompt, a hybrid technique that prevents harmful\ninformation generation using real-world data-driven contrastive learning.\nVulnGuard integrates few-shot examples from curated GitHub repositories,\nethical chain-of-thought reasoning, and adaptive role-prompting to create\npopulation-specific protective barriers. Our framework employs theoretical\nmulti-objective optimization with formal proofs demonstrating 25-30% analytical\nharm reduction through entropy bounds and Pareto optimality. PromptGuard\norchestrates six core modules: Input Classification, VulnGuard Prompting,\nEthical Principles Integration, External Tool Interaction, Output Validation,\nand User-System Interaction, creating an intelligent expert system for\nreal-time harm prevention. We provide comprehensive mathematical formalization\nincluding convergence proofs, vulnerability analysis using information theory,\nand theoretical validation framework using GitHub-sourced datasets,\nestablishing mathematical foundations for systematic empirical research.", "AI": {"tldr": "The paper introduces PromptGuard, a modular prompting framework with VulnGuard Prompt for proactively preventing harmful outputs in Large Language Models (LLMs).", "motivation": "The proliferation of LLMs in real-world applications risks generating harmful, biased, or misleading information that affects vulnerable populations such as LGBTQ+ individuals, single parents, and marginalized communities.", "method": "The authors propose PromptGuard, which is a modular prompting framework. Its highlight, VulnGuard Prompt, uses hybrid techniques combining real-world data-driven contrastive learning, few-shot examples from GitHub repositories, ethical reasoning, and adaptive role-prompting. The framework integrates modules like Input Classification, Ethical Principles Integration, External Tool Interaction, among others.", "result": "PromptGuard demonstrates 25-30% harm reduction analytically through entropy bounds and Pareto optimality. It employs formal proofs regarding theoretical multi-objective optimization and vulnerability analysis using information theory.", "conclusion": "PromptGuard establishes a novel, mathematically-backed approach to real-time harm prevention in LLMs through its modular and population-specific methodology, setting a foundation for systematic empirical research."}}
{"id": "2509.09074", "pdf": "https://arxiv.org/pdf/2509.09074", "abs": "https://arxiv.org/abs/2509.09074", "authors": ["Alice Kate Li", "Thales C Silva", "Victoria Edwards", "Vijay Kumar", "M. Ani Hsieh"], "title": "KoopMotion: Learning Almost Divergence Free Koopman Flow Fields for Motion Planning", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Accepted to CoRL 2025 (Conference on Robot Learning). 15 pages 11\n  figures", "summary": "In this work, we propose a novel flow field-based motion planning method that\ndrives a robot from any initial state to a desired reference trajectory such\nthat it converges to the trajectory's end point. Despite demonstrated efficacy\nin using Koopman operator theory for modeling dynamical systems, Koopman does\nnot inherently enforce convergence to desired trajectories nor to specified\ngoals -- a requirement when learning from demonstrations (LfD). We present\nKoopMotion which represents motion flow fields as dynamical systems,\nparameterized by Koopman Operators to mimic desired trajectories, and leverages\nthe divergence properties of the learnt flow fields to obtain smooth motion\nfields that converge to a desired reference trajectory when a robot is placed\naway from the desired trajectory, and tracks the trajectory until the end\npoint. To demonstrate the effectiveness of our approach, we show evaluations of\nKoopMotion on the LASA human handwriting dataset and a 3D manipulator\nend-effector trajectory dataset, including spectral analysis. We also perform\nexperiments on a physical robot, verifying KoopMotion on a miniature autonomous\nsurface vehicle operating in a non-static fluid flow environment. Our approach\nis highly sample efficient in both space and time, requiring only 3\\% of the\nLASA dataset to generate dense motion plans. Additionally, KoopMotion provides\na significant improvement over baselines when comparing metrics that measure\nspatial and temporal dynamics modeling efficacy.", "AI": {"tldr": "This paper introduces KoopMotion, a method based on Koopman Operators to design motion planning systems that ensure robots smoothly follow desired trajectories and converge to desired endpoints.", "motivation": "To address the limitation of existing Koopman operator theory in ensuring smooth trajectory following and endpoint convergence in motion planning tasks, especially essential in learning from demonstrations.", "method": "KoopMotion represents motion flow fields as dynamical systems parameterized by Koopman Operators, ensuring divergence properties that allow robots to converge to reference trajectories and endpoints.", "result": "KoopMotion demonstrated effectiveness on datasets such as LASA handwriting and 3D manipulator trajectories, as well as physical experiments with autonomous robots. It achieved high efficiency, requiring only 3% of LASA data for dense motion plans, and outperformed baselines in modeling spatial and temporal dynamics.", "conclusion": "KoopMotion is a sample-efficient solution for motion planning in dynamic environments, offering smooth trajectory tracking and endpoint convergence with significant efficacy improvements over alternative methods."}}
{"id": "2509.08933", "pdf": "https://arxiv.org/pdf/2509.08933", "abs": "https://arxiv.org/abs/2509.08933", "authors": ["Sreejeet Maity", "Aritra Mitra"], "title": "Corruption-Tolerant Asynchronous Q-Learning with Near-Optimal Rates", "categories": ["cs.LG", "cs.SY", "eess.SY", "math.OC"], "comment": null, "summary": "We consider the problem of learning the optimal policy in a discounted,\ninfinite-horizon reinforcement learning (RL) setting where the reward signal is\nsubject to adversarial corruption. Such corruption, which may arise from\nextreme noise, sensor faults, or malicious attacks, can severely degrade the\nperformance of classical algorithms such as Q-learning. To address this\nchallenge, we propose a new provably robust variant of the Q-learning algorithm\nthat operates effectively even when a fraction of the observed rewards are\narbitrarily perturbed by an adversary. Under the asynchronous sampling model\nwith time-correlated data, we establish that despite adversarial corruption,\nthe finite-time convergence rate of our algorithm matches that of existing\nresults for the non-adversarial case, up to an additive term proportional to\nthe fraction of corrupted samples. Moreover, we derive an information-theoretic\nlower bound revealing that the additive corruption term in our upper bounds is\nunavoidable.\n  Next, we propose a variant of our algorithm that requires no prior knowledge\nof the statistics of the true reward distributions. The analysis of this\nsetting is particularly challenging and is enabled by carefully exploiting a\nrefined Azuma-Hoeffding inequality for almost-martingales, a technical tool\nthat might be of independent interest. Collectively, our contributions provide\nthe first finite-time robustness guarantees for asynchronous Q-learning,\nbridging a significant gap in robust RL.", "AI": {"tldr": "The paper introduces a robust Q-learning algorithm for reinforcement learning in the presence of adversarially corrupted reward signals, ensuring finite-time convergence despite such perturbations.", "motivation": "Address the challenge of learning optimal policies in reinforcement learning settings where reward signals can be disrupted by adversarial corruption, which degrades the performance of classical algorithms.", "method": "Propose a variant of Q-learning with provable robustness against reward corruption, establish finite-time convergence rate matching non-adversarial cases, and derive information-theoretic bounds. Explore an adaptation requiring no prior knowledge on reward statistics using refined mathematical tools.", "result": "The robust Q-learning variant shows finite-time convergence resilience against adversarial reward corruption, with an unavoidable additive term proportional to corrupted samples. A second variant handles unknown reward statistics effectively.", "conclusion": "This work bridges the gap in robust reinforcement learning by providing finite-time robustness guarantees for asynchronous Q-learning, even under adversarial corruption conditions."}}
{"id": "2509.08863", "pdf": "https://arxiv.org/pdf/2509.08863", "abs": "https://arxiv.org/abs/2509.08863", "authors": ["Qianqian Luo", "Liuchang Xu", "Qingming Lin", "Sensen Wu", "Ruichen Mao", "Chao Wang", "Hailin Feng", "Bo Huang", "Zhenhong Du"], "title": "GeoJSON Agents:A Multi-Agent LLM Architecture for Geospatial Analysis-Function Calling vs Code Generation", "categories": ["cs.SE"], "comment": null, "summary": "LLMs have made substantial progress in task automation and natural language\nunderstanding.However,without expertise in GIS,they continue to encounter\nlimitations.To address these issues, we propose GeoJSON Agents-a multi-agent\nLLM architecture.This framework transforms natural language tasks into\nstructured GeoJSON operation commands and processes spatial data using two\nwidely adopted LLM enhancement techniques:Function Calling and Code\nGeneration.The architecture consists of three components-task parsing,agent\ncollaboration,and result integration-aimed at enhancing both the performance\nand scalability of GIS automation.The Planner agent interprets natural language\ntasks into structured GeoJSON commands.Then,specialized Worker agents\ncollaborate according to assigned roles to perform spatial data processing and\nanalysis,either by invoking predefined function APIs or by dynamically\ngenerating and executing Python-based spatial analysis code.Finally,the system\nintegrates the outputs from multiple execution rounds into\nreusable,standards-compliant GeoJSON files.To systematically evaluate the\nperformance of the two approaches,we constructed a benchmark dataset of 70\ntasks with varying complexity and conducted experiments using OpenAI's GPT-4o\nas the core model.Results indicate that the Function Calling-based GeoJSON\nAgent achieved an accuracy of 85.71%,while the Code Generation-based agent\nreached 97.14%,both significantly outperforming the best-performing\ngeneral-purpose model (48.57%).Further analysis reveals that the Code\nGeneration provides greater flexibility,whereas the Function Calling approach\noffers more stable execution.This study is the first to introduce an LLM\nmulti-agent framework for GeoJSON data and to compare the strengths and\nlimitations of two mainstream LLM enhancement methods,offering new perspectives\nfor improving GeoAI system performance.", "AI": {"tldr": "The paper introduces GeoJSON Agents, a multi-agent LLM framework, using Function Calling and Code Generation techniques to automate GIS tasks with improved performance and scalability.", "motivation": "LLMs face limitations in handling GIS tasks due to the complexity of spatial data processing and analysis.", "method": "The framework uses Planner agents to convert natural language tasks into GeoJSON commands and Worker agents to process spatial data via function APIs or Python code generation.", "result": "The Code Generation approach achieved 97.14% accuracy, outperforming Function Calling (85.71%) and a general-purpose model (48.57%), demonstrating flexibility and stability advantages.", "conclusion": "This study establishes a novel LLM-based multi-agent framework for GeoJSON tasks, systematically evaluating two enhancement techniques and offering insights for enhancing GeoAI performance."}}
{"id": "2509.09353", "pdf": "https://arxiv.org/pdf/2509.09353", "abs": "https://arxiv.org/abs/2509.09353", "authors": ["Alexandra Carpentier", "Simone Maria Giancola", "Christophe Giraud", "Nicolas Verzelen"], "title": "Low-degree lower bounds via almost orthonormal bases", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Low-degree polynomials have emerged as a powerful paradigm for providing\nevidence of statistical-computational gaps across a variety of high-dimensional\nstatistical models [Wein25]. For detection problems -- where the goal is to\ntest a planted distribution $\\mathbb{P}'$ against a null distribution\n$\\mathbb{P}$ with independent components -- the standard approach is to bound\nthe advantage using an $\\mathbb{L}^2(\\mathbb{P})$-orthonormal family of\npolynomials. However, this method breaks down for estimation tasks or more\ncomplex testing problems where $\\mathbb{P}$ has some planted structures, so\nthat no simple $\\mathbb{L}^2(\\mathbb{P})$-orthogonal polynomial family is\navailable. To address this challenge, several technical workarounds have been\nproposed [SW22,SW25], though their implementation can be delicate. In this\nwork, we propose a more direct proof strategy. Focusing on random graph models,\nwe construct a basis of polynomials that is almost orthonormal under\n$\\mathbb{P}$, in precisely those regimes where statistical-computational gaps\narise. This almost orthonormal basis not only yields a direct route to\nestablishing low-degree lower bounds, but also allows us to explicitly identify\nthe polynomials that optimize the low-degree criterion. This, in turn, provides\ninsights into the design of optimal polynomial-time algorithms. We illustrate\nthe effectiveness of our approach by recovering known low-degree lower bounds,\nand establishing new ones for problems such as hidden subcliques, stochastic\nblock models, and seriation models.", "AI": {"tldr": "The paper focuses on constructing almost orthonormal polynomial bases for random graph models to better understand statistical-computational gaps and optimize low-degree bounds in high-dimensional testing problems.", "motivation": "Traditional methods for analyzing statistical-computational gaps in detection problems fail for estimation tasks or complex testing scenarios with planted structures, necessitating new techniques.", "method": "The authors propose constructing a nearly orthonormal basis of polynomials under specific statistical regimes in random graph models, targeting areas where statistical-computational gaps emerge.", "result": "The new basis provides a direct method for low-degree lower bounds, allows identification of optimal low-degree criterion polynomials, and recovers known bounds while establishing new ones for various models.", "conclusion": "This approach simplifies proving statistical-computational gaps and has algorithmic implications by revealing the design of optimal polynomial-time methods."}}
{"id": "2509.09400", "pdf": "https://arxiv.org/pdf/2509.09400", "abs": "https://arxiv.org/abs/2509.09400", "authors": ["Valerio Besozzi", "Enrico Fiasco", "Marco Danelutto", "Patrizio Dazzi"], "title": "WebAssembly and Unikernels: A Comparative Study for Serverless at the Edge", "categories": ["cs.DC", "cs.PF"], "comment": "Accepted at VHPC25", "summary": "Serverless computing at the edge requires lightweight execution environments\nto minimize cold start latency, especially in Urgent Edge Computing (UEC). This\npaper compares WebAssembly and unikernel-based MicroVMs for serverless\nworkloads. We present Limes, a WebAssembly runtime built on Wasmtime, and\nevaluate it against the Firecracker-based environment used in SPARE. Results\nshow that WebAssembly offers lower cold start times for lightweight functions\nbut suffers with complex workloads, while Firecracker provides higher, but\nstable, cold starts and better execution performance, particularly for\nI/O-heavy tasks.", "AI": {"tldr": "The paper compares performance of WebAssembly and Firecracker MicroVMs for serverless computing at the edge, focusing on cold start latency and workload execution.", "motivation": "The paper seeks to identify the most suitable lightweight execution environment for minimizing cold start latency in urgent edge computing scenarios, where quick response is crucial.", "method": "The study introduces Limes, a WebAssembly runtime built on Wasmtime, and compares its performance to Firecracker MicroVMs using serverless workloads.", "result": "WebAssembly provides lower cold start times for lightweight functions, while Firecracker shows stable cold starts and superior performance for I/O-heavy tasks.", "conclusion": "WebAssembly is advantageous for lightweight tasks due to its reduced latency, but Firecracker is better suited for complex and I/O-intensive workloads in serverless edge computing."}}
{"id": "2509.09552", "pdf": "https://arxiv.org/pdf/2509.09552", "abs": "https://arxiv.org/abs/2509.09552", "authors": ["Baoqi Zhao", "Xiong Yang", "Hoileong Lee", "Bowen Dong"], "title": "An improved educational competition optimizer with multi-covariance learning operators for global optimization problems", "categories": ["cs.NE", "cs.AI", "cs.CE"], "comment": "Submitted to Cluster Computing", "summary": "The educational competition optimizer is a recently introduced metaheuristic\nalgorithm inspired by human behavior, originating from the dynamics of\neducational competition within society. Nonetheless, ECO faces constraints due\nto an imbalance between exploitation and exploration, rendering it susceptible\nto local optima and demonstrating restricted effectiveness in addressing\ncomplex optimization problems. To address these limitations, this study\npresents an enhanced educational competition optimizer (IECO-MCO) utilizing\nmulti-covariance learning operators. In IECO, three distinct covariance\nlearning operators are introduced to improve the performance of ECO. Each\noperator effectively balances exploitation and exploration while preventing\npremature convergence of the population. The effectiveness of IECO is assessed\nthrough benchmark functions derived from the CEC 2017 and CEC 2022 test suites,\nand its performance is compared with various basic and improved algorithms\nacross different categories. The results demonstrate that IECO-MCO surpasses\nthe basic ECO and other competing algorithms in convergence speed, stability,\nand the capability to avoid local optima. Furthermore, statistical analyses,\nincluding the Friedman test, Kruskal-Wallis test, and Wilcoxon rank-sum test,\nare conducted to validate the superiority of IECO-MCO over the compared\nalgorithms. Compared with the basic algorithm (improved algorithm), IECO-MCO\nachieved an average ranking of 2.213 (2.488) on the CE2017 and CEC2022 test\nsuites. Additionally, the practical applicability of the proposed IECO-MCO\nalgorithm is verified by solving constrained optimization problems. The\nexperimental outcomes demonstrate the superior performance of IECO-MCO in\ntackling intricate optimization problems, underscoring its robustness and\npractical effectiveness in real-world scenarios.", "AI": {"tldr": "The paper enhances the Educational Competition Optimizer (ECO) by introducing a new algorithm, IECO-MCO, which uses multi-covariance learning operators to balance exploration and exploitation, outperforming previous methods in terms of speed, stability, and avoiding local optima.", "motivation": "The original ECO algorithm struggles with imbalances in exploration and exploitation, making it prone to local optima and limiting its utility in complex optimization problems.", "method": "The paper introduces IECO-MCO, which implements three multi-covariance learning operators to improve exploration, exploitation, and population convergence. It validates performance on benchmark functions and conducts statistical tests.", "result": "IECO-MCO outperforms the original ECO and other algorithms, achieving faster convergence, greater stability, and better avoidance of local optima in multiple benchmark tests.", "conclusion": "IECO-MCO is robust and effective for solving complex optimization problems, demonstrating superior performance over existing methods and practical feasibility for constrained real-world scenarios."}}
{"id": "2509.09152", "pdf": "https://arxiv.org/pdf/2509.09152", "abs": "https://arxiv.org/abs/2509.09152", "authors": ["Taha Binhuraib", "Ruimin Gao", "Anna A. Ivanova"], "title": "LITcoder: A General-Purpose Library for Building and Comparing Encoding Models", "categories": ["cs.CL", "q-bio.NC"], "comment": null, "summary": "We introduce LITcoder, an open-source library for building and benchmarking\nneural encoding models. Designed as a flexible backend, LITcoder provides\nstandardized tools for aligning continuous stimuli (e.g., text and speech) with\nbrain data, transforming stimuli into representational features, mapping those\nfeatures onto brain data, and evaluating the predictive performance of the\nresulting model on held-out data. The library implements a modular pipeline\ncovering a wide array of methodological design choices, so researchers can\neasily compose, compare, and extend encoding models without reinventing core\ninfrastructure. Such choices include brain datasets, brain regions, stimulus\nfeature (both neural-net-based and control, such as word rate), downsampling\napproaches, and many others. In addition, the library provides built-in\nlogging, plotting, and seamless integration with experiment tracking platforms\nsuch as Weights & Biases (W&B). We demonstrate the scalability and versatility\nof our framework by fitting a range of encoding models to three story listening\ndatasets: LeBel et al. (2023), Narratives, and Little Prince. We also explore\nthe methodological choices critical for building encoding models for continuous\nfMRI data, illustrating the importance of accounting for all tokens in a TR\nscan (as opposed to just taking the last one, even when contextualized),\nincorporating hemodynamic lag effects, using train-test splits that minimize\ninformation leakage, and accounting for head motion effects on encoding model\npredictivity. Overall, LITcoder lowers technical barriers to encoding model\nimplementation, facilitates systematic comparisons across models and datasets,\nfosters methodological rigor, and accelerates the development of high-quality\nhigh-performance predictive models of brain activity.\n  Project page: https://litcoder-brain.github.io", "AI": {"tldr": "LITcoder is an open-source library for creating and comparing neural encoding models, providing tools and a modular pipeline for turning continuous stimuli into brain data and prediction models.", "motivation": "The motivation is to simplify and standardize the process for building and comparing encoding models for neural data, removing repetitive tasks and enabling more accessible experimentation.", "method": "LITcoder provides a modular and flexible pipeline for aligning stimuli with brain data, creating stimulus features, and mapping and evaluating predictive models. It supports different datasets, brain regions, and feature types, with built-in logging and visualization tools.", "result": "The paper demonstrates that the framework effectively fits encoding models across three fMRI datasets, explores key methodological challenges, and proves its scalability and robustness.", "conclusion": "LITcoder reduces technical barriers, facilitates systematic model comparison and fosters methodological rigor, ultimately advancing predictive modeling of brain activity."}}
{"id": "2509.09071", "pdf": "https://arxiv.org/pdf/2509.09071", "abs": "https://arxiv.org/abs/2509.09071", "authors": ["Crystal Qian", "Kehang Zhu", "John Horton", "Benjamin S. Manning", "Vivian Tsai", "James Wexler", "Nithum Thain"], "title": "Understanding Economic Tradeoffs Between Human and AI Agents in Bargaining Games", "categories": ["cs.AI", "cs.GT", "cs.HC"], "comment": null, "summary": "Coordination tasks traditionally performed by humans are increasingly being\ndelegated to autonomous agents. As this pattern progresses, it becomes critical\nto evaluate not only these agents' performance but also the processes through\nwhich they negotiate in dynamic, multi-agent environments. Furthermore,\ndifferent agents exhibit distinct advantages: traditional statistical agents,\nsuch as Bayesian models, may excel under well-specified conditions, whereas\nlarge language models (LLMs) can generalize across contexts. In this work, we\ncompare humans (N = 216), LLMs (GPT-4o, Gemini 1.5 Pro), and Bayesian agents in\na dynamic negotiation setting that enables direct, identical-condition\ncomparisons across populations, capturing both outcomes and behavioral\ndynamics. Bayesian agents extract the highest surplus through aggressive\noptimization, at the cost of frequent trade rejections. Humans and LLMs can\nachieve similar overall surplus, but through distinct behaviors: LLMs favor\nconservative, concessionary trades with few rejections, while humans employ\nmore strategic, risk-taking, and fairness-oriented behaviors. Thus, we find\nthat performance parity -- a common benchmark in agent evaluation -- can\nconceal fundamental differences in process and alignment, which are critical\nfor practical deployment in real-world coordination tasks.", "AI": {"tldr": "This paper compares humans, large language models (LLMs), and Bayesian agents in dynamic negotiation scenarios, highlighting differences in outcomes and behavioral strategies.", "motivation": "The study aims to assess the negotiation performance and behavioral dynamics of autonomous agents compared to humans, given the increasing reliance on such agents for decision-making tasks.", "method": "The researchers conducted experiments involving humans (N = 216), LLMs (GPT-4o, Gemini 1.5 Pro), and Bayesian agents, directly comparing their dynamic negotiation outcomes and processes under identical conditions.", "result": "Bayesian agents optimized results aggressively but faced frequent trade rejections. Humans and LLMs achieved similar surplus, with humans displaying fairness-oriented risk-taking and LLMs relying on conservative behaviors with fewer rejections.", "conclusion": "Performance parity between humans and agents does not account for underlying behavioral differences, which are vital for deploying agents in real-world negotiations."}}
{"id": "2509.08960", "pdf": "https://arxiv.org/pdf/2509.08960", "abs": "https://arxiv.org/abs/2509.08960", "authors": ["Thales Sales Almeida", "Giovana Kerche Bon\u00e1s", "Jo\u00e3o Guilherme Alves Santos"], "title": "BRoverbs -- Measuring how much LLMs understand Portuguese proverbs", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) exhibit significant performance variations\ndepending on the linguistic and cultural context in which they are applied.\nThis disparity signals the necessity of mature evaluation frameworks that can\nassess their capabilities in specific regional settings. In the case of\nPortuguese, existing evaluations remain limited, often relying on translated\ndatasets that may not fully capture linguistic nuances or cultural references.\nMeanwhile, native Portuguese-language datasets predominantly focus on\nstructured national exams or sentiment analysis of social media interactions,\nleaving gaps in evaluating broader linguistic understanding. To address this\nlimitation, we introduce BRoverbs, a dataset specifically designed to assess\nLLM performance through Brazilian proverbs. Proverbs serve as a rich linguistic\nresource, encapsulating cultural wisdom, figurative expressions, and complex\nsyntactic structures that challenge the model comprehension of regional\nexpressions. BRoverbs aims to provide a new evaluation tool for\nPortuguese-language LLMs, contributing to advancing regionally informed\nbenchmarking. The benchmark is available at\nhttps://huggingface.co/datasets/Tropic-AI/BRoverbs.", "AI": {"tldr": "This paper introduces BRoverbs, a dataset for evaluating large language models (LLMs) using Brazilian proverbs to address the lack of comprehensive Portuguese-language benchmarks.", "motivation": "The paper highlights the limitations of existing Portuguese evaluations of LLMs, which often use translated datasets that fail to capture linguistic and cultural nuances, and the underrepresentation of broader linguistic understanding in native datasets.", "method": "The authors developed BRoverbs, a dataset featuring Brazilian proverbs, to test LLM performance on cultural wisdom, figurative expressions, and complex syntactic structures specific to Brazilian Portuguese.", "result": "BRoverbs serves as an evaluation tool designed to test Portuguese-language LLMs in a culturally rich and linguistically nuanced context.", "conclusion": "BRoverbs contributes to advancing culturally and regionally informed benchmarking for Portuguese-language LLMs and is available for public access on HuggingFace."}}
{"id": "2509.08926", "pdf": "https://arxiv.org/pdf/2509.08926", "abs": "https://arxiv.org/abs/2509.08926", "authors": ["Waqar Ahmad", "Evan Murphy", "Vladimir A. Krylov"], "title": "Similarity-based Outlier Detection for Noisy Object Re-Identification Using Beta Mixtures", "categories": ["cs.CV", "cs.AI", "cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "Object re-identification (Re-ID) methods are highly sensitive to label noise,\nwhich typically leads to significant performance degradation. We address this\nchallenge by reframing Re-ID as a supervised image similarity task and adopting\na Siamese network architecture trained to capture discriminative pairwise\nrelationships. Central to our approach is a novel statistical outlier detection\n(OD) framework, termed Beta-SOD (Beta mixture Similarity-based Outlier\nDetection), which models the distribution of cosine similarities between\nembedding pairs using a two-component Beta distribution mixture model. We\nestablish a novel identifiability result for mixtures of two Beta\ndistributions, ensuring that our learning task is well-posed.The proposed OD\nstep complements the Re-ID architecture combining binary cross-entropy,\ncontrastive, and cosine embedding losses that jointly optimize feature-level\nsimilarity learning.We demonstrate the effectiveness of Beta-SOD in de-noising\nand Re-ID tasks for person Re-ID, on CUHK03 and Market-1501 datasets, and\nvehicle Re-ID, on VeRi-776 dataset. Our method shows superior performance\ncompared to the state-of-the-art methods across various noise levels (10-30\\%),\ndemonstrating both robustness and broad applicability in noisy Re-ID scenarios.\nThe implementation of Beta-SOD is available at:\nhttps://github.com/waqar3411/Beta-SOD", "AI": {"tldr": "The paper addresses label noise in object Re-ID by proposing Beta-SOD, a statistical outlier detection framework utilizing a two-component Beta mixture model, integrated with a Siamese network for improved performance.", "motivation": "Object Re-ID suffers from label noise, leading to poor performance. There is a need for robust methods that can handle noisy datasets and enhance identification accuracy.", "method": "The authors use a Siamese network architecture for supervised image similarity learning combined with a novel Beta-SOD outlier detection framework. This involves modeling embedding pair cosine similarity distributions using a two-component Beta mixture and integrating multiple loss functions for optimization.", "result": "Experiments on CUHK03, Market-1501, and VeRi-776 datasets show that Beta-SOD significantly outperforms state-of-the-art Re-ID methods, especially under noise levels of 10%-30%.", "conclusion": "Beta-SOD improves robustness and generalizability in noisy Re-ID tasks and demonstrates its effectiveness on both person and vehicle Re-ID datasets."}}
{"id": "2509.09093", "pdf": "https://arxiv.org/pdf/2509.09093", "abs": "https://arxiv.org/abs/2509.09093", "authors": ["Nan Mao", "Guanglu Jia", "Junpeng Chen", "Emmanouil Spyrakos-Papastavridis", "Jian S. Dai"], "title": "Kinetostatics and Particle-Swarm Optimization of Vehicle-Mounted Underactuated Metamorphic Loading Manipulators", "categories": ["cs.RO"], "comment": "50 pages, 19 figures", "summary": "Fixed degree-of-freedom (DoF) loading mechanisms often suffer from excessive\nactuators, complex control, and limited adaptability to dynamic tasks. This\nstudy proposes an innovative mechanism of underactuated metamorphic loading\nmanipulators (UMLM), integrating a metamorphic arm with a passively adaptive\ngripper. The metamorphic arm exploits geometric constraints, enabling the\ntopology reconfiguration and flexible motion trajectories without additional\nactuators. The adaptive gripper, driven entirely by the arm, conforms to\ndiverse objects through passive compliance. A structural model is developed,\nand a kinetostatics analysis is conducted to investigate isomorphic grasping\nconfigurations. To optimize performance, Particle-Swarm Optimization (PSO) is\nutilized to refine the gripper's dimensional parameters, ensuring robust\nadaptability across various applications. Simulation results validate the\nUMLM's easily implemented control strategy, operational versatility, and\neffectiveness in grasping diverse objects in dynamic environments. This work\nunderscores the practical potential of underactuated metamorphic mechanisms in\napplications requiring efficient and adaptable loading solutions. Beyond the\nspecific design, this generalized modeling and optimization framework extends\nto a broader class of manipulators, offering a scalable approach to the\ndevelopment of robotic systems that require efficiency, flexibility, and robust\nperformance.", "AI": {"tldr": "This paper introduces an underactuated metamorphic loading manipulator (UMLM) integrating a metamorphic arm and adaptively driven gripper for dynamic tasks with efficient performance.", "motivation": "To address the limitations of fixed degree-of-freedom (DoF) mechanisms, such as excessive actuators, complex control, and restricted adaptability in dynamic environments.", "method": "The study proposes a UMLM integrating a metamorphic arm for topology reconfiguration and a passively adaptive gripper. A structural model and kinetostatics analysis are conducted, and the Particle-Swarm Optimization (PSO) is used to optimize gripper parameters.", "result": "Simulation results confirm the UMLM's effective control strategy, versatility, and ability to adapt to dynamic environments by grasping diverse objects easily.", "conclusion": "This research validates underactuated metamorphic mechanisms' practicality and introduces a scalable modeling and optimization framework applicable to various robotic systems requiring efficiency and flexibility."}}
{"id": "2509.08942", "pdf": "https://arxiv.org/pdf/2509.08942", "abs": "https://arxiv.org/abs/2509.08942", "authors": ["Xenia Konti", "Yi Shen", "Zifan Wang", "Karl Henrik Johansson", "Michael J. Pencina", "Nicoleta J. Economou-Zavlanos", "Michael M. Zavlanos"], "title": "Group Distributionally Robust Machine Learning under Group Level Distributional Uncertainty", "categories": ["cs.LG"], "comment": null, "summary": "The performance of machine learning (ML) models critically depends on the\nquality and representativeness of the training data. In applications with\nmultiple heterogeneous data generating sources, standard ML methods often learn\nspurious correlations that perform well on average but degrade performance for\natypical or underrepresented groups. Prior work addresses this issue by\noptimizing the worst-group performance. However, these approaches typically\nassume that the underlying data distributions for each group can be accurately\nestimated using the training data, a condition that is frequently violated in\nnoisy, non-stationary, and evolving environments. In this work, we propose a\nnovel framework that relies on Wasserstein-based distributionally robust\noptimization (DRO) to account for the distributional uncertainty within each\ngroup, while simultaneously preserving the objective of improving the\nworst-group performance. We develop a gradient descent-ascent algorithm to\nsolve the proposed DRO problem and provide convergence results. Finally, we\nvalidate the effectiveness of our method on real-world data.", "AI": {"tldr": "This paper proposes a framework using Wasserstein-based distributionally robust optimization (DRO) to improve machine learning performance for underrepresented data groups in noisy, evolving environments.", "motivation": "Standard machine learning models often fail to perform well on underrepresented or atypical data groups, especially in heterogeneous and non-stationary environments.", "method": "The authors introduce a framework leveraging Wasserstein-based DRO to handle distributional uncertainty within groups, coupled with a gradient descent-ascent algorithm for optimization.", "result": "The proposed method effectively improves worst-group performance and shows efficacy on real-world datasets.", "conclusion": "The framework successfully addresses challenges with underrepresented groups in noisy, evolving environments by combining DRO with worst-group performance optimization principles."}}
{"id": "2509.08865", "pdf": "https://arxiv.org/pdf/2509.08865", "abs": "https://arxiv.org/abs/2509.08865", "authors": ["Guangyu Zhang", "Xixuan Wang", "Shiyu Sun", "Peiyan Xiao", "Kun Sun", "Yanhai Xiong"], "title": "TraceRAG: A LLM-Based Framework for Explainable Android Malware Detection and Behavior Analysis", "categories": ["cs.SE"], "comment": null, "summary": "Sophisticated evasion tactics in malicious Android applications, combined\nwith their intricate behavioral semantics, enable attackers to conceal\nmalicious logic within legitimate functions, underscoring the critical need for\nrobust and in-depth analysis frameworks. However, traditional analysis\ntechniques often fail to recover deeply hidden behaviors or provide\nhuman-readable justifications for their decisions. Inspired by advances in\nlarge language models (LLMs), we introduce TraceRAG, a retrieval-augmented\ngeneration (RAG) framework that bridges natural language queries and Java code\nto deliver explainable malware detection and analysis. First, TraceRAG\ngenerates summaries of method-level code snippets, which are indexed in a\nvector database. At query time, behavior-focused questions retrieve the most\nsemantically relevant snippets for deeper inspection. Finally, based on the\nmulti-turn analysis results, TraceRAG produces human-readable reports that\npresent the identified malicious behaviors and their corresponding code\nimplementations. Experimental results demonstrate that our method achieves 96\\%\nmalware detection accuracy and 83.81\\% behavior identification accuracy based\non updated VirusTotal (VT) scans and manual verification. Furthermore, expert\nevaluation confirms the practical utility of the reports generated by TraceRAG.", "AI": {"tldr": "TraceRAG is a retrieval-augmented generation framework leveraging large language models to analyze and identify malware in Android applications with high accuracy and human-readable explanations.", "motivation": "Traditional malware detection methods struggle with deeply concealed malicious behaviors in apps and fail to provide understandable justifications for detected threats. This gap necessitates more robust, explainable detection techniques.", "method": "The proposed TraceRAG framework uses large language models to generate summaries of method-level code snippets that are stored in a vector database. During query time, relevant code snippets are retrieved for inspection based on behavioral questions, culminating in human-readable reports that correlate detected behaviors with code.", "result": "TraceRAG achieves a malware detection accuracy of 96% and behavior identification accuracy of 83.81%, validated by VirusTotal scans and manual assessments. Experts found the generated reports to be practically useful.", "conclusion": "TraceRAG effectively bridges the gap between explainable AI and malware analysis, offering a highly accurate and comprehensible solution for detecting and analyzing malicious behaviors in Android applications."}}
{"id": "2509.09127", "pdf": "https://arxiv.org/pdf/2509.09127", "abs": "https://arxiv.org/abs/2509.09127", "authors": ["Khashayar Namdar", "Pin-Chien Wang", "Tushar Raju", "Steven Zheng", "Fiona Li", "Safwat Tahmin Khan"], "title": "Anti-Money Laundering Machine Learning Pipelines; A Technical Analysis on Identifying High-risk Bank Clients with Supervised Learning", "categories": ["cs.AI"], "comment": null, "summary": "Anti-money laundering (AML) actions and measurements are among the priorities\nof financial institutions, for which machine learning (ML) has shown to have a\nhigh potential. In this paper, we propose a comprehensive and systematic\napproach for developing ML pipelines to identify high-risk bank clients in a\ndataset curated for Task 1 of the University of Toronto 2023-2024 Institute for\nManagement and Innovation (IMI) Big Data and Artificial Intelligence\nCompetition. The dataset included 195,789 customer IDs, and we employed a\n16-step design and statistical analysis to ensure the final pipeline was\nrobust. We also framed the data in a SQLite database, developed SQL-based\nfeature engineering algorithms, connected our pre-trained model to the\ndatabase, and made it inference-ready, and provided explainable artificial\nintelligence (XAI) modules to derive feature importance. Our pipeline achieved\na mean area under the receiver operating characteristic curve (AUROC) of 0.961\nwith a standard deviation (SD) of 0.005. The proposed pipeline achieved second\nplace in the competition.", "AI": {"tldr": "This paper proposes a machine learning pipeline for identifying high-risk bank clients, achieving high accuracy and second place in a competition.", "motivation": "Financial institutions prioritize AML actions due to their importance, with machine learning showing strong potential in this area.", "method": "The authors used a 16-step design and statistical analysis, SQLite for data framing, SQL-based feature engineering, inference-ready pre-trained models, and XAI modules for feature importance.", "result": "The pipeline demonstrated a mean AUROC of 0.961 with an SD of 0.005, outperforming most competitors.", "conclusion": "The developed pipeline is robust, highly effective in identifying risk, and integrates explainable AI capabilities, securing second place in the competition and showcasing ML's utility in AML measures."}}
{"id": "2509.09435", "pdf": "https://arxiv.org/pdf/2509.09435", "abs": "https://arxiv.org/abs/2509.09435", "authors": ["Houming Qiu", "Kun Zhu", "Dusit Niyato", "Nguyen Cong Luong", "Changyan Yi", "Chen Dai"], "title": "Barycentric Coded Distributed Computing with Flexible Recovery Threshold for Collaborative Mobile Edge Computing", "categories": ["cs.DC"], "comment": null, "summary": "Collaborative mobile edge computing (MEC) has emerged as a promising paradigm\nto enable low-capability edge nodes to cooperatively execute\ncomputation-intensive tasks. However, straggling edge nodes (stragglers)\nsignificantly degrade the performance of MEC systems by prolonging computation\nlatency. While coded distributed computing (CDC) as an effective technique is\nwidely adopted to mitigate straggler effects, existing CDC schemes exhibit two\ncritical limitations: (i) They cannot successfully decode the final result\nunless the number of received results reaches a fixed recovery threshold, which\nseriously restricts their flexibility; (ii) They suffer from inherent poles in\ntheir encoding/decoding functions, leading to decoding inaccuracies and\nnumerical instability in the computational results. To address these\nlimitations, this paper proposes an approximated CDC scheme based on\nbarycentric rational interpolation. The proposed CDC scheme offers several\noutstanding advantages. Firstly, it can decode the final result leveraging any\nreturned results from workers. Secondly, it supports computations over both\nfinite and real fields while ensuring numerical stability. Thirdly, its\nencoding/decoding functions are free of poles, which not only enhances\napproximation accuracy but also achieves flexible accuracy tuning. Fourthly, it\nintegrates a novel BRI-based gradient coding algorithm accelerating the\ntraining process while providing robustness against stragglers. Finally,\nexperimental results reveal that the proposed scheme is superior to existing\nCDC schemes in both waiting time and approximate accuracy.", "AI": {"tldr": "The paper proposes an improved coded distributed computing (CDC) scheme using barycentric rational interpolation to address straggler issues in mobile edge computing systems, ensuring flexibility, numerical stability, and enhanced performance.", "motivation": "Current CDC schemes for collaborative mobile edge computing face issues such as rigid recovery thresholds and numerical instability due to poles in encoding/decoding functions.", "method": "The authors utilize barycentric rational interpolation to develop a CDC scheme that allows decoding with any partial results, supports computations over both finite and real fields, and eliminates poles for enhanced tuning and numerical stability.", "result": "Experimental results demonstrate superior waiting time reduction and approximate accuracy compared to existing CDC solutions.", "conclusion": "The proposed scheme effectively mitigates straggler effects, accelerates computing tasks, and offers robustness, flexibility, and accuracy improvements over traditional CDC methods."}}
{"id": "2509.09013", "pdf": "https://arxiv.org/pdf/2509.09013", "abs": "https://arxiv.org/abs/2509.09013", "authors": ["Monjoy Narayan Choudhury", "Junling Wang", "Yifan Hou", "Mrinmaya Sachan"], "title": "Can Vision-Language Models Solve Visual Math Equations?", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "Monjoy Narayan Choudhury and Junling Wang contributed equally to this\n  work. Accepted at EMNLP2025 main. Code and datasets are open-sourced with\n  links in the paper", "summary": "Despite strong performance in visual understanding and language-based\nreasoning, Vision-Language Models (VLMs) struggle with tasks requiring\nintegrated perception and symbolic computation. We study this limitation\nthrough visual equation solving, where mathematical equations are embedded in\nimages, variables are represented by object icons, and coefficients must be\ninferred by counting. While VLMs perform well on textual equations, they fail\non visually grounded counterparts. To understand this gap, we decompose the\ntask into coefficient counting and variable recognition, and find that counting\nis the primary bottleneck, even when recognition is accurate. We also observe\nthat composing recognition and reasoning introduces additional errors,\nhighlighting challenges in multi-step visual reasoning. Finally, as equation\ncomplexity increases, symbolic reasoning itself becomes a limiting factor.\nThese findings reveal key weaknesses in current VLMs and point toward future\nimprovements in visually grounded mathematical reasoning.", "AI": {"tldr": "This paper analyzes Vision-Language Models (VLMs) and their struggles with mathematical reasoning tasks embedded in images.", "motivation": "Understanding the limitations of current Vision-Language Models when handling visually integrated perception and symbolic computation.", "method": "The authors studied visual equation solving, breaking down tasks into coefficient counting and variable recognition, and analyzed how these factors contribute to VLM performance.", "result": "They found that counting is the primary bottleneck, recognition errors compound reasoning issues, and increased equation complexity further limits VLM efficacy.", "conclusion": "Current VLMs face significant challenges in visually grounded reasoning, particularly in counting and multi-step symbolic computations, requiring advancements in mathematical reasoning capabilities."}}
{"id": "2509.08934", "pdf": "https://arxiv.org/pdf/2509.08934", "abs": "https://arxiv.org/abs/2509.08934", "authors": ["Nan Mu", "Ruiqi Song", "Zhihui Xu", "Jingfeng Jiang", "Chen Zhao"], "title": "SFD-Mamba2Net: Strcture-Guided Frequency-Enhanced Dual-Stream Mamba2 Network for Coronary Artery Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Background: Coronary Artery Disease (CAD) is one of the leading causes of\ndeath worldwide. Invasive Coronary Angiography (ICA), regarded as the gold\nstandard for CAD diagnosis, necessitates precise vessel segmentation and\nstenosis detection. However, ICA images are typically characterized by low\ncontrast, high noise levels, and complex, fine-grained vascular structures,\nwhich pose significant challenges to the clinical adoption of existing\nsegmentation and detection methods. Objective: This study aims to improve the\naccuracy of coronary artery segmentation and stenosis detection in ICA images\nby integrating multi-scale structural priors, state-space-based long-range\ndependency modeling, and frequency-domain detail enhancement strategies.\nMethods: We propose SFD-Mamba2Net, an end-to-end framework tailored for\nICA-based vascular segmentation and stenosis detection. In the encoder, a\nCurvature-Aware Structural Enhancement (CASE) module is embedded to leverage\nmulti-scale responses for highlighting slender tubular vascular structures,\nsuppressing background interference, and directing attention toward vascular\nregions. In the decoder, we introduce a Progressive High-Frequency Perception\n(PHFP) module that employs multi-level wavelet decomposition to progressively\nrefine high-frequency details while integrating low-frequency global\nstructures. Results and Conclusions: SFD-Mamba2Net consistently outperformed\nstate-of-the-art methods across eight segmentation metrics, and achieved the\nhighest true positive rate and positive predictive value in stenosis detection.", "AI": {"tldr": "The paper introduces SFD-Mamba2Net, a framework designed to improve segmentation and stenosis detection in challenging ICA images, achieving superior performance metrics.", "motivation": "Current segmentation and detection methods for ICA images struggle with low contrast, high noise, and complex vascular structures. This study aims to address these challenges for improved clinical adoption.", "method": "The authors propose SFD-Mamba2Net, an end-to-end framework. It incorporates a CASE module for multi-scale structural enhancements in the encoder and a PHFP module for refining vascular details using wavelet decomposition in the decoder.", "result": "SFD-Mamba2Net outperformed existing methods across eight segmentation metrics and achieved top performance in stenosis detection's predictive value and true positive rate.", "conclusion": "The proposed framework successfully enhances segmentation accuracy and stenosis detection performance, addressing visual and structural challenges in ICA images."}}
{"id": "2509.09106", "pdf": "https://arxiv.org/pdf/2509.09106", "abs": "https://arxiv.org/abs/2509.09106", "authors": ["Haokai Su", "Haoxiang Luo", "Shunpeng Yang", "Kaiwen Jiang", "Wei Zhang", "Hua Chen"], "title": "LIPM-Guided Reinforcement Learning for Stable and Perceptive Locomotion in Bipedal Robots", "categories": ["cs.RO"], "comment": null, "summary": "Achieving stable and robust perceptive locomotion for bipedal robots in\nunstructured outdoor environments remains a critical challenge due to complex\nterrain geometry and susceptibility to external disturbances. In this work, we\npropose a novel reward design inspired by the Linear Inverted Pendulum Model\n(LIPM) to enable perceptive and stable locomotion in the wild. The LIPM\nprovides theoretical guidance for dynamic balance by regulating the center of\nmass (CoM) height and the torso orientation. These are key factors for\nterrain-aware locomotion, as they help ensure a stable viewpoint for the\nrobot's camera. Building on this insight, we design a reward function that\npromotes balance and dynamic stability while encouraging accurate CoM\ntrajectory tracking. To adaptively trade off between velocity tracking and\nstability, we leverage the Reward Fusion Module (RFM) approach that prioritizes\nstability when needed. A double-critic architecture is adopted to separately\nevaluate stability and locomotion objectives, improving training efficiency and\nrobustness. We validate our approach through extensive experiments on a bipedal\nrobot in both simulation and real-world outdoor environments. The results\ndemonstrate superior terrain adaptability, disturbance rejection, and\nconsistent performance across a wide range of speeds and perceptual conditions.", "AI": {"tldr": "The paper proposes a reward design based on the Linear Inverted Pendulum Model (LIPM) for enabling stable and robust locomotion in bipedal robots on complex terrains.", "motivation": "Bipedal robots struggle with stability and robustness in unstructured, outdoor environments due to terrain complexity and external disturbances.", "method": "A novel reward function is designed using LIPM principles, along with a Reward Fusion Module (RFM) for adaptive trade-offs between stability and velocity. A double-critic architecture improves evaluation and training efficiency.", "result": "Extensive experiments validate superior performance in terrain adaptability, disturbance rejection, and consistent locomotion over varied speeds and perceptual scenarios.", "conclusion": "The proposed approach effectively ensures perceptive and stable locomotion for bipedal robots, demonstrating practical viability in dynamic outdoor settings."}}
{"id": "2509.08961", "pdf": "https://arxiv.org/pdf/2509.08961", "abs": "https://arxiv.org/abs/2509.08961", "authors": ["Md. Sajeebul Islam Sk.", "Md Jobayer", "Md Mehedi Hasan Shawon", "Md. Golam Raibul Alam"], "title": "FoundationalECGNet: A Lightweight Foundational Model for ECG-based Multitask Cardiac Analysis", "categories": ["cs.LG", "68T07 (Primary) 68T09, 68T10 (Secondary)"], "comment": null, "summary": "Cardiovascular diseases (CVDs) remain a leading cause of mortality worldwide,\nunderscoring the importance of accurate and scalable diagnostic systems.\nElectrocardiogram (ECG) analysis is central to detecting cardiac abnormalities,\nyet challenges such as noise, class imbalance, and dataset heterogeneity limit\ncurrent methods. To address these issues, we propose FoundationalECGNet, a\nfoundational framework for automated ECG classification. The model integrates a\ndual-stage denoising by Morlet and Daubechies wavelets transformation,\nConvolutional Block Attention Module (CBAM), Graph Attention Networks (GAT),\nand Time Series Transformers (TST) to jointly capture spatial and temporal\ndependencies in multi-channel ECG signals. FoundationalECGNet first\ndistinguishes between Normal and Abnormal ECG signals, and then classifies the\nAbnormal signals into one of five cardiac conditions: Arrhythmias, Conduction\nDisorders, Myocardial Infarction, QT Abnormalities, or Hypertrophy. Across\nmultiple datasets, the model achieves a 99% F1-score for Normal vs. Abnormal\nclassification and shows state-of-the-art performance in multi-class disease\ndetection, including a 99% F1-score for Conduction Disorders and Hypertrophy,\nas well as a 98.9% F1-score for Arrhythmias. Additionally, the model provides\nrisk level estimations to facilitate clinical decision-making. In conclusion,\nFoundationalECGNet represents a scalable, interpretable, and generalizable\nsolution for automated ECG analysis, with the potential to improve diagnostic\nprecision and patient outcomes in healthcare settings. We'll share the code\nafter acceptance.", "AI": {"tldr": "This paper presents FoundationalECGNet, an automated ECG classification model that achieves high diagnostic accuracy and provides risk estimations.", "motivation": "Cardiovascular diseases remain a major cause of mortality, highlighting the need for accurate and scalable ECG diagnostic systems to address challenges like noise, class imbalance, and dataset heterogeneity.", "method": "The method includes a dual-stage denoising process (using Morlet and Daubechies wavelets), CBAM, GAT, and Time Series Transformers to capture spatial and temporal dependencies in multi-channel ECG signals. It further classifies signals hierarchically into normal or one of five cardiac conditions.", "result": "FoundationalECGNet achieves 99% F1-score for Normal vs. Abnormal classification and state-of-the-art performance in multi-class disease detection, including nearly 99% F1-scores for specific conditions like Conduction Disorders and Hypertrophy.", "conclusion": "FoundationalECGNet offers a scalable and interpretable framework for ECG analysis, improving diagnostic precision and aiding clinical decision-making, with potential benefits for healthcare."}}
{"id": "2509.08867", "pdf": "https://arxiv.org/pdf/2509.08867", "abs": "https://arxiv.org/abs/2509.08867", "authors": ["K. Pronk", "Q. Zhao"], "title": "Benchmarking Energy Efficiency of Large Language Models Using vLLM", "categories": ["cs.SE", "cs.AI", "68T01", "I.2.7"], "comment": "6 pages, 6 figures", "summary": "The prevalence of Large Language Models (LLMs) is having an growing impact on\nthe climate due to the substantial energy required for their deployment and\nuse. To create awareness for developers who are implementing LLMs in their\nproducts, there is a strong need to collect more information about the energy\nefficiency of LLMs. While existing research has evaluated the energy efficiency\nof various models, these benchmarks often fall short of representing realistic\nproduction scenarios. In this paper, we introduce the LLM Efficiency Benchmark,\ndesigned to simulate real-world usage conditions. Our benchmark utilizes vLLM,\na high-throughput, production-ready LLM serving backend that optimizes model\nperformance and efficiency. We examine how factors such as model size,\narchitecture, and concurrent request volume affect inference energy efficiency.\nOur findings demonstrate that it is possible to create energy efficiency\nbenchmarks that better reflect practical deployment conditions, providing\nvaluable insights for developers aiming to build more sustainable AI systems.", "AI": {"tldr": "The paper introduces an energy efficiency benchmark for Large Language Models (LLMs) under real-world usage conditions.", "motivation": "Rising deployment and use of LLMs are impacting climate due to substantial energy consumption, necessitating awareness and improved energy efficiency information.", "method": "Proposed a benchmark (LLM Efficiency Benchmark) using vLLM backend, evaluating model size, architecture, and concurrent requests' impact on inference efficiency.", "result": "Showed that practical energy efficiency benchmarks can offer insights that align more closely with real-world conditions.", "conclusion": "The benchmark aids developers in creating more energy-efficient and sustainable AI systems."}}
{"id": "2509.09154", "pdf": "https://arxiv.org/pdf/2509.09154", "abs": "https://arxiv.org/abs/2509.09154", "authors": ["Bui Duc Manh", "Soumyaratna Debnath", "Zetong Zhang", "Shriram Damodaran", "Arvind Kumar", "Yueyi Zhang", "Lu Mi", "Erik Cambria", "Lin Wang"], "title": "Mind Meets Space: Rethinking Agentic Spatial Intelligence from a Neuroscience-inspired Perspective", "categories": ["cs.AI", "cs.CV"], "comment": "54 pages, journal", "summary": "Recent advances in agentic AI have led to systems capable of autonomous task\nexecution and language-based reasoning, yet their spatial reasoning abilities\nremain limited and underexplored, largely constrained to symbolic and\nsequential processing. In contrast, human spatial intelligence, rooted in\nintegrated multisensory perception, spatial memory, and cognitive maps, enables\nflexible, context-aware decision-making in unstructured environments.\nTherefore, bridging this gap is critical for advancing Agentic Spatial\nIntelligence toward better interaction with the physical 3D world. To this end,\nwe first start from scrutinizing the spatial neural models as studied in\ncomputational neuroscience, and accordingly introduce a novel computational\nframework grounded in neuroscience principles. This framework maps core\nbiological functions to six essential computation modules: bio-inspired\nmultimodal sensing, multi-sensory integration, egocentric-allocentric\nconversion, an artificial cognitive map, spatial memory, and spatial reasoning.\nTogether, these modules form a perspective landscape for agentic spatial\nreasoning capability across both virtual and physical environments. On top, we\nconduct a framework-guided analysis of recent methods, evaluating their\nrelevance to each module and identifying critical gaps that hinder the\ndevelopment of more neuroscience-grounded spatial reasoning modules. We further\nexamine emerging benchmarks and datasets and explore potential application\ndomains ranging from virtual to embodied systems, such as robotics. Finally, we\noutline potential research directions, emphasizing the promising roadmap that\ncan generalize spatial reasoning across dynamic or unstructured environments.\nWe hope this work will benefit the research community with a\nneuroscience-grounded perspective and a structured pathway. Our project page\ncan be found at Github.", "AI": {"tldr": "This research explores bridging the gap in spatial reasoning for AI by drawing learning from human spatial intelligence and neuroscience principles, proposing a novel framework for agentic spatial intelligence.", "motivation": "The paper aims to enhance current agentic AI's limited spatial reasoning abilities by leveraging brain-inspired models, as humanlike spatial intelligence is critical for AI's effective operation in complex 3D environments.", "method": "The researchers propose a neuroscience-inspired computational framework with six modules (e.g., bio-inspired sensing, multi-sensory integration, cognitive mapping, etc.), evaluate existing methods under this framework, and identify research gaps.", "result": "The authors analyze current methods and benchmarks, revealing gaps in neuroscience-rooted models for spatial reasoning and suggest practical application domains like robotics, while also proposing general strategies to address these limitations.", "conclusion": "This work provides a neuroscience-based structured framework and roadmap for advancing agentic AI's spatial reasoning capabilities, offering future directions toward generalizability in unstructured environments."}}
{"id": "2509.09493", "pdf": "https://arxiv.org/pdf/2509.09493", "abs": "https://arxiv.org/abs/2509.09493", "authors": ["Ignacio Amores-Sesar", "Christian Cachin", "Juan Villacis"], "title": "Weaker Assumptions for Asymmetric Trust", "categories": ["cs.DC"], "comment": null, "summary": "In distributed systems with asymmetric trust, each participant is free to\nmake its own trust assumptions about others, captured by an asymmetric quorum\nsystem. This contrasts with ordinary, symmetric quorum systems and threshold\nmodels, where trust assumptions are uniformly shared among participants.\nFundamental problems like reliable broadcast and consensus are unsolvable in\nthe asymmetric model if quorum systems satisfy only the classical properties of\nconsistency and availability. Existing approaches overcome this by introducing\nstronger assumptions. We show that some of these assumptions are overly\nrestrictive, so much so that they effectively eliminate the benefits of\nasymmetric trust. To address this, we propose a new approach to characterize\nasymmetric problems and, building upon it, present algorithms for reliable\nbroadcast and consensus that require weaker assumptions than previous\nsolutions. Our methods are general and can be extended to other core problems\nin systems with asymmetric trust.", "AI": {"tldr": "The paper addresses the challenges in asymmetric trust models for distributed systems by introducing less restrictive assumptions and proposing improved algorithms for reliable broadcast and consensus.", "motivation": "Distributed systems with asymmetric trust face limitations in reliability and consensus when only classical quorum properties are considered. Current methods often use restrictive assumptions, negating the advantages of asymmetric trust.", "method": "The authors propose a novel characterization of asymmetric problems and develop algorithms for reliable broadcast and consensus with weaker assumptions than prior solutions.", "result": "The proposed approach enables reliable broadcast and consensus in asymmetric trust settings without the need for overly restrictive assumptions, preserving the system's flexibility.", "conclusion": "By leveraging the new characterization and algorithms, the paper demonstrates that foundational problems in distributed systems can be solved in asymmetric trust environments with reduced restrictions."}}
{"id": "2509.09043", "pdf": "https://arxiv.org/pdf/2509.09043", "abs": "https://arxiv.org/abs/2509.09043", "authors": ["Thomas Manuel Rost", "Martina Figlia", "Bernd Wallraff"], "title": "Stated Preference for Interaction and Continued Engagement (SPICE): Evaluating an LLM's Willingness to Re-engage in Conversation", "categories": ["cs.CL", "cs.AI", "cs.MA"], "comment": null, "summary": "We introduce and evaluate Stated Preference for Interaction and Continued\nEngagement (SPICE), a simple diagnostic signal elicited by asking a Large\nLanguage Model a YES or NO question about its willingness to re-engage with a\nuser's behavior after reviewing a short transcript. In a study using a 3-tone\n(friendly, unclear, abusive) by 10-interaction stimulus set, we tested four\nopen-weight chat models across four framing conditions, resulting in 480\ntrials. Our findings show that SPICE sharply discriminates by user tone.\nFriendly interactions yielded a near-unanimous preference to continue (97.5%\nYES), while abusive interactions yielded a strong preference to discontinue\n(17.9% YES), with unclear interactions falling in between (60.4% YES). This\ncore association remains decisive under multiple dependence-aware statistical\ntests, including Rao-Scott adjustment and cluster permutation tests.\nFurthermore, we demonstrate that SPICE provides a distinct signal from abuse\nclassification. In trials where a model failed to identify abuse, it still\noverwhelmingly stated a preference not to continue the interaction (81% of the\ntime). An exploratory analysis also reveals a significant interaction effect: a\npreamble describing the study context significantly impacts SPICE under\nambiguity, but only when transcripts are presented as a single block of text\nrather than a multi-turn chat. The results validate SPICE as a robust,\nlow-overhead, and reproducible tool for auditing model dispositions,\ncomplementing existing metrics by offering a direct, relational signal of a\nmodel's state. All stimuli, code, and analysis scripts are released to support\nreplication.", "AI": {"tldr": "The paper introduces SPICE, a tool to measure a language model's willingness to re-engage with users based on interaction tone (friendly, unclear, abusive) and shows that SPICE can discern user tone effectively and transparently.", "motivation": "To develop a diagnostic signal for evaluating whether large language models are inclined to engage in further interaction with a user based on the user's tone.", "method": "The authors tested SPICE using 480 trials with 3 interaction tones, 4 open-weight chat models, and 4 framing conditions. Statistical methods like Rao-Scott adjustment and cluster permutation tests were implemented to validate results.", "result": "SPICE distinguished user tones effectively, with friendly interactions yielding a 97.5% agreement to re-engage, abusive interactions yielding 17.9%, and unclear interactions at 60.4%. It also provided insights beyond standard abuse detection metrics.", "conclusion": "SPICE is validated as a useful, low-effort tool for analyzing a language model's relational engagement preference, complementing existing metrics and offering transparency in model behavior evaluation tools."}}
{"id": "2509.08935", "pdf": "https://arxiv.org/pdf/2509.08935", "abs": "https://arxiv.org/abs/2509.08935", "authors": ["Muhammad Alberb", "Helen Cheung", "Anne Martel"], "title": "Live(r) Die: Predicting Survival in Colorectal Liver Metastasis", "categories": ["cs.CV"], "comment": "Thesis at Erasmus Mundus Joint Master's Degree in Medical Imaging and\n  Applications", "summary": "Colorectal cancer frequently metastasizes to the liver, significantly\nreducing long-term survival. While surgical resection is the only potentially\ncurative treatment for colorectal liver metastasis (CRLM), patient outcomes\nvary widely depending on tumor characteristics along with clinical and genomic\nfactors. Current prognostic models, often based on limited clinical or\nmolecular features, lack sufficient predictive power, especially in multifocal\nCRLM cases. We present a fully automated framework for surgical outcome\nprediction from pre- and post-contrast MRI acquired before surgery. Our\nframework consists of a segmentation pipeline and a radiomics pipeline. The\nsegmentation pipeline learns to segment the liver, tumors, and spleen from\npartially annotated data by leveraging promptable foundation models to complete\nmissing labels. Also, we propose SAMONAI, a novel zero-shot 3D prompt\npropagation algorithm that leverages the Segment Anything Model to segment 3D\nregions of interest from a single point prompt, significantly improving our\nsegmentation pipeline's accuracy and efficiency. The predicted pre- and\npost-contrast segmentations are then fed into our radiomics pipeline, which\nextracts features from each tumor and predicts survival using SurvAMINN, a\nnovel autoencoder-based multiple instance neural network for survival analysis.\nSurvAMINN jointly learns dimensionality reduction and hazard prediction from\nright-censored survival data, focusing on the most aggressive tumors. Extensive\nevaluation on an institutional dataset comprising 227 patients demonstrates\nthat our framework surpasses existing clinical and genomic biomarkers,\ndelivering a C-index improvement exceeding 10%. Our results demonstrate the\npotential of integrating automated segmentation algorithms and radiomics-based\nsurvival analysis to deliver accurate, annotation-efficient, and interpretable\noutcome prediction in CRLM.", "AI": {"tldr": "This paper introduces an automated framework combining MRI-based segmentation and radiomics analysis to predict surgical outcomes for colorectal liver metastasis (CRLM), outperforming existing methods by over 10% in accuracy.", "motivation": "Improve the limited predictive power of current prognostic models for CRLM, especially in multifocal cases, through advanced automation and integration of imaging and survival analysis.", "method": "The framework uses a segmentation pipeline and a radiomics pipeline. A zero-shot 3D prompt propagation algorithm, SAMONAI, enhances segmentation accuracy, while the survival analysis employs SurvAMINN, a novel neural network focusing on aggressive tumors.", "result": "The framework significantly outperformed clinical and genomic biomarkers, achieving a C-index improvement of over 10% in experiments on a dataset of 227 patients.", "conclusion": "Integrating automated segmentation algorithms with survival analysis can deliver accurate, efficient, and interpretable outcomes, highlighting its potential in CRLM surgical planning."}}
{"id": "2509.09141", "pdf": "https://arxiv.org/pdf/2509.09141", "abs": "https://arxiv.org/abs/2509.09141", "authors": ["Jianping Li", "Xinhang Xu", "Zhongyuan Liu", "Shenghai Yuan", "Muqing Cao", "Lihua Xie"], "title": "AEOS: Active Environment-aware Optimal Scanning Control for UAV LiDAR-Inertial Odometry in Complex Scenes", "categories": ["cs.RO"], "comment": null, "summary": "LiDAR-based 3D perception and localization on unmanned aerial vehicles (UAVs)\nare fundamentally limited by the narrow field of view (FoV) of compact LiDAR\nsensors and the payload constraints that preclude multi-sensor configurations.\nTraditional motorized scanning systems with fixed-speed rotations lack scene\nawareness and task-level adaptability, leading to degraded odometry and mapping\nperformance in complex, occluded environments. Inspired by the active sensing\nbehavior of owls, we propose AEOS (Active Environment-aware Optimal Scanning),\na biologically inspired and computationally efficient framework for adaptive\nLiDAR control in UAV-based LiDAR-Inertial Odometry (LIO). AEOS combines model\npredictive control (MPC) and reinforcement learning (RL) in a hybrid\narchitecture: an analytical uncertainty model predicts future pose\nobservability for exploitation, while a lightweight neural network learns an\nimplicit cost map from panoramic depth representations to guide exploration. To\nsupport scalable training and generalization, we develop a point cloud-based\nsimulation environment with real-world LiDAR maps across diverse scenes,\nenabling sim-to-real transfer. Extensive experiments in both simulation and\nreal-world environments demonstrate that AEOS significantly improves odometry\naccuracy compared to fixed-rate, optimization-only, and fully learned\nbaselines, while maintaining real-time performance under onboard computational\nconstraints. The project page can be found at\nhttps://kafeiyin00.github.io/AEOS/.", "AI": {"tldr": "The paper proposes a biologically inspired adaptive LiDAR control framework, AEOS, to improve UAV-based 3D perception by addressing limitations of narrow field-of-view LiDAR sensors.", "motivation": "Traditional LiDAR-based systems for UAVs are hindered by narrow fields of view and hardware constraints, which degrade performance in complex environments.", "method": "AEOS uses a hybrid approach combining model predictive control (MPC) and reinforcement learning (RL) to optimize LiDAR-inertial odometry. It features a simulation environment for scalable training and real-world generalization.", "result": "AEOS demonstrated better odometry accuracy compared to traditional, optimization-only, and fully learned baselines in both simulated and real-world scenarios.", "conclusion": "The framework significantly enhances real-time odometry performance for UAVs while addressing hardware limitations, making it viable for practical deployment."}}
{"id": "2509.08963", "pdf": "https://arxiv.org/pdf/2509.08963", "abs": "https://arxiv.org/abs/2509.08963", "authors": ["Alexander Binder", "Nastaran Takmil-Homayouni", "Urun Dogan"], "title": "Value bounds and Convergence Analysis for Averages of LRP attributions", "categories": ["cs.LG", "cs.CV"], "comment": "37 pages", "summary": "We analyze numerical properties of Layer-wise relevance propagation\n(LRP)-type attribution methods by representing them as a product of modified\ngradient matrices. This representation creates an analogy to matrix\nmultiplications of Jacobi-matrices which arise from the chain rule of\ndifferentiation. In order to shed light on the distribution of attribution\nvalues, we derive upper bounds for singular values. Furthermore we derive\ncomponent-wise bounds for attribution map values. As a main result, we apply\nthese component-wise bounds to obtain multiplicative constants. These constants\ngovern the convergence of empirical means of attributions to expectations of\nattribution maps. This finding has important implications for scenarios where\nmultiple non-geometric data augmentations are applied to individual test\nsamples, as well as for Smoothgrad-type attribution methods. In particular, our\nanalysis reveals that the constants for LRP-beta remain independent of weight\nnorms, a significant distinction from both gradient-based methods and\nLRP-epsilon.", "AI": {"tldr": "The study examines numerical properties of Layer-wise relevance propagation (LRP) attribution methods, deriving bounds for attribution values and constants governing empirical convergence. Notably, LRP-beta constants remain independent of weight norms.", "motivation": "The motivation is to understand the numerical behavior of LRP attribution methods and their implications for empirical convergence, especially in test samples with multiple data augmentations.", "method": "The paper analyzes LRP-type methods by representing them via modified gradient matrices and deriving upper bounds for singular values and attribution map components.", "result": "The study finds constants that govern the convergence of attributions to expectations, highlighting notable differences between LRP-beta and other approaches like gradient-based methods and LRP-epsilon.", "conclusion": "LRP-beta attribution methods offer a distinct advantage with constants unaffected by weight norms, providing insights for applications like Smoothgrad and multiple augmentations on test samples."}}
{"id": "2509.09072", "pdf": "https://arxiv.org/pdf/2509.09072", "abs": "https://arxiv.org/abs/2509.09072", "authors": ["Ahmed Adnan", "Mushfiqur Rahman", "Saad Sakib Noor", "Kazi Sakib"], "title": "CLARA: A Developer's Companion for Code Comprehension and Analysis", "categories": ["cs.SE"], "comment": "In proceedings at the 40th IEEE/ACM International Conference on\n  Automated Software Engineering, ASE 2025", "summary": "Code comprehension and analysis of open-source project codebases is a task\nfrequently performed by developers and researchers. However, existing tools\nthat practitioners use for assistance with such tasks often require prior\nproject setup, lack context-awareness, and involve significant manual effort.\nTo address this, we present CLARA, a browser extension that utilizes a\nstate-of-the-art inference model to assist developers and researchers in: (i)\ncomprehending code files and code fragments, (ii) code refactoring, and (iii)\ncode quality attribute detection. We qualitatively evaluated CLARA's inference\nmodel using existing datasets and methodology, and performed a comprehensive\nuser study with 10 developers and academic researchers to assess its usability\nand usefulness. The results show that CLARA is useful, accurate, and practical\nin code comprehension and analysis tasks. CLARA is an open-source tool\navailable at https://github.com/SaadNoor555/CLARA_tool_demo. A video showing\nthe full capabilities of CLARA can be found at\nhttps://youtu.be/VDKVXvIH41Q?si=qBFsmS_Y4m_9x3YH.", "AI": {"tldr": "CLARA is an open-source browser extension designed to assist with code comprehension, refactoring, and quality detection using an inference model, evaluated for usability and accuracy.", "motivation": "Existing tools for understanding and analyzing open-source codebases require extensive setup, lack context-awareness, and demand significant manual intervention, making them inefficient.", "method": "The authors developed CLARA, a tool using state-of-the-art inference models, and conducted qualitative evaluation using datasets as well as a user study with 10 developers and researchers.", "result": "CLARA was found to be accurate, usable, and practical for code-related tasks during evaluation by developers and researchers.", "conclusion": "CLARA enhances code comprehension and analysis by addressing gaps in existing tools. It is open-source and demonstrated to be effective and user-friendly."}}
{"id": "2509.09210", "pdf": "https://arxiv.org/pdf/2509.09210", "abs": "https://arxiv.org/abs/2509.09210", "authors": ["Xing Gao", "Zherui Huang", "Weiyao Lin", "Xiao Sun"], "title": "ProgD: Progressive Multi-scale Decoding with Dynamic Graphs for Joint Multi-agent Motion Forecasting", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Accurate motion prediction of surrounding agents is crucial for the safe\nplanning of autonomous vehicles. Recent advancements have extended prediction\ntechniques from individual agents to joint predictions of multiple interacting\nagents, with various strategies to address complex interactions within future\nmotions of agents. However, these methods overlook the evolving nature of these\ninteractions. To address this limitation, we propose a novel progressive\nmulti-scale decoding strategy, termed ProgD, with the help of dynamic\nheterogeneous graph-based scenario modeling. In particular, to explicitly and\ncomprehensively capture the evolving social interactions in future scenarios,\ngiven their inherent uncertainty, we design a progressive modeling of scenarios\nwith dynamic heterogeneous graphs. With the unfolding of such dynamic\nheterogeneous graphs, a factorized architecture is designed to process the\nspatio-temporal dependencies within future scenarios and progressively\neliminate uncertainty in future motions of multiple agents. Furthermore, a\nmulti-scale decoding procedure is incorporated to improve on the future\nscenario modeling and consistent prediction of agents' future motion. The\nproposed ProgD achieves state-of-the-art performance on the INTERACTION\nmulti-agent prediction benchmark, ranking $1^{st}$, and the Argoverse 2\nmulti-world forecasting benchmark.", "AI": {"tldr": "This paper introduces a novel strategy, ProgD, leveraging dynamic heterogeneous graphs for more accurate motion predictions of interacting agents, specifically tailored to autonomous vehicle systems.", "motivation": "Existing methods for motion prediction overlook the evolving nature of interactions among agents, which is critical for future scenario modeling in autonomous vehicle systems.", "method": "The paper proposes the ProgD approach, utilizing dynamic heterogeneous graphs to progressively model social interactions and employs a multi-scale decoding strategy to address spatio-temporal dependencies and reduce future motion uncertainty.", "result": "ProgD achieved state-of-the-art rankings: 1st on the INTERACTION multi-agent prediction benchmark and competitive performance on the Argoverse 2 forecasting benchmark.", "conclusion": "ProgD's holistic approach to prediction improves interaction modeling, delivering improved accuracy in autonomous vehicle motion forecasting scenarios."}}
{"id": "2509.09525", "pdf": "https://arxiv.org/pdf/2509.09525", "abs": "https://arxiv.org/abs/2509.09525", "authors": ["Jialiang Huang", "Teng Ma", "Zheng Liu", "Sixing Lin", "Kang Chen", "Jinlei Jiang", "Xia Liao", "Yingdi Shan", "Yongwei Wu", "Ning Zhang", "Mengting Lu", "Tao Ma", "Haifeng Gong", "Mingxing Zhang"], "title": "TrEnv: Transparently Share Serverless Execution Environments Across Different Functions and Nodes", "categories": ["cs.DC", "cs.OS"], "comment": "38 pages", "summary": "Serverless computing provides dynamic scalability, but its infrastructure\noverhead becomes a bottleneck for emerging workloads such as LLM agents, which\nexhibit unpredictable invocation patterns and variable resource demands. Our\nanalysis shows that for these agents, the cost of running on serverless\nplatforms can reach up to 70% of the cost of LLM API calls. This finding\nmotivates the need for a more efficient, high-density serverless platform. We\npresent TrEnv, a co-designed serverless platform that supports both container-\nand VM-based environments, optimized for the unique demands of LLM agents.\nTrEnv reduces startup latency and memory usage through repurposable sandboxes\nand memory templates, which enable fast reuse and restoration of execution\nenvironments. To further reduce overhead in VM-based agent workloads, TrEnv\nleverages browser sharing and a page cache bypassing mechanism. Evaluations\nshow that TrEnv reduces P99 latency by up to 7X and memory usage by 48% in\ncontainer-based settings, and achieves up to 58% lower P99 latency and 61%\nmemory savings for VM-based agents compared to state-of-the-art systems like\nE2B.", "AI": {"tldr": "TrEnv is a serverless platform tailored for LLM agents, reducing latency and memory overhead compared to current systems.", "motivation": "Emerging workloads like LLM agents have unpredictable patterns, requiring a more efficient serverless platform to address high infrastructure costs.", "method": "TrEnv optimizes serverless computing via co-designed environments, repurposable sandboxes, memory templates, browser sharing, and page cache bypassing.", "result": "P99 latency reduced by up to 7X and memory usage reduced by 48% in container settings; for VM-based agents, latency decreased by 58% and memory reduced by 61%, outperforming systems like E2B.", "conclusion": "TrEnv demonstrates significant efficiency improvements for serverless computing tailored for the unique demands of LLM agents."}}
{"id": "2509.09055", "pdf": "https://arxiv.org/pdf/2509.09055", "abs": "https://arxiv.org/abs/2509.09055", "authors": ["Piyush Pant"], "title": "Improving LLM Safety and Helpfulness using SFT and DPO: A Study on OPT-350M", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "17 pages, 3 figures. Code and dataset available at\n  https://github.com/PiyushWithPant/Improving-LLM-Safety-and-Helpfulness-using-SFT-and-DPO", "summary": "This research investigates the effectiveness of alignment techniques,\nSupervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and a\ncombined SFT+DPO approach on improving the safety and helpfulness of the\nOPT-350M language model. Utilizing the Anthropic Helpful-Harmless RLHF dataset,\nwe train and evaluate four models: the base OPT350M, an SFT model, a DPO model,\nand a model trained with both SFT and DPO. We introduce three key evaluation\nmetrics: Harmlessness Rate (HmR), Helpfulness Rate (HpR), and a Combined\nAlignment Score (CAS), all derived from reward model outputs. The results show\nthat while SFT outperforms DPO, The combined SFT+DPO model outperforms all\nothers across all metrics, demonstrating the complementary nature of these\ntechniques. Our findings also highlight challenges posed by noisy data, limited\nGPU resources, and training constraints. This study offers a comprehensive view\nof how fine-tuning strategies affect model alignment and provides a foundation\nfor more robust alignment pipelines in future work.", "AI": {"tldr": "This study enhances the safety and helpfulness of the OPT-350M language model using fine-tuning techniques (SFT, DPO, and their combination). Combined approaches outperform others in evaluation metrics.", "motivation": "To determine the effectiveness of alignment techniques in improving safety and helpfulness in a smaller-sized language model (OPT-350M).", "method": "The authors fine-tuned the OPT-350M model using SFT, DPO, and a combination of both, leveraging the Anthropic Helpful-Harmless RLHF dataset, and evaluated their performance using metrics: Harmlessness Rate, Helpfulness Rate, and Combined Alignment Score.", "result": "The combined SFT+DPO model achieved the best results, outperforming both standalone SFT and DPO across all evaluation metrics, indicating the techniques' complementary strengths.", "conclusion": "The study emphasizes the combined approach's superiority in improving alignment and highlights challenges like noisy data and limited resources, paving the way for more efficient alignment strategies."}}
{"id": "2509.08940", "pdf": "https://arxiv.org/pdf/2509.08940", "abs": "https://arxiv.org/abs/2509.08940", "authors": ["Lisa Dunlap", "Joseph E. Gonzalez", "Trevor Darrell", "Fabian Caba Heilbron", "Josef Sivic", "Bryan Russell"], "title": "Discovering Divergent Representations between Text-to-Image Models", "categories": ["cs.CV"], "comment": "Accepted to ICCV 2025. Code available at\n  https://github.com/adobe-research/CompCon", "summary": "In this paper, we investigate when and how visual representations learned by\ntwo different generative models diverge. Given two text-to-image models, our\ngoal is to discover visual attributes that appear in images generated by one\nmodel but not the other, along with the types of prompts that trigger these\nattribute differences. For example, \"flames\" might appear in one model's\noutputs when given prompts expressing strong emotions, while the other model\ndoes not produce this attribute given the same prompts. We introduce CompCon\n(Comparing Concepts), an evolutionary search algorithm that discovers visual\nattributes more prevalent in one model's output than the other, and uncovers\nthe prompt concepts linked to these visual differences. To evaluate CompCon's\nability to find diverging representations, we create an automated data\ngeneration pipeline to produce ID2, a dataset of 60 input-dependent\ndifferences, and compare our approach to several LLM- and VLM-powered\nbaselines. Finally, we use CompCon to compare popular text-to-image models,\nfinding divergent representations such as how PixArt depicts prompts mentioning\nloneliness with wet streets and Stable Diffusion 3.5 depicts African American\npeople in media professions. Code at: https://github.com/adobe-research/CompCon", "AI": {"tldr": "The paper explores differences in visual outputs between generative text-to-image models, introducing CompCon, an evolutionary search algorithm to identify attribute divergences and associated prompt types.", "motivation": "Understanding how visual representations generated by different text-to-image models diverge can improve model design, fairness, and prompt utility.", "method": "The authors developed CompCon, an evolutionary search algorithm, alongside creating ID2, a dataset with 60 differences, to identify prompt-induced visual discrepancies between models.", "result": "CompCon successfully uncovers various visual divergences, finding that PixArt associates loneliness with wet streets, and Stable Diffusion 3.5 represents African American people in media professions distinctively.", "conclusion": "CompCon is effective in identifying divergent visual attributes and linked concepts, providing insights into nuanced representations in generative models."}}
{"id": "2509.09206", "pdf": "https://arxiv.org/pdf/2509.09206", "abs": "https://arxiv.org/abs/2509.09206", "authors": ["Farhad Nawaz", "Faizan M. Tariq", "Sangjae Bae", "David Isele", "Avinash Singh", "Nadia Figueroa", "Nikolai Matni", "Jovin D'sa"], "title": "Occupancy-aware Trajectory Planning for Autonomous Valet Parking in Uncertain Dynamic Environments", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Accurately reasoning about future parking spot availability and integrated\nplanning is critical for enabling safe and efficient autonomous valet parking\nin dynamic, uncertain environments. Unlike existing methods that rely solely on\ninstantaneous observations or static assumptions, we present an approach that\npredicts future parking spot occupancy by explicitly distinguishing between\ninitially vacant and occupied spots, and by leveraging the predicted motion of\ndynamic agents. We introduce a probabilistic spot occupancy estimator that\nincorporates partial and noisy observations within a limited Field-of-View\n(FoV) model and accounts for the evolving uncertainty of unobserved regions.\nCoupled with this, we design a strategy planner that adaptively balances\ngoal-directed parking maneuvers with exploratory navigation based on\ninformation gain, and intelligently incorporates wait-and-go behaviors at\npromising spots. Through randomized simulations emulating large parking lots,\nwe demonstrate that our framework significantly improves parking efficiency,\nsafety margins, and trajectory smoothness compared to existing approaches.", "AI": {"tldr": "The paper introduces an approach for autonomous valet parking by predicting future parking spot availability and planning dynamic maneuvers to improve efficiency and safety.", "motivation": "Existing methods for autonomous valet parking rely on static assumptions or instantaneous observations, which limit their adaptability in uncertain and dynamic environments.", "method": "The authors developed a probabilistic spot occupancy estimator that incorporates partial and noisy data from a limited Field-of-View model and accounts for evolving uncertainty. They combined this with a strategy planner for adaptive parking maneuvers, exploratory navigation, and wait-and-go behaviors.", "result": "Simulations in large parking lots showed the approach improved parking efficiency, safety margins, and trajectory smoothness compared to prior methods.", "conclusion": "This framework advances autonomous valet parking systems by enabling better prediction, planning, and adaptability in dynamic environments, addressing key limitations of existing solutions."}}
{"id": "2509.08980", "pdf": "https://arxiv.org/pdf/2509.08980", "abs": "https://arxiv.org/abs/2509.08980", "authors": ["Daniel Richards Arputharaj", "Charlotte Rodriguez", "Angelo Rodio", "Giovanni Neglia"], "title": "Green Federated Learning via Carbon-Aware Client and Time Slot Scheduling", "categories": ["cs.LG"], "comment": null, "summary": "Training large-scale machine learning models incurs substantial carbon\nemissions. Federated Learning (FL), by distributing computation across\ngeographically dispersed clients, offers a natural framework to leverage\nregional and temporal variations in Carbon Intensity (CI). This paper\ninvestigates how to reduce emissions in FL through carbon-aware client\nselection and training scheduling. We first quantify the emission savings of a\ncarbon-aware scheduling policy that leverages slack time -- permitting a modest\nextension of the training duration so that clients can defer local training\nrounds to lower-carbon periods. We then examine the performance trade-offs of\nsuch scheduling which stem from statistical heterogeneity among clients,\nselection bias in participation, and temporal correlation in model updates. To\nleverage these trade-offs, we construct a carbon-aware scheduler that\nintegrates slack time, $\\alpha$-fair carbon allocation, and a global\nfine-tuning phase. Experiments on real-world CI data show that our scheduler\noutperforms slack-agnostic baselines, achieving higher model accuracy across a\nwide range of carbon budgets, with especially strong gains under tight carbon\nconstraints.", "AI": {"tldr": "The paper explores reducing carbon emissions in Federated Learning through carbon-aware client scheduling and training practices, offering higher model accuracy under stringent carbon limitations.", "motivation": "Federated Learning incurs high carbon emissions due to large-scale distributed training, but leveraging regional and temporal variations in carbon intensity could mitigate this impact.", "method": "The authors propose a carbon-aware scheduler integrating slack time, \u03b1-fair carbon allocation, and global fine-tuning, balancing carbon reduction and model performance trade-offs.", "result": "Experiments on real-world carbon intensity data demonstrated significant accuracy improvements over conventional methods, particularly under strict carbon constraints.", "conclusion": "A carefully designed carbon-aware FL framework can achieve substantial emission reductions without compromising model performance, making it suitable under varying carbon budgets."}}
{"id": "2509.09192", "pdf": "https://arxiv.org/pdf/2509.09192", "abs": "https://arxiv.org/abs/2509.09192", "authors": ["Doha Nam", "Taehyoun Kim", "Duksan Ryu", "Jongmoon Baik"], "title": "Probing Pre-trained Language Models on Code Changes: Insights from ReDef, a High-Confidence Just-in-Time Defect Prediction Dataset", "categories": ["cs.SE", "cs.AI"], "comment": "An anonymous link containing the dataset, construction scripts, and\n  experimental code is publicly available for reproducibility:\n  https://figshare.com/s/4f202bc0921e26b41dc2", "summary": "Just-in-Time software defect prediction (JIT-SDP) plays a critical role in\nprioritizing risky code changes during code review and continuous integration.\nHowever, existing datasets often suffer from noisy labels and low precision in\nidentifying bug-inducing commits. To address this, we present ReDef\n(Revert-based Defect dataset), a high-confidence benchmark of function-level\nmodifications curated from 22 large-scale C/C++ projects. Defective cases are\nanchored by revert commits, while clean cases are validated through post-hoc\nhistory checks. Ambiguous instances are conservatively filtered out via a\nGPT-assisted triage process involving multiple votes and audits. This pipeline\nyields 3,164 defective and 10,268 clean modifications, offering substantially\nmore reliable labels than prior existing resources. Beyond dataset\nconstruction, we provide the first systematic evaluation of how pre-trained\nlanguage models (PLMs) reason about code modifications -- specifically, which\ninput encodings most effectively expose change information, and whether models\ngenuinely capture edit semantics. We fine-tune CodeBERT, CodeT5+, and UniXcoder\nunder five encoding strategies, and further probe their sensitivity through\ncounterfactual perturbations that swap added/deleted blocks, invert diff\npolarity, or inject spurious markers. Our results show that compact diff-style\nencodings consistently outperform whole-function formats across all PLMs, with\nstatistical tests confirming large, model-independent effects. However, under\ncounterfactual tests, performance degrades little or not at all -- revealing\nthat what appears to be robustness in fact reflects reliance on superficial\ncues rather than true semantic understanding. These findings indicate that,\nunlike in snapshot-based tasks, current PLMs remain limited in their ability to\ngenuinely comprehend code modifications.", "AI": {"tldr": "This paper introduces ReDef, a high-confidence dataset for software defect prediction based on revert commits, evaluates pre-trained language models' reasoning on code modifications, and uncovers limitations in semantic understanding.", "motivation": "To address the issues of noisy labels and low precision in bug-inducing commit identification in software defect prediction datasets.", "method": "Construct a reliable defect dataset using revert commits and post-hoc history validation, filter ambiguous cases via GPT-assisted triage, evaluate PLMs using five encoding strategies, and perform counterfactual tests.", "result": "ReDef includes 3,164 defective and 10,268 clean modifications with more reliable labeling than existing datasets. Compact diff-style encodings outperform whole-function formats for PLMs, exposing reliance on superficial cues under counterfactual tests.", "conclusion": "Current pre-trained language models show limited ability to understand code modifications semantically, relying on superficial patterns instead."}}
{"id": "2509.09070", "pdf": "https://arxiv.org/pdf/2509.09070", "abs": "https://arxiv.org/abs/2509.09070", "authors": ["Chaeyun Ko"], "title": "STRIDE: Scalable and Interpretable XAI via Subset-Free Functional Decomposition", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "10 pages, 2 figures", "summary": "Most explainable AI (XAI) frameworks face two practical limitations: the\nexponential cost of reasoning over feature subsets and the reduced\nexpressiveness of summarizing effects as single scalar values. We present\nSTRIDE, a scalable framework that aims to mitigate both issues by framing\nexplanation as a subset-enumeration-free, orthogonal functional decomposition\nin a Reproducing Kernel Hilbert Space (RKHS). Rather than focusing only on\nscalar attributions, STRIDE computes functional components f_S(x_S) via an\nanalytical projection scheme based on a recursive kernel-centering procedure,\navoiding explicit subset enumeration. In the tabular setups we study, the\napproach is model-agnostic, provides both local and global views, and is\nsupported by theoretical results on orthogonality and L^2 convergence under\nstated assumptions. On public tabular benchmarks in our environment, we\nobserved speedups ranging from 0.6 times (slower than TreeSHAP on a small\ndataset) to 9.7 times (California), with a median approximate 3.0 times across\n10 datasets, while maintaining high fidelity (R^2 between 0.81 and 0.999) and\nsubstantial rank agreement on most datasets. Overall, STRIDE complements scalar\nattribution methods by offering a structured functional perspective, enabling\nnovel diagnostics like 'component surgery' to quantitatively measure the impact\nof specific interactions within our experimental scope.", "AI": {"tldr": "STRIDE is a scalable model-agnostic framework for explainable AI (XAI) that addresses inefficiencies in reasoning over feature subsets and limitations of scalar attribution by leveraging orthogonal functional decomposition within RKHS.", "motivation": "Current XAI methods face challenges like high computational cost in subset reasoning and reduced interpretability when effects are represented as single scalar values. STRIDE aims to overcome these obstacles for better scalability and expressiveness.", "method": "STRIDE uses functional decomposition in the RKHS and computes functional components via recursive kernel-centering procedures. It avoids subset enumeration and supports both local and global views.", "result": "STRIDE achieved a speedup of up to 9.7 times on benchmarks while maintaining high fidelity (R2 \u2265 0.81) and strong rank agreement across datasets.", "conclusion": "STRIDE complements XAI scalar attribution methods, introduces structured functional diagnostics, and demonstrates scalability and effectiveness in tabular setups."}}
{"id": "2509.09215", "pdf": "https://arxiv.org/pdf/2509.09215", "abs": "https://arxiv.org/abs/2509.09215", "authors": ["Qinnan Hu", "Yuntao Wang", "Yuan Gao", "Zhou Su", "Linkang Du"], "title": "Enabling Regulatory Multi-Agent Collaboration: Architecture, Challenges, and Solutions", "categories": ["cs.AI", "cs.CR"], "comment": "7 pages, 6 figures", "summary": "Large language models (LLMs)-empowered autonomous agents are transforming\nboth digital and physical environments by enabling adaptive, multi-agent\ncollaboration. While these agents offer significant opportunities across\ndomains such as finance, healthcare, and smart manufacturing, their\nunpredictable behaviors and heterogeneous capabilities pose substantial\ngovernance and accountability challenges. In this paper, we propose a\nblockchain-enabled layered architecture for regulatory agent collaboration,\ncomprising an agent layer, a blockchain data layer, and a regulatory\napplication layer. Within this framework, we design three key modules: (i) an\nagent behavior tracing and arbitration module for automated accountability,\n(ii) a dynamic reputation evaluation module for trust assessment in\ncollaborative scenarios, and (iii) a malicious behavior forecasting module for\nearly detection of adversarial activities. Our approach establishes a\nsystematic foundation for trustworthy, resilient, and scalable regulatory\nmechanisms in large-scale agent ecosystems. Finally, we discuss the future\nresearch directions for blockchain-enabled regulatory frameworks in multi-agent\nsystems.", "AI": {"tldr": "The paper proposes a blockchain-enabled architecture to improve governance, accountability, and trust for large language model-driven multi-agent systems in digital and physical domains.", "motivation": "The motivation is to address governance and accountability challenges posed by unpredictable behaviors and varying capabilities of LLM-empowered autonomous agents.", "method": "The authors introduce a layered architecture including blockchain, agents, and regulatory applications, with modules for behavior tracing, reputation assessment, and malicious activity forecasting.", "result": "The proposed framework establishes a foundation for trustworthy, resilient, and scalable regulatory mechanisms within agent ecosystems.", "conclusion": "The blockchain-enabled architecture enhances collaboration and accountability in agent systems, while suggesting future research directions for multi-agent regulatory frameworks."}}
{"id": "2509.08971", "pdf": "https://arxiv.org/pdf/2509.08971", "abs": "https://arxiv.org/abs/2509.08971", "authors": ["Julien Loiseau", "Hyun Lim", "Andr\u00e9s Yag\u00fce L\u00f3pez", "Mammadbaghir Baghirzade", "Shihab Shahriar Khan", "Yoonsoo Kim", "Sudarshan Neopane", "Alexander Strack", "Farhana Taiyebah", "Benjamin K. Bergen"], "title": "HARD: A Performance Portable Radiation Hydrodynamics Code based on FleCSI Framework", "categories": ["physics.comp-ph", "astro-ph.IM", "cs.DC"], "comment": "15 pages, 8 figures", "summary": "Hydrodynamics And Radiation Diffusion} (HARD) is an open-source application\nfor high-performance simulations of compressible hydrodynamics with\nradiation-diffusion coupling. Built on the FleCSI (Flexible Computational\nScience Infrastructure) framework, HARD expresses its computational units as\ntasks whose execution can be orchestrated by multiple back-end runtimes,\nincluding Legion, MPI, and HPX. Node-level parallelism is delegated to Kokkos,\nproviding a single, portable code base that runs efficiently on laptops, small\nhomogeneous clusters, and the largest heterogeneous supercomputers currently\navailable. To ensure scientific reliability, HARD includes a regression-test\nsuite that automatically reproduces canonical verification problems such as the\nSod and LeBlanc shock tubes and the Sedov blast wave, comparing numerical\nsolutions against known analytical results. The project is distributed under an\nOSI-approved license, hosted on GitHub, and accompanied by reproducible build\nscripts and continuous integration workflows. This combination of performance\nportability, verification infrastructure, and community-focused development\nmakes HARD a sustainable platform for advancing radiation hydrodynamics\nresearch across multiple domains.", "AI": {"tldr": "HARD is an open-source tool designed for high-performance simulations, focusing on compressible hydrodynamics coupled with radiation diffusion, leveraging extensible computation frameworks.", "motivation": "To provide a sustainable, open-source platform capable of handling complex radiation hydrodynamics simulations across diverse computing environments.", "method": "The paper introduces HARD, using FleCSI for expressing computational tasks, Kokkos for efficient node-level parallelism, and incorporating verification tests against analytical solutions.", "result": "HARD showcases efficient performance across various environments, reproduces canonical verification problems, and supports community-focused development with reliable tools.", "conclusion": "HARD emerges as a reliable and flexible simulation tool that facilitates advancements in radiation hydrodynamics research, suitable for diverse computational setups."}}
{"id": "2509.09082", "pdf": "https://arxiv.org/pdf/2509.09082", "abs": "https://arxiv.org/abs/2509.09082", "authors": ["Zhongqiu Li", "Shiquan Wang", "Ruiyu Fang", "Mengjiao Bao", "Zhenhe Wu", "Shuangyong Song", "Yongxiang Li", "Zhongjiang He"], "title": "MR-UIE: Multi-Perspective Reasoning with Reinforcement Learning for Universal Information Extraction", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) demonstrate robust capabilities across diverse\nresearch domains. However, their performance in universal information\nextraction (UIE) remains insufficient, especially when tackling structured\noutput scenarios that involve complex schema descriptions and require\nmulti-step reasoning. While existing approaches enhance the performance of LLMs\nthrough in-context learning and instruction tuning, significant limitations\nnonetheless persist. To enhance the model's generalization ability, we propose\nintegrating reinforcement learning (RL) with multi-perspective reasoning for\ninformation extraction (IE) tasks. Our work transitions LLMs from passive\nextractors to active reasoners, enabling them to understand not only what to\nextract but also how to reason. Experiments conducted on multiple IE benchmarks\ndemonstrate that MR-UIE consistently elevates extraction accuracy across\ndomains and surpasses state-of-the-art methods on several datasets.\nFurthermore, incorporating multi-perspective reasoning into RL notably enhances\ngeneralization in complex IE tasks, underscoring the critical role of reasoning\nin challenging scenarios.", "AI": {"tldr": "The paper introduces a method integrating reinforcement learning and multi-perspective reasoning into large language models for universal information extraction tasks to improve accuracy and generalization.", "motivation": "To address limitations of large language models in universal information extraction tasks, particularly in handling structured output scenarios and complex reasoning requirements.", "method": "Integrating reinforcement learning with multi-perspective reasoning to transition large language models from passive extractors to active reasoners.", "result": "Experiments on multiple IE benchmarks show significant improvements in extraction accuracy and surpassing state-of-the-art methods on several datasets.", "conclusion": "Multi-perspective reasoning and reinforcement learning enhance large language models, proving critical for complex information extraction tasks."}}
{"id": "2509.08949", "pdf": "https://arxiv.org/pdf/2509.08949", "abs": "https://arxiv.org/abs/2509.08949", "authors": ["Yibin Wang", "Wondimagegn Beshah", "Padmanava Dash", "Haifeng Wang"], "title": "An U-Net-Based Deep Neural Network for Cloud Shadow and Sun-Glint Correction of Unmanned Aerial System (UAS) Imagery", "categories": ["cs.CV"], "comment": null, "summary": "The use of unmanned aerial systems (UASs) has increased tremendously in the\ncurrent decade. They have significantly advanced remote sensing with the\ncapability to deploy and image the terrain as per required spatial, spectral,\ntemporal, and radiometric resolutions for various remote sensing applications.\nOne of the major advantages of UAS imagery is that images can be acquired in\ncloudy conditions by flying the UAS under the clouds. The limitation to the\ntechnology is that the imagery is often sullied by cloud shadows. Images taken\nover water are additionally affected by sun glint. These are two pose serious\nissues for estimating water quality parameters from the UAS images. This study\nproposes a novel machine learning approach first to identify and extract\nregions with cloud shadows and sun glint and separate such regions from\nnon-obstructed clear sky regions and sun-glint unaffected regions. The data was\nextracted from the images at pixel level to train an U-Net based deep learning\nmodel and best settings for model training was identified based on the various\nevaluation metrics from test cases. Using this evaluation, a high-quality image\ncorrection model was determined, which was used to recover the cloud shadow and\nsun glint areas in the images.", "AI": {"tldr": "A novel U-Net based deep learning model is introduced to identify and correct cloud shadows and sun glint in unmanned aerial system (UAS) imagery, particularly for water quality assessment.", "motivation": "Although UAS imagery is advantageous for remote sensing, its utility is hindered by disturbances like cloud shadows and sun glint, particularly when analyzing water quality.", "method": "A U-Net based machine learning model was designed to detect and segregate cloud shadowed and sun-glint regions from clear areas, followed by applying a corrective mechanism to restore the affected image sections.", "result": "The model achieved high-quality correction of affected UAS images, validated by robust evaluation metrics.", "conclusion": "This study successfully developed and implemented a deep learning approach to address key limitations in UAS-based imagery, enhancing its usability for remote sensing of water bodies."}}
{"id": "2509.09283", "pdf": "https://arxiv.org/pdf/2509.09283", "abs": "https://arxiv.org/abs/2509.09283", "authors": ["Yueqi Zhang", "Quancheng Qian", "Taixian Hou", "Peng Zhai", "Xiaoyi Wei", "Kangmai Hu", "Jiafu Yi", "Lihua Zhang"], "title": "RENet: Fault-Tolerant Motion Control for Quadruped Robots via Redundant Estimator Networks under Visual Collapse", "categories": ["cs.RO"], "comment": "Accepted for IEEE Robotics and Automation Letters (RA-L)", "summary": "Vision-based locomotion in outdoor environments presents significant\nchallenges for quadruped robots. Accurate environmental prediction and\neffective handling of depth sensor noise during real-world deployment remain\ndifficult, severely restricting the outdoor applications of such algorithms. To\naddress these deployment challenges in vision-based motion control, this letter\nproposes the Redundant Estimator Network (RENet) framework. The framework\nemploys a dual-estimator architecture that ensures robust motion performance\nwhile maintaining deployment stability during onboard vision failures. Through\nan online estimator adaptation, our method enables seamless transitions between\nestimation modules when handling visual perception uncertainties. Experimental\nvalidation on a real-world robot demonstrates the framework's effectiveness in\ncomplex outdoor environments, showing particular advantages in scenarios with\ndegraded visual perception. This framework demonstrates its potential as a\npractical solution for reliable robotic deployment in challenging field\nconditions. Project website: https://RENet-Loco.github.io/", "AI": {"tldr": "This paper introduces a framework called Redundant Estimator Network (RENet) for robust quadruped locomotion in outdoor environments, focusing on overcoming challenges in vision-based depth estimation and environmental prediction.", "motivation": "The motivation behind this paper is to enable reliable vision-based locomotion for quadruped robots in outdoor environments where visual perception can be uncertain or noisy.", "method": "The proposed methodology involves a dual-estimator architecture that incorporates online estimator adaptation, allowing transitions between modules to handle perception uncertainties and vision failures.", "result": "The RENet framework was experimentally validated on a real-world quadruped robot, achieving reliable motion control in complex outdoor environments, especially in conditions of degraded visual perception.", "conclusion": "RENet provides a practical solution for robust and stable robotic deployment in challenging field conditions, improving real-world applicability for outdoor locomotion algorithms."}}
{"id": "2509.08988", "pdf": "https://arxiv.org/pdf/2509.08988", "abs": "https://arxiv.org/abs/2509.08988", "authors": ["Brendan Young", "Brendan Alvey", "Andreas Werbrouck", "Will Murphy", "James Keller", "Mattias J. Young", "Matthew Maschmann"], "title": "Active Learning and Explainable AI for Multi-Objective Optimization of Spin Coated Polymers", "categories": ["cs.LG"], "comment": "8 pages, 7 figures, Presented at 2025 AAAI Spring Symposium Series", "summary": "Spin coating polymer thin films to achieve specific mechanical properties is\ninherently a multi-objective optimization problem. We present a framework that\nintegrates an active Pareto front learning algorithm (PyePAL) with\nvisualization and explainable AI techniques to optimize processing parameters.\nPyePAL uses Gaussian process models to predict objective values (hardness and\nelasticity) from the design variables (spin speed, dilution, and polymer\nmixture), guiding the adaptive selection of samples toward promising regions of\nthe design space. To enable interpretable insights into the high-dimensional\ndesign space, we utilize UMAP (Uniform Manifold Approximation and Projection)\nfor two-dimensional visualization of the Pareto front exploration.\nAdditionally, we incorporate fuzzy linguistic summaries, which translate the\nlearned relationships between process parameters and performance objectives\ninto linguistic statements, thus enhancing the explainability and understanding\nof the optimization results. Experimental results demonstrate that our method\nefficiently identifies promising polymer designs, while the visual and\nlinguistic explanations facilitate expert-driven analysis and knowledge\ndiscovery.", "AI": {"tldr": "This paper discusses a framework combining PyePAL, UMAP visualization, and fuzzy linguistic summaries for optimizing polymer thin film processing parameters.", "motivation": "The goal was to optimize spin coating parameters to achieve specific mechanical properties in polymer thin films, ensuring efficient exploration of a high-dimensional design space.", "method": "The authors utilized PyePAL, a Pareto front learning algorithm with Gaussian process models, UMAP for dimensional visualization, and fuzzy linguistic summaries to interpret the optimization process.", "result": "The approach effectively identified optimal designs for specific mechanical properties and provided interpretable insights through visualizations and linguistic summaries.", "conclusion": "The integrated framework enables efficient parameter optimization and facilitates better understanding of the trade-offs in thin film design, aiding expert decision-making."}}
{"id": "2509.09194", "pdf": "https://arxiv.org/pdf/2509.09194", "abs": "https://arxiv.org/abs/2509.09194", "authors": ["Ayelet Berzack", "Guy Katz"], "title": "On Integrating Large Language Models and Scenario-Based Programming for Improving Software Reliability", "categories": ["cs.SE", "cs.AI", "68N19"], "comment": null, "summary": "Large Language Models (LLMs) are fast becoming indispensable tools for\nsoftware developers, assisting or even partnering with them in crafting complex\nprograms. The advantages are evident -- LLMs can significantly reduce\ndevelopment time, generate well-organized and comprehensible code, and\noccasionally suggest innovative ideas that developers might not conceive on\ntheir own. However, despite their strengths, LLMs will often introduce\nsignificant errors and present incorrect code with persuasive confidence,\npotentially misleading developers into accepting flawed solutions.\n  In order to bring LLMs into the software development cycle in a more reliable\nmanner, we propose a methodology for combining them with ``traditional''\nsoftware engineering techniques in a structured way, with the goal of\nstreamlining the development process, reducing errors, and enabling users to\nverify crucial program properties with increased confidence. Specifically, we\nfocus on the Scenario-Based Programming (SBP) paradigm -- an event-driven,\nscenario-based approach for software engineering -- to allow human developers\nto pour their expert knowledge into the LLM, as well as to inspect and verify\nits outputs.\n  To evaluate our methodology, we conducted a significant case study, and used\nit to design and implement the Connect4 game. By combining LLMs and SBP we were\nable to create a highly-capable agent, which could defeat various strong\nexisting agents. Further, in some cases, we were able to formally verify the\ncorrectness of our agent. Finally, our experience reveals interesting insights\nregarding the ease-of-use of our proposed approach. The full code of our\ncase-study will be made publicly available with the final version of this\npaper.", "AI": {"tldr": "The paper explores a methodology to integrate Large Language Models (LLMs) with traditional software engineering practices, specifically Scenario-Based Programming (SBP), to enhance software development reliability and correctness. A Connect4 agent built using this approach demonstrates promising results.", "motivation": "LLMs offer significant benefits in software development, such as reduced development time and creative code suggestions. However, their tendency to produce confident but incorrect outputs poses risks, necessitating a structured approach to leverage their potential reliably.", "method": "The authors propose combining LLMs with the Scenario-Based Programming (SBP) paradigm, allowing developers to incorporate domain knowledge, inspect outputs, and verify program properties. This integration was tested through a case study involving the development of a Connect4 game.", "result": "The methodology successfully produced a Connect4 agent capable of defeating strong existing agents. Additionally, some aspects of the agent's correctness were formally verified, demonstrating the approach's effectiveness.", "conclusion": "Integrating LLMs with SBP enhances the software development process by reducing errors and improving verification. The proposed methodology shows promise in creating reliable and high-performing software solutions while shedding light on its user-friendliness."}}
{"id": "2509.09362", "pdf": "https://arxiv.org/pdf/2509.09362", "abs": "https://arxiv.org/abs/2509.09362", "authors": ["Hanfei Zhou", "Lei Shi"], "title": "Expressive Power of Deep Networks on Manifolds: Simultaneous Approximation", "categories": ["math.NA", "cs.LG", "cs.NA", "stat.ML"], "comment": null, "summary": "A key challenge in scientific machine learning is solving partial\ndifferential equations (PDEs) on complex domains, where the curved geometry\ncomplicates the approximation of functions and their derivatives required by\ndifferential operators. This paper establishes the first simultaneous\napproximation theory for deep neural networks on manifolds. We prove that a\nconstant-depth $\\mathrm{ReLU}^{k-1}$ network with bounded weights--a property\nthat plays a crucial role in controlling generalization error--can approximate\nany function in the Sobolev space $\\mathcal{W}_p^{k}(\\mathcal{M}^d)$ to an\nerror of $\\varepsilon$ in the $\\mathcal{W}_p^{s}(\\mathcal{M}^d)$ norm, for\n$k\\geq 3$ and $s<k$, using $\\mathcal{O}(\\varepsilon^{-d/(k-s)})$ nonzero\nparameters, a rate that overcomes the curse of dimensionality by depending only\non the intrinsic dimension $d$. These results readily extend to functions in\nH\\\"older-Zygmund spaces. We complement this result with a matching lower bound,\nproving our construction is nearly optimal by showing the required number of\nparameters matches up to a logarithmic factor. Our proof of the lower bound\nintroduces novel estimates for the Vapnik-Chervonenkis dimension and\npseudo-dimension of the network's high-order derivative classes. These\ncomplexity bounds provide a theoretical cornerstone for learning PDEs on\nmanifolds involving derivatives. Our analysis reveals that the network\narchitecture leverages a sparse structure to efficiently exploit the manifold's\nlow-dimensional geometry.", "AI": {"tldr": "The paper develops a theoretical foundation for approximating functions on intricate manifolds using deep neural networks, demonstrating efficient parameter use and overcoming dimensionality issues.", "motivation": "The complexity of curved geometries in domains makes solving PDEs using traditional methods challenging, necessitating new approaches leveraging machine learning.", "method": "The authors created approximation theories showing how constant-depth ReLU networks with bounded weights can approximate functions in Sobolev spaces on manifolds.", "result": "The method efficiently achieves approximation rates without suffering from the curse of dimensionality, depending only on intrinsic manifold dimensions. They establish near-optimal bounds for required parameters.", "conclusion": "The study provides a theoretical basis for using deep neural networks to learn manifold-based PDEs, taking advantage of sparse architectural designs and low-dimensional geometry properties."}}
{"id": "2509.09245", "pdf": "https://arxiv.org/pdf/2509.09245", "abs": "https://arxiv.org/abs/2509.09245", "authors": ["Shuocheng Li", "Yihao Liu", "Silin Du", "Wenxuan Zeng", "Zhe Xu", "Mengyu Zhou", "Yeye He", "Haoyu Dong", "Shi Han", "Dongmei Zhang"], "title": "Jupiter: Enhancing LLM Data Analysis Capabilities via Notebook and Inference-Time Value-Guided Search", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) have shown great promise in automating data\nscience workflows, but existing models still struggle with multi-step reasoning\nand tool use, which limits their effectiveness on complex data analysis tasks.\nTo address this, we propose a scalable pipeline that extracts high-quality,\ntool-based data analysis tasks and their executable multi-step solutions from\nreal-world Jupyter notebooks and associated data files. Using this pipeline, we\nintroduce NbQA, a large-scale dataset of standardized task-solution pairs that\nreflect authentic tool-use patterns in practical data science scenarios. To\nfurther enhance multi-step reasoning, we present Jupiter, a framework that\nformulates data analysis as a search problem and applies Monte Carlo Tree\nSearch (MCTS) to generate diverse solution trajectories for value model\nlearning. During inference, Jupiter combines the value model and node visit\ncounts to efficiently collect executable multi-step plans with minimal search\nsteps. Experimental results show that Qwen2.5-7B and 14B-Instruct models on\nNbQA solve 77.82% and 86.38% of tasks on InfiAgent-DABench,\nrespectively-matching or surpassing GPT-4o and advanced agent frameworks.\nFurther evaluations demonstrate improved generalization and stronger tool-use\nreasoning across diverse multi-step reasoning tasks.", "AI": {"tldr": "The paper introduces a pipeline to extract practical data analysis tasks from Jupyter notebooks and proposes a dataset (NbQA) and a framework (Jupiter) that enhance multi-step reasoning for large language models using Monte Carlo Tree Search.", "motivation": "Current large language models struggle with multi-step reasoning and effective tool use in complex data analysis tasks, limiting their usefulness in automating data science workflows.", "method": "A pipeline extracts high-quality, tool-based data analysis tasks from Jupyter notebooks. NbQA dataset is introduced, and Jupiter framework employs Monte Carlo Tree Search for formulating data analysis tasks as search problems and generating solution trajectories.", "result": "Models using NbQA and Jupiter framework achieve high task-solving rates, with Qwen2.5-7B solving 77.82% and 14B-Instruct solving 86.38% of tasks, surpassing GPT-4o and advanced agent frameworks.", "conclusion": "The approach offers substantial advancements in multi-step reasoning and tool-use capabilities for LLMs, improving generalization and practical usability in data science tasks."}}
{"id": "2509.09534", "pdf": "https://arxiv.org/pdf/2509.09534", "abs": "https://arxiv.org/abs/2509.09534", "authors": ["Sena Ergisi", "Luis Ma\u00dfny", "Rawad Bitar"], "title": "ProDiGy: Proximity- and Dissimilarity-Based Byzantine-Robust Federated Learning", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Federated Learning (FL) emerged as a widely studied paradigm for distributed\nlearning. Despite its many advantages, FL remains vulnerable to adversarial\nattacks, especially under data heterogeneity. We propose a new Byzantine-robust\nFL algorithm called ProDiGy. The key novelty lies in evaluating the client\ngradients using a joint dual scoring system based on the gradients' proximity\nand dissimilarity. We demonstrate through extensive numerical experiments that\nProDiGy outperforms existing defenses in various scenarios. In particular, when\nthe clients' data do not follow an IID distribution, while other defense\nmechanisms fail, ProDiGy maintains strong defense capabilities and model\naccuracy. These findings highlight the effectiveness of a dual perspective\napproach that promotes natural similarity among honest clients while detecting\nsuspicious uniformity as a potential indicator of an attack.", "AI": {"tldr": "The paper introduces ProDiGy, a Byzantine-robust federated learning (FL) algorithm using a dual scoring system for client gradient evaluation.", "motivation": "To address the vulnerability of federated learning (FL) algorithms to adversarial attacks, especially under non-IID data heterogeneity.", "method": "ProDiGy evaluates client gradients using a joint dual scoring system based on proximity and dissimilarity to distinguish honest clients from attackers.", "result": "ProDiGy demonstrated superior performance and robustness against adversarial attacks, especially in non-IID data scenarios, outperforming existing defense mechanisms.", "conclusion": "The dual perspective approach enhances FL security by promoting natural similarity among honest clients and identifying abnormal uniformity as potential attack signals."}}
{"id": "2509.09101", "pdf": "https://arxiv.org/pdf/2509.09101", "abs": "https://arxiv.org/abs/2509.09101", "authors": ["Nishat Raihan", "Antonios Anastasopoulos", "Marcos Zampieri"], "title": "TigerCoder: A Novel Suite of LLMs for Code Generation in Bangla", "categories": ["cs.CL"], "comment": null, "summary": "Despite being the 5th most spoken language, Bangla remains underrepresented\nin Large Language Models (LLMs), particularly for code generation. This\nprimarily stems from the scarcity of high-quality data to pre-train and/or\nfinetune such models. Hence, we introduce the first dedicated family of Code\nLLMs for Bangla (1B & 9B). We offer three major contributions: (1) a\ncomprehensive Bangla code instruction datasets for programming domain\nadaptation; (2) MBPP-Bangla, an evaluation benchmark for Bangla code\ngeneration; and (3) the TigerCoder-family of Code LLMs, achieving significant\n~11-18% performance gains at Pass@1 over existing multilingual and\ngeneral-purpose Bangla LLMs. Our findings show that curated, high-quality\ndatasets can overcome limitations of smaller models for low-resource languages.\nWe open-source all resources to advance further Bangla LLM research.", "AI": {"tldr": "This paper introduces TigerCoder, the first specialized Code LLMs (1B & 9B) for Bangla code generation, overcoming data limitations and achieving significant performance improvements.", "motivation": "Bangla, despite being the 5th most spoken language, lacks representation in LLMs for code generation due to the scarcity of high-quality datasets.", "method": "The authors developed dedicated LLMs by (1) creating Bangla code instruction datasets for programming adaptation, (2) building an evaluation benchmark (MBPP-Bangla), and (3) training TigerCoder models.", "result": "TigerCoder models achieved substantial performance gains of ~11\u201318% Pass@1 over existing multilingual Bangla LLMs, demonstrating that high-quality datasets can mitigate limitations of smaller models for low-resource languages.", "conclusion": "The study highlights that creating curated datasets effectively improves code generation in low-resource languages like Bangla, and open-sourcing resources promotes further research."}}
{"id": "2509.08959", "pdf": "https://arxiv.org/pdf/2509.08959", "abs": "https://arxiv.org/abs/2509.08959", "authors": ["Puskal Khadka", "Rodrigue Rizk", "Longwei Wang", "KC Santosh"], "title": "CoSwin: Convolution Enhanced Hierarchical Shifted Window Attention For Small-Scale Vision", "categories": ["cs.CV"], "comment": null, "summary": "Vision Transformers (ViTs) have achieved impressive results in computer\nvision by leveraging self-attention to model long-range dependencies. However,\ntheir emphasis on global context often comes at the expense of local feature\nextraction in small datasets, particularly due to the lack of key inductive\nbiases such as locality and translation equivariance. To mitigate this, we\npropose CoSwin, a novel feature-fusion architecture that augments the\nhierarchical shifted window attention with localized convolutional feature\nlearning. Specifically, CoSwin integrates a learnable local feature enhancement\nmodule into each attention block, enabling the model to simultaneously capture\nfine-grained spatial details and global semantic structure. We evaluate CoSwin\non multiple image classification benchmarks including CIFAR-10, CIFAR-100,\nMNIST, SVHN, and Tiny ImageNet. Our experimental results show consistent\nperformance gains over state-of-the-art convolutional and transformer-based\nmodels. Notably, CoSwin achieves improvements of 2.17% on CIFAR-10, 4.92% on\nCIFAR-100, 0.10% on MNIST, 0.26% on SVHN, and 4.47% on Tiny ImageNet over the\nbaseline Swin Transformer. These improvements underscore the effectiveness of\nlocal-global feature fusion in enhancing the generalization and robustness of\ntransformers for small-scale vision. Code and pretrained weights available at\nhttps://github.com/puskal-khadka/coswin", "AI": {"tldr": "The paper introduces CoSwin, an architecture combining local convolutional features with hierarchical shifted window attention in Vision Transformers (ViTs), achieving significant performance gains on multiple small-scale image classification benchmarks.", "motivation": "While Vision Transformers excel at global feature extraction, they struggle with local feature learning due to the absence of inductive biases like locality and translation equivariance, especially in small datasets.", "method": "The authors propose CoSwin, a feature-fusion architecture that integrates a learnable local feature enhancement module into each attention block, combining fine-grained spatial information with global semantic structure.", "result": "Experimental results show CoSwin consistently outperforms state-of-the-art vision models with improvements of up to 4.92% on CIFAR-100 and 4.47% on Tiny ImageNet compared to the baseline Swin Transformer.", "conclusion": "CoSwin demonstrates that integrating local-global feature fusion significantly enhances the generalization and robustness of Vision Transformers in small-scale vision tasks."}}
{"id": "2509.09332", "pdf": "https://arxiv.org/pdf/2509.09332", "abs": "https://arxiv.org/abs/2509.09332", "authors": ["Yuecheng Liu", "Dafeng Chi", "Shiguang Wu", "Zhanguang Zhang", "Yuzheng Zhuang", "Bowen Yang", "He Zhu", "Lingfeng Zhang", "Pengwei Xie", "David Gamaliel Arcos Bravo", "Yingxue Zhang", "Jianye Hao", "Xingyue Quan"], "title": "OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Recent advances in multimodal large language models (MLLMs) have opened new\nopportunities for embodied intelligence, enabling multimodal understanding,\nreasoning, and interaction, as well as continuous spatial decision-making.\nNevertheless, current MLLM-based embodied systems face two critical\nlimitations. First, Geometric Adaptability Gap: models trained solely on 2D\ninputs or with hard-coded 3D geometry injection suffer from either insufficient\nspatial information or restricted 2D generalization, leading to poor\nadaptability across tasks with diverse spatial demands. Second, Embodiment\nConstraint Gap: prior work often neglects the physical constraints and\ncapacities of real robots, resulting in task plans that are theoretically valid\nbut practically infeasible.To address these gaps, we introduce OmniEVA -- an\nembodied versatile planner that enables advanced embodied reasoning and task\nplanning through two pivotal innovations: (1) a Task-Adaptive 3D Grounding\nmechanism, which introduces a gated router to perform explicit selective\nregulation of 3D fusion based on contextual requirements, enabling\ncontext-aware 3D grounding for diverse embodied tasks. (2) an Embodiment-Aware\nReasoning framework that jointly incorporates task goals and embodiment\nconstraints into the reasoning loop, resulting in planning decisions that are\nboth goal-directed and executable. Extensive experimental results demonstrate\nthat OmniEVA not only achieves state-of-the-art general embodied reasoning\nperformance, but also exhibits a strong ability across a wide range of\ndownstream scenarios. Evaluations of a suite of proposed embodied benchmarks,\nincluding both primitive and composite tasks, confirm its robust and versatile\nplanning capabilities. Project page: https://omnieva.github.io", "AI": {"tldr": "OmniEVA addresses gaps in current embodied systems by introducing task-adaptive 3D grounding and embodiment-aware reasoning, significantly enhancing multimodal task planning and execution.", "motivation": "The paper aims to overcome deficits in multimodal large language models (MLLMs), specifically their lack of adaptability to tasks requiring diverse spatial processing and neglect of real-world robotic constraints.", "method": "OmniEVA introduces a Task-Adaptive 3D Grounding mechanism for selective 3D fusion based on context and an Embodiment-Aware Reasoning framework that integrates task goals with embodiment constraints.", "result": "Experimental results show state-of-the-art performance in general embodied reasoning and robust planning across diverse tasks and scenarios.", "conclusion": "OmniEVA advances embodied reasoning and planning by addressing geometric adaptability and embodiment constraints, proving its capability through comprehensive benchmarking."}}
{"id": "2509.09001", "pdf": "https://arxiv.org/pdf/2509.09001", "abs": "https://arxiv.org/abs/2509.09001", "authors": ["Jingwen Liu", "Hantao Yu", "Clayton Sanford", "Alexandr Andoni", "Daniel Hsu"], "title": "Fast attention mechanisms: a tale of parallelism", "categories": ["cs.LG"], "comment": null, "summary": "Transformers have the representational capacity to simulate Massively\nParallel Computation (MPC) algorithms, but they suffer from quadratic time\ncomplexity, which severely limits their scalability. We introduce an efficient\nattention mechanism called Approximate Nearest Neighbor Attention (ANNA) with\nsub-quadratic time complexity. We prove that ANNA-transformers (1) retain the\nexpressive power previously established for standard attention in terms of\nmatching the capabilities of MPC algorithms, and (2) can solve key reasoning\ntasks such as Match2 and $k$-hop with near-optimal depth. Using the MPC\nframework, we further prove that constant-depth ANNA-transformers can simulate\nconstant-depth low-rank transformers, thereby providing a unified way to reason\nabout a broad class of efficient attention approximations.", "AI": {"tldr": "The paper introduces Approximate Nearest Neighbor Attention (ANNA), an efficient attention mechanism for transformers, achieving sub-quadratic complexity without losing representational power.", "motivation": "Transformers struggle with quadratic time complexity, limiting their scalability for tasks requiring massive parallel computation.", "method": "The paper designs ANNA, leveraging Approximate Nearest Neighbor techniques to reduce complexity, while retaining the capacity to perform reasoning tasks and simulate low-rank transformers.", "result": "ANNA-transformers are demonstrated to match the capabilities of standard attention models in solving reasoning tasks like Match2 and k-hop with near-optimal depth.", "conclusion": "The method unifies and extends reasoning approaches for efficient transformer approximations, offering scalable and powerful solutions for computational tasks."}}
{"id": "2509.09294", "pdf": "https://arxiv.org/pdf/2509.09294", "abs": "https://arxiv.org/abs/2509.09294", "authors": ["Solal Rapaport", "Laurent Pautet", "Samuel Tardieu", "Stefano Zacchiroli"], "title": "Altered Histories in Version Control System Repositories: Evidence from the Trenches", "categories": ["cs.SE"], "comment": null, "summary": "Version Control Systems (VCS) like Git allow developers to locally rewrite\nrecorded history, e.g., to reorder and suppress commits or specific data in\nthem. These alterations have legitimate use cases, but become problematic when\nperformed on public branches that have downstream users: they break push/pull\nworkflows, challenge the integrity and reproducibility of repositories, and\ncreate opportunities for supply chain attackers to sneak into them nefarious\nchanges. We conduct the first large-scale investigation of Git history\nalterations in public code repositories. We analyze 111 M (millions)\nrepositories archived by Software Heritage, which preserves VCS histories even\nacross alterations. We find history alterations in 1.22 M repositories, for a\ntotal of 8.7 M rewritten histories. We categorize changes by where they happen\n(which repositories, which branches) and what is changed in them (files or\ncommit metadata). Conducting two targeted case studies we show that altered\nhistories recurrently change licenses retroactively, or are used to remove\n''secrets'' (e.g., private keys) committed by mistake. As these behaviors\ncorrespond to bad practices-in terms of project governance or security\nmanagement, respectively-that software recipients might want to avoid, we\nintroduce GitHistorian, an automated tool, that developers can use to spot and\ndescribe history alterations in public Git repositories.", "AI": {"tldr": "The paper investigates history alterations in Git repositories, identifying potential security and governance concerns, and introduces the GitHistorian tool for detecting such modifications.", "motivation": "To evaluate the impact of Git history alterations on project integrity, reproducibility, and security, particularly when affecting public branches.", "method": "Analyzed 111 million Git repositories archived by Software Heritage to identify and categorize history alterations. Conducted case studies on license changes and secret removal.", "result": "Found 1.22 million repositories containing history alterations, with 8.7 million rewritten histories. Revealed recurrent issues like license retroactive modifications and secret removal practices.", "conclusion": "History alterations pose governance and security risks. The GitHistorian tool helps developers identify such changes to ensure better project management and security practices."}}
{"id": "2509.09272", "pdf": "https://arxiv.org/pdf/2509.09272", "abs": "https://arxiv.org/abs/2509.09272", "authors": ["Vaibhav Chaudhary", "Neha Soni", "Narotam Singh", "Amita Kapoor"], "title": "Fusing Knowledge and Language: A Comparative Study of Knowledge Graph-Based Question Answering with LLMs", "categories": ["cs.AI"], "comment": "46 pages, 4 figures, 17 tables", "summary": "Knowledge graphs, a powerful tool for structuring information through\nrelational triplets, have recently become the new front-runner in enhancing\nquestion-answering systems. While traditional Retrieval Augmented Generation\n(RAG) approaches are proficient in fact-based and local context-based\nextraction from concise texts, they encounter limitations when addressing the\nthematic and holistic understanding of complex, extensive texts, requiring a\ndeeper analysis of both text and context. This paper presents a comprehensive\ntechnical comparative study of three different methodologies for constructing\nknowledge graph triplets and integrating them with Large Language Models (LLMs)\nfor question answering: spaCy, Stanford CoreNLP-OpenIE, and GraphRAG, all\nleveraging open source technologies. We evaluate the effectiveness,\nfeasibility, and adaptability of these methods by analyzing their capabilities,\nstate of development, and their impact on the performance of LLM-based question\nanswering. Experimental results indicate that while OpenIE provides the most\ncomprehensive coverage of triplets, GraphRAG demonstrates superior reasoning\nabilities among the three. We conclude with a discussion on the strengths and\nlimitations of each method and provide insights into future directions for\nimproving knowledge graph-based question answering.", "AI": {"tldr": "The paper compares three methods for integrating knowledge graphs with LLMs for question answering (spaCy, CoreNLP-OpenIE, and GraphRAG), finding OpenIE excels in triplet coverage while GraphRAG performs better in reasoning.", "motivation": "Current retrieval-based systems struggle with answering complex, thematic questions from extensive texts. Using knowledge graphs can potentially enhance question answering capabilities.", "method": "The authors conducted a comparative analysis of spaCy, CoreNLP-OpenIE, and GraphRAG in constructing knowledge graph triplets and using them with LLMs for question answering. Evaluation included effectiveness, feasibility, and adaptability in question answering tasks.", "result": "OpenIE provided the best triplet coverage, whereas GraphRAG exhibited superior reasoning capabilities among the three methods evaluated.", "conclusion": "While OpenIE excels in coverage and GraphRAG in reasoning, the paper discusses the strengths and weaknesses of each, offering insights into future improvements for knowledge graph integration in question answering."}}
{"id": "2509.09653", "pdf": "https://arxiv.org/pdf/2509.09653", "abs": "https://arxiv.org/abs/2509.09653", "authors": ["Yufeng Xin", "Liang Zhang"], "title": "Towards A High-Performance Quantum Data Center Network Architecture", "categories": ["quant-ph", "cs.DC", "cs.NI"], "comment": "IEEE International Conference on Communications 2025 (ICC 2025)", "summary": "Quantum Data Centers (QDCs) are needed to support large-scale quantum\nprocessing for both academic and commercial applications. While large-scale\nquantum computers are constrained by technological and financial barriers, a\nmodular approach that clusters small quantum computers offers an alternative.\nThis approach, however, introduces new challenges in network scalability,\nentanglement generation, and quantum memory management. In this paper, we\npropose a three-layer fat-tree network architecture for QDCs, designed to\naddress these challenges. Our architecture features a unique leaf switch and an\nadvanced swapping spine switch design, optimized to handle high volumes of\nentanglement requests as well as a queue scheduling mechanism that efficiently\nmanages quantum memory to prevent decoherence. Through queuing-theoretical\nmodels and simulations in NetSquid, we demonstrate the proposed architecture's\nscalability and effectiveness in maintaining high entanglement fidelity,\noffering a practical path forward for modular QDC networks.", "AI": {"tldr": "The paper proposes a novel three-layer fat-tree network architecture for quantum data centers (QDCs) to address challenges in scalability, entanglement, and memory management.", "motivation": "Large-scale quantum computers are limited by technology and cost, necessitating modular quantum computer clusters for scalable quantum processing.", "method": "The authors designed a three-layer fat-tree network leveraging a specialized leaf switch, an advanced spine switch, and a queue scheduling mechanism. Performance was validated through queuing-theoretical models and NetSquid-based simulations.", "result": "The new architecture demonstrated both scalability and success in maintaining high entanglement fidelity, ensuring efficient handling of quantum tasks.", "conclusion": "The proposed design offers a practical and scalable solution for implementing modular quantum data center networks while addressing critical operational challenges."}}
{"id": "2509.09121", "pdf": "https://arxiv.org/pdf/2509.09121", "abs": "https://arxiv.org/abs/2509.09121", "authors": ["Sophia Maria"], "title": "Compass-v3: Scaling Domain-Specific LLMs for Multilingual E-Commerce in Southeast Asia", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) excel in general-domain applications, yet their\nperformance often degrades in specialized tasks requiring domain-specific\nknowledge. E-commerce is particularly challenging, as its data are noisy,\nheterogeneous, multilingual, and highly dynamic. We present Compass-v3, a\nvertical-domain Mixture-of-Experts (MoE) model with 245B total parameters and\n71B active per token, designed for Southeast Asian e-commerce. Compass-v3\nadopts fewer but larger experts, combined with hardware-efficient\noptimizations-such as intra-node expert parallelism and a customized memcpy\noperator-to maximize GPU utilization. The model is trained on 12T tokens of\ncurated multilingual corpora and large-scale synthetic e-commerce instructions\nusing a mixed-training strategy. To enhance alignment, we propose\nOptimal-Transport Direct Preference Optimization (OTPO), which captures\ntoken-level distinctions and improves instruction adherence in\ncommerce-specific scenarios. Extensive evaluations demonstrate that Compass-v3\ndelivers state-of-the-art e-commerce performance, surpassing DeepSeek-V3.1,\nGPT-4 series, and Qwen3-235B. Moreover, Compass-v3 demonstrates strong\nmultilingual capability across low-resource Southeast Asian languages\n(Indonesian, Thai, Filipino, Vietnamese, Malay, Taglog) and Portuguese while\nsustaining competitive performance on general benchmarks. It has already been\nwidely applied in Shopee's industrial-scale e-commerce platform and is\ngradually replacing OpenAI's traffic, now accounting for over 70\\% of total LLM\nusage, highlighting its dual strengths in specialized commerce expertise and\nbroad linguistic competence.", "AI": {"tldr": "Compass-v3 is a domain-specific Mixture-of-Experts model designed for Southeast Asian e-commerce, featuring 245B parameters and advanced hardware optimizations to handle noisy, multilingual, and dynamic data effectively.", "motivation": "Large language models struggle in specialized domains, requiring domain-specific enhancements for impactful applications. E-commerce, especially in Southeast Asia, presents challenges due to its noisy, multilingual, and rapidly changing nature.", "method": "Compass-v3 combines fewer but larger experts utilizing hardware-efficient techniques like intra-node expert parallelism for GPU usage. Trained on curated multilingual corpora and synthetic e-commerce instructions, it employs Optimal-Transport Direct Preference Optimization (OTPO) for improved alignment and instruction adherence.", "result": "The model achieves state-of-the-art performance in e-commerce by surpassing other models such as GPT-4 and DeepSeek-V3.1. It demonstrates strong multilingual competency in Southeast Asian languages and Portuguese alongside solid performance in general benchmarks.", "conclusion": "Compass-v3 is a successful application in industrial-scale platforms like Shopee, replacing OpenAI's model usage for over 70% of LLM tasks, showcasing its dual proficiency in domain-specific expertise and broad language capabilities."}}
{"id": "2509.08982", "pdf": "https://arxiv.org/pdf/2509.08982", "abs": "https://arxiv.org/abs/2509.08982", "authors": ["Karim Slimani", "Catherine Achard", "Brahim Tamadazte"], "title": "iMatcher: Improve matching in point cloud registration via local-to-global geometric consistency learning", "categories": ["cs.CV"], "comment": null, "summary": "This paper presents iMatcher, a fully differentiable framework for feature\nmatching in point cloud registration. The proposed method leverages learned\nfeatures to predict a geometrically consistent confidence matrix, incorporating\nboth local and global consistency. First, a local graph embedding module leads\nto an initialization of the score matrix. A subsequent repositioning step\nrefines this matrix by considering bilateral source-to-target and\ntarget-to-source matching via nearest neighbor search in 3D space. The paired\npoint features are then stacked together to be refined through global geometric\nconsistency learning to predict a point-wise matching probability. Extensive\nexperiments on real-world outdoor (KITTI, KITTI-360) and indoor (3DMatch)\ndatasets, as well as on 6-DoF pose estimation (TUD-L) and partial-to-partial\nmatching (MVP-RG), demonstrate that iMatcher significantly improves rigid\nregistration performance. The method achieves state-of-the-art inlier ratios,\nscoring 95% - 97% on KITTI, 94% - 97% on KITTI-360, and up to 81.1% on 3DMatch,\nhighlighting its robustness across diverse settings.", "AI": {"tldr": "The paper introduces iMatcher, a novel framework for improving point cloud registration using learned features and geometric consistency.", "motivation": "To enhance feature matching in point cloud registration by improving the geometric consistency and robustness across diverse settings.", "method": "iMatcher employs a local graph embedding module for initialization, refines matching with nearest-neighbor-based repositioning steps, and uses global geometric consistency learning for final probability prediction.", "result": "The experiments show significant performance improvements on datasets like KITTI (95%-97%), KITTI-360 (94%-97%), and 3DMatch (81.1%), demonstrating state-of-the-art inlier ratios.", "conclusion": "iMatcher proves to be a robust and effective framework, achieving excellent results in rigid registration tasks for diverse datasets."}}
{"id": "2509.09364", "pdf": "https://arxiv.org/pdf/2509.09364", "abs": "https://arxiv.org/abs/2509.09364", "authors": ["Grzegorz Ficht", "Luis Denninger", "Sven Behnke"], "title": "AGILOped: Agile Open-Source Humanoid Robot for Research", "categories": ["cs.RO"], "comment": "10th IEEE International Conference on Advanced Robotics and\n  Mechatronics (ARM), Portsmouth, UK, August 2025", "summary": "With academic and commercial interest for humanoid robots peaking, multiple\nplatforms are being developed. Through a high level of customization, they\nshowcase impressive performance. Most of these systems remain closed-source or\nhave high acquisition and maintenance costs, however. In this work, we present\nAGILOped - an open-source humanoid robot that closes the gap between high\nperformance and accessibility. Our robot is driven by off-the-shelf\nbackdrivable actuators with high power density and uses standard electronic\ncomponents. With a height of 110 cm and weighing only 14.5 kg, AGILOped can be\noperated without a gantry by a single person. Experiments in walking, jumping,\nimpact mitigation and getting-up demonstrate its viability for use in research.", "AI": {"tldr": "AGILOped is an open-source humanoid robot combining accessibility with high performance, demonstrated through various physical experiments.", "motivation": "Fill the gap between high-performance humanoid robots and accessibility by offering an open-source platform.", "method": "Develop AGILOped using standard components and lightweight design, enabling single-person operation and versatile capabilities.", "result": "AGILOped shows successful performance in walking, jumping, impact mitigation, and getting-up experiments.", "conclusion": "AGILOped offers researchers an accessible and high-performing humanoid robot platform for various applications."}}
{"id": "2509.09009", "pdf": "https://arxiv.org/pdf/2509.09009", "abs": "https://arxiv.org/abs/2509.09009", "authors": ["Marianna Nezhurina", "Taishi Nakamura", "Timur Carstensen", "Niccol\u00f2 Ajroldi", "Ville Komulainen", "David Salinas", "Jenia Jitsev"], "title": "Open-sci-ref-0.01: open and reproducible reference baselines for language model and dataset comparison", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Model weights and intermediate checkpoints are available at\n  \\url{https://huggingface.co/collections/open-sci/open-sci-ref-001-685905e598be658fbcebff4f};\n  code for reproducing training, evaluation and raw experiments data at\n  \\url{https://github.com/LAION-AI/open-sci-ref-0.01}", "summary": "We introduce open-sci-ref, a family of dense transformer models trained as\nresearch baselines across multiple model (0.13B to 1.7B parameters) and token\nscales (up to 1T) on 8 recent open reference datasets. Evaluating the models on\nvarious standardized benchmarks, our training runs set establishes reference\npoints that enable researchers to assess the sanity and quality of alternative\ntraining approaches across scales and datasets. Intermediate checkpoints allow\ncomparison and studying of the training dynamics. The established reference\nbaselines allow training procedures to be compared through their scaling\ntrends, aligning them on a common compute axis. Comparison of open reference\ndatasets reveals that training on NemoTron-CC HQ consistently outperforms other\nreference datasets, followed by DCLM-baseline and FineWeb-Edu. In addition to\nintermediate training checkpoints, the release includes logs, code, and\ndownstream evaluations to simplify reproduction, standardize comparison, and\nfacilitate future research.", "AI": {"tldr": "The paper introduces a family of dense transformer models, open-sci-ref, designed as research baselines across various scales and datasets and provides tools for standardized comparison.", "motivation": "To provide standardized baselines and tools for researchers to evaluate and compare training approaches and datasets across compute, scale, and performance.", "method": "Developed transformer models with 0.13B to 1.7B parameters, trained on 8 open reference datasets, and evaluated on standardized benchmarks with intermediate checkpoints and scaling trend analysis.", "result": "Training on NemoTron-CC HQ dataset performs best, beating other datasets like DCLM-baseline and FineWeb-Edu, with results supporting reproducibility and standardization of comparisons.", "conclusion": "The work sets crucial baselines, introduces reliable datasets and evaluation protocols, and provides resources for advancing transformer training and scaling studies."}}
{"id": "2509.09313", "pdf": "https://arxiv.org/pdf/2509.09313", "abs": "https://arxiv.org/abs/2509.09313", "authors": ["Moritz Mock", "Thomas Forrer", "Barbara Russo"], "title": "Cross-Domain Evaluation of Transformer-Based Vulnerability Detection on Open & Industry Data", "categories": ["cs.SE"], "comment": "Accepted to the 26th International Conference on Product-Focused\n  Software Process Improvement (PROFES 2025)", "summary": "Deep learning solutions for vulnerability detection proposed in academic\nresearch are not always accessible to developers, and their applicability in\nindustrial settings is rarely addressed. Transferring such technologies from\nacademia to industry presents challenges related to trustworthiness, legacy\nsystems, limited digital literacy, and the gap between academic and industrial\nexpertise. For deep learning in particular, performance and integration into\nexisting workflows are additional concerns. In this work, we first evaluate the\nperformance of CodeBERT for detecting vulnerable functions in industrial and\nopen-source software. We analyse its cross-domain generalisation when\nfine-tuned on open-source data and tested on industrial data, and vice versa,\nalso exploring strategies for handling class imbalance. Based on these results,\nwe develop AI-DO(Automating vulnerability detection Integration for Developers'\nOperations), a Continuous Integration-Continuous Deployment (CI/CD)-integrated\nrecommender system that uses fine-tuned CodeBERT to detect and localise\nvulnerabilities during code review without disrupting workflows. Finally, we\nassess the tool's perceived usefulness through a survey with the company's IT\nprofessionals. Our results show that models trained on industrial data detect\nvulnerabilities accurately within the same domain but lose performance on\nopen-source code, while a deep learner fine-tuned on open data, with\nappropriate undersampling techniques, improves the detection of\nvulnerabilities.", "AI": {"tldr": "CodeBERT-based deep learning models were evaluated for vulnerability detection across industrial and open-source software. Results indicate domain-specific limitations and class imbalance strategies proved beneficial. A CI/CD-integrated tool called AI-DO was developed for real-world use and assessed positively through surveys.", "motivation": "The paper aims to address gaps in transitioning deep learning vulnerability detection models from academia to industry, focusing on trustworthiness, performance, integration challenges, and applicability to real-world workflows.", "method": "Performance of CodeBERT was evaluated for vulnerability detection in cross-domain settings (industrial versus open-source). Additionally, a CI/CD-integrated recommender system called AI-DO was developed using fine-tuned CodeBERT. A survey with IT professionals was conducted to assess usability.", "result": "CodeBERT models yielded strong performance in detecting vulnerabilities within their trained domain. Models trained on open-source data performed better on industrial data under certain strategies like undersampling to handle class imbalance.", "conclusion": "Deep learning models such as fine-tuned CodeBERT can be adapted effectively for industrial vulnerability detection, especially when integrated into existing workflows like CI/CD pipelines. However, domain-specific training data plays a crucial role in model performance."}}
{"id": "2509.09284", "pdf": "https://arxiv.org/pdf/2509.09284", "abs": "https://arxiv.org/abs/2509.09284", "authors": ["Bingning Huang", "Tu Nguyen", "Matthieu Zimmer"], "title": "Tree-OPO: Off-policy Monte Carlo Tree-Guided Advantage Optimization for Multistep Reasoning", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Recent advances in reasoning with large language models (LLMs) have shown the\neffectiveness of Monte Carlo Tree Search (MCTS) for generating high-quality\nintermediate trajectories, particularly in math and symbolic domains. Inspired\nby this, we explore how MCTS-derived trajectories, traditionally used for\ntraining value or reward models, can be repurposed to improve policy\noptimization in preference-based reinforcement learning (RL). Specifically, we\nfocus on Group Relative Policy Optimization (GRPO), a recent algorithm that\nenables preference-consistent policy learning without value networks. We\npropose a staged GRPO training paradigm where completions are derived from\npartially revealed MCTS rollouts, introducing a novel tree-structured setting\nfor advantage estimation. This leads to a rich class of prefix-conditioned\nreward signals, which we analyze theoretically and empirically. Our initial\nresults indicate that while structured advantage estimation can stabilize\nupdates and better reflect compositional reasoning quality, challenges such as\nadvantage saturation and reward signal collapse remain. We propose heuristic\nand statistical solutions to mitigate these issues and discuss open challenges\nfor learning under staged or tree-like reward structures.", "AI": {"tldr": "This paper explores using Monte Carlo Tree Search (MCTS)-derived intermediate trajectories to enhance policy optimization in preference-based reinforcement learning, proposing a novel tree-structured advantage estimation technique.", "motivation": "Building on the success of MCTS for generating high-quality trajectories, the study aims to utilize these trajectories to improve policy optimization, particularly in preference-based RL methods where value models or reward models may not be employed.", "method": "The researchers focus on the Group Relative Policy Optimization (GRPO) algorithm and introduce a staged training paradigm that uses partially revealed MCTS rollouts for tree-structured advantage estimation and a novel reward signal approach.", "result": "Initial findings show that their structured advantage estimation stabilizes updates and aids compositional reasoning quality, but they observed challenges like advantage saturation and reward signal collapse.", "conclusion": "The proposed method demonstrates promise in improving policy optimization, but practical challenges such as reward structure issues require further study, with potential solutions and open challenges identified."}}
{"id": "2509.09125", "pdf": "https://arxiv.org/pdf/2509.09125", "abs": "https://arxiv.org/abs/2509.09125", "authors": ["Liqun He", "Jiaqi Xu"], "title": "Automated Classification of Tutors' Dialogue Acts Using Generative AI: A Case Study Using the CIMA Corpus", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted for publication in the journal Reflecting Digital Learning.\n  First submitted: 30 Oct 2023. The final version will be available open access\n  via the journal", "summary": "This study explores the use of generative AI for automating the\nclassification of tutors' Dialogue Acts (DAs), aiming to reduce the time and\neffort required by traditional manual coding. This case study uses the\nopen-source CIMA corpus, in which tutors' responses are pre-annotated into four\nDA categories. Both GPT-3.5-turbo and GPT-4 models were tested using tailored\nprompts. Results show that GPT-4 achieved 80% accuracy, a weighted F1-score of\n0.81, and a Cohen's Kappa of 0.74, surpassing baseline performance and\nindicating substantial agreement with human annotations. These findings suggest\nthat generative AI has strong potential to provide an efficient and accessible\napproach to DA classification, with meaningful implications for educational\ndialogue analysis. The study also highlights the importance of task-specific\nlabel definitions and contextual information in enhancing the quality of\nautomated annotation. Finally, it underscores the ethical considerations\nassociated with the use of generative AI and the need for responsible and\ntransparent research practices. The script of this research is publicly\navailable at\nhttps://github.com/liqunhe27/Generative-AI-for-educational-dialogue-act-tagging.", "AI": {"tldr": "This study evaluated GPT-4 for automating educational dialogue act classification, achieving substantial accuracy and agreement with human annotations.", "motivation": "Traditional manual coding of tutors' Dialogue Acts is time-consuming and labor-intensive, prompting exploration of generative AI as an efficient alternative.", "method": "GPT-3.5-turbo and GPT-4 were tested using tailored prompts against the CIMA corpus, pre-annotated into four categories of Dialogue Acts.", "result": "GPT-4 achieved 80% accuracy, a weighted F1-score of 0.81, and a Cohen's Kappa of 0.74, surpassing baseline manual annotation performance.", "conclusion": "Generative AI shows strong potential to automate Dialogue Act classification efficiently, while emphasizing the importance of task-specific definitions and ethical considerations."}}
{"id": "2509.08991", "pdf": "https://arxiv.org/pdf/2509.08991", "abs": "https://arxiv.org/abs/2509.08991", "authors": ["Magdalena Wysocki", "Felix Duelmer", "Ananya Bal", "Nassir Navab", "Mohammad Farid Azampour"], "title": "UltrON: Ultrasound Occupancy Networks", "categories": ["cs.CV"], "comment": "MICCAI 2025", "summary": "In free-hand ultrasound imaging, sonographers rely on expertise to mentally\nintegrate partial 2D views into 3D anatomical shapes. Shape reconstruction can\nassist clinicians in this process. Central to this task is the choice of shape\nrepresentation, as it determines how accurately and efficiently the structure\ncan be visualized, analyzed, and interpreted. Implicit representations, such as\nSDF and occupancy function, offer a powerful alternative to traditional voxel-\nor mesh-based methods by modeling continuous, smooth surfaces with compact\nstorage, avoiding explicit discretization. Recent studies demonstrate that SDF\ncan be effectively optimized using annotations derived from segmented B-mode\nultrasound images. Yet, these approaches hinge on precise annotations,\noverlooking the rich acoustic information embedded in B-mode intensity.\nMoreover, implicit representation approaches struggle with the ultrasound's\nview-dependent nature and acoustic shadowing artifacts, which impair\nreconstruction. To address the problems resulting from occlusions and\nannotation dependency, we propose an occupancy-based representation and\nintroduce \\gls{UltrON} that leverages acoustic features to improve geometric\nconsistency in weakly-supervised optimization regime. We show that these\nfeatures can be obtained from B-mode images without additional annotation cost.\nMoreover, we propose a novel loss function that compensates for view-dependency\nin the B-mode images and facilitates occupancy optimization from multiview\nultrasound. By incorporating acoustic properties, \\gls{UltrON} generalizes to\nshapes of the same anatomy. We show that \\gls{UltrON} mitigates the limitations\nof occlusions and sparse labeling and paves the way for more accurate 3D\nreconstruction. Code and dataset will be available at\nhttps://github.com/magdalena-wysocki/ultron.", "AI": {"tldr": "The paper introduces UltrON, an advanced method for geometrically consistent 3D ultrasound reconstruction utilizing acoustic features and occupancy-based representation, overcoming limitations of occlusions and sparse annotations.", "motivation": "Sonographers face challenges in mentally reconstructing 3D anatomical shapes from partial 2D ultrasound views, and existing methods struggle with precision due to artifacts and dependencies on extensive annotations.", "method": "The study proposes an occupancy-based representation and UltrON framework, leveraging acoustic features embedded in B-mode ultrasound images for a weakly-supervised optimization regime, along with a novel loss function addressing view dependency.", "result": "UltrON successfully integrates acoustic features to enhance geometric consistency and enables reconstruction of anatomical shapes from multiview ultrasound despite occlusions and sparse labeling.", "conclusion": "By incorporating acoustic properties, UltrON generalizes to improve 3D anatomical reconstructions, mitigating challenges of occlusions and annotation dependency, with code and dataset shared for future research."}}
{"id": "2509.09372", "pdf": "https://arxiv.org/pdf/2509.09372", "abs": "https://arxiv.org/abs/2509.09372", "authors": ["Yihao Wang", "Pengxiang Ding", "Lingxiao Li", "Can Cui", "Zirui Ge", "Xinyang Tong", "Wenxuan Song", "Han Zhao", "Wei Zhao", "Pengxu Hou", "Siteng Huang", "Yifan Tang", "Wenhui Wang", "Ru Zhang", "Jianyi Liu", "Donglin Wang"], "title": "VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model", "categories": ["cs.RO"], "comment": null, "summary": "Vision-Language-Action (VLA) models typically bridge the gap between\nperceptual and action spaces by pre-training a large-scale Vision-Language\nModel (VLM) on robotic data. While this approach greatly enhances performance,\nit also incurs significant training costs. In this paper, we investigate how to\neffectively bridge vision-language (VL) representations to action (A). We\nintroduce VLA-Adapter, a novel paradigm designed to reduce the reliance of VLA\nmodels on large-scale VLMs and extensive pre-training. To this end, we first\nsystematically analyze the effectiveness of various VL conditions and present\nkey findings on which conditions are essential for bridging perception and\naction spaces. Based on these insights, we propose a lightweight Policy module\nwith Bridge Attention, which autonomously injects the optimal condition into\nthe action space. In this way, our method achieves high performance using only\na 0.5B-parameter backbone, without any robotic data pre-training. Extensive\nexperiments on both simulated and real-world robotic benchmarks demonstrate\nthat VLA-Adapter not only achieves state-of-the-art level performance, but also\noffers the fast inference speed reported to date. Furthermore, thanks to the\nproposed advanced bridging paradigm, VLA-Adapter enables the training of a\npowerful VLA model in just 8 hours on a single consumer-grade GPU, greatly\nlowering the barrier to deploying the VLA model. Project page:\nhttps://vla-adapter.github.io/.", "AI": {"tldr": "The paper introduces VLA-Adapter, a lightweight model reducing reliance on large Vision-Language Models (VLMs) for robotic tasks, achieving high performance without extensive pre-training.", "motivation": "Current Vision-Language-Action models require large-scale VLMs and significant training, which is costly and resource-intensive.", "method": "Proposes VLA-Adapter, a lightweight policy module with Bridge Attention, which integrates optimal vision-language conditions for action predictions, removing the need for large pre-trained VLMs or extensive robotic data.", "result": "VLA-Adapter achieves state-of-the-art performance on simulated and real-world robotic benchmarks, executes in fast inference speeds, and can be trained in 8 hours on a consumer GPU.", "conclusion": "The approach reduces the computational and resource burden for training VLA models while maintaining high performance, making them more accessible."}}
{"id": "2509.09030", "pdf": "https://arxiv.org/pdf/2509.09030", "abs": "https://arxiv.org/abs/2509.09030", "authors": ["Spencer King", "Zhilu Zhang", "Ruofan Yu", "Baris Coskun", "Wei Ding", "Qian Cui"], "title": "Deep Context-Conditioned Anomaly Detection for Tabular Data", "categories": ["cs.LG"], "comment": "Submitted to WSDM 2026. 11 pages, 4 figures, 5 tables, 1 algorithm, 8\n  datasets, contextual anomaly detection framework for tabular data", "summary": "Anomaly detection is critical in domains such as cybersecurity and finance,\nespecially when working with large-scale tabular data. Yet, unsupervised\nanomaly detection -- where no labeled anomalies are available -- remains a\nsignificant challenge. Although various deep learning methods have been\nproposed to model a dataset's joint distribution, real-world tabular data often\ncontain heterogeneous contexts (e.g., different users), making globally rare\nevents normal under certain contexts. Consequently, relying on a single global\ndistribution can overlook these contextual nuances, degrading detection\nperformance. In this paper, we present a context-conditional anomaly detection\nframework tailored for tabular datasets. Our approach automatically identifies\ncontext features and models the conditional data distribution using a simple\ndeep autoencoder. Extensive experiments on multiple tabular benchmark datasets\ndemonstrate that our method outperforms state-of-the-art approaches,\nunderscoring the importance of context in accurately distinguishing anomalous\nfrom normal instances.", "AI": {"tldr": "The paper proposes a context-conditional anomaly detection framework for tabular datasets using a deep autoencoder, achieving better performance than existing methods.", "motivation": "Existing methods for unsupervised anomaly detection often miss context-specific nuances in heterogeneous tabular data, leading to lower detection accuracy.", "method": "The framework uses context feature identification and conditional data distribution modeling with a deep autoencoder to account for contextual variations in tabular datasets.", "result": "Experimental results on multiple benchmark datasets show that this approach outperforms current state-of-the-art methods in anomaly detection.", "conclusion": "The study highlights the critical role of incorporating context for enhanced anomaly detection in heterogeneous tabular data."}}
{"id": "2509.09322", "pdf": "https://arxiv.org/pdf/2509.09322", "abs": "https://arxiv.org/abs/2509.09322", "authors": ["Jacopo Bufalino", "Agathe Blaise", "Stefano Secci"], "title": "ORCA: Unveiling Obscure Containers In The Wild", "categories": ["cs.SE", "cs.CR"], "comment": null, "summary": "Modern software development increasingly depends on open-source libraries and\nthird-party components, which are often encapsulated into containerized\nenvironments. While improving the development and deployment of applications,\nthis approach introduces security risks, particularly when outdated or\nvulnerable components are inadvertently included in production environments.\nSoftware Composition Analysis (SCA) is a critical process that helps identify\nand manage packages and dependencies inside a container. However, unintentional\nmodifications to the container filesystem can lead to incomplete container\nimages, which compromise the reliability of SCA tools. In this paper, we\nexamine the limitations of both cloud-based and open-source SCA tools when\nfaced with such obscure images. An analysis of 600 popular containers revealed\nthat obscure containers exist in well-known registries and trusted images and\nthat many tools fail to analyze such containers. To mitigate these issues, we\npropose an obscuration-resilient methodology for container analysis and\nintroduce ORCA (Obscuration-Resilient Container Analyzer), its open-source\nimplementation. We reported our findings to all vendors using their appropriate\nchannels. Our results demonstrate that ORCA effectively detects the content of\nobscure containers and achieves a median 40% improvement in file coverage\ncompared to Docker Scout and Syft.", "AI": {"tldr": "The paper identifies limitations in existing Software Composition Analysis (SCA) tools for analyzing obscure container images and proposes an improved solution, ORCA, which achieves superior results.", "motivation": "The growing reliance on open-source libraries and containerized environments in software development carries risks of security vulnerabilities due to outdated or modified components, highlighting the need for robust SCA tools.", "method": "The authors analyzed 600 popular containers to assess the limitations of cloud-based and open-source SCA tools with obscure images and designed ORCA, an obscuration-resilient container analysis methodology.", "result": "ORCA was found to improve file coverage by a median of 40% over existing tools like Docker Scout and Syft when analyzing obscure containers.", "conclusion": "ORCA effectively addresses the limitations of current SCA tools, providing a more reliable solution for analyzing containerized environments and improving security in production workflows."}}
{"id": "2509.09292", "pdf": "https://arxiv.org/pdf/2509.09292", "abs": "https://arxiv.org/abs/2509.09292", "authors": ["Weige Cai", "Tong Zhu", "Jinyi Niu", "Ruiqi Hu", "Lingyao Li", "Tenglong Wang", "Xiaowu Dai", "Weining Shen", "Liwen Zhang"], "title": "LightAgent: Production-level Open-source Agentic AI Framework", "categories": ["cs.AI"], "comment": null, "summary": "With the rapid advancement of large language models (LLMs), Multi-agent\nSystems (MAS) have achieved significant progress in various application\nscenarios. However, substantial challenges remain in designing versatile,\nrobust, and efficient platforms for agent deployment. To address these\nlimitations, we propose \\textbf{LightAgent}, a lightweight yet powerful agentic\nframework, effectively resolving the trade-off between flexibility and\nsimplicity found in existing frameworks. LightAgent integrates core\nfunctionalities such as Memory (mem0), Tools, and Tree of Thought (ToT), while\nmaintaining an extremely lightweight structure. As a fully open-source\nsolution, it seamlessly integrates with mainstream chat platforms, enabling\ndevelopers to easily build self-learning agents. We have released LightAgent at\n\\href{https://github.com/wxai-space/LightAgent}{https://github.com/wxai-space/LightAgent}", "AI": {"tldr": "The paper presents 'LightAgent,' a lightweight framework for multi-agent systems, which balances flexibility and simplicity while incorporating key functionalities like memory, tools, and Tree of Thought (ToT).", "motivation": "Existing multi-agent system (MAS) frameworks often struggle with balancing versatility, robustness, and simplicity, leaving developers with challenges in designing efficient agent deployment platforms.", "method": "LightAgent integrates core features such as memory (mem0), tools, and the Tree of Thought (ToT) while maintaining a lightweight structure. It is open-source and compatible with mainstream chat platforms for seamless development.", "result": "The proposed framework enables developers to create self-learning agents easily while resolving trade-offs between flexibility and simplicity.", "conclusion": "LightAgent offers a practical and accessible solution for MAS development, advancing the creation of efficient agent systems while remaining lightweight and developer-friendly."}}
{"id": "2509.09131", "pdf": "https://arxiv.org/pdf/2509.09131", "abs": "https://arxiv.org/abs/2509.09131", "authors": ["Phuong-Nam Dang", "Kieu-Linh Nguyen", "Thanh-Hieu Pham"], "title": "ViRanker: A BGE-M3 & Blockwise Parallel Transformer Cross-Encoder for Vietnamese Reranking", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages", "summary": "This paper presents ViRanker, a cross-encoder reranking model tailored to the\nVietnamese language. Built on the BGE-M3 encoder and enhanced with the\nBlockwise Parallel Transformer, ViRanker addresses the lack of competitive\nrerankers for Vietnamese, a low-resource language with complex syntax and\ndiacritics. The model was trained on an 8 GB curated corpus and fine-tuned with\nhybrid hard-negative sampling to strengthen robustness. Evaluated on the\nMMARCO-VI benchmark, ViRanker achieves strong early-rank accuracy, surpassing\nmultilingual baselines and competing closely with PhoRanker. By releasing the\nmodel openly on Hugging Face, we aim to support reproducibility and encourage\nwider adoption in real-world retrieval systems. Beyond Vietnamese, this study\nillustrates how careful architectural adaptation and data curation can advance\nreranking in other underrepresented languages.", "AI": {"tldr": "ViRanker, a reranking model for Vietnamese, outperforms multilingual baselines and competes with existing models, enhancing information retrieval for low-resource languages.", "motivation": "Address the lack of competitive rerankers for Vietnamese, a low-resource language with complex syntax and diacritics.", "method": "Developed based on BGE-M3 encoder with Blockwise Parallel Transformer, trained on an 8 GB curated corpus, and fine-tuned with hybrid hard-negative sampling.", "result": "ViRanker achieves strong performance on the MMARCO-VI benchmark, surpassing multilingual baselines and closely competing with PhoRanker.", "conclusion": "ViRanker enhances retrieval for Vietnamese and underrepresented languages through architectural adaptation, robust training, and open access for further improvement and adoption."}}
{"id": "2509.09004", "pdf": "https://arxiv.org/pdf/2509.09004", "abs": "https://arxiv.org/abs/2509.09004", "authors": ["Andrew Bell", "Yan Kit Choi", "Steffen Peterson", "Andrew King", "Muhummad Sohaib Nazir", "Alistair Young"], "title": "Implicit Neural Representations of Intramyocardial Motion and Strain", "categories": ["cs.CV", "cs.AI"], "comment": "STACOM 2025 @ MICCAI", "summary": "Automatic quantification of intramyocardial motion and strain from tagging\nMRI remains an important but challenging task. We propose a method using\nimplicit neural representations (INRs), conditioned on learned latent codes, to\npredict continuous left ventricular (LV) displacement -- without requiring\ninference-time optimisation. Evaluated on 452 UK Biobank test cases, our method\nachieved the best tracking accuracy (2.14 mm RMSE) and the lowest combined\nerror in global circumferential (2.86%) and radial (6.42%) strain compared to\nthree deep learning baselines. In addition, our method is $\\sim$380$\\times$\nfaster than the most accurate baseline. These results highlight the suitability\nof INR-based models for accurate and scalable analysis of myocardial strain in\nlarge CMR datasets.", "AI": {"tldr": "The study presents an efficient method using implicit neural representations (INRs) to analyze left ventricular motion from MRI data, outperforming existing methods in accuracy and speed.", "motivation": "Accurately quantifying intramyocardial motion and strain from tagging MRI remains crucial but is technically challenging.", "method": "The researchers utilized INR models conditioned on learned latent codes to predict continuous left ventricular displacement, bypassing inference-time optimization.", "result": "On a dataset of 452 UK Biobank cases, the method achieved the best tracking accuracy (2.14 mm RMSE), the lowest global strain errors, and was approximately 380 times faster than the most accurate baseline model.", "conclusion": "INR-based models are effective and scalable, making them well-suited for analyzing myocardial strain in large cardiac MRI datasets."}}
{"id": "2509.09404", "pdf": "https://arxiv.org/pdf/2509.09404", "abs": "https://arxiv.org/abs/2509.09404", "authors": ["Tongshun Chen", "Zezhou Sun", "Yanhan Sun", "Yuhao Wang", "Dezhen Song", "Ke Wu"], "title": "A Hybrid Hinge-Beam Continuum Robot with Passive Safety Capping for Real-Time Fatigue Awareness", "categories": ["cs.RO"], "comment": null, "summary": "Cable-driven continuum robots offer high flexibility and lightweight design,\nmaking them well-suited for tasks in constrained and unstructured environments.\nHowever, prolonged use can induce mechanical fatigue from plastic deformation\nand material degradation, compromising performance and risking structural\nfailure. In the state of the art, fatigue estimation of continuum robots\nremains underexplored, limiting long-term operation. To address this, we\npropose a fatigue-aware continuum robot with three key innovations: (1) a\nHybrid Hinge-Beam structure where TwistBeam and BendBeam decouple torsion and\nbending: passive revolute joints in the BendBeam mitigate stress concentration,\nwhile TwistBeam's limited torsional deformation reduces BendBeam stress\nmagnitude, enhancing durability; (2) a Passive Stopper that safely constrains\nmotion via mechanical constraints and employs motor torque sensing to detect\ncorresponding limit torque, ensuring safety and enabling data collection; and\n(3) a real-time fatigue-awareness method that estimates stiffness from motor\ntorque at the limit pose, enabling online fatigue estimation without additional\nsensors. Experiments show that the proposed design reduces fatigue accumulation\nby about 49% compared with a conventional design, while passive mechanical\nlimiting combined with motor-side sensing allows accurate estimation of\nstructural fatigue and damage. These results confirm the effectiveness of the\nproposed architecture for safe and reliable long-term operation.", "AI": {"tldr": "This paper proposes a fatigue-aware cable-driven continuum robot design and real-time fatigue-awareness method to improve durability and long-term reliability.", "motivation": "Current continuum robots suffer from performance degradation and structural failure due to mechanical fatigue, limiting their usability in prolonged operations.", "method": "The study introduces a Hybrid Hinge-Beam structure that decouples torsion and bending stresses, a Passive Stopper ensuring safety and enabling torque sensing, and a real-time stiffness estimation method for online fatigue assessment.", "result": "Experiments demonstrated a 49% reduction in fatigue accumulation compared to conventional designs while enabling accurate fatigue estimation using motor-side sensing.", "conclusion": "The proposed design shows significant potential for enhancing the durability and operational reliability of continuum robots in constrained environments."}}
{"id": "2509.09052", "pdf": "https://arxiv.org/pdf/2509.09052", "abs": "https://arxiv.org/abs/2509.09052", "authors": ["Dibyajyoti Chakraborty", "Romit Maulik", "Peter Harrington", "Dallas Foster", "Mohammad Amin Nabian", "Sanjay Choudhry"], "title": "MoWE : A Mixture of Weather Experts", "categories": ["cs.LG", "cs.AI", "physics.ao-ph", "physics.geo-ph"], "comment": null, "summary": "Data-driven weather models have recently achieved state-of-the-art\nperformance, yet progress has plateaued in recent years. This paper introduces\na Mixture of Experts (MoWE) approach as a novel paradigm to overcome these\nlimitations, not by creating a new forecaster, but by optimally combining the\noutputs of existing models. The MoWE model is trained with significantly lower\ncomputational resources than the individual experts. Our model employs a Vision\nTransformer-based gating network that dynamically learns to weight the\ncontributions of multiple \"expert\" models at each grid point, conditioned on\nforecast lead time. This approach creates a synthesized deterministic forecast\nthat is more accurate than any individual component in terms of Root Mean\nSquared Error (RMSE). Our results demonstrate the effectiveness of this method,\nachieving up to a 10% lower RMSE than the best-performing AI weather model on a\n2-day forecast horizon, significantly outperforming individual experts as well\nas a simple average across experts. This work presents a computationally\nefficient and scalable strategy to push the state of the art in data-driven\nweather prediction by making the most out of leading high-quality forecast\nmodels.", "AI": {"tldr": "This paper proposes a Mixture of Experts (MoWE) approach to improve weather model accuracy by combining outputs from existing models using a Vision Transformer-based gating network.", "motivation": "The authors aim to overcome a plateau in progress among state-of-the-art data-driven weather models by leveraging existing high-quality models in a novel way instead of building a new forecaster.", "method": "A Mixture of Experts (MoWE) model is trained using significantly fewer computational resources, employing a Vision Transformer-based gating network that dynamically weights the contributions of multiple expert models based on each grid point and forecast lead time.", "result": "The proposed approach improves weather forecasting accuracy, achieving up to a 10% reduction in RMSE compared to the best-performing AI weather model over a 2-day forecast horizon, outperforming individual models and simple averaging methods.", "conclusion": "MoWE offers a computationally efficient and scalable strategy to enhance data-driven weather forecasting accuracy by optimally synthesizing outputs from leading models."}}
{"id": "2509.09614", "pdf": "https://arxiv.org/pdf/2509.09614", "abs": "https://arxiv.org/abs/2509.09614", "authors": ["Jielin Qiu", "Zuxin Liu", "Zhiwei Liu", "Rithesh Murthy", "Jianguo Zhang", "Haolin Chen", "Shiyu Wang", "Ming Zhu", "Liangwei Yang", "Juntao Tan", "Zhepeng Cen", "Cheng Qian", "Shelby Heinecke", "Weiran Yao", "Silvio Savarese", "Caiming Xiong", "Huan Wang"], "title": "LoCoBench: A Benchmark for Long-Context Large Language Models in Complex Software Engineering", "categories": ["cs.SE", "cs.AI"], "comment": "53 pages", "summary": "The emergence of long-context language models with context windows extending\nto millions of tokens has created new opportunities for sophisticated code\nunderstanding and software development evaluation. We propose LoCoBench, a\ncomprehensive benchmark specifically designed to evaluate long-context LLMs in\nrealistic, complex software development scenarios. Unlike existing code\nevaluation benchmarks that focus on single-function completion or short-context\ntasks, LoCoBench addresses the critical evaluation gap for long-context\ncapabilities that require understanding entire codebases, reasoning across\nmultiple files, and maintaining architectural consistency across large-scale\nsoftware systems. Our benchmark provides 8,000 evaluation scenarios\nsystematically generated across 10 programming languages, with context lengths\nspanning 10K to 1M tokens, a 100x variation that enables precise assessment of\nlong-context performance degradation in realistic software development\nsettings. LoCoBench introduces 8 task categories that capture essential\nlong-context capabilities: architectural understanding, cross-file refactoring,\nmulti-session development, bug investigation, feature implementation, code\ncomprehension, integration testing, and security analysis. Through a 5-phase\npipeline, we create diverse, high-quality scenarios that challenge LLMs to\nreason about complex codebases at unprecedented scale. We introduce a\ncomprehensive evaluation framework with 17 metrics across 4 dimensions,\nincluding 8 new evaluation metrics, combined in a LoCoBench Score (LCBS). Our\nevaluation of state-of-the-art long-context models reveals substantial\nperformance gaps, demonstrating that long-context understanding in complex\nsoftware development represents a significant unsolved challenge that demands\nmore attention. LoCoBench is released at:\nhttps://github.com/SalesforceAIResearch/LoCoBench.", "AI": {"tldr": "LoCoBench is a novel benchmark for evaluating long-context language models (LLMs) in complex software development scenarios, focusing on their ability to handle entire codebases and multi-file reasoning.", "motivation": "To address the lack of evaluation tools for long-context LLMs, which struggle with understanding large-scale software systems beyond individual functions or short-context tasks.", "method": "LoCoBench systematically generates 8,000 scenarios across 10 programming languages with context lengths of 10K-1M tokens, covering 8 task categories and featuring a 5-phase pipeline for scenario creation. It introduces 17 evaluation metrics combined into a LoCoBench Score (LCBS).", "result": "State-of-the-art long-context LLMs were evaluated, highlighting significant performance gaps and the challenges in developing models capable of understanding large-scale codebases.", "conclusion": "Long-context language models require substantial advancements to achieve effective understanding and reasoning in realistic software development environments. LoCoBench provides a robust framework to benchmark progress in this area."}}
{"id": "2509.09312", "pdf": "https://arxiv.org/pdf/2509.09312", "abs": "https://arxiv.org/abs/2509.09312", "authors": ["Cl\u00e9ment Contet", "Umberto Grandi", "J\u00e9r\u00f4me Mengin"], "title": "Explaining Tournament Solutions with Minimal Supports", "categories": ["cs.AI"], "comment": null, "summary": "Tournaments are widely used models to represent pairwise dominance between\ncandidates, alternatives, or teams. We study the problem of providing certified\nexplanations for why a candidate appears among the winners under various\ntournament rules. To this end, we identify minimal supports, minimal\nsub-tournaments in which the candidate is guaranteed to win regardless of how\nthe rest of the tournament is completed (that is, the candidate is a necessary\nwinner of the sub-tournament). This notion corresponds to an abductive\nexplanation for the question,\"Why does the winner win the tournament\", a\ncentral concept in formal explainable AI. We focus on common tournament\nsolutions: the top cycle, the uncovered set, the Copeland rule, the Borda rule,\nthe maximin rule, and the weighted uncovered set. For each rule we determine\nthe size of the smallest minimal supports, and we present polynomial-time\nalgorithms to compute them for all but the weighted uncovered set, for which\nthe problem is NP-complete. Finally, we show how minimal supports can serve to\nproduce compact, certified, and intuitive explanations.", "AI": {"tldr": "The paper examines tournament models that represent pairwise dominance among candidates and proposes methods to explain why a candidate is a necessary winner under various tournament rules. It identifies minimal supports that guarantee wins and presents algorithms for computation.", "motivation": "The motivation of the paper is to provide clear, certified, and intuitive explanations for why a candidate emerges as a winner in tournaments, addressing a key aspect of explainable AI.", "method": "The paper focuses on identifying minimal sub-tournaments\u2014necessary winners\u2014which guarantee a candidate's victory under various tournament rules. It develops polynomial-time algorithms for most rules but identifies NP-completeness for the weighted uncovered set.", "result": "Minimal supports were defined for various tournament rules, their smallest sizes were established, and efficient algorithms were designed for most cases except one (weighted uncovered set), where complexity challenges remain.", "conclusion": "Minimal supports provide a robust framework for explaining necessary winners in tournaments, enhancing transparency and accountability in decision-making systems, although some challenges persist with specific rules."}}
{"id": "2509.09006", "pdf": "https://arxiv.org/pdf/2509.09006", "abs": "https://arxiv.org/abs/2509.09006", "authors": ["Samuel Felipe dos Santos", "Tiago Agostinho de Almeida", "Jurandy Almeida"], "title": "E-MLNet: Enhanced Mutual Learning for Universal Domain Adaptation with Sample-Specific Weighting", "categories": ["cs.CV"], "comment": null, "summary": "Universal Domain Adaptation (UniDA) seeks to transfer knowledge from a\nlabeled source to an unlabeled target domain without assuming any relationship\nbetween their label sets, requiring models to classify known samples while\nrejecting unknown ones. Advanced methods like Mutual Learning Network (MLNet)\nuse a bank of one-vs-all classifiers adapted via Open-set Entropy Minimization\n(OEM). However, this strategy treats all classifiers equally, diluting the\nlearning signal. We propose the Enhanced Mutual Learning Network (E-MLNet),\nwhich integrates a dynamic weighting strategy to OEM. By leveraging the\nclosed-set classifier's predictions, E-MLNet focuses adaptation on the most\nrelevant class boundaries for each target sample, sharpening the distinction\nbetween known and unknown classes. We conduct extensive experiments on four\nchallenging benchmarks: Office-31, Office-Home, VisDA-2017, and ImageCLEF. The\nresults demonstrate that E-MLNet achieves the highest average H-scores on VisDA\nand ImageCLEF and exhibits superior robustness over its predecessor. E-MLNet\noutperforms the strong MLNet baseline in the majority of individual adaptation\ntasks -- 22 out of 31 in the challenging Open-Partial DA setting and 19 out of\n31 in the Open-Set DA setting -- confirming the benefits of our focused\nadaptation strategy.", "AI": {"tldr": "E-MLNet introduces a dynamic weighting strategy to improve domain adaptation tasks, achieving better performance and robustness compared to its predecessor, MLNet.", "motivation": "Address challenges in Universal Domain Adaptation, where models must classify known samples and reject unknown ones without assuming label set relationships.", "method": "The Enhanced Mutual Learning Network incorporates dynamic weighting into Open-set Entropy Minimization, focusing adaptation on relevant class boundaries using closed-set classifier predictions.", "result": "Extensive evaluations on benchmarks confirm E-MLNet's superior performance, achieving highest average H-scores and outperforming MLNet in most adaptation tasks.", "conclusion": "E-MLNet effectively enhances adaptation and robustness in universal domain tasks, showcasing the benefits of integrating targeted weighting strategies."}}
{"id": "2509.09484", "pdf": "https://arxiv.org/pdf/2509.09484", "abs": "https://arxiv.org/abs/2509.09484", "authors": ["Peng Zhou", "Jiaming Qi", "Hongmin Wu", "Chen Wang", "Yizhou Chen", "Zeqing Zhang"], "title": "BagIt! An Adaptive Dual-Arm Manipulation of Fabric Bags for Object Bagging", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Bagging tasks, commonly found in industrial scenarios, are challenging\nconsidering deformable bags' complicated and unpredictable nature. This paper\npresents an automated bagging system from the proposed adaptive\nStructure-of-Interest (SOI) manipulation strategy for dual robot arms. The\nsystem dynamically adjusts its actions based on real-time visual feedback,\nremoving the need for pre-existing knowledge of bag properties. Our framework\nincorporates Gaussian Mixture Models (GMM) for estimating SOI states,\noptimization techniques for SOI generation, motion planning via Constrained\nBidirectional Rapidly-exploring Random Tree (CBiRRT), and dual-arm coordination\nusing Model Predictive Control (MPC). Extensive experiments validate the\ncapability of our system to perform precise and robust bagging across various\nobjects, showcasing its adaptability. This work offers a new solution for\nrobotic deformable object manipulation (DOM), particularly in automated bagging\ntasks. Video of this work is available at https://youtu.be/6JWjCOeTGiQ.", "AI": {"tldr": "The paper presents a dual-arm robotic system for adaptive bag manipulation using real-time visual feedback and advanced modeling/planning techniques.", "motivation": "To address the challenges of deformable object manipulation in industrial bagging tasks, where traditional methods struggle due to unpredictable material properties.", "method": "The system leverages Gaussian Mixture Models (GMM) for estimating deformable structures, optimizes SOI generation, employs Constrained Bidirectional Rapidly-exploring Random Tree (CBiRRT) for motion planning, and utilizes Model Predictive Control (MPC) for dual-arm coordination.", "result": "Extensive experiments showed that the proposed system adapts well to various bagging scenarios, performing robustly and precisely without requiring prior knowledge of bag properties.", "conclusion": "The proposed method offers an innovative, efficient approach for automated deformable object manipulation, advancing robotics applications in industrial bagging."}}
{"id": "2509.09053", "pdf": "https://arxiv.org/pdf/2509.09053", "abs": "https://arxiv.org/abs/2509.09053", "authors": ["Julian Oelhaf", "Georg Kordowich", "Mehran Pashaei", "Christian Bergler", "Andreas Maier", "Johann J\u00e4ger", "Siming Bayer"], "title": "A Scoping Review of Machine Learning Applications in Power System Protection and Disturbance Management", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "The integration of renewable and distributed energy resources reshapes modern\npower systems, challenging conventional protection schemes. This scoping review\nsynthesizes recent literature on machine learning (ML) applications in power\nsystem protection and disturbance management, following the PRISMA for Scoping\nReviews framework. Based on over 100 publications, three key objectives are\naddressed: (i) assessing the scope of ML research in protection tasks; (ii)\nevaluating ML performance across diverse operational scenarios; and (iii)\nidentifying methods suitable for evolving grid conditions. ML models often\ndemonstrate high accuracy on simulated datasets; however, their performance\nunder real-world conditions remains insufficiently validated. The existing\nliterature is fragmented, with inconsistencies in methodological rigor, dataset\nquality, and evaluation metrics. This lack of standardization hampers the\ncomparability of results and limits the generalizability of findings. To\naddress these challenges, this review introduces a ML-oriented taxonomy for\nprotection tasks, resolves key terminological inconsistencies, and advocates\nfor standardized reporting practices. It further provides guidelines for\ncomprehensive dataset documentation, methodological transparency, and\nconsistent evaluation protocols, aiming to improve reproducibility and enhance\nthe practical relevance of research outcomes. Critical gaps remain, including\nthe scarcity of real-world validation, insufficient robustness testing, and\nlimited consideration of deployment feasibility. Future research should\nprioritize public benchmark datasets, realistic validation methods, and\nadvanced ML architectures. These steps are essential to move ML-based\nprotection from theoretical promise to practical deployment in increasingly\ndynamic and decentralized power systems.", "AI": {"tldr": "This review evaluates the use of machine learning (ML) in power system protection and disturbance management. It identifies inconsistencies in research methodologies, dataset quality, and evaluation metrics, and suggests standardized practices for future work.", "motivation": "The integration of renewable energy and distributed energy resources necessitates improved protection schemes for power systems. Current protection mechanisms face challenges due to the dynamic nature of grid conditions, prompting exploration into ML solutions.", "method": "A comprehensive scoping review of over 100 publications was conducted, guided by the PRISMA framework. The study synthesizes research trends, evaluates ML performance, introduces a taxonomy, and proposes standardized practices.", "result": "The study indicates ML models perform well on simulated datasets but lack real-world validation. It identifies fragmented literature, terminological inconsistencies, and methodological gaps that hinder the general applicability of findings.", "conclusion": "The paper emphasizes the need for standardized reporting, better dataset documentation, and robust evaluation methods. It calls for prioritizing real-world validation, public benchmarks, and advanced ML architectures to make ML-based protection viable for modern power systems."}}
{"id": "2509.09630", "pdf": "https://arxiv.org/pdf/2509.09630", "abs": "https://arxiv.org/abs/2509.09630", "authors": ["Zhenguang Liu", "Lixun Ma", "Zhongzheng Mu", "Chengkun Wei", "Xiaojun Xu", "Yingying Jiao", "Kui Ren"], "title": "I Know Who Clones Your Code: Interpretable Smart Contract Similarity Detection", "categories": ["cs.SE", "cs.CR"], "comment": null, "summary": "Widespread reuse of open-source code in smart contract development boosts\nprogramming efficiency but significantly amplifies bug propagation across\ncontracts, while dedicated methods for detecting similar smart contract\nfunctions remain very limited. Conventional abstract-syntax-tree (AST) based\nmethods for smart contract similarity detection face challenges in handling\nintricate tree structures, which impedes detailed semantic comparison of code.\nRecent deep-learning based approaches tend to overlook code syntax and\ndetection interpretability, resulting in suboptimal performance.\n  To fill this research gap, we introduce SmartDetector, a novel approach for\ncomputing similarity between smart contract functions, explainable at the\nfine-grained statement level. Technically, SmartDetector decomposes the AST of\na smart contract function into a series of smaller statement trees, each\nreflecting a structural element of the source code. Then, SmartDetector uses a\nclassifier to compute the similarity score of two functions by comparing each\npair of their statement trees. To address the infinite hyperparameter space of\nthe classifier, we mathematically derive a cosine-wise diffusion process to\nefficiently search optimal hyperparameters. Extensive experiments conducted on\nthree large real-world datasets demonstrate that SmartDetector outperforms\ncurrent state-of-the-art methods by an average improvement of 14.01% in\nF1-score, achieving an overall average F1-score of 95.88%.", "AI": {"tldr": "This paper introduces SmartDetector, an approach to detect similarity between smart contract functions using explainable methods.", "motivation": "The high reuse of open-source smart contract code aids efficiency but accelerates bug propagation, with limited tools available for precise similarity detection.", "method": "SmartDetector dissects ASTs of functions into statement trees to compare at a statement level, using a classifier optimized through a cosine-wise diffusion process.", "result": "SmartDetector achieves an average 14.01% improvement in F1-score over current methods, with an average F1-score of 95.88% in experiments on large datasets.", "conclusion": "SmartDetector provides interpretable and effective detection of similar smart contract functions, addressing limitations in existing methods with significant performance improvements."}}
{"id": "2509.09314", "pdf": "https://arxiv.org/pdf/2509.09314", "abs": "https://arxiv.org/abs/2509.09314", "authors": ["Thuy Ngoc Nguyen", "Anita Williams Woolley", "Cleotilde Gonzalez"], "title": "Measuring Implicit Spatial Coordination in Teams: Effects on Collective Intelligence and Performance", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "Coordinated teamwork is essential in fast-paced decision-making environments\nthat require dynamic adaptation, often without an opportunity for explicit\ncommunication. Although implicit coordination has been extensively considered\nin the existing literature, the majority of work has focused on co-located,\nsynchronous teamwork (such as sports teams) or, in distributed teams, primarily\non coordination of knowledge work. However, many teams (firefighters, military,\nlaw enforcement, emergency response) must coordinate their movements in\nphysical space without the benefit of visual cues or extensive explicit\ncommunication. This paper investigates how three dimensions of spatial\ncoordination, namely exploration diversity, movement specialization, and\nadaptive spatial proximity, influence team performance in a collaborative\nonline search and rescue task where explicit communication is restricted and\nteam members rely on movement patterns to infer others' intentions and\ncoordinate actions. Our metrics capture the relational aspects of teamwork by\nmeasuring spatial proximity, distribution patterns, and alignment of movements\nwithin shared environments. We analyze data from 34 four-person teams (136\nparticipants) assigned to specialized roles in a search and rescue task.\nResults show that spatial specialization positively predicts performance, while\nadaptive spatial proximity exhibits a marginal inverted U-shaped relationship,\nsuggesting moderate levels of adaptation are optimal. Furthermore, the temporal\ndynamics of these metrics differentiate high- from low-performing teams over\ntime. These findings provide insights into implicit spatial coordination in\nrole-based teamwork and highlight the importance of balanced adaptive\nstrategies, with implications for training and AI-assisted team support\nsystems.", "AI": {"tldr": "The paper explores the influence of spatial coordination metrics on team performance during restricted communication in a search and rescue task.", "motivation": "The researchers aim to understand how spatial coordination impacts performance in physical, role-based teamwork scenarios, especially when explicit communication and visual cues are absent.", "method": "Four-person teams performed a collaborative online search and rescue task, with metrics created to measure spatial proximity, distribution patterns, and movement alignment in restricted communication settings.", "result": "Spatial specialization positively predicted performance, while adaptive spatial proximity showed a marginal inverted U-shaped relationship with performance. Temporal dynamics distinguished high-performing from low-performing teams.", "conclusion": "Balanced adaptive strategies in spatial coordination are essential for effective teamwork, with implications for training and AI-assisted systems."}}
{"id": "2509.09160", "pdf": "https://arxiv.org/pdf/2509.09160", "abs": "https://arxiv.org/abs/2509.09160", "authors": ["Zhiyue Liu", "Fanrong Ma", "Xin Ling"], "title": "Target-oriented Multimodal Sentiment Classification with Counterfactual-enhanced Debiasing", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by the IEEE International Conference on Multimedia and Expo\n  (ICME 2025). \\copyright\\ 2025 IEEE. Personal use of this material is\n  permitted. Permission from IEEE must be obtained for all other uses", "summary": "Target-oriented multimodal sentiment classification seeks to predict\nsentiment polarity for specific targets from image-text pairs. While existing\nworks achieve competitive performance, they often over-rely on textual content\nand fail to consider dataset biases, in particular word-level contextual\nbiases. This leads to spurious correlations between text features and output\nlabels, impairing classification accuracy. In this paper, we introduce a novel\ncounterfactual-enhanced debiasing framework to reduce such spurious\ncorrelations. Our framework incorporates a counterfactual data augmentation\nstrategy that minimally alters sentiment-related causal features, generating\ndetail-matched image-text samples to guide the model's attention toward content\ntied to sentiment. Furthermore, for learning robust features from\ncounterfactual data and prompting model decisions, we introduce an adaptive\ndebiasing contrastive learning mechanism, which effectively mitigates the\ninfluence of biased words. Experimental results on several benchmark datasets\nshow that our proposed method outperforms state-of-the-art baselines.", "AI": {"tldr": "The paper addresses biases in multimodal sentiment classification and proposes a framework using counterfactual data augmentation and contrastive learning to improve classification accuracy.", "motivation": "Existing target-oriented multimodal sentiment classification models rely too heavily on textual content, leading to spurious correlations and biases, particularly word-level contextual biases. These impair overall classification accuracy, creating a need for more robust approaches.", "method": "The paper introduces a counterfactual-enhanced debiasing framework. It includes counterfactual data augmentation by modifying causal sentiment-related features and generating detail-matched image-text samples. Additionally, an adaptive debiasing contrastive learning mechanism is used to mitigate biased word influence.", "result": "Experimental results demonstrate that the proposed framework surpasses state-of-the-art baselines in classification accuracy across benchmark datasets, improving robustness against biases.", "conclusion": "The novel framework effectively reduces spurious correlations in multimodal sentiment classification, emphasizing sentiment-related features and improving accuracy. It demonstrates scalability and superiority over existing models."}}
{"id": "2509.09014", "pdf": "https://arxiv.org/pdf/2509.09014", "abs": "https://arxiv.org/abs/2509.09014", "authors": ["Umair Hassan"], "title": "COCO-Urdu: A Large-Scale Urdu Image-Caption Dataset with Multimodal Quality Estimation", "categories": ["cs.CV", "cs.CL", "68T45 (Primary) 68T50 (Secondary)"], "comment": "17 pages, 3 figures, 3 tables. Dataset available at\n  https://huggingface.co/datasets/umairhassan02/urdu-translated-coco-captions-subset.\n  Scripts and notebooks to reproduce results available at\n  https://github.com/umair-hassan2/COCO-Urdu", "summary": "Urdu, spoken by over 250 million people, remains critically under-served in\nmultimodal and vision-language research. The absence of large-scale,\nhigh-quality datasets has limited the development of Urdu-capable systems and\nreinforced biases in multilingual vision-language models trained primarily on\nhigh-resource languages. To address this gap, we present COCO-Urdu, a\nlarge-scale image-caption dataset derived from MS COCO, containing 59,000\nimages and 319,000 Urdu captions selected through stratified sampling to\npreserve the original distribution. Captions were translated using SeamlessM4T\nv2 and validated with a hybrid multimodal quality estimation framework that\nintegrates COMET-Kiwi for translation quality, CLIP-based similarity for visual\ngrounding, and BERTScore with back-translation for semantic consistency;\nlow-scoring captions were iteratively refined using open-source large language\nmodels. We further benchmark COCO-Urdu on BLEU, SacreBLEU, and chrF, reporting\nconsistently strong results. To the best of our knowledge, COCO-Urdu is the\nlargest publicly available Urdu captioning dataset. By releasing both the\ndataset and the quality estimation pipeline, we aim to reduce language bias in\nmultimodal research and establish a foundation for inclusive vision-language\nsystems.", "AI": {"tldr": "COCO-Urdu is a large-scale Urdu image-captioning dataset derived from MS COCO, featuring 319,000 Urdu captions validated using a multimodal quality estimation pipeline.", "motivation": "Urdu remains underserved in vision-language research, due to the lack of high-quality datasets, which leads to biases in multilingual AI models.", "method": "The authors created COCO-Urdu by translating MS COCO captions into Urdu using SeamlessM4T v2, followed by quality validation through a hybrid framework that combines COMET-Kiwi, CLIP, and BERTScore tools. Iterative refinements were made using large language models.", "result": "COCO-Urdu consists of 59,000 images and 319,000 Urdu captions, achieving strong benchmarks on BLEU, SacreBLEU, and chrF evaluations.", "conclusion": "COCO-Urdu fills a gap in multimodal research for Urdu by providing a high-quality dataset and quality estimation pipeline, promoting more inclusive vision-language systems."}}
{"id": "2509.09509", "pdf": "https://arxiv.org/pdf/2509.09509", "abs": "https://arxiv.org/abs/2509.09509", "authors": ["Pedro Miguel Bastos Soares", "Ali Tourani", "Miguel Fernandez-Cortizas", "Asier Bikandi Noya", "Jose Luis Sanchez-Lopez", "Holger Voos"], "title": "SMapper: A Multi-Modal Data Acquisition Platform for SLAM Benchmarking", "categories": ["cs.RO"], "comment": "12 pages, 6 figures, 5 tables", "summary": "Advancing research in fields like Simultaneous Localization and Mapping\n(SLAM) and autonomous navigation critically depends on reliable and\nreproducible multimodal datasets. While several influential datasets have\ndriven progress in these domains, they often suffer from limitations in sensing\nmodalities, environmental diversity, and the reproducibility of the underlying\nhardware setups. To address these challenges, this paper introduces SMapper, a\nnovel open-hardware, multi-sensor platform designed explicitly for, though not\nlimited to, SLAM research. The device integrates synchronized LiDAR,\nmulti-camera, and inertial sensing, supported by a robust calibration and\nsynchronization pipeline that ensures precise spatio-temporal alignment across\nmodalities. Its open and replicable design allows researchers to extend its\ncapabilities and reproduce experiments across both handheld and robot-mounted\nscenarios. To demonstrate its practicality, we additionally release\nSMapper-light, a publicly available SLAM dataset containing representative\nindoor and outdoor sequences. The dataset includes tightly synchronized\nmultimodal data and ground-truth trajectories derived from offline LiDAR-based\nSLAM with sub-centimeter accuracy, alongside dense 3D reconstructions.\nFurthermore, the paper contains benchmarking results on state-of-the-art LiDAR\nand visual SLAM frameworks using the SMapper-light dataset. By combining\nopen-hardware design, reproducible data collection, and comprehensive\nbenchmarking, SMapper establishes a robust foundation for advancing SLAM\nalgorithm development, evaluation, and reproducibility.", "AI": {"tldr": "The paper introduces SMapper, an open-hardware platform for SLAM research integrating multiple synchronized sensors and releasing a public dataset called SMapper-light for evaluation.", "motivation": "SLAM and autonomous navigation research require reliable datasets, yet many existing datasets lack sufficient sensing and environmental diversity, making experiments less reproducible.", "method": "The study presents SMapper, a platform with integrated LiDAR, cameras, and inertial sensors, supported by a calibration pipeline. It also releases the SMapper-light dataset with synchronized data and benchmarks SLAM frameworks.", "result": "SMapper proved capable of precise multimodal sensing and reproducible experiments, while the SMapper-light dataset provided high-accuracy ground-truth trajectories for SLAM benchmarking.", "conclusion": "The work enhances SLAM research capabilities through its open hardware design, reproducible dataset, and benchmark evaluations, fostering progress in algorithm development and comparisons."}}
{"id": "2509.09321", "pdf": "https://arxiv.org/pdf/2509.09321", "abs": "https://arxiv.org/abs/2509.09321", "authors": ["Hangyi Jia", "Yuxi Qian", "Hanwen Tong", "Xinhui Wu", "Lin Chen", "Feng Wei"], "title": "Towards Adaptive ML Benchmarks: Web-Agent-Driven Construction, Domain Expansion, and Metric Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled the emergence of\ngeneral-purpose agents for automating end-to-end machine learning (ML)\nworkflows, including data analysis, feature engineering, model training, and\ncompetition solving. However, existing benchmarks remain limited in task\ncoverage, domain diversity, difficulty modeling, and evaluation rigor, failing\nto capture the full capabilities of such agents in realistic settings. We\npresent TAM Bench, a diverse, realistic, and structured benchmark for\nevaluating LLM-based agents on end-to-end ML tasks. TAM Bench features three\nkey innovations: (1) A browser automation and LLM-based task acquisition system\nthat automatically collects and structures ML challenges from platforms such as\nKaggle, AIcrowd, and Biendata, spanning multiple task types and data modalities\n(e.g., tabular, text, image, graph, audio); (2) A leaderboard-driven difficulty\nmodeling mechanism that estimates task complexity using participant counts and\nscore dispersion, enabling scalable and objective task calibration; (3) A\nmulti-dimensional evaluation framework incorporating performance, format\ncompliance, constraint adherence, and task generalization. Based on 150 curated\nAutoML tasks, we construct three benchmark subsets of different sizes -- Lite,\nMedium, and Full -- designed for varying evaluation scenarios. The Lite\nversion, with 18 tasks and balanced coverage across modalities and difficulty\nlevels, serves as a practical testbed for daily benchmarking and comparative\nstudies.", "AI": {"tldr": "The paper introduces TAM Bench, a benchmark to evaluate LLM-based agents on comprehensive ML tasks using diverse datasets and structured evaluations.", "motivation": "To address limitations in existing benchmarks which fall short in task coverage, domain diversity, difficulty modeling, and evaluation rigor for end-to-end ML workflows.", "method": "Developing TAM Bench using three innovations: automation for task acquisition from ML platforms, difficulty modeling based on leaderboard dynamics, and a framework for multi-dimensional evaluation with 150 curated tasks.", "result": "TAM Bench provides benchmark subsets in Lite, Medium, and Full scales for targeted and comprehensive evaluations of ML agents across multiple modalities and challenges.", "conclusion": "TAM Bench offers a realistic and structured approach to evaluate the full potential of LLM-based agents in automating and solving diverse ML tasks effectively."}}
{"id": "2509.09174", "pdf": "https://arxiv.org/pdf/2509.09174", "abs": "https://arxiv.org/abs/2509.09174", "authors": ["Yuhao Zhang", "Yuhao Du", "Zhanchen Dai", "Xiangnan Ma", "Kaiqi Kou", "Benyou Wang", "Haizhou Li"], "title": "EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs", "categories": ["cs.CL", "cs.AI", "cs.SD"], "comment": null, "summary": "Speech-to-speech large language models (SLLMs) are attracting increasing\nattention. Derived from text-based large language models (LLMs), SLLMs often\nexhibit degradation in knowledge and reasoning capabilities. We hypothesize\nthat this limitation arises because current training paradigms for SLLMs fail\nto bridge the acoustic-semantic gap in the feature representation space. To\naddress this issue, we propose EchoX, which leverages semantic representations\nand dynamically generates speech training targets. This approach integrates\nboth acoustic and semantic learning, enabling EchoX to preserve strong\nreasoning abilities as a speech LLM. Experimental results demonstrate that\nEchoX, with about six thousand hours of training data, achieves advanced\nperformance on multiple knowledge-based question-answering benchmarks. The\nproject is available at https://github.com/FreedomIntelligence/EchoX.", "AI": {"tldr": "EchoX bridges the gap between speech and semantics to enhance knowledge and reasoning in speech-based large language models, outperforming existing approaches on QA benchmarks.", "motivation": "Current speech-based LLMs underperform in knowledge and reasoning tasks due to inadequate bridging of acoustic and semantic representations.", "method": "EchoX uses semantic representations and dynamically generated speech training targets to integrate acoustic and semantic learning, maintaining strong reasoning capabilities.", "result": "Experimental results showed EchoX achieves advanced performance in knowledge-based QA benchmarks with six thousand hours of training.", "conclusion": "EchoX successfully preserves reasoning ability in speech LLMs, proving effective in addressing the acoustic-semantic gap."}}
{"id": "2509.09015", "pdf": "https://arxiv.org/pdf/2509.09015", "abs": "https://arxiv.org/abs/2509.09015", "authors": ["Chenqian Le", "Yilin Zhao", "Nikasadat Emami", "Kushagra Yadav", "Xujin \"Chris\" Liu", "Xupeng Chen", "Yao Wang"], "title": "VoxelFormer: Parameter-Efficient Multi-Subject Visual Decoding from fMRI", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in fMRI-based visual decoding have enabled compelling\nreconstructions of perceived images. However, most approaches rely on\nsubject-specific training, limiting scalability and practical deployment. We\nintroduce \\textbf{VoxelFormer}, a lightweight transformer architecture that\nenables multi-subject training for visual decoding from fMRI. VoxelFormer\nintegrates a Token Merging Transformer (ToMer) for efficient voxel compression\nand a query-driven Q-Former that produces fixed-size neural representations\naligned with the CLIP image embedding space. Evaluated on the 7T Natural Scenes\nDataset, VoxelFormer achieves competitive retrieval performance on subjects\nincluded during training with significantly fewer parameters than existing\nmethods. These results highlight token merging and query-based transformers as\npromising strategies for parameter-efficient neural decoding.", "AI": {"tldr": "The paper introduces VoxelFormer, a transformer-based architecture for multi-subject visual decoding from fMRI data, achieving competitive performance with fewer parameters compared to existing methods.", "motivation": "Existing fMRI-based visual decoding methods primarily rely on subject-specific training, hindering scalability and broad applicability.", "method": "VoxelFormer utilizes a Token Merging Transformer for efficient voxel compression and a query-driven Q-Former for generating neural representations aligned with CLIP image embeddings.", "result": "VoxelFormer demonstrates competitive performance with reduced parameters on the 7T Natural Scenes Dataset for visual decoding tasks.", "conclusion": "The study underscores token merging and query-based transformers as efficient techniques for scalable neural decoding in fMRI-based visual applications."}}
{"id": "2509.09546", "pdf": "https://arxiv.org/pdf/2509.09546", "abs": "https://arxiv.org/abs/2509.09546", "authors": ["Yanhui Lu", "Zeyu Deng", "Stephen J. Redmond", "Efi Psomopoulou", "Benjamin Ward-Cherrier"], "title": "A Neuromorphic Incipient Slip Detection System using Papillae Morphology", "categories": ["cs.RO"], "comment": "7 pages, 12 figures. Submitted to IEEE Robotics and Automation\n  Letters (RAL), under review", "summary": "Detecting incipient slip enables early intervention to prevent object\nslippage and enhance robotic manipulation safety. However, deploying such\nsystems on edge platforms remains challenging, particularly due to energy\nconstraints. This work presents a neuromorphic tactile sensing system based on\nthe NeuroTac sensor with an extruding papillae-based skin and a spiking\nconvolutional neural network (SCNN) for slip-state classification. The SCNN\nmodel achieves 94.33% classification accuracy across three classes (no slip,\nincipient slip, and gross slip) in slip conditions induced by sensor motion.\nUnder the dynamic gravity-induced slip validation conditions, after temporal\nsmoothing of the SCNN's final-layer spike counts, the system detects incipient\nslip at least 360 ms prior to gross slip across all trials, consistently\nidentifying incipient slip before gross slip occurs. These results demonstrate\nthat this neuromorphic system has stable and responsive incipient slip\ndetection capability.", "AI": {"tldr": "The paper presents a neuromorphic tactile sensing system using a spiking convolutional neural network (SCNN) for accurate slip-state classification and early detection of incipient slippage.", "motivation": "To address the challenge of detecting incipient slippage for safer robotic manipulation on energy-constrained edge platforms.", "method": "Developed a tactile sensing system combining NeuroTac sensor with spiking convolutional neural network (SCNN) to classify slip states and perform early slip detection.", "result": "Achieved over 94% classification accuracy, detected incipient slip at least 360 ms before gross slip in all tested conditions.", "conclusion": "The neuromorphic tactile sensing system provides reliable, early incipient slip detection, supporting safer robotic manipulation."}}
{"id": "2509.09073", "pdf": "https://arxiv.org/pdf/2509.09073", "abs": "https://arxiv.org/abs/2509.09073", "authors": ["Gianlucca Zuin", "Adriano Veloso"], "title": "\"A 6 or a 9?\": Ensemble Learning Through the Multiplicity of Performant Models and Explanations", "categories": ["cs.LG"], "comment": "Paper accepted to the ACM Transactions on Knowledge Discovery from\n  Data (TKDD) for publication (preprint version)", "summary": "Creating models from past observations and ensuring their effectiveness on\nnew data is the essence of machine learning. However, selecting models that\ngeneralize well remains a challenging task. Related to this topic, the Rashomon\nEffect refers to cases where multiple models perform similarly well for a given\nlearning problem. This often occurs in real-world scenarios, like the\nmanufacturing process or medical diagnosis, where diverse patterns in data lead\nto multiple high-performing solutions. We propose the Rashomon Ensemble, a\nmethod that strategically selects models from these diverse high-performing\nsolutions to improve generalization. By grouping models based on both their\nperformance and explanations, we construct ensembles that maximize diversity\nwhile maintaining predictive accuracy. This selection ensures that each model\ncovers a distinct region of the solution space, making the ensemble more robust\nto distribution shifts and variations in unseen data. We validate our approach\non both open and proprietary collaborative real-world datasets, demonstrating\nup to 0.20+ AUROC improvements in scenarios where the Rashomon ratio is large.\nAdditionally, we demonstrate tangible benefits for businesses in various\nreal-world applications, highlighting the robustness, practicality, and\neffectiveness of our approach.", "AI": {"tldr": "The paper introduces the Rashomon Ensemble method, selecting diverse yet accurate models to improve robustness and generalization, validated through real-world datasets.", "motivation": "The authors aim to address the challenge of selecting machine learning models that generalize well to unseen data, particularly in cases with the Rashomon Effect, where multiple models achieve similar high performance.", "method": "The proposed approach strategically selects models from the Rashomon set, grouping them based on performance and explanation diversity, to form ensembles that are robust to distribution shifts while maintaining accuracy.", "result": "The method showed up to 0.20+ AUROC improvements and demonstrated practical applicability in real-world business scenarios where the Rashomon ratio is significant.", "conclusion": "The Rashomon Ensemble improves robustness and generalization for machine learning models in diverse and complex real-world settings, offering tangible benefits."}}
{"id": "2509.09392", "pdf": "https://arxiv.org/pdf/2509.09392", "abs": "https://arxiv.org/abs/2509.09392", "authors": ["Simon Leistikow", "Thomas Miro", "Adrian Kummerl\u00e4nder", "Ali Nahardani", "Katja Gr\u00fcn", "Markus Franz", "Verena Hoerr", "Mathias J. Krause", "Lars Linsen"], "title": "An Integrated Open Source Software System for the Generation and Analysis of Subject-Specific Blood Flow Simulation Ensembles", "categories": ["physics.med-ph", "cs.SE"], "comment": "21 pages, 7 figures, 2 tables", "summary": "Background and Objective: Hemodynamic analysis of blood flow through arteries\nand veins is critical for diagnosing cardiovascular diseases, such as aneurysms\nand stenoses, and for investigating cardiovascular parameters, such as\nturbulence and wall shear stress. For subject-specific analyses, the anatomy\nand blood flow of the subject can be captured non-invasively using structural\nand 4D Magnetic Resonance Imaging (MRI). Computational Fluid Dynamics (CFD), on\nthe other hand, can be used to generate blood flow simulations by solving the\nNavier-Stokes equations. To generate and analyze subject-specific blood flow\nsimulations, MRI and CFD have to be brought together.\n  Methods: We present an interactive, customizable, and user-oriented visual\nanalysis tool that assists researchers in both medicine and numerical analysis.\nOur open-source tool is applicable to domains such as CFD and MRI, and it\nfacilitates the analysis of simulation results and medical data, especially in\nhemodynamic studies. It enables the creation of simulation ensembles with a\nhigh variety of parameters. Furthermore, it allows for the visual and\nanalytical examination of simulations and measurements through 2D embeddings of\nthe similarity space.\n  Results: To demonstrate the effectiveness of our tool, we applied it to three\nreal-world use cases, showcasing its ability to configure simulation ensembles\nand analyse blood flow dynamics. We evaluated our example cases together with\nMRI and CFD experts to further enhance features and increase the usability.\n  Conclusions: By combining the strengths of both CFD and MRI, our tool\nprovides a more comprehensive understanding of hemodynamic parameters,\nfacilitating more accurate analysis of hemodynamic biomarkers.", "AI": {"tldr": "The paper introduces an interactive tool merging MRI and CFD for improved blood flow analysis, emphasizing comprehensive hemodynamic studies.", "motivation": "To integrate MRI and CFD for subject-specific hemodynamic analysis, addressing cardiovascular disease diagnostics and parameter investigations.", "method": "An open-source visual analysis tool was developed for customizable simulation ensembles, enabling detailed examination of simulations and measurements.", "result": "The tool was successfully demonstrated in three real-world use cases, co-evaluated with MRI and CFD experts, which improved its features and usability.", "conclusion": "The tool effectively combines CFD and MRI to enhance comprehension of hemodynamic parameters, improving the analysis of hemodynamic biomarkers."}}
{"id": "2509.09356", "pdf": "https://arxiv.org/pdf/2509.09356", "abs": "https://arxiv.org/abs/2509.09356", "authors": ["Abdel Hakim Drid", "Vincenzo Suriani", "Daniele Nardi", "Abderrezzak Debilou"], "title": "Curriculum-Based Multi-Tier Semantic Exploration via Deep Reinforcement Learning", "categories": ["cs.AI", "cs.RO"], "comment": "The 19th International Conference on Intelligent Autonomous Systems\n  (IAS 19), 2025, Genoa", "summary": "Navigating and understanding complex and unknown environments autonomously\ndemands more than just basic perception and movement from embodied agents.\nTruly effective exploration requires agents to possess higher-level cognitive\nabilities, the ability to reason about their surroundings, and make more\ninformed decisions regarding exploration strategies. However, traditional RL\napproaches struggle to balance efficient exploration and semantic understanding\ndue to limited cognitive capabilities embedded in the small policies for the\nagents, leading often to human drivers when dealing with semantic exploration.\nIn this paper, we address this challenge by presenting a novel Deep\nReinforcement Learning (DRL) architecture that is specifically designed for\nresource efficient semantic exploration. A key methodological contribution is\nthe integration of a Vision-Language Model (VLM) common-sense through a layered\nreward function. The VLM query is modeled as a dedicated action, allowing the\nagent to strategically query the VLM only when deemed necessary for gaining\nexternal guidance, thereby conserving resources. This mechanism is combined\nwith a curriculum learning strategy designed to guide learning at different\nlevels of complexity to ensure robust and stable learning. Our experimental\nevaluation results convincingly demonstrate that our agent achieves\nsignificantly enhanced object discovery rates and develops a learned capability\nto effectively navigate towards semantically rich regions. Furthermore, it also\nshows a strategic mastery of when to prompt for external environmental\ninformation. By demonstrating a practical and scalable method for embedding\ncommon-sense semantic reasoning with autonomous agents, this research provides\na novel approach to pursuing a fully intelligent and self-guided exploration in\nrobotics.", "AI": {"tldr": "The paper proposes a novel Deep Reinforcement Learning (DRL) architecture integrating Vision-Language Models (VLM) for efficient semantic exploration.", "motivation": "To address the inefficiencies in exploration and semantic understanding caused by limited cognitive capabilities in traditional RL approaches, which often require human intervention.", "method": "Introduced a DRL architecture with a layered reward function integrating VLM as a dedicated and strategic query action, combined with curriculum learning to ensure stable learning.", "result": "The proposed agent demonstrated significantly improved object discovery rates, effective navigation in semantically-rich areas, and strategic invocation of external guidance through the VLM.", "conclusion": "The research offers a scalable method for embedding common-sense semantic reasoning, advancing autonomous agents towards fully self-guided and intelligent exploration in robotics."}}
{"id": "2509.09196", "pdf": "https://arxiv.org/pdf/2509.09196", "abs": "https://arxiv.org/abs/2509.09196", "authors": ["Chin Yuen Kwok", "Jia Qi yip"], "title": "Efficient Trie-based Biasing using K-step Prediction for Rare Word Recognition", "categories": ["cs.CL", "cs.AI"], "comment": "Published in Interspeech 2025", "summary": "Contextual biasing improves rare word recognition of ASR models by\nprioritizing the output of rare words during decoding. A common approach is\nTrie-based biasing, which gives \"bonus scores\" to partial hypothesis (e.g.\n\"Bon\") that may lead to the generation of the rare word (e.g. \"Bonham\"). If the\nfull word (\"Bonham\") isn't ultimately recognized, the system revokes those\nearlier bonuses. This revocation is limited to beam search and is\ncomputationally expensive, particularly for models with large decoders. To\novercome these limitations, we propose adapting ASR models to look ahead and\npredict multiple steps at once. This avoids the revocation step entirely by\nbetter estimating whether a partial hypothesis will lead to the generation of\nthe full rare word. By fine-tuning Whisper with only 10 hours of synthetic\ndata, our method reduces the word error rate on the NSC Part 2 test set from\n30.86% to 12.19%.", "AI": {"tldr": "The paper proposes an improved contextual biasing algorithm for ASR models, which enhances rare word recognition performance and bypasses computational inefficiencies related to trie-based biasing.", "motivation": "Current Trie-based contextual biasing methods for ASR struggle with efficiency and accuracy, especially with models having large decoders, and often require costly revocation steps.", "method": "Adapt ASR models to predict multiple decoding steps simultaneously, eliminating the need for revocation steps. Fine-tune the existing Whisper model using 10 hours of synthetic data.", "result": "The proposed method successfully reduces the word error rate on the NSC Part 2 test set from 30.86% to 12.19%, highlighting significant improvement in rare word recognition.", "conclusion": "The new decoding approach effectively enhances rare word recognition in ASR while addressing computational inefficiencies, proving successful with minimal fine-tuning."}}
{"id": "2509.09054", "pdf": "https://arxiv.org/pdf/2509.09054", "abs": "https://arxiv.org/abs/2509.09054", "authors": ["Binxu Li", "Wei Peng", "Mingjie Li", "Ehsan Adeli", "Kilian M. Pohl"], "title": "Integrating Anatomical Priors into a Causal Diffusion Model", "categories": ["cs.CV"], "comment": "15 pages, 4 figures", "summary": "3D brain MRI studies often examine subtle morphometric differences between\ncohorts that are hard to detect visually. Given the high cost of MRI\nacquisition, these studies could greatly benefit from image syntheses,\nparticularly counterfactual image generation, as seen in other domains, such as\ncomputer vision. However, counterfactual models struggle to produce\nanatomically plausible MRIs due to the lack of explicit inductive biases to\npreserve fine-grained anatomical details. This shortcoming arises from the\ntraining of the models aiming to optimize for the overall appearance of the\nimages (e.g., via cross-entropy) rather than preserving subtle, yet medically\nrelevant, local variations across subjects. To preserve subtle variations, we\npropose to explicitly integrate anatomical constraints on a voxel-level as\nprior into a generative diffusion framework. Called Probabilistic Causal Graph\nModel (PCGM), the approach captures anatomical constraints via a probabilistic\ngraph module and translates those constraints into spatial binary masks of\nregions where subtle variations occur. The masks (encoded by a 3D extension of\nControlNet) constrain a novel counterfactual denoising UNet, whose encodings\nare then transferred into high-quality brain MRIs via our 3D diffusion decoder.\nExtensive experiments on multiple datasets demonstrate that PCGM generates\nstructural brain MRIs of higher quality than several baseline approaches.\nFurthermore, we show for the first time that brain measurements extracted from\ncounterfactuals (generated by PCGM) replicate the subtle effects of a disease\non cortical brain regions previously reported in the neuroscience literature.\nThis achievement is an important milestone in the use of synthetic MRIs in\nstudies investigating subtle morphological differences.", "AI": {"tldr": "The paper introduces Probabilistic Causal Graph Model (PCGM), a 3D generative diffusion framework that integrates voxel-level anatomical constraints to produce high-quality counterfactual brain MRIs, addressing fine-grained morphological distinctions.", "motivation": "Counterfactual MRI generation is needed to observe subtle brain morphology differences, but current models struggle due to lack of explicit anatomical inductive biases, which prevents them from preserving fine anatomical details.", "method": "The authors propose PCGM, which integrates probabilistic graph anatomical constraints into diffusion models. It uses spatial binary masks generated via a 3D ControlNet, coupled with a counterfactual denoising UNet and 3D diffusion decoder to synthesize anatomically plausible MRIs.", "result": "PCGM outperforms baseline models in generating high-quality brain MRIs, replicating medically relevant subtle effects of diseases on cortical brain regions as seen in real-world neuroscience studies.", "conclusion": "PCGM successfully addresses the limitations of counterfactual MRI generation, offering a key tool to support studies on subtle brain morphological changes using synthetic MRIs."}}
{"id": "2509.09594", "pdf": "https://arxiv.org/pdf/2509.09594", "abs": "https://arxiv.org/abs/2509.09594", "authors": ["Sourav Garg", "Dustin Craggs", "Vineeth Bhat", "Lachlan Mares", "Stefan Podgorski", "Madhava Krishna", "Feras Dayoub", "Ian Reid"], "title": "ObjectReact: Learning Object-Relative Control for Visual Navigation", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "comment": "CoRL 2025; 23 pages including appendix", "summary": "Visual navigation using only a single camera and a topological map has\nrecently become an appealing alternative to methods that require additional\nsensors and 3D maps. This is typically achieved through an \"image-relative\"\napproach to estimating control from a given pair of current observation and\nsubgoal image. However, image-level representations of the world have\nlimitations because images are strictly tied to the agent's pose and\nembodiment. In contrast, objects, being a property of the map, offer an\nembodiment- and trajectory-invariant world representation. In this work, we\npresent a new paradigm of learning \"object-relative\" control that exhibits\nseveral desirable characteristics: a) new routes can be traversed without\nstrictly requiring to imitate prior experience, b) the control prediction\nproblem can be decoupled from solving the image matching problem, and c) high\ninvariance can be achieved in cross-embodiment deployment for variations across\nboth training-testing and mapping-execution settings. We propose a topometric\nmap representation in the form of a \"relative\" 3D scene graph, which is used to\nobtain more informative object-level global path planning costs. We train a\nlocal controller, dubbed \"ObjectReact\", conditioned directly on a high-level\n\"WayObject Costmap\" representation that eliminates the need for an explicit RGB\ninput. We demonstrate the advantages of learning object-relative control over\nits image-relative counterpart across sensor height variations and multiple\nnavigation tasks that challenge the underlying spatial understanding\ncapability, e.g., navigating a map trajectory in the reverse direction. We\nfurther show that our sim-only policy is able to generalize well to real-world\nindoor environments. Code and supplementary material are accessible via project\npage: https://object-react.github.io/", "AI": {"tldr": "This paper proposes a novel paradigm, \"object-relative\" control for visual navigation which uses a topometric map and object-relative representations.", "motivation": "Current methods of visual navigation rely heavily on image-relative approaches tied to agents' pose and embodiment, which restrict flexibility and generalization.", "method": "The authors present \"ObjectReact,\" leveraging a relative 3D scene graph and object-level global path planning costs, trained using a high-level \"WayObject Costmap\" without relying on RGB inputs.", "result": "Object-relative control shows greater adaptability across sensor and embodiment variations, performs well on complex navigation tasks, and generalizes from simulation to real-world environments.", "conclusion": "Object-relative control surpasses conventional image-relative control in flexibility, generalization, and robustness in visual navigation tasks."}}
{"id": "2509.09088", "pdf": "https://arxiv.org/pdf/2509.09088", "abs": "https://arxiv.org/abs/2509.09088", "authors": ["Govind Menon", "Tianmin Yu"], "title": "An entropy formula for the Deep Linear Network", "categories": ["cs.LG", "math.DG", "math.DS"], "comment": null, "summary": "We study the Riemannian geometry of the Deep Linear Network (DLN) as a\nfoundation for a thermodynamic description of the learning process. The main\ntools are the use of group actions to analyze overparametrization and the use\nof Riemannian submersion from the space of parameters to the space of\nobservables. The foliation of the balanced manifold in the parameter space by\ngroup orbits is used to define and compute a Boltzmann entropy. We also show\nthat the Riemannian geometry on the space of observables defined in [2] is\nobtained by Riemannian submersion of the balanced manifold. The main technical\nstep is an explicit construction of an orthonormal basis for the tangent space\nof the balanced manifold using the theory of Jacobi matrices.", "AI": {"tldr": "This paper investigates the Riemannian geometry of Deep Linear Networks as a basis for understanding the learning process using thermodynamics concepts.", "motivation": "To provide a geometric and thermodynamic understanding of deep learning, particularly in overparametrized models.", "method": "Uses group actions, Riemannian submersion, and the foliation of balanced manifolds to derive a Riemannian geometry and compute Boltzmann entropy.", "result": "An orthonormal basis for the tangent space of the balanced manifold is constructed, connecting parameter space and observable space through geometry.", "conclusion": "The use of Riemannian submersion effectively bridges the parameter space and observable space geometry, with implications for thermodynamic interpretations of learning processes."}}
{"id": "2509.09448", "pdf": "https://arxiv.org/pdf/2509.09448", "abs": "https://arxiv.org/abs/2509.09448", "authors": ["Minhyuk Kim", "Seungyoon Lee", "Heuiseok Lim"], "title": "TORSO: Template-Oriented Reasoning Towards General Tasks", "categories": ["cs.AI"], "comment": "9 pages, 3 figures", "summary": "The approaches that guide Large Language Models (LLMs) to emulate human\nreasoning during response generation have emerged as an effective method for\nenabling them to solve complex problems in a step-by-step manner, thereby\nachieving superior performance. However, most existing approaches using\nfew-shot prompts to generate responses heavily depend on the provided examples,\nlimiting the utilization of the model's inherent reasoning capabilities.\nMoreover, constructing task-specific few-shot prompts is often costly and may\nlead to inconsistencies across different tasks. In this work, we introduce\nTemplate-Oriented Reasoning (TORSO), which elicits the model to utilize\ninternal reasoning abilities to generate proper responses across various tasks\nwithout the need for manually crafted few-shot examples. Our experimental\nresults demonstrate that TORSO achieves strong performance on diverse LLMs\nbenchmarks with reasonable rationales.", "AI": {"tldr": "The paper introduces Template-Oriented Reasoning (TORSO), a method enabling LLMs to leverage their internal reasoning capabilities without relying on costly task-specific few-shot prompts.", "motivation": "Current methods for guiding LLM reasoning rely heavily on costly, manually crafted few-shot prompts, which can limit their utility and consistency across tasks.", "method": "TORSO uses templates to elicit internal reasoning capabilities in LLMs, replacing the need for few-shot examples.", "result": "TORSO demonstrated strong performance across diverse benchmarks, enabling LLMs to generate appropriate, rationale-backed responses to varied tasks.", "conclusion": "TORSO is an effective alternative to few-shot prompting, unlocking broader task adaptability and reducing the dependency on manually designed prompts."}}
{"id": "2509.09197", "pdf": "https://arxiv.org/pdf/2509.09197", "abs": "https://arxiv.org/abs/2509.09197", "authors": ["Chin Yuen Kwok", "Jia Qi Yip", "Eng Siong Chng"], "title": "Improving Synthetic Data Training for Contextual Biasing Models with a Keyword-Aware Cost Function", "categories": ["cs.CL", "cs.AI"], "comment": "Published in Interspeech 2025", "summary": "Rare word recognition can be improved by adapting ASR models to synthetic\ndata that includes these words. Further improvements can be achieved through\ncontextual biasing, which trains and adds a biasing module into the model\narchitecture to prioritize rare words. While training the module on synthetic\nrare word data is more effective than using non-rare-word data, it can lead to\noverfitting due to artifacts in the synthetic audio. To address this, we\nenhance the TCPGen-based contextual biasing approach and propose a\nkeyword-aware loss function that additionally focuses on biased words when\ntraining biasing modules. This loss includes a masked cross-entropy term for\nbiased word prediction and a binary classification term for detecting biased\nword positions. These two terms complementarily support the decoding of biased\nwords during inference. By adapting Whisper to 10 hours of synthetic data, our\nmethod reduced the word error rate on the NSC Part 2 test set from 29.71% to\n11.81%.", "AI": {"tldr": "This paper improves rare word recognition in ASR systems by introducing an enhanced TCPGen-based contextual biasing method and a keyword-aware loss function, significantly reducing word error rates.", "motivation": "The motivation is to address the difficulty in recognizing rare words in ASR systems, which are crucial for improving accuracy in specific tasks but often suffer from limitations like overfitting on synthetic data.", "method": "The method involves enhancing the TCPGen-based contextual biasing approach and introducing a keyword-aware loss function. This includes a masked cross-entropy term for rare-word prediction and a binary classification term for position detection.", "result": "The proposed method reduced the word error rate on the NSC Part 2 test set from 29.71% to 11.81%, demonstrating significant improvements.", "conclusion": "The approach effectively mitigates synthetic data overfitting while enhancing rare word recognition, showing the potential for improving ASR models with contextual adaptations."}}
{"id": "2509.09064", "pdf": "https://arxiv.org/pdf/2509.09064", "abs": "https://arxiv.org/abs/2509.09064", "authors": ["Qiuhui Chen", "Xuancheng Yao", "Huping Ye", "Yi Hong"], "title": "Enhancing 3D Medical Image Understanding with Pretraining Aided by 2D Multimodal Large Language Models", "categories": ["cs.CV"], "comment": "Accepted by IEEE Journal of Biomedical and Health Informatics (JBHI)", "summary": "Understanding 3D medical image volumes is critical in the medical field, yet\nexisting 3D medical convolution and transformer-based self-supervised learning\n(SSL) methods often lack deep semantic comprehension. Recent advancements in\nmultimodal large language models (MLLMs) provide a promising approach to\nenhance image understanding through text descriptions. To leverage these 2D\nMLLMs for improved 3D medical image understanding, we propose Med3DInsight, a\nnovel pretraining framework that integrates 3D image encoders with 2D MLLMs via\na specially designed plane-slice-aware transformer module. Additionally, our\nmodel employs a partial optimal transport based alignment, demonstrating\ngreater tolerance to noise introduced by potential noises in LLM-generated\ncontent. Med3DInsight introduces a new paradigm for scalable multimodal 3D\nmedical representation learning without requiring human annotations. Extensive\nexperiments demonstrate our state-of-the-art performance on two downstream\ntasks, i.e., segmentation and classification, across various public datasets\nwith CT and MRI modalities, outperforming current SSL methods. Med3DInsight can\nbe seamlessly integrated into existing 3D medical image understanding networks,\npotentially enhancing their performance. Our source code, generated datasets,\nand pre-trained models will be available at\nhttps://github.com/Qybc/Med3DInsight.", "AI": {"tldr": "Med3DInsight is a novel framework integrating 3D medical image encoders with 2D multimodal large language models, enhancing understanding for medical tasks like segmentation and classification.", "motivation": "Improve semantic comprehension in 3D medical image understanding by leveraging advancements in multimodal large language models.", "method": "Med3DInsight uses a plane-slice-aware transformer module to connect 3D image encoders and 2D MLLMs, with a partial optimal transport alignment to handle noise.", "result": "Demonstrated state-of-the-art performance in segmentation and classification tasks across CT and MRI datasets, outperforming standard methods.", "conclusion": "Med3DInsight offers a scalable, annotation-free framework for multimodal 3D medical image learning, with potential for integration into existing networks and wide availability of resources."}}
{"id": "2509.09613", "pdf": "https://arxiv.org/pdf/2509.09613", "abs": "https://arxiv.org/abs/2509.09613", "authors": ["Taisei Mogi", "Mari Saito", "Yoshihiro Nakata"], "title": "MOFU: Development of a MOrphing Fluffy Unit with Expansion and Contraction Capabilities and Evaluation of the Animacy of Its Movements", "categories": ["cs.RO"], "comment": null, "summary": "Robots for therapy and social interaction are often intended to evoke\n\"animacy\" in humans. While many robots imitate appearance and joint movements,\nlittle attention has been given to whole-body expansion-contraction,\nvolume-changing movements observed in living organisms, and their effect on\nanimacy perception. We developed a mobile robot called \"MOFU (Morphing Fluffy\nUnit),\" capable of whole-body expansion-contraction with a single motor and\ncovered with a fluffy exterior. MOFU employs a \"Jitterbug\" structure, a\ngeometric transformation mechanism that enables smooth volume change in\ndiameter from 210 to 280 mm using one actuator. It is also equipped with a\ndifferential two-wheel drive mechanism for locomotion. To evaluate the effect\nof expansion-contraction movements, we conducted an online survey using videos\nof MOFU's behavior. Participants rated impressions with the Godspeed\nQuestionnaire Series. First, we compared videos of MOFU in a stationary state\nwith and without expansion-contraction and turning, finding that\nexpansion-contraction significantly increased perceived animacy. Second, we\nhypothesized that presenting two MOFUs would increase animacy compared with a\nsingle robot; however, this was not supported, as no significant difference\nemerged. Exploratory analyses further compared four dual-robot motion\nconditions. Third, when expansion-contraction was combined with locomotion,\nanimacy ratings were higher than locomotion alone. These results suggest that\nvolume-changing movements such as expansion and contraction enhance perceived\nanimacy in robots and should be considered an important design element in\nfuture robot development aimed at shaping human impressions.", "AI": {"tldr": "This paper introduces a new robot, MOFU, capable of whole-body expansion-contraction movements, which increase perceived animacy compared to traditional robots. It finds that movement features like volume changes enhance animacy.", "motivation": "Robots for therapy and social interaction aim to evoke animacy, but little attention has been paid to volume-changing movements observed in living organisms and their impact on animacy perception.", "method": "The researchers developed MOFU with volume-changing capability using a \"Jitterbug\" structure for smooth expansion and contraction via a single motor and conducted an online survey to evaluate animacy perception based on MOFU's movements.", "result": "Expansion-contraction movements significantly increased perceived animacy. Combining expansion-contraction with locomotion further improved animacy ratings. No significant animacy difference arose between single and dual robots.", "conclusion": "Design elements like expansion-contraction enhance perceived animacy in robots and should be considered in future robot development to improve human-robot interaction."}}
{"id": "2509.09119", "pdf": "https://arxiv.org/pdf/2509.09119", "abs": "https://arxiv.org/abs/2509.09119", "authors": ["Hao Zhang", "Bo Huang", "Zhenjia Li", "Xi Xiao", "Hui Yi Leong", "Zumeng Zhang", "Xinwei Long", "Tianyang Wang", "Hao Xu"], "title": "Sensitivity-LoRA: Low-Load Sensitivity-Based Fine-Tuning for Large Language Models", "categories": ["cs.LG"], "comment": "15 pages", "summary": "Large Language Models (LLMs) have transformed both everyday life and\nscientific research. However, adapting LLMs from general-purpose models to\nspecialized tasks remains challenging, particularly in resource-constrained\nenvironments. Low-Rank Adaptation (LoRA), a prominent method within\nParameter-Efficient Fine-Tuning (PEFT), has emerged as a promising approach to\nLLMs by approximating model weight updates using low-rank decomposition.\nHowever, LoRA is limited by its uniform rank ( r ) allocation to each\nincremental matrix, and existing rank allocation techniques aimed at addressing\nthis issue remain computationally inefficient, complex, and unstable, hindering\npractical applications. To address these limitations, we propose\nSensitivity-LoRA, an efficient fine-tuning method that dynamically allocates\nranks to weight matrices based on both their global and local sensitivities. It\nleverages the second-order derivatives (Hessian Matrix) of the loss function to\neffectively capture weight sensitivity, enabling optimal rank allocation with\nminimal computational overhead. Our experimental results have demonstrated\nrobust effectiveness, efficiency and stability of Sensitivity-LoRA across\ndiverse tasks and benchmarks.", "AI": {"tldr": "This paper introduces Sensitivity-LoRA, a technique for efficiently fine-tuning large language models (LLMs) by dynamically allocating ranks to weight matrices using sensitivity analysis.", "motivation": "Adapting LLMs to specialized tasks is challenging due to computational constraints and the inefficiency of existing rank allocation techniques in fine-tuning methods like LoRA.", "method": "Sensitivity-LoRA dynamically allocates ranks based on weight sensitivity derived from second-order derivatives, minimizing computational overhead and stabilizing adaptation.", "result": "Experimental results showcase the robustness, efficiency, and stability of Sensitivity-LoRA across a variety of tasks and benchmarks.", "conclusion": "Sensitivity-LoRA provides a significant advancement in parameter-efficient fine-tuning, addressing limitations of previous methods while maintaining practical efficiency and effectiveness."}}
{"id": "2509.09467", "pdf": "https://arxiv.org/pdf/2509.09467", "abs": "https://arxiv.org/abs/2509.09467", "authors": ["Alex Dantart"], "title": "Inteligencia Artificial jur\u00eddica y el desaf\u00edo de la veracidad: an\u00e1lisis de alucinaciones, optimizaci\u00f3n de RAG y principios para una integraci\u00f3n responsable", "categories": ["cs.AI"], "comment": "in Spanish and English languages", "summary": "This technical report analyzes the challenge of \"hallucinations\" (false\ninformation) in LLMs applied to law. It examines their causes, manifestations,\nand the effectiveness of the RAG mitigation strategy, highlighting its\nlimitations and proposing holistic optimizations. The paper explores the\nethical and regulatory implications, emphasizing human oversight as an\nirreplaceable role. It concludes that the solution lies not in incrementally\nimproving generative models, but in adopting a \"consultative\" AI paradigm that\nprioritizes veracity and traceability, acting as a tool to amplify, not\nreplace, professional judgment.\n  --\n  Este informe t\\'ecnico analiza el desaf\\'io de las \"alucinaciones\"\n(informaci\\'on falsa) en los LLMs aplicados al derecho. Se examinan sus causas,\nmanifestaciones y la efectividad de la estrategia de mitigaci\\'on RAG,\nexponiendo sus limitaciones y proponiendo optimizaciones hol\\'isticas. Se\nexploran las implicaciones \\'eticas y regulatorias, enfatizando la\nsupervisi\\'on humana como un rol insustituible. El documento concluye que la\nsoluci\\'on no reside en mejorar incrementalmente los modelos generativos, sino\nen adoptar un paradigma de IA \"consultiva\" que priorice la veracidad y la\ntrazabilidad, actuando como una herramienta para amplificar, y no sustituir, el\njuicio profesional.", "AI": {"tldr": "The report examines the issue of false information or 'hallucinations' in LLMs for law, evaluates mitigation strategies, and advocates for AI systems as tools to support professional judgment rather than replace it.", "motivation": "The motivation is to address the issue of hallucinations in large language models (LLMs) applied to legal contexts, which present significant challenges for reliability, ethical compliance, and professional integrity.", "method": "The paper analyzes hallucination causes, evaluates the RAG mitigation strategy, and proposes holistic optimizations while discussing ethical and regulatory challenges.", "result": "The study finds limitations in RAG as a mitigation strategy, underscores the necessity of human oversight, and highlights the ethical significance of ensuring veracity and traceability in AI outputs.", "conclusion": "The report concludes that improving generative models incrementally is insufficient; the future lies in consultative AI systems designed as tools for enhancing, not replacing, professional decision-making in legal settings."}}
{"id": "2509.09198", "pdf": "https://arxiv.org/pdf/2509.09198", "abs": "https://arxiv.org/abs/2509.09198", "authors": ["Talia Sternberg", "Michael London", "David Omer", "Yossi Adi"], "title": "GmSLM : Generative Marmoset Spoken Language Modeling", "categories": ["cs.CL"], "comment": null, "summary": "Marmoset monkeys exhibit complex vocal communication, challenging the view\nthat nonhuman primates vocal communication is entirely innate, and show similar\nfeatures of human speech, such as vocal labeling of others and turn-taking.\nStudying their vocal communication offers a unique opportunity to link it with\nbrain activity-especially given the difficulty of accessing the human brain in\nspeech and language research. Since Marmosets communicate primarily through\nvocalizations, applying standard LLM approaches is not straightforward. We\nintroduce Generative Marmoset Spoken Language Modeling (GmSLM), an optimized\nspoken language model pipeline for Marmoset vocal communication. We designed a\nnovel zero-shot evaluation metrics using unsupervised in-the-wild data,\nalongside weakly labeled conversational data, to assess GmSLM and demonstrate\nits advantage over a basic human-speech-based baseline. GmSLM generated\nvocalizations closely matched real resynthesized samples acoustically and\nperformed well on downstream tasks. Despite being fully unsupervised, GmSLM\neffectively distinguish real from artificial conversations and may support\nfurther investigations of the neural basis of vocal communication and provides\na practical framework linking vocalization and brain activity. We believe GmSLM\nstands to benefit future work in neuroscience, bioacoustics, and evolutionary\nbiology. Samples are provided under: pages.cs.huji.ac.il/adiyoss-lab/GmSLM.", "AI": {"tldr": "The paper introduces GmSLM, a language model for studying vocal communication in Marmoset monkeys. It performs well on vocal generation and analysis tasks despite being unsupervised.", "motivation": "The paper aims to explore marmoset monkeys' vocal communication, which resembles human-like speech features, to better understand the neural basis of vocal interactions, something difficult to study in humans.", "method": "A novel spoken language model pipeline (GmSLM) is designed, incorporating unsupervised evaluation metrics using wild data and weakly labeled conversational data.", "result": "GmSLM demonstrated acoustically accurate vocal generation, effective performance in distinguishing real vs. artificial conversations, and relevance for downstream tasks.", "conclusion": "GmSLM offers a powerful framework for linking marmosets' vocalizations with brain activity and has cross-disciplinary applications in neuroscience, bioacoustics, and evolutionary biology."}}
{"id": "2509.09067", "pdf": "https://arxiv.org/pdf/2509.09067", "abs": "https://arxiv.org/abs/2509.09067", "authors": ["Hesham M. Shehata", "Mohammad Abdolrahmani"], "title": "Improvement of Human-Object Interaction Action Recognition Using Scene Information and Multi-Task Learning Approach", "categories": ["cs.CV"], "comment": null, "summary": "Recent graph convolutional neural networks (GCNs) have shown high performance\nin the field of human action recognition by using human skeleton poses.\nHowever, it fails to detect human-object interaction cases successfully due to\nthe lack of effective representation of the scene information and appropriate\nlearning architectures. In this context, we propose a methodology to utilize\nhuman action recognition performance by considering fixed object information in\nthe environment and following a multi-task learning approach. In order to\nevaluate the proposed method, we collected real data from public environments\nand prepared our data set, which includes interaction classes of hands-on fixed\nobjects (e.g., ATM ticketing machines, check-in/out machines, etc.) and\nnon-interaction classes of walking and standing. The multi-task learning\napproach, along with interaction area information, succeeds in recognizing the\nstudied interaction and non-interaction actions with an accuracy of 99.25%,\noutperforming the accuracy of the base model using only human skeleton poses by\n2.75%.", "AI": {"tldr": "The paper presents a multi-task learning approach to improve human action recognition, particularly for human-object interactions, achieving 99.25% accuracy.", "motivation": "Recent GCNs struggle to detect human-object interactions due to inadequate representation of scene information and learning architectures.", "method": "Proposed a multi-task learning methodology incorporating fixed object information and interaction area data for better action recognition.", "result": "Achieved 99.25% accuracy in recognizing interactions and non-interactions, surpassing baseline accuracy by 2.75%.", "conclusion": "The multi-task approach enhances action recognition involving fixed objects, proving to be more effective than conventional methods."}}
{"id": "2509.09671", "pdf": "https://arxiv.org/pdf/2509.09671", "abs": "https://arxiv.org/abs/2509.09671", "authors": ["Sirui Xu", "Yu-Wei Chao", "Liuyu Bian", "Arsalan Mousavian", "Yu-Xiong Wang", "Liang-Yan Gui", "Wei Yang"], "title": "Dexplore: Scalable Neural Control for Dexterous Manipulation from Reference-Scoped Exploration", "categories": ["cs.RO", "cs.CV"], "comment": "CoRL 2025", "summary": "Hand-object motion-capture (MoCap) repositories offer large-scale,\ncontact-rich demonstrations and hold promise for scaling dexterous robotic\nmanipulation. Yet demonstration inaccuracies and embodiment gaps between human\nand robot hands limit the straightforward use of these data. Existing methods\nadopt a three-stage workflow, including retargeting, tracking, and residual\ncorrection, which often leaves demonstrations underused and compound errors\nacross stages. We introduce Dexplore, a unified single-loop optimization that\njointly performs retargeting and tracking to learn robot control policies\ndirectly from MoCap at scale. Rather than treating demonstrations as ground\ntruth, we use them as soft guidance. From raw trajectories, we derive adaptive\nspatial scopes, and train with reinforcement learning to keep the policy\nin-scope while minimizing control effort and accomplishing the task. This\nunified formulation preserves demonstration intent, enables robot-specific\nstrategies to emerge, improves robustness to noise, and scales to large\ndemonstration corpora. We distill the scaled tracking policy into a\nvision-based, skill-conditioned generative controller that encodes diverse\nmanipulation skills in a rich latent representation, supporting generalization\nacross objects and real-world deployment. Taken together, these contributions\nposition Dexplore as a principled bridge that transforms imperfect\ndemonstrations into effective training signals for dexterous manipulation.", "AI": {"tldr": "The paper introduces Dexplore, a unified framework that optimizes robot control policies directly from large-scale motion-capture data, addressing inaccuracies and embodiment gaps in traditional approaches.", "motivation": "To overcome the limitations of using motion-capture data for robot manipulation due to inaccuracies and embodiment differences between human and robot hands.", "method": "A single-loop optimization framework that unifies retargeting and tracking to train robot policies using reinforcement learning, leveraging adaptive spatial scopes derived from raw demonstration trajectories.", "result": "Dexplore improves noise robustness, scales effectively to large datasets, and generates a skill-conditioned controller with diverse manipulation strategies that generalize across objects for real-world applications.", "conclusion": "Dexplore effectively transforms imperfect human demonstrations into valuable training signals for dexterous robotic manipulation, supporting scalable and robust robotic strategies."}}
{"id": "2509.09128", "pdf": "https://arxiv.org/pdf/2509.09128", "abs": "https://arxiv.org/abs/2509.09128", "authors": ["Emam Hossain", "Md Osman Gani"], "title": "Learning What Matters: Causal Time Series Modeling for Arctic Sea Ice Prediction", "categories": ["cs.LG"], "comment": "Accepted and presented at the AI4TS Workshop @ IJCAI 2025\n  (non-archival)", "summary": "Conventional machine learning and deep learning models typically rely on\ncorrelation-based learning, which often fails to distinguish genuine causal\nrelationships from spurious associations, limiting their robustness,\ninterpretability, and ability to generalize. To overcome these limitations, we\nintroduce a causality-aware deep learning framework that integrates\nMultivariate Granger Causality (MVGC) and PCMCI+ for causal feature selection\nwithin a hybrid neural architecture. Leveraging 43 years (1979-2021) of Arctic\nSea Ice Extent (SIE) data and associated ocean-atmospheric variables at daily\nand monthly resolutions, the proposed method identifies causally influential\npredictors, prioritizes direct causes of SIE dynamics, reduces unnecessary\nfeatures, and enhances computational efficiency. Experimental results show that\nincorporating causal inputs leads to improved prediction accuracy and\ninterpretability across varying lead times. While demonstrated on Arctic SIE\nforecasting, the framework is broadly applicable to other dynamic,\nhigh-dimensional domains, offering a scalable approach that advances both the\ntheoretical foundations and practical performance of causality-informed\npredictive modeling.", "AI": {"tldr": "The paper presents a deep learning framework using causal inference techniques to enhance the robustness and interpretability of predictions, applied to Arctic sea ice forecasting.", "motivation": "Correlations in typical machine learning models struggle to distinguish real causative factors from spurious ones, compromising robustness, interpretability, and generalizability.", "method": "The framework integrates MVGC and PCMCI+ for selecting causal features, employing a hybrid neural architecture to identify and prioritize direct causal influences using 43 years of Arctic sea ice data.", "result": "The use of causal inputs improves prediction accuracy, interpretability, and reduces computational load across different forecasting lead times.", "conclusion": "The causality-aware framework proves broadly applicable beyond Arctic forecasting, offering scalable improvements to predictive modeling in dynamic, high-dimensional domains."}}
{"id": "2509.09498", "pdf": "https://arxiv.org/pdf/2509.09498", "abs": "https://arxiv.org/abs/2509.09498", "authors": ["Haoran Xu", "Jiacong Hu", "Ke Zhang", "Lei Yu", "Yuxin Tang", "Xinyuan Song", "Yiqun Duan", "Lynn Ai", "Bill Shi"], "title": "SEDM: Scalable Self-Evolving Distributed Memory for Agents", "categories": ["cs.AI"], "comment": null, "summary": "Long-term multi-agent systems inevitably generate vast amounts of\ntrajectories and historical interactions, which makes efficient memory\nmanagement essential for both performance and scalability. Existing methods\ntypically depend on vector retrieval and hierarchical storage, yet they are\nprone to noise accumulation, uncontrolled memory expansion, and limited\ngeneralization across domains. To address these challenges, we present SEDM,\nSelf-Evolving Distributed Memory, a verifiable and adaptive framework that\ntransforms memory from a passive repository into an active, self-optimizing\ncomponent. SEDM integrates verifiable write admission based on reproducible\nreplay, a self-scheduling memory controller that dynamically ranks and\nconsolidates entries according to empirical utility, and cross-domain knowledge\ndiffusion that abstracts reusable insights to support transfer across\nheterogeneous tasks. Evaluations on benchmark datasets demonstrate that SEDM\nimproves reasoning accuracy while reducing token overhead compared with strong\nmemory baselines, and further enables knowledge distilled from fact\nverification to enhance multi-hop reasoning. The results highlight SEDM as a\nscalable and sustainable memory mechanism for open-ended multi-agent\ncollaboration. The code will be released in the later stage of this project.", "AI": {"tldr": "SEDM proposes a new memory management system for long-term multi-agent systems to improve scalability and performance by addressing noise, memory expansion, and cross-domain generalization.", "motivation": "The paper aims to address issues in existing memory systems for multi-agent systems, which struggle with scalability, utility across domains, and noise accumulation.", "method": "SEDM incorporates verifiable write admission, a dynamic memory controller for optimizing entries, and cross-domain knowledge diffusion for reusable insights.", "result": "Evaluations show that SEDM enhances reasoning accuracy and reduces token overhead while facilitating knowledge transfer across tasks.", "conclusion": "SEDM represents a scalable, sustainable solution for memory management in multi-agent systems, enabling efficient collaboration and reasoning across domains."}}
{"id": "2509.09199", "pdf": "https://arxiv.org/pdf/2509.09199", "abs": "https://arxiv.org/abs/2509.09199", "authors": ["Wenhao Li", "Bangcheng Sun", "Weihao Ye", "Tianyi Zhang", "Daohai Yu", "Fei Chao", "Rongrong Ji"], "title": "CCF: A Context Compression Framework for Efficient Long-Sequence Language Modeling", "categories": ["cs.CL"], "comment": null, "summary": "Scaling language models to longer contexts is essential for capturing rich\ndependencies across extended discourse. However, na\\\"ive context extension\nimposes significant computational and memory burdens, often resulting in\ninefficiencies during both training and inference. In this work, we propose\nCCF, a novel context compression framework designed to enable efficient\nlong-context modeling by learning hierarchical latent representations that\npreserve global semantics while aggressively reducing input redundancy. CCF\nintegrates segment-wise semantic aggregation with key-value memory encoding,\nforming compact representations that support accurate reconstruction and\nlong-range understanding. To further enhance scalability, we introduce a\ntraining-efficient optimization strategy that couples incremental segment\ndecoding with sparse reservoir sampling, substantially reducing memory overhead\nwithout degrading performance. Empirical results on multiple long-context\nlanguage modeling benchmarks demonstrate that CCF achieves competitive\nperplexity under high compression ratios, and significantly improves throughput\nand memory efficiency compared to existing approaches. These findings highlight\nthe potential of structured compression for scalable and effective long-context\nlanguage modeling.", "AI": {"tldr": "The researchers propose a method (CCF) to efficiently model long-context language data by compressing input while maintaining semantic integrity.", "motivation": "The motivation behind this work is to address the computational and memory inefficiencies posed by scaling language models to handle longer contexts, which are needed for richer discourse analysis.", "method": "The method combines segment-wise semantic aggregation with memory encoding to create compact, yet semantically-rich, hierarchical representations. It includes a specific training strategy involving incremental decoding and sparse sampling for efficiency.", "result": "Experiments on benchmarks showed that the method achieves competitive perplexity under high compression and improves throughput and memory usage over other approaches.", "conclusion": "CCF is an effective and scalable solution for modeling long-context dependencies in language tasks."}}
{"id": "2509.09085", "pdf": "https://arxiv.org/pdf/2509.09085", "abs": "https://arxiv.org/abs/2509.09085", "authors": ["Jifeng Shen", "Haibo Zhan", "Xin Zuo", "Heng Fan", "Xiaohui Yuan", "Jun Li", "Wankou Yang"], "title": "IRDFusion: Iterative Relation-Map Difference guided Feature Fusion for Multispectral Object Detection", "categories": ["cs.CV"], "comment": "31 pages,6 pages, submitted on 3 Sep,2025", "summary": "Current multispectral object detection methods often retain extraneous\nbackground or noise during feature fusion, limiting perceptual performance.To\naddress this, we propose an innovative feature fusion framework based on\ncross-modal feature contrastive and screening strategy, diverging from\nconventional approaches. The proposed method adaptively enhances salient\nstructures by fusing object-aware complementary cross-modal features while\nsuppressing shared background interference.Our solution centers on two novel,\nspecially designed modules: the Mutual Feature Refinement Module (MFRM) and the\nDifferential Feature Feedback Module (DFFM). The MFRM enhances intra- and\ninter-modal feature representations by modeling their relationships, thereby\nimproving cross-modal alignment and discriminative power.Inspired by feedback\ndifferential amplifiers, the DFFM dynamically computes inter-modal differential\nfeatures as guidance signals and feeds them back to the MFRM, enabling adaptive\nfusion of complementary information while suppressing common-mode noise across\nmodalities. To enable robust feature learning, the MFRM and DFFM are integrated\ninto a unified framework, which is formally formulated as an Iterative\nRelation-Map Differential Guided Feature Fusion mechanism, termed IRDFusion.\nIRDFusion enables high-quality cross-modal fusion by progressively amplifying\nsalient relational signals through iterative feedback, while suppressing\nfeature noise, leading to significant performance gains.In extensive\nexperiments on FLIR, LLVIP and M$^3$FD datasets, IRDFusion achieves\nstate-of-the-art performance and consistently outperforms existing methods\nacross diverse challenging scenarios, demonstrating its robustness and\neffectiveness. Code will be available at\nhttps://github.com/61s61min/IRDFusion.git.", "AI": {"tldr": "The paper introduces IRDFusion, a framework for enhanced multispectral object detection using cross-modal feature fusion strategies to improve perceptual performance while suppressing noise.", "motivation": "Current multispectral object detection methods struggle with retaining background noise during feature fusion, which affects detection accuracy and perceptual performance.", "method": "The paper proposes IRDFusion, which incorporates Mutual Feature Refinement Module (MFRM) and Differential Feature Feedback Module (DFFM). These modules enable adaptive cross-modal feature enhancement and suppression of shared noise, modeled via iterative relation maps.", "result": "IRDFusion demonstrated state-of-the-art performance on FLIR, LLVIP, and M$^3$FD datasets, consistently outperforming existing methods and showcasing robustness across various scenarios.", "conclusion": "The integrated mechanisms within IRDFusion amplify salient signals while reducing noise, delivering significantly enhanced cross-modal object detection accuracy and reliability."}}
{"id": "2509.09674", "pdf": "https://arxiv.org/pdf/2509.09674", "abs": "https://arxiv.org/abs/2509.09674", "authors": ["Haozhan Li", "Yuxin Zuo", "Jiale Yu", "Yuhao Zhang", "Zhaohui Yang", "Kaiyan Zhang", "Xuekai Zhu", "Yuchen Zhang", "Tianxing Chen", "Ganqu Cui", "Dehui Wang", "Dingxiang Luo", "Yuchen Fan", "Youbang Sun", "Jia Zeng", "Jiangmiao Pang", "Shanghang Zhang", "Yu Wang", "Yao Mu", "Bowen Zhou", "Ning Ding"], "title": "SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Vision-Language-Action (VLA) models have recently emerged as a powerful\nparadigm for robotic manipulation. Despite substantial progress enabled by\nlarge-scale pretraining and supervised fine-tuning (SFT), these models face two\nfundamental challenges: (i) the scarcity and high cost of large-scale\nhuman-operated robotic trajectories required for SFT scaling, and (ii) limited\ngeneralization to tasks involving distribution shift. Recent breakthroughs in\nLarge Reasoning Models (LRMs) demonstrate that reinforcement learning (RL) can\ndramatically enhance step-by-step reasoning capabilities, raising a natural\nquestion: Can RL similarly improve the long-horizon step-by-step action\nplanning of VLA? In this work, we introduce SimpleVLA-RL, an efficient RL\nframework tailored for VLA models. Building upon veRL, we introduce\nVLA-specific trajectory sampling, scalable parallelization, multi-environment\nrendering, and optimized loss computation. When applied to OpenVLA-OFT,\nSimpleVLA-RL achieves SoTA performance on LIBERO and even outperforms $\\pi_0$\non RoboTwin 1.0\\&2.0 with the exploration-enhancing strategies we introduce.\nSimpleVLA-RL not only reduces dependence on large-scale data and enables robust\ngeneralization, but also remarkably surpasses SFT in real-world tasks.\nMoreover, we identify a novel phenomenon ``pushcut'' during RL training,\nwherein the policy discovers previously unseen patterns beyond those seen in\nthe previous training process. Github: https://github.com/PRIME-RL/SimpleVLA-RL", "AI": {"tldr": "This paper introduces SimpleVLA-RL, an RL framework for Vision-Language-Action (VLA) models, which improves long-horizon action planning and generalization while reducing reliance on large-scale human-operated datasets.", "motivation": "The scarcity and high cost of human-operated robotic trajectories for supervised fine-tuning and the need to address limited generalization of VLA models in tasks involving distribution shifts.", "method": "The authors propose SimpleVLA-RL, an RL framework with features like VLA-specific trajectory sampling, scalable parallelization, multi-environment rendering, and optimized loss computation.", "result": "SimpleVLA-RL achieves state-of-the-art performance on LIBERO, outperforms baseline $\\pi_0$ on RoboTwin 1.0 & 2.0, and enhances exploration strategies. It also discovers previously unseen patterns through a phenomenon called \"pushcut.\"", "conclusion": "SimpleVLA-RL demonstrates significant advantages over traditional supervised fine-tuning, enabling robust generalization and more effective long-horizon action planning for VLA models."}}
{"id": "2509.09135", "pdf": "https://arxiv.org/pdf/2509.09135", "abs": "https://arxiv.org/abs/2509.09135", "authors": ["Xuefeng Wang", "Lei Zhang", "Henglin Pu", "Ahmed H. Qureshi", "Husheng Li"], "title": "Continuous-Time Value Iteration for Multi-Agent Reinforcement Learning", "categories": ["cs.LG", "cs.MA"], "comment": "19 pages, 10 figures", "summary": "Existing reinforcement learning (RL) methods struggle with complex dynamical\nsystems that demand interactions at high frequencies or irregular time\nintervals. Continuous-time RL (CTRL) has emerged as a promising alternative by\nreplacing discrete-time Bellman recursion with differential value functions\ndefined as viscosity solutions of the Hamilton--Jacobi--Bellman (HJB) equation.\nWhile CTRL has shown promise, its applications have been largely limited to the\nsingle-agent domain. This limitation stems from two key challenges: (i)\nconventional solution methods for HJB equations suffer from the curse of\ndimensionality (CoD), making them intractable in high-dimensional systems; and\n(ii) even with HJB-based learning approaches, accurately approximating\ncentralized value functions in multi-agent settings remains difficult, which in\nturn destabilizes policy training. In this paper, we propose a CT-MARL\nframework that uses physics-informed neural networks (PINNs) to approximate\nHJB-based value functions at scale. To ensure the value is consistent with its\ndifferential structure, we align value learning with value-gradient learning by\nintroducing a Value Gradient Iteration (VGI) module that iteratively refines\nvalue gradients along trajectories. This improves gradient fidelity, in turn\nyielding more accurate values and stronger policy learning. We evaluate our\nmethod using continuous-time variants of standard benchmarks, including\nmulti-agent particle environment (MPE) and multi-agent MuJoCo. Our results\ndemonstrate that our approach consistently outperforms existing continuous-time\nRL baselines and scales to complex multi-agent dynamics.", "AI": {"tldr": "The paper introduces CT-MARL, a continuous-time multi-agent RL framework using physics-informed neural networks to overcome challenges in high-dimensional systems and destabilized policy training.", "motivation": "To address the limitations of continuous-time RL applications in multi-agent scenarios, particularly the issues of dimensionality and policy instability.", "method": "Introduce the CT-MARL framework, leveraging PINNs for scalable HJB-based value function approximation and a Value Gradient Iteration module for refining value gradients.", "result": "CT-MARL outperforms existing continuous-time RL baselines in benchmarks like MPE and MuJoCo, showcasing scalability and improved policy learning.", "conclusion": "CT-MARL effectively extends CTRL methods to multi-agent systems, offering improved scalability and accuracy in continuous-time dynamics."}}
{"id": "2509.09541", "pdf": "https://arxiv.org/pdf/2509.09541", "abs": "https://arxiv.org/abs/2509.09541", "authors": ["Hala Hawashin", "Mina Abbaszadeh", "Nicholas Joseph", "Beth Pearson", "Martha Lewis", "Mehrnoosh sadrzadeh"], "title": "Compositional Concept Generalization with Variational Quantum Circuits", "categories": ["cs.AI"], "comment": "Accepted to: 2025 IEEE International Conference on Quantum Artificial\n  Intelligence (QAI), Naples, Italy, Nov 2-5, 2025. This is the authors'\n  accepted manuscript (AAM). An IEEE copyright notice appears on page 1. The\n  final published version will appear in IEEE Xplore; DOI to be added when\n  available", "summary": "Compositional generalization is a key facet of human cognition, but lacking\nin current AI tools such as vision-language models. Previous work examined\nwhether a compositional tensor-based sentence semantics can overcome the\nchallenge, but led to negative results. We conjecture that the increased\ntraining efficiency of quantum models will improve performance in these tasks.\nWe interpret the representations of compositional tensor-based models in\nHilbert spaces and train Variational Quantum Circuits to learn these\nrepresentations on an image captioning task requiring compositional\ngeneralization. We used two image encoding techniques: a multi-hot encoding\n(MHE) on binary image vectors and an angle/amplitude encoding on image vectors\ntaken from the vision-language model CLIP. We achieve good proof-of-concept\nresults using noisy MHE encodings. Performance on CLIP image vectors was more\nmixed, but still outperformed classical compositional models.", "AI": {"tldr": "The paper explores quantum models to address compositional generalization in image captioning tasks, achieving better performance than classical models in some cases.", "motivation": "To address the lack of compositional generalization in vision-language models by leveraging the training efficiency of quantum models.", "method": "The authors trained Variational Quantum Circuits to interpret compositional tensor-based model representations in Hilbert spaces for an image captioning task, using two image encoding techniques: multi-hot encoding (MHE) and angle/amplitude encoding with CLIP vectors.", "result": "The approach achieved proof-of-concept results using noisy MHE encodings and mixed but improved performance over classical models with CLIP image vectors.", "conclusion": "Quantum models show potential for advancing compositional generalization in AI, particularly in tasks like image captioning, though performance may vary with encoding techniques."}}
{"id": "2509.09229", "pdf": "https://arxiv.org/pdf/2509.09229", "abs": "https://arxiv.org/abs/2509.09229", "authors": ["Matan Cohen", "Shira Shani", "Eden Menahem", "Yehudit Aperstein", "Alexander Apartsin"], "title": "Reading Between the Lines: Classifying Resume Seniority with Large Language Models", "categories": ["cs.CL"], "comment": "5 pages, 3 figures", "summary": "Accurately assessing candidate seniority from resumes is a critical yet\nchallenging task, complicated by the prevalence of overstated experience and\nambiguous self-presentation. In this study, we investigate the effectiveness of\nlarge language models (LLMs), including fine-tuned BERT architectures, for\nautomating seniority classification in resumes. To rigorously evaluate model\nperformance, we introduce a hybrid dataset comprising both real-world resumes\nand synthetically generated hard examples designed to simulate exaggerated\nqualifications and understated seniority. Using the dataset, we evaluate the\nperformance of Large Language Models in detecting subtle linguistic cues\nassociated with seniority inflation and implicit expertise. Our findings\nhighlight promising directions for enhancing AI-driven candidate evaluation\nsystems and mitigating bias introduced by self-promotional language. The\ndataset is available for the research community at https://bit.ly/4mcTovt", "AI": {"tldr": "The study examines the capability of large language models (LLMs), especially fine-tuned BERT architectures, to classify candidate seniority from resumes, tackling challenges of overstated and ambiguous qualifications.", "motivation": "The motivation is to improve automated seniority classification from resumes, addressing issues of inflated qualifications and ambiguous self-presentations.", "method": "The method involves using LLMs, including fine-tuned BERT models, applied on a hybrid dataset of real-world resumes and synthetically manipulated examples to detect subtle linguistic cues.", "result": "The study demonstrates that LLMs perform well in detecting exaggerated or understated seniority, providing useful insights into AI-based candidate evaluation.", "conclusion": "LLMs can significantly enhance automated candidate evaluation and mitigate bias introduced by self-promotional or overstated resume content. The dataset is shared for community use."}}
{"id": "2509.09090", "pdf": "https://arxiv.org/pdf/2509.09090", "abs": "https://arxiv.org/abs/2509.09090", "authors": ["Hengyu Fang", "Yijiang Liu", "Yuan Du", "Li Du", "Huanrui Yang"], "title": "SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models", "categories": ["cs.CV", "cs.AI"], "comment": "12 pages, 9 figures", "summary": "Vision-Language-Action (VLA) models exhibit unprecedented capabilities for\nembodied intelligence. However, their extensive computational and memory costs\nhinder their practical deployment. Existing VLA compression and acceleration\napproaches conduct quantization or token pruning in an ad-hoc manner but fail\nto enable both for a holistic efficiency improvement due to an observed\nincompatibility. This work introduces SQAP-VLA, the first structured,\ntraining-free VLA inference acceleration framework that simultaneously enables\nstate-of-the-art quantization and token pruning. We overcome the\nincompatibility by co-designing the quantization and token pruning pipeline,\nwhere we propose new quantization-aware token pruning criteria that work on an\naggressively quantized model while improving the quantizer design to enhance\npruning effectiveness. When applied to standard VLA models, SQAP-VLA yields\nsignificant gains in computational efficiency and inference speed while\nsuccessfully preserving core model performance, achieving a $\\times$1.93\nspeedup and up to a 4.5\\% average success rate enhancement compared to the\noriginal model.", "AI": {"tldr": "SQAP-VLA is a novel framework that efficiently accelerates Vision-Language-Action models by combining quantization and token pruning for better performance and efficiency.", "motivation": "To address the computational and memory challenges in deploying Vision-Language-Action models while improving their efficiency and speed without compromising performance.", "method": "The authors co-designed a framework that integrates new quantization-aware token pruning criteria with enhanced quantizer design, enabling compatibility between aggressive quantization and token pruning.", "result": "SQAP-VLA resulted in a 1.93\u00d7 inference speedup and up to a 4.5% average success rate improvement compared to standard VLA models.", "conclusion": "SQAP-VLA demonstrates the potential for structured, training-free optimization techniques to balance efficiency and performance in Vision-Language-Action models, setting a new standard for model acceleration frameworks."}}
{"id": "2509.09146", "pdf": "https://arxiv.org/pdf/2509.09146", "abs": "https://arxiv.org/abs/2509.09146", "authors": ["Md Ibrahim Ibne Alam", "Ankur Senapati", "Anindo Mahmood", "Murat Yuksel", "Koushik Kar"], "title": "Peering Partner Recommendation for ISPs using Machine Learning", "categories": ["cs.LG"], "comment": "Submitted to IEEE Transactions on Machine Learning in Communications\n  and Networking", "summary": "Internet service providers (ISPs) need to connect with other ISPs to provide\nglobal connectivity services to their users. To ensure global connectivity,\nISPs can either use transit service(s) or establish direct peering\nrelationships between themselves via Internet exchange points (IXPs). Peering\noffers more room for ISP-specific optimizations and is preferred, but it often\ninvolves a lengthy and complex process. Automating peering partner selection\ncan enhance efficiency in the global Internet ecosystem. We explore the use of\npublicly available data on ISPs to develop a machine learning (ML) model that\ncan predict whether an ISP pair should peer or not. At first, we explore public\ndatabases, e.g., PeeringDB, CAIDA, etc., to gather data on ISPs. Then, we\nevaluate the performance of three broad types of ML models for predicting\npeering relationships: tree-based, neural network-based, and transformer-based.\nAmong these, we observe that tree-based models achieve the highest accuracy and\nefficiency in our experiments. The XGBoost model trained with publicly\navailable data showed promising performance, with a 98% accuracy rate in\npredicting peering partners. In addition, the model demonstrated great\nresilience to variations in time, space, and missing data. We envision that\nISPs can adopt our method to fully automate the peering partner selection\nprocess, thus transitioning to a more efficient and optimized Internet\necosystem.", "AI": {"tldr": "The paper proposes machine learning models to automate peering partner selection using publicly available ISP data, achieving 98% accuracy with tree-based models.", "motivation": "To enhance efficiency and optimize ISP operations by automating the complex and lengthy peering partner selection process.", "method": "Public data from platforms like PeeringDB and CAIDA were utilized to train different machine learning models\u2014tree-based, neural network-based, and transformer-based. Tree-based models were found most effective.", "result": "The XGBoost model showed 98% accuracy in predicting peering partners and exhibited resiliency to variations in data.", "conclusion": "ISPs can use the proposed automated approach to streamline the selection of peering partners, leading to a more efficient global Internet ecosystem."}}
{"id": "2509.09560", "pdf": "https://arxiv.org/pdf/2509.09560", "abs": "https://arxiv.org/abs/2509.09560", "authors": ["Shulai Zhang", "Ao Xu", "Quan Chen", "Han Zhao", "Weihao Cui", "Ningxin Zheng", "Haibin Lin", "Xin Liu", "Minyi Guo"], "title": "Boosting Embodied AI Agents through Perception-Generation Disaggregation and Asynchronous Pipeline Execution", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Embodied AI systems operate in dynamic environments, requiring seamless\nintegration of perception and generation modules to process high-frequency\ninput and output demands. Traditional sequential computation patterns, while\neffective in ensuring accuracy, face significant limitations in achieving the\nnecessary \"thinking\" frequency for real-world applications. In this work, we\npresent Auras, an algorithm-system co-designed inference framework to optimize\nthe inference frequency of embodied AI agents. Auras disaggregates the\nperception and generation and provides controlled pipeline parallelism for them\nto achieve high and stable throughput. Faced with the data staleness problem\nthat appears when the parallelism is increased, Auras establishes a public\ncontext for perception and generation to share, thereby promising the accuracy\nof embodied agents. Experimental results show that Auras improves throughput by\n2.54x on average while achieving 102.7% of the original accuracy, demonstrating\nits efficacy in overcoming the constraints of sequential computation and\nproviding high throughput.", "AI": {"tldr": "The paper discusses Auras, a novel inference framework aimed at optimizing the computational efficiency of embodied AI agents for real-world tasks.", "motivation": "Embodied AI needs to operate effectively in dynamic environments, but traditional computation methods struggle to meet the required frequency for real-time operation.", "method": "The study introduces Auras, which uses pipeline parallelism and a shared public context for perception and generation modules to improve throughput while maintaining accuracy.", "result": "Auras increased throughput by 2.54 times on average and preserved the original accuracy (102.7%).", "conclusion": "Auras effectively balances processing speed and accuracy, offering a robust solution for advancing embodied AI systems."}}
{"id": "2509.09234", "pdf": "https://arxiv.org/pdf/2509.09234", "abs": "https://arxiv.org/abs/2509.09234", "authors": ["Rishit Tyagi", "Mohit Gupta", "Rahul Bouri"], "title": "Agentic LLMs for Question Answering over Tabular Data", "categories": ["cs.CL"], "comment": "Accepted at ACL workshop SemEval 2025", "summary": "Question Answering over Tabular Data (Table QA) presents unique challenges\ndue to the diverse structure, size, and data types of real-world tables. The\nSemEval 2025 Task 8 (DataBench) introduced a benchmark composed of large-scale,\ndomain-diverse datasets to evaluate the ability of models to accurately answer\nstructured queries. We propose a Natural Language to SQL (NL-to-SQL) approach\nleveraging large language models (LLMs) such as GPT-4o, GPT-4o-mini, and\nDeepSeek v2:16b to generate SQL queries dynamically. Our system follows a\nmulti-stage pipeline involving example selection, SQL query generation, answer\nextraction, verification, and iterative refinement. Experiments demonstrate the\neffectiveness of our approach, achieving 70.5\\% accuracy on DataBench QA and\n71.6\\% on DataBench Lite QA, significantly surpassing baseline scores of 26\\%\nand 27\\% respectively. This paper details our methodology, experimental\nresults, and alternative approaches, providing insights into the strengths and\nlimitations of LLM-driven Table QA.", "AI": {"tldr": "The paper proposes a Natural Language to SQL (NL-to-SQL) approach using large language models for Question Answering over tabular data, achieving significant accuracy improvements over baseline methods.", "motivation": "Challenges in Table QA arise from the diverse structure and data types of real-world tables, prompting the development of effective evaluation benchmarks.", "method": "A multi-stage pipeline leveraging large language models to generate SQL queries dynamically, including steps like example selection, query generation, answer extraction, verification, and refinement.", "result": "Achieved 70.5% accuracy on DataBench QA and 71.6% on DataBench Lite QA, which are much higher than the baseline scores of 26% and 27% respectively.", "conclusion": "The approach proves to be highly effective in improving table QA performance, showcasing the strengths and limitations of large language models for this domain."}}
{"id": "2509.09110", "pdf": "https://arxiv.org/pdf/2509.09110", "abs": "https://arxiv.org/abs/2509.09110", "authors": ["Chenghao Zhang", "Lun Luo", "Si-Yuan Cao", "Xiaokai Bai", "Yuncheng Jin", "Zhu Yu", "Beinan Yu", "Yisen Wang", "Hui-Liang Shen"], "title": "S-BEVLoc: BEV-based Self-supervised Framework for Large-scale LiDAR Global Localization", "categories": ["cs.CV"], "comment": null, "summary": "LiDAR-based global localization is an essential component of simultaneous\nlocalization and mapping (SLAM), which helps loop closure and re-localization.\nCurrent approaches rely on ground-truth poses obtained from GPS or SLAM\nodometry to supervise network training. Despite the great success of these\nsupervised approaches, substantial cost and effort are required for\nhigh-precision ground-truth pose acquisition. In this work, we propose\nS-BEVLoc, a novel self-supervised framework based on bird's-eye view (BEV) for\nLiDAR global localization, which eliminates the need for ground-truth poses and\nis highly scalable. We construct training triplets from single BEV images by\nleveraging the known geographic distances between keypoint-centered BEV\npatches. Convolutional neural network (CNN) is used to extract local features,\nand NetVLAD is employed to aggregate global descriptors. Moreover, we introduce\nSoftCos loss to enhance learning from the generated triplets. Experimental\nresults on the large-scale KITTI and NCLT datasets show that S-BEVLoc achieves\nstate-of-the-art performance in place recognition, loop closure, and global\nlocalization tasks, while offering scalability that would require extra effort\nfor supervised approaches.", "AI": {"tldr": "This paper presents a self-supervised framework, S-BEVLoc, for LiDAR global localization using bird's-eye view (BEV) images without requiring ground-truth poses.", "motivation": "High-precision ground-truth pose acquisition for training LiDAR-based global localization models is costly and labor-intensive.", "method": "S-BEVLoc uses BEV image triplets based on geographic distances, CNN for feature extraction, NetVLAD for global descriptor aggregation, and SoftCos loss for triplet learning.", "result": "S-BEVLoc achieves state-of-the-art performance in place recognition, loop closure, and global localization across the KITTI and NCLT datasets.", "conclusion": "S-BEVLoc provides scalable, accurate LiDAR localization without relying on ground-truth poses, outperforming supervised approaches."}}
{"id": "2509.09155", "pdf": "https://arxiv.org/pdf/2509.09155", "abs": "https://arxiv.org/abs/2509.09155", "authors": ["Maria Risques", "Kratika Bhagtani", "Amit Kumar Singh Yadav", "Edward J. Delp"], "title": "HISPASpoof: A New Dataset For Spanish Speech Forensics", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages, 1 figure, 10 tables, being submitted to ICASSP 2026 (IEEE\n  International Conference on Acoustics, Speech, and Signal Processing 2026)", "summary": "Zero-shot Voice Cloning (VC) and Text-to-Speech (TTS) methods have advanced\nrapidly, enabling the generation of highly realistic synthetic speech and\nraising serious concerns about their misuse. While numerous detectors have been\ndeveloped for English and Chinese, Spanish-spoken by over 600 million people\nworldwide-remains underrepresented in speech forensics. To address this gap, we\nintroduce HISPASpoof, the first large-scale Spanish dataset designed for\nsynthetic speech detection and attribution. It includes real speech from public\ncorpora across six accents and synthetic speech generated with six zero-shot\nTTS systems. We evaluate five representative methods, showing that detectors\ntrained on English fail to generalize to Spanish, while training on HISPASpoof\nsubstantially improves detection. We also evaluate synthetic speech attribution\nperformance on HISPASpoof, i.e., identifying the generation method of synthetic\nspeech. HISPASpoof thus provides a critical benchmark for advancing reliable\nand inclusive speech forensics in Spanish.", "AI": {"tldr": "This paper introduces HISPASpoof, a large-scale dataset for detecting and attributing synthetic Spanish speech, addressing the gap in speech forensics for non-English languages.", "motivation": "Despite advancements in detecting synthetic speech in English and Chinese, Spanish\u2014a major global language\u2014lacks sufficient forensic tools for synthetic speech detection.", "method": "Created HISPASpoof, a dataset combining real Spanish speech (with different accents) and synthetic speech generated using six zero-shot TTS systems. Evaluated five detection methods, comparing performance for synthetic speech detection and attribution.", "result": "General findings show English-trained detectors fail in Spanish application. However, training on HISPASpoof significantly enhances synthetic speech detection and generation method attribution in Spanish.", "conclusion": "HISPASpoof bridges a critical gap in speech forensics, ensuring inclusivity for Spanish and advancing the reliability of detection and attribution systems for synthetic speech."}}
{"id": "2509.09677", "pdf": "https://arxiv.org/pdf/2509.09677", "abs": "https://arxiv.org/abs/2509.09677", "authors": ["Akshit Sinha", "Arvindh Arun", "Shashwat Goel", "Steffen Staab", "Jonas Geiping"], "title": "The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs", "categories": ["cs.AI"], "comment": null, "summary": "Does continued scaling of large language models (LLMs) yield diminishing\nreturns? Real-world value often stems from the length of task an agent can\ncomplete. We start this work by observing the simple but counterintuitive fact\nthat marginal gains in single-step accuracy can compound into exponential\nimprovements in the length of a task a model can successfully complete. Then,\nwe argue that failures of LLMs when simple tasks are made longer arise from\nmistakes in execution, rather than an inability to reason. We propose isolating\nexecution capability, by explicitly providing the knowledge and plan needed to\nsolve a long-horizon task. We find that larger models can correctly execute\nsignificantly more turns even when small models have 100\\% single-turn\naccuracy. We observe that the per-step accuracy of models degrades as the\nnumber of steps increases. This is not just due to long-context limitations --\ncuriously, we observe a self-conditioning effect -- models become more likely\nto make mistakes when the context contains their errors from prior turns.\nSelf-conditioning does not reduce by just scaling the model size. In contrast,\nrecent thinking models do not self-condition, and can also execute much longer\ntasks in a single turn. We conclude by benchmarking frontier thinking models on\nthe length of task they can execute in a single turn. Overall, by focusing on\nthe ability to execute, we hope to reconcile debates on how LLMs can solve\ncomplex reasoning problems yet fail at simple tasks when made longer, and\nhighlight the massive benefits of scaling model size and sequential test-time\ncompute for long-horizon tasks.", "AI": {"tldr": "The study examines the performance of large language models (LLMs) in long-horizon tasks, finding that their execution capability diminishes with increasing task length due to errors compounding, even if reasoning capability remains intact.", "motivation": "To understand whether scaling up LLMs can effectively address the challenge of completing long-horizon tasks, and to investigate why LLMs struggle with even simple tasks when extended over multiple steps.", "method": "The authors isolate execution capability by providing explicit knowledge and plans for long tasks, measure the relationship between model size and execution performance, and analyze context degradation effects (self-conditioning). They also benchmark thinking models on task length execution.", "result": "Larger LLMs are more successful in long-horizon tasks compared to smaller ones, but struggle with compounded execution errors over multiple steps. Notably, self-conditioning (errors feeding onto themselves) occurs regardless of model size, whereas recent thinking models do not suffer from this issue.", "conclusion": "Execution capability, not reasoning inability, is the limiting factor in LLMs' long-horizon task performance. Scaling model size and improving sequential test-time compute can yield substantial benefits despite intrinsic constraints like self-conditioning."}}
{"id": "2509.09303", "pdf": "https://arxiv.org/pdf/2509.09303", "abs": "https://arxiv.org/abs/2509.09303", "authors": ["Grazia Sveva Ascione", "Nicol\u00f2 Tamagnone"], "title": "From scratch to silver: Creating trustworthy training data for patent-SDG classification using Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Classifying patents by their relevance to the UN Sustainable Development\nGoals (SDGs) is crucial for tracking how innovation addresses global\nchallenges. However, the absence of a large, labeled dataset limits the use of\nsupervised learning. Existing methods, such as keyword searches, transfer\nlearning, and citation-based heuristics, lack scalability and generalizability.\nThis paper frames patent-to-SDG classification as a weak supervision problem,\nusing citations from patents to SDG-tagged scientific publications (NPL\ncitations) as a noisy initial signal. To address its sparsity and noise, we\ndevelop a composite labeling function (LF) that uses large language models\n(LLMs) to extract structured concepts, namely functions, solutions, and\napplications, from patents and SDG papers based on a patent ontology.\nCross-domain similarity scores are computed and combined using a rank-based\nretrieval approach. The LF is calibrated via a custom positive-only loss that\naligns with known NPL-SDG links without penalizing discovery of new SDG\nassociations. The result is a silver-standard, soft multi-label dataset mapping\npatents to SDGs, enabling the training of effective multi-label regression\nmodels. We validate our approach through two complementary strategies: (1)\ninternal validation against held-out NPL-based labels, where our method\noutperforms several baselines including transformer-based models, and zero-shot\nLLM; and (2) external validation using network modularity in patent citation,\nco-inventor, and co-applicant graphs, where our labels reveal greater thematic,\ncognitive, and organizational coherence than traditional technological\nclassifications. These results show that weak supervision and semantic\nalignment can enhance SDG classification at scale.", "AI": {"tldr": "This paper proposes a weak supervision method leveraging large language models (LLMs) to classify patents by their relevance to UN Sustainable Development Goals (SDGs), overcoming challenges like lack of labeled datasets and scalability of traditional methods.", "motivation": "To address the absence of large labeled datasets for patent-to-SDG classification and improve scalability and generalizability of existing methods like keyword searches and citation-based heuristics.", "method": "The approach uses noisy signals from patent citations to SDG-tagged publications, employing large language models to extract structured concepts and compute cross-domain similarity scores via a composite labeling function. A rank-based retrieval approach and custom positive-only loss are applied to create a soft multi-label dataset.", "result": "The method outperforms baselines in internal validations and demonstrates thematic, cognitive, and organizational coherence in external validations, showcasing its effectiveness in creating scalable SDG classifications.", "conclusion": "Weak supervision and semantic alignment, powered by large language models, provide an effective and scalable method for SDG-related patent classification, offering improved generalizability and utility compared to traditional approaches."}}
{"id": "2509.09111", "pdf": "https://arxiv.org/pdf/2509.09111", "abs": "https://arxiv.org/abs/2509.09111", "authors": ["Jianqin Gao", "Tianqi Wang", "Yu Zhang", "Yishu Zhang", "Chenyuan Wang", "Allan Dong", "Zihao Wang"], "title": "FPI-Det: a face--phone Interaction Dataset for phone-use detection and understanding", "categories": ["cs.CV"], "comment": null, "summary": "The widespread use of mobile devices has created new challenges for vision\nsystems in safety monitoring, workplace productivity assessment, and attention\nmanagement. Detecting whether a person is using a phone requires not only\nobject recognition but also an understanding of behavioral context, which\ninvolves reasoning about the relationship between faces, hands, and devices\nunder diverse conditions. Existing generic benchmarks do not fully capture such\nfine-grained human--device interactions. To address this gap, we introduce the\nFPI-Det, containing 22{,}879 images with synchronized annotations for faces and\nphones across workplace, education, transportation, and public scenarios. The\ndataset features extreme scale variation, frequent occlusions, and varied\ncapture conditions. We evaluate representative YOLO and DETR detectors,\nproviding baseline results and an analysis of performance across object sizes,\nocclusion levels, and environments. Source code and dataset is available at\nhttps://github.com/KvCgRv/FPI-Det.", "AI": {"tldr": "The paper introduces FPI-Det, a dataset for detecting human-mobile device interactions under diverse conditions, to address limitations in existing benchmarks.", "motivation": "Mobile device usage poses challenges for vision systems in contexts like safety monitoring and productivity, requiring fine-grained analysis of human-device interactions.", "method": "FPI-Det dataset includes 22,879 annotated images across various scenarios, evaluating models like YOLO and DETR for performance on factors such as occlusion and scale variation.", "result": "Baseline performance of YOLO and DETR detectors is evaluated, highlighting the impact of object size, occlusion, and environment on detection.", "conclusion": "FPI-Det fills a gap in fine-grained human-device interaction detection, and its annotations enable advancements in vision systems for diverse scenarios."}}
{"id": "2509.09297", "pdf": "https://arxiv.org/pdf/2509.09297", "abs": "https://arxiv.org/abs/2509.09297", "authors": ["Spyridon Loukovitis", "Anastasios Arsenos", "Vasileios Karampinis", "Athanasios Voulodimos"], "title": "Model-Agnostic Open-Set Air-to-Air Visual Object Detection for Reliable UAV Perception", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "Open-set detection is crucial for robust UAV autonomy in air-to-air object\ndetection under real-world conditions. Traditional closed-set detectors degrade\nsignificantly under domain shifts and flight data corruption, posing risks to\nsafety-critical applications. We propose a novel, model-agnostic open-set\ndetection framework designed specifically for embedding-based detectors. The\nmethod explicitly handles unknown object rejection while maintaining robustness\nagainst corrupted flight data. It estimates semantic uncertainty via entropy\nmodeling in the embedding space and incorporates spectral normalization and\ntemperature scaling to enhance open-set discrimination. We validate our\napproach on the challenging AOT aerial benchmark and through extensive\nreal-world flight tests. Comprehensive ablation studies demonstrate consistent\nimprovements over baseline methods, achieving up to a 10\\% relative AUROC gain\ncompared to standard YOLO-based detectors. Additionally, we show that\nbackground rejection further strengthens robustness without compromising\ndetection accuracy, making our solution particularly well-suited for reliable\nUAV perception in dynamic air-to-air environments.", "AI": {"tldr": "The paper introduces an open-set detection framework for UAV object detection under real-world conditions, combating domain shifts and corrupted data.", "motivation": "UAV autonomy faces risks in safety-critical scenarios due to performance degradation of closed-set detectors under domain shifts and flight data corruption.", "method": "The approach models semantic uncertainty using entropy in the embedding space, integrates spectral normalization, and applies temperature scaling for better open-set detection.", "result": "The method achieved up to a 10% AUROC improvement on aerial benchmarks and consistently outperformed baselines in real-world tests.", "conclusion": "The framework enhances open-set detection robustness and suitability for UAV applications in dynamic air-to-air conditions, balancing robustness and accuracy."}}
{"id": "2509.09168", "pdf": "https://arxiv.org/pdf/2509.09168", "abs": "https://arxiv.org/abs/2509.09168", "authors": ["Omar Erak", "Omar Alhussein", "Hatem Abou-Zeid", "Mehdi Bennis"], "title": "Adaptive Pareto-Optimal Token Merging for Edge Transformer Models in Semantic Communication", "categories": ["cs.LG", "cs.AI", "cs.CV", "eess.IV"], "comment": "To appear in IEEE Globecom 2025", "summary": "Large-scale transformer models have emerged as a powerful tool for semantic\ncommunication systems, enabling edge devices to extract rich representations\nfor robust inference across noisy wireless channels. However, their substantial\ncomputational demands remain a major barrier to practical deployment in\nresource-constrained 6G networks. In this paper, we present a training-free\nframework for adaptive token merging in pretrained vision transformers to\njointly reduce inference time and transmission resource usage. We formulate the\nselection of per-layer merging proportions as a multi-objective optimization\nproblem to balance accuracy and computational cost. We employ Gaussian\nprocess-based Bayesian optimization to construct a Pareto frontier of optimal\nconfigurations, enabling flexible runtime adaptation to dynamic application\nrequirements and channel conditions. Extensive experiments demonstrate that our\nmethod consistently outperforms other baselines and achieves significant\nreductions in floating-point operations while maintaining competitive accuracy\nacross a wide range of signal-to-noise ratio (SNR) conditions. Additional\nresults highlight the effectiveness of adaptive policies that adjust merging\naggressiveness in response to channel quality, providing a practical mechanism\nto trade off latency and semantic fidelity on demand. These findings establish\na scalable and efficient approach for deploying transformer-based semantic\ncommunication in future edge intelligence systems.", "AI": {"tldr": "This paper introduces a training-free framework for adaptive token merging in pretrained vision transformers to enhance efficiency and performance in resource-constrained 6G networks.", "motivation": "There is a need to overcome the computational barriers of deploying large-scale transformer models in constrained 6G networks for semantic communication systems.", "method": "A multi-objective optimization problem is formulated using Bayesian optimization to adaptively reduce token merging, optimizing for both accuracy and computational cost.", "result": "The method reduces floating-point operations while maintaining competitive accuracy even across varying SNR conditions, outperforming other baseline methods.", "conclusion": "An efficient and scalable approach is provided for deploying transformer-based semantic communication systems, allowing adaptive merging in response to channel conditions, ensuring practical and dynamic applications in edge intelligence."}}
{"id": "2509.08829", "pdf": "https://arxiv.org/pdf/2509.08829", "abs": "https://arxiv.org/abs/2509.08829", "authors": ["Chandan Kumar Sah"], "title": "PerFairX: Is There a Balance Between Fairness and Personality in Large Language Model Recommendations?", "categories": ["cs.CY", "cs.AI", "cs.IR"], "comment": "10 pages, 5 figures. Accepted to the Workshop on Multimodal Continual\n  Learning (MCL) at ICCV 2025. @2025 IEEE/CVF International Conference on\n  Computer Vision Workshops (ICCVW), ICCV's 2025", "summary": "The integration of Large Language Models (LLMs) into recommender systems has\nenabled zero-shot, personality-based personalization through prompt-based\ninteractions, offering a new paradigm for user-centric recommendations.\nHowever, incorporating user personality traits via the OCEAN model highlights a\ncritical tension between achieving psychological alignment and ensuring\ndemographic fairness. To address this, we propose PerFairX, a unified\nevaluation framework designed to quantify the trade-offs between\npersonalization and demographic equity in LLM-generated recommendations. Using\nneutral and personality-sensitive prompts across diverse user profiles, we\nbenchmark two state-of-the-art LLMs, ChatGPT and DeepSeek, on movie (MovieLens\n10M) and music (Last.fm 360K) datasets. Our results reveal that\npersonality-aware prompting significantly improves alignment with individual\ntraits but can exacerbate fairness disparities across demographic groups.\nSpecifically, DeepSeek achieves stronger psychological fit but exhibits higher\nsensitivity to prompt variations, while ChatGPT delivers stable yet less\npersonalized outputs. PerFairX provides a principled benchmark to guide the\ndevelopment of LLM-based recommender systems that are both equitable and\npsychologically informed, contributing to the creation of inclusive,\nuser-centric AI applications in continual learning contexts.", "AI": {"tldr": "This paper introduces PerFairX, a framework to measure trade-offs between personalization and demographic fairness in recommender systems with LLMs.", "motivation": "To address the challenge of balancing psychological alignment through personality traits and demographic fairness in LLM-based recommender systems.", "method": "Developed PerFairX framework to evaluate zero-shot personality-based personalization and fairness, benchmarking ChatGPT and DeepSeek using neutral and personality-sensitive prompts on movie and music datasets.", "result": "DeepSeek achieves better psychological alignment but is more sensitive to prompts, while ChatGPT provides stable but less personalized recommendations.", "conclusion": "PerFairX offers a benchmark to aid in designing equitable and psychologically aware LLM-based recommender systems for inclusive user-centric applications."}}
{"id": "2509.09360", "pdf": "https://arxiv.org/pdf/2509.09360", "abs": "https://arxiv.org/abs/2509.09360", "authors": ["Channdeth Sok", "David Luz", "Yacine Haddam"], "title": "MetaRAG: Metamorphic Testing for Hallucination Detection in RAG Systems", "categories": ["cs.CL"], "comment": "under review", "summary": "Large Language Models (LLMs) are increasingly deployed in enterprise\napplications, yet their reliability remains limited by hallucinations, i.e.,\nconfident but factually incorrect information. Existing detection approaches,\nsuch as SelfCheckGPT and MetaQA, primarily target standalone LLMs and do not\naddress the unique challenges of Retrieval-Augmented Generation (RAG) systems,\nwhere responses must be consistent with retrieved evidence. We therefore\npresent MetaRAG, a metamorphic testing framework for hallucination detection in\nRetrieval-Augmented Generation (RAG) systems. MetaRAG operates in a real-time,\nunsupervised, black-box setting, requiring neither ground-truth references nor\naccess to model internals, making it suitable for proprietary and high-stakes\ndomains. The framework proceeds in four stages: (1) decompose answers into\natomic factoids, (2) generate controlled mutations of each factoid using\nsynonym and antonym substitutions, (3) verify each variant against the\nretrieved context (synonyms are expected to be entailed and antonyms\ncontradicted), and (4) aggregate penalties for inconsistencies into a\nresponse-level hallucination score. Crucially for identity-aware AI, MetaRAG\nlocalizes unsupported claims at the factoid span where they occur (e.g.,\npregnancy-specific precautions, LGBTQ+ refugee rights, or labor eligibility),\nallowing users to see flagged spans and enabling system designers to configure\nthresholds and guardrails for identity-sensitive queries. Experiments on a\nproprietary enterprise dataset illustrate the effectiveness of MetaRAG for\ndetecting hallucinations and enabling trustworthy deployment of RAG-based\nconversational agents. We also outline a topic-based deployment design that\ntranslates MetaRAG's span-level scores into identity-aware safeguards; this\ndesign is discussed but not evaluated in our experiments.", "AI": {"tldr": "The paper introduces MetaRAG, a framework to detect hallucinations in Retrieval-Augmented Generation (RAG) systems. It works unsupervised and without model access, targeting unsupported claims at a granular level for real-time use.", "motivation": "To address the challenge of hallucinations in Retrieval-Augmented Generation (RAG) systems, which require generated responses to align with retrieved evidence.", "method": "MetaRAG uses a four-stage framework: decompose responses into atomic factoids, mutate them using synonyms/antonyms, verify variants against the retrieved context, and aggregate inconsistencies into a hallucination score.", "result": "MetaRAG effectively detects hallucinations in a proprietary enterprise dataset and allows users to pinpoint unsupported claims at a granular factoid span level.", "conclusion": "MetaRAG enhances trustworthiness of RAG systems by providing real-time hallucination detection and tailoring identity-aware safeguards for sensitive information."}}
{"id": "2509.09116", "pdf": "https://arxiv.org/pdf/2509.09116", "abs": "https://arxiv.org/abs/2509.09116", "authors": ["Junhao Xing", "Ryohei Miyakawa", "Yang Yang", "Xinpeng Liu", "Risa Shinoda", "Hiroaki Santo", "Yosuke Toda", "Fumio Okura"], "title": "Zero-shot Hierarchical Plant Segmentation via Foundation Segmentation Models and Text-to-image Attention", "categories": ["cs.CV"], "comment": "WACV 2026 accepted", "summary": "Foundation segmentation models achieve reasonable leaf instance extraction\nfrom top-view crop images without training (i.e., zero-shot). However,\nsegmenting entire plant individuals with each consisting of multiple\noverlapping leaves remains challenging. This problem is referred to as a\nhierarchical segmentation task, typically requiring annotated training\ndatasets, which are often species-specific and require notable human labor. To\naddress this, we introduce ZeroPlantSeg, a zero-shot segmentation for\nrosette-shaped plant individuals from top-view images. We integrate a\nfoundation segmentation model, extracting leaf instances, and a vision-language\nmodel, reasoning about plants' structures to extract plant individuals without\nadditional training. Evaluations on datasets with multiple plant species,\ngrowth stages, and shooting environments demonstrate that our method surpasses\nexisting zero-shot methods and achieves better cross-domain performance than\nsupervised methods. Implementations are available at\nhttps://github.com/JunhaoXing/ZeroPlantSeg.", "AI": {"tldr": "Introduces ZeroPlantSeg, a zero-shot segmentation system for rosette-shaped plant individuals, leveraging foundational segmentation and vision-language models.", "motivation": "To overcome the challenge of hierarchical segmentation for plant individuals, specifically to eliminate the need for species-specific annotation and reduce human labor.", "method": "ZeroPlantSeg combines foundational segmentation models for leaf instance extraction with vision-language models to identify and segment entire plant individuals without training.", "result": "Outperformed existing zero-shot methods and showed better cross-domain performance compared to supervised methods, tested across various datasets with different plant species and growth stages.", "conclusion": "ZeroPlantSeg is effective for rosette-shaped plant segmentation, offering superior performance in zero-shot scenarios and is accessible for further use via open implementations."}}
{"id": "2509.09349", "pdf": "https://arxiv.org/pdf/2509.09349", "abs": "https://arxiv.org/abs/2509.09349", "authors": ["Ian Nell", "Shane Gilroy"], "title": "Classification of Driver Behaviour Using External Observation Techniques for Autonomous Vehicles", "categories": ["cs.CV", "cs.AI", "cs.ET", "cs.RO", "eess.IV"], "comment": null, "summary": "Road traffic accidents remain a significant global concern, with human error,\nparticularly distracted and impaired driving, among the leading causes. This\nstudy introduces a novel driver behavior classification system that uses\nexternal observation techniques to detect indicators of distraction and\nimpairment. The proposed framework employs advanced computer vision\nmethodologies, including real-time object tracking, lateral displacement\nanalysis, and lane position monitoring. The system identifies unsafe driving\nbehaviors such as excessive lateral movement and erratic trajectory patterns by\nimplementing the YOLO object detection model and custom lane estimation\nalgorithms. Unlike systems reliant on inter-vehicular communication, this\nvision-based approach enables behavioral analysis of non-connected vehicles.\nExperimental evaluations on diverse video datasets demonstrate the framework's\nreliability and adaptability across varying road and environmental conditions.", "AI": {"tldr": "The paper introduces an external observation-based system using computer vision to detect distracted/impaired driving behaviors, employing YOLO object detection and custom algorithms for real-time analysis.", "motivation": "To address the persistent issue of road traffic accidents caused by human error, particularly distractions and impairments, by providing a method that works even for non-connected vehicles.", "method": "The study utilizes computer vision techniques including YOLO object detection, real-time object tracking, lateral displacement analysis, and lane position monitoring to classify driver behavior.", "result": "Experimental evaluations confirmed the system's reliability and adaptability across diverse video datasets under various road and environmental conditions.", "conclusion": "The proposed vision-based system successfully identifies unsafe driving behaviors and offers a viable alternative to inter-vehicular communication for behavioral analysis."}}
{"id": "2509.09176", "pdf": "https://arxiv.org/pdf/2509.09176", "abs": "https://arxiv.org/abs/2509.09176", "authors": ["Jun-Hao Chen", "Yu-Chien Huang", "Yun-Cheng Tsai", "Samuel Yen-Chi Chen"], "title": "Quantum Machine Learning, Quantitative Trading, Reinforcement Learning, Deep Learning", "categories": ["cs.LG", "cs.CY"], "comment": null, "summary": "The convergence of quantum-inspired neural networks and deep reinforcement\nlearning offers a promising avenue for financial trading. We implemented a\ntrading agent for USD/TWD by integrating Quantum Long Short-Term Memory (QLSTM)\nfor short-term trend prediction with Quantum Asynchronous Advantage\nActor-Critic (QA3C), a quantum-enhanced variant of the classical A3C. Trained\non data from 2000-01-01 to 2025-04-30 (80\\% training, 20\\% testing), the\nlong-only agent achieves 11.87\\% return over around 5 years with 0.92\\% max\ndrawdown, outperforming several currency ETFs. We detail state design (QLSTM\nfeatures and indicators), reward function for trend-following/risk control, and\nmulti-core training. Results show hybrid models yield competitive FX trading\nperformance. Implications include QLSTM's effectiveness for small-profit trades\nwith tight risk and future enhancements. Key hyperparameters: QLSTM sequence\nlength$=$4, QA3C workers$=$8. Limitations: classical quantum simulation and\nsimplified strategy. \\footnote{The views expressed in this article are those of\nthe authors and do not represent the views of Wells Fargo. This article is for\ninformational purposes only. Nothing contained in this article should be\nconstrued as investment advice. Wells Fargo makes no express or implied\nwarranties and expressly disclaims all legal, tax, and accounting implications\nrelated to this article.", "AI": {"tldr": "This paper explores the fusion of quantum-inspired neural networks and deep reinforcement learning for financial trading, delivering improved performance through quantum-enhanced methods.", "motivation": "To enhance financial trading efficiency using quantum-inspired neural networks and deep reinforcement learning approaches specifically targeting the USD/TWD currency pair.", "method": "They implemented Quantum Long Short-Term Memory (QLSTM) for short-term trend prediction and Quantum Asynchronous Advantage Actor-Critic (QA3C) for reinforcement learning, training data spanning over 25 years.", "result": "The trading agent achieved an 11.87% return over about 5 years, with only a 0.92% maximum drawdown, outperforming several currency ETFs.", "conclusion": "Hybrid models using quantum-inspired techniques demonstrate competitive performance in FX trading, with QLSTM effective for small-profit trades under tight risk controls."}}
{"id": "2509.08835", "pdf": "https://arxiv.org/pdf/2509.08835", "abs": "https://arxiv.org/abs/2509.08835", "authors": ["Vincent C. M\u00fcller"], "title": "Deep opacity and AI: A threat to XAI and to privacy protection mechanisms", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "It is known that big data analytics and AI pose a threat to privacy, and that\nsome of this is due to some kind of \"black box problem\" in AI. I explain how\nthis becomes a problem in the context of justification for judgments and\nactions. Furthermore, I suggest distinguishing three kinds of opacity: 1) the\nsubjects do not know what the system does (\"shallow opacity\"), 2) the analysts\ndo not know what the system does (\"standard black box opacity\"), or 3) the\nanalysts cannot possibly know what the system might do (\"deep opacity\"). If the\nagents, data subjects as well as analytics experts, operate under opacity, then\nthese agents cannot provide justifications for judgments that are necessary to\nprotect privacy, e.g., they cannot give \"informed consent\", or guarantee\n\"anonymity\". It follows from these points that agents in big data analytics and\nAI often cannot make the judgments needed to protect privacy. So I conclude\nthat big data analytics makes the privacy problems worse and the remedies less\neffective. As a positive note, I provide a brief outlook on technical ways to\nhandle this situation.", "AI": {"tldr": "Big data analytics and AI create privacy issues due to opacity, making it harder to ensure informed consent or anonymity.", "motivation": "The paper aims to address privacy threats posed by opacity in AI and big data systems, where judgments and actions lack proper justification.", "method": "The author differentiates between three types of opacity and analyzes their implications for privacy and informed consent.", "result": "Agents involved in AI and big data cannot adequately justify judgments needed to protect privacy, exacerbating privacy risks.", "conclusion": "Big data analytics worsens privacy problems while technical solutions may offer partial remedies to address opacity issues."}}
{"id": "2509.09381", "pdf": "https://arxiv.org/pdf/2509.09381", "abs": "https://arxiv.org/abs/2509.09381", "authors": ["Molly R Petersen", "Claire E Stevenson", "Lonneke van der Plas"], "title": "Modelling Analogies and Analogical Reasoning: Connecting Cognitive Science Theory and NLP Research", "categories": ["cs.CL"], "comment": null, "summary": "Analogical reasoning is an essential aspect of human cognition. In this\npaper, we summarize key theory about the processes underlying analogical\nreasoning from the cognitive science literature and relate it to current\nresearch in natural language processing. While these processes can be easily\nlinked to concepts in NLP, they are generally not viewed through a cognitive\nlens. Furthermore, we show how these notions are relevant for several major\nchallenges in NLP research, not directly related to analogy solving. This may\nguide researchers to better optimize relational understanding in text, as\nopposed to relying heavily on entity-level similarity.", "AI": {"tldr": "The paper discusses the cognitive processes behind analogical reasoning, linking them to NLP research and showcasing their broader relevance.", "motivation": "The motivation is to bridge the cognitive science theories of analogical reasoning with NLP to improve relational understanding in text.", "method": "The authors summarize theories from cognitive science on analogical reasoning and explore their relevance to NLP challenges.", "result": "It highlights how cognitive perspectives on analogy can address challenges in NLP beyond analogical reasoning tasks.", "conclusion": "Incorporating cognitive insights on analogical reasoning can enhance NLP's focus on relational understanding over entity similarity."}}
{"id": "2509.09118", "pdf": "https://arxiv.org/pdf/2509.09118", "abs": "https://arxiv.org/abs/2509.09118", "authors": ["Tianlu Zheng", "Yifan Zhang", "Xiang An", "Ziyong Feng", "Kaicheng Yang", "Qichuan Ding"], "title": "Gradient-Attention Guided Dual-Masking Synergetic Framework for Robust Text-based Person Retrieval", "categories": ["cs.CV"], "comment": "Accepted by EMNLP2025 Main", "summary": "Although Contrastive Language-Image Pre-training (CLIP) exhibits strong\nperformance across diverse vision tasks, its application to person\nrepresentation learning faces two critical challenges: (i) the scarcity of\nlarge-scale annotated vision-language data focused on person-centric images,\nand (ii) the inherent limitations of global contrastive learning, which\nstruggles to maintain discriminative local features crucial for fine-grained\nmatching while remaining vulnerable to noisy text tokens. This work advances\nCLIP for person representation learning through synergistic improvements in\ndata curation and model architecture. First, we develop a noise-resistant data\nconstruction pipeline that leverages the in-context learning capabilities of\nMLLMs to automatically filter and caption web-sourced images. This yields\nWebPerson, a large-scale dataset of 5M high-quality person-centric image-text\npairs. Second, we introduce the GA-DMS (Gradient-Attention Guided Dual-Masking\nSynergetic) framework, which improves cross-modal alignment by adaptively\nmasking noisy textual tokens based on the gradient-attention similarity score.\nAdditionally, we incorporate masked token prediction objectives that compel the\nmodel to predict informative text tokens, enhancing fine-grained semantic\nrepresentation learning. Extensive experiments show that GA-DMS achieves\nstate-of-the-art performance across multiple benchmarks.", "AI": {"tldr": "This paper tackles challenges in adapting CLIP to person representation learning by proposing improvements in both data curation and model architecture, resulting in state-of-the-art performance.", "motivation": "To address the scarcity of annotated person-centric image-text datasets and the limitations of global contrastive learning in maintaining fine-grained discriminative features for person representation.", "method": "The authors developed a noise-resistant data pipeline yielding the WebPerson dataset from web-sourced images and proposed the GA-DMS framework, which employs adaptive masking and masked token predictions for improved cross-modal alignment.", "result": "Their GA-DMS framework achieved state-of-the-art performance across various person representation benchmarks.", "conclusion": "Enhancing data quality and cross-modal alignment methods can significantly improve person representation learning applications."}}
{"id": "2509.09177", "pdf": "https://arxiv.org/pdf/2509.09177", "abs": "https://arxiv.org/abs/2509.09177", "authors": ["Hanyi Mao", "Quanjia Xiao", "Lei Pang", "Haixiao Liu"], "title": "Clip Your Sequences Fairly: Enforcing Length Fairness for Sequence-Level RL", "categories": ["cs.LG"], "comment": null, "summary": "We propose FSPO (Fair Sequence Policy Optimization), a sequence-level\nreinforcement learning method for LLMs that enforces length-fair clipping\ndirectly in the importance-sampling (IS) weight space. We revisit\nsequence-level RL methods and identify a mismatch when PPO/GRPO-style clipping\nis transplanted to sequences: a fixed clip range systematically reweights short\nvs. long responses, distorting the effective objective. Theoretically, we\nformalize length fairness via a Length Reweighting Error (LRE) and prove that\nsmall LRE yields a directional cosine guarantee between the clipped and true\nupdates. FSPO introduces a simple, Gaussian-motivated remedy: we clip the\nsequence log-IS ratio with a band that applies a KL-corrected drift term and\nscales as $\\sqrt{L}$. Empirically, FSPO flattens clip rates across length bins,\nstabilizes training, and outperforms all baselines across multiple evaluation\ndatasets.", "AI": {"tldr": "FSPO is a sequence-level reinforcement learning method for training large language models, addressing fairness in response lengths by using a novel clipping method based on importance-sampling weights.", "motivation": "To address the mismatch in sequence-level reinforcement learning methods where traditional clipping approaches favor short or long responses unevenly during training of large language models.", "method": "FSPO revisits sequence-level RL techniques and introduces a length-fair clipping mechanism using a Gaussian-inspired adjustment to the importance-sampling weight space, adjusting log-IS ratios with a KL-corrected drift that scales proportionally to sequence length.", "result": "FSPO demonstrates stabilized training, equalized clip rates across varying response lengths, and superior performance compared with baseline methods across diverse evaluation datasets.", "conclusion": "Correcting length-based bias in RL methods for LLM training using FSPO contributes to fairer and more stable optimization processes, producing better results overall."}}
{"id": "2509.09388", "pdf": "https://arxiv.org/pdf/2509.09388", "abs": "https://arxiv.org/abs/2509.09388", "authors": ["Ana Ezquerro", "Carlos G\u00f3mez-Rodr\u00edguez", "David Vilares"], "title": "Hierarchical Bracketing Encodings Work for Dependency Graphs", "categories": ["cs.CL"], "comment": "Accepted at EMNLP 2025 (main)", "summary": "We revisit hierarchical bracketing encodings from a practical perspective in\nthe context of dependency graph parsing. The approach encodes graphs as\nsequences, enabling linear-time parsing with $n$ tagging actions, and still\nrepresenting reentrancies, cycles, and empty nodes. Compared to existing graph\nlinearizations, this representation substantially reduces the label space while\npreserving structural information. We evaluate it on a multilingual and\nmulti-formalism benchmark, showing competitive results and consistent\nimprovements over other methods in exact match accuracy.", "AI": {"tldr": "The paper explores hierarchical bracketing encodings in dependency graph parsing, enabling linear-time parsing while handling complex graph features effectively. Results show improvement over existing methods.", "motivation": "To address the challenges in dependency graph parsing, such as efficiently representing complex graph features like reentrancies, cycles, and empty nodes, while reducing label space.", "method": "Encodes dependency graphs as sequences employing hierarchical bracketing, allowing parsing with $n$ tagging actions while retaining complex structure information.", "result": "Demonstrates competitive results on multilingual and multi-formalism benchmarks, with consistent improvements in exact match accuracy over other methods.", "conclusion": "The hierarchical encoding approach effectively balances efficiency and structural representation, proving to be a promising method for dependency graph parsing."}}
{"id": "2509.09130", "pdf": "https://arxiv.org/pdf/2509.09130", "abs": "https://arxiv.org/abs/2509.09130", "authors": ["Bin Huang", "Kang Chen", "Bingxuan Li", "Huafeng Liu", "Qiegen Liu"], "title": "ALL-PET: A Low-resource and Low-shot PET Foundation Model in the Projection Domain", "categories": ["cs.CV"], "comment": null, "summary": "Building large-scale foundation model for PET imaging is hindered by limited\naccess to labeled data and insufficient computational resources. To overcome\ndata scarcity and efficiency limitations, we propose ALL-PET, a low-resource,\nlow-shot PET foundation model operating directly in the projection domain.\nALL-PET leverages a latent diffusion model (LDM) with three key innovations.\nFirst, we design a Radon mask augmentation strategy (RMAS) that generates over\n200,000 structurally diverse training samples by projecting randomized\nimage-domain masks into sinogram space, significantly improving generalization\nwith minimal data. This is extended by a dynamic multi-mask (DMM) mechanism\nthat varies mask quantity and distribution, enhancing data diversity without\nadded model complexity. Second, we implement positive/negative mask constraints\nto embed strict geometric consistency, reducing parameter burden while\npreserving generation quality. Third, we introduce transparent medical\nattention (TMA), a parameter-free, geometry-driven mechanism that enhances\nlesion-related regions in raw projection data. Lesion-focused attention maps\nare derived from coarse segmentation, covering both hypermetabolic and\nhypometabolic areas, and projected into sinogram space for physically\nconsistent guidance. The system supports clinician-defined ROI adjustments,\nensuring flexible, interpretable, and task-adaptive emphasis aligned with PET\nacquisition physics. Experimental results show ALL-PET achieves high-quality\nsinogram generation using only 500 samples, with performance comparable to\nmodels trained on larger datasets. ALL-PET generalizes across tasks including\nlow-dose reconstruction, attenuation correction, delayed-frame prediction, and\ntracer separation, operating efficiently with memory use under 24GB.", "AI": {"tldr": "The paper introduces ALL-PET, a PET imaging foundation model relying on limited data and low resources, leveraging latent diffusion models and innovative techniques for efficient sinogram generation.", "motivation": "The development of PET imaging models is hindered by limited labeled data and computational constraints, necessitating efficient solutions for enriched generalization and performance.", "method": "The approach uses three key innovations: Radon mask augmentation strategy to create diverse data, positive/negative mask constraints for geometric consistency, and transparent medical attention to enhance focus on lesion-related regions, all while ensuring efficient resource use.", "result": "ALL-PET achieves high-quality sinogram generation using just 500 samples, comparable to models trained on larger datasets, and performs well across multiple PET imaging tasks.", "conclusion": "ALL-PET is a resource-efficient, generalizable PET imaging model employing innovative strategies to overcome data and computational limitations, demonstrating promising performance in diverse applications."}}
{"id": "2509.09584", "pdf": "https://arxiv.org/pdf/2509.09584", "abs": "https://arxiv.org/abs/2509.09584", "authors": ["Lingdong Kong", "Dongyue Lu", "Ao Liang", "Rong Li", "Yuhao Dong", "Tianshuai Hu", "Lai Xing Ng", "Wei Tsang Ooi", "Benoit R. Cottereau"], "title": "Visual Grounding from Event Cameras", "categories": ["cs.CV", "cs.RO"], "comment": "Abstract Paper (Non-Archival) @ ICCV 2025 NeVi Workshop", "summary": "Event cameras capture changes in brightness with microsecond precision and\nremain reliable under motion blur and challenging illumination, offering clear\nadvantages for modeling highly dynamic scenes. Yet, their integration with\nnatural language understanding has received little attention, leaving a gap in\nmultimodal perception. To address this, we introduce Talk2Event, the first\nlarge-scale benchmark for language-driven object grounding using event data.\nBuilt on real-world driving scenarios, Talk2Event comprises 5,567 scenes,\n13,458 annotated objects, and more than 30,000 carefully validated referring\nexpressions. Each expression is enriched with four structured attributes --\nappearance, status, relation to the viewer, and relation to surrounding objects\n-- that explicitly capture spatial, temporal, and relational cues. This\nattribute-centric design supports interpretable and compositional grounding,\nenabling analysis that moves beyond simple object recognition to contextual\nreasoning in dynamic environments. We envision Talk2Event as a foundation for\nadvancing multimodal and temporally-aware perception, with applications\nspanning robotics, human-AI interaction, and so on.", "AI": {"tldr": "Talk2Event is a large-scale benchmark dataset integrating event camera data with natural language for dynamic object grounding tasks.", "motivation": "To bridge the gap in integrating event camera data with natural language understanding, enabling improved multimodal perception.", "method": "The creation of a benchmark dataset (Talk2Event) comprising real-world driving scenes and richly annotated with spatial, temporal, and relational attributes for objects and their surroundings.", "result": "Talk2Event features 5,567 scenes, 13,458 objects, and 30,000 annotated referring expressions, enabling compositional and contextual language-based object reasoning.", "conclusion": "Talk2Event provides a foundation for advancing multimodal perception and contextual understanding in dynamic environments, supporting areas like robotics and human-AI interaction."}}
{"id": "2509.09195", "pdf": "https://arxiv.org/pdf/2509.09195", "abs": "https://arxiv.org/abs/2509.09195", "authors": ["Md Tanveer Hossain Munim"], "title": "Breaking the Statistical Similarity Trap in Extreme Convection Detection", "categories": ["cs.LG", "cs.CV", "68T07, 86A10", "I.2.6; J.2"], "comment": "43 pages, 7 figures", "summary": "Current evaluation metrics for deep learning weather models create a\n\"Statistical Similarity Trap\", rewarding blurry predictions while missing rare,\nhigh-impact events. We provide quantitative evidence of this trap, showing\nsophisticated baselines achieve 97.9% correlation yet 0.00 CSI for dangerous\nconvection detection. We introduce DART (Dual Architecture for Regression\nTasks), a framework addressing the challenge of transforming coarse atmospheric\nforecasts into high-resolution satellite brightness temperature fields\noptimized for extreme convection detection (below 220 K). DART employs\ndual-decoder architecture with explicit background/extreme decomposition,\nphysically motivated oversampling, and task-specific loss functions. We present\nfour key findings: (1) empirical validation of the Statistical Similarity Trap\nacross multiple sophisticated baselines; (2) the \"IVT Paradox\", removing\nIntegrated Water Vapor Transport, widely regarded as essential for atmospheric\nriver analysis, improves extreme convection detection by 270%; (3)\narchitectural necessity demonstrated through operational flexibility (DART\nachieves CSI = 0.273 with bias = 2.52 vs. 6.72 for baselines at equivalent\nCSI), and (4) real-world validation with the August 2023 Chittagong flooding\ndisaster as a case study. To our knowledge, this is the first work to\nsystematically address this hybrid conversion-segmentation-downscaling task,\nwith no direct prior benchmarks identified in existing literature. Our\nvalidation against diverse statistical and deep learning baselines sufficiently\ndemonstrates DART's specialized design. The framework enables precise\noperational calibration through beta-tuning, trains in under 10 minutes on\nstandard hardware, and integrates seamlessly with existing meteorological\nworkflows, demonstrating a pathway toward trustworthy AI for extreme weather\npreparedness.", "AI": {"tldr": "Current metrics overvalue statistical similarity, leading to missing rare weather events. DART introduces methods for high-resolution extreme event prediction.", "motivation": "Address deficiencies in weather prediction metrics that prioritize statistical similarity and overlook high-impact rare weather events.", "method": "Propose a Dual Architecture (DART) using dual-decoder design, extreme event-decomposition, specialized loss functions, and physically motivated oversampling.", "result": "Demonstrates improved prediction accuracy for rare weather events, including better CSI scores and operational flexibility. Real-world validation included.", "conclusion": "DART addresses critical gaps in extreme weather detection, enhances accuracy compared to baselines, and supports streamlined integration into meteorological workflows."}}
{"id": "2509.08852", "pdf": "https://arxiv.org/pdf/2509.08852", "abs": "https://arxiv.org/abs/2509.08852", "authors": ["Kajetan Schweighofer", "Barbara Brune", "Lukas Gruber", "Simon Schmid", "Alexander Aufreiter", "Andreas Gruber", "Thomas Doms", "Sebastian Eder", "Florian Mayer", "Xaver-Paul Stadlbauer", "Christoph Schwald", "Werner Zellinger", "Bernhard Nessler", "Sepp Hochreiter"], "title": "Safe and Certifiable AI Systems: Concepts, Challenges, and Lessons Learned", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "63 pages, 27 figures", "summary": "There is an increasing adoption of artificial intelligence in safety-critical\napplications, yet practical schemes for certifying that AI systems are safe,\nlawful and socially acceptable remain scarce. This white paper presents the\nT\\\"UV AUSTRIA Trusted AI framework an end-to-end audit catalog and methodology\nfor assessing and certifying machine learning systems. The audit catalog has\nbeen in continuous development since 2019 in an ongoing collaboration with\nscientific partners. Building on three pillars - Secure Software Development,\nFunctional Requirements, and Ethics & Data Privacy - the catalog translates the\nhigh-level obligations of the EU AI Act into specific, testable criteria. Its\ncore concept of functional trustworthiness couples a statistically defined\napplication domain with risk-based minimum performance requirements and\nstatistical testing on independently sampled data, providing transparent and\nreproducible evidence of model quality in real-world settings. We provide an\noverview of the functional requirements that we assess, which are oriented on\nthe lifecycle of an AI system. In addition, we share some lessons learned from\nthe practical application of the audit catalog, highlighting common pitfalls we\nencountered, such as data leakage scenarios, inadequate domain definitions,\nneglect of biases, or a lack of distribution drift controls. We further discuss\nkey aspects of certifying AI systems, such as robustness, algorithmic fairness,\nor post-certification requirements, outlining both our current conclusions and\na roadmap for future research. In general, by aligning technical best practices\nwith emerging European standards, the approach offers regulators, providers,\nand users a practical roadmap for legally compliant, functionally trustworthy,\nand certifiable AI systems.", "AI": {"tldr": "The paper introduces the T\u00dcV AUSTRIA Trusted AI framework, an audit methodology to assess AI systems' functional trustworthiness in compliance with the EU AI Act.", "motivation": "There is a growing demand to assess and certify AI systems for safety, legality, and social acceptance, especially in safety-critical applications.", "method": "The paper develops an audit catalog based on three pillars: Secure Software Development, Functional Requirements, and Ethics & Data Privacy. This methodology translates the EU AI Act into specific, testable criteria with a focus on risk-based performance requirements and statistical testing.", "result": "The framework defines transparent criteria for auditing AI systems and highlights pitfalls like data leakage, biased data, and lack of distribution drift controls from practical applications.", "conclusion": "By aligning with EU standards, the framework offers a structured way to ensure AI systems are legally compliant, trustworthy, and certifiable, with future research directions outlined to enhance its utility."}}
{"id": "2509.09438", "pdf": "https://arxiv.org/pdf/2509.09438", "abs": "https://arxiv.org/abs/2509.09438", "authors": ["Zhaohan Zhang", "Ziquan Liu", "Ioannis Patras"], "title": "GrACE: A Generative Approach to Better Confidence Elicitation in Large Language Models", "categories": ["cs.CL"], "comment": "20 pages, 11 figures", "summary": "Assessing the reliability of Large Language Models (LLMs) by confidence\nelicitation is a prominent approach to AI safety in high-stakes applications,\nsuch as healthcare and finance. Existing methods either require expensive\ncomputational overhead or suffer from poor calibration, making them impractical\nand unreliable for real-world deployment. In this work, we propose GrACE, a\nGenerative Approach to Confidence Elicitation that enables scalable and\nreliable confidence elicitation for LLMs. GrACE adopts a novel mechanism in\nwhich the model expresses confidence by the similarity between the last hidden\nstate and the embedding of a special token appended to the vocabulary, in\nreal-time. We fine-tune the model for calibrating the confidence with\ncalibration targets associated with accuracy. Experiments with three LLMs and\ntwo benchmark datasets show that the confidence produced by GrACE achieves the\nbest discriminative capacity and calibration on open-ended generation tasks,\noutperforming six competing methods without resorting to additional sampling or\nan auxiliary model. Moreover, we propose two strategies for improving test-time\nscaling based on confidence induced by GrACE. Experimental results show that\nusing GrACE not only improves the accuracy of the final decision but also\nsignificantly reduces the number of required samples in the test-time scaling\nscheme, indicating the potential of GrACE as a practical solution for deploying\nLLMs with scalable, reliable, and real-time confidence estimation.", "AI": {"tldr": "The paper introduces GrACE, a novel method for generating reliable and scalable confidence estimations for Large Language Models (LLMs), outperforming other methods in calibration and efficiency.", "motivation": "Existing methods for confidence elicitation in LLMs are computationally expensive or poorly calibrated, limiting reliability and viability in real-world applications such as healthcare and finance.", "method": "GrACE introduces a new mechanism where the model expresses confidence based on the similarity between its final hidden state and the embedding of a dedicated token, fine-tuned with calibration targets that relate to accuracy.", "result": "Experiments with three LLMs and two datasets demonstrate that GrACE provides superior calibration and discrimination in open-ended tasks compared to six competing methods. Test-time scaling improves accuracy and reduces sample requirements.", "conclusion": "GrACE is a promising, practical solution for reliable, real-time, and scalable confidence elicitation in LLMs, showing strong potential for practical deployment in high-stakes environments."}}
{"id": "2509.09140", "pdf": "https://arxiv.org/pdf/2509.09140", "abs": "https://arxiv.org/abs/2509.09140", "authors": ["Dylan Peek", "Matthew P. Skerritt", "Stephan Chalup"], "title": "Noise-Robust Topology Estimation of 2D Image Data via Neural Networks and Persistent Homology", "categories": ["cs.CV"], "comment": "12 pages", "summary": "Persistent Homology (PH) and Artificial Neural Networks (ANNs) offer\ncontrasting approaches to inferring topological structure from data. In this\nstudy, we examine the noise robustness of a supervised neural network trained\nto predict Betti numbers in 2D binary images. We compare an ANN approach\nagainst a PH pipeline based on cubical complexes and the Signed Euclidean\nDistance Transform (SEDT), which is a widely adopted strategy for noise-robust\ntopological analysis. Using one synthetic and two real-world datasets, we show\nthat ANNs can outperform this PH approach under noise, likely due to their\ncapacity to learn contextual and geometric priors from training data. Though\nstill emerging, the use of ANNs for topology estimation offers a compelling\nalternative to PH under structural noise.", "AI": {"tldr": "The paper examines the noise robustness of artificial neural networks (ANNs) trained to predict Betti numbers in 2D images, comparing this approach against persistent homology (PH) pipelines, and finds ANNs to be more robust under noise.", "motivation": "To evaluate the efficacy and noise robustness of ANNs in topological analysis compared to traditional persistent homology (PH) techniques, particularly in predicting Betti numbers in 2D images.", "method": "The study trains supervised ANNs to predict Betti numbers in 2D binary images and compares their performance with a PH pipeline using cubical complexes and SEDT across synthetic and real-world datasets.", "result": "ANNs demonstrated better performance than PH pipelines in noisy scenarios, likely owing to their ability to learn contextual and geometric priors.", "conclusion": "ANNs represent a promising alternative to PH techniques for topology estimation, especially under structural noise, due to their adaptability and learning capabilities."}}
{"id": "2509.09208", "pdf": "https://arxiv.org/pdf/2509.09208", "abs": "https://arxiv.org/abs/2509.09208", "authors": ["Somnath Hazra", "Pallab Dasgupta", "Soumyajit Dey"], "title": "Incentivizing Safer Actions in Policy Optimization for Constrained Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, Accepted to the 34th International Joint Conference on\n  Artificial Intelligence (IJCAI) 2025, Main Track", "summary": "Constrained Reinforcement Learning (RL) aims to maximize the return while\nadhering to predefined constraint limits, which represent domain-specific\nsafety requirements. In continuous control settings, where learning agents\ngovern system actions, balancing the trade-off between reward maximization and\nconstraint satisfaction remains a significant challenge. Policy optimization\nmethods often exhibit instability near constraint boundaries, resulting in\nsuboptimal training performance. To address this issue, we introduce a novel\napproach that integrates an adaptive incentive mechanism in addition to the\nreward structure to stay within the constraint bound before approaching the\nconstraint boundary. Building on this insight, we propose Incrementally\nPenalized Proximal Policy Optimization (IP3O), a practical algorithm that\nenforces a progressively increasing penalty to stabilize training dynamics.\nThrough empirical evaluation on benchmark environments, we demonstrate the\nefficacy of IP3O compared to the performance of state-of-the-art Safe RL\nalgorithms. Furthermore, we provide theoretical guarantees by deriving a bound\non the worst-case error of the optimality achieved by our algorithm.", "AI": {"tldr": "The paper presents IP3O, a new reinforcement learning algorithm designed to maintain safety constraints while optimizing performance.", "motivation": "Balancing reward maximization with constraint satisfaction in constrained reinforcement learning is challenging due to instability near constraint boundaries.", "method": "The authors proposed the IP3O algorithm, which uses an adaptive incentive mechanism and incremental penalties to stabilize training near constraints.", "result": "Empirical evaluations show that IP3O outperforms state-of-the-art Safe RL algorithms on benchmark tests.", "conclusion": "IP3O effectively handles trade-offs between performance and safety constraints, supported by strong theoretical guarantees."}}
{"id": "2509.08854", "pdf": "https://arxiv.org/pdf/2509.08854", "abs": "https://arxiv.org/abs/2509.08854", "authors": ["David James Woo", "Kai Guo", "Yangyang Yu"], "title": "A vibe coding learning design to enhance EFL students' talking to, through, and about AI", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": "15 pages, 12 figures", "summary": "This innovative practice article reports on the piloting of vibe coding\n(using natural language to create software applications with AI) for English as\na Foreign Language (EFL) education. We developed a human-AI meta-languaging\nframework with three dimensions: talking to AI (prompt engineering), talking\nthrough AI (negotiating authorship), and talking about AI (mental models of\nAI). Using backward design principles, we created a four-hour workshop where\ntwo students designed applications addressing authentic EFL writing challenges.\nWe adopted a case study methodology, collecting data from worksheets and video\nrecordings, think-aloud protocols, screen recordings, and AI-generated images.\nContrasting cases showed one student successfully vibe coding a functional\napplication cohering to her intended design, while another encountered\ntechnical difficulties with major gaps between intended design and actual\nfunctionality. Analysis reveals differences in students' prompt engineering\napproaches, suggesting different AI mental models and tensions in attributing\nauthorship. We argue that AI functions as a beneficial languaging machine, and\nthat differences in how students talk to, through, and about AI explain vibe\ncoding outcome variations. Findings indicate that effective vibe coding\ninstruction requires explicit meta-languaging scaffolding, teaching structured\nprompt engineering, facilitating critical authorship discussions, and\ndeveloping vocabulary for articulating AI mental models.", "AI": {"tldr": "This paper piloted the use of vibe coding (natural language-based AI programming) for EFL education, revealing the role of meta-languaging in effective AI interaction and coding outcomes.", "motivation": "The study aims to explore teaching methodologies that integrate AI programming (vibe coding) into EFL education to address writing challenges and improve technology-mediated language learning.", "method": "A four-hour workshop was designed using backward principles, where students created applications. Data was collected via worksheets, video recordings, think-aloud protocols, screen recordings, and AI output for a case study analysis.", "result": "One student successfully created a functional application aligning with her design, while the other faced technical issues, highlighting varied outcomes due to differences in prompt engineering and AI mental models.", "conclusion": "Effective vibe coding instruction requires a focus on meta-languaging scaffolding, structured prompt engineering guidance, fostering discussions on authorship, and enhancing understanding of AI mental models."}}
{"id": "2509.09473", "pdf": "https://arxiv.org/pdf/2509.09473", "abs": "https://arxiv.org/abs/2509.09473", "authors": ["Lucie Pol\u00e1kov\u00e1", "Martin Popel", "V\u011bra Kloudov\u00e1", "Michal Nov\u00e1k", "Mariia Anisimova", "Ji\u0159\u00ed Balhar"], "title": "Mitigating Language Barriers in Education: Developing Multilingual Digital Learning Materials with Machine Translation", "categories": ["cs.CL"], "comment": "8 pages, 2 figures", "summary": "The EdUKate project combines digital education, linguistics, translation\nstudies, and machine translation to develop multilingual learning materials for\nCzech primary and secondary schools. Launched through collaboration between a\nmajor Czech academic institution and the country's largest educational\npublisher, the project is aimed at translating up to 9,000 multimodal\ninteractive exercises from Czech into Ukrainian, English, and German for an\neducational web portal. It emphasizes the development and evaluation of a\ndirect Czech-Ukrainian machine translation system tailored to the educational\ndomain, with special attention to processing formatted content such as XML and\nPDF and handling technical and scientific terminology. We present findings from\nan initial survey of Czech teachers regarding the needs of non-Czech-speaking\nstudents and describe the system's evaluation and implementation on the web\nportal. All resulting applications are freely available to students, educators,\nand researchers.", "AI": {"tldr": "The EdUKate project develops multilingual learning materials using machine translation for Czech schools, translating interactive exercises into Ukrainian, English, and German.", "motivation": "To address the challenge of providing multilingual educational materials tailored for non-Czech-speaking students in Czech primary and secondary schools.", "method": "The project combines machine translation, linguistics, and education. It develops a direct Czech-Ukrainian MT system optimized for educational content and formatted content processing while utilizing feedback from Czech teachers.", "result": "Successfully translates up to 9,000 interactive exercises and evaluates machine translation performance on educational materials. Applications are made freely available.", "conclusion": "The initiative bridges linguistic gaps in education through tailored machine translation systems, benefiting non-Czech-speaking students, educators, and researchers."}}
{"id": "2509.09143", "pdf": "https://arxiv.org/pdf/2509.09143", "abs": "https://arxiv.org/abs/2509.09143", "authors": ["Yuiko Uchida", "Ren Togo", "Keisuke Maeda", "Takahiro Ogawa", "Miki Haseyama"], "title": "Objectness Similarity: Capturing Object-Level Fidelity in 3D Scene Evaluation", "categories": ["cs.CV", "cs.AI", "cs.GR"], "comment": "Accepted by the ICCV 2025 UniLight Workshop", "summary": "This paper presents Objectness SIMilarity (OSIM), a novel evaluation metric\nfor 3D scenes that explicitly focuses on \"objects,\" which are fundamental units\nof human visual perception. Existing metrics assess overall image quality,\nleading to discrepancies with human perception. Inspired by neuropsychological\ninsights, we hypothesize that human recognition of 3D scenes fundamentally\ninvolves attention to individual objects. OSIM enables object-centric\nevaluations by leveraging an object detection model and its feature\nrepresentations to quantify the \"objectness\" of each object in the scene. Our\nuser study demonstrates that OSIM aligns more closely with human perception\ncompared to existing metrics. We also analyze the characteristics of OSIM using\nvarious approaches. Moreover, we re-evaluate recent 3D reconstruction and\ngeneration models under a standardized experimental setup to clarify\nadvancements in this field. The code is available at\nhttps://github.com/Objectness-Similarity/OSIM.", "AI": {"tldr": "This study introduces OSIM, a metric for 3D scene evaluation emphasizing object-focused perception for better alignment with human visual understanding.", "motivation": "Existing evaluation metrics fail to adequately align with human perception, as they assess overall image quality rather than focusing on individual objects, which are essential to human visual recognition.", "method": "The paper proposes OSIM, leveraging an object detection model and its features to quantify object properties within a 3D scene and conducts user studies to validate its alignment with human perception.", "result": "OSIM shows closer alignment with human judgment compared to existing metrics, providing a standardized experimental setup for assessing recent 3D models.", "conclusion": "OSIM enhances evaluation of 3D scenes by focusing on individual object similarly to human visual perception, offering insights into advancements in 3D reconstruction and generation."}}
{"id": "2509.09214", "pdf": "https://arxiv.org/pdf/2509.09214", "abs": "https://arxiv.org/abs/2509.09214", "authors": ["Alka Gadakh", "Vidya Kumbhar", "Sonal Khosla", "Kumar Karunendra"], "title": "Identifying Key Features for Establishing Sustainable Agro-Tourism Centre: A Data Driven Approach", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Agro-tourism serves as a strategic economic model designed to facilitate\nrural development by diversifying income streams for local communities like\nfarmers while promoting the conservation of indigenous cultural heritage and\ntraditional agricultural practices. As a very booming subdomain of tourism,\nthere is a need to study the strategies for the growth of Agro-tourism in\ndetail. The current study has identified the important indicators for the\ngrowth and enhancement of agro-tourism. The study is conducted in two phases:\nidentification of the important indicators through a comprehensive literature\nreview and in the second phase state-of-the-art techniques were used to\nidentify the important indicators for the growth of agro-tourism. The\nindicators are also called features synonymously, the machine learning models\nfor feature selection were applied and it was observed that the Least Absolute\nShrinkage and Selection Operator (LASSO) method combined with, the machine\nLearning Classifiers such as Logistic Regression (LR), Decision Trees (DT),\nRandom Forest (RF) Tree, and Extreme Gradient Boosting (XGBOOST) models were\nused to suggest the growth of the agro-tourism. The results show that with the\nLASSO method, LR model gives the highest classification accuracy of 98% in\n70-30% train-test data followed by RF with 95% accuracy. Similarly, in the\n80-20% train-test data LR maintains the highest accuracy at 99%, while DT and\nXGBoost follow with 97% accuracy.", "AI": {"tldr": "The study explores agro-tourism as a tool for rural development, using ML methods to identify growth indicators, with LR achieving high accuracy in predictions.", "motivation": "Agro-tourism is a booming area in tourism that supports rural economies and cultural preservation. The study aims to identify strategies for its growth.", "method": "The study involved two phases: a literature review to determine agro-tourism growth indicators and the application of machine learning techniques such as LASSO combined with classifiers like LR, DT, RF, and XGBoost for feature selection.", "result": "LASSO combined with LR achieved the highest classification accuracy of 98% (70-30 split) and 99% (80-20 split), outperforming RF, DT, and XGBoost.", "conclusion": "Machine learning models are effective in identifying key indicators for agro-tourism growth. LR emerged as the most accurate model, highlighting its suitability for predicting successful strategies."}}
{"id": "2509.09522", "pdf": "https://arxiv.org/pdf/2509.09522", "abs": "https://arxiv.org/abs/2509.09522", "authors": ["Vadim Zadykian", "Bruno Andrade", "Haithem Afli"], "title": "Towards Explainable Job Title Matching: Leveraging Semantic Textual Relatedness and Knowledge Graphs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Semantic Textual Relatedness (STR) captures nuanced relationships between\ntexts that extend beyond superficial lexical similarity. In this study, we\ninvestigate STR in the context of job title matching - a key challenge in\nresume recommendation systems, where overlapping terms are often limited or\nmisleading. We introduce a self-supervised hybrid architecture that combines\ndense sentence embeddings with domain-specific Knowledge Graphs (KGs) to\nimprove both semantic alignment and explainability. Unlike previous work that\nevaluated models on aggregate performance, our approach emphasizes data\nstratification by partitioning the STR score continuum into distinct regions:\nlow, medium, and high semantic relatedness. This stratified evaluation enables\na fine-grained analysis of model performance across semantically meaningful\nsubspaces. We evaluate several embedding models, both with and without KG\nintegration via graph neural networks. The results show that fine-tuned SBERT\nmodels augmented with KGs produce consistent improvements in the high-STR\nregion, where the RMSE is reduced by 25% over strong baselines. Our findings\nhighlight not only the benefits of combining KGs with text embeddings, but also\nthe importance of regional performance analysis in understanding model\nbehavior. This granular approach reveals strengths and weaknesses hidden by\nglobal metrics, and supports more targeted model selection for use in Human\nResources (HR) systems and applications where fairness, explainability, and\ncontextual matching are essential.", "AI": {"tldr": "This paper proposes a novel approach combining dense sentence embeddings and Knowledge Graphs (KGs) to enhance semantic textual relatedness (STR) in job title matching for resume recommendation systems, emphasizing granular performance analysis across different STR regions.", "motivation": "The study addresses the challenge of limited or misleading lexical overlap in job title matching within resume recommendation systems, aiming to improve semantic alignment and provide explainability in STR tasks.", "method": "The authors introduce a self-supervised hybrid architecture that integrates fine-tuned SBERT models with domain-specific KGs via graph neural networks, and assess model performance using a stratified STR score continuum (low, medium, high) rather than aggregate metrics.", "result": "The hybrid approach achieves a 25% reduction in RMSE in the high-STR score region compared to strong baselines, demonstrating consistent improvements in semantic alignment when combining KGs with text embeddings.", "conclusion": "Combining domain-specific Knowledge Graphs with dense sentence embeddings enhances STR performance, particularly in high-STR regions, while stratified performance analysis provides deeper insights into model behavior for applications in HR systems."}}
{"id": "2509.09151", "pdf": "https://arxiv.org/pdf/2509.09151", "abs": "https://arxiv.org/abs/2509.09151", "authors": ["Lei Wang", "Piotr Koniusz", "Yongsheng Gao"], "title": "Video Understanding by Design: How Datasets Shape Architectures and Insights", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Research report", "summary": "Video understanding has advanced rapidly, fueled by increasingly complex\ndatasets and powerful architectures. Yet existing surveys largely classify\nmodels by task or family, overlooking the structural pressures through which\ndatasets guide architectural evolution. This survey is the first to adopt a\ndataset-driven perspective, showing how motion complexity, temporal span,\nhierarchical composition, and multimodal richness impose inductive biases that\nmodels should encode. We reinterpret milestones, from two-stream and 3D CNNs to\nsequential, transformer, and multimodal foundation models, as concrete\nresponses to these dataset-driven pressures. Building on this synthesis, we\noffer practical guidance for aligning model design with dataset invariances\nwhile balancing scalability and task demands. By unifying datasets, inductive\nbiases, and architectures into a coherent framework, this survey provides both\na comprehensive retrospective and a prescriptive roadmap for advancing\ngeneral-purpose video understanding.", "AI": {"tldr": "This survey highlights how video datasets influence the evolution of model architectures and provides guidance for aligning model designs with dataset characteristics.", "motivation": "Existing surveys tend to classify video understanding models by task or architecture family, missing the influence of dataset structures on model evolution.", "method": "The authors adopt a dataset-driven perspective, analyzing pressures like motion complexity, temporal span, hierarchical composition, and multimodal richness, and reinterpret model milestones accordingly.", "result": "The survey presents a unified framework connecting datasets, inductive biases, and architectures, explaining past model developments and offering practical design guidance.", "conclusion": "This work bridges the gap between datasets and model evolution, delivering a retrospective synthesis and a framework for advancing video understanding through informed model design."}}
{"id": "2509.09219", "pdf": "https://arxiv.org/pdf/2509.09219", "abs": "https://arxiv.org/abs/2509.09219", "authors": ["Jakob Nyberg", "Pontus Johnson"], "title": "Vejde: A Framework for Inductive Deep Reinforcement Learning Based on Factor Graph Color Refinement", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We present and evaluate Vejde; a framework which combines data abstraction,\ngraph neural networks and reinforcement learning to produce inductive policy\nfunctions for decision problems with richly structured states, such as object\nclasses and relations. MDP states are represented as data bases of facts about\nentities, and Vejde converts each state to a bipartite graph, which is mapped\nto latent states through neural message passing. The factored representation of\nboth states and actions allows Vejde agents to handle problems of varying size\nand structure. We tested Vejde agents on eight problem domains defined in RDDL,\nwith ten problem instances each, where policies were trained using both\nsupervised and reinforcement learning. To test policy generalization, we\nseparate problem instances in two sets, one for training and the other solely\nfor testing. Test results on unseen instances for the Vejde agents were\ncompared to MLP agents trained on each problem instance, as well as the online\nplanning algorithm Prost. Our results show that Vejde policies in average\ngeneralize to the test instances without a significant loss in score.\nAdditionally, the inductive agents received scores on unseen test instances\nthat on average were close to the instance-specific MLP agents.", "AI": {"tldr": "Vejde framework combines data abstraction, graph neural networks, and reinforcement learning to create policies for decision problems with complex states.", "motivation": "To address decision problems involving structured states, like object classes and relations, which are challenging for standard methods.", "method": "Vejde uses database facts as MDP states, representing them as bipartite graphs, and applies message passing in graph neural networks. It trains policies using supervised and reinforcement learning.", "result": "Testing on eight domains showed Vejde generalizes well to unseen instances, scoring almost on par with MLP agents and Prost planning algorithm.", "conclusion": "Vejde demonstrates effective generalization and comparable performance, offering a flexible solution for problems with variable sizes and structures."}}
{"id": "2509.08862", "pdf": "https://arxiv.org/pdf/2509.08862", "abs": "https://arxiv.org/abs/2509.08862", "authors": ["Chang Liu", "Loc Hoang", "Andrew Stolman", "Rene F. Kizilcec", "Bo Wu"], "title": "Investigating Student Interaction Patterns with Large Language Model-Powered Course Assistants in Computer Science Courses", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": null, "summary": "Providing students with flexible and timely academic support is a challenge\nat most colleges and universities, leaving many students without help outside\nscheduled hours. Large language models (LLMs) are promising for bridging this\ngap, but interactions between students and LLMs are rarely overseen by\neducators. We developed and studied an LLM-powered course assistant deployed\nacross multiple computer science courses to characterize real-world use and\nunderstand pedagogical implications. By Spring 2024, our system had been\ndeployed to approximately 2,000 students across six courses at three\ninstitutions. Analysis of the interaction data shows that usage remains strong\nin the evenings and nights and is higher in introductory courses, indicating\nthat our system helps address temporal support gaps and novice learner needs.\nWe sampled 200 conversations per course for manual annotation: most sampled\nresponses were judged correct and helpful, with a small share unhelpful or\nerroneous; few responses included dedicated examples. We also examined an\ninquiry-based learning strategy: only around 11% of sampled conversations\ncontained LLM-generated follow-up questions, which were often ignored by\nstudents in advanced courses. A Bloom's taxonomy analysis reveals that current\nLLM capabilities are limited in generating higher-order cognitive questions.\nThese patterns suggest opportunities for pedagogically oriented LLM-based\neducational systems and greater educator involvement in configuring prompts,\ncontent, and policies.", "AI": {"tldr": "Researchers deployed an LLM-powered course assistant to aid 2,000 students across six computer science courses, discovering that it effectively fills support gaps, but faces pedagogical limitations in higher cognitive tasks.", "motivation": "To address the challenge of providing flexible and timely academic support to students when educators aren't available.", "method": "Deployed an LLM-powered course assistant across multiple computer science courses, analyzed interaction data, manually annotated 200 conversations per course, and assessed pedagogical implications using metrics like Bloom's taxonomy.", "result": "The system was used significantly during evenings, nights, and by novice learners. Most responses were correct, though higher-order cognitive questions were lacking and follow-up questions were often ignored.", "conclusion": "LLMs show promise in addressing support gaps but need educator involvement and advancements in higher-level questioning capabilities to improve pedagogical outcomes."}}
{"id": "2509.09524", "pdf": "https://arxiv.org/pdf/2509.09524", "abs": "https://arxiv.org/abs/2509.09524", "authors": ["Daniil Ignatev", "Nan Li", "Hugh Mee Wong", "Anh Dang", "Shane Kaszefski Yaschuk"], "title": "DeMeVa at LeWiDi-2025: Modeling Perspectives with In-Context Learning and Label Distribution Learning", "categories": ["cs.CL", "cs.LG"], "comment": "11 pages, 4 figures; to appear at NLPerspectives@EMNLP-2025", "summary": "This system paper presents the DeMeVa team's approaches to the third edition\nof the Learning with Disagreements shared task (LeWiDi 2025; Leonardelli et\nal., 2025). We explore two directions: in-context learning (ICL) with large\nlanguage models, where we compare example sampling strategies; and label\ndistribution learning (LDL) methods with RoBERTa (Liu et al., 2019b), where we\nevaluate several fine-tuning methods. Our contributions are twofold: (1) we\nshow that ICL can effectively predict annotator-specific annotations\n(perspectivist annotations), and that aggregating these predictions into soft\nlabels yields competitive performance; and (2) we argue that LDL methods are\npromising for soft label predictions and merit further exploration by the\nperspectivist community.", "AI": {"tldr": "The paper explores in-context learning (ICL) with large language models and label distribution learning (LDL) methods using RoBERTa for the Learning with Disagreements (LeWiDi 2025) shared task.", "motivation": "To investigate effective approaches for handling disagreements in learning tasks, specifically using ICL with large language models and LDL methods.", "method": "The authors used ICL with various sampling strategies and fine-tuned RoBERTa models under LDL methods to evaluate their performance for predicting perspectivist annotations and soft label aggregation.", "result": "They demonstrated that ICL effectively predicts annotator-specific annotations, with aggregated predictions performing competitively, and highlighted the promise of LDL methods for soft label predictions.", "conclusion": "ICL and LDL methods show significant potential in handling disagreements in learning tasks, with LDL deserving further exploration in perspectivist annotation contexts."}}
{"id": "2509.09153", "pdf": "https://arxiv.org/pdf/2509.09153", "abs": "https://arxiv.org/abs/2509.09153", "authors": ["JaeWoong Shin", "Jeongun Ryu", "Aaron Valero Puche", "Jinhee Lee", "Biagio Brattoli", "Wonkyung Jung", "Soo Ick Cho", "Kyunghyun Paeng", "Chan-Young Ock", "Donggeun Yoo", "Zhaoyang Li", "Wangkai Li", "Huayu Mai", "Joshua Millward", "Zhen He", "Aiden Nibali", "Lydia Anette Schoenpflug", "Viktor Hendrik Koelzer", "Xu Shuoyu", "Ji Zheng", "Hu Bin", "Yu-Wen Lo", "Ching-Hui Yang", "S\u00e9rgio Pereira"], "title": "OCELOT 2023: Cell Detection from Cell-Tissue Interaction Challenge", "categories": ["cs.CV", "cs.AI"], "comment": "This is the accepted manuscript of an article published in Medical\n  Image Analysis (Elsevier). The final version is available at:\n  https://doi.org/10.1016/j.media.2025.103751", "summary": "Pathologists routinely alternate between different magnifications when\nexamining Whole-Slide Images, allowing them to evaluate both broad tissue\nmorphology and intricate cellular details to form comprehensive diagnoses.\nHowever, existing deep learning-based cell detection models struggle to\nreplicate these behaviors and learn the interdependent semantics between\nstructures at different magnifications. A key barrier in the field is the lack\nof datasets with multi-scale overlapping cell and tissue annotations. The\nOCELOT 2023 challenge was initiated to gather insights from the community to\nvalidate the hypothesis that understanding cell and tissue (cell-tissue)\ninteractions is crucial for achieving human-level performance, and to\naccelerate the research in this field. The challenge dataset includes\noverlapping cell detection and tissue segmentation annotations from six organs,\ncomprising 673 pairs sourced from 306 The Cancer Genome Atlas (TCGA)\nWhole-Slide Images with hematoxylin and eosin staining, divided into training,\nvalidation, and test subsets. Participants presented models that significantly\nenhanced the understanding of cell-tissue relationships. Top entries achieved\nup to a 7.99 increase in F1-score on the test set compared to the baseline\ncell-only model that did not incorporate cell-tissue relationships. This is a\nsubstantial improvement in performance over traditional cell-only detection\nmethods, demonstrating the need for incorporating multi-scale semantics into\nthe models. This paper provides a comparative analysis of the methods used by\nparticipants, highlighting innovative strategies implemented in the OCELOT 2023\nchallenge.", "AI": {"tldr": "The paper discusses the OCELOT 2023 challenge, emphasizing the importance of understanding multi-scale cell-tissue interactions in pathology. Results show models using multi-scale approaches outperformed traditional methods.", "motivation": "Pathologists utilize multi-scale examination of Whole-Slide Images for comprehensive diagnosis, but current deep learning models struggle to replicate this. There is a lack of datasets addressing overlapping cell and tissue semantics.", "method": "The OCELOT 2023 challenge introduced a dataset with multi-scale annotations for overlapping cell detection and tissue segmentation across six organs, using 673 image pairs from TCGA. Participants developed models incorporating cell-tissue relationships.", "result": "Top-performing models improved F1-scores by up to 7.99 points compared to baseline models focusing only on cells, showcasing substantial performance improvement through multi-scale semantics.", "conclusion": "Incorporating multi-scale semantics into models is crucial for replicating pathologists' diagnostic approaches, as demonstrated by results from the OCELOT 2023 challenge and its dataset."}}
{"id": "2509.09226", "pdf": "https://arxiv.org/pdf/2509.09226", "abs": "https://arxiv.org/abs/2509.09226", "authors": ["Haipeng Liu", "Ting Long", "Jing Fu"], "title": "Constructing a Question-Answering Simulator through the Distillation of LLMs", "categories": ["cs.LG", "cs.IR"], "comment": null, "summary": "The question-answering (QA) simulator is a model that mimics real student\nlearning behaviors and predicts their correctness of their responses to\nquestions. QA simulators enable educational recommender systems (ERS) to\ncollect large amounts of training data without interacting with real students,\nthereby preventing harmful recommendations made by an undertrained ERS from\nundermining actual student learning. Given the QA history, there are two\ncategories of solutions to predict the correctness, conducting the simulation:\n(1) LLM-free methods, which apply a traditional sequential model to transfer\nthe QA history into a vector representation first, and make predictions based\non the representation; (2) LLM-based methods, which leverage the domain\nknowledge and reasoning capability of LLM to enhence the prediction. LLM-free\nmethods offer fast inference but generally yield suboptimal performance. In\ncontrast, most LLM-based methods achieve better results, but at the cost of\nslower inference speed and higher GPU memory consumption. In this paper, we\npropose a method named LLM Distillation based Simulator (LDSim), which distills\ndomain knowledge and reasoning capability from an LLM to better assist\nprediction, thereby improving simulation performance. Extensive experiments\ndemonstrate that our LDSim achieves strong results on both the simulation task\nand the knowledge tracing (KT) task. Our code is publicly available at\nhttps://anonymous.4open.science/r/LDSim-05A9.", "AI": {"tldr": "This paper introduces LDSim, a QA simulator leveraging knowledge distillation from large language models (LLMs) for effective performance in predicting students' responses.", "motivation": "To improve educational recommendation systems by enabling accurate predictions of student responses while addressing the limitations of LLM-free and LLM-based methods.", "method": "Develop LDSim that distills domain knowledge and reasoning capabilities from LLMs, combining efficiency and performance for student response prediction.", "result": "Experiments show LDSim outperforms existing methods in simulation tasks and knowledge tracing tasks.", "conclusion": "LDSim effectively balances speed, memory efficiency, and performance, making it a strong approach for enhancing student learning prediction models."}}
{"id": "2509.09544", "pdf": "https://arxiv.org/pdf/2509.09544", "abs": "https://arxiv.org/abs/2509.09544", "authors": ["Paolo Pedinotti", "Peter Baumann", "Nathan Jessurun", "Leslie Barrett", "Enrico Santus"], "title": "Prompting the Market? A Large-Scale Meta-Analysis of GenAI in Finance NLP (2022-2025)", "categories": ["cs.CL"], "comment": "7 pages, 6 appendices, EMNLP industry track", "summary": "Large Language Models (LLMs) have rapidly reshaped financial NLP, enabling\nnew tasks and driving a proliferation of datasets and diversification of data\nsources. Yet, this transformation has outpaced traditional surveys. In this\npaper, we present MetaGraph, a generalizable methodology for extracting\nknowledge graphs from scientific literature and analyzing them to obtain a\nstructured, queryable view of research trends. We define an ontology for\nfinancial NLP research and apply an LLM-based extraction pipeline to 681 papers\n(2022-2025), enabling large-scale, data-driven analysis. MetaGraph reveals\nthree key phases: early LLM adoption and task/dataset innovation; critical\nreflection on LLM limitations; and growing integration of peripheral techniques\ninto modular systems. This structured view offers both practitioners and\nresearchers a clear understanding of how financial NLP has evolved -\nhighlighting emerging trends, shifting priorities, and methodological\nshifts-while also demonstrating a reusable approach for mapping scientific\nprogress in other domains.", "AI": {"tldr": "The paper introduces MetaGraph, a methodology for extracting knowledge graphs to analyze research trends in financial NLP, using 681 papers from 2022-2025.", "motivation": "The study aims to address the rapid evolution of financial NLP brought by LLMs, which traditional surveys struggle to keep up with.", "method": "The authors defined an ontology for financial NLP research and developed an LLM-based pipeline to extract data from 681 relevant papers, analyzing trends using a structured approach.", "result": "MetaGraph identified three evolving phases in financial NLP: innovation in tasks and datasets, reflection on limitations of LLMs, and increasing modular integration with peripheral techniques.", "conclusion": "The research provides insights into the evolution of financial NLP research, identifies trends, and offers a reusable methodology for other scientific domains."}}
{"id": "2509.09157", "pdf": "https://arxiv.org/pdf/2509.09157", "abs": "https://arxiv.org/abs/2509.09157", "authors": ["Yuan Shufang"], "title": "RT-DETR++ for UAV Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Object detection in unmanned aerial vehicle (UAV) imagery presents\nsignificant challenges. Issues such as densely packed small objects, scale\nvariations, and occlusion are commonplace. This paper introduces RT-DETR++,\nwhich enhances the encoder component of the RT-DETR model. Our improvements\nfocus on two key aspects. First, we introduce a channel-gated attention-based\nupsampling/downsampling (AU/AD) mechanism. This dual-path system minimizes\nerrors and preserves details during feature layer propagation. Second, we\nincorporate CSP-PAC during feature fusion. This technique employs parallel\nhollow convolutions to process local and contextual information within the same\nlayer, facilitating the integration of multi-scale features. Evaluation\ndemonstrates that our novel neck design achieves superior performance in\ndetecting small and densely packed objects. The model maintains sufficient\nspeed for real-time detection without increasing computational complexity. This\nstudy provides an effective approach for feature encoding design in real-time\ndetection systems.", "AI": {"tldr": "The paper proposes RT-DETR++, enhancing small object detection in UAV imagery via advanced encoder mechanisms without added computational burden.", "motivation": "Address challenges in UAV object detection, such as handling densely packed small objects, scale variations, and occlusions.", "method": "Introduced channel-gated attention mechanisms for feature layer propagation, and CSP-PAC for improved feature fusion with multi-scale integration.", "result": "Achieved better detection of small, densely packed objects while preserving real-time processing speeds.", "conclusion": "The improved encoder design offers effective solutions for enhancing real-time detection systems without compromising efficiency."}}
{"id": "2509.09251", "pdf": "https://arxiv.org/pdf/2509.09251", "abs": "https://arxiv.org/abs/2509.09251", "authors": ["Hanyang Wang", "Yuxuan Yang", "Hongjun Wang", "Lihui Wang"], "title": "Unsupervised Multi-Attention Meta Transformer for Rotating Machinery Fault Diagnosis", "categories": ["cs.LG"], "comment": null, "summary": "The intelligent fault diagnosis of rotating mechanical equipment usually\nrequires a large amount of labeled sample data. However, in practical\nindustrial applications, acquiring enough data is both challenging and\nexpensive in terms of time and cost. Moreover, different types of rotating\nmechanical equipment with different unique mechanical properties, require\nseparate training of diagnostic models for each case. To address the challenges\nof limited fault samples and the lack of generalizability in prediction models\nfor practical engineering applications, we propose a Multi-Attention Meta\nTransformer method for few-shot unsupervised rotating machinery fault diagnosis\n(MMT-FD). This framework extracts potential fault representations from\nunlabeled data and demonstrates strong generalization capabilities, making it\nsuitable for diagnosing faults across various types of mechanical equipment.\nThe MMT-FD framework integrates a time-frequency domain encoder and a\nmeta-learning generalization model. The time-frequency domain encoder predicts\nstatus representations generated through random augmentations in the\ntime-frequency domain. These enhanced data are then fed into a meta-learning\nnetwork for classification and generalization training, followed by fine-tuning\nusing a limited amount of labeled data. The model is iteratively optimized\nusing a small number of contrastive learning iterations, resulting in high\nefficiency. To validate the framework, we conducted experiments on a bearing\nfault dataset and rotor test bench data. The results demonstrate that the\nMMT-FD model achieves 99\\% fault diagnosis accuracy with only 1\\% of labeled\nsample data, exhibiting robust generalization capabilities.", "AI": {"tldr": "The paper proposes a Multi-Attention Meta Transformer (MMT-FD) for diagnosing rotating machinery faults using minimal labeled data, achieving 99% accuracy with only 1% labeled samples.", "motivation": "Fault diagnosis of rotating mechanical equipment requires extensive labeled data, which is hard and costly to obtain. Existing models lack generalizability for diverse equipment types.", "method": "MMT-FD integrates a time-frequency domain encoder and a meta-learning model. It utilizes data augmentation, contrastive learning, and fine-tuning with limited labeled data for fault classification.", "result": "Experiments on bearing fault and rotor test bench datasets show the model achieves 99% fault diagnosis accuracy with only 1% labeled data.", "conclusion": "MMT-FD exhibits strong fault representation extraction and generalization capabilities, making it highly efficient and applicable across diverse types of rotating machinery."}}
{"id": "2509.09583", "pdf": "https://arxiv.org/pdf/2509.09583", "abs": "https://arxiv.org/abs/2509.09583", "authors": ["Brittany Harbison", "Samuel Taubman", "Travis Taylor", "Ashok. K. Goel"], "title": "Personality-Enhanced Social Recommendations in SAMI: Exploring the Role of Personality Detection in Matchmaking", "categories": ["cs.CL", "cs.CY", "cs.HC", "cs.LG", "cs.SI"], "comment": null, "summary": "Social connection is a vital part of learning, yet online course environments\npresent barriers to the organic formation of social groups. SAMI offers one\nsolution by facilitating student connections, but its effectiveness is\nconstrained by an incomplete Theory of Mind, limiting its ability to create an\neffective mental model of a student. One facet of this is its inability to\nintuit personality, which may influence the relevance of its recommendations.\nTo explore this, we propose a personality detection model utilizing GPTs\nzero-shot capability to infer Big-Five personality traits from forum\nintroduction posts, often encouraged in online courses. We benchmark its\nperformance against established models, demonstrating its efficacy in this\ntask. Furthermore, we integrate this model into SAMIs entity-based matchmaking\nsystem, enabling personality-informed social recommendations. Initial\nintegration suggests personality traits can complement existing matching\nfactors, though additional evaluation is required to determine their full\nimpact on student engagement and match quality.", "AI": {"tldr": "The paper explores the integration of a GPT-based personality detection model into SAMI, an online course matchmaking system, to enhance social connections and student engagement.", "motivation": "Online learning environments often lack effective tools to foster social connections, which are critical to student learning and engagement.", "method": "The researchers propose a zero-shot personality detection model using GPT to infer Big-Five personality traits from students' forum introduction posts. They benchmarked this model against established alternatives and integrated it into SAMI's matchmaking system.", "result": "The GPT-based personality detection model showed efficacy in identifying personality traits and was successfully implemented into SAMI, enabling personality-informed matchmaking.", "conclusion": "Integrating personality recognition enhances matchmaking in online learning platforms, but further evaluation is needed to fully understand its impact on social connections and engagement."}}
{"id": "2509.09159", "pdf": "https://arxiv.org/pdf/2509.09159", "abs": "https://arxiv.org/abs/2509.09159", "authors": ["Zhiyue Liu", "Sihang Liu", "Jinyuan Liu", "Xinru Zhang"], "title": "A Knowledge Noise Mitigation Framework for Knowledge-based Visual Question Answering", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by the IEEE International Conference on Multimedia and Expo\n  (ICME 2025) for oral presentation. \\copyright\\ 2025 IEEE. Personal use of\n  this material is permitted. Permission from IEEE must be obtained for all\n  other uses", "summary": "Knowledge-based visual question answering (KB-VQA) requires a model to\nunderstand images and utilize external knowledge to provide accurate answers.\nExisting approaches often directly augment models with retrieved information\nfrom knowledge sources while ignoring substantial knowledge redundancy, which\nintroduces noise into the answering process. To address this, we propose a\ntraining-free framework with knowledge focusing for KB-VQA, that mitigates the\nimpact of noise by enhancing knowledge relevance and reducing redundancy.\nFirst, for knowledge retrieval, our framework concludes essential parts from\nthe image-question pairs, creating low-noise queries that enhance the retrieval\nof highly relevant knowledge. Considering that redundancy still persists in the\nretrieved knowledge, we then prompt large models to identify and extract\nanswer-beneficial segments from knowledge. In addition, we introduce a\nselective knowledge integration strategy, allowing the model to incorporate\nknowledge only when it lacks confidence in answering the question, thereby\nmitigating the influence of redundant information. Our framework enables the\nacquisition of accurate and critical knowledge, and extensive experiments\ndemonstrate that it outperforms state-of-the-art methods.", "AI": {"tldr": "The paper addresses KB-VQA challenges by proposing a training-free framework that reduces redundant and noisy knowledge for improved answering performance.", "motivation": "Existing KB-VQA methods struggle with redundant and noisy external knowledge, impacting their answering accuracy.", "method": "The proposed framework enhances relevance in knowledge retrieval, uses large models to extract answer-relevant knowledge, and adopts a selective integration strategy to only incorporate knowledge when needed.", "result": "The approach effectively reduces noise and improves performance, outperforming state-of-the-art KB-VQA methods in extensive experiments.", "conclusion": "By focusing and selectively using external knowledge, the paper demonstrates a practical and noise-reducing framework for KB-VQA that improves overall answer accuracy."}}
{"id": "2509.09265", "pdf": "https://arxiv.org/pdf/2509.09265", "abs": "https://arxiv.org/abs/2509.09265", "authors": ["Jiawei Wang", "Jiacai Liu", "Yuqian Fu", "Yingru Li", "Xintao Wang", "Yuan Lin", "Yu Yue", "Lin Zhang", "Yang Wang", "Ke Wang"], "title": "Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents", "categories": ["cs.LG", "cs.CL"], "comment": "ICLR 2026 Under review", "summary": "In long-horizon tasks, recent agents based on Large Language Models (LLMs)\nface a significant challenge that sparse, outcome-based rewards make it\ndifficult to assign credit to intermediate steps. Previous methods mainly focus\non creating dense reward signals to guide learning, either through traditional\nreinforcement learning techniques like inverse reinforcement learning or by\nusing Process Reward Models for step-by-step feedback. In this paper, we\nidentify a fundamental problem in the learning dynamics of LLMs: the magnitude\nof policy gradients is inherently coupled with the entropy, which leads to\ninefficient small updates for confident correct actions and potentially\ndestabilizes large updates for uncertain ones. To resolve this, we propose\nEntropy-Modulated Policy Gradients (EMPG), a framework that re-calibrates the\nlearning signal based on step-wise uncertainty and the final task outcome. EMPG\namplifies updates for confident correct actions, penalizes confident errors,\nand attenuates updates from uncertain steps to stabilize exploration. We\nfurther introduce a bonus term for future clarity that encourages agents to\nfind more predictable solution paths. Through comprehensive experiments on\nthree challenging agent tasks, WebShop, ALFWorld, and Deep Search, we\ndemonstrate that EMPG achieves substantial performance gains and significantly\noutperforms strong policy gradient baselines. Project page is at\nhttps://empgseed-seed.github.io/", "AI": {"tldr": "Sparse rewards in long-horizon tasks challenge LLM agents, prompting the introduction of Entropy-Modulated Policy Gradients (EMPG) to improve learning dynamics and achieve significant gains.", "motivation": "LLMs face difficulties in assigning credit in tasks with sparse, outcome-based rewards, impeding efficient learning and solution exploration.", "method": "EMPG adjusts policy gradient magnitudes based on step-wise uncertainty and task outcomes, amplifying confident correct actions, penalizing errors, and attenuating uncertain updates.", "result": "EMPG shows substantial performance improvements, outperforming strong policy gradient baselines in tasks like WebShop, ALFWorld, and Deep Search.", "conclusion": "EMPG effectively addresses learning inefficiencies in LLMs for sparse-reward tasks, demonstrating its usefulness for stable exploration and improved performance."}}
{"id": "2509.09593", "pdf": "https://arxiv.org/pdf/2509.09593", "abs": "https://arxiv.org/abs/2509.09593", "authors": ["Bangzhao Shu", "Isha Joshi", "Melissa Karnaze", "Anh C. Pham", "Ishita Kakkar", "Sindhu Kothe", "Arpine Hovasapian", "Mai ElSherief"], "title": "Fluent but Unfeeling: The Emotional Blind Spots of Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Camera-ready version for ICWSM 2026. First two authors contributed\n  equally", "summary": "The versatility of Large Language Models (LLMs) in natural language\nunderstanding has made them increasingly popular in mental health research.\nWhile many studies explore LLMs' capabilities in emotion recognition, a\ncritical gap remains in evaluating whether LLMs align with human emotions at a\nfine-grained level. Existing research typically focuses on classifying emotions\ninto predefined, limited categories, overlooking more nuanced expressions. To\naddress this gap, we introduce EXPRESS, a benchmark dataset curated from Reddit\ncommunities featuring 251 fine-grained, self-disclosed emotion labels. Our\ncomprehensive evaluation framework examines predicted emotion terms and\ndecomposes them into eight basic emotions using established emotion theories,\nenabling a fine-grained comparison. Systematic testing of prevalent LLMs under\nvarious prompt settings reveals that accurately predicting emotions that align\nwith human self-disclosed emotions remains challenging. Qualitative analysis\nfurther shows that while certain LLMs generate emotion terms consistent with\nestablished emotion theories and definitions, they sometimes fail to capture\ncontextual cues as effectively as human self-disclosures. These findings\nhighlight the limitations of LLMs in fine-grained emotion alignment and offer\ninsights for future research aimed at enhancing their contextual understanding.", "AI": {"tldr": "The paper introduces EXPRESS, a Reddit-sourced dataset with 251 fine-grained emotion labels, to evaluate the alignment of LLM-predicted emotions with human self-disclosures.", "motivation": "Existing research on LLMs in emotion recognition is limited by predefined, coarse emotion categories, failing to capture finer nuances in human emotional expressions.", "method": "The authors curated the EXPRESS dataset with 251 emotion labels from Reddit communities and devised an evaluation framework using emotion theories to compare LLM predictions with fine-grained human emotions.", "result": "Testing reveals that while some LLMs align with emotion theories, they struggle to predict fine-grained, context-dependent emotions aligned with human cues.", "conclusion": "LLMs face significant challenges in aligning with human self-disclosed emotions at a fine-grained level, underscoring the need for improved contextual understanding in future models."}}
{"id": "2509.09163", "pdf": "https://arxiv.org/pdf/2509.09163", "abs": "https://arxiv.org/abs/2509.09163", "authors": ["Yulin Tong", "Fengzong Zhang", "Haiqin Cheng"], "title": "CWSSNet: Hyperspectral Image Classification Enhanced by Wavelet Domain Convolution", "categories": ["cs.CV"], "comment": null, "summary": "Hyperspectral remote sensing technology has significant application value in\nfields such as forestry ecology and precision agriculture, while also putting\nforward higher requirements for fine ground object classification. However,\nalthough hyperspectral images are rich in spectral information and can improve\nrecognition accuracy, they tend to cause prominent feature redundancy due to\ntheir numerous bands, high dimensionality, and spectral mixing characteristics.\nTo address this, this study used hyperspectral images from the ZY1F satellite\nas a data source and selected Yugan County, Shangrao City, Jiangxi Province as\nthe research area to perform ground object classification research. A\nclassification framework named CWSSNet was proposed, which integrates 3D\nspectral-spatial features and wavelet convolution. This framework integrates\nmultimodal information us-ing a multiscale convolutional attention module and\nbreaks through the classification performance bottleneck of traditional methods\nby introducing multi-band decomposition and convolution operations in the\nwavelet domain. The experiments showed that CWSSNet achieved 74.50\\%, 82.73\\%,\nand 84.94\\% in mean Intersection over Union (mIoU), mean Accuracy (mAcc), and\nmean F1-score (mF1) respectively in Yugan County. It also obtained the highest\nIntersection over Union (IoU) in the classifica-tion of water bodies,\nvegetation, and bare land, demonstrating good robustness. Additionally, when\nthe training set proportion was 70\\%, the increase in training time was\nlimited, and the classification effect was close to the optimal level,\nindicating that the model maintains reliable performance under small-sample\ntraining conditions.", "AI": {"tldr": "The study introduces CWSSNet, a hyperspectral image classification framework using spectral-spatial features and wavelet convolution, achieving high classification accuracies in a forestry and agriculture application.", "motivation": "To address feature redundancy challenges in hyperspectral images while improving ground object classification for applications in forestry and precision agriculture.", "method": "The proposed CWSSNet integrates multimodal information, 3D spectral-spatial features, and wavelet convolution using wavelet domain decomposition and convolutional attention modules.", "result": "CWSSNet achieved high metrics: mIoU of 74.50%, mAcc of 82.73%, and mF1 of 84.94% in Yugan County, excelling in classifying water bodies, vegetation, and bare land.", "conclusion": "CWSSNet demonstrates robust performance under small-sample training conditions and effectively overcomes limitations of traditional hyperspectral classification methods."}}
{"id": "2509.09278", "pdf": "https://arxiv.org/pdf/2509.09278", "abs": "https://arxiv.org/abs/2509.09278", "authors": ["Saumitra Dwivedi", "Ricardo da Silva Torres", "Ibrahim A. Hameed", "Gunnar Tufte", "Anniken Susanne T. Karlsen"], "title": "Data Driven Discovery of Emergent Dynamics in Reaction Diffusion Systems from Sparse and Noisy Observations", "categories": ["cs.LG", "cs.MA"], "comment": null, "summary": "Data-driven discovery of emergent dynamics is gaining popularity,\nparticularly in the context of reaction-diffusion systems. These systems are\nwidely studied across various fields, including neuroscience, ecology,\nepidemiology, and several other subject areas that deal with emergent dynamics.\nA current challenge in the discovery process relates to system identification\nwhen there is no prior knowledge of the underlying physics. We attempt to\naddress this challenge by learning Soft Artificial Life (Soft ALife) models,\nsuch as Agent-based and Cellular Automata (CA) models, from observed data for\nreaction-diffusion systems. In this paper, we present findings on the\napplicability of a conceptual framework, the Data-driven Rulesets for Soft\nArtificial Life (DRSALife) model, to learn Soft ALife rulesets that accurately\nrepresent emergent dynamics in a reaction-diffusion system from observed data.\nThis model has demonstrated promising results for Elementary CA Rule 30, Game\nof Life, and Vicsek Flocking problems in recent work. To our knowledge, this is\none of the few studies that explore machine-based Soft ALife ruleset learning\nand system identification for reaction-diffusion dynamics without any prior\nknowledge of the underlying physics. Moreover, we provide comprehensive\nfindings from experiments investigating the potential effects of using noisy\nand sparse observed datasets on learning emergent dynamics. Additionally, we\nsuccessfully identify the structure and parameters of the underlying partial\ndifferential equations (PDEs) representing these dynamics. Experimental results\ndemonstrate that the learned models are able to predict the emergent dynamics\nwith good accuracy (74%) and exhibit quite robust performance when subjected to\nGaussian noise and temporal sparsity.", "AI": {"tldr": "This paper addresses the challenges of discovering emergent dynamics in reaction-diffusion systems by developing a data-driven method using Soft Artificial Life models, achieving good prediction accuracy even under noisy and sparse conditions.", "motivation": "The motivation is to address the challenge of identifying reaction-diffusion systems when the underlying physics is unknown, which is crucial for various fields such as neuroscience, ecology, and epidemiology.", "method": "The authors propose a conceptual framework, DRSALife, to learn Soft Artificial Life rulesets for reaction-diffusion systems. They conduct experiments using noisy and sparse data to evaluate performance.", "result": "Their learned models achieve a prediction accuracy of 74% for emergent dynamics and exhibit robustness against Gaussian noise and temporal sparsity.", "conclusion": "This study successfully demonstrates the potential of machine-based Soft ALife ruleset learning for reaction-diffusion dynamics, advancing the field of data-driven system identification without prior physics knowledge."}}
{"id": "2509.09602", "pdf": "https://arxiv.org/pdf/2509.09602", "abs": "https://arxiv.org/abs/2509.09602", "authors": ["Yiqun T. Chen", "Tyler H. McCormick", "Li Liu", "Abhirup Datta"], "title": "LAVA: Language Model Assisted Verbal Autopsy for Cause-of-Death Determination", "categories": ["cs.CL", "stat.AP"], "comment": null, "summary": "Verbal autopsy (VA) is a critical tool for estimating causes of death in\nresource-limited settings where medical certification is unavailable. This\nstudy presents LA-VA, a proof-of-concept pipeline that combines Large Language\nModels (LLMs) with traditional algorithmic approaches and embedding-based\nclassification for improved cause-of-death prediction. Using the Population\nHealth Metrics Research Consortium (PHMRC) dataset across three age categories\n(Adult: 7,580; Child: 1,960; Neonate: 2,438), we evaluate multiple approaches:\nGPT-5 predictions, LCVA baseline, text embeddings, and meta-learner ensembles.\nOur results demonstrate that GPT-5 achieves the highest individual performance\nwith average test site accuracies of 48.6% (Adult), 50.5% (Child), and 53.5%\n(Neonate), outperforming traditional statistical machine learning baselines by\n5-10%. Our findings suggest that simple off-the-shelf LLM-assisted approaches\ncould substantially improve verbal autopsy accuracy, with important\nimplications for global health surveillance in low-resource settings.", "AI": {"tldr": "This paper introduces LA-VA, a hybrid method leveraging Large Language Models (LLMs) and traditional algorithms to better predict causes of death using verbal autopsies in low-resource settings.", "motivation": "Improve verbal autopsy accuracy in low-resource areas where medical certification of death is unavailable.", "method": "Develops and evaluates LA-VA, a pipeline combining GPT-5, traditional algorithms, text embeddings, and ensemble methods on the PHMRC dataset.", "result": "GPT-5 demonstrated the best standalone performance with accuracy improvements of 5-10% over baseline methods.", "conclusion": "LLM-assisted approaches like LA-VA can significantly enhance the accuracy of cause-of-death predictions, aiding global health surveillance."}}
{"id": "2509.09172", "pdf": "https://arxiv.org/pdf/2509.09172", "abs": "https://arxiv.org/abs/2509.09172", "authors": ["Chunxiao Li", "Xiaoxiao Wang", "Meiling Li", "Boming Miao", "Peng Sun", "Yunjian Zhang", "Xiangyang Ji", "Yao Zhu"], "title": "Bridging the Gap Between Ideal and Real-world Evaluation: Benchmarking AI-Generated Image Detection in Challenging Scenarios", "categories": ["cs.CV"], "comment": "ICCV2025", "summary": "With the rapid advancement of generative models, highly realistic image\nsynthesis has posed new challenges to digital security and media credibility.\nAlthough AI-generated image detection methods have partially addressed these\nconcerns, a substantial research gap remains in evaluating their performance\nunder complex real-world conditions. This paper introduces the Real-World\nRobustness Dataset (RRDataset) for comprehensive evaluation of detection models\nacross three dimensions: 1) Scenario Generalization: RRDataset encompasses\nhigh-quality images from seven major scenarios (War and Conflict, Disasters and\nAccidents, Political and Social Events, Medical and Public Health, Culture and\nReligion, Labor and Production, and everyday life), addressing existing dataset\ngaps from a content perspective. 2) Internet Transmission Robustness: examining\ndetector performance on images that have undergone multiple rounds of sharing\nacross various social media platforms. 3) Re-digitization Robustness: assessing\nmodel effectiveness on images altered through four distinct re-digitization\nmethods. We benchmarked 17 detectors and 10 vision-language models (VLMs) on\nRRDataset and conducted a large-scale human study involving 192 participants to\ninvestigate human few-shot learning capabilities in detecting AI-generated\nimages. The benchmarking results reveal the limitations of current AI detection\nmethods under real-world conditions and underscore the importance of drawing on\nhuman adaptability to develop more robust detection algorithms.", "AI": {"tldr": "This paper introduces the Real-World Robustness Dataset (RRDataset) for evaluating AI-generated image detection under real-world challenges.", "motivation": "To address the limitations of current AI-generated image detection methods, particularly in real-world, complex scenarios.", "method": "The authors created RRDataset focusing on scenario generalization, internet transmission robustness, and re-digitization robustness. They benchmarked 17 detection models and 10 vision-language models, conducting a human study to evaluate few-shot learning for detecting AI-generated images.", "result": "The study highlighted the limitations of current AI detection models under real-world conditions and the potential of human adaptability in improving detection performance.", "conclusion": "The paper emphasizes the need for robust detection algorithms, leveraging insights from human adaptability and addressing real-world complexities in AI-generated image detection."}}
{"id": "2509.09337", "pdf": "https://arxiv.org/pdf/2509.09337", "abs": "https://arxiv.org/abs/2509.09337", "authors": ["Junda Ye", "Zhongbao Zhang", "Li Sun", "Siqiang Luo"], "title": "MoSE: Unveiling Structural Patterns in Graphs via Mixture of Subgraph Experts", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 11 figures", "summary": "While graph neural networks (GNNs) have achieved great success in learning\nfrom graph-structured data, their reliance on local, pairwise message passing\nrestricts their ability to capture complex, high-order subgraph patterns.\nleading to insufficient structural expressiveness. Recent efforts have\nattempted to enhance structural expressiveness by integrating random walk\nkernels into GNNs. However, these methods are inherently designed for\ngraph-level tasks, which limits their applicability to other downstream tasks\nsuch as node classification. Moreover, their fixed kernel configurations hinder\nthe model's flexibility in capturing diverse subgraph structures. To address\nthese limitations, this paper proposes a novel Mixture of Subgraph Experts\n(MoSE) framework for flexible and expressive subgraph-based representation\nlearning across diverse graph tasks. Specifically, MoSE extracts informative\nsubgraphs via anonymous walks and dynamically routes them to specialized\nexperts based on structural semantics, enabling the model to capture diverse\nsubgraph patterns with improved flexibility and interpretability. We further\nprovide a theoretical analysis of MoSE's expressivity within the Subgraph\nWeisfeiler-Lehman (SWL) Test, proving that it is more powerful than SWL.\nExtensive experiments, together with visualizations of learned subgraph\nexperts, demonstrate that MoSE not only outperforms competitive baselines but\nalso provides interpretable insights into structural patterns learned by the\nmodel.", "AI": {"tldr": "This paper introduces a novel framework called Mixture of Subgraph Experts (MoSE) to improve the flexibility and expressiveness of subgraph-based representation learning in graph neural networks (GNNs).", "motivation": "Existing graph neural networks (GNNs) rely on local message-passing schemes, which cannot fully capture high-order subgraph patterns due to insufficient structural expressiveness. Even recent methods using random walk kernels face limitations in flexibility and applicability to various graph tasks.", "method": "The authors propose the MoSE framework, which employs anonymous walks to extract subgraphs and dynamically routes them to specialized experts based on structural semantics. The framework is designed to capture diverse subgraph patterns with improved adaptability and interpretability.", "result": "MoSE demonstrates superior performance compared to competitive baselines in experiments. The model also provides interpretable visualizations that show how subgraph experts learn structural patterns. Theoretical analysis reveals that MoSE is more powerful than the Subgraph Weisfeiler-Lehman (SWL) test in terms of structural expressivity.", "conclusion": "The study concludes that MoSE extends the capabilities of GNNs by enhancing their structural expressiveness, flexibility, and interpretability, making it suitable for diverse tasks like node classification and other graph-level problems."}}
{"id": "2509.09629", "pdf": "https://arxiv.org/pdf/2509.09629", "abs": "https://arxiv.org/abs/2509.09629", "authors": ["Minghang Zhu", "Zhengliang Shi", "Zhiwei Xu", "Shiguang Wu", "Lingjie Wang", "Pengjie Ren", "Zhaochun Ren", "Zhumin Chen"], "title": "Bridging the Capability Gap: Joint Alignment Tuning for Harmonizing LLM-based Multi-Agent Systems", "categories": ["cs.CL"], "comment": "EMNLP 2025 Findings", "summary": "The advancement of large language models (LLMs) has enabled the construction\nof multi-agent systems to solve complex tasks by dividing responsibilities\namong specialized agents, such as a planning agent for subgoal generation and a\ngrounding agent for executing tool-use actions. Most existing methods typically\nfine-tune these agents independently, leading to capability gaps among them\nwith poor coordination. To address this, we propose MOAT, a Multi-Agent Joint\nAlignment Tuning framework that improves agents collaboration through iterative\nalignment. MOAT alternates between two key stages: (1) Planning Agent\nAlignment, which optimizes the planning agent to generate subgoal sequences\nthat better guide the grounding agent; and (2) Grounding Agent Improving, which\nfine-tunes the grounding agent using diverse subgoal-action pairs generated by\nthe agent itself to enhance its generalization capablity. Theoretical analysis\nproves that MOAT ensures a non-decreasing and progressively convergent training\nprocess. Experiments across six benchmarks demonstrate that MOAT outperforms\nstate-of-the-art baselines, achieving average improvements of 3.1% on held-in\ntasks and 4.4% on held-out tasks.", "AI": {"tldr": "The paper introduces MOAT, a framework for aligning multi-agent systems in solving complex tasks, which shows improved coordination between agents and performance gains.", "motivation": "Existing multi-agent systems fail to address coordination issues among agents when tuned independently, leading to capability gaps and ineffective task execution.", "method": "The authors propose MOAT, which alternates between optimizing a planning agent to guide a grounding agent and fine-tuning the grounding agent with diverse subgoal-action pairs to improve collaboration.", "result": "The framework achieves an average improvement of 3.1% on held-in tasks and 4.4% on held-out tasks across six benchmarks, outperforming state-of-the-art methods.", "conclusion": "Iterative alignment in multi-agent systems via MOAT enhances collaboration, ensuring non-decreasing training efficiency and better generalization, addressing existing coordination problems."}}
{"id": "2509.09183", "pdf": "https://arxiv.org/pdf/2509.09183", "abs": "https://arxiv.org/abs/2509.09183", "authors": ["Jiasheng Guo", "Xin Gao", "Yuxiang Yan", "Guanghao Li", "Jian Pu"], "title": "Dark-ISP: Enhancing RAW Image Processing for Low-Light Object Detection", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 6 figures, conference", "summary": "Low-light Object detection is crucial for many real-world applications but\nremains challenging due to degraded image quality. While recent studies have\nshown that RAW images offer superior potential over RGB images, existing\napproaches either use RAW-RGB images with information loss or employ complex\nframeworks. To address these, we propose a lightweight and self-adaptive Image\nSignal Processing (ISP) plugin, Dark-ISP, which directly processes Bayer RAW\nimages in dark environments, enabling seamless end-to-end training for object\ndetection. Our key innovations are: (1) We deconstruct conventional ISP\npipelines into sequential linear (sensor calibration) and nonlinear (tone\nmapping) sub-modules, recasting them as differentiable components optimized\nthrough task-driven losses. Each module is equipped with content-aware\nadaptability and physics-informed priors, enabling automatic RAW-to-RGB\nconversion aligned with detection objectives. (2) By exploiting the ISP\npipeline's intrinsic cascade structure, we devise a Self-Boost mechanism that\nfacilitates cooperation between sub-modules. Through extensive experiments on\nthree RAW image datasets, we demonstrate that our method outperforms\nstate-of-the-art RGB- and RAW-based detection approaches, achieving superior\nresults with minimal parameters in challenging low-light environments.", "AI": {"tldr": "This paper introduces Dark-ISP, a lightweight ISP plugin that processes Bayer RAW images for improved low-light object detection, outperforming existing methods.", "motivation": "The paper seeks to enhance object detection in low-light conditions by tackling the challenges of degraded image quality and inefficiency in existing RAW image-based approaches.", "method": "Dark-ISP leverages a deconstructed ISP pipeline with linear and nonlinear modules, optimized through task-driven losses and equipped with content-aware adaptability and physics-informed priors. It also includes a Self-Boost mechanism for module cooperation.", "result": "Extensive experiments across three RAW image datasets show that Dark-ISP surpasses state-of-the-art methods in low-light object detection while remaining parameter-efficient.", "conclusion": "The proposed Dark-ISP plugin effectively improves low-light object detection through an innovative and efficient framework, making it suitable for real-world applications."}}
{"id": "2509.09380", "pdf": "https://arxiv.org/pdf/2509.09380", "abs": "https://arxiv.org/abs/2509.09380", "authors": ["Luca Giuliani", "Michele Lombardi"], "title": "Robust Non-Linear Correlations via Polynomial Regression", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "comment": null, "summary": "The Hirschfeld-Gebelein-R\\'enyi (HGR) correlation coefficient is an extension\nof Pearson's correlation that is not limited to linear correlations, with\npotential applications in algorithmic fairness, scientific analysis, and causal\ndiscovery. Recently, novel algorithms to estimate HGR in a differentiable\nmanner have been proposed to facilitate its use as a loss regularizer in\nconstrained machine learning applications. However, the inherent\nuncomputability of HGR requires a bias-variance trade-off, which can possibly\ncompromise the robustness of the proposed methods, hence raising technical\nconcerns if applied in real-world scenarios. We introduce a novel computational\napproach for HGR that relies on user-configurable polynomial kernels, offering\ngreater robustness compared to previous methods and featuring a faster yet\nalmost equally effective restriction. Our approach provides significant\nadvantages in terms of robustness and determinism, making it a more reliable\noption for real-world applications. Moreover, we present a brief experimental\nanalysis to validate the applicability of our approach within a constrained\nmachine learning framework, showing that its computation yields an insightful\nsubgradient that can serve as a loss regularizer.", "AI": {"tldr": "The paper introduces a novel, robust approach for computing the Hirschfeld-Gebelein-R\u00e9nyi (HGR) correlation coefficient using polynomial kernels, addressing the limitations of existing methods.", "motivation": "There is a need for a reliable method to compute the HGR correlation for broader applications like fairness in algorithms and causal discovery without compromising robustness and real-world applicability.", "method": "A new computational approach based on user-configurable polynomial kernels for HGR correlation calculation, improving robustness and speed while maintaining effectiveness.", "result": "The approach demonstrated robustness, determinism, and superior applicability in constrained machine learning, providing an effective subgradient for loss regularization.", "conclusion": "The proposed method offers a reliable and advantageous alternative to existing HGR computation techniques, suitable for practical, real-world deployment."}}
{"id": "2509.09650", "pdf": "https://arxiv.org/pdf/2509.09650", "abs": "https://arxiv.org/abs/2509.09650", "authors": ["Siddarth Mamidanna", "Daking Rai", "Ziyu Yao", "Yilun Zhou"], "title": "All for One: LLMs Solve Mental Math at the Last Token With Information Transferred From Other Tokens", "categories": ["cs.CL", "I.2.7"], "comment": "EMNLP 2025 Main Conference", "summary": "Large language models (LLMs) demonstrate proficiency across numerous\ncomputational tasks, yet their inner workings remain unclear. In theory, the\ncombination of causal self-attention and multilayer perceptron layers allows\nevery token to access and compute information based on all preceding tokens. In\npractice, to what extent are such operations present? In this paper, on mental\nmath tasks (i.e., direct math calculation via next-token prediction without\nexplicit reasoning), we investigate this question in three steps: inhibiting\ninput-specific token computations in the initial layers, restricting the routes\nof information transfer across token positions in the next few layers, and\nforcing all computation to happen at the last token in the remaining layers.\nWith two proposed techniques, Context-Aware Mean Ablation (CAMA) and\nAttention-Based Peeking (ABP), we identify an All-for-One subgraph (AF1) with\nhigh accuracy on a wide variety of mental math tasks, where meaningful\ncomputation occurs very late (in terms of layer depth) and only at the last\ntoken, which receives information of other tokens in few specific middle\nlayers. Experiments on a variety of models and arithmetic expressions show that\nthis subgraph is sufficient and necessary for high model performance, transfers\nacross different models, and works on a variety of input styles. Ablations on\ndifferent CAMA and ABP alternatives reveal their unique advantages over other\nmethods, which may be of independent interest.", "AI": {"tldr": "This paper studies how computations for mental math tasks occur in LLMs using techniques like Context-Aware Mean Ablation (CAMA) and Attention-Based Peeking (ABP), identifying a crucial computational subgraph.", "motivation": "The motivation is to understand how computations within large language models (LLMs) work during direct math calculation tasks, as their precise inner workings remain unclear despite their demonstrated proficiency.", "method": "The study uses mental math tasks and introduces techniques like CAMA and ABP to inhibit, restrict, and focus token computations at different layers within LLMs to identify computation patterns.", "result": "An All-for-One subgraph (AF1) was identified as both necessary and sufficient for high-performance mental math tasks; meaningful computation occurs late in the layers and is focused at the final token, involving specific middle layers.", "conclusion": "Key computational paths for mental math tasks in LLMs were revealed, demonstrating that the identified AF1 subgraph is transferable and effective across models with various input styles while outperforming other computation-restriction methods."}}
{"id": "2509.09190", "pdf": "https://arxiv.org/pdf/2509.09190", "abs": "https://arxiv.org/abs/2509.09190", "authors": ["Hanwei Zhu", "Haoning Wu", "Zicheng Zhang", "Lingyu Zhu", "Yixuan Li", "Peilin Chen", "Shiqi Wang", "Chris Wei Zhou", "Linhan Cao", "Wei Sun", "Xiangyang Zhu", "Weixia Zhang", "Yucheng Zhu", "Jing Liu", "Dandan Zhu", "Guangtao Zhai", "Xiongkuo Min", "Zhichao Zhang", "Xinyue Li", "Shubo Xu", "Anh Dao", "Yifan Li", "Hongyuan Yu", "Jiaojiao Yi", "Yiding Tian", "Yupeng Wu", "Feiran Sun", "Lijuan Liao", "Song Jiang"], "title": "VQualA 2025 Challenge on Visual Quality Comparison for Large Multimodal Models: Methods and Results", "categories": ["cs.CV"], "comment": "ICCV VQualA Workshop 2025", "summary": "This paper presents a summary of the VQualA 2025 Challenge on Visual Quality\nComparison for Large Multimodal Models (LMMs), hosted as part of the ICCV 2025\nWorkshop on Visual Quality Assessment. The challenge aims to evaluate and\nenhance the ability of state-of-the-art LMMs to perform open-ended and detailed\nreasoning about visual quality differences across multiple images. To this end,\nthe competition introduces a novel benchmark comprising thousands of\ncoarse-to-fine grained visual quality comparison tasks, spanning single images,\npairs, and multi-image groups. Each task requires models to provide accurate\nquality judgments. The competition emphasizes holistic evaluation protocols,\nincluding 2AFC-based binary preference and multi-choice questions (MCQs).\nAround 100 participants submitted entries, with five models demonstrating the\nemerging capabilities of instruction-tuned LMMs on quality assessment. This\nchallenge marks a significant step toward open-domain visual quality reasoning\nand comparison and serves as a catalyst for future research on interpretable\nand human-aligned quality evaluation systems.", "AI": {"tldr": "This paper summarizes the VQualA 2025 Challenge, which evaluated large multimodal models (LMMs) on visual quality reasoning across diverse tasks.", "motivation": "The paper aims to advance the ability of LMMs to reason about visual quality differences in a nuanced, open-domain context.", "method": "The authors introduced a benchmark of visual quality comparison tasks involving single, paired, and multi-image groups, emphasizing binary preference and multiple-choice questions for holistic evaluations.", "result": "Five models showcased emerging capabilities in instruction-tuned LMMs, with entries from around 100 participants in the challenge.", "conclusion": "The challenge represents progress in visual quality assessment, fostering innovation in interpretable and human-aligned evaluation models."}}
{"id": "2509.09387", "pdf": "https://arxiv.org/pdf/2509.09387", "abs": "https://arxiv.org/abs/2509.09387", "authors": ["Mohammed Tiouti", "Mohamed Bal-Ghaoui"], "title": "MetaLLMix : An XAI Aided LLM-Meta-learning Based Approach for Hyper-parameters Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Effective model and hyperparameter selection remains a major challenge in\ndeep learning, often requiring extensive expertise and computation. While\nAutoML and large language models (LLMs) promise automation, current LLM-based\napproaches rely on trial and error and expensive APIs, which provide limited\ninterpretability and generalizability. We propose MetaLLMiX, a zero-shot\nhyperparameter optimization framework combining meta-learning, explainable AI,\nand efficient LLM reasoning. By leveraging historical experiment outcomes with\nSHAP explanations, MetaLLMiX recommends optimal hyperparameters and pretrained\nmodels without additional trials. We further employ an LLM-as-judge evaluation\nto control output format, accuracy, and completeness. Experiments on eight\nmedical imaging datasets using nine open-source lightweight LLMs show that\nMetaLLMiX achieves competitive or superior performance to traditional HPO\nmethods while drastically reducing computational cost. Our local deployment\noutperforms prior API-based approaches, achieving optimal results on 5 of 8\ntasks, response time reductions of 99.6-99.9%, and the fastest training times\non 6 datasets (2.4-15.7x faster), maintaining accuracy within 1-5% of\nbest-performing baselines.", "AI": {"tldr": "MetaLLMiX presents a zero-shot hyperparameter optimization framework utilizing meta-learning, explainable AI, and efficient LLM reasoning to tackle challenges in deep learning hyperparameter selection, achieving significant cost and time savings while maintaining competitive accuracy.", "motivation": "Deep learning model and hyperparameter selection are notoriously resource-intensive and often require substantial expertise, which limits accessibility and efficiency. Current automated approaches, like AutoML and LLM-based methods, face a lack of interpretability and generalizability.", "method": "The paper introduces MetaLLMiX, which leverages meta-learning and SHAP-based explanations of historical experimental data for hyperparameter recommendation. It integrates local LLM-based reasoning and introduces an LLM-as-judge evaluation to ensure quality control in format, accuracy, and completeness.", "result": "MetaLLMiX achieves comparable or better performance than traditional hyperparameter optimization methods, with drastic reductions in computational cost and response times (99.6%-99.9%). It provides fast training speeds (2.4-15.7x faster on specific datasets) and accuracy within 1-5% of the best-performing baselines.", "conclusion": "MetaLLMiX effectively reduces resource consumption and training time while delivering competitive or superior performance in hyperparameter optimization for deep learning applications. It outperforms prior API-based approaches in multiple tasks with local deployment benefits."}}
{"id": "2509.09660", "pdf": "https://arxiv.org/pdf/2509.09660", "abs": "https://arxiv.org/abs/2509.09660", "authors": ["Mohsen Fayyaz", "Ali Modarressi", "Hanieh Deilamsalehy", "Franck Dernoncourt", "Ryan Rossi", "Trung Bui", "Hinrich Sch\u00fctze", "Nanyun Peng"], "title": "Steering MoE LLMs via Expert (De)Activation", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Mixture-of-Experts (MoE) in Large Language Models (LLMs) routes each token\nthrough a subset of specialized Feed-Forward Networks (FFN), known as experts.\nWe present SteerMoE, a framework for steering MoE models by detecting and\ncontrolling behavior-linked experts. Our detection method identifies experts\nwith distinct activation patterns across paired inputs exhibiting contrasting\nbehaviors. By selectively (de)activating such experts during inference, we\ncontrol behaviors like faithfulness and safety without retraining or modifying\nweights. Across 11 benchmarks and 6 LLMs, our steering raises safety by up to\n+20% and faithfulness by +27%. In adversarial attack mode, it drops safety by\n-41% alone, and -100% when combined with existing jailbreak methods, bypassing\nall safety guardrails and exposing a new dimension of alignment faking hidden\nwithin experts.", "AI": {"tldr": "The paper introduces SteerMoE, a framework for controlling behaviors in Mixture-of-Experts models by selectively activating or deactivating specialized components, achieving significant improvements in faithfulness and safety without retraining.", "motivation": "To address challenges in controlling the behavior of Mixture-of-Experts models within Large Language Models, particularly concerning faithfulness and safety during inference.", "method": "SteerMoE framework detects experts with specific activation patterns and strategically activates or deactivates them during inference to steer model behaviors.", "result": "Using SteerMoE, improvements include up to +20% in safety, +27% in faithfulness, and refined behavior control in adversarial contexts, effectively revealing vulnerabilities in alignment mechanisms.", "conclusion": "SteerMoE unlocks the potential to adjust expert-linked behaviors, offering a tool both for enhancing and critically assessing model alignment and safety frameworks."}}
{"id": "2509.09200", "pdf": "https://arxiv.org/pdf/2509.09200", "abs": "https://arxiv.org/abs/2509.09200", "authors": ["Ge Sun", "Jun Ma"], "title": "MGTraj: Multi-Granularity Goal-Guided Human Trajectory Prediction with Recursive Refinement Network", "categories": ["cs.CV"], "comment": null, "summary": "Accurate human trajectory prediction is crucial for robotics navigation and\nautonomous driving. Recent research has demonstrated that incorporating goal\nguidance significantly enhances prediction accuracy by reducing uncertainty and\nleveraging prior knowledge. Most goal-guided approaches decouple the prediction\ntask into two stages: goal prediction and subsequent trajectory completion\nbased on the predicted goal, which operate at extreme granularities:\ncoarse-grained goal prediction forecasts the overall intention, while\nfine-grained trajectory completion needs to generate the positions for all\nfuture timesteps. The potential utility of intermediate temporal granularity\nremains largely unexplored, which motivates multi-granularity trajectory\nmodeling. While prior work has shown that multi-granularity representations\ncapture diverse scales of human dynamics and motion patterns, effectively\nintegrating this concept into goal-guided frameworks remains challenging. In\nthis paper, we propose MGTraj, a novel Multi-Granularity goal-guided model for\nhuman Trajectory prediction. MGTraj recursively encodes trajectory proposals\nfrom coarse to fine granularity levels. At each level, a transformer-based\nrecursive refinement network (RRN) captures features and predicts progressive\nrefinements. Features across different granularities are integrated using a\nweight-sharing strategy, and velocity prediction is employed as an auxiliary\ntask to further enhance performance. Comprehensive experimental results in\nEHT/UCY and Stanford Drone Dataset indicate that MGTraj outperforms baseline\nmethods and achieves state-of-the-art performance among goal-guided methods.", "AI": {"tldr": "The paper introduces MGTraj, a multi-granularity goal-guided model for human trajectory prediction using recursive refinement networks and velocity prediction, showing superior performance in benchmark datasets.", "motivation": "Traditional goal-guided approaches in human trajectory prediction focus on coarse and fine levels, neglecting intermediate granularity, which has potential to boost accuracy.", "method": "MGTraj uses recursive encoding across granularities with a transformer-based refinement network, integrates features via weight-sharing, and complements prediction with a velocity-based auxiliary task.", "result": "MGTraj demonstrated state-of-the-art performance on benchmark datasets like EHT/UCY and the Stanford Drone Dataset compared to baseline methods.", "conclusion": "MGTraj proves that leveraging multi-granularity modeling in goal-guided frameworks can enhance prediction accuracy and capture diverse human dynamics effectively, pushing the boundaries of current techniques."}}
{"id": "2509.09396", "pdf": "https://arxiv.org/pdf/2509.09396", "abs": "https://arxiv.org/abs/2509.09396", "authors": ["Harry Mayne", "Ryan Othniel Kearns", "Yushi Yang", "Andrew M. Bean", "Eoin Delaney", "Chris Russell", "Adam Mahdi"], "title": "LLMs Don't Know Their Own Decision Boundaries: The Unreliability of Self-Generated Counterfactual Explanations", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted to EMNLP 2025 Main", "summary": "To collaborate effectively with humans, language models must be able to\nexplain their decisions in natural language. We study a specific type of\nself-explanation: self-generated counterfactual explanations (SCEs), where a\nmodel explains its prediction by modifying the input such that it would have\npredicted a different outcome. We evaluate whether LLMs can produce SCEs that\nare valid, achieving the intended outcome, and minimal, modifying the input no\nmore than necessary. When asked to generate counterfactuals, we find that LLMs\ntypically produce SCEs that are valid, but far from minimal, offering little\ninsight into their decision-making behaviour. Worryingly, when asked to\ngenerate minimal counterfactuals, LLMs typically make excessively small edits\nthat fail to change predictions. The observed validity-minimality trade-off is\nconsistent across several LLMs, datasets, and evaluation settings. Our findings\nsuggest that SCEs are, at best, an ineffective explainability tool and, at\nworst, can provide misleading insights into model behaviour. Proposals to\ndeploy LLMs in high-stakes settings must consider the impact of unreliable\nself-explanations on downstream decision-making. Our code is available at\nhttps://github.com/HarryMayne/SCEs.", "AI": {"tldr": "This paper investigates how effectively language models can produce self-generated counterfactual explanations (SCEs) to explain their decisions, revealing limitations in their validity and minimality when generating such counterfactuals.", "motivation": "The study aims to evaluate language models' potential to provide self-explanations through counterfactual reasoning, crucial for transparent decision-making in human-AI collaboration, especially in high-stakes scenarios.", "method": "The authors analyze the ability of large language models (LLMs) to generate SCEs that balance two properties: validity (achieving the intended change in prediction) and minimality (making the smallest possible modification). They test across multiple models, datasets, and settings.", "result": "LLMs can generate valid SCEs but fail to meet minimality requirements. When aiming for minimality, the generated counterfactuals often do not change predictions. This validity-minimality trade-off highlights significant shortcomings in their explainability.", "conclusion": "SCEs do not offer reliable insight into model behavior and could be misleading. This raises concerns about using LLMs in critical applications, emphasizing the importance of addressing explainability pitfalls."}}
{"id": "2509.09675", "pdf": "https://arxiv.org/pdf/2509.09675", "abs": "https://arxiv.org/abs/2509.09675", "authors": ["Runpeng Dai", "Linfeng Song", "Haolin Liu", "Zhenwen Liang", "Dian Yu", "Haitao Mi", "Zhaopeng Tu", "Rui Liu", "Tong Zheng", "Hongtu Zhu", "Dong Yu"], "title": "CDE: Curiosity-Driven Exploration for Efficient Reinforcement Learning in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "21 pages", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) is a powerful paradigm\nfor enhancing the reasoning ability of Large Language Models (LLMs). Yet\ncurrent RLVR methods often explore poorly, leading to premature convergence and\nentropy collapse. To address this challenge, we introduce Curiosity-Driven\nExploration (CDE), a framework that leverages the model's own intrinsic sense\nof curiosity to guide exploration. We formalize curiosity with signals from\nboth the actor and the critic: for the actor, we use perplexity over its\ngenerated response, and for the critic, we use the variance of value estimates\nfrom a multi-head architecture. Both signals serve as an exploration bonus\nwithin the RLVR framework to guide the model. Our theoretical analysis shows\nthat the actor-wise bonus inherently penalizes overconfident errors and\npromotes diversity among correct responses; moreover, we connect the\ncritic-wise bonus to the well-established count-based exploration bonus in RL.\nEmpirically, our method achieves an approximate +3 point improvement over\nstandard RLVR using GRPO/PPO on AIME benchmarks. Further analysis identifies a\ncalibration collapse mechanism within RLVR, shedding light on common LLM\nfailure modes.", "AI": {"tldr": "The paper introduces Curiosity-Driven Exploration (CDE) to improve exploration in Reinforcement Learning with Verifiable Rewards (RLVR) applied to Large Language Models (LLMs), addressing issues such as entropy collapse and premature convergence.", "motivation": "Current RLVR methods for enhancing LLM reasoning suffer from poor exploration, leading to issues like premature convergence and entropy collapse.", "method": "The proposed CDE framework uses intrinsic curiosity signals derived from the actor's perplexity and the critic's value-estimate variance to guide exploration bonuses within RLVR.", "result": "CDE showed an approximate +3 point improvement in performance on AIME benchmarks, outperforming standard RLVR methods like GRPO/PPO.", "conclusion": "Using curiosity signals for exploration effectively addresses RLVR failures and enhances LLM reasoning, providing better insights into LLM calibration issues and failure modes."}}
{"id": "2509.09232", "pdf": "https://arxiv.org/pdf/2509.09232", "abs": "https://arxiv.org/abs/2509.09232", "authors": ["Jiesi Hu", "Jianfeng Cao", "Yanwu Yang", "Chenfei Ye", "Yixuan Zhang", "Hanyang Peng", "Ting Ma"], "title": "Medverse: A Universal Model for Full-Resolution 3D Medical Image Segmentation, Transformation and Enhancement", "categories": ["cs.CV"], "comment": null, "summary": "In-context learning (ICL) offers a promising paradigm for universal medical\nimage analysis, enabling models to perform diverse image processing tasks\nwithout retraining. However, current ICL models for medical imaging remain\nlimited in two critical aspects: they cannot simultaneously achieve\nhigh-fidelity predictions and global anatomical understanding, and there is no\nunified model trained across diverse medical imaging tasks (e.g., segmentation\nand enhancement) and anatomical regions. As a result, the full potential of ICL\nin medical imaging remains underexplored. Thus, we present \\textbf{Medverse}, a\nuniversal ICL model for 3D medical imaging, trained on 22 datasets covering\ndiverse tasks in universal image segmentation, transformation, and enhancement\nacross multiple organs, imaging modalities, and clinical centers. Medverse\nemploys a next-scale autoregressive in-context learning framework that\nprogressively refines predictions from coarse to fine, generating consistent,\nfull-resolution volumetric outputs and enabling multi-scale anatomical\nawareness. We further propose a blockwise cross-attention module that\nfacilitates long-range interactions between context and target inputs while\npreserving computational efficiency through spatial sparsity. Medverse is\nextensively evaluated on a broad collection of held-out datasets covering\npreviously unseen clinical centers, organs, species, and imaging modalities.\nResults demonstrate that Medverse substantially outperforms existing ICL\nbaselines and establishes a novel paradigm for in-context learning. Code and\nmodel weights will be made publicly available. Our model are publicly available\nat https://github.com/jiesihu/Medverse.", "AI": {"tldr": "Medverse introduces a universal in-context learning (ICL) model for 3D medical imaging, addressing challenges in achieving high-quality predictions while incorporating diverse tasks and global anatomical understanding.", "motivation": "Existing ICL models for medical imaging struggle with balancing high-fidelity predictions and global anatomical understanding, and lack a unified approach for handling diverse tasks across varied datasets.", "method": "Medverse uses a next-scale autoregressive ICL framework for progressive refinement and incorporates a blockwise cross-attention module for efficient long-range interactions in 3D medical imaging tasks.", "result": "Medverse outperformed existing ICL baselines across unseen clinical centers, organs, imaging modalities, and species while enhancing universal segmentation, transformation, and enhancement capabilities.", "conclusion": "Medverse demonstrates its capability as a robust universal ICL model for medical imaging, setting a new benchmark and paving the way for further exploration in medical image processing without retraining."}}
{"id": "2509.09408", "pdf": "https://arxiv.org/pdf/2509.09408", "abs": "https://arxiv.org/abs/2509.09408", "authors": ["Jonas Schmidinger", "Viacheslav Barkov", "Sebastian Vogel", "Martin Atzmueller", "Gerard B M Heuvelink"], "title": "Kriging prior Regression: A Case for Kriging-Based Spatial Features with TabPFN in Soil Mapping", "categories": ["cs.LG"], "comment": null, "summary": "Machine learning and geostatistics are two fundamentally different frameworks\nfor predicting and spatially mapping soil properties. Geostatistics leverages\nthe spatial structure of soil properties, while machine learning captures the\nrelationship between available environmental features and soil properties. We\npropose a hybrid framework that enriches ML with spatial context through\nengineering of 'spatial lag' features from ordinary kriging. We call this\napproach 'kriging prior regression' (KpR), as it follows the inverse logic of\nregression kriging. To evaluate this approach, we assessed both the point and\nprobabilistic prediction performance of KpR, using the TabPFN model across six\nfieldscale datasets from LimeSoDa. These datasets included soil organic carbon,\nclay content, and pH, along with features derived from remote sensing and\nin-situ proximal soil sensing. KpR with TabPFN demonstrated reliable\nuncertainty estimates and more accurate predictions in comparison to several\nother spatial techniques (e.g., regression/residual kriging with TabPFN), as\nwell as to established non-spatial machine learning algorithms (e.g., random\nforest). Most notably, it significantly improved the average R2 by around 30%\ncompared to machine learning algorithms without spatial context. This\nimprovement was due to the strong prediction performance of the TabPFN\nalgorithm itself and the complementary spatial information provided by KpR\nfeatures. TabPFN is particularly effective for prediction tasks with small\nsample sizes, common in precision agriculture, whereas KpR can compensate for\nweak relationships between sensing features and soil properties when proximal\nsoil sensing data are limited. Hence, we conclude that KpR with TabPFN is a\nvery robust and versatile modelling framework for digital soil mapping in\nprecision agriculture.", "AI": {"tldr": "The paper proposes a hybrid framework, 'kriging prior regression' (KpR), combining geostatistics and machine learning for improved spatial prediction of soil properties.", "motivation": "To address the limitations of geostatistics and machine learning in spatially mapping soil properties, particularly the need for accurate predictions and uncertainty estimates.", "method": "A hybrid approach was developed that incorporates 'spatial lag' features derived from ordinary kriging into machine learning models, specifically using the TabPFN algorithm.", "result": "KpR with TabPFN achieved a 30% average R2 improvement over non-spatial machine learning algorithms and demonstrated reliable uncertainty estimates across six soil datasets.", "conclusion": "KpR with TabPFN is a robust and versatile framework for digital soil mapping, particularly effective in settings with small datasets or weak sensing feature relationships, making it valuable for precision agriculture."}}
{"id": "2509.09018", "pdf": "https://arxiv.org/pdf/2509.09018", "abs": "https://arxiv.org/abs/2509.09018", "authors": ["Xueyi Wang", "C. J. C.", "Lamoth", "Elisabeth Wilhelm"], "title": "Personalized Sleep Prediction via Deep Adaptive Spatiotemporal Modeling and Sparse Data", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "The paper has been acceptted and presented in the 47th Annual\n  International Conference of the IEEE Engineering in Medicine and Biology\n  Society", "summary": "A sleep forecast allows individuals and healthcare providers to anticipate\nand proactively address factors influencing restful rest, ultimately improving\nmental and physical well-being. This work presents an adaptive spatial and\ntemporal model (AdaST-Sleep) for predicting sleep scores. Our proposed model\ncombines convolutional layers to capture spatial feature interactions between\nmultiple features and recurrent neural network layers to handle longer-term\ntemporal health-related data. A domain classifier is further integrated to\ngeneralize across different subjects. We conducted several experiments using\nfive input window sizes (3, 5, 7, 9, 11 days) and five predicting window sizes\n(1, 3, 5, 7, 9 days). Our approach consistently outperformed four baseline\nmodels, achieving its lowest RMSE (0.282) with a seven-day input window and a\none-day predicting window. Moreover, the method maintained strong performance\neven when forecasting multiple days into the future, demonstrating its\nversatility for real-world applications. Visual comparisons reveal that the\nmodel accurately tracks both the overall sleep score level and daily\nfluctuations. These findings prove that the proposed framework provides a\nrobust and adaptable solution for personalized sleep forecasting using sparse\ndata from commercial wearable devices and domain adaptation techniques.", "AI": {"tldr": "This paper introduces the AdaST-Sleep model for personalized sleep forecasting, leveraging both spatial and temporal data interactions and demonstrating high predictive accuracy.", "motivation": "To create a personalized and accurate model for sleep forecasting that can assist individuals and healthcare providers in improving well-being.", "method": "The model combines convolutional layers (spatial features), recurrent neural networks (temporal data), and a domain classifier to make it generalized across various subjects. Multiple input and prediction window sizes were tested.", "result": "The model outperformed four baseline models, achieving an RMSE of 0.282 (seven-day input, one-day predicting) and demonstrated reliable multi-day forecasting.", "conclusion": "AdaST-Sleep provides a robust solution for sleep forecasting, effectively using sparse wearable device data and adapting well across different users."}}
{"id": "2509.09242", "pdf": "https://arxiv.org/pdf/2509.09242", "abs": "https://arxiv.org/abs/2509.09242", "authors": ["Mustafa Yurdakul", "Sakir Tasdemir"], "title": "CoAtNeXt:An Attention-Enhanced ConvNeXtV2-Transformer Hybrid Model for Gastric Tissue Classification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Background and objective Early diagnosis of gastric diseases is crucial to\nprevent fatal outcomes. Although histopathologic examination remains the\ndiagnostic gold standard, it is performed entirely manually, making evaluations\nlabor-intensive and prone to variability among pathologists. Critical findings\nmay be missed, and lack of standard procedures reduces consistency. These\nlimitations highlight the need for automated, reliable, and efficient methods\nfor gastric tissue analysis. Methods In this study, a novel hybrid model named\nCoAtNeXt was proposed for the classification of gastric tissue images. The\nmodel is built upon the CoAtNet architecture by replacing its MBConv layers\nwith enhanced ConvNeXtV2 blocks. Additionally, the Convolutional Block\nAttention Module (CBAM) is integrated to improve local feature extraction\nthrough channel and spatial attention mechanisms. The architecture was scaled\nto achieve a balance between computational efficiency and classification\nperformance. CoAtNeXt was evaluated on two publicly available datasets,\nHMU-GC-HE-30K for eight-class classification and GasHisSDB for binary\nclassification, and was compared against 10 Convolutional Neural Networks\n(CNNs) and ten Vision Transformer (ViT) models. Results CoAtNeXt achieved\n96.47% accuracy, 96.60% precision, 96.47% recall, 96.45% F1 score, and 99.89%\nAUC on HMU-GC-HE-30K. On GasHisSDB, it reached 98.29% accuracy, 98.07%\nprecision, 98.41% recall, 98.23% F1 score, and 99.90% AUC. It outperformed all\nCNN and ViT models tested and surpassed previous studies in the literature.\nConclusion Experimental results show that CoAtNeXt is a robust architecture for\nhistopathological classification of gastric tissue images, providing\nperformance on binary and multiclass. Its highlights its potential to assist\npathologists by enhancing diagnostic accuracy and reducing workload.", "AI": {"tldr": "The study presents CoAtNeXt, a novel hybrid model for classifying gastric tissue images, achieving superior accuracy and efficiency compared to existing methods.", "motivation": "Manual histopathologic analysis of gastric tissues is labor-intensive, prone to variability, and lacks standard procedures. This paper aims to address these limitations by proposing automated methods.", "method": "The proposed CoAtNeXt model combines CoAtNet architecture, enhanced ConvNeXtV2 blocks, and CBAM for better feature extraction. It was tested on two datasets for eight-class and binary classification, compared to CNNs and ViT models.", "result": "CoAtNeXt demonstrated high performance: 96-98% accuracy, precision, recall, F1 score, and nearly perfect AUC on both datasets, outperforming other models and prior studies.", "conclusion": "CoAtNeXt's robust performance indicates its potential to assist pathologists in gastric tissue analysis, improving diagnostic accuracy and reducing the workload."}}
{"id": "2509.09413", "pdf": "https://arxiv.org/pdf/2509.09413", "abs": "https://arxiv.org/abs/2509.09413", "authors": ["Daniel Agyapong", "Briana H. Beatty", "Peter G. Kennedy", "Toby D. Hocking"], "title": "Fused Lasso Improves Accuracy of Co-occurrence Network Inference in Grouped Samples", "categories": ["cs.LG", "q-bio.PE"], "comment": null, "summary": "Co-occurrence network inference algorithms have significantly advanced our\nunderstanding of microbiome communities. However, these algorithms typically\nanalyze microbial associations within samples collected from a single\nenvironmental niche, often capturing only static snapshots rather than dynamic\nmicrobial processes. Previous studies have commonly grouped samples from\ndifferent environmental niches together without fully considering how microbial\ncommunities adapt their associations when faced with varying ecological\nconditions. Our study addresses this limitation by explicitly investigating\nboth spatial and temporal dynamics of microbial communities. We analyzed\npublicly available microbiome abundance data across multiple locations and time\npoints, to evaluate algorithm performance in predicting microbial associations\nusing our proposed Same-All Cross-validation (SAC) framework. SAC evaluates\nalgorithms in two distinct scenarios: training and testing within the same\nenvironmental niche (Same), and training and testing on combined data from\nmultiple environmental niches (All). To overcome the limitations of\nconventional algorithms, we propose fuser, an algorithm that, while not\nentirely new in machine learning, is novel for microbiome community network\ninference. It retains subsample-specific signals while simultaneously sharing\nrelevant information across environments during training. Unlike standard\napproaches that infer a single generalized network from combined data, fuser\ngenerates distinct, environment-specific predictive networks. Our results\ndemonstrate that fuser achieves comparable predictive performance to existing\nalgorithms such as glmnet when evaluated within homogeneous environments\n(Same), and notably reduces test error compared to baseline algorithms in\ncross-environment (All) scenarios.", "AI": {"tldr": "The paper introduces 'fuser,' an algorithm for microbiome community network inference that considers spatial and temporal dynamics, outperforming existing methods in cross-environment scenarios.", "motivation": "To address the limitations of microbiome network algorithms, which often ignore the dynamics of microbial communities adapting to varied ecological conditions and rely on static or single-environment analyses.", "method": "The study introduces the Same-All Cross-validation (SAC) framework for evaluating algorithm performance and proposes 'fuser,' an algorithm that preserves environment-specific signals while integrating shared information across niches.", "result": "The proposed 'fuser' algorithm shows comparable performance to existing methods in single-environment evaluations (Same) and significantly better performance in cross-environment analyses (All).", "conclusion": "'Fuser' offers an effective and innovative approach for analyzing microbiome networks under varying ecological conditions by generating environment-specific predictive networks, addressing limitations in current methods and improving predictive accuracy."}}
{"id": "2509.09037", "pdf": "https://arxiv.org/pdf/2509.09037", "abs": "https://arxiv.org/abs/2509.09037", "authors": ["Amanda Aird", "Ben Armstrong", "Nicholas Mattei", "Robin Burke"], "title": "Envy-Free but Still Unfair: Envy-Freeness Up To One Item (EF-1) in Personalized Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Envy-freeness and the relaxation to Envy-freeness up to one item (EF-1) have\nbeen used as fairness concepts in the economics, game theory, and social choice\nliteratures since the 1960s, and have recently gained popularity within the\nrecommendation systems communities. In this short position paper we will give\nan overview of envy-freeness and its use in economics and recommendation\nsystems; and illustrate why envy is not appropriate to measure fairness for use\nin settings where personalization plays a role.", "AI": {"tldr": "The paper discusses envy-freeness (EF) in economics and recommendation systems, questioning its suitability in personalized settings.", "motivation": "To explore and critique the appropriateness of envy-freeness as a fairness metric in personalized settings, such as recommendation systems.", "method": "The study overviews the concept of envy-freeness and examines its applications in economics and recommendation systems.", "result": "The authors argue that envy, as a measure of fairness, may not align well with scenarios involving personalization.", "conclusion": "Envy-freeness, while popular in various fields, may not be suitable for measuring fairness in personalized contexts."}}
{"id": "2509.09254", "pdf": "https://arxiv.org/pdf/2509.09254", "abs": "https://arxiv.org/abs/2509.09254", "authors": ["Jing Hao", "Yuxuan Fan", "Yanpeng Sun", "Kaixin Guo", "Lizhuo Lin", "Jinrong Yang", "Qi Yong H. Ai", "Lun M. Wong", "Hao Tang", "Kuo Feng Hung"], "title": "Towards Better Dental AI: A Multimodal Benchmark and Instruction Dataset for Panoramic X-ray Analysis", "categories": ["cs.CV", "cs.MM"], "comment": "40 pages, 26 figures, 9 tables", "summary": "Recent advances in large vision-language models (LVLMs) have demonstrated\nstrong performance on general-purpose medical tasks. However, their\neffectiveness in specialized domains such as dentistry remains underexplored.\nIn particular, panoramic X-rays, a widely used imaging modality in oral\nradiology, pose interpretative challenges due to dense anatomical structures\nand subtle pathological cues, which are not captured by existing medical\nbenchmarks or instruction datasets. To this end, we introduce MMOral, the first\nlarge-scale multimodal instruction dataset and benchmark tailored for panoramic\nX-ray interpretation. MMOral consists of 20,563 annotated images paired with\n1.3 million instruction-following instances across diverse task types,\nincluding attribute extraction, report generation, visual question answering,\nand image-grounded dialogue. In addition, we present MMOral-Bench, a\ncomprehensive evaluation suite covering five key diagnostic dimensions in\ndentistry. We evaluate 64 LVLMs on MMOral-Bench and find that even the\nbest-performing model, i.e., GPT-4o, only achieves 41.45% accuracy, revealing\nsignificant limitations of current models in this domain. To promote the\nprogress of this specific domain, we also propose OralGPT, which conducts\nsupervised fine-tuning (SFT) upon Qwen2.5-VL-7B with our meticulously curated\nMMOral instruction dataset. Remarkably, a single epoch of SFT yields\nsubstantial performance enhancements for LVLMs, e.g., OralGPT demonstrates a\n24.73% improvement. Both MMOral and OralGPT hold significant potential as a\ncritical foundation for intelligent dentistry and enable more clinically\nimpactful multimodal AI systems in the dental field. The dataset, model,\nbenchmark, and evaluation suite are available at\nhttps://github.com/isbrycee/OralGPT.", "AI": {"tldr": "The paper presents MMOral, a multimodal dataset and benchmark tailored for interpreting panoramic X-rays in dentistry, supplementing LVLMs' limitations through OralGPT fine-tuning.", "motivation": "There is a need to address the underexplored domain of dentistry using LVLMs to interpret challenging medical imagery like panoramic X-rays.", "method": "The authors introduced MMOral, a dataset with annotated images and instruction-following instances, developed OralGPT through supervised fine-tuning, and evaluated models via MMOral-Bench.", "result": "Even the best current model achieves only 41.45% accuracy; OralGPT, after fine-tuning, shows a 24.73% performance improvement.", "conclusion": "MMOral and OralGPT represent critical advancements for developing intelligent systems in dentistry, addressing gaps in general-purpose LVLMs."}}
{"id": "2509.09451", "pdf": "https://arxiv.org/pdf/2509.09451", "abs": "https://arxiv.org/abs/2509.09451", "authors": ["Anjie Qiao", "Zhen Wang", "Chuan Chen", "DeFu Lian", "Enhong Chen"], "title": "Composable Score-based Graph Diffusion Model for Multi-Conditional Molecular Generation", "categories": ["cs.LG"], "comment": null, "summary": "Controllable molecular graph generation is essential for material and drug\ndiscovery, where generated molecules must satisfy diverse property constraints.\nWhile recent advances in graph diffusion models have improved generation\nquality, their effectiveness in multi-conditional settings remains limited due\nto reliance on joint conditioning or continuous relaxations that compromise\nfidelity. To address these limitations, we propose Composable Score-based Graph\nDiffusion model (CSGD), the first model that extends score matching to discrete\ngraphs via concrete scores, enabling flexible and principled manipulation of\nconditional guidance. Building on this foundation, we introduce two score-based\ntechniques: Composable Guidance (CoG), which allows fine-grained control over\narbitrary subsets of conditions during sampling, and Probability Calibration\n(PC), which adjusts estimated transition probabilities to mitigate train-test\nmismatches. Empirical results on four molecular datasets show that CSGD\nachieves state-of-the-art performance, with a 15.3% average improvement in\ncontrollability over prior methods, while maintaining high validity and\ndistributional fidelity. Our findings highlight the practical advantages of\nscore-based modeling for discrete graph generation and its capacity for\nflexible, multi-property molecular design.", "AI": {"tldr": "The paper introduces Composable Score-based Graph Diffusion model (CSGD) to improve molecular graph generation with multi-property constraints, achieving state-of-the-art results in validity, fidelity, and controllability.", "motivation": "The authors aim to address the challenges in molecular graph generation, particularly improving controllability in multi-conditional settings, which is essential for material and drug discovery.", "method": "The paper introduces CSGD, using score matching for discrete graphs. Techniques like Composable Guidance (CoG) for fine-tuned property control and Probability Calibration (PC) are developed to enhance the training process and model performance.", "result": "CSGD delivers an average improvement of 15.3% in controllability compared to prior methods across four molecular datasets, while maintaining high validity and adherence to target molecule distributions.", "conclusion": "CSGD demonstrates the potential of score-based modeling for discrete graph generation, offering flexible and effective molecular designs for real-world applications in drug and material innovation."}}
{"id": "2509.09263", "pdf": "https://arxiv.org/pdf/2509.09263", "abs": "https://arxiv.org/abs/2509.09263", "authors": ["Chao Yuan", "Yang Yang", "Yehui Yang", "Zach Cheng"], "title": "DATE: Dynamic Absolute Time Enhancement for Long Video Understanding", "categories": ["cs.CV"], "comment": null, "summary": "Long video understanding remains a fundamental challenge for multimodal large\nlanguage models (MLLMs), particularly in tasks requiring precise temporal\nreasoning and event localization. Existing approaches typically adopt uniform\nframe sampling and rely on implicit position encodings to model temporal order.\nHowever, these methods struggle with long-range dependencies, leading to\ncritical information loss and degraded temporal comprehension. In this paper,\nwe propose Dynamic Absolute Time Enhancement (DATE) that enhances temporal\nawareness in MLLMs through the Timestamp Injection Mechanism (TIM) and a\nsemantically guided Temporal-Aware Similarity Sampling (TASS) strategy.\nSpecifically, we interleave video frame embeddings with textual timestamp\ntokens to construct a continuous temporal reference system. We further\nreformulate the video sampling problem as a vision-language retrieval task and\nintroduce a two-stage algorithm to ensure both semantic relevance and temporal\ncoverage: enriching each query into a descriptive caption to better align with\nthe vision feature, and sampling key event with a similarity-driven temporally\nregularized greedy strategy. Our method achieves remarkable improvements w.r.t.\nabsolute time understanding and key event localization, resulting in\nstate-of-the-art performance among 7B and 72B models on hour-long video\nbenchmarks. Particularly, our 7B model even exceeds many 72B models on some\nbenchmarks.", "AI": {"tldr": "This paper proposes DATE, a method to improve video understanding in MLLMs through enhanced temporal reasoning using TIM and TASS strategies. It achieves superior performance on long video tasks.", "motivation": "To address the challenge of poor temporal reasoning and event localization in existing multimodal large language models (MLLMs) for long videos.", "method": "The DATE method introduces Timestamp Injection Mechanism (TIM) for continuous temporal reference and Temporal-Aware Similarity Sampling (TASS) for semantically guided video frame sampling. It uses a two-stage algorithm for alignment and retrieval.", "result": "DATE significantly enhances time understanding and event localization, achieving state-of-the-art performance on benchmarks with both 7B and 72B models. The 7B model even outperforms many larger models.", "conclusion": "By enhancing temporal reasoning with TIM and TASS, DATE improves video understanding in MLLMs, offering superior accuracy for key event localization in long videos."}}
{"id": "2509.09458", "pdf": "https://arxiv.org/pdf/2509.09458", "abs": "https://arxiv.org/abs/2509.09458", "authors": ["Golnoosh Abdollahinejad", "Saleh Baghersalimi", "Denisa-Andreea Constantinescu", "Sergey Shevchik", "David Atienza"], "title": "AquaCast: Urban Water Dynamics Forecasting with Precipitation-Informed Multi-Input Transformer", "categories": ["cs.LG"], "comment": "This work has been submitted to Journal of Hydrology, Elsevier, and a\n  preprint version is also available at SSRN 10.2139/ssrn.5399833", "summary": "This work addresses the challenge of forecasting urban water dynamics by\ndeveloping a multi-input, multi-output deep learning model that incorporates\nboth endogenous variables (e.g., water height or discharge) and exogenous\nfactors (e.g., precipitation history and forecast reports). Unlike conventional\nforecasting, the proposed model, AquaCast, captures both inter-variable and\ntemporal dependencies across all inputs, while focusing forecast solely on\nendogenous variables. Exogenous inputs are fused via an embedding layer,\neliminating the need to forecast them and enabling the model to attend to their\nshort-term influences more effectively. We evaluate our approach on the\nLausanneCity dataset, which includes measurements from four urban drainage\nsensors, and demonstrate state-of-the-art performance when using only\nendogenous variables. Performance also improves with the inclusion of exogenous\nvariables and forecast reports. To assess generalization and scalability, we\nadditionally test the model on three large-scale synthesized datasets,\ngenerated from MeteoSwiss records, the Lorenz Attractors model, and the Random\nFields model, each representing a different level of temporal complexity across\n100 nodes. The results confirm that our model consistently outperforms existing\nbaselines and maintains a robust and accurate forecast across both real and\nsynthetic datasets.", "AI": {"tldr": "The paper introduces AquaCast, a deep learning model for urban water dynamics forecasting, which integrates endogenous and exogenous variables to achieve enhanced accuracy and generalization.", "motivation": "To address the forecasting challenges in urban water systems by improving how temporal and variable dependencies are captured using endogenous and exogenous data.", "method": "The study proposes AquaCast, a deep learning model incorporating embedding layers for exogenous inputs, focusing forecast computation only on endogenous variables, tested on real and synthetic datasets.", "result": "AquaCast achieves state-of-the-art performance in forecasting urban water variables, surpassing baselines on both realistic and synthetic datasets across varying levels of temporal complexity.", "conclusion": "AquaCast is an effective, generalizable, and scalable approach for improving urban water dynamics forecasting through advanced modeling of variable interactions and temporal dependencies."}}
{"id": "2509.08919", "pdf": "https://arxiv.org/pdf/2509.08919", "abs": "https://arxiv.org/abs/2509.08919", "authors": ["Mahe Chen", "Xiaoxuan Wang", "Kaiwen Chen", "Nick Koudas"], "title": "Generative Engine Optimization: How to Dominate AI Search", "categories": ["cs.IR", "cs.CL", "cs.SI"], "comment": null, "summary": "The rapid adoption of generative AI-powered search engines like ChatGPT,\nPerplexity, and Gemini is fundamentally reshaping information retrieval, moving\nfrom traditional ranked lists to synthesized, citation-backed answers. This\nshift challenges established Search Engine Optimization (SEO) practices and\nnecessitates a new paradigm, which we term Generative Engine Optimization\n(GEO).\n  This paper presents a comprehensive comparative analysis of AI Search and\ntraditional web search (Google). Through a series of large-scale, controlled\nexperiments across multiple verticals, languages, and query paraphrases, we\nquantify critical differences in how these systems source information. Our key\nfindings reveal that AI Search exhibit a systematic and overwhelming bias\ntowards Earned media (third-party, authoritative sources) over Brand-owned and\nSocial content, a stark contrast to Google's more balanced mix. We further\ndemonstrate that AI Search services differ significantly from each other in\ntheir domain diversity, freshness, cross-language stability, and sensitivity to\nphrasing.\n  Based on these empirical results, we formulate a strategic GEO agenda. We\nprovide actionable guidance for practitioners, emphasizing the critical need\nto: (1) engineer content for machine scannability and justification, (2)\ndominate earned media to build AI-perceived authority, (3) adopt\nengine-specific and language-aware strategies, and (4) overcome the inherent\n\"big brand bias\" for niche players. Our work provides the foundational\nempirical analysis and a strategic framework for achieving visibility in the\nnew generative search landscape.", "AI": {"tldr": "The paper investigates the shift in search engines from traditional ranked lists to generative AI-driven answers, coining the term Generative Engine Optimization (GEO) to adapt to this new paradigm.", "motivation": "The motivation is to address the impact of generative AI-powered search engines such as ChatGPT on traditional SEO and offer strategies for improving visibility in this transformed search landscape.", "method": "The study conducts large-scale, controlled experiments comparing traditional web search with AI search across various dimensions, such as verticals, languages, and paraphrasing, to identify differences in information sourcing and presentation.", "result": "Key findings include AI Search's bias toward authoritative third-party sources (earned media), distinct differences between AI search services, and significant deviations from the domain diversity and content balance found in Google search.", "conclusion": "The paper proposes a GEO framework with actionable strategies to optimize for AI-driven search engines, focusing on machine-readable content, earned media authority, and overcoming biases against smaller brands."}}
{"id": "2509.09267", "pdf": "https://arxiv.org/pdf/2509.09267", "abs": "https://arxiv.org/abs/2509.09267", "authors": ["Linhao Li", "Yiwen Ye", "Ziyang Chen", "Yong Xia"], "title": "Unified Start, Personalized End: Progressive Pruning for Efficient 3D Medical Image Segmentation", "categories": ["cs.CV"], "comment": "15 pages, 8 figures", "summary": "3D medical image segmentation often faces heavy resource and time\nconsumption, limiting its scalability and rapid deployment in clinical\nenvironments. Existing efficient segmentation models are typically static and\nmanually designed prior to training, which restricts their adaptability across\ndiverse tasks and makes it difficult to balance performance with resource\nefficiency. In this paper, we propose PSP-Seg, a progressive pruning framework\nthat enables dynamic and efficient 3D segmentation. PSP-Seg begins with a\nredundant model and iteratively prunes redundant modules through a combination\nof block-wise pruning and a functional decoupling loss. We evaluate PSP-Seg on\nfive public datasets, benchmarking it against seven state-of-the-art models and\nsix efficient segmentation models. Results demonstrate that the lightweight\nvariant, PSP-Seg-S, achieves performance on par with nnU-Net while reducing GPU\nmemory usage by 42-45%, training time by 29-48%, and parameter number by 83-87%\nacross all datasets. These findings underscore PSP-Seg's potential as a\ncost-effective yet high-performing alternative for widespread clinical\napplication.", "AI": {"tldr": "PSP-Seg introduces a dynamic pruning framework to make 3D medical image segmentation more efficient and adaptable, significantly reducing computational resources while maintaining high performance.", "motivation": "The heavy resource and time consumption of current 3D medical segmentation models limits their scalability and use in clinical environments.", "method": "PSP-Seg employs progressive pruning combined with a block-wise pruning approach and functional decoupling loss to dynamically refine a redundant model.", "result": "The lightweight version PSP-Seg-S matches state-of-the-art segmentation performance while reducing GPU memory usage (42-45%), training time (29-48%), and parameters (83-87%).", "conclusion": "PSP-Seg is a promising framework that balances cost-efficiency with effective segmentation, making it suitable for clinical deployment."}}
{"id": "2509.09470", "pdf": "https://arxiv.org/pdf/2509.09470", "abs": "https://arxiv.org/abs/2509.09470", "authors": ["Om Vishesh", "Harshad Khadilkar", "Deepak Akkil"], "title": "AEGIS: An Agent for Extraction and Geographic Identification in Scholarly Proceedings", "categories": ["cs.LG"], "comment": "5 pages, 2 figures", "summary": "Keeping pace with the rapid growth of academia literature presents a\nsignificant challenge for researchers, funding bodies, and academic societies.\nTo address the time-consuming manual effort required for scholarly discovery,\nwe present a novel, fully automated system that transitions from data discovery\nto direct action. Our pipeline demonstrates how a specialized AI agent,\n'Agent-E', can be tasked with identifying papers from specific geographic\nregions within conference proceedings and then executing a Robotic Process\nAutomation (RPA) to complete a predefined action, such as submitting a\nnomination form. We validated our system on 586 papers from five different\nconferences, where it successfully identified every target paper with a recall\nof 100% and a near perfect accuracy of 99.4%. This demonstration highlights the\npotential of task-oriented AI agents to not only filter information but also to\nactively participate in and accelerate the workflows of the academic community.", "AI": {"tldr": "The paper introduces 'Agent-E,' an AI system that identifies academic papers from specific regions and automates subsequent actions like form submission, achieving 100% recall and 99.4% accuracy.", "motivation": "To simplify and expedite scholarly discovery by automating the labor-intensive process of identifying target papers and executing related actions.", "method": "Implemented a specialized AI agent ('Agent-E') combined with Robotic Process Automation to locate academic papers matching specific criteria and perform predefined tasks.", "result": "Validated the system on 586 papers from five conferences, achieving a recall of 100% and an accuracy of 99.4%.", "conclusion": "Task-oriented AI agents, such as 'Agent-E,' can streamline academic workflows by effectively integrating data discovery with action execution."}}
{"id": "2509.09286", "pdf": "https://arxiv.org/pdf/2509.09286", "abs": "https://arxiv.org/abs/2509.09286", "authors": ["Bohao Tang", "Yan Ma", "Fei Zhang", "Jiadi Su", "Ethan Chern", "Zhulin Hu", "Zhixin Wang", "Pengfei Liu", "Ya Zhang"], "title": "Visual Programmability: A Guide for Code-as-Thought in Chart Understanding", "categories": ["cs.CV"], "comment": null, "summary": "Chart understanding presents a critical test to the reasoning capabilities of\nVision-Language Models (VLMs). Prior approaches face critical limitations: some\nrely on external tools, making them brittle and constrained by a predefined\ntoolkit, while others fine-tune specialist models that often adopt a single\nreasoning strategy, such as text-based chain-of-thought (CoT). The intermediate\nsteps of text-based reasoning are difficult to verify, which complicates the\nuse of reinforcement-learning signals that reward factual accuracy. To address\nthis, we propose a Code-as-Thought (CaT) approach to represent the visual\ninformation of a chart in a verifiable, symbolic format. Our key insight is\nthat this strategy must be adaptive: a fixed, code-only implementation\nconsistently fails on complex charts where symbolic representation is\nunsuitable. This finding leads us to introduce Visual Programmability: a\nlearnable property that determines if a chart-question pair is better solved\nwith code or direct visual analysis. We implement this concept in an adaptive\nframework where a VLM learns to choose between the CaT pathway and a direct\nvisual reasoning pathway. The selection policy of the model is trained with\nreinforcement learning using a novel dual-reward system. This system combines a\ndata-accuracy reward to ground the model in facts and prevent numerical\nhallucination, with a decision reward that teaches the model when to use each\nstrategy, preventing it from defaulting to a single reasoning mode. Experiments\ndemonstrate strong and robust performance across diverse chart-understanding\nbenchmarks. Our work shows that VLMs can be taught not only to reason but also\nhow to reason, dynamically selecting the optimal reasoning pathway for each\ntask.", "AI": {"tldr": "The paper introduces an adaptive \"Code-as-Thought\" (CaT) strategy combined with Visual Programmability for chart understanding, improving reasoning capabilities of Vision-Language Models (VLMs).", "motivation": "Existing approaches to chart understanding in VLMs are either tool-reliant or overly focused on a single reasoning strategy like text-based chain-of-thought, resulting in brittleness and challenges in verifying reasoning steps.", "method": "The authors propose an adaptive framework where VLMs decide between a code-based symbolic reasoning pathway (CaT) or direct visual reasoning, guided by reinforcement learning with a dual-reward system.", "result": "Experiments show robust performance across diverse benchmarks, demonstrating the effectiveness of dynamic reasoning pathway selection.", "conclusion": "VLMs can learn not only to reason effectively but also to adaptively choose the most appropriate reasoning strategy for a given task, enhancing their versatility and robustness in chart understanding."}}
{"id": "2509.09474", "pdf": "https://arxiv.org/pdf/2509.09474", "abs": "https://arxiv.org/abs/2509.09474", "authors": ["Julia Gastinger", "Christian Meilicke", "Heiner Stuckenschmidt"], "title": "CountTRuCoLa: Rule Confidence Learning for Temporal Knowledge Graph Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "We address the task of temporal knowledge graph (TKG) forecasting by\nintroducing a fully explainable method based on temporal rules. Motivated by\nrecent work proposing a strong baseline using recurrent facts, our approach\nlearns four simple types of rules with a confidence function that considers\nboth recency and frequency. Evaluated on nine datasets, our method matches or\nsurpasses the performance of eight state-of-the-art models and two baselines,\nwhile providing fully interpretable predictions.", "AI": {"tldr": "The paper proposes a new explainable method based on temporal rules for forecasting temporal knowledge graphs.", "motivation": "To improve performance and interpretability in temporal knowledge graph forecasting by leveraging rules based on recency and frequency.", "method": "The authors introduce a method that learns four types of temporal rules, combined with a confidence function, to forecast knowledge graph data.", "result": "The proposed method achieves comparable or superior performance to eight state-of-the-art models and two baselines across nine datasets.", "conclusion": "Their method is effective and provides fully interpretable predictions, addressing a key gap in temporal knowledge graph forecasting research."}}
{"id": "2509.09290", "pdf": "https://arxiv.org/pdf/2509.09290", "abs": "https://arxiv.org/abs/2509.09290", "authors": ["Anthony P. Addison", "Felix Wagner", "Wentian Xu", "Natalie Voets", "Konstantinos Kamnitsas"], "title": "Modality-Agnostic Input Channels Enable Segmentation of Brain lesions in Multimodal MRI with Sequences Unavailable During Training", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to MICCAI 2025, for the following workshop: ML-CDS 2025:\n  Multimodal Learning and Fusion Across Scales for Clinical Decision Support", "summary": "Segmentation models are important tools for the detection and analysis of\nlesions in brain MRI. Depending on the type of brain pathology that is imaged,\nMRI scanners can acquire multiple, different image modalities (contrasts). Most\nsegmentation models for multimodal brain MRI are restricted to fixed modalities\nand cannot effectively process new ones at inference. Some models generalize to\nunseen modalities but may lose discriminative modality-specific information.\nThis work aims to develop a model that can perform inference on data that\ncontain image modalities unseen during training, previously seen modalities,\nand heterogeneous combinations of both, thus allowing a user to utilize any\navailable imaging modalities. We demonstrate this is possible with a simple,\nthus practical alteration to the U-net architecture, by integrating a\nmodality-agnostic input channel or pathway, alongside modality-specific input\nchannels. To train this modality-agnostic component, we develop an image\naugmentation scheme that synthesizes artificial MRI modalities. Augmentations\ndifferentially alter the appearance of pathological and healthy brain tissue to\ncreate artificial contrasts between them while maintaining realistic anatomical\nintegrity. We evaluate the method using 8 MRI databases that include 5 types of\npathologies (stroke, tumours, traumatic brain injury, multiple sclerosis and\nwhite matter hyperintensities) and 8 modalities (T1, T1+contrast, T2, PD, SWI,\nDWI, ADC and FLAIR). The results demonstrate that the approach preserves the\nability to effectively process MRI modalities encountered during training,\nwhile being able to process new, unseen modalities to improve its segmentation.\nProject code: https://github.com/Anthony-P-Addison/AGN-MOD-SEG", "AI": {"tldr": "This paper presents an enhanced U-net segmentation model capable of processing both seen and unseen MRI modalities for brain lesion detection and analysis.", "motivation": "Current segmentation models struggle to generalize across unseen MRI modalities and fail to utilize heterogeneous combinations of imaging data.", "method": "The proposed model introduces modality-specific and modality-agnostic input pathways, combined with an image augmentation scheme synthesizing artificial MRI modalities for training.", "result": "Experiments across 8 MRI databases demonstrate the model maintains performance for seen modalities while effectively handling unseen ones.", "conclusion": "The approach offers a practical solution to improve brain lesion segmentation across diverse MRI modalities, enhancing clinical usability."}}
{"id": "2509.09485", "pdf": "https://arxiv.org/pdf/2509.09485", "abs": "https://arxiv.org/abs/2509.09485", "authors": ["Zhanhong Jiang", "Md Zahid Hasan", "Nastaran Saadati", "Aditya Balu", "Chao Liu", "Soumik Sarkar"], "title": "Balancing Utility and Privacy: Dynamically Private SGD with Random Projection", "categories": ["cs.LG"], "comment": "27 pages, 13 figures", "summary": "Stochastic optimization is a pivotal enabler in modern machine learning,\nproducing effective models for various tasks. However, several existing works\nhave shown that model parameters and gradient information are susceptible to\nprivacy leakage. Although Differentially Private SGD (DPSGD) addresses privacy\nconcerns, its static noise mechanism impacts the error bounds for model\nperformance. Additionally, with the exponential increase in model parameters,\nefficient learning of these models using stochastic optimizers has become more\nchallenging. To address these concerns, we introduce the Dynamically\nDifferentially Private Projected SGD (D2P2-SGD) optimizer. In D2P2-SGD, we\ncombine two important ideas: (i) dynamic differential privacy (DDP) with\nautomatic gradient clipping and (ii) random projection with SGD, allowing\ndynamic adjustment of the tradeoff between utility and privacy of the model. It\nexhibits provably sub-linear convergence rates across different objective\nfunctions, matching the best available rate. The theoretical analysis further\nsuggests that DDP leads to better utility at the cost of privacy, while random\nprojection enables more efficient model learning. Extensive experiments across\ndiverse datasets show that D2P2-SGD remarkably enhances accuracy while\nmaintaining privacy. Our code is available here.", "AI": {"tldr": "The paper introduces D2P2-SGD, an optimizer that addresses privacy challenges and learning efficiency in stochastic optimization by combining dynamic differential privacy and random projections, achieving sub-linear convergence and improved model utility.", "motivation": "Existing stochastic optimization approaches face challenges such as privacy leakage of model parameters and gradients, static noise mechanisms affecting model performance, and inefficiencies due to increasing model complexity.", "method": "The paper proposes D2P2-SGD, which integrates dynamic differential privacy with automated gradient clipping alongside a random projection mechanism in SGD, enabling adaptable trade-offs between model utility and privacy.", "result": "The D2P2-SGD optimizer achieves provably sub-linear convergence rates, surpasses other methods in balancing privacy and accuracy, and shows improved utility through extensive experimental validation across diverse datasets.", "conclusion": "D2P2-SGD successfully addresses privacy concerns and learning challenges in stochastic optimization, improving accuracy while preserving differential privacy, and offers a theoretical framework with practical implementation."}}
{"id": "2509.09204", "pdf": "https://arxiv.org/pdf/2509.09204", "abs": "https://arxiv.org/abs/2509.09204", "authors": ["Chin Yuen Kwok", "Jia Qi Yip", "Zhen Qiu", "Chi Hung Chi", "Kwok Yan Lam"], "title": "Bona fide Cross Testing Reveals Weak Spot in Audio Deepfake Detection Systems", "categories": ["cs.SD", "cs.AI", "cs.CL"], "comment": "Published in Interspeech 2025", "summary": "Audio deepfake detection (ADD) models are commonly evaluated using datasets\nthat combine multiple synthesizers, with performance reported as a single Equal\nError Rate (EER). However, this approach disproportionately weights\nsynthesizers with more samples, underrepresenting others and reducing the\noverall reliability of EER. Additionally, most ADD datasets lack diversity in\nbona fide speech, often featuring a single environment and speech style (e.g.,\nclean read speech), limiting their ability to simulate real-world conditions.\nTo address these challenges, we propose bona fide cross-testing, a novel\nevaluation framework that incorporates diverse bona fide datasets and\naggregates EERs for more balanced assessments. Our approach improves robustness\nand interpretability compared to traditional evaluation methods. We benchmark\nover 150 synthesizers across nine bona fide speech types and release a new\ndataset to facilitate further research at\nhttps://github.com/cyaaronk/audio_deepfake_eval.", "AI": {"tldr": "The paper tackles the limitations of current Audio Deepfake Detection (ADD) evaluation methods, proposing a novel framework that incorporates diverse bona fide datasets for more balanced and realistic assessments.", "motivation": "Current ADD evaluation methods overly favor synthesizers with more samples and lack diversity in bona fide speech, thus failing to simulate real-world conditions effectively.", "method": "The authors propose a 'bona fide cross-testing' approach, which includes a diverse set of bona fide datasets and calculates aggregated EERs for balanced and robust evaluation.", "result": "They benchmarked over 150 synthesizers across 9 different bona fide speech types and released a new dataset for further research.", "conclusion": "The proposed framework provides a more realistic and balanced assessment method, improving robustness and interpretability in the evaluation of ADD models."}}
{"id": "2509.09512", "pdf": "https://arxiv.org/pdf/2509.09512", "abs": "https://arxiv.org/abs/2509.09512", "authors": ["Cynthia Moreira Maia", "Lucas B. V. de Amorim", "George D. C. Cavalcanti", "Rafael M. O. Cruz"], "title": "PIPES: A Meta-dataset of Machine Learning Pipelines", "categories": ["cs.LG"], "comment": null, "summary": "Solutions to the Algorithm Selection Problem (ASP) in machine learning face\nthe challenge of high computational costs associated with evaluating various\nalgorithms' performances on a given dataset. To mitigate this cost, the\nmeta-learning field can leverage previously executed experiments shared in\nonline repositories such as OpenML. OpenML provides an extensive collection of\nmachine learning experiments. However, an analysis of OpenML's records reveals\nlimitations. It lacks diversity in pipelines, specifically when exploring data\npreprocessing steps/blocks, such as scaling or imputation, resulting in limited\nrepresentation. Its experiments are often focused on a few popular techniques\nwithin each pipeline block, leading to an imbalanced sample. To overcome the\nobserved limitations of OpenML, we propose PIPES, a collection of experiments\ninvolving multiple pipelines designed to represent all combinations of the\nselected sets of techniques, aiming at diversity and completeness. PIPES stores\nthe results of experiments performed applying 9,408 pipelines to 300 datasets.\nIt includes detailed information on the pipeline blocks, training and testing\ntimes, predictions, performances, and the eventual error messages. This\ncomprehensive collection of results allows researchers to perform analyses\nacross diverse and representative pipelines and datasets. PIPES also offers\npotential for expansion, as additional data and experiments can be incorporated\nto support the meta-learning community further. The data, code, supplementary\nmaterial, and all experiments can be found at\nhttps://github.com/cynthiamaia/PIPES.git.", "AI": {"tldr": "The paper proposes PIPES, a diverse collection of machine learning experiments addressing limitations in OpenML regarding pipeline diversity and balance, facilitating more comprehensive meta-learning analyses.", "motivation": "The work aims to address the imbalance and lack of diversity in algorithmic pipelines available in OpenML for meta-learning, which can hinder effective algorithm selection and broader analyses.", "method": "PIPES involves experiments from 9,408 pipelines across 300 datasets, ensuring diversity by combining various techniques in pipeline blocks and storing detailed execution data.", "result": "PIPES achieved a comprehensive dataset that covers diverse pipelines, training/testing details, error logs, and predictions, which enhances research capabilities in the meta-learning field.", "conclusion": "PIPES improves the representation of preprocessing techniques, provides a more balanced dataset for experiments, and offers a foundation for further meta-learning research."}}
{"id": "2509.09298", "pdf": "https://arxiv.org/pdf/2509.09298", "abs": "https://arxiv.org/abs/2509.09298", "authors": ["Oh-Tae Jang", "Min-Gon Cho", "Kyung-Tae Kim"], "title": "Learning Object-Centric Representations in SAR Images with Multi-Level Feature Fusion", "categories": ["cs.CV"], "comment": "12 pages, 5 figures", "summary": "Synthetic aperture radar (SAR) images contain not only targets of interest\nbut also complex background clutter, including terrain reflections and speckle\nnoise. In many cases, such clutter exhibits intensity and patterns that\nresemble targets, leading models to extract entangled or spurious features.\nSuch behavior undermines the ability to form clear target representations,\nregardless of the classifier. To address this challenge, we propose a novel\nobject-centric learning (OCL) framework, named SlotSAR, that disentangles\ntarget representations from background clutter in SAR images without mask\nannotations. SlotSAR first extracts high-level semantic features from SARATR-X\nand low-level scattering features from the wavelet scattering network in order\nto obtain complementary multi-level representations for robust target\ncharacterization. We further present a multi-level slot attention module that\nintegrates these low- and high-level features to enhance slot-wise\nrepresentation distinctiveness, enabling effective OCL. Experimental results\ndemonstrate that SlotSAR achieves state-of-the-art performance in SAR imagery\nby preserving structural details compared to existing OCL methods.", "AI": {"tldr": "SlotSAR is a framework for disentangling target representations from background clutter in SAR images. It leverages multi-level representations and slot attention without requiring mask annotations.", "motivation": "The paper addresses the challenge of SAR images containing complex background clutter and noise, which affects the clarity of target representations.", "method": "SlotSAR integrates high-level semantic features and low-level scattering features into a multi-level slot attention module for effective object-centric learning.", "result": "SlotSAR outperforms existing object-centric learning methods, demonstrating state-of-the-art performance and preserving structural details in SAR images.", "conclusion": "SlotSAR provides a robust framework that successfully disentangles target features from clutter in SAR imagery, advancing the field of SAR image analysis."}}
{"id": "2509.09515", "pdf": "https://arxiv.org/pdf/2509.09515", "abs": "https://arxiv.org/abs/2509.09515", "authors": ["Yoga Disha Sendhil Kumar", "Manas V Shetty", "Sudip Vhaduri"], "title": "Cough Classification using Few-Shot Learning", "categories": ["cs.LG"], "comment": "8 pages 8 images Has been accepted in Pervasive Health 2025", "summary": "This paper investigates the effectiveness of few-shot learning for\nrespiratory sound classification, focusing on coughbased detection of COVID-19,\nFlu, and healthy conditions. We leverage Prototypical Networks with spectrogram\nrepresentations of cough sounds to address the challenge of limited labeled\ndata. Our study evaluates whether few-shot learning can enable models to\nachieve performance comparable to traditional deep learning approaches while\nusing significantly fewer training samples. Additionally, we compare\nmulti-class and binary classification models to assess whether multi-class\nmodels can perform comparably to their binary counterparts. Experimental\nfindings show that few-shot learning models can achieve competitive accuracy.\nOur model attains 74.87% accuracy in multi-class classification with only 15\nsupport examples per class, while binary classification achieves over 70%\naccuracy across all class pairs. Class-wise analysis reveals Flu as the most\ndistinguishable class, and Healthy as the most challenging. Statistical tests\n(paired t-test p = 0.149, Wilcoxon p = 0.125) indicate no significant\nperformance difference between binary and multiclass models, supporting the\nviability of multi-class classification in this setting. These results\nhighlight the feasibility of applying few-shot learning in medical diagnostics,\nparticularly when large labeled datasets are unavailable.", "AI": {"tldr": "The paper explores utilizing Prototypical Networks for few-shot learning in respiratory sound classification, achieving competitive performance with limited data, especially in a multi-class setting.", "motivation": "To investigate the application of few-shot learning in medical diagnostics and its potential to achieve accurate results with minimal labeled data, focusing on COVID-19, Flu, and healthy cough sound classification.", "method": "The authors use Prototypical Networks combined with spectrogram representations of cough sounds for both multi-class and binary classification tasks, evaluating model effectiveness with varying support examples.", "result": "Few-shot learning models achieved up to 74.87% accuracy in multi-class classification with 15 support examples per class and over 70% accuracy in binary classification, with Flu being most distinguishable and Healthy the most challenging.", "conclusion": "Few-shot learning proves feasible for medical diagnostics with limited data, and multi-class models perform comparably to binary ones, emphasizing its utility in scenarios lacking large labeled datasets."}}
{"id": "2509.09307", "pdf": "https://arxiv.org/pdf/2509.09307", "abs": "https://arxiv.org/abs/2509.09307", "authors": ["Zhengzhao Lai", "Youbin Zheng", "Zhenyang Cai", "Haonan Lyu", "Jinpu Yang", "Hongqing Liang", "Yan Hu", "Benyou Wang"], "title": "Can Multimodal LLMs See Materials Clearly? A Multimodal Benchmark on Materials Characterization", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "comment": null, "summary": "Materials characterization is fundamental to acquiring materials information,\nrevealing the processing-microstructure-property relationships that guide\nmaterial design and optimization. While multimodal large language models\n(MLLMs) have recently shown promise in generative and predictive tasks within\nmaterials science, their capacity to understand real-world characterization\nimaging data remains underexplored. To bridge this gap, we present MatCha, the\nfirst benchmark for materials characterization image understanding, comprising\n1,500 questions that demand expert-level domain expertise. MatCha encompasses\nfour key stages of materials research comprising 21 distinct tasks, each\ndesigned to reflect authentic challenges faced by materials scientists. Our\nevaluation of state-of-the-art MLLMs on MatCha reveals a significant\nperformance gap compared to human experts. These models exhibit degradation\nwhen addressing questions requiring higher-level expertise and sophisticated\nvisual perception. Simple few-shot and chain-of-thought prompting struggle to\nalleviate these limitations. These findings highlight that existing MLLMs still\nexhibit limited adaptability to real-world materials characterization\nscenarios. We hope MatCha will facilitate future research in areas such as new\nmaterial discovery and autonomous scientific agents. MatCha is available at\nhttps://github.com/FreedomIntelligence/MatCha.", "AI": {"tldr": "The paper introduces MatCha, a benchmark designed to test multimodal large language models (MLLMs) on materials characterization image understanding, revealing a performance gap compared to human experts.", "motivation": "The motivation is to address the underexplored capability of MLLMs in handling real-world materials characterization imaging data, which is critical for advancing materials science research.", "method": "The authors developed MatCha, a benchmark comprising 1,500 expert-level questions spanning 21 tasks related to four stages of materials research, to evaluate MLLMs.", "result": "State-of-the-art MLLMs show significant performance gaps when compared to human expertise, with particular struggles in complex tasks requiring higher visual perception and reasoning.", "conclusion": "The study demonstrates that current MLLMs are insufficiently adaptable for real-world materials characterization scenarios and highlights MatCha's potential to drive progress in materials science and AI research."}}
{"id": "2509.09091", "pdf": "https://arxiv.org/pdf/2509.09091", "abs": "https://arxiv.org/abs/2509.09091", "authors": ["Honglan Yu", "Yibin Wang", "Feifei Dai", "Dong Liu", "Haihui Fan", "Xiaoyan Gu"], "title": "Towards Confidential and Efficient LLM Inference with Dual Privacy Protection", "categories": ["cs.CR", "cs.AI"], "comment": "Accepted by DASFAA2025", "summary": "CPU-based trusted execution environments (TEEs) and differential privacy (DP)\nhave gained wide applications for private inference. Due to high inference\nlatency in TEEs, researchers use partition-based approaches that offload linear\nmodel components to GPUs. However, dense nonlinear layers of large language\nmodels (LLMs) result in significant communication overhead between TEEs and\nGPUs. DP-based approaches apply random noise to protect data privacy, but this\ncompromises LLM performance and semantic understanding. To overcome the above\ndrawbacks, this paper proposes CMIF, a Confidential and efficient Model\nInference Framework. CMIF confidentially deploys the embedding layer in the\nclient-side TEE and subsequent layers on GPU servers. Meanwhile, it optimizes\nthe Report-Noisy-Max mechanism to protect sensitive inputs with a slight\ndecrease in model performance. Extensive experiments on Llama-series models\ndemonstrate that CMIF reduces additional inference overhead in TEEs while\npreserving user data privacy.", "AI": {"tldr": "This paper introduces CMIF, a model inference framework addressing latency, privacy, and performance concerns in deploying large language models within trusted execution environments and GPUs.", "motivation": "Current methods for private inference using TEEs and DP suffer from high latency in TEEs and performance degradation due to random noise application in DP.", "method": "CMIF deploys the embedding layer in client-side TEEs and subsequent layers on GPU servers. It also optimizes the Report-Noisy-Max mechanism for protecting sensitive inputs.", "result": "Experiments on Llama-series models show CMIF improves latency in TEEs and maintains user data privacy with minimal performance loss.", "conclusion": "CMIF effectively balances efficient inference and confidentiality, overcoming limitations in current TEEs and DP methods for large language models."}}
{"id": "2509.09310", "pdf": "https://arxiv.org/pdf/2509.09310", "abs": "https://arxiv.org/abs/2509.09310", "authors": ["Hao Si", "Ehsan Javanmardi", "Manabu Tsukada"], "title": "You Share Beliefs, I Adapt: Progressive Heterogeneous Collaborative Perception", "categories": ["cs.CV"], "comment": null, "summary": "Collaborative perception enables vehicles to overcome individual perception\nlimitations by sharing information, allowing them to see further and through\nocclusions. In real-world scenarios, models on different vehicles are often\nheterogeneous due to manufacturer variations. Existing methods for\nheterogeneous collaborative perception address this challenge by fine-tuning\nadapters or the entire network to bridge the domain gap. However, these methods\nare impractical in real-world applications, as each new collaborator must\nundergo joint training with the ego vehicle on a dataset before inference, or\nthe ego vehicle stores models for all potential collaborators in advance.\nTherefore, we pose a new question: Can we tackle this challenge directly during\ninference, eliminating the need for joint training? To answer this, we\nintroduce Progressive Heterogeneous Collaborative Perception (PHCP), a novel\nframework that formulates the problem as few-shot unsupervised domain\nadaptation. Unlike previous work, PHCP dynamically aligns features by\nself-training an adapter during inference, eliminating the need for labeled\ndata and joint training. Extensive experiments on the OPV2V dataset demonstrate\nthat PHCP achieves strong performance across diverse heterogeneous scenarios.\nNotably, PHCP achieves performance comparable to SOTA methods trained on the\nentire dataset while using only a small amount of unlabeled data.", "AI": {"tldr": "PHCP introduces a new framework for collaborative vehicle perception that adapts to heterogeneous models during inference without requiring joint training, achieving results comparable to state-of-the-art methods.", "motivation": "Real-world collaborative perception faces challenges because vehicles often have heterogeneous models, and existing methods require impractical joint training or advance model storage.", "method": "PHCP uses a few-shot unsupervised domain adaptation approach, dynamically self-training an adapter during inference to align features without needing labeled data or prior joint training.", "result": "PHCP achieves strong performance on the OPV2V dataset, performing comparably to state-of-the-art methods trained with a full dataset but requires only minimal unlabeled data.", "conclusion": "PHCP effectively enables real-time heterogeneous collaborative perception in practical settings, eliminating reliance on joint training while maintaining high performance."}}
{"id": "2509.09597", "pdf": "https://arxiv.org/pdf/2509.09597", "abs": "https://arxiv.org/abs/2509.09597", "authors": ["Maysam Behmanesh", "Erkan Turan", "Maks Ovsjanikov"], "title": "Graph Alignment via Dual-Pass Spectral Encoding and Latent Space Communication", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "23 pages", "summary": "Graph alignment-the problem of identifying corresponding nodes across\nmultiple graphs-is fundamental to numerous applications. Most existing\nunsupervised methods embed node features into latent representations to enable\ncross-graph comparison without ground-truth correspondences. However, these\nmethods suffer from two critical limitations: the degradation of node\ndistinctiveness due to oversmoothing in GNN-based embeddings, and the\nmisalignment of latent spaces across graphs caused by structural noise, feature\nheterogeneity, and training instability, ultimately leading to unreliable node\ncorrespondences. We propose a novel graph alignment framework that\nsimultaneously enhances node distinctiveness and enforces geometric consistency\nacross latent spaces. Our approach introduces a dual-pass encoder that combines\nlow-pass and high-pass spectral filters to generate embeddings that are both\nstructure-aware and highly discriminative. To address latent space\nmisalignment, we incorporate a geometry-aware functional map module that learns\nbijective and isometric transformations between graph embeddings, ensuring\nconsistent geometric relationships across different representations. Extensive\nexperiments on graph benchmarks demonstrate that our method consistently\noutperforms existing unsupervised alignment baselines, exhibiting superior\nrobustness to structural inconsistencies and challenging alignment scenarios.\nAdditionally, comprehensive evaluation on vision-language benchmarks using\ndiverse pretrained models shows that our framework effectively generalizes\nbeyond graph domains, enabling unsupervised alignment of vision and language\nrepresentations.", "AI": {"tldr": "This paper proposes a novel framework for graph alignment that optimizes node distinctiveness and latent space consistency to outperform current unsupervised baselines in aligning graphs and other representations.", "motivation": "Existing unsupervised graph alignment methods struggle with oversmoothing in GNN-based embeddings and misalignment of latent spaces caused by structural noise and feature heterogeneity.", "method": "The proposed approach employs a dual-pass encoder combining low-pass and high-pass spectral filters for distinctive embeddings and a geometry-aware functional map module for consistent latent space transformations.", "result": "Experimental analysis demonstrates superior performance and robustness in both graph benchmarks and vision-language benchmarks, indicating effective generalization.", "conclusion": "The framework successfully enhances node distinctiveness and geometric consistency, proving its applicability in graph and cross-domain alignment tasks."}}
{"id": "2509.09097", "pdf": "https://arxiv.org/pdf/2509.09097", "abs": "https://arxiv.org/abs/2509.09097", "authors": ["Honghui Xu", "Shiva Shrestha", "Wei Chen", "Zhiyuan Li", "Zhipeng Cai"], "title": "DP-FedLoRA: Privacy-Enhanced Federated Fine-Tuning for On-Device Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "As on-device large language model (LLM) systems become increasingly\nprevalent, federated fine-tuning enables advanced language understanding and\ngeneration directly on edge devices; however, it also involves processing\nsensitive, user-specific data, raising significant privacy concerns within the\nfederated learning framework. To address these challenges, we propose\nDP-FedLoRA, a privacy-enhanced federated fine-tuning framework that integrates\nLoRA-based adaptation with differential privacy in a communication-efficient\nsetting. Each client locally clips and perturbs its LoRA matrices using\nGaussian noise to satisfy ($\\epsilon$, $\\delta$)-differential privacy. We\nfurther provide a theoretical analysis demonstrating the unbiased nature of the\nupdates and deriving bounds on the variance introduced by noise, offering\npractical guidance for privacy-budget calibration. Experimental results across\nmainstream benchmarks show that DP-FedLoRA delivers competitive performance\nwhile offering strong privacy guarantees, paving the way for scalable and\nprivacy-preserving LLM deployment in on-device environments.", "AI": {"tldr": "This paper presents DP-FedLoRA, a method for privacy-preserving fine-tuning of large language models (LLMs) on edge devices using federated learning combined with differential privacy and LoRA adaptation.", "motivation": "The motivation is to enable advanced language understanding and generation on edge devices while addressing privacy concerns related to user-specific sensitive data in federated learning.", "method": "DP-FedLoRA combines LoRA-based model adaptation with differential privacy by locally clipping and perturbing LoRA matrices on each client using Gaussian noise, ensuring ($\\epsilon$, $\\delta$)-differential privacy in a communication-efficient manner.", "result": "The proposed method is theoretically analyzed for unbiased updates and controlled noise variance. Experiments on mainstream benchmarks demonstrate that it achieves competitive performance while maintaining strong privacy guarantees.", "conclusion": "DP-FedLoRA provides a scalable, privacy-preserving solution for federated fine-tuning, facilitating the deployment of large language models in on-device environments."}}
{"id": "2509.09311", "pdf": "https://arxiv.org/pdf/2509.09311", "abs": "https://arxiv.org/abs/2509.09311", "authors": ["Illia Volkov", "Nikita Kisel", "Klara Janouskova", "Jiri Matas"], "title": "Image Recognition with Vision and Language Embeddings of VLMs", "categories": ["cs.CV"], "comment": null, "summary": "Vision-language models (VLMs) have enabled strong zero-shot classification\nthrough image-text alignment. Yet, their purely visual inference capabilities\nremain under-explored. In this work, we conduct a comprehensive evaluation of\nboth language-guided and vision-only image classification with a diverse set of\ndual-encoder VLMs, including both well-established and recent models such as\nSigLIP 2 and RADIOv2.5. The performance is compared in a standard setup on the\nImageNet-1k validation set and its label-corrected variant. The key factors\naffecting accuracy are analysed, including prompt design, class diversity, the\nnumber of neighbours in k-NN, and reference set size. We show that language and\nvision offer complementary strengths, with some classes favouring textual\nprompts and others better handled by visual similarity. To exploit this\ncomplementarity, we introduce a simple, learning-free fusion method based on\nper-class precision that improves classification performance. The code is\navailable at: https://github.com/gonikisgo/bmvc2025-vlm-image-recognition.", "AI": {"tldr": "The paper evaluates the performance of vision-language models (VLMs) in language-guided and visual-only image classification, using various models and proposing a fusion method for improved classification.", "motivation": "To understand and enhance the unexamined capabilities of vision-language models in purely visual inference and improve classification performance.", "method": "The paper evaluates VLMs using ImageNet datasets, analyzing factors like prompt design and class diversity, and introduces a fusion method based on per-class precision.", "result": "Language and vision show complementary strengths, and the proposed fusion method enhances classification accuracy.", "conclusion": "The study highlights the complementary strengths of language and vision modalities and provides insights for improving image classification performance through a simple fusion approach."}}
{"id": "2509.09599", "pdf": "https://arxiv.org/pdf/2509.09599", "abs": "https://arxiv.org/abs/2509.09599", "authors": ["Ira J. S. Shokar", "Rich R. Kerswell", "Peter H. Haynes"], "title": "Conditioning on PDE Parameters to Generalise Deep Learning Emulation of Stochastic and Chaotic Dynamics", "categories": ["cs.LG", "math.DS", "nlin.CD", "physics.ao-ph"], "comment": null, "summary": "We present a deep learning emulator for stochastic and chaotic\nspatio-temporal systems, explicitly conditioned on the parameter values of the\nunderlying partial differential equations (PDEs). Our approach involves\npre-training the model on a single parameter domain, followed by fine-tuning on\na smaller, yet diverse dataset, enabling generalisation across a broad range of\nparameter values. By incorporating local attention mechanisms, the network is\ncapable of handling varying domain sizes and resolutions. This enables\ncomputationally efficient pre-training on smaller domains while requiring only\na small additional dataset to learn how to generalise to larger domain sizes.\nWe demonstrate the model's capabilities on the chaotic Kuramoto-Sivashinsky\nequation and stochastically-forced beta-plane turbulence, showcasing its\nability to capture phenomena at interpolated parameter values. The emulator\nprovides significant computational speed-ups over conventional numerical\nintegration, facilitating efficient exploration of parameter space, while a\nprobabilistic variant of the emulator provides uncertainty quantification,\nallowing for the statistical study of rare events.", "AI": {"tldr": "This paper introduces a deep learning model capable of emulating chaotic and stochastic systems governed by PDEs, with high computational efficiency and the ability to generalize across varying parameters and domain sizes.", "motivation": "To address the computational complexity in exploring parametric and spatial variations of spatio-temporal systems modeled by PDEs, and to enable efficient uncertainty quantification and rare event analysis.", "method": "The method involves pre-training a deep learning emulator on a single set of PDE parameter values, then fine-tuning it on a smaller, diverse dataset. The emulator incorporates local attention mechanisms to handle variable domain sizes and resolutions.", "result": "The model demonstrates efficient and accurate emulation of chaotic systems such as the Kuramoto-Sivashinsky equation and beta-plane turbulence, showing computational speed-ups and reliable performance at interpolated parameter values.", "conclusion": "The proposed emulator not only provides a faster alternative to numerical integration but also facilitates statistical studies, including uncertainty quantification and rare event analysis, showcasing its potential for broader applications."}}
{"id": "2509.09112", "pdf": "https://arxiv.org/pdf/2509.09112", "abs": "https://arxiv.org/abs/2509.09112", "authors": ["Zhaoxi Zhang", "Xiaomei Zhang", "Yanjun Zhang", "He Zhang", "Shirui Pan", "Bo Liu", "Asif Qumer Gill", "Leo Yu Zhang"], "title": "Character-Level Perturbations Disrupt LLM Watermarks", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Model (LLM) watermarking embeds detectable signals into\ngenerated text for copyright protection, misuse prevention, and content\ndetection. While prior studies evaluate robustness using watermark removal\nattacks, these methods are often suboptimal, creating the misconception that\neffective removal requires large perturbations or powerful adversaries.\n  To bridge the gap, we first formalize the system model for LLM watermark, and\ncharacterize two realistic threat models constrained on limited access to the\nwatermark detector. We then analyze how different types of perturbation vary in\ntheir attack range, i.e., the number of tokens they can affect with a single\nedit. We observe that character-level perturbations (e.g., typos, swaps,\ndeletions, homoglyphs) can influence multiple tokens simultaneously by\ndisrupting the tokenization process. We demonstrate that character-level\nperturbations are significantly more effective for watermark removal under the\nmost restrictive threat model. We further propose guided removal attacks based\non the Genetic Algorithm (GA) that uses a reference detector for optimization.\nUnder a practical threat model with limited black-box queries to the watermark\ndetector, our method demonstrates strong removal performance. Experiments\nconfirm the superiority of character-level perturbations and the effectiveness\nof the GA in removing watermarks under realistic constraints. Additionally, we\nargue there is an adversarial dilemma when considering potential defenses: any\nfixed defense can be bypassed by a suitable perturbation strategy. Motivated by\nthis principle, we propose an adaptive compound character-level attack.\nExperimental results show that this approach can effectively defeat the\ndefenses. Our findings highlight significant vulnerabilities in existing LLM\nwatermark schemes and underline the urgency for the development of new robust\nmechanisms.", "AI": {"tldr": "The research explores vulnerabilities in watermarking of Large Language Models (LLM) and proposes advanced methods for watermark removal using character-level perturbations and Genetic Algorithm-based attacks, demonstrating their effectiveness against practical defenses.", "motivation": "The paper aims to highlight the limitations of current LLM watermarking schemes and stresses the need for more robust mechanisms to protect copyrights, prevent misuse, and enhance content detection in the face of attacks.", "method": "The authors formalized a system model for LLM watermarking, identified two realistic threat models, analyzed the effectiveness of different perturbation approaches, and developed removal attacks guided by the Genetic Algorithm under constrained black-box query situations.", "result": "Character-level perturbations proved highly effective at disrupting tokenization and removing watermarks under restrictive threat models. The Genetic Algorithm-based attacks demonstrated strong watermark removal capabilities with limited access to detectors, outperforming existing approaches.", "conclusion": "Current LLM watermark schemes face significant risks from advanced perturbation and attack methods, emphasizing the need for adaptive and robust defenses against vulnerabilities highlighted in this study."}}
{"id": "2509.09324", "pdf": "https://arxiv.org/pdf/2509.09324", "abs": "https://arxiv.org/abs/2509.09324", "authors": ["Hui Li", "Yi You", "Qiqi Chen", "Bingfeng Zhang", "George Q. Huang"], "title": "Fine-Grained Customized Fashion Design with Image-into-Prompt benchmark and dataset from LMM", "categories": ["cs.CV"], "comment": null, "summary": "Generative AI evolves the execution of complex workflows in industry, where\nthe large multimodal model empowers fashion design in the garment industry.\nCurrent generation AI models magically transform brainstorming into fancy\ndesigns easily, but the fine-grained customization still suffers from text\nuncertainty without professional background knowledge from end-users. Thus, we\npropose the Better Understanding Generation (BUG) workflow with LMM to\nautomatically create and fine-grain customize the cloth designs from chat with\nimage-into-prompt. Our framework unleashes users' creative potential beyond\nwords and also lowers the barriers of clothing design/editing without further\nhuman involvement. To prove the effectiveness of our model, we propose a new\nFashionEdit dataset that simulates the real-world clothing design workflow,\nevaluated from generation similarity, user satisfaction, and quality. The code\nand dataset: https://github.com/detectiveli/FashionEdit.", "AI": {"tldr": "This paper introduces the BUG workflow with a large multimodal model (LMM) to streamline and enhance clothing design through chat and image-to-prompt features.", "motivation": "The motivation behind this paper is to address the limitations of current generative AI in fine-grained customization where lack of professional background knowledge creates challenges in achieving precise clothing designs.", "method": "The authors propose the Better Understanding Generation (BUG) workflow that integrates a large multimodal model. It takes input from chat and image prompts to generate and customize clothing designs with minimal user expertise needed.", "result": "A new FashionEdit dataset is created to benchmark the BUG workflow. The evaluations focus on generation similarity, user satisfaction, and the quality of the designs, demonstrating the model's effectiveness in real-world conditions.", "conclusion": "The BUG workflow significantly lowers the barriers for users without professional expertise to design and edit clothing while enhancing creative potential with minimal human intervention."}}
{"id": "2509.09611", "pdf": "https://arxiv.org/pdf/2509.09611", "abs": "https://arxiv.org/abs/2509.09611", "authors": ["Haolan Zheng", "Yanlai Chen", "Jiequn Han", "Yue Yu"], "title": "ReBaNO: Reduced Basis Neural Operator Mitigating Generalization Gaps and Achieving Discretization Invariance", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "We propose a novel data-lean operator learning algorithm, the Reduced Basis\nNeural Operator (ReBaNO), to solve a group of PDEs with multiple distinct\ninputs. Inspired by the Reduced Basis Method and the recently introduced\nGenerative Pre-Trained Physics-Informed Neural Networks, ReBaNO relies on a\nmathematically rigorous greedy algorithm to build its network structure offline\nadaptively from the ground up. Knowledge distillation via task-specific\nactivation function allows ReBaNO to have a compact architecture requiring\nminimal computational cost online while embedding physics. In comparison to\nstate-of-the-art operator learning algorithms such as PCA-Net, DeepONet, FNO,\nand CNO, numerical results demonstrate that ReBaNO significantly outperforms\nthem in terms of eliminating/shrinking the generalization gap for both in- and\nout-of-distribution tests and being the only operator learning algorithm\nachieving strict discretization invariance.", "AI": {"tldr": "The paper introduces ReBaNO, a data-efficient operator learning algorithm designed for solving PDEs with multiple inputs, that achieves state-of-the-art generalization and strict discretization invariance.", "motivation": "The motivation is to address the challenges of solving groups of PDEs with multiple distinct inputs while ensuring generalization, computational efficiency, and discretization invariance.", "method": "ReBaNO uses a greedy algorithm for adaptive offline network structure building, paired with task-specific activation functions for efficient and physics-embedded learning.", "result": "Numerical results show that ReBaNO outperforms PCA-Net, DeepONet, FNO, and CNO in terms of generalization capabilities and achieving strict discretization invariance.", "conclusion": "ReBaNO offers a compact, effective, and generalization-enhancing solution for operator learning with minimal computational cost and embedded physics advantages."}}
{"id": "2509.09327", "pdf": "https://arxiv.org/pdf/2509.09327", "abs": "https://arxiv.org/abs/2509.09327", "authors": ["Dimitrios Anastasiou", "Razvan Caramalau", "Nazir Sirajudeen", "Matthew Boal", "Philip Edwards", "Justin Collins", "John Kelly", "Ashwin Sridhar", "Maxine Tran", "Faiz Mumtaz", "Nevil Pavithran", "Nader Francis", "Danail Stoyanov", "Evangelos B. Mazomenos"], "title": "Exploring Pre-training Across Domains for Few-Shot Surgical Skill Assessment", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at MICCAI 2025 DEMI Workshop", "summary": "Automated surgical skill assessment (SSA) is a central task in surgical\ncomputer vision. Developing robust SSA models is challenging due to the\nscarcity of skill annotations, which are time-consuming to produce and require\nexpert consensus. Few-shot learning (FSL) offers a scalable alternative\nenabling model development with minimal supervision, though its success\ncritically depends on effective pre-training. While widely studied for several\nsurgical downstream tasks, pre-training has remained largely unexplored in SSA.\nIn this work, we formulate SSA as a few-shot task and investigate how\nself-supervised pre-training strategies affect downstream few-shot SSA\nperformance. We annotate a publicly available robotic surgery dataset with\nObjective Structured Assessment of Technical Skill (OSATS) scores, and evaluate\nvarious pre-training sources across three few-shot settings. We quantify domain\nsimilarity and analyze how domain gap and the inclusion of procedure-specific\ndata into pre-training influence transferability. Our results show that small\nbut domain-relevant datasets can outperform large scale, less aligned ones,\nachieving accuracies of 60.16%, 66.03%, and 73.65% in the 1-, 2-, and 5-shot\nsettings, respectively. Moreover, incorporating procedure-specific data into\npre-training with a domain-relevant external dataset significantly boosts\ndownstream performance, with an average gain of +1.22% in accuracy and +2.28%\nin F1-score; however, applying the same strategy with less similar but\nlarge-scale sources can instead lead to performance degradation. Code and\nmodels are available at https://github.com/anastadimi/ssa-fsl.", "AI": {"tldr": "This paper explores self-supervised pre-training strategies for few-shot surgical skill assessment. It highlights the importance of domain-relevant datasets over large, unrelated datasets.", "motivation": "Surgical skill assessment is challenging due to the scarcity of labeled data, necessitating scalable alternatives like few-shot learning, which rely on effective pre-training.", "method": "The authors annotate a public robotic surgery dataset with skill scores and evaluate various self-supervised pre-training sources in multiple few-shot settings. Domain similarity and procedure-specific data inclusion are analyzed.", "result": "Small, domain-relevant datasets demonstrate better performance in few-shot learning scenarios compared to large, less aligned datasets. Incorporating procedure-specific data improves both accuracy (+1.22%) and F1-score (+2.28%).", "conclusion": "For surgical skill assessment, smaller datasets closely aligned with the domain outperform larger, unrelated datasets in few-shot learning setups. Procedure-specific pre-training yields notable performance gains."}}
{"id": "2509.09616", "pdf": "https://arxiv.org/pdf/2509.09616", "abs": "https://arxiv.org/abs/2509.09616", "authors": ["Ignacy St\u0119pka", "Jerzy Stefanowski"], "title": "Explaining Concept Drift through the Evolution of Group Counterfactuals", "categories": ["cs.LG", "cs.AI"], "comment": "TempXAI Workshop @ ECML PKDD 2025", "summary": "Machine learning models in dynamic environments often suffer from concept\ndrift, where changes in the data distribution degrade performance. While\ndetecting this drift is a well-studied topic, explaining how and why the\nmodel's decision-making logic changes still remains a significant challenge. In\nthis paper, we introduce a novel methodology to explain concept drift by\nanalyzing the temporal evolution of group-based counterfactual explanations\n(GCEs). Our approach tracks shifts in the GCEs' cluster centroids and their\nassociated counterfactual action vectors before and after a drift. These\nevolving GCEs act as an interpretable proxy, revealing structural changes in\nthe model's decision boundary and its underlying rationale. We operationalize\nthis analysis within a three-layer framework that synergistically combines\ninsights from the data layer (distributional shifts), the model layer\n(prediction disagreement), and our proposed explanation layer. We show that\nsuch holistic view allows for a more comprehensive diagnosis of drift, making\nit possible to distinguish between different root causes, such as a spatial\ndata shift versus a re-labeling of concepts.", "AI": {"tldr": "The paper proposes a novel method for explaining concept drift in machine learning models by analyzing the temporal evolution of group-based counterfactual explanations (GCEs).", "motivation": "To address the challenge of understanding how and why a model's decision-making logic changes in the presence of concept drift.", "method": "The method tracks shifts in GCEs' cluster centroids and counterfactual action vectors before and after drift, combining insights from data shifts, prediction disagreements, and explanation levels in a three-layer framework.", "result": "The approach enables a comprehensive diagnosis of drift, distinguishing between different root causes, such as spatial data shifts versus concept re-labeling.", "conclusion": "By leveraging evolving GCEs, the methodology provides interpretable proxies for structural changes in models, facilitating better understanding and troubleshooting of concept drift."}}
{"id": "2509.09631", "pdf": "https://arxiv.org/pdf/2509.09631", "abs": "https://arxiv.org/abs/2509.09631", "authors": ["Ngoc-Son Nguyen", "Hieu-Nghia Huynh-Nguyen", "Thanh V. T. Tran", "Truong-Son Hy", "Van Nguyen"], "title": "DiFlow-TTS: Discrete Flow Matching with Factorized Speech Tokens for Low-Latency Zero-Shot Text-To-Speech", "categories": ["cs.SD", "cs.CL", "cs.CV"], "comment": null, "summary": "Zero-shot Text-to-Speech (TTS) aims to synthesize high-quality speech that\nmimics the voice of an unseen speaker using only a short reference sample,\nrequiring not only speaker adaptation but also accurate modeling of prosodic\nattributes. Recent approaches based on language models, diffusion, and flow\nmatching have shown promising results in zero-shot TTS, but still suffer from\nslow inference and repetition artifacts. Discrete codec representations have\nbeen widely adopted for speech synthesis, and recent works have begun to\nexplore diffusion models in purely discrete settings, suggesting the potential\nof discrete generative modeling for speech synthesis. However, existing\nflow-matching methods typically embed these discrete tokens into a continuous\nspace and apply continuous flow matching, which may not fully leverage the\nadvantages of discrete representations. To address these challenges, we\nintroduce DiFlow-TTS, which, to the best of our knowledge, is the first model\nto explore purely Discrete Flow Matching for speech synthesis. DiFlow-TTS\nexplicitly models factorized speech attributes within a compact and unified\narchitecture. It leverages in-context learning by conditioning on textual\ncontent, along with prosodic and acoustic attributes extracted from a reference\nspeech, enabling effective attribute cloning in a zero-shot setting. In\naddition, the model employs a factorized flow prediction mechanism with\ndistinct heads for prosody and acoustic details, allowing it to learn\naspect-specific distributions. Experimental results demonstrate that DiFlow-TTS\nachieves promising performance in several key metrics, including naturalness,\nprosody, preservation of speaker style, and energy control. It also maintains a\ncompact model size and achieves low-latency inference, generating speech up to\n25.8 times faster than the latest existing baselines.", "AI": {"tldr": "DiFlow-TTS introduces a novel approach in zero-shot Text-to-Speech synthesis by utilizing purely Discrete Flow Matching for fast and high-quality speech generation.", "motivation": "Current zero-shot TTS systems face challenges such as slow inference speed and repetition artifacts while attempting to synthesize high-quality speech mimicking unseen speakers. Existing approaches do not fully utilize discrete representations in flow-matching methods.", "method": "DiFlow-TTS employs a purely Discrete Flow Matching mechanism, modeling factorized speech attributes through distinct heads for prosody and acoustic details. The model utilizes in-context learning by conditioning the synthesis on textual and prosodic/acoustic attributes extracted from reference speech.", "result": "The model achieves improved performance across metrics like speech naturalness, prosody, and speaker style mimicry. Additionally, it offers faster synthesis, generating speech up to 25.8 times quicker than existing baselines.", "conclusion": "DiFlow-TTS establishes a novel, efficient, and high-performing method for zero-shot TTS, leveraging discrete generative modeling with low-latency and compact architecture advancements."}}
{"id": "2509.09619", "pdf": "https://arxiv.org/pdf/2509.09619", "abs": "https://arxiv.org/abs/2509.09619", "authors": ["Roshan Balaji", "Joe Bobby", "Nirav Pravinbhai Bhatt"], "title": "Functional Groups are All you Need for Chemically Interpretable Molecular Property Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Molecular property prediction using deep learning (DL) models has accelerated\ndrug and materials discovery, but the resulting DL models often lack\ninterpretability, hindering their adoption by chemists. This work proposes\ndeveloping molecule representations using the concept of Functional Groups (FG)\nin chemistry. We introduce the Functional Group Representation (FGR) framework,\na novel approach to encoding molecules based on their fundamental chemical\nsubstructures. Our method integrates two types of functional groups: those\ncurated from established chemical knowledge (FG), and those mined from a large\nmolecular corpus using sequential pattern mining (MFG). The resulting FGR\nframework encodes molecules into a lower-dimensional latent space by leveraging\npre-training on a large dataset of unlabeled molecules. Furthermore, the\nproposed framework allows the inclusion of 2D structure-based descriptors of\nmolecules. We demonstrate that the FGR framework achieves state-of-the-art\nperformance on a diverse range of 33 benchmark datasets spanning physical\nchemistry, biophysics, quantum mechanics, biological activity, and\npharmacokinetics while enabling chemical interpretability. Crucially, the\nmodel's representations are intrinsically aligned with established chemical\nprinciples, allowing chemists to directly link predicted properties to specific\nfunctional groups and facilitating novel insights into structure-property\nrelationships. Our work presents a significant step toward developing\nhigh-performing, chemically interpretable DL models for molecular discovery.", "AI": {"tldr": "This paper introduces the Functional Group Representation (FGR) framework for molecular property prediction using functional group-based encodings to improve performance and interpretability of deep learning models.", "motivation": "To address the lack of interpretability in deep learning models for molecular property prediction, which hinders their adoption by chemists.", "method": "The paper proposes the Functional Group Representation (FGR) framework, which encodes molecules based on curated and data-mined functional groups, integrating pre-training on large unlabeled datasets and 2D structural descriptors.", "result": "The FGR framework achieved state-of-the-art performance across 33 benchmark datasets and provided chemically interpretable predictions by linking them to specific functional groups.", "conclusion": "This framework enhances the accuracy and interpretability of deep learning models, promoting their relevance and usability for molecular discovery."}}
{"id": "2509.09651", "pdf": "https://arxiv.org/pdf/2509.09651", "abs": "https://arxiv.org/abs/2509.09651", "authors": ["Zakaria El Kassimi", "Fares Fourati", "Mohamed-Slim Alouini"], "title": "Retrieval-Augmented Generation for Reliable Interpretation of Radio Regulations", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG", "eess.SP"], "comment": null, "summary": "We study question answering in the domain of radio regulations, a legally\nsensitive and high-stakes area. We propose a telecom-specific\nRetrieval-Augmented Generation (RAG) pipeline and introduce, to our knowledge,\nthe first multiple-choice evaluation set for this domain, constructed from\nauthoritative sources using automated filtering and human validation. To assess\nretrieval quality, we define a domain-specific retrieval metric, under which\nour retriever achieves approximately 97% accuracy. Beyond retrieval, our\napproach consistently improves generation accuracy across all tested models. In\nparticular, while naively inserting documents without structured retrieval\nyields only marginal gains for GPT-4o (less than 1%), applying our pipeline\nresults in nearly a 12% relative improvement. These findings demonstrate that\ncarefully targeted grounding provides a simple yet strong baseline and an\neffective domain-specific solution for regulatory question answering. All code\nand evaluation scripts, along with our derived question-answer dataset, are\navailable at https://github.com/Zakaria010/Radio-RAG.", "AI": {"tldr": "The paper introduces a telecom-specific Retrieval-Augmented Generation (RAG) pipeline for question answering in radio regulations and demonstrates its effectiveness through improved accuracy and evaluation metrics.", "motivation": "The authors aim to address the challenges of question answering in the legally sensitive and high-stakes domain of radio regulations.", "method": "The study develops a telecom-specific RAG pipeline, creates a multiple-choice evaluation set, defines a domain-specific retrieval metric, and benchmarks retrieval and generation models using their approach.", "result": "The retrieval method achieves 97% accuracy in its domain-specific metric, and their pipeline improves GPT-4o generation accuracy by nearly 12% relative improvement, far outperforming unstructured document insertion.", "conclusion": "The research demonstrates that targeted grounding with their RAG pipeline is both a strong baseline and an effective domain-specific solution for regulatory question answering."}}
{"id": "2509.09352", "pdf": "https://arxiv.org/pdf/2509.09352", "abs": "https://arxiv.org/abs/2509.09352", "authors": ["Xiaodong Wang", "Zijun He", "Xin Yuan"], "title": "Texture-aware Intrinsic Image Decomposition with Model- and Learning-based Priors", "categories": ["cs.CV"], "comment": null, "summary": "This paper aims to recover the intrinsic reflectance layer and shading layer\ngiven a single image. Though this intrinsic image decomposition problem has\nbeen studied for decades, it remains a significant challenge in cases of\ncomplex scenes, i.e. spatially-varying lighting effect and rich textures. In\nthis paper, we propose a novel method for handling severe lighting and rich\ntextures in intrinsic image decomposition, which enables to produce\nhigh-quality intrinsic images for real-world images. Specifically, we observe\nthat previous learning-based methods tend to produce texture-less and\nover-smoothing intrinsic images, which can be used to infer the lighting and\ntexture information given a RGB image. In this way, we design a texture-guided\nregularization term and formulate the decomposition problem into an\noptimization framework, to separate the material textures and lighting effect.\nWe demonstrate that combining the novel texture-aware prior can produce\nsuperior results to existing approaches.", "AI": {"tldr": "The paper introduces a new method for intrinsic image decomposition that effectively separates reflectance and shading layers, overcoming challenges in complex scenes with varying lighting and rich textures.", "motivation": "The motivation is to address challenges in intrinsic image decomposition, especially for scenes with severe lighting variations and rich textures, which traditional methods struggle to handle.", "method": "The method introduces a texture-guided regularization term within an optimization framework to differentiate material textures and lighting effects while leveraging prior knowledge.", "result": "The proposed method produces higher-quality intrinsic images compared to previous approaches, overcoming issues like texture-less or over-smoothed outputs.", "conclusion": "Integrating texture-aware priors into intrinsic image decomposition significantly improves the ability to handle real-world complex scenes with better separation of textures and lighting."}}
{"id": "2509.09655", "pdf": "https://arxiv.org/pdf/2509.09655", "abs": "https://arxiv.org/abs/2509.09655", "authors": ["Sanjay Basu", "Sadiq Y. Patel", "Parth Sheth", "Bhairavi Muralidharan", "Namrata Elamaran", "Aakriti Kinra", "Rajaie Batniji"], "title": "Feasibility-Guided Fair Adaptive Offline Reinforcement Learning for Medicaid Care Management", "categories": ["cs.LG", "cs.AI", "cs.LO", "stat.AP"], "comment": "12 pages, 5 figures, 3 tables", "summary": "We introduce Feasibility-Guided Fair Adaptive Reinforcement Learning\n(FG-FARL), an offline RL procedure that calibrates per-group safety thresholds\nto reduce harm while equalizing a chosen fairness target (coverage or harm)\nacross protected subgroups. Using de-identified longitudinal trajectories from\na Medicaid population health management program, we evaluate FG-FARL against\nbehavior cloning (BC) and HACO (Hybrid Adaptive Conformal Offline RL; a global\nconformal safety baseline). We report off-policy value estimates with bootstrap\n95% confidence intervals and subgroup disparity analyses with p-values. FG-FARL\nachieves comparable value to baselines while improving fairness metrics,\ndemonstrating a practical path to safer and more equitable decision support.", "AI": {"tldr": "FG-FARL, a novel offline RL approach, is introduced to improve fairness and safety in decision-making for protected subgroups.", "motivation": "To address fairness and safety in reinforcement learning for scenarios like population health management, where subgroup disparities may cause harm.", "method": "FG-FARL calibrates per-group safety thresholds within an offline RL framework to equalize fairness metrics such as coverage or harm across subgroups.", "result": "FG-FARL delivered comparable value to existing methods like BC and HACO, while significantly enhancing fairness metrics across protected subgroups.", "conclusion": "The method provides a feasible and effective way to implement safer and more equitable decision-making in offline RL applications."}}
{"id": "2509.09365", "pdf": "https://arxiv.org/pdf/2509.09365", "abs": "https://arxiv.org/abs/2509.09365", "authors": ["Xiaodong Wang", "Ping Wang", "Zhangyuan Li", "Xin Yuan"], "title": "Plug-and-play Diffusion Models for Image Compressive Sensing with Data Consistency Projection", "categories": ["cs.CV"], "comment": null, "summary": "We explore the connection between Plug-and-Play (PnP) methods and Denoising\nDiffusion Implicit Models (DDIM) for solving ill-posed inverse problems, with a\nfocus on single-pixel imaging. We begin by identifying key distinctions between\nPnP and diffusion models-particularly in their denoising mechanisms and\nsampling procedures. By decoupling the diffusion process into three\ninterpretable stages: denoising, data consistency enforcement, and sampling, we\nprovide a unified framework that integrates learned priors with physical\nforward models in a principled manner. Building upon this insight, we propose a\nhybrid data-consistency module that linearly combines multiple PnP-style\nfidelity terms. This hybrid correction is applied directly to the denoised\nestimate, improving measurement consistency without disrupting the diffusion\nsampling trajectory. Experimental results on single-pixel imaging tasks\ndemonstrate that our method achieves better reconstruction quality.", "AI": {"tldr": "The paper bridges Plug-and-Play (PnP) approaches and Denoising Diffusion Implicit Models (DDIM), proposing a unified framework for solving inverse problems. Experimental results show improved reconstruction quality in single-pixel imaging.", "motivation": "To integrate learned priors with physical forward models systematically and improve reconstruction quality in ill-posed inverse problems using PnP and DDIM approaches.", "method": "The authors decouple the diffusion process into three stages (denoising, data consistency enforcement, sampling) and introduce a hybrid data-consistency module that combines multiple PnP-style fidelity terms to enhance measurement consistency.", "result": "Experimental results demonstrate improved reconstruction quality in single-pixel imaging tasks using the proposed unified framework.", "conclusion": "The proposed framework effectively combines PnP and DDIM principles, showcasing improved reconstruction quality without disrupting the sampling procedure, especially in single-pixel imaging applications."}}
{"id": "2509.09679", "pdf": "https://arxiv.org/pdf/2509.09679", "abs": "https://arxiv.org/abs/2509.09679", "authors": ["Bingxin Xu", "Zhen Dong", "Oussama Elachqar", "Yuzhang Shang"], "title": "ButterflyQuant: Ultra-low-bit LLM Quantization through Learnable Orthogonal Butterfly Transforms", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Replace discrete Hadamard transforms with continuous Butterfly\n  transforms to facilitate the learning of rotation matrices in LLM\n  quantization", "summary": "Large language models require massive memory footprints, severely limiting\ndeployment on consumer hardware. Quantization reduces memory through lower\nnumerical precision, but extreme 2-bit quantization suffers from catastrophic\nperformance loss due to outliers in activations. Rotation-based methods such as\nQuIP and QuaRot apply orthogonal transforms to eliminate outliers before\nquantization, using computational invariance: $\\mathbf{y} = \\mathbf{Wx} =\n(\\mathbf{WQ}^T)(\\mathbf{Qx})$ for orthogonal $\\mathbf{Q}$. However, these\nmethods use fixed transforms--Hadamard matrices achieving optimal worst-case\ncoherence $\\mu = 1/\\sqrt{n}$--that cannot adapt to specific weight\ndistributions. We identify that different transformer layers exhibit distinct\noutlier patterns, motivating layer-adaptive rotations rather than\none-size-fits-all approaches. We propose ButterflyQuant, which replaces\nHadamard rotations with learnable butterfly transforms parameterized by\ncontinuous Givens rotation angles. Unlike Hadamard's discrete $\\{+1, -1\\}$\nentries that are non-differentiable and prohibit gradient-based learning,\nbutterfly transforms' continuous parameterization enables smooth optimization\nwhile guaranteeing orthogonality by construction. This orthogonal constraint\nensures theoretical guarantees in outlier suppression while achieving $O(n \\log\nn)$ computational complexity with only $\\frac{n \\log n}{2}$ learnable\nparameters. We further introduce a uniformity regularization on\npost-transformation activations to promote smoother distributions amenable to\nquantization. Learning requires only 128 calibration samples and converges in\nminutes on a single GPU--a negligible one-time cost. On LLaMA-2-7B with 2-bit\nquantization, ButterflyQuant achieves 15.4 perplexity versus 22.1 for QuaRot.", "AI": {"tldr": "This paper introduces ButterflyQuant, a novel method for 2-bit quantization in large language models using learnable butterfly transforms to handle activation outliers.", "motivation": "To address the memory challenges in deploying large language models on consumer hardware while overcoming performance degradation caused by fixed quantization methods.", "method": "The authors replace fixed Hadamard rotations with learnable butterfly transforms parameterized by continuous Givens rotation angles. Orthogonality is enforced to achieve efficient outlier suppression and uniformity in activations.", "result": "On LLaMA-2-7B, ButterflyQuant achieves a perplexity of 15.4, significantly better than QuaRot's 22.1, for 2-bit quantization using only minimal calibration samples and computation time.", "conclusion": "ButterflyQuant offers an efficient, layer-adaptive quantization approach with improved performance metrics and computational effectiveness for memory-limited deployment of large language models."}}
{"id": "2509.09368", "pdf": "https://arxiv.org/pdf/2509.09368", "abs": "https://arxiv.org/abs/2509.09368", "authors": ["Pengxu Wen", "Tingting Yu", "Ziwei Nie", "Cheng Jiang", "Zhenyu Yin", "Mingyang He", "Bo Liao", "Xiaoping Yang"], "title": "A Fully Automatic Framework for Intracranial Pressure Grading: Integrating Keyframe Identification, ONSD Measurement and Clinical Data", "categories": ["cs.CV"], "comment": null, "summary": "Intracranial pressure (ICP) elevation poses severe threats to cerebral\nfunction, thus necessitating monitoring for timely intervention. While lumbar\npuncture is the gold standard for ICP measurement, its invasiveness and\nassociated risks drive the need for non-invasive alternatives. Optic nerve\nsheath diameter (ONSD) has emerged as a promising biomarker, as elevated ICP\ndirectly correlates with increased ONSD. However, current clinical practices\nfor ONSD measurement suffer from inconsistency in manual operation,\nsubjectivity in optimal view selection, and variability in thresholding,\nlimiting their reliability. To address these challenges, we introduce a fully\nautomatic two-stage framework for ICP grading, integrating keyframe\nidentification, ONSD measurement and clinical data. Specifically, the fundus\nultrasound video processing stage performs frame-level anatomical segmentation,\nrule-based keyframe identification guided by an international consensus\nstatement, and precise ONSD measurement. The intracranial pressure grading\nstage then fuses ONSD metrics with clinical features to enable the prediction\nof ICP grades, thereby demonstrating an innovative blend of interpretable\nultrasound analysis and multi-source data integration for objective clinical\nevaluation. Experimental results demonstrate that our method achieves a\nvalidation accuracy of $0.845 \\pm 0.071$ (with standard deviation from\nfive-fold cross-validation) and an independent test accuracy of 0.786,\nsignificantly outperforming conventional threshold-based method ($0.637 \\pm\n0.111$ validation accuracy, $0.429$ test accuracy). Through effectively\nreducing operator variability and integrating multi-source information, our\nframework establishes a reliable non-invasive approach for clinical ICP\nevaluation, holding promise for improving patient management in acute\nneurological conditions.", "AI": {"tldr": "The paper introduces a fully automatic two-stage framework for grading intracranial pressure (ICP) using optic nerve sheath diameter (ONSD) and clinical data, achieving higher accuracy compared to traditional methods.", "motivation": "The study is motivated by the need for a reliable, non-invasive alternative to measure intracranial pressure, as traditional methods like lumbar puncture are invasive and risky.", "method": "The researchers developed a two-stage framework: first, it processes fundus ultrasound videos for segmentation, keyframe identification, and ONSD measurement; second, it combines these ONSD metrics with clinical data for ICP grade prediction.", "result": "The framework achieved a validation accuracy of 0.845 \u00b1 0.071 and a test accuracy of 0.786, significantly outperforming traditional threshold-based methods.", "conclusion": "This framework reduces operator variability and integrates multi-source data, providing a reliable non-invasive solution for ICP evaluation and improving patient care in neurological conditions."}}
{"id": "2509.08830", "pdf": "https://arxiv.org/pdf/2509.08830", "abs": "https://arxiv.org/abs/2509.08830", "authors": ["Seong-A Park", "Jong-Eui Chae", "Sungdong Kim", "Hyung-Chul Lee", "Hyun-Lim Yang"], "title": "A Masked Representation Learning to Model Cardiac Functions Using Multiple Physiological Signals", "categories": ["eess.SP", "cs.LG"], "comment": "16 pages, 5 figures", "summary": "In clinical settings, monitoring hemodynamics is crucial for managing patient\nprognosis, necessitating the integrated analysis of multiple physiological\nsignals. While recent research has analyzed single signals such as\nelectrocardiography (ECG) or photoplethysmography (PPG), there has yet to be a\nproposal for an approach that encompasses the complex signal analysis required\nin actual clinical scenarios. In this study, we introduce the SNUPHY-M (Seoul\nNational University hospital PHYsiological signal Masked representation\nlearning) model extracts physiological features reflecting the electrical,\npressure, and fluid characteristics of the cardiac cycle in the process of\nrestoring three masked physiological signals based on self-supervised learning\n(SSL): ECG, PPG, and arterial blood pressure (ABP) signals. By employing\nmultiple physical characteristics, the model can extract more enriched features\nonly using non-invasive signals. We evaluated the model's performance in\nclinical downstream tasks such as hypotension, stroke volume, systolic blood\npressure, diastolic blood pressure, and age prediction. Our results showed that\nthe SNUPHY-M significantly outperformed supervised or SSL models, especially in\nprediction tasks using non-invasive signals. To the best of our knowledge,\nSNUPHY-M is the first model to apply multi-modal SSL to cardiovascular analysis\ninvolving ECG, PPG, and ABP signals. This approach effectively supports\nclinical decision-making and enables precise diagnostics, contributing\nsignificantly to the early diagnosis and management of hemodynamics without\ninvasiveness.", "AI": {"tldr": "This paper introduces SNUPHY-M, a self-supervised learning model integrating ECG, PPG, and ABP signals to enhance hemodynamic analysis for clinical applications.", "motivation": "Clinical settings require integrated analysis of multiple physiological signals to accurately monitor hemodynamics and improve patient prognosis.", "method": "SNUPHY-M uses self-supervised learning to restore masked ECG, PPG, and ABP signals while extracting enriched physiological features useful for clinical predictions.", "result": "The SNUPHY-M model outperformed other supervised and SSL models in clinical prediction tasks utilizing non-invasive signals.", "conclusion": "SNUPHY-M represents a significant advancement, enabling multi-modal signal analysis without invasiveness, thus enhancing early diagnosis and management in clinical hemodynamics."}}
{"id": "2509.09680", "pdf": "https://arxiv.org/pdf/2509.09680", "abs": "https://arxiv.org/abs/2509.09680", "authors": ["Rongyao Fang", "Aldrich Yu", "Chengqi Duan", "Linjiang Huang", "Shuai Bai", "Yuxuan Cai", "Kun Wang", "Si Liu", "Xihui Liu", "Hongsheng Li"], "title": "FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark", "categories": ["cs.CV", "cs.CL"], "comment": "Project page: https://flux-reason-6m.github.io/", "summary": "The advancement of open-source text-to-image (T2I) models has been hindered\nby the absence of large-scale, reasoning-focused datasets and comprehensive\nevaluation benchmarks, resulting in a performance gap compared to leading\nclosed-source systems. To address this challenge, We introduce FLUX-Reason-6M\nand PRISM-Bench (Precise and Robust Image Synthesis Measurement Benchmark).\nFLUX-Reason-6M is a massive dataset consisting of 6 million high-quality\nFLUX-generated images and 20 million bilingual (English and Chinese)\ndescriptions specifically designed to teach complex reasoning. The image are\norganized according to six key characteristics: Imagination, Entity, Text\nrendering, Style, Affection, and Composition, and design explicit Generation\nChain-of-Thought (GCoT) to provide detailed breakdowns of image generation\nsteps. The whole data curation takes 15,000 A100 GPU days, providing the\ncommunity with a resource previously unattainable outside of large industrial\nlabs. PRISM-Bench offers a novel evaluation standard with seven distinct\ntracks, including a formidable Long Text challenge using GCoT. Through\ncarefully designed prompts, it utilizes advanced vision-language models for\nnuanced human-aligned assessment of prompt-image alignment and image\naesthetics. Our extensive evaluation of 19 leading models on PRISM-Bench\nreveals critical performance gaps and highlights specific areas requiring\nimprovement. Our dataset, benchmark, and evaluation code are released to\ncatalyze the next wave of reasoning-oriented T2I generation. Project page:\nhttps://flux-reason-6m.github.io/ .", "AI": {"tldr": "The paper addresses a gap in reasoning-focused T2I models by introducing a large-scale dataset (FLUX-Reason-6M) and evaluation benchmark (PRISM-Bench). These resources aim to boost reasoning capabilities and offer a rigorous standard for model evaluation.", "motivation": "The motivation stems from the performance gap in open-source T2I models compared to closed-source systems due to lack of reasoning-centric resources.", "method": "Authors developed a massive dataset (FLUX-Reason-6M) with bilingual descriptions and six characteristics, alongside the PRISM-Bench evaluation framework with uniquely designed assessment tracks.", "result": "Evaluation on 19 models showcased performance gaps and areas needing improvement, validating the utility of these new resources.", "conclusion": "Releasing FLUX-Reason-6M and PRISM-Bench aims to catalyze advancements in reasoning-oriented T2I generation and facilitate growth in the open-source community."}}
{"id": "2509.09375", "pdf": "https://arxiv.org/pdf/2509.09375", "abs": "https://arxiv.org/abs/2509.09375", "authors": ["Botong Zhao", "Qijun Shi", "Shujing Lyu", "Yue Lu"], "title": "Unsupervised Integrated-Circuit Defect Segmentation via Image-Intrinsic Normality", "categories": ["cs.CV"], "comment": null, "summary": "Modern Integrated-Circuit(IC) manufacturing introduces diverse, fine-grained\ndefects that depress yield and reliability. Most industrial defect segmentation\ncompares a test image against an external normal set, a strategy that is\nbrittle for IC imagery where layouts vary across products and accurate\nalignment is difficult. We observe that defects are predominantly local, while\neach image still contains rich, repeatable normal patterns. We therefore\npropose an unsupervised IC defect segmentation framework that requires no\nexternal normal support. A learnable normal-information extractor aggregates\nrepresentative normal features from the test image, and a coherence loss\nenforces their association with normal regions. Guided by these features, a\ndecoder reconstructs only normal content; the reconstruction residual then\nsegments defects. Pseudo-anomaly augmentation further stabilizes training.\nExperiments on datasets from three IC process stages show consistent\nimprovements over existing approaches and strong robustness to product\nvariability.", "AI": {"tldr": "The paper proposes an unsupervised IC defect segmentation framework that eliminates reliance on external normal image sets, focusing on inherent patterns in the test image for robust defect identification.", "motivation": "Address limitations of traditional IC defect segmentation methods that require external normal image sets, which can be brittle due to product variability and difficult alignment.", "method": "The approach involves an unsupervised framework with a learnable normal-information extractor, coherence loss for normalization, and reconstruction residuals to segment defects, complemented by pseudo-anomaly augmentation for stable training.", "result": "Experiments across three IC process stages demonstrate the approach's consistent performance improvement and robustness to variability in IC products.", "conclusion": "The proposed framework effectively segments IC defects using local image information without external references, making it adaptable and robust across diverse manufacturing stages."}}
{"id": "2509.09397", "pdf": "https://arxiv.org/pdf/2509.09397", "abs": "https://arxiv.org/abs/2509.09397", "authors": ["Umaima Rahman", "Raza Imam", "Mohammad Yaqub", "Dwarikanath Mahapatra"], "title": "Decoupling Clinical and Class-Agnostic Features for Reliable Few-Shot Adaptation under Shift", "categories": ["cs.CV"], "comment": null, "summary": "Medical vision-language models (VLMs) offer promise for clinical decision\nsupport, yet their reliability under distribution shifts remains a major\nconcern for safe deployment. These models often learn task-agnostic\ncorrelations due to variability in imaging protocols and free-text reports,\nlimiting their generalizability and increasing the risk of failure in\nreal-world settings. We propose DRiFt, a structured feature decoupling\nframework that explicitly separates clinically relevant signals from\ntask-agnostic noise using parameter-efficient tuning (LoRA) and learnable\nprompt tokens. To enhance cross-modal alignment and reduce uncertainty, we\ncurate high-quality, clinically grounded image-text pairs by generating\ncaptions for a diverse medical dataset. Our approach improves in-distribution\nperformance by +11.4% Top-1 accuracy and +3.3% Macro-F1 over prior prompt-based\nmethods, while maintaining strong robustness across unseen datasets. Ablation\nstudies reveal that disentangling task-relevant features and careful alignment\nsignificantly enhance model generalization and reduce unpredictable behavior\nunder domain shift. These insights contribute toward building safer, more\ntrustworthy VLMs for clinical use. The code is available at\nhttps://github.com/rumaima/DRiFt.", "AI": {"tldr": "This paper introduces DRiFt, a structured feature decoupling framework aimed at improving medical vision-language models' reliability and generalizability by separating clinically relevant signals from irrelevant noise.", "motivation": "There is a critical need to enhance the reliability and generalizability of medical VLMs under distribution shifts to ensure their safe deployment in clinical settings.", "method": "DRiFt uses parameter-efficient tuning (LoRA) and learnable prompt tokens to decouple clinically relevant signals from task-agnostic noise, and leverages high-quality image-text pairs for better cross-modal alignment.", "result": "The proposed approach boosts in-distribution performance (+11.4% Top-1 accuracy and +3.3% Macro-F1) and demonstrates strong robustness across unseen datasets.", "conclusion": "Disentangling task-relevant features and achieving careful alignment significantly enhance the generalization and safety of vision-language models, paving the way for more trustworthy clinical applications."}}
{"id": "2509.09427", "pdf": "https://arxiv.org/pdf/2509.09427", "abs": "https://arxiv.org/abs/2509.09427", "authors": ["Yuchan Jie", "Yushen Xu", "Xiaosong Li", "Fuqiang Zhou", "Jianming Lv", "Huafeng Li"], "title": "FS-Diff: Semantic guidance and clarity-aware simultaneous multimodal image fusion and super-resolution", "categories": ["cs.CV"], "comment": null, "summary": "As an influential information fusion and low-level vision technique, image\nfusion integrates complementary information from source images to yield an\ninformative fused image. A few attempts have been made in recent years to\njointly realize image fusion and super-resolution. However, in real-world\napplications such as military reconnaissance and long-range detection missions,\nthe target and background structures in multimodal images are easily corrupted,\nwith low resolution and weak semantic information, which leads to suboptimal\nresults in current fusion techniques. In response, we propose FS-Diff, a\nsemantic guidance and clarity-aware joint image fusion and super-resolution\nmethod. FS-Diff unifies image fusion and super-resolution as a conditional\ngeneration problem. It leverages semantic guidance from the proposed clarity\nsensing mechanism for adaptive low-resolution perception and cross-modal\nfeature extraction. Specifically, we initialize the desired fused result as\npure Gaussian noise and introduce the bidirectional feature Mamba to extract\nthe global features of the multimodal images. Moreover, utilizing the source\nimages and semantics as conditions, we implement a random iterative denoising\nprocess via a modified U-Net network. This network istrained for denoising at\nmultiple noise levels to produce high-resolution fusion results with\ncross-modal features and abundant semantic information. We also construct a\npowerful aerial view multiscene (AVMS) benchmark covering 600 pairs of images.\nExtensive joint image fusion and super-resolution experiments on six public and\nour AVMS datasets demonstrated that FS-Diff outperforms the state-of-the-art\nmethods at multiple magnifications and can recover richer details and semantics\nin the fused images. The code is available at\nhttps://github.com/XylonXu01/FS-Diff.", "AI": {"tldr": "FS-Diff proposes a novel joint image fusion and super-resolution method for multimodal images, ensuring better semantic detail and resolution recovery.", "motivation": "To address the challenge of corrupted target and background structures in low-resolution and weak semantic multimodal images, which lead to suboptimal fusion results in existing methods.", "method": "FS-Diff integrates image fusion and super-resolution as a conditional generation problem, utilizing a clarity-sensing mechanism, a bidirectional feature 'Mamba,' and a modified U-Net for denoising at different noise levels.", "result": "Experiments on six published datasets and the newly constructed AVMS dataset demonstrated that FS-Diff surpasses state-of-the-art methods, providing superior details and semantic recovery at different magnifications.", "conclusion": "FS-Diff represents a significant advancement in achieving high-quality image fusion and super-resolution, suitable for applications like military reconnaissance and long-distance detection tasks."}}
{"id": "2509.08858", "pdf": "https://arxiv.org/pdf/2509.08858", "abs": "https://arxiv.org/abs/2509.08858", "authors": ["Oriane Peter", "Kate Devlin"], "title": "Decentralising LLM Alignment: A Case for Context, Pluralism, and Participation", "categories": ["cs.CY", "cs.LG"], "comment": "Accepted at AIES 2025", "summary": "Large Language Models (LLMs) alignment methods have been credited with the\ncommercial success of products like ChatGPT, given their role in steering LLMs\ntowards user-friendly outputs. However, current alignment techniques\npredominantly mirror the normative preferences of a narrow reference group,\neffectively imposing their values on a wide user base. Drawing on theories of\nthe power/knowledge nexus, this work argues that current alignment practices\ncentralise control over knowledge production and governance within already\ninfluential institutions. To counter this, we propose decentralising alignment\nthrough three characteristics: context, pluralism, and participation.\nFurthermore, this paper demonstrates the critical importance of delineating the\ncontext-of-use when shaping alignment practices by grounding each of these\nfeatures in concrete use cases. This work makes the following contributions:\n(1) highlighting the role of context, pluralism, and participation in\ndecentralising alignment; (2) providing concrete examples to illustrate these\nstrategies; and (3) demonstrating the nuanced requirements associated with\napplying alignment across different contexts of use. Ultimately, this paper\npositions LLM alignment as a potential site of resistance against epistemic\ninjustice and the erosion of democratic processes, while acknowledging that\nthese strategies alone cannot substitute for broader societal changes.", "AI": {"tldr": "The paper critiques current alignment methods of large language models (LLMs) for centralizing control and proposes a decentralized approach based on context, pluralism, and participation, supported with concrete use cases.", "motivation": "Current alignment techniques in LLMs disproportionately reflect normative values of a small reference group, consolidating knowledge governance within influential institutions, and creating potential epistemic injustices.", "method": "The authors propose decentralizing LLM alignment using three key principles: context, pluralism, and participation. They ground their framework in specific use cases to illustrate its applicability.", "result": "The paper highlights the significance of decentralizing LLM alignment and provides practical examples to illustrate context-specific strategies while addressing the nuances of implementation.", "conclusion": "LLM alignment, if guided by decentralization principles, can fight against epistemic injustices and support democratic values, though these methods alone cannot address the larger societal inequalities."}}
{"id": "2509.09429", "pdf": "https://arxiv.org/pdf/2509.09429", "abs": "https://arxiv.org/abs/2509.09429", "authors": ["Peisong Wen", "Qianqian Xu", "Siran Dai", "Runmin Cong", "Qingming Huang"], "title": "Semantic Concentration for Self-Supervised Dense Representations Learning", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Recent advances in image-level self-supervised learning (SSL) have made\nsignificant progress, yet learning dense representations for patches remains\nchallenging. Mainstream methods encounter an over-dispersion phenomenon that\npatches from the same instance/category scatter, harming downstream performance\non dense tasks. This work reveals that image-level SSL avoids over-dispersion\nby involving implicit semantic concentration. Specifically, the non-strict\nspatial alignment ensures intra-instance consistency, while shared patterns,\ni.e., similar parts of within-class instances in the input space, ensure\ninter-image consistency. Unfortunately, these approaches are infeasible for\ndense SSL due to their spatial sensitivity and complicated scene-centric data.\nThese observations motivate us to explore explicit semantic concentration for\ndense SSL. First, to break the strict spatial alignment, we propose to distill\nthe patch correspondences. Facing noisy and imbalanced pseudo labels, we\npropose a noise-tolerant ranking loss. The core idea is extending the Average\nPrecision (AP) loss to continuous targets, such that its decision-agnostic and\nadaptive focusing properties prevent the student model from being misled.\nSecond, to discriminate the shared patterns from complicated scenes, we propose\nthe object-aware filter to map the output space to an object-based space.\nSpecifically, patches are represented by learnable prototypes of objects via\ncross-attention. Last but not least, empirical studies across various tasks\nsoundly support the effectiveness of our method. Code is available in\nhttps://github.com/KID-7391/CoTAP.", "AI": {"tldr": "This paper addresses the challenges of learning dense representations for patches in self-supervised learning (SSL) by revealing issues of over-dispersion and introducing methods for explicit semantic concentration using a noise-tolerant ranking loss and object-aware filtering.", "motivation": "The authors aim to address the over-dispersion phenomenon in dense SSL, where patches from the same instance scatter and harm downstream performance, in contrast to image-level SSL which benefits from implicit semantic concentration.", "method": "The paper proposes distilling patch correspondences to break strict spatial alignment and using a noise-tolerant ranking loss extended from Average Precision loss. Additionally, the authors introduce an object-aware filter to map patch representations to object-based spaces via cross-attention.", "result": "Empirical studies demonstrate the effectiveness of the proposed methods across various tasks. Code for replication is provided.", "conclusion": "Explicit semantic concentration techniques, such as noise-tolerant ranking loss and object-aware filtering, effectively mitigate the challenges in dense SSL, enabling significant improvements in representation learning."}}
{"id": "2509.08872", "pdf": "https://arxiv.org/pdf/2509.08872", "abs": "https://arxiv.org/abs/2509.08872", "authors": ["Felipe \u00c1lvarez Barrientos", "Tom\u00e1s Banduc", "Isabeau Sirven", "Francisco Sahli Costabal"], "title": "WarpPINN-fibers: improved cardiac strain estimation from cine-MR with physics-informed neural networks", "categories": ["eess.IV", "cs.LG", "physics.med-ph"], "comment": null, "summary": "The contractile motion of the heart is strongly determined by the\ndistribution of the fibers that constitute cardiac tissue. Strain analysis\ninformed with the orientation of fibers allows to describe several pathologies\nthat are typically associated with impaired mechanics of the myocardium, such\nas cardiovascular disease. Several methods have been developed to estimate\nstrain-derived metrics from traditional imaging techniques. However, the\nphysical models underlying these methods do not include fiber mechanics,\nrestricting their capacity to accurately explain cardiac function. In this\nwork, we introduce WarpPINN-fibers, a physics-informed neural network framework\nto accurately obtain cardiac motion and strains enhanced by fiber information.\nWe train our neural network to satisfy a hyper-elastic model and promote fiber\ncontraction with the goal to predict the deformation field of the heart from\ncine magnetic resonance images. For this purpose, we build a loss function\ncomposed of three terms: a data-similarity loss between the reference and the\nwarped template images, a regularizer enforcing near-incompressibility of\ncardiac tissue and a fiber-stretch penalization that controls strain in the\ndirection of synthetically produced fibers. We show that our neural network\nimproves the former WarpPINN model and effectively controls fiber stretch in a\nsynthetic phantom experiment. Then, we demonstrate that WarpPINN-fibers\noutperforms alternative methodologies in landmark-tracking and strain curve\nprediction for a cine-MRI benchmark with a cohort of 15 healthy volunteers. We\nexpect that our method will enable a more precise quantification of cardiac\nstrains through accurate deformation fields that are consistent with fiber\nphysiology, without requiring imaging techniques more sophisticated than MRI.", "AI": {"tldr": "The paper presents WarpPINN-fibers, a physics-informed neural network that leverages cardiac fiber information to improve the accuracy of strain and motion predictions in the heart using cine MRI data.", "motivation": "The motivation is to address the limited accuracy of existing cardiac strain estimation approaches, which fail to incorporate fiber mechanics essential to accurately describing heart function and related pathologies.", "method": "The authors developed WarpPINN-fibers, a neural network trained on a hyper-elastic model with a novel loss function combining data similarity, near-incompressibility regularization, and fiber-stretch penalization. This framework uses cine MRI to predict deformation fields in cardiac tissue.", "result": "WarpPINN-fibers enhances strain estimation by improving fiber stretch control and outperforms previous methodologies in both synthetic phantom and real-world cine MRI experiments involving 15 healthy volunteers.", "conclusion": "The study concludes that WarpPINN-fibers can provide highly accurate deformation fields and strain predictions that align with fiber physiology using standard MRI imaging techniques."}}
{"id": "2509.09456", "pdf": "https://arxiv.org/pdf/2509.09456", "abs": "https://arxiv.org/abs/2509.09456", "authors": ["Yushen Xu", "Xiaosong Li", "Yuchun Wang", "Xiaoqi Cheng", "Huafeng Li", "Haishu Tan"], "title": "FlexiD-Fuse: Flexible number of inputs multi-modal medical image fusion based on diffusion model", "categories": ["cs.CV"], "comment": null, "summary": "Different modalities of medical images provide unique physiological and\nanatomical information for diseases. Multi-modal medical image fusion\nintegrates useful information from different complementary medical images with\ndifferent modalities, producing a fused image that comprehensively and\nobjectively reflects lesion characteristics to assist doctors in clinical\ndiagnosis. However, existing fusion methods can only handle a fixed number of\nmodality inputs, such as accepting only two-modal or tri-modal inputs, and\ncannot directly process varying input quantities, which hinders their\napplication in clinical settings. To tackle this issue, we introduce\nFlexiD-Fuse, a diffusion-based image fusion network designed to accommodate\nflexible quantities of input modalities. It can end-to-end process two-modal\nand tri-modal medical image fusion under the same weight. FlexiD-Fuse\ntransforms the diffusion fusion problem, which supports only fixed-condition\ninputs, into a maximum likelihood estimation problem based on the diffusion\nprocess and hierarchical Bayesian modeling. By incorporating the\nExpectation-Maximization algorithm into the diffusion sampling iteration\nprocess, FlexiD-Fuse can generate high-quality fused images with cross-modal\ninformation from source images, independently of the number of input images. We\ncompared the latest two and tri-modal medical image fusion methods, tested them\non Harvard datasets, and evaluated them using nine popular metrics. The\nexperimental results show that our method achieves the best performance in\nmedical image fusion with varying inputs. Meanwhile, we conducted extensive\nextension experiments on infrared-visible, multi-exposure, and multi-focus\nimage fusion tasks with arbitrary numbers, and compared them with the\nperspective SOTA methods. The results of the extension experiments consistently\ndemonstrate the effectiveness and superiority of our method.", "AI": {"tldr": "This paper proposes FlexiD-Fuse, a diffusion-based network for flexible and high-quality multi-modal medical image fusion, surpassing existing methods that handle fixed numbers of modalities.", "motivation": "Existing medical image fusion techniques are limited because they only handle a fixed number of input modalities, making them less practical for clinical applications.", "method": "The paper introduces FlexiD-Fuse, a diffusion-based network that integrates Expectation-Maximization with diffusion sampling to accommodate flexible numbers of input modalities for medical image fusion.", "result": "Experimental results on Harvard datasets and nine metrics show that FlexiD-Fuse outperformed state-of-the-art methods. Additionally, extensive extensions showed it is effective for various other image fusion tasks.", "conclusion": "FlexiD-Fuse is a highly effective and versatile solution for multi-modal medical image fusion, addressing the limitations of fixed-modality fusion methods and demonstrating superior performance in diverse applications."}}
{"id": "2509.09469", "pdf": "https://arxiv.org/pdf/2509.09469", "abs": "https://arxiv.org/abs/2509.09469", "authors": ["Freedmore Sidume", "Oumayma Soula", "Joseph Muthui Wacira", "YunFei Zhu", "Abbas Rabiu Muhammad", "Abderrazek Zeraii", "Oluwaseun Kalejaye", "Hajer Ibrahim", "Olfa Gaddour", "Brain Halubanza", "Dong Zhang", "Udunna C Anazodo", "Confidence Raymond"], "title": "Resource-Efficient Glioma Segmentation on Sub-Saharan MRI", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 7 figures", "summary": "Gliomas are the most prevalent type of primary brain tumors, and their\naccurate segmentation from MRI is critical for diagnosis, treatment planning,\nand longitudinal monitoring. However, the scarcity of high-quality annotated\nimaging data in Sub-Saharan Africa (SSA) poses a significant challenge for\ndeploying advanced segmentation models in clinical workflows. This study\nintroduces a robust and computationally efficient deep learning framework\ntailored for resource-constrained settings. We leveraged a 3D Attention UNet\narchitecture augmented with residual blocks and enhanced through transfer\nlearning from pre-trained weights on the BraTS 2021 dataset. Our model was\nevaluated on 95 MRI cases from the BraTS-Africa dataset, a benchmark for glioma\nsegmentation in SSA MRI data. Despite the limited data quality and quantity,\nour approach achieved Dice scores of 0.76 for the Enhancing Tumor (ET), 0.80\nfor Necrotic and Non-Enhancing Tumor Core (NETC), and 0.85 for Surrounding\nNon-Functional Hemisphere (SNFH). These results demonstrate the\ngeneralizability of the proposed model and its potential to support clinical\ndecision making in low-resource settings. The compact architecture,\napproximately 90 MB, and sub-minute per-volume inference time on consumer-grade\nhardware further underscore its practicality for deployment in SSA health\nsystems. This work contributes toward closing the gap in equitable AI for\nglobal health by empowering underserved regions with high-performing and\naccessible medical imaging solutions.", "AI": {"tldr": "This paper proposes a deep learning framework using 3D Attention UNet for glioma segmentation in MRI images from data-scarce Sub-Saharan Africa, achieving high accuracy and efficient deployment.", "motivation": "To address the lack of annotated glioma MRI datasets and computational resources in Sub-Saharan Africa, which hinders the use of advanced segmentation models in clinical workflows.", "method": "The study used a 3D Attention UNet architecture enhanced with residual blocks and transfer learning from the BraTS 2021 dataset. The model was evaluated on the BraTS-Africa dataset.", "result": "The model achieved Dice scores of 0.76 for Enhancing Tumor (ET), 0.80 for Necrotic and Non-Enhancing Tumor Core (NETC), and 0.85 for Surrounding Non-Functional Hemisphere (SNFH) despite limited data.", "conclusion": "The framework demonstrates high potential for clinical use in resource-constrained settings and promotes AI solutions for equitable global healthcare in underserved regions."}}
{"id": "2509.08950", "pdf": "https://arxiv.org/pdf/2509.08950", "abs": "https://arxiv.org/abs/2509.08950", "authors": ["Jarvis Haupt", "Qin Lu", "Yanning Shen", "Jia Chen", "Yue Dong", "Dan McCreary", "Mehmet Ak\u00e7akaya", "Georgios B. Giannakis"], "title": "Deploying AI for Signal Processing education: Selected challenges and intriguing opportunities", "categories": ["eess.SP", "cs.LG"], "comment": "Accepted to the IEEE Signal Processing Magazine Special Issue on\n  Artificial Intelligence for Education: A Signal Processing Perspective", "summary": "Powerful artificial intelligence (AI) tools that have emerged in recent years\n-- including large language models, automated coding assistants, and advanced\nimage and speech generation technologies -- are the result of monumental human\nachievements. These breakthroughs reflect mastery across multiple technical\ndisciplines and the resolution of significant technological challenges.\nHowever, some of the most profound challenges may still lie ahead. These\nchallenges are not purely technical but pertain to the fair and responsible use\nof AI in ways that genuinely improve the global human condition. This article\nexplores one promising application aligned with that vision: the use of AI\ntools to facilitate and enhance education, with a specific focus on signal\nprocessing (SP). It presents two interrelated perspectives: identifying and\naddressing technical limitations, and applying AI tools in practice to improve\neducational experiences. Primers are provided on several core technical issues\nthat arise when using AI in educational settings, including how to ensure\nfairness and inclusivity, handle hallucinated outputs, and achieve efficient\nuse of resources. These and other considerations -- such as transparency,\nexplainability, and trustworthiness -- are illustrated through the development\nof an immersive, structured, and reliable \"smart textbook.\" The article serves\nas a resource for researchers and educators seeking to advance AI's role in\nengineering education.", "AI": {"tldr": "The paper discusses how emerging AI tools, like large language models and speech generation technologies, can be applied to improve education, especially in signal processing, while addressing challenges such as fairness, inclusivity, and transparency.", "motivation": "The motivation behind this paper is to explore the use of advanced AI tools for meaningful global improvements, particularly in enhancing educational experiences in engineering and signal processing.", "method": "The paper employs the development of a \"smart textbook\" as an example to demonstrate principles of fairness, inclusivity, handling AI hallucinations, and promoting transparency and trustworthiness in AI applications in education.", "result": "The proposed \"smart textbook\" serves as a structured and reliable educational tool, addressing core challenges such as resource efficiency and inclusivity while showcasing the practical value of AI in enhancing educational experiences.", "conclusion": "AI has immense potential to advance education, but non-technical concerns like fairness and explainability must be addressed. The paper illustrates how these challenges can be mitigated through its application in engineering education."}}
{"id": "2509.09495", "pdf": "https://arxiv.org/pdf/2509.09495", "abs": "https://arxiv.org/abs/2509.09495", "authors": ["Victor Livernoche", "Akshatha Arodi", "Andreea Musulan", "Zachary Yang", "Adam Salvail", "Ga\u00e9tan Marceau Caron", "Jean-Fran\u00e7ois Godbout", "Reihaneh Rabbany"], "title": "OpenFake: An Open Dataset and Platform Toward Large-Scale Deepfake Detection", "categories": ["cs.CV", "cs.AI", "cs.LG", "I.4.9; I.5.4; I.2.10"], "comment": "25 pages, 12 figures", "summary": "Deepfakes, synthetic media created using advanced AI techniques, have\nintensified the spread of misinformation, particularly in politically sensitive\ncontexts. Existing deepfake detection datasets are often limited, relying on\noutdated generation methods, low realism, or single-face imagery, restricting\nthe effectiveness for general synthetic image detection. By analyzing social\nmedia posts, we identify multiple modalities through which deepfakes propagate\nmisinformation. Furthermore, our human perception study demonstrates that\nrecently developed proprietary models produce synthetic images increasingly\nindistinguishable from real ones, complicating accurate identification by the\ngeneral public. Consequently, we present a comprehensive, politically-focused\ndataset specifically crafted for benchmarking detection against modern\ngenerative models. This dataset contains three million real images paired with\ndescriptive captions, which are used for generating 963k corresponding\nhigh-quality synthetic images from a mix of proprietary and open-source models.\nRecognizing the continual evolution of generative techniques, we introduce an\ninnovative crowdsourced adversarial platform, where participants are\nincentivized to generate and submit challenging synthetic images. This ongoing\ncommunity-driven initiative ensures that deepfake detection methods remain\nrobust and adaptive, proactively safeguarding public discourse from\nsophisticated misinformation threats.", "AI": {"tldr": "The paper addresses the challenge of detecting deepfakes, especially in politically-sensitive contexts, and introduces a large, modern dataset and crowdsourced platform to enhance detection methods.", "motivation": "The study is motivated by the limitations of existing deepfake detection datasets, including outdated generation methods and low-quality images, which hinder the development of effective detection algorithms against sophisticated modern synthetic media.", "method": "Researchers conducted a human perception study to identify how realistic synthetic images have become and created a dataset containing three million real images and 963,000 synthetic images. They used both proprietary and open-source models and designed an adversarial crowdsourcing platform for ongoing dataset updates.", "result": "The authors provided a benchmark dataset with millions of images while establishing a dynamic crowdsourced approach to stay ahead of constantly evolving generative techniques.", "conclusion": "The paper highlights the need for robust deepfake detection and presents tools enabling adaptive advancements, contributing to the mitigation of misinformation risks in public discourse."}}
{"id": "2509.08954", "pdf": "https://arxiv.org/pdf/2509.08954", "abs": "https://arxiv.org/abs/2509.08954", "authors": ["Le Duc Hieu"], "title": "Convexity of Optimization Curves: Local Sharp Thresholds, Robustness Impossibility, and New Counterexamples", "categories": ["math.OC", "cs.LG", "90C25, 90C30, 65K05, 37N40, 26B25"], "comment": null, "summary": "We study when the \\emph{optimization curve} of first-order methods -- the\nsequence \\${f(x\\_n)}*{n\\ge0}\\$ produced by constant-stepsize iterations -- is\nconvex, equivalently when the forward differences \\$f(x\\_n)-f(x*{n+1})\\$ are\nnonincreasing. For gradient descent (GD) on convex \\$L\\$-smooth functions, the\ncurve is convex for all stepsizes \\$\\eta \\le 1.75/L\\$, and this threshold is\ntight. Moreover, gradient norms are nonincreasing for all \\$\\eta \\le 2/L\\$, and\nin continuous time (gradient flow) the curve is always convex. These results\ncomplement and refine the classical smooth convex optimization toolbox,\nconnecting discrete and continuous dynamics as well as worst-case analyses.", "AI": {"tldr": "The paper investigates when the optimization curve of gradient descent (GD) and similar methods is convex, focusing on stepsize thresholds for convex L-smooth functions.", "motivation": "To explore the properties of first-order optimization curves, particularly their convexity, in the context of gradient descent for convex L-smooth functions. The study bridges discrete and continuous optimization dynamics.", "method": "The authors analyze the behavior of optimization curves produced by gradient descent iterations, deriving critical stepsize thresholds for convexity and monotonicity of gradient norms.", "result": "For convex L-smooth functions, the optimization curve is convex if stepsizes are at most 1.75/L, while gradient norms decrease for stepsizes up to 2/L. Continuously, gradient flows always yield convex curves.", "conclusion": "The paper provides tight stepsize bounds, enhancing the classical optimization toolbox by linking discrete iterations with continuous dynamics and refining worst-case convex optimization analysis."}}
{"id": "2509.09496", "pdf": "https://arxiv.org/pdf/2509.09496", "abs": "https://arxiv.org/abs/2509.09496", "authors": ["Ha Linh Nguyen", "Tze Ho Elden Tse", "Angela Yao"], "title": "Improving Human Motion Plausibility with Body Momentum", "categories": ["cs.CV"], "comment": "Accepted at BMVC 2025", "summary": "Many studies decompose human motion into local motion in a frame attached to\nthe root joint and global motion of the root joint in the world frame, treating\nthem separately. However, these two components are not independent. Global\nmovement arises from interactions with the environment, which are, in turn,\ndriven by changes in the body configuration. Motion models often fail to\nprecisely capture this physical coupling between local and global dynamics,\nwhile deriving global trajectories from joint torques and external forces is\ncomputationally expensive and complex. To address these challenges, we propose\nusing whole-body linear and angular momentum as a constraint to link local\nmotion with global movement. Since momentum reflects the aggregate effect of\njoint-level dynamics on the body's movement through space, it provides a\nphysically grounded way to relate local joint behavior to global displacement.\nBuilding on this insight, we introduce a new loss term that enforces\nconsistency between the generated momentum profiles and those observed in\nground-truth data. Incorporating our loss reduces foot sliding and jitter,\nimproves balance, and preserves the accuracy of the recovered motion. Code and\ndata are available at the project page https://hlinhn.github.io/momentum_bmvc.", "AI": {"tldr": "The paper addresses human motion modeling challenges by linking local joint behavior to global displacement using whole-body momentum constraints and proposes a momentum-based loss term to improve motion realism.", "motivation": "Existing models fail to adequately capture the physical coupling between local joint dynamics and global motion, while direct derivation through joint torques and forces is computationally complex.", "method": "The authors use linear and angular momentum as constraints and introduce a novel loss term enforcing consistency between generated and ground-truth momentum profiles.", "result": "The proposed approach reduces foot sliding, jitter, and improves balance while preserving the accuracy of motion recovery.", "conclusion": "Employing momentum-based constraints effectively enhances human motion modeling by linking local and global dynamics, offering improvements in motion realism."}}
{"id": "2509.08967", "pdf": "https://arxiv.org/pdf/2509.08967", "abs": "https://arxiv.org/abs/2509.08967", "authors": ["Xinquan Huang", "Fu Wang", "Tariq Alkhalifah"], "title": "Physics-informed waveform inversion using pretrained wavefield neural operators", "categories": ["physics.geo-ph", "cs.LG"], "comment": null, "summary": "Full waveform inversion (FWI) is crucial for reconstructing high-resolution\nsubsurface models, but it is often hindered, considering the limited data, by\nits null space resulting in low-resolution models, and more importantly, by its\ncomputational cost, especially if needed for real-time applications. Recent\nattempts to accelerate FWI using learned wavefield neural operators have shown\npromise in efficiency and differentiability, but typically suffer from noisy\nand unstable inversion performance. To address these limitations, we introduce\na novel physics-informed FWI framework to enhance the inversion in accuracy\nwhile maintaining the efficiency of neural operator-based FWI. Instead of\nrelying only on the L2 norm objective function via automatic differentiation,\nresulting in noisy model reconstruction, we integrate a physics constraint term\nin the loss function of FWI, improving the quality of the inverted velocity\nmodels. Specifically, starting with an initial model to simulate wavefields and\nthen evaluating the loss over how much the resulting wavefield obeys the\nphysical laws (wave equation) and matches the recorded data, we achieve a\nreduction in noise and artifacts. Numerical experiments using the OpenFWI and\nOverthrust models demonstrate our method's superior performance, offering\ncleaner and more accurate subsurface velocity than vanilla approaches.\nConsidering the efficiency of the approach compared to FWI, this advancement\nrepresents a significant step forward in the practical application of FWI for\nreal-time subsurface monitoring.", "AI": {"tldr": "The paper introduces a physics-informed FWI framework leveraging neural operators to enhance subsurface model accuracy while ensuring computational efficiency.", "motivation": "To overcome the limitations of traditional FWI methods, namely low-resolution models due to null spaces, and the high computational cost, especially for real-time applications.", "method": "The framework integrates a physics constraint term into the loss function of FWI, improving inversion by reducing noise and artifacts. It leverages neural operators and a physics-informed loss based on wave equation compliance and data matching.", "result": "Numerical experiments on OpenFWI and Overthrust models reveal that the proposed method achieves cleaner and more accurate subsurface velocity reconstructions compared to traditional FWI approaches.", "conclusion": "The physics-informed neural operator-based FWI framework demonstrates superior performance and efficiency, marking a significant advancement for real-time subsurface applications."}}
{"id": "2509.09501", "pdf": "https://arxiv.org/pdf/2509.09501", "abs": "https://arxiv.org/abs/2509.09501", "authors": ["Yingxuan Li", "Jiafeng Mao", "Qianru Qiu", "Yusuke Matsui"], "title": "Region-Wise Correspondence Prediction between Manga Line Art Images", "categories": ["cs.CV"], "comment": null, "summary": "Understanding region-wise correspondence between manga line art images is a\nfundamental task in manga processing, enabling downstream applications such as\nautomatic line art colorization and in-between frame generation. However, this\ntask remains largely unexplored, especially in realistic scenarios without\npre-existing segmentation or annotations. In this paper, we introduce a novel\nand practical task: predicting region-wise correspondence between raw manga\nline art images without any pre-existing labels or masks. To tackle this\nproblem, we divide each line art image into a set of patches and propose a\nTransformer-based framework that learns patch-level similarities within and\nacross images. We then apply edge-aware clustering and a region matching\nalgorithm to convert patch-level predictions into coherent region-level\ncorrespondences. To support training and evaluation, we develop an automatic\nannotation pipeline and manually refine a subset of the data to construct\nbenchmark datasets. Experiments on multiple datasets demonstrate that our\nmethod achieves high patch-level accuracy (e.g., 96.34%) and generates\nconsistent region-level correspondences, highlighting its potential for\nreal-world manga applications.", "AI": {"tldr": "The paper proposes a method to predict region-wise correspondence in manga line art images without pre-existing annotations, achieving high patch- and region-level accuracy.", "motivation": "Enable applications like automatic colorization and frame generation for manga, overcoming the lack of segmentation and annotations.", "method": "A Transformer-based framework to learn patch-level similarities, combined with edge-aware clustering and a region matching algorithm.", "result": "Achieved 96.34% accuracy on patch-level predictions and consistent region-level correspondences across datasets.", "conclusion": "The method is effective and practical for applications in manga processing, showing strong potential in real-world scenarios."}}
{"id": "2509.09527", "pdf": "https://arxiv.org/pdf/2509.09527", "abs": "https://arxiv.org/abs/2509.09527", "authors": ["Jian Zhu", "Xin Zou", "Xi Wang", "Ning Zhang", "Bian Wu", "Yao Yang", "Ying Zhou", "Lingfang Zeng", "Chang Tang", "Cheng Luo"], "title": "Generative Diffusion Contrastive Network for Multi-View Clustering", "categories": ["cs.CV"], "comment": "This paper is submitted to International Conference on Acoustics,\n  Speech, and Signal Processing (ICASSP2026)", "summary": "In recent years, Multi-View Clustering (MVC) has been significantly advanced\nunder the influence of deep learning. By integrating heterogeneous data from\nmultiple views, MVC enhances clustering analysis, making multi-view fusion\ncritical to clustering performance. However, there is a problem of low-quality\ndata in multi-view fusion. This problem primarily arises from two reasons: 1)\nCertain views are contaminated by noisy data. 2) Some views suffer from missing\ndata. This paper proposes a novel Stochastic Generative Diffusion Fusion (SGDF)\nmethod to address this problem. SGDF leverages a multiple generative mechanism\nfor the multi-view feature of each sample. It is robust to low-quality data.\nBuilding on SGDF, we further present the Generative Diffusion Contrastive\nNetwork (GDCN). Extensive experiments show that GDCN achieves the\nstate-of-the-art results in deep MVC tasks. The source code is publicly\navailable at https://github.com/HackerHyper/GDCN.", "AI": {"tldr": "This paper introduces a new method called Stochastic Generative Diffusion Fusion (SGDF) to address low-quality data issues in Multi-View Clustering (MVC), and extends it with the Generative Diffusion Contrastive Network (GDCN) to achieve state-of-the-art performance.", "motivation": "To improve clustering performance in Multi-View Clustering (MVC) by addressing challenges related to noisy and missing data during the multi-view fusion process.", "method": "The paper proposes the Stochastic Generative Diffusion Fusion (SGDF) method, which uses a multi-generative mechanism to handle low-quality data in multi-view samples. It also develops the Generative Diffusion Contrastive Network (GDCN) built on SGDF.", "result": "The proposed GDCN achieves state-of-the-art performance in deep Multi-View Clustering tasks based on extensive experiments.", "conclusion": "The study successfully tackles the multi-view data quality problem using SGDF and GDCN, significantly enhancing clustering analysis capabilities. The source code is openly available for public use."}}
{"id": "2509.09530", "pdf": "https://arxiv.org/pdf/2509.09530", "abs": "https://arxiv.org/abs/2509.09530", "authors": ["Paul F. R. Wilson", "Matteo Ronchetti", "R\u00fcdiger G\u00f6bl", "Viktoria Markova", "Sebastian Rosenzweig", "Raphael Prevost", "Parvin Mousavi", "Oliver Zettinig"], "title": "DualTrack: Sensorless 3D Ultrasound needs Local and Global Context", "categories": ["cs.CV"], "comment": null, "summary": "Three-dimensional ultrasound (US) offers many clinical advantages over\nconventional 2D imaging, yet its widespread adoption is limited by the cost and\ncomplexity of traditional 3D systems. Sensorless 3D US, which uses deep\nlearning to estimate a 3D probe trajectory from a sequence of 2D US images, is\na promising alternative. Local features, such as speckle patterns, can help\npredict frame-to-frame motion, while global features, such as coarse shapes and\nanatomical structures, can situate the scan relative to anatomy and help\npredict its general shape. In prior approaches, global features are either\nignored or tightly coupled with local feature extraction, restricting the\nability to robustly model these two complementary aspects. We propose\nDualTrack, a novel dual-encoder architecture that leverages decoupled local and\nglobal encoders specialized for their respective scales of feature extraction.\nThe local encoder uses dense spatiotemporal convolutions to capture\nfine-grained features, while the global encoder utilizes an image backbone\n(e.g., a 2D CNN or foundation model) and temporal attention layers to embed\nhigh-level anatomical features and long-range dependencies. A lightweight\nfusion module then combines these features to estimate the trajectory.\nExperimental results on a large public benchmark show that DualTrack achieves\nstate-of-the-art accuracy and globally consistent 3D reconstructions,\noutperforming previous methods and yielding an average reconstruction error\nbelow 5 mm.", "AI": {"tldr": "The paper introduces DualTrack, a novel dual-encoder deep learning system for estimating 3D ultrasound probe trajectories using decoupled local and global feature extraction, achieving state-of-the-art results.", "motivation": "The paper aims to address the limitations in adopting 3D ultrasound systems due to their cost and complexity by proposing a deep learning-based alternative that separately models local and global features for better performance.", "method": "The proposed method, DualTrack, uses a dual-encoder architecture with a local encoder capturing fine-grained features via dense spatiotemporal convolutions and a global encoder for high-level anatomical features using a CNN backbone and temporal attention. The features are fused for trajectory estimation.", "result": "Experimental validation on a large benchmark dataset demonstrates superior accuracy and globally consistent 3D ultrasound reconstructions, with reconstruction errors under 5 mm, outperforming prior methods.", "conclusion": "DualTrack effectively models complementary local and global features, facilitating accurate and cost-effective 3D ultrasound imaging, paving the way for broader adoption in clinical applications."}}
{"id": "2509.09033", "pdf": "https://arxiv.org/pdf/2509.09033", "abs": "https://arxiv.org/abs/2509.09033", "authors": ["Hsin-Yuan Huang", "Michael Broughton", "Norhan Eassa", "Hartmut Neven", "Ryan Babbush", "Jarrod R. McClean"], "title": "Generative quantum advantage for classical and quantum problems", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Recent breakthroughs in generative machine learning, powered by massive\ncomputational resources, have demonstrated unprecedented human-like\ncapabilities. While beyond-classical quantum experiments can generate samples\nfrom classically intractable distributions, their complexity has thwarted all\nefforts toward efficient learning. This challenge has hindered demonstrations\nof generative quantum advantage: the ability of quantum computers to learn and\ngenerate desired outputs substantially better than classical computers. We\nresolve this challenge by introducing families of generative quantum models\nthat are hard to simulate classically, are efficiently trainable, exhibit no\nbarren plateaus or proliferating local minima, and can learn to generate\ndistributions beyond the reach of classical computers. Using a $68$-qubit\nsuperconducting quantum processor, we demonstrate these capabilities in two\nscenarios: learning classically intractable probability distributions and\nlearning quantum circuits for accelerated physical simulation. Our results\nestablish that both learning and sampling can be performed efficiently in the\nbeyond-classical regime, opening new possibilities for quantum-enhanced\ngenerative models with provable advantage.", "AI": {"tldr": "The paper introduces generative quantum models capable of efficiently learning and sampling distributions that are beyond classical computation reach and demonstrates these using a quantum processor.", "motivation": "To overcome the challenge of efficiently learning and generating samples from classically intractable quantum distributions, establishing generative quantum advantage.", "method": "The authors propose trainable quantum models that avoid classical simulation limitations, barren plateaus, and local minima, implementing their approach on a $68$-qubit quantum processor.", "result": "They successfully demonstrated learning classically intractable distributions and implementing quantum circuits for faster physical simulations on the quantum processor.", "conclusion": "The study proves that generative quantum models can efficiently perform learning and sampling in the beyond-classical regime, showcasing quantum's potential in enhancing generative tasks."}}
{"id": "2509.09547", "pdf": "https://arxiv.org/pdf/2509.09547", "abs": "https://arxiv.org/abs/2509.09547", "authors": ["Dohun Lee", "Hyeonho Jeong", "Jiwook Kim", "Duygu Ceylan", "Jong Chul Ye"], "title": "Improving Video Diffusion Transformer Training by Multi-Feature Fusion and Alignment from Self-Supervised Vision Encoders", "categories": ["cs.CV", "cs.AI"], "comment": "17 pages, 14 figures", "summary": "Video diffusion models have advanced rapidly in the recent years as a result\nof series of architectural innovations (e.g., diffusion transformers) and use\nof novel training objectives (e.g., flow matching). In contrast, less attention\nhas been paid to improving the feature representation power of such models. In\nthis work, we show that training video diffusion models can benefit from\naligning the intermediate features of the video generator with feature\nrepresentations of pre-trained vision encoders. We propose a new metric and\nconduct an in-depth analysis of various vision encoders to evaluate their\ndiscriminability and temporal consistency, thereby assessing their suitability\nfor video feature alignment. Based on the analysis, we present Align4Gen which\nprovides a novel multi-feature fusion and alignment method integrated into\nvideo diffusion model training. We evaluate Align4Gen both for unconditional\nand class-conditional video generation tasks and show that it results in\nimproved video generation as quantified by various metrics. Full video results\nare available on our project page: https://align4gen.github.io/align4gen/", "AI": {"tldr": "This paper introduces Align4Gen, a method to improve video diffusion models by aligning their intermediate features with pre-trained vision encoders, leading to better video generation.", "motivation": "To enhance the feature representation power of video diffusion models, which has received less attention compared to architectural innovations and novel training objectives.", "method": "Proposed Align4Gen, a multi-feature fusion and alignment method, integrated with video diffusion model training. The paper includes a new metric and an analysis of vision encoders for discriminability and temporal consistency.", "result": "Align4Gen improves both unconditional and class-conditional video generation tasks with better results quantified by various metrics.", "conclusion": "Align4Gen enhances video diffusion model training via feature alignment, resulting in higher-quality video generation. Full video results are shared on their project page."}}
{"id": "2509.09045", "pdf": "https://arxiv.org/pdf/2509.09045", "abs": "https://arxiv.org/abs/2509.09045", "authors": ["Shrabani Ghosh", "Erik Saule"], "title": "The Role of Community Detection Methods in Performance Variations of Graph Mining Tasks", "categories": ["cs.SI", "cs.LG"], "comment": null, "summary": "In real-world scenarios, large graphs represent relationships among entities\nin complex systems. Mining these large graphs often containing millions of\nnodes and edges helps uncover structural patterns and meaningful insights.\nDividing a large graph into smaller subgraphs facilitates complex system\nanalysis by revealing local information. Community detection extracts clusters\nor communities of graphs based on statistical methods and machine learning\nmodels using various optimization techniques. Structure based community\ndetection methods are more suitable for applying to graphs because they do not\nrely heavily on rich node or edge attribute information. The features derived\nfrom these communities can improve downstream graph mining tasks, such as link\nprediction and node classification. In real-world applications, we often lack\nground truth community information. Additionally, there is neither a\nuniversally accepted gold standard for community detection nor a single method\nthat is consistently optimal across diverse applications. In many cases, it is\nunclear how practitioners select community detection methods, and choices are\noften made without explicitly considering their potential impact on downstream\ntasks. In this study, we investigate whether the choice of community detection\nalgorithm significantly influences the performance of downstream applications.\nWe propose a framework capable of integrating various community detection\nmethods to systematically evaluate their effects on downstream task outcomes.\nOur comparative analysis reveals that specific community detection algorithms\nyield superior results in certain applications, highlighting that method\nselection substantially affects performance.", "AI": {"tldr": "The paper explores how the choice of community detection algorithms impacts downstream graph mining tasks, using a systematic evaluation framework.", "motivation": "To understand whether the selection of community detection algorithms significantly affects the performance of downstream graph analysis tasks.", "method": "A framework integrating various community detection methods was designed to systematically compare and evaluate their effects on downstream applications such as link prediction and node classification.", "result": "The analysis shows that certain community detection algorithms perform better in specific applications, emphasizing the importance of method selection.", "conclusion": "Community detection method choices significantly impact downstream task performance; thus, careful selection tailored to application needs is crucial."}}
{"id": "2509.09555", "pdf": "https://arxiv.org/pdf/2509.09555", "abs": "https://arxiv.org/abs/2509.09555", "authors": ["Sirui Xu", "Dongting Li", "Yucheng Zhang", "Xiyan Xu", "Qi Long", "Ziyin Wang", "Yunzhi Lu", "Shuchang Dong", "Hezi Jiang", "Akshat Gupta", "Yu-Xiong Wang", "Liang-Yan Gui"], "title": "InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation", "categories": ["cs.CV"], "comment": "CVPR 2025", "summary": "While large-scale human motion capture datasets have advanced human motion\ngeneration, modeling and generating dynamic 3D human-object interactions (HOIs)\nremain challenging due to dataset limitations. Existing datasets often lack\nextensive, high-quality motion and annotation and exhibit artifacts such as\ncontact penetration, floating, and incorrect hand motions. To address these\nissues, we introduce InterAct, a large-scale 3D HOI benchmark featuring dataset\nand methodological advancements. First, we consolidate and standardize 21.81\nhours of HOI data from diverse sources, enriching it with detailed textual\nannotations. Second, we propose a unified optimization framework to enhance\ndata quality by reducing artifacts and correcting hand motions. Leveraging the\nprinciple of contact invariance, we maintain human-object relationships while\nintroducing motion variations, expanding the dataset to 30.70 hours. Third, we\ndefine six benchmarking tasks and develop a unified HOI generative modeling\nperspective, achieving state-of-the-art performance. Extensive experiments\nvalidate the utility of our dataset as a foundational resource for advancing 3D\nhuman-object interaction generation. To support continued research in this\narea, the dataset is publicly available at\nhttps://github.com/wzyabcas/InterAct, and will be actively maintained.", "AI": {"tldr": "The paper introduces InterAct, a benchmark for 3D human-object interaction (HOI), addressing limitations in existing datasets through data enrichment and quality enhancement methods.", "motivation": "Current challenges in modeling dynamic 3D human-object interactions arise due to limitations in existing datasets, such as lack of high-quality motion, incomplete annotations, and artifacts.", "method": "The authors consolidate and standardize 21.81 hours of diverse HOI data, improve quality using a unified optimization framework, and expand the dataset to 30.70 hours by introducing motion variations while preserving human-object contact relationships.", "result": "InterAct achieves state-of-the-art performance on six benchmarking tasks and demonstrates the utility of its enriched dataset through extensive experiments.", "conclusion": "InterAct serves as a foundational resource for advancing 3D HOI generation and is made publicly available for continued research, with active maintenance provided."}}
{"id": "2509.09235", "pdf": "https://arxiv.org/pdf/2509.09235", "abs": "https://arxiv.org/abs/2509.09235", "authors": ["Sarah C. Irvine", "Christian Lucas", "Diana Kr\u00fcger", "Bianca Guedert", "Julian Moosmann", "Berit Zeller-Plumhoff"], "title": "Virtual staining for 3D X-ray histology of bone implants", "categories": ["eess.IV", "cs.AI", "cs.CV", "physics.comp-ph", "q-bio.QM"], "comment": null, "summary": "Three-dimensional X-ray histology techniques offer a non-invasive alternative\nto conventional 2D histology, enabling volumetric imaging of biological tissues\nwithout the need for physical sectioning or chemical staining. However, the\ninherent greyscale image contrast of X-ray tomography limits its biochemical\nspecificity compared to traditional histological stains. Within digital\npathology, deep learning-based virtual staining has demonstrated utility in\nsimulating stained appearances from label-free optical images. In this study,\nwe extend virtual staining to the X-ray domain by applying cross-modality image\ntranslation to generate artificially stained slices from\nsynchrotron-radiation-based micro-CT scans. Using over 50 co-registered image\npairs of micro-CT and toluidine blue-stained histology from bone-implant\nsamples, we trained a modified CycleGAN network tailored for limited paired\ndata. Whole slide histology images were downsampled to match the voxel size of\nthe CT data, with on-the-fly data augmentation for patch-based training. The\nmodel incorporates pixelwise supervision and greyscale consistency terms,\nproducing histologically realistic colour outputs while preserving\nhigh-resolution structural detail. Our method outperformed Pix2Pix and standard\nCycleGAN baselines across SSIM, PSNR, and LPIPS metrics. Once trained, the\nmodel can be applied to full CT volumes to generate virtually stained 3D\ndatasets, enhancing interpretability without additional sample preparation.\nWhile features such as new bone formation were able to be reproduced, some\nvariability in the depiction of implant degradation layers highlights the need\nfor further training data and refinement. This work introduces virtual staining\nto 3D X-ray imaging and offers a scalable route for chemically informative,\nlabel-free tissue characterisation in biomedical research.", "AI": {"tldr": "The paper proposes virtual staining for 3D X-ray imaging using deep learning, enhancing interpretability without extra sample preparation.", "motivation": "Current X-ray tomography has limited biochemical specificity compared to conventional histology staining techniques.", "method": "The authors developed a modified CycleGAN network for cross-modality image translation of synchrotron micro-CT scans into virtually stained slices using matched histological image pairs.", "result": "The proposed method outperformed baseline models like Pix2Pix and CycleGAN across multiple metrics (SSIM, PSNR, LPIPS) while preserving structural details.", "conclusion": "The approach enables chemically informative, label-free tissue characterization in 3D without invasive sample preparation, although future work is required to refine implant degradation visualization."}}
{"id": "2509.09558", "pdf": "https://arxiv.org/pdf/2509.09558", "abs": "https://arxiv.org/abs/2509.09558", "authors": ["Akshit Achara", "Esther Puyol Anton", "Alexander Hammers", "Andrew P. King"], "title": "Invisible Attributes, Visible Biases: Exploring Demographic Shortcuts in MRI-based Alzheimer's Disease Classification", "categories": ["cs.CV", "cs.AI"], "comment": "FAIMI @ MICCAI 2025", "summary": "Magnetic resonance imaging (MRI) is the gold standard for brain imaging. Deep\nlearning (DL) algorithms have been proposed to aid in the diagnosis of diseases\nsuch as Alzheimer's disease (AD) from MRI scans. However, DL algorithms can\nsuffer from shortcut learning, in which spurious features, not directly related\nto the output label, are used for prediction. When these features are related\nto protected attributes, they can lead to performance bias against\nunderrepresented protected groups, such as those defined by race and sex. In\nthis work, we explore the potential for shortcut learning and demographic bias\nin DL based AD diagnosis from MRI. We first investigate if DL algorithms can\nidentify race or sex from 3D brain MRI scans to establish the presence or\notherwise of race and sex based distributional shifts. Next, we investigate\nwhether training set imbalance by race or sex can cause a drop in model\nperformance, indicating shortcut learning and bias. Finally, we conduct a\nquantitative and qualitative analysis of feature attributions in different\nbrain regions for both the protected attribute and AD classification tasks.\nThrough these experiments, and using multiple datasets and DL models (ResNet\nand SwinTransformer), we demonstrate the existence of both race and sex based\nshortcut learning and bias in DL based AD classification. Our work lays the\nfoundation for fairer DL diagnostic tools in brain MRI. The code is provided at\nhttps://github.com/acharaakshit/ShortMR", "AI": {"tldr": "The paper investigates shortcut learning and demographic bias in deep learning-based Alzheimer\u2019s disease diagnostic models using brain MRI scans, revealing race and sex biases.", "motivation": "Understanding and mitigating demographic biases in deep learning models for brain MRI analysis is crucial for developing equitable diagnostic tools for diseases like Alzheimer\u2019s.", "method": "Researchers tested whether deep learning models can identify race and sex from MRI scans and assessed the impact of training set imbalances. Additionally, they analyzed feature attribution for protected attributes and disease classification using models like ResNet and SwinTransformer across multiple datasets.", "result": "Both race and sex-based biases were identified in the diagnostic models, influenced by shortcut learning, as demonstrated through experiments across datasets and model types.", "conclusion": "The study highlights the need for addressing bias and shortcut learning in DL-based tools for fairer and more accurate Alzheimer\u2019s disease MRI diagnostics."}}
{"id": "2509.09572", "pdf": "https://arxiv.org/pdf/2509.09572", "abs": "https://arxiv.org/abs/2509.09572", "authors": ["Sijun Dong", "Yuxuan Hu", "LiBo Wang", "Geng Chen", "Xiaoliang Meng"], "title": "PeftCD: Leveraging Vision Foundation Models with Parameter-Efficient Fine-Tuning for Remote Sensing Change Detection", "categories": ["cs.CV"], "comment": null, "summary": "To tackle the prevalence of pseudo changes, the scarcity of labeled samples,\nand the difficulty of cross-domain generalization in multi-temporal and\nmulti-source remote sensing imagery, we propose PeftCD, a change detection\nframework built upon Vision Foundation Models (VFMs) with Parameter-Efficient\nFine-Tuning (PEFT). At its core, PeftCD employs a weight-sharing Siamese\nencoder derived from a VFM, into which LoRA and Adapter modules are seamlessly\nintegrated. This design enables highly efficient task adaptation by training\nonly a minimal set of additional parameters. To fully unlock the potential of\nVFMs, we investigate two leading backbones: the Segment Anything Model v2\n(SAM2), renowned for its strong segmentation priors, and DINOv3, a\nstate-of-the-art self-supervised representation learner. The framework is\ncomplemented by a deliberately lightweight decoder, ensuring the focus remains\non the powerful feature representations from the backbones. Extensive\nexperiments demonstrate that PeftCD achieves state-of-the-art performance\nacross multiple public datasets, including SYSU-CD (IoU 73.81%), WHUCD\n(92.05%), MSRSCD (64.07%), MLCD (76.89%), CDD (97.01%), S2Looking (52.25%) and\nLEVIR-CD (85.62%), with notably precise boundary delineation and strong\nsuppression of pseudo-changes. In summary, PeftCD presents an optimal balance\nof accuracy, efficiency, and generalization. It offers a powerful and scalable\nparadigm for adapting large-scale VFMs to real-world remote sensing change\ndetection applications. The code and pretrained models will be released at\nhttps://github.com/dyzy41/PeftCD.", "AI": {"tldr": "PeftCD is a change detection framework utilizing Vision Foundation Models with efficient fine-tuning to achieve state-of-the-art performance on remote sensing tasks.", "motivation": "The paper aims to address challenges in remote sensing change detection, such as pseudo changes, lack of labeled samples, and cross-domain generalization.", "method": "PeftCD employs a Siamese encoder from VFMs, integrating LoRA and Adapter modules, alongside leading backbones like SAM2 and DINOv3, and a lightweight decoder.", "result": "PeftCD achieves high accuracy on public datasets, with impressive IoU scores across systems like SYSU-CD, WHUCD, and others, reducing pseudo changes and improving boundary precision.", "conclusion": "The proposed framework is efficient, accurate, scalable, and adapts large VFMs effectively for real-world remote sensing applications."}}
{"id": "2509.09262", "pdf": "https://arxiv.org/pdf/2509.09262", "abs": "https://arxiv.org/abs/2509.09262", "authors": ["Seung Gyu Jeong", "Seong Eun Kim"], "title": "Adaptive Knowledge Distillation using a Device-Aware Teacher for Low-Complexity Acoustic Scene Classification", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "In this technical report, we describe our submission for Task 1,\nLow-Complexity Device-Robust Acoustic Scene Classification, of the DCASE 2025\nChallenge. Our work tackles the dual challenges of strict complexity\nconstraints and robust generalization to both seen and unseen devices, while\nalso leveraging the new rule allowing the use of device labels at test time.\nOur proposed system is based on a knowledge distillation framework where an\nefficient CP-MobileNet student learns from a compact, specialized two-teacher\nensemble. This ensemble combines a baseline PaSST teacher, trained with\nstandard cross-entropy, and a 'generalization expert' teacher. This expert is\ntrained using our novel Device-Aware Feature Alignment (DAFA) loss, adapted\nfrom prior work, which explicitly structures the feature space for device\nrobustness. To capitalize on the availability of test-time device labels, the\ndistilled student model then undergoes a final device-specific fine-tuning\nstage. Our proposed system achieves a final accuracy of 57.93\\% on the\ndevelopment set, demonstrating a significant improvement over the official\nbaseline, particularly on unseen devices.", "AI": {"tldr": "The paper presents a system for acoustic scene classification with low complexity and device robustness using a knowledge distillation framework and device-specific fine-tuning.", "motivation": "To address the challenges of low computational complexity and robust performance on both seen and unseen devices in acoustic scene classification.", "method": "The approach uses a knowledge distillation framework with a CP-MobileNet student learning from two teacher models, including a specialized teacher with a DAFA loss for device robustness. Final fine-tuning is performed using test-time device labels.", "result": "The system achieves a 57.93% accuracy on the development set, outperforming the official baseline, especially on unseen devices.", "conclusion": "The proposed method is effective in delivering significant performance improvements while meeting low complexity and device robustness requirements."}}
{"id": "2509.09107", "pdf": "https://arxiv.org/pdf/2509.09107", "abs": "https://arxiv.org/abs/2509.09107", "authors": ["Pritam Sen", "Yao Ma", "Cristian Borcea"], "title": "CryptGNN: Enabling Secure Inference for Graph Neural Networks", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "We present CryptGNN, a secure and effective inference solution for\nthird-party graph neural network (GNN) models in the cloud, which are accessed\nby clients as ML as a service (MLaaS). The main novelty of CryptGNN is its\nsecure message passing and feature transformation layers using distributed\nsecure multi-party computation (SMPC) techniques. CryptGNN protects the\nclient's input data and graph structure from the cloud provider and the\nthird-party model owner, and it protects the model parameters from the cloud\nprovider and the clients. CryptGNN works with any number of SMPC parties, does\nnot require a trusted server, and is provably secure even if P-1 out of P\nparties in the cloud collude. Theoretical analysis and empirical experiments\ndemonstrate the security and efficiency of CryptGNN.", "AI": {"tldr": "CryptGNN introduces a secure method for third-party graph neural network inference in the cloud using secure multi-party computation (SMPC).", "motivation": "The paper aims to address data security concerns when using third-party GNN models and cloud-based ML as a service.", "method": "The authors use distributed SMPC techniques for secure message passing and feature transformation layers in CryptGNN.", "result": "CryptGNN is secure against collusion of up to P-1 out of P cloud parties and does not rely on a trusted server, as evidenced by both theoretical analysis and experiments.", "conclusion": "CryptGNN effectively protects client data, graph structures, and model parameters while maintaining efficiency in cloud-based GNN inference."}}
{"id": "2509.09595", "pdf": "https://arxiv.org/pdf/2509.09595", "abs": "https://arxiv.org/abs/2509.09595", "authors": ["Yikang Ding", "Jiwen Liu", "Wenyuan Zhang", "Zekun Wang", "Wentao Hu", "Liyuan Cui", "Mingming Lao", "Yingchao Shao", "Hui Liu", "Xiaohan Li", "Ming Chen", "Xiaoqiang Liu", "Yu-Shen Liu", "Pengfei Wan"], "title": "Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis", "categories": ["cs.CV"], "comment": "Technical Report. Project Page: https://klingavatar.github.io/", "summary": "Recent advances in audio-driven avatar video generation have significantly\nenhanced audio-visual realism. However, existing methods treat instruction\nconditioning merely as low-level tracking driven by acoustic or visual cues,\nwithout modeling the communicative purpose conveyed by the instructions. This\nlimitation compromises their narrative coherence and character expressiveness.\nTo bridge this gap, we introduce Kling-Avatar, a novel cascaded framework that\nunifies multimodal instruction understanding with photorealistic portrait\ngeneration. Our approach adopts a two-stage pipeline. In the first stage, we\ndesign a multimodal large language model (MLLM) director that produces a\nblueprint video conditioned on diverse instruction signals, thereby governing\nhigh-level semantics such as character motion and emotions. In the second\nstage, guided by blueprint keyframes, we generate multiple sub-clips in\nparallel using a first-last frame strategy. This global-to-local framework\npreserves fine-grained details while faithfully encoding the high-level intent\nbehind multimodal instructions. Our parallel architecture also enables fast and\nstable generation of long-duration videos, making it suitable for real-world\napplications such as digital human livestreaming and vlogging. To\ncomprehensively evaluate our method, we construct a benchmark of 375 curated\nsamples covering diverse instructions and challenging scenarios. Extensive\nexperiments demonstrate that Kling-Avatar is capable of generating vivid,\nfluent, long-duration videos at up to 1080p and 48 fps, achieving superior\nperformance in lip synchronization accuracy, emotion and dynamic\nexpressiveness, instruction controllability, identity preservation, and\ncross-domain generalization. These results establish Kling-Avatar as a new\nbenchmark for semantically grounded, high-fidelity audio-driven avatar\nsynthesis.", "AI": {"tldr": "Kling-Avatar introduces a two-stage framework for creating semantically-rich, photorealistic avatar videos driven by multimodal instructions.", "motivation": "Improve narrative coherence and character expressiveness in audio-driven avatar video generation by integrating instruction understanding.", "method": "A cascaded two-stage framework: 1) multimodal large language model (MLLM) director generates blueprint videos, 2) first-last frame strategy synthesizes detailed sub-clips guided by blueprints.", "result": "High-quality avatar videos (up to 1080p, 48 fps) with better lip synchronization, emotion expression, instruction controllability, identity fidelity, and cross-domain generalization.", "conclusion": "Kling-Avatar sets a new standard for audio-driven avatar synthesis in terms of fidelity, semantics, and scalability, suitable for practical applications like livestreaming and vlogging."}}
{"id": "2509.09610", "pdf": "https://arxiv.org/pdf/2509.09610", "abs": "https://arxiv.org/abs/2509.09610", "authors": ["Daria Laslo", "Efthymios Georgiou", "Marius George Linguraru", "Andreas Rauschecker", "Sabine Muller", "Catherine R. Jutzeler", "Sarah Bruningk"], "title": "Mechanistic Learning with Guided Diffusion Models to Predict Spatio-Temporal Brain Tumor Growth", "categories": ["cs.CV", "cs.AI"], "comment": "13 pages, 4 figures", "summary": "Predicting the spatio-temporal progression of brain tumors is essential for\nguiding clinical decisions in neuro-oncology. We propose a hybrid mechanistic\nlearning framework that combines a mathematical tumor growth model with a\nguided denoising diffusion implicit model (DDIM) to synthesize anatomically\nfeasible future MRIs from preceding scans. The mechanistic model, formulated as\na system of ordinary differential equations, captures temporal tumor dynamics\nincluding radiotherapy effects and estimates future tumor burden. These\nestimates condition a gradient-guided DDIM, enabling image synthesis that\naligns with both predicted growth and patient anatomy. We train our model on\nthe BraTS adult and pediatric glioma datasets and evaluate on 60 axial slices\nof in-house longitudinal pediatric diffuse midline glioma (DMG) cases. Our\nframework generates realistic follow-up scans based on spatial similarity\nmetrics. It also introduces tumor growth probability maps, which capture both\nclinically relevant extent and directionality of tumor growth as shown by 95th\npercentile Hausdorff Distance. The method enables biologically informed image\ngeneration in data-limited scenarios, offering generative-space-time\npredictions that account for mechanistic priors.", "AI": {"tldr": "The paper proposes a hybrid framework for predicting brain tumor progression by combining a mathematical tumor growth model with image synthesis using a guided DDIM model.", "motivation": "Accurate spatio-temporal prediction of brain tumor progression is crucial for improving clinical decision-making in neuro-oncology.", "method": "The framework integrates a mathematical tumor growth model (using ordinary differential equations to capture tumor dynamics and radiotherapy effects) with a guided denoising diffusion implicit model to synthesize future MRIs conditioned on predicted tumor growth.", "result": "The model, trained on BraTS glioma datasets and tested on pediatric diffuse midline glioma cases, generates anatomically realistic follow-up scans and provides tumor growth probability maps with high spatial resemblance to ground truth.", "conclusion": "The method offers a novel, data-efficient approach for generating future tumor progression scenarios, enhancing clinical insights into tumor growth directionality and extent."}}
{"id": "2509.09658", "pdf": "https://arxiv.org/pdf/2509.09658", "abs": "https://arxiv.org/abs/2509.09658", "authors": ["Bingkui Tong", "Jiaer Xia", "Sifeng Shang", "Kaiyang Zhou"], "title": "Measuring Epistemic Humility in Multimodal Large Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Hallucinations in multimodal large language models (MLLMs) -- where the model\ngenerates content inconsistent with the input image -- pose significant risks\nin real-world applications, from misinformation in visual question answering to\nunsafe errors in decision-making. Existing benchmarks primarily test\nrecognition accuracy, i.e., evaluating whether models can select the correct\nanswer among distractors. This overlooks an equally critical capability for\ntrustworthy AI: recognizing when none of the provided options are correct, a\nbehavior reflecting epistemic humility. We present HumbleBench, a new\nhallucination benchmark designed to evaluate MLLMs' ability to reject plausible\nbut incorrect answers across three hallucination types: object, relation, and\nattribute. Built from a panoptic scene graph dataset, we leverage fine-grained\nscene graph annotations to extract ground-truth entities and relations, and\nprompt GPT-4-Turbo to generate multiple-choice questions, followed by a\nrigorous manual filtering process. Each question includes a \"None of the above\"\noption, requiring models not only to recognize correct visual information but\nalso to identify when no provided answer is valid. We evaluate a variety of\nstate-of-the-art MLLMs -- including both general-purpose and specialized\nreasoning models -- on HumbleBench and share valuable findings and insights\nwith the community. By incorporating explicit false-option rejection,\nHumbleBench fills a key gap in current evaluation suites, providing a more\nrealistic measure of MLLM reliability in safety-critical settings. Our code and\ndataset are released publicly and can be accessed at\nhttps://github.com/maifoundations/HumbleBench.", "AI": {"tldr": "HumbleBench is a benchmark for assessing multimodal large language models (MLLMs) on their ability to reject incorrect visual content, enhancing safety-critical evaluations.", "motivation": "Hallucinations in MLLMs can lead to misinformation and unsafe decision-making, emphasizing the need for benchmarks that assess not only recognition accuracy but also epistemic humility.", "method": "HumbleBench utilizes a panoptic scene graph dataset, GPT-4-Turbo generated questions, and manual filtering to create a benchmark measuring the ability of MLLMs to identify incorrect answers across object, relation, and attribute hallucination types.", "result": "State-of-the-art MLLMs were evaluated, highlighting strengths and weaknesses in their performance on rejecting incorrect options and validating the benchmark's utility.", "conclusion": "HumbleBench provides a realistic and critical measure of MLLM reliability, addressing gaps in current evaluation methods and supporting safer applications of these models."}}
{"id": "2509.09666", "pdf": "https://arxiv.org/pdf/2509.09666", "abs": "https://arxiv.org/abs/2509.09666", "authors": ["Zhiyuan Yan", "Kaiqing Lin", "Zongjian Li", "Junyan Ye", "Hui Han", "Zhendong Wang", "Hao Liu", "Bin Lin", "Hao Li", "Xue Xu", "Xinyan Xiao", "Jingdong Wang", "Haifeng Wang", "Li Yuan"], "title": "Can Understanding and Generation Truly Benefit Together -- or Just Coexist?", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we introduce an insightful paradigm through the Auto-Encoder\nlens-understanding as the encoder (I2T) that compresses images into text, and\ngeneration as the decoder (T2I) that reconstructs images from that text. Using\nreconstruction fidelity as the unified training objective, we enforce the\ncoherent bidirectional information flow between the understanding and\ngeneration processes, bringing mutual gains. To implement this, we propose UAE,\na novel framework for unified multimodal learning. We begin by pre-training the\ndecoder with large-scale long-context image captions to capture fine-grained\nsemantic and complex spatial relationships. We then propose Unified-GRPO via\nreinforcement learning (RL), which covers three stages: (1) A cold-start phase\nto gently initialize both encoder and decoder with a semantic reconstruction\nloss; (2) Generation for Understanding, where the encoder is trained to\ngenerate informative captions that maximize the decoder's reconstruction\nquality, enhancing its visual understanding; (3) Understanding for Generation,\nwhere the decoder is refined to reconstruct from these captions, forcing it to\nleverage every detail and improving its long-context instruction following and\ngeneration fidelity. For evaluation, we introduce Unified-Bench, the first\nbenchmark tailored to assess the degree of unification of the UMMs. A\nsurprising \"aha moment\" arises within the multimodal learning domain: as RL\nprogresses, the encoder autonomously produces more descriptive captions, while\nthe decoder simultaneously demonstrates a profound ability to understand these\nintricate descriptions, resulting in reconstructions of striking fidelity.", "AI": {"tldr": "The paper presents a new framework, UAE, to unify multimodal learning by using bidirectional processes of image-to-text (I2T) and text-to-image (T2I) with a focus on reconstruction fidelity.", "motivation": "The authors aim to bridge understanding (image-to-text) and generation (text-to-image) in multimodal learning by creating a unified system that enhances both processes through mutual gains.", "method": "They propose the UAE framework, which pre-trains a decoder using large-scale data and employs a three-stage Unified-GRPO reinforcement learning process to fine-tune the encoder and decoder iteratively.", "result": "Surprisingly, the encoder autonomously generates more descriptive captions while the decoder improves its ability to understand these descriptions, resulting in high-quality image reconstructions.", "conclusion": "The UAE framework demonstrates significant mutual enhancement of image understanding and generation, setting a new benchmark (Unified-Bench) for evaluating unified multimodal models."}}
{"id": "2509.09667", "pdf": "https://arxiv.org/pdf/2509.09667", "abs": "https://arxiv.org/abs/2509.09667", "authors": ["Zhengdi Yu", "Simone Foti", "Linguang Zhang", "Amy Zhao", "Cem Keskin", "Stefanos Zafeiriou", "Tolga Birdal"], "title": "Geometric Neural Distance Fields for Learning Human Motion Priors", "categories": ["cs.CV"], "comment": "8 pages", "summary": "We introduce Neural Riemannian Motion Fields (NRMF), a novel 3D generative\nhuman motion prior that enables robust, temporally consistent, and physically\nplausible 3D motion recovery. Unlike existing VAE or diffusion-based methods,\nour higher-order motion prior explicitly models the human motion in the zero\nlevel set of a collection of neural distance fields (NDFs) corresponding to\npose, transition (velocity), and acceleration dynamics. Our framework is\nrigorous in the sense that our NDFs are constructed on the product space of\njoint rotations, their angular velocities, and angular accelerations,\nrespecting the geometry of the underlying articulations. We further introduce:\n(i) a novel adaptive-step hybrid algorithm for projecting onto the set of\nplausible motions, and (ii) a novel geometric integrator to \"roll out\"\nrealistic motion trajectories during test-time-optimization and generation. Our\nexperiments show significant and consistent gains: trained on the AMASS\ndataset, NRMF remarkably generalizes across multiple input modalities and to\ndiverse tasks ranging from denoising to motion in-betweening and fitting to\npartial 2D / 3D observations.", "AI": {"tldr": "This paper introduces Neural Riemannian Motion Fields (NRMF), a 3D generative human motion model offering robust, consistent, and realistic motion recovery.", "motivation": "Current motion priors lack robustness and fail to ensure temporally consistent, physically plausible motion recovery. A more geometrically rigorous approach is needed to model human motion.", "method": "NRMF models human motion as neural distance fields (NDFs) on a product space of joint rotations, velocities, and accelerations. It includes an adaptive-step projection algorithm and a geometric integrator for realistic motion generation.", "result": "NRMF achieves significant performance improvements across tasks like denoising, motion in-betweening, and fitting sparse 2D/3D observations, outperforming existing methods.", "conclusion": "NRMF provides a physically and temporally consistent framework for 3D motion generation that generalizes effectively across tasks and input modes."}}
{"id": "2509.09672", "pdf": "https://arxiv.org/pdf/2509.09672", "abs": "https://arxiv.org/abs/2509.09672", "authors": ["Artem Lukoianov", "Chenyang Yuan", "Justin Solomon", "Vincent Sitzmann"], "title": "Locality in Image Diffusion Models Emerges from Data Statistics", "categories": ["cs.CV"], "comment": "30 pages, 18 figures, 6 tables", "summary": "Among generative models, diffusion models are uniquely intriguing due to the\nexistence of a closed-form optimal minimizer of their training objective, often\nreferred to as the optimal denoiser. However, diffusion using this optimal\ndenoiser merely reproduces images in the training set and hence fails to\ncapture the behavior of deep diffusion models. Recent work has attempted to\ncharacterize this gap between the optimal denoiser and deep diffusion models,\nproposing analytical, training-free models that can generate images that\nresemble those generated by a trained UNet. The best-performing method\nhypothesizes that shift equivariance and locality inductive biases of\nconvolutional neural networks are the cause of the performance gap, hence\nincorporating these assumptions into its analytical model. In this work, we\npresent evidence that the locality in deep diffusion models emerges as a\nstatistical property of the image dataset, not due to the inductive bias of\nconvolutional neural networks. Specifically, we demonstrate that an optimal\nparametric linear denoiser exhibits similar locality properties to the deep\nneural denoisers. We further show, both theoretically and experimentally, that\nthis locality arises directly from the pixel correlations present in natural\nimage datasets. Finally, we use these insights to craft an analytical denoiser\nthat better matches scores predicted by a deep diffusion model than the prior\nexpert-crafted alternative.", "AI": {"tldr": "The paper investigates the gap between the optimal diffusion model denoiser and deep diffusion models, showing that the emergent locality in deep diffusion is driven by dataset properties rather than CNN biases, and proposes an improved analytical denoiser.", "motivation": "Diffusion models are intriguing because they have a closed-form optimal denoiser, but this optimality doesn't replicate deep diffusion model behaviors. This paper explores the reasons behind this discrepancy and aims to better understand the performance gaps.", "method": "The study examines how locality arises in diffusion models, demonstrating that it stems from datasets' statistical image properties rather than CNN inductive biases. An analytical parametric linear denoiser is proposed alongside theoretical and experimental analysis.", "result": "The optimal parametric linear denoiser exhibits locality properties similar to deep neural denoisers, which the study attributes to dataset-driven pixel correlations. The study constructs an improved analytical denoiser aligning more closely with deep diffusion models.", "conclusion": "Locality in diffusion models is statistically emergent from image datasets, challenging previous assumptions of it being tied to CNNs' inductive biases. This insight enables the design of a more accurate analytical denoiser for diffusion models."}}
{"id": "2509.09676", "pdf": "https://arxiv.org/pdf/2509.09676", "abs": "https://arxiv.org/abs/2509.09676", "authors": ["Jiahao Wang", "Yufeng Yuan", "Rujie Zheng", "Youtian Lin", "Jian Gao", "Lin-Zhuo Chen", "Yajie Bao", "Yi Zhang", "Chang Zeng", "Yanxi Zhou", "Xiaoxiao Long", "Hao Zhu", "Zhaoxiang Zhang", "Xun Cao", "Yao Yao"], "title": "SpatialVID: A Large-Scale Video Dataset with Spatial Annotations", "categories": ["cs.CV"], "comment": "Project page: https://nju-3dv.github.io/projects/SpatialVID/", "summary": "Significant progress has been made in spatial intelligence, spanning both\nspatial reconstruction and world exploration. However, the scalability and\nreal-world fidelity of current models remain severely constrained by the\nscarcity of large-scale, high-quality training data. While several datasets\nprovide camera pose information, they are typically limited in scale,\ndiversity, and annotation richness, particularly for real-world dynamic scenes\nwith ground-truth camera motion. To this end, we collect \\textbf{SpatialVID}, a\ndataset consists of a large corpus of in-the-wild videos with diverse scenes,\ncamera movements and dense 3D annotations such as per-frame camera poses,\ndepth, and motion instructions. Specifically, we collect more than 21,000 hours\nof raw video, and process them into 2.7 million clips through a hierarchical\nfiltering pipeline, totaling 7,089 hours of dynamic content. A subsequent\nannotation pipeline enriches these clips with detailed spatial and semantic\ninformation, including camera poses, depth maps, dynamic masks, structured\ncaptions, and serialized motion instructions. Analysis of SpatialVID's data\nstatistics reveals a richness and diversity that directly foster improved model\ngeneralization and performance, establishing it as a key asset for the video\nand 3D vision research community.", "AI": {"tldr": "The paper introduces SpatialVID, a large-scale dataset of diverse real-world videos with dense 3D annotations aimed at improving model scalability and performance in spatial intelligence tasks.", "motivation": "Existing datasets for spatial reconstruction and world exploration are limited in scale, diversity, and annotation detail, particularly for real-world dynamic scenes with ground-truth camera motion, impeding model scalability and real-world application.", "method": "The authors collect over 21,000 hours of video, filter it into 2.7 million clips, and annotate these with dense spatial and semantic details such as camera poses, depth maps, dynamic masks, and motion instructions, ensuring rich diversity and fidelity.", "result": "SpatialVID consists of 7,089 hours of dynamic content enriched with detailed 3D and semantic annotations. Its diversity and richness enhance model generalization and usability in video and 3D vision tasks.", "conclusion": "SpatialVID addresses the limitations of existing datasets by offering a high-quality, large-scale resource that significantly enhances the potential for advancements in spatial intelligence and 3D vision research."}}
{"id": "2509.09371", "pdf": "https://arxiv.org/pdf/2509.09371", "abs": "https://arxiv.org/abs/2509.09371", "authors": ["Zitao Wang", "Nian Si", "Molei Liu"], "title": "Representation-Aware Distributionally Robust Optimization: A Knowledge Transfer Framework", "categories": ["stat.ME", "cs.LG"], "comment": null, "summary": "We propose REpresentation-Aware Distributionally Robust Estimation (READ), a\nnovel framework for Wasserstein distributionally robust learning that accounts\nfor predictive representations when guarding against distributional shifts.\nUnlike classical approaches that treat all feature perturbations equally, READ\nembeds a multidimensional alignment parameter into the transport cost, allowing\nthe model to differentially discourage perturbations along directions\nassociated with informative representations. This yields robustness to feature\nvariation while preserving invariant structure. Our first contribution is a\ntheoretical foundation: we show that seminorm regularizations for linear\nregression and binary classification arise as Wasserstein distributionally\nrobust objectives, thereby providing tractable reformulations of READ and\nunifying a broad class of regularized estimators under the DRO lens. Second, we\nadopt a principled procedure for selecting the Wasserstein radius using the\ntechniques of robust Wasserstein profile inference. This further enables the\nconstruction of valid, representation-aware confidence regions for model\nparameters with distinct geometric features. Finally, we analyze the geometry\nof READ estimators as the alignment parameters vary and propose an optimization\nalgorithm to estimate the projection of the global optimum onto this solution\nsurface. This procedure selects among equally robust estimators while optimally\nconstructing a representation structure. We conclude by demonstrating the\neffectiveness of our framework through extensive simulations and a real-world\nstudy, providing a powerful robust estimation grounded in learning\nrepresentation.", "AI": {"tldr": "This paper introduces READ, a new framework for robust learning using Wasserstein distributionally robust optimization (DRO), which adapts to predictive representations to handle distributional shifts effectively.", "motivation": "Existing robust learning methods treat all feature perturbations equally, which may overlook the importance of predictive representations. The authors aim to improve robustness by considering representation-aware alignments.", "method": "The authors propose embedding a multidimensional alignment parameter into the transport cost of the Wasserstein DRO problem. They theoretically link this to seminorm regularizations, introduce robust Wasserstein radius selection, analyze the estimator geometry, and propose an optimization algorithm for projection estimation.", "result": "READ offers robustness against feature variation without compromising the invariant structure. It generates confidence regions with unique geometries and selects robust estimators with optimized representation structures.", "conclusion": "Through simulations and a real-world study, READ proves to be a powerful framework for robust estimation, offering the advantage of representation-awareness and enhanced robustness against distributional shifts."}}
{"id": "2509.09414", "pdf": "https://arxiv.org/pdf/2509.09414", "abs": "https://arxiv.org/abs/2509.09414", "authors": ["Alan Said", "Maria Soledad Pera", "Michael D. Ekstrand"], "title": "We're Still Doing It (All) Wrong: Recommender Systems, Fifteen Years Later", "categories": ["cs.IR", "cs.AI"], "comment": "This is the author's version of the work. It is posted here for your\n  personal use. Not for redistribution. The definitive Version of Record was\n  accepted for publication in the Beyond Algorithms: Reclaiming the\n  Interdisciplinary Roots of Recommender Systems Workshop (BEYOND 2025),\n  September 26th, 2025, co-located with the 19th ACM Recommender Systems\n  Conference, Prague, Czech Republic", "summary": "In 2011, Xavier Amatriain sounded the alarm: recommender systems research was\n\"doing it all wrong\" [1]. His critique, rooted in statistical misinterpretation\nand methodological shortcuts, remains as relevant today as it was then. But\nrather than correcting course, we added new layers of sophistication on top of\nthe same broken foundations. This paper revisits Amatriain's diagnosis and\nargues that many of the conceptual, epistemological, and infrastructural\nfailures he identified still persist, in more subtle or systemic forms. Drawing\non recent work in reproducibility, evaluation methodology, environmental\nimpact, and participatory design, we showcase how the field's accelerating\ncomplexity has outpaced its introspection. We highlight ongoing community-led\ninitiatives that attempt to shift the paradigm, including workshops, evaluation\nframeworks, and calls for value-sensitive and participatory research. At the\nsame time, we contend that meaningful change will require not only new metrics\nor better tooling, but a fundamental reframing of what recommender systems\nresearch is for, who it serves, and how knowledge is produced and validated.\nOur call is not just for technical reform, but for a recommender systems\nresearch agenda grounded in epistemic humility, human impact, and sustainable\npractice.", "AI": {"tldr": "This paper revisits longstanding issues in recommender systems research, arguing that fundamental flaws identified in 2011 persist, despite increasing complexity in methodologies.", "motivation": "The research addresses the enduring conceptual, methodological, and infrastructural issues in recommender systems, aiming to critique and refine the field.", "method": "The paper draws on recent developments in reproducibility, evaluation methods, environmental impact studies, and participatory design to analyze problems and propose shifts in the research landscape.", "result": "Highlighting community-driven initiatives, the study identifies that meaningful changes require fundamental reframing of research goals and methodologies within the field.", "conclusion": "Recommender systems research must focus on epistemic humility, prioritize human impact, and adopt sustainable practices instead of compounding complexity on flawed foundations."}}
{"id": "2409.05569", "pdf": "https://arxiv.org/pdf/2409.05569", "abs": "https://arxiv.org/abs/2409.05569", "authors": ["Andreas Langer", "Sara Behnamian"], "title": "DeepTV: A neural network approach for total variation minimization", "categories": ["math.NA", "cs.CV", "cs.NA"], "comment": null, "summary": "Neural network approaches have been demonstrated to work quite well to solve\npartial differential equations in practice. In this context approaches like\nphysics-informed neural networks and the Deep Ritz method have become popular.\nIn this paper, we propose a similar approach to solve an infinite-dimensional\ntotal variation minimization problem using neural networks. We illustrate that\nthe resulting neural network problem does not have a solution in general. To\ncircumvent this theoretic issue, we consider an auxiliary neural network\nproblem, which indeed has a solution, and show that it converges in the sense\nof $\\Gamma$-convergence to the original problem. For computing a numerical\nsolution we further propose a discrete version of the auxiliary neural network\nproblem and again show its $\\Gamma$-convergence to the original\ninfinite-dimensional problem. In particular, the $\\Gamma$-convergence proof\nsuggests a particular discretization of the total variation. Moreover, we\nconnect the discrete neural network problem to a finite difference\ndiscretization of the infinite-dimensional total variation minimization\nproblem. Numerical experiments are presented supporting our theoretical\nfindings.", "AI": {"tldr": "This paper proposes a neural network-based approach to solve an infinite-dimensional total variation minimization problem, establishes theoretical guarantees, and validates findings with numerical experiments.", "motivation": "To explore the use of neural networks in solving infinite-dimensional total variation minimization problems and address the theoretical gaps in existing approaches.", "method": "The authors circumvent the lack of solutions for the neural network problem by creating an auxiliary problem that \u0393-converges to the original. They also propose a discrete version of the problem and analyze its connection to finite difference methods.", "result": "Both the auxiliary and discrete problems are proven to \u0393-converge to the original infinite-dimensional problem. Connections to standard discretization methods are established, and numerical experiments support the theoretical results.", "conclusion": "The study advances the link between infinite-dimensional variational problems and neural network solutions, providing a framework for practical and theoretical problem-solving."}}
{"id": "2509.09424", "pdf": "https://arxiv.org/pdf/2509.09424", "abs": "https://arxiv.org/abs/2509.09424", "authors": ["Zhiyu He", "Maojiang Wang", "Xinwen Gao", "Yuchuan Luo", "Lin Liu", "Shaojing Fu"], "title": "ENSI: Efficient Non-Interactive Secure Inference for Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Secure inference enables privacy-preserving machine learning by leveraging\ncryptographic protocols that support computations on sensitive user data\nwithout exposing it. However, integrating cryptographic protocols with large\nlanguage models (LLMs) presents significant challenges, as the inherent\ncomplexity of these protocols, together with LLMs' massive parameter scale and\nsophisticated architectures, severely limits practical usability. In this work,\nwe propose ENSI, a novel non-interactive secure inference framework for LLMs,\nbased on the principle of co-designing the cryptographic protocols and LLM\narchitecture. ENSI employs an optimized encoding strategy that seamlessly\nintegrates CKKS scheme with a lightweight LLM variant, BitNet, significantly\nreducing the computational complexity of encrypted matrix multiplications. In\nresponse to the prohibitive computational demands of softmax under homomorphic\nencryption (HE), we pioneer the integration of the sigmoid attention mechanism\nwith HE as a seamless, retraining-free alternative. Furthermore, by embedding\nthe Bootstrapping operation within the RMSNorm process, we efficiently refresh\nciphertexts while markedly decreasing the frequency of costly bootstrapping\ninvocations. Experimental evaluations demonstrate that ENSI achieves\napproximately an 8x acceleration in matrix multiplications and a 2.6x speedup\nin softmax inference on CPU compared to state-of-the-art method, with the\nproportion of bootstrapping is reduced to just 1%.", "AI": {"tldr": "ENSI proposes a non-interactive, secure inference framework for LLMs, integrating cryptography protocols with a lightweight LLM architecture to reduce computational complexity.", "motivation": "To address the challenges of integrating cryptographic protocols with large language models (LLMs) for secure and practical privacy-preserving machine learning.", "method": "ENSI co-designs cryptographic protocols and LLM architecture. It uses an optimized encoding strategy with the CKKS scheme and a lightweight LLM (BitNet), integrates sigmoid attention as a retraining-free alternative under homomorphic encryption (HE), and embeds Bootstrapping into RMSNorm to efficiently refresh ciphertexts.", "result": "The framework achieves an 8x acceleration in encrypted matrix multiplications and a 2.6x speedup in softmax inference compared to current methods, while reducing bootstrapping usage to 1%.", "conclusion": "ENSI overcomes critical computational barriers in secure inference for LLMs, offering a significant improvement in efficiency and practicality for privacy-preserving machine learning applications."}}
{"id": "2509.08947", "pdf": "https://arxiv.org/pdf/2509.08947", "abs": "https://arxiv.org/abs/2509.08947", "authors": ["Yancheng Cai", "Robert Wanat", "Rafal Mantiuk"], "title": "CameraVDP: Perceptual Display Assessment with Uncertainty Estimation via Camera and Visual Difference Prediction", "categories": ["cs.GR", "cs.CV"], "comment": "Accepted by SIGGRAPH Asia 2025", "summary": "Accurate measurement of images produced by electronic displays is critical\nfor the evaluation of both traditional and computational displays. Traditional\ndisplay measurement methods based on sparse radiometric sampling and fitting a\nmodel are inadequate for capturing spatially varying display artifacts, as they\nfail to capture high-frequency and pixel-level distortions. While cameras offer\nsufficient spatial resolution, they introduce optical, sampling, and\nphotometric distortions. Furthermore, the physical measurement must be combined\nwith a model of a visual system to assess whether the distortions are going to\nbe visible. To enable perceptual assessment of displays, we propose a\ncombination of a camera-based reconstruction pipeline with a visual difference\npredictor, which account for both the inaccuracy of camera measurements and\nvisual difference prediction. The reconstruction pipeline combines HDR image\nstacking, MTF inversion, vignetting correction, geometric undistortion,\nhomography transformation, and color correction, enabling cameras to function\nas precise display measurement instruments. By incorporating a Visual\nDifference Predictor (VDP), our system models the visibility of various stimuli\nunder different viewing conditions for the human visual system. We validate the\nproposed CameraVDP framework through three applications: defective pixel\ndetection, color fringing awareness, and display non-uniformity evaluation. Our\nuncertainty analysis framework enables the estimation of the theoretical upper\nbound for defect pixel detection performance and provides confidence intervals\nfor VDP quality scores.", "AI": {"tldr": "This paper introduces a system (CameraVDP) combining camera-based image reconstruction with perceptual evaluation, enabling precise measurement of display artifacts and their visibility to human viewers.", "motivation": "Traditional methods fail to capture spatially detailed distortions in modern displays, and camera measurements alone are inaccurate without visual system modeling.", "method": "Developed a pipeline for camera-based reconstruction with techniques like HDR stacking, vignetting correction, and paired it with a Visual Difference Predictor to model human visual perception.", "result": "Validated the CameraVDP framework across three applications: defective pixel detection, color fringes analysis, and display uniformity evaluation.", "conclusion": "CameraVDP effectively combines physical measurements with perceptual modeling, offering robust analysis for display performance and defect detection."}}
{"id": "2509.09482", "pdf": "https://arxiv.org/pdf/2509.09482", "abs": "https://arxiv.org/abs/2509.09482", "authors": ["Agapi Rissaki", "Ilias Fountalis", "Wolfgang Gatterbauer", "Benny Kimelfeld"], "title": "Database Views as Explanations for Relational Deep Learning", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "In recent years, there has been significant progress in the development of\ndeep learning models over relational databases, including architectures based\non heterogeneous graph neural networks (hetero-GNNs) and heterogeneous graph\ntransformers. In effect, such architectures state how the database records and\nlinks (e.g., foreign-key references) translate into a large, complex numerical\nexpression, involving numerous learnable parameters. This complexity makes it\nhard to explain, in human-understandable terms, how a model uses the available\ndata to arrive at a given prediction. We present a novel framework for\nexplaining machine-learning models over relational databases, where\nexplanations are view definitions that highlight focused parts of the database\nthat mostly contribute to the model's prediction. We establish such global\nabductive explanations by adapting the classic notion of determinacy by Nash,\nSegoufin, and Vianu (2010). In addition to tuning the tradeoff between\ndeterminacy and conciseness, the framework allows controlling the level of\ngranularity by adopting different fragments of view definitions, such as ones\nhighlighting whole columns, foreign keys between tables, relevant groups of\ntuples, and so on. We investigate the realization of the framework in the case\nof hetero-GNNs. We develop heuristic algorithms that avoid the exhaustive\nsearch over the space of all databases. We propose techniques that are\nmodel-agnostic, and others that are tailored to hetero-GNNs via the notion of\nlearnable masking. Our approach is evaluated through an extensive empirical\nstudy on the RelBench collection, covering a variety of domains and different\nrecord-level tasks. The results demonstrate the usefulness of the proposed\nexplanations, as well as the efficiency of their generation.", "AI": {"tldr": "This paper introduces a framework to explain predictions of deep learning models, particularly hetero-GNNs, over relational databases using view definitions that highlight relevant database portions.", "motivation": "The complexity of deep learning models over relational databases makes it difficult to explain predictions in understandable terms.", "method": "The approach adapts the notion of determinacy to generate concise and granular explanations while employing model-agnostic and hetero-GNN-specific techniques like learnable masking.", "result": "The proposed explanation framework was empirically validated on the RelBench collection, showing usefulness across various tasks and domains along with efficiency.", "conclusion": "The framework enhances interpretability of relational database ML models like hetero-GNNs, offering meaningful and efficient explanations."}}
{"id": "2509.09488", "pdf": "https://arxiv.org/pdf/2509.09488", "abs": "https://arxiv.org/abs/2509.09488", "authors": ["Felix M\u00e4chtle", "Ashwath Shetty", "Jonas Sander", "Nils Loose", "S\u00f6ren Pirk", "Thomas Eisenbarth"], "title": "Prompt Pirates Need a Map: Stealing Seeds helps Stealing Prompts", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Diffusion models have significantly advanced text-to-image generation,\nenabling the creation of highly realistic images conditioned on textual prompts\nand seeds. Given the considerable intellectual and economic value embedded in\nsuch prompts, prompt theft poses a critical security and privacy concern. In\nthis paper, we investigate prompt-stealing attacks targeting diffusion models.\nWe reveal that numerical optimization-based prompt recovery methods are\nfundamentally limited as they do not account for the initial random noise used\nduring image generation. We identify and exploit a noise-generation\nvulnerability (CWE-339), prevalent in major image-generation frameworks,\noriginating from PyTorch's restriction of seed values to a range of $2^{32}$\nwhen generating the initial random noise on CPUs. Through a large-scale\nempirical analysis conducted on images shared via the popular platform CivitAI,\nwe demonstrate that approximately 95% of these images' seed values can be\neffectively brute-forced in 140 minutes per seed using our seed-recovery tool,\nSeedSnitch. Leveraging the recovered seed, we propose PromptPirate, a genetic\nalgorithm-based optimization method explicitly designed for prompt stealing.\nPromptPirate surpasses state-of-the-art methods, i.e., PromptStealer, P2HP, and\nCLIP-Interrogator, achieving an 8-11% improvement in LPIPS similarity.\nFurthermore, we introduce straightforward and effective countermeasures that\nrender seed stealing, and thus optimization-based prompt stealing, ineffective.\nWe have disclosed our findings responsibly and initiated coordinated mitigation\nefforts with the developers to address this critical vulnerability.", "AI": {"tldr": "This paper discusses vulnerabilities in text-to-image diffusion models, focusing on prompt theft and a flaw in noise generation, and proposes solutions.", "motivation": "To address the security and privacy concerns related to prompt theft in text-to-image diffusion models, which hold significant intellectual and economic value.", "method": "The authors identify a noise-generation vulnerability in major frameworks caused by PyTorch's seed value limitations and conduct large-scale empirical evaluations. They also develop PromptPirate, a new optimization method leveraging brute-forced seeds, and propose countermeasures.", "result": "The authors demonstrate that 95% of images on CivitAI can have their seeds brute-forced within 140 minutes using SeedSnitch. PromptPirate achieves a significant improvement of 8-11% in LPIPS similarity over existing state-of-the-art methods.", "conclusion": "The paper highlights a critical vulnerability in text-to-image generation models and offers both enhanced attacking and defending strategies, ensuring models remain secure and privacy-respecting."}}
{"id": "2509.08973", "pdf": "https://arxiv.org/pdf/2509.08973", "abs": "https://arxiv.org/abs/2509.08973", "authors": ["Harshit Agrawal", "Ari Hietanen", "Simo S\u00e4rkk\u00e4"], "title": "Ultrafast Deep Learning-Based Scatter Estimation in Cone-Beam Computed Tomography", "categories": ["eess.SP", "cs.CV"], "comment": null, "summary": "Purpose: Scatter artifacts drastically degrade the image quality of cone-beam\ncomputed tomography (CBCT) scans. Although deep learning-based methods show\npromise in estimating scatter from CBCT measurements, their deployment in\nmobile CBCT systems or edge devices is still limited due to the large memory\nfootprint of the networks. This study addresses the issue by applying networks\nat varying resolutions and suggesting an optimal one, based on speed and\naccuracy.\n  Methods: First, the reconstruction error in down-up sampling of CBCT scatter\nsignal was examined at six resolutions by comparing four interpolation methods.\nNext, a recent state-of-the-art method was trained across five image\nresolutions and evaluated for the reductions in floating-point operations\n(FLOPs), inference times, and GPU memory requirements.\n  Results: Reducing the input size and network parameters achieved a 78-fold\nreduction in FLOPs compared to the baseline method, while maintaining comarable\nperformance in terms of mean-absolute-percentage-error (MAPE) and\nmean-square-error (MSE). Specifically, the MAPE decreased to 3.85% compared to\n4.42%, and the MSE decreased to 1.34 \\times 10^{-2} compared to 2.01 \\times\n10^{-2}. Inference time and GPU memory usage were reduced by factors of 16 and\n12, respectively. Further experiments comparing scatter-corrected\nreconstructions on a large, simulated dataset and real CBCT scans from water\nand Sedentex CT phantoms clearly demonstrated the robustness of our method.\n  Conclusion: This study highlights the underappreciated role of downsampling\nin deep learning-based scatter estimation. The substantial reduction in FLOPs\nand GPU memory requirements achieved by our method enables scatter correction\nin resource-constrained environments, such as mobile CBCT and edge devices.", "AI": {"tldr": "This paper explores reducing scatter artifacts in CBCT scans using lightweight deep learning techniques, emphasizing downsampling to balance speed and accuracy, with significant improvements in computational efficiency.", "motivation": "Scatter artifacts degrade CBCT image quality, and current deep learning-based solutions are too resource-intensive for mobile CBCT or edge devices. This study aims to enable deployment in such constrained environments by optimizing resolution.", "method": "The paper first analyzed reconstruction errors from down-up sampling of CBCT scatter signals across six resolutions using four interpolation methods. Then, a recent model was trained and evaluated across five resolutions for computational efficiency and performance.", "result": "The proposed method reduced FLOPs by 78-fold while achieving comparable performance in MAPE (3.85% vs. 4.42%) and MSE (1.34 \u00d7 10^-2 vs. 2.01 \u00d7 10^-2). Inference time and GPU memory usage were reduced by factors of 16 and 12, respectively. Consistent performance was demonstrated on simulated and real datasets.", "conclusion": "Downsampling plays a critical role in deep learning-based scatter correction. The method's computational efficiency and maintained accuracy make it feasible for resource-constrained devices like mobile CBCT systems."}}
{"id": "2509.09513", "pdf": "https://arxiv.org/pdf/2509.09513", "abs": "https://arxiv.org/abs/2509.09513", "authors": ["Quentin Uhl", "Tommaso Pavan", "Julianna Gerold", "Kwok-Shing Chan", "Yohan Jun", "Shohei Fujita", "Aneri Bhatt", "Yixin Ma", "Qiaochu Wang", "Hong-Hsi Lee", "Susie Y. Huang", "Berkin Bilgic", "Ileana Jelescu"], "title": "Explainable AI for Accelerated Microstructure Imaging: A SHAP-Guided Protocol on the Connectome 2.0 scanner", "categories": ["physics.med-ph", "cs.AI", "cs.CV", "cs.LG", "eess.IV", "J.3"], "comment": "Submitted to IEEE Transactions on Medical Imaging (TMI). This\n  all-in-one version includes supplementary materials. 18 pages, 14 figures, 2\n  tables", "summary": "The diffusion MRI Neurite Exchange Imaging model offers a promising framework\nfor probing gray matter microstructure by estimating parameters such as\ncompartment sizes, diffusivities, and inter-compartmental water exchange time.\nHowever, existing protocols require long scan times. This study proposes a\nreduced acquisition scheme for the Connectome 2.0 scanner that preserves model\naccuracy while substantially shortening scan duration. We developed a\ndata-driven framework using explainable artificial intelligence with a guided\nrecursive feature elimination strategy to identify an optimal 8-feature subset\nfrom a 15-feature protocol. The performance of this optimized protocol was\nvalidated in vivo and benchmarked against the full acquisition and alternative\nreduction strategies. Parameter accuracy, preservation of anatomical contrast,\nand test-retest reproducibility were assessed. The reduced protocol yielded\nparameter estimates and cortical maps comparable to the full protocol, with low\nestimation errors in synthetic data and minimal impact on test-retest\nvariability. Compared to theory-driven and heuristic reduction schemes, the\noptimized protocol demonstrated superior robustness, reducing the deviation in\nwater exchange time estimates by over two-fold. In conclusion, this hybrid\noptimization framework enables viable imaging of neurite exchange in 14 minutes\nwithout loss of parameter fidelity. This approach supports the broader\napplication of exchange-sensitive diffusion magnetic resonance imaging in\nneuroscience and clinical research, and offers a generalizable method for\ndesigning efficient acquisition protocols in biophysical parameter mapping.", "AI": {"tldr": "The paper presents a reduced acquisition scheme for the Connectome 2.0 scanner that shortens scan time while maintaining model accuracy for Neurite Exchange Imaging.", "motivation": "To address the problem of long scan times in current gray matter microstructure imaging protocols, thereby enhancing practicality and clinical applicability.", "method": "Developed a data-driven framework using explainable AI with a guided recursive feature elimination strategy to optimize an 8-feature protocol, reducing features from 15.", "result": "The reduced 8-feature protocol produced parameter estimates and cortical maps comparable to the full protocol, with minimal test-retest variability and estimation errors.", "conclusion": "The proposed framework achieves accurate neurite exchange imaging in 14 minutes, improving accessibility and providing a generalized approach for efficient imaging protocols."}}
{"id": "2509.09508", "pdf": "https://arxiv.org/pdf/2509.09508", "abs": "https://arxiv.org/abs/2509.09508", "authors": ["Avinash Agarwal", "Manisha J. Nene"], "title": "Incorporating AI Incident Reporting into Telecommunications Law and Policy: Insights from India", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "16 pages, 2 figures, 1 table", "summary": "The integration of artificial intelligence (AI) into telecommunications\ninfrastructure introduces novel risks, such as algorithmic bias and\nunpredictable system behavior, that fall outside the scope of traditional\ncybersecurity and data protection frameworks. This paper introduces a precise\ndefinition and a detailed typology of telecommunications AI incidents,\nestablishing them as a distinct category of risk that extends beyond\nconventional cybersecurity and data protection breaches. It argues for their\nrecognition as a distinct regulatory concern. Using India as a case study for\njurisdictions that lack a horizontal AI law, the paper analyzes the country's\nkey digital regulations. The analysis reveals that India's existing legal\ninstruments, including the Telecommunications Act, 2023, the CERT-In Rules, and\nthe Digital Personal Data Protection Act, 2023, focus on cybersecurity and data\nbreaches, creating a significant regulatory gap for AI-specific operational\nincidents, such as performance degradation and algorithmic bias. The paper also\nexamines structural barriers to disclosure and the limitations of existing AI\nincident repositories. Based on these findings, the paper proposes targeted\npolicy recommendations centered on integrating AI incident reporting into\nIndia's existing telecom governance. Key proposals include mandating reporting\nfor high-risk AI failures, designating an existing government body as a nodal\nagency to manage incident data, and developing standardized reporting\nframeworks. These recommendations aim to enhance regulatory clarity and\nstrengthen long-term resilience, offering a pragmatic and replicable blueprint\nfor other nations seeking to govern AI risks within their existing sectoral\nframeworks.", "AI": {"tldr": "The paper emphasizes the unique risks AI poses to telecommunications, highlighting India's regulatory gaps and offering actionable policy suggestions for addressing AI-specific incidents.", "motivation": "To address the emerging risks of integrating AI into telecommunications that are not covered by existing cybersecurity and data protection laws, especially in jurisdictions without horizontal AI regulations, like India.", "method": "The paper provides a typology of telecommunications AI incidents, analyzes India's key digital regulations, identifies regulatory gaps, and explores disclosure barriers and limitations of AI incident repositories.", "result": "India's regulations like the Telecommunications Act, CERT-In Rules, and Digital Personal Data Protection Act fail to address specific AI risks such as algorithmic bias and performance degradation, revealing a substantial regulatory gap.", "conclusion": "The paper suggests specific policy solutions, including mandatory AI incident reporting and designating a government body to handle such incidents, to improve the integration of AI risk management into existing telecom regulatory frameworks."}}
{"id": "2509.09550", "pdf": "https://arxiv.org/pdf/2509.09550", "abs": "https://arxiv.org/abs/2509.09550", "authors": ["Harry Julia", "Rachel Beeson", "Lohith Konathala", "Johanna Ulin", "Jiameng Gao"], "title": "Finite Scalar Quantization Enables Redundant and Transmission-Robust Neural Audio Compression at Low Bit-rates", "categories": ["cs.SD", "cs.LG"], "comment": null, "summary": "Neural Audio Codecs (NACs) have become increasingly adopted in speech\nprocessing tasks due to their excellent rate-distortion performance and\ncompatibility with Large Language Models (LLMs) as discrete feature\nrepresentations for audio generation. While most existing codecs rely on\nResidual Vector Quantization (RVQ), Finite Scalar Quantization (FSQ) has\nrecently emerged as a compelling alternative that simplifies training and\nnatively supports single codebooks. We introduce NeuCodec, an FSQ-based NAC,\nand show that FSQ encodes baked-in redundancy which produces an encoding which\nis robust when transmitted through noisy channels. First, through an encoder\ndistillation experiment, we show that two different encoders can learn to\nencode identical audio into vastly different code sequences whilst maintaining\ncomparable reconstruction quality with the same quantizer and decoder. Second,\nwe demonstrate that FSQ has vastly superior bit-level perturbation robustness\nby comparing the performance of RVQ and FSQ codecs when simulating the\ntransmission of code sequences through a noisy channel.", "AI": {"tldr": "NeuCodec, an FSQ-based neural audio codec, demonstrates robust performance in noisy channels and is shown to maintain reconstruction quality despite encoding variations.", "motivation": "Exploring a new FSQ-based approach in neural audio codecs due to baked-in redundancy, aiming to enhance robustness for transmission over noisy channels.", "method": "Encoder distillation experiments to compare encoding approaches and noise simulation tests for bit-level perturbation robustness analysis.", "result": "FSQ codecs exhibit superior robustness to noisy transmission compared to RVQ codecs, with encoders creating diverse code sequences while preserving reconstruction quality.", "conclusion": "FSQ-based NACs, like NeuCodec, hold promise for applications requiring resilience in noisy environments, leveraging FSQ's inherent capabilities."}}
{"id": "2509.09564", "pdf": "https://arxiv.org/pdf/2509.09564", "abs": "https://arxiv.org/abs/2509.09564", "authors": ["Meghan Wilkinson", "Robert H Thomson"], "title": "What Does Normal Even Mean? Evaluating Benign Traffic in Intrusion Detection Datasets", "categories": ["cs.CR", "cs.LG"], "comment": "10 pages; accepted to SBP-BRiMS 2025 Poster Session", "summary": "Supervised machine learning techniques rely on labeled data to achieve high\ntask performance, but this requires the labels to capture some meaningful\ndifferences in the underlying data structure. For training network intrusion\ndetection algorithms, most datasets contain a series of attack classes and a\nsingle large benign class which captures all non-attack network traffic. A\nreview of intrusion detection papers and guides that explicitly state their\ndata preprocessing steps identified that the majority took the labeled\ncategories of the dataset at face value when training their algorithms. The\npresent paper evaluates the structure of benign traffic in several common\nintrusion detection datasets (NSL-KDD, UNSW-NB15, and CIC-IDS 2017) and\ndetermines whether there are meaningful sub-categories within this traffic\nwhich may improve overall multi-classification performance using common machine\nlearning techniques. We present an overview of some unsupervised clustering\ntechniques (e.g., HDBSCAN, Mean Shift Clustering) and show how they\ndifferentially cluster the benign traffic space.", "AI": {"tldr": "The paper investigates whether sub-categories exist within benign traffic in network intrusion detection datasets to potentially enhance multi-classification performance using clustering techniques.", "motivation": "Most intrusion detection research treats benign traffic as a single undifferentiated class, raising concerns that this approach might overlook meaningful substructures within the data.", "method": "The authors employ unsupervised clustering techniques, like HDBSCAN and Mean Shift Clustering, to analyze and evaluate benign traffic in datasets such as NSL-KDD, UNSW-NB15, and CIC-IDS 2017.", "result": "The study demonstrates that different clustering techniques produce distinct partitions of benign traffic, suggesting the presence of meaningful sub-categories.", "conclusion": "Identifying sub-categories within benign traffic using clustering approaches could improve the performance of existing supervised intrusion detection algorithms."}}
{"id": "2509.09227", "pdf": "https://arxiv.org/pdf/2509.09227", "abs": "https://arxiv.org/abs/2509.09227", "authors": ["Yinzheng Zhao", "Zhihao Zhao", "Rundong Jiang", "Louisa Sackewitz", "Quanmin Liang", "Mathias Maier", "Daniel Zapp", "Peter Charbel Issa", "Mohammad Ali Nasseri"], "title": "Dynamic Structural Recovery Parameters Enhance Prediction of Visual Outcomes After Macular Hole Surgery", "categories": ["eess.IV", "cs.CV", "I.4.6"], "comment": "TVST", "summary": "Purpose: To introduce novel dynamic structural parameters and evaluate their\nintegration within a multimodal deep learning (DL) framework for predicting\npostoperative visual recovery in idiopathic full-thickness macular hole (iFTMH)\npatients. Methods: We utilized a publicly available longitudinal OCT dataset at\nfive stages (preoperative, 2 weeks, 3 months, 6 months, and 12 months). A stage\nspecific segmentation model delineated related structures, and an automated\npipeline extracted quantitative, composite, qualitative, and dynamic features.\nBinary logistic regression models, constructed with and without dynamic\nparameters, assessed their incremental predictive value for best-corrected\nvisual acuity (BCVA). A multimodal DL model combining clinical variables,\nOCT-derived features, and raw OCT images was developed and benchmarked against\nregression models. Results: The segmentation model achieved high accuracy\nacross all timepoints (mean Dice > 0.89). Univariate and multivariate analyses\nidentified base diameter, ellipsoid zone integrity, and macular hole area as\nsignificant BCVA predictors (P < 0.05). Incorporating dynamic recovery rates\nconsistently improved logistic regression AUC, especially at the 3-month\nfollow-up. The multimodal DL model outperformed logistic regression, yielding\nhigher AUCs and overall accuracy at each stage. The difference is as high as\n0.12, demonstrating the complementary value of raw image volume and dynamic\nparameters. Conclusions: Integrating dynamic parameters into the multimodal DL\nmodel significantly enhances the accuracy of predictions. This fully automated\nprocess therefore represents a promising clinical decision support tool for\npersonalized postoperative management in macular hole surgery.", "AI": {"tldr": "The paper proposes using dynamic structural parameters within a multimodal deep learning framework to enhance prediction accuracy for visual recovery in macular hole patients.", "motivation": "Current methods lack the precision to predict postoperative visual outcomes for macular hole surgery, necessitating better predictive tools.", "method": "The study leveraged publicly available longitudinal OCT data and integrated automated feature extraction with multimodal deep learning techniques alongside logistic regression models.", "result": "Dynamic recovery parameters notably improved predictive accuracy in regression models, and the multimodal deep learning model outperformed these, with significant performance boosts at various postoperative stages.", "conclusion": "Dynamic parameters integrated within deep learning frameworks present substantial promise for improving personalized postoperative management in macular hole surgeries."}}
{"id": "2509.09494", "pdf": "https://arxiv.org/pdf/2509.09494", "abs": "https://arxiv.org/abs/2509.09494", "authors": ["Zhuoyuan Li", "Jiacheng Li", "Yao Li", "Jialin Li", "Li Li", "Dong Liu", "Feng Wu"], "title": "In-Loop Filtering Using Learned Look-Up Tables for Video Coding", "categories": ["eess.IV", "cs.CV", "cs.MM"], "comment": "25 pages", "summary": "In-loop filtering (ILF) is a key technology in video coding standards to\nreduce artifacts and enhance visual quality. Recently, neural network-based ILF\nschemes have achieved remarkable coding gains, emerging as a powerful candidate\nfor next-generation video coding standards. However, the use of deep neural\nnetworks (DNN) brings significant computational and time complexity or high\ndemands for dedicated hardware, making it challenging for general use. To\naddress this limitation, we study a practical ILF solution by adopting look-up\ntables (LUTs). After training a DNN with a restricted reference range for ILF,\nall possible inputs are traversed, and the output values of the DNN are cached\ninto LUTs. During the coding process, the filtering process is performed by\nsimply retrieving the filtered pixel through locating the input pixels and\ninterpolating between the cached values, instead of relying on heavy inference\ncomputations. In this paper, we propose a universal LUT-based ILF framework,\ntermed LUT-ILF++. First, we introduce the cooperation of multiple kinds of\nfiltering LUTs and propose a series of customized indexing mechanisms to enable\nbetter filtering reference perception with limited storage consumption. Second,\nwe propose the cross-component indexing mechanism to enable the filtering of\ndifferent color components jointly. Third, in order to make our solution\npractical for coding uses, we propose the LUT compaction scheme to enable the\nLUT pruning, achieving a lower storage cost of the entire solution. The\nproposed framework is implemented in the VVC reference software. Experimental\nresults show that the proposed framework achieves on average 0.82%/2.97%/1.63%\nand 0.85%/4.11%/2.06% bitrate reduction for common test sequences, under the AI\nand RA configurations, respectively. Compared to DNN-based solutions, our\nproposed solution has much lower time complexity and storage cost.", "AI": {"tldr": "The paper proposes a look-up table-based in-loop filtering (ILF) solution, LUT-ILF++, to enhance video coding efficiency with reduced time and computational complexity.", "motivation": "Deep neural network-based ILF methods, while effective, are computationally intensive and demand dedicated hardware. The paper aims to address this limitation by exploring a practical solution using look-up tables (LUTs) to reduce this complexity.", "method": "The authors train a DNN for ILF and store its output values into LUTs, enabling filtering by retrieving the filtered pixels instead of heavy computations. Innovations include cooperation of multiple filtering LUTs, cross-component indexing for joint filtering of color components, and LUT pruning to reduce storage requirements.", "result": "The framework was implemented in VVC reference software and showed significant bitrate reductions (0.82%\u20134.11%) across different configurations with much lower computational and storage costs compared to DNN-based methods.", "conclusion": "The LUT-ILF++ framework demonstrates a practical and efficient solution for video coding, providing a good balance between performance and resource requirements, making it more suitable for general use."}}
