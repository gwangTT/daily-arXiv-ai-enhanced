{"id": "2510.01216", "pdf": "https://arxiv.org/pdf/2510.01216", "abs": "https://arxiv.org/abs/2510.01216", "authors": ["Preston Vander Vos"], "title": "Odontoceti: Ultra-Fast DAG Consensus with Two Round Commitment", "categories": ["cs.DC", "cs.CR"], "comment": "MSc thesis. Supervisors: Philipp Jovanovic and Alberto Sonnino", "summary": "Users of blockchains value scalability, expecting fast confirmations and\nimmediate transaction processing. Odontoceti, the latest in DAG-based\nconsensus, addresses these concerns by prioritizing low latency and high\nthroughput, making a strategic trade-off in security by operating with a 20%\nfault tolerance instead of the established 33% level. It is the first DAG-based\nprotocol to achieve commitment in just two communication rounds, delivering\nmedian latency of 300 milliseconds while processing 10,000 transactions per\nsecond under realistic network conditions. Odontoceti operates with n = 5f + 1\nvalidators and creates an uncertified DAG with a novel decision rule for\ncommitting blocks. The protocol includes an optimization that advances progress\nwhen participants are slow, benefiting crash fault scenarios which are more\ncommon in practice than Byzantine faults. Evaluation results demonstrate 20-25%\nlatency improvements compared to an existing production protocol, validating\nthat reducing wave length from three rounds to two rounds yields meaningful\nperformance benefits. This paper establishes the practical viability of lower\nfault tolerance consensus protocols for blockchains.", "AI": {"tldr": "Odontoceti, a DAG-based consensus protocol, improves blockchain scalability with low latency (300ms) and high throughput (10,000 TPS) by trading off fault tolerance (20% instead of 33%). It uses two communication rounds and demonstrates notable performance improvements.", "motivation": "Blockchain users demand faster transaction processing and reduced latency, leading to scalability concerns, which the study addresses through a new DAG-based protocol.", "method": "The protocol uses a DAG structure with n = 5f + 1 validators, operating under 20% fault tolerance. It commits blocks in two communication rounds, includes crash-fault optimizations, and measures performance under realistic conditions.", "result": "The protocol achieves a median latency of 300 milliseconds and processes 10,000 transactions per second, with a 20-25% latency improvement over existing protocols.", "conclusion": "Odontoceti demonstrates the practicality of lower fault tolerance consensus protocols for enhancing blockchain scalability and performance."}}
{"id": "2510.01256", "pdf": "https://arxiv.org/pdf/2510.01256", "abs": "https://arxiv.org/abs/2510.01256", "authors": ["Lingling Zeng", "Gen Zhang", "Jialin Peng", "Xiang Xu", "Yuan Xu", "Lijun Ma"], "title": "Kant: An Efficient Unified Scheduling System for Large-Scale AI Clusters", "categories": ["cs.DC", "cs.AI", "cs.IT", "cs.LG", "math.IT", "I.2.6; I.2.7; C.2.4; C.1.4"], "comment": "25 pages,15 figures", "summary": "As AI cluster sizes continue to expand and the demand for\nlarge-language-model (LLM) training and inference workloads grows rapidly,\ntraditional scheduling systems face significant challenges in balancing\nresource utilization, scheduling efficiency, and service quality. This paper\npresents and evaluates Kant: an efficient unified scheduling platform designed\nfor large-scale AI container clusters, supporting the co-scheduling of both\ntraining and inference jobs. Based on the practical implementation of the Kant\nsystem, we systematically define a set of key evaluation metrics for AI\nclusters, including GPU Allocation Ratio (GAR), Scheduling Occupancy Rate\n(SOR), GPU Node Fragmentation Ratio (GFR), Job Waiting Time Distribution\n(JWTD), and Job Training Time Estimation Distribution (JTTED), providing a\nfoundation for quantitative performance analysis. Experimental results\ndemonstrate that Kant achieves exceptional performance in clusters ranging from\nhundreds to tens of thousands of GPUs. By leveraging scheduling strategies such\nas Backfill and Enhanced Binpack (E-Binpack), the system significantly improves\nresource utilization and scheduling efficiency, while effectively reducing\nresource fragmentation and communication overhead in distributed training. The\nsystem has been deployed in multiple AI data center clusters, where it stably\nsupports large-scale intelligent computing workloads. This work provides a\npractical engineering approach for building high-performance, highly available,\nAI-native scheduling infrastructure.", "AI": {"tldr": "This paper introduces Kant, a unified scheduling platform for AI container clusters, which improves resource utilization, efficiency, and reduces fragmentation in training and inference jobs.", "motivation": "To address traditional scheduling systems' inefficiency in large-scale AI workloads.", "method": "Developed and implemented the Kant system, employing Backfill and Enhanced Binpack (E-Binpack) strategies to optimize scheduling.", "result": "Kant achieved high performance in large AI clusters, improving GPU utilization and reducing resource fragmentation.", "conclusion": "The system enables high-performance scheduling for AI workloads and has been successfully deployed in multiple AI data centers."}}
{"id": "2510.01260", "pdf": "https://arxiv.org/pdf/2510.01260", "abs": "https://arxiv.org/abs/2510.01260", "authors": ["Ningyuan Yang", "Guanliang Lyu", "Mingchen Ma", "Yiyi Lu", "Yiming Li", "Zhihui Gao", "Hancheng Ye", "Jianyi Zhang", "Tingjun Chen", "Yiran Chen"], "title": "IoT-MCP: Bridging LLMs and IoT Systems Through Model Context Protocol", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "The integration of Large Language Models (LLMs) with Internet-of-Things (IoT)\nsystems faces significant challenges in hardware heterogeneity and control\ncomplexity. The Model Context Protocol (MCP) emerges as a critical enabler,\nproviding standardized communication between LLMs and physical devices. We\npropose IoT-MCP, a novel framework that implements MCP through edge-deployed\nservers to bridge LLMs and IoT ecosystems. To support rigorous evaluation, we\nintroduce IoT-MCP Bench, the first benchmark containing 114 Basic Tasks (e.g.,\n``What is the current temperature?'') and 1,140 Complex Tasks (e.g., ``I feel\nso hot, do you have any ideas?'') for IoT-enabled LLMs. Experimental validation\nacross 22 sensor types and 6 microcontroller units demonstrates IoT-MCP's 100%\ntask success rate to generate tool calls that fully meet expectations and\nobtain completely accurate results, 205ms average response time, and 74KB peak\nmemory footprint. This work delivers both an open-source integration framework\n(https://github.com/Duke-CEI-Center/IoT-MCP-Servers) and a standardized\nevaluation methodology for LLM-IoT systems.", "AI": {"tldr": "The paper introduces IoT-MCP, a framework integrating Large Language Models (LLMs) with Internet-of-Things (IoT) via the Model Context Protocol (MCP), achieving 100% task success rate with low resource usage.", "motivation": "Address challenges in hardware heterogeneity and control complexity for LLM-IoT integration.", "method": "Developed IoT-MCP framework using edge-deployed servers and benchmarked it with IoT-MCP Bench, encompassing Basic and Complex Tasks.", "result": "The framework achieved 100% task success, 205ms average response time, and 74KB peak memory use across diverse IoT devices.", "conclusion": "IoT-MCP provides a robust solution for LLM-IoT connectivity and establishes a standardized methodology alongside an open-source integration framework."}}
