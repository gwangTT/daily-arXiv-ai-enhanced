{"id": "2512.03565", "pdf": "https://arxiv.org/pdf/2512.03565", "abs": "https://arxiv.org/abs/2512.03565", "authors": ["Luis Gall", "Samuel James Newcome", "Fabio Alexander Gratl", "Markus M\u00fchlh\u00e4u\u00dfer", "Manish Kumar Mishra", "Hans-Joachim Bungartz"], "title": "Tuning of Vectorization Parameters for Molecular Dynamics Simulations in AutoPas", "categories": ["cs.DC", "cs.CE", "cs.PF"], "comment": "20 pages, 8 figures. Submitted to the 5th International Conference on Computational Engineering (ICCE 2024). No changes were made after the peer review process", "summary": "Molecular Dynamics simulations can help scientists to gather valuable insights for physical processes on an atomic scale. This work explores various techniques for SIMD vectorization to improve the pairwise force calculation between molecules in the scope of the particle simulation library AutoPas. The focus lies on the order in which particle values are loaded into vector registers to achieve the most optimal performance regarding execution time or energy consumption.\n  As previous work indicates that the optimal MD algorithm can change during runtime, this paper investigates simulation-specific parameters like particle density and the impact of the neighbor identification algorithms, which distinguishes this work from related projects. Furthermore, AutoPas' dynamic tuning mechanism is extended to choose the optimal vectorization order during runtime.\n  The benchmarks show that considering different particle interaction orders during runtime can lead to a considerable performance improvement for the force calculation compared to AutoPas' previous approach.", "AI": {"tldr": "The paper explores SIMD vectorization techniques to optimize molecular dynamics (MD) force calculation in AutoPas with adaptive runtime tuning.", "motivation": "To improve the computational efficiency of molecular dynamics simulations for pairwise force calculations by leveraging SIMD vectorization.", "method": "The study investigates vectorization orders, evaluates particle density and neighbor identification algorithms, and extends AutoPas' dynamic tuning to adjust vectorization orders during runtime.", "result": "Benchmarks demonstrate significant performance improvement in force calculation by dynamically adjusting particle interaction orders compared to previous AutoPas methods.", "conclusion": "Dynamic tuning of vectorization orders during runtime enhances execution time and energy efficiency in molecular dynamics simulations."}}
{"id": "2512.03864", "pdf": "https://arxiv.org/pdf/2512.03864", "abs": "https://arxiv.org/abs/2512.03864", "authors": ["Danny Hoang", "Anandkumar Patel", "Ruimen Chen", "Rajiv Malhotra", "Farhad Imani"], "title": "Hyperdimensional Computing for Sustainable Manufacturing: An Initial Assessment", "categories": ["cs.LG", "cs.AI", "cs.PF", "cs.SC"], "comment": null, "summary": "Smart manufacturing can significantly improve efficiency and reduce energy consumption, yet the energy demands of AI models may offset these gains. This study utilizes in-situ sensing-based prediction of geometric quality in smart machining to compare the energy consumption, accuracy, and speed of common AI models. HyperDimensional Computing (HDC) is introduced as an alternative, achieving accuracy comparable to conventional models while drastically reducing energy consumption, 200$\\times$ for training and 175 to 1000$\\times$ for inference. Furthermore, HDC reduces training times by 200$\\times$ and inference times by 300 to 600$\\times$, showcasing its potential for energy-efficient smart manufacturing.", "AI": {"tldr": "The paper discusses HyperDimensional Computing (HDC), an energy-efficient AI model, in smart manufacturing, greatly reducing energy usage and computation times while maintaining high accuracy.", "motivation": "To address the challenge of excessive energy consumption by AI models in smart manufacturing, which could offset the efficiency benefits.", "method": "The study employs in-situ sensing-based predictions for geometric quality in machining and compares the performance (energy, accuracy, speed) of common AI models with HDC.", "result": "HDC shows significant energy and time savings: 200\u00d7 reduction in training energy, 175\u20131000\u00d7 reduction in inference energy, 200\u00d7 reduction in training time, and 300\u2013600\u00d7 reduction in inference time.", "conclusion": "HyperDimensional Computing emerges as a viable, energy-efficient alternative for AI applications in smart manufacturing without compromising accuracy."}}
{"id": "2512.03914", "pdf": "https://arxiv.org/pdf/2512.03914", "abs": "https://arxiv.org/abs/2512.03914", "authors": ["Jeremy J. Williams", "Stefan Costea", "Daniel Medeiros", "Jordy Trilaksono", "Pratibha Hegde", "David Tskhakaya", "Leon Kos", "Ales Podolnik", "Jakub Hromadka", "Kevin A. Huck", "Allen D. Malony", "Frank Jenko", "Erwin Laure", "Stefano Markidis"], "title": "Integrating High Performance In-Memory Data Streaming and In-Situ Visualization in Hybrid MPI+OpenMP PIC MC Simulations Towards Exascale", "categories": ["physics.plasm-ph", "cs.DC", "cs.PF"], "comment": "Accepted by The International Journal of High Performance Computing Applications (IJHPCA) prepared in English, formatted in Sage Journals (LaTex) template and consists of 22 pages, which includes the main text, references, and figures", "summary": "Efficient simulation of complex plasma dynamics is crucial for advancing fusion energy research. Particle-in-Cell (PIC) Monte Carlo (MC) simulations provide insights into plasma behavior, including turbulence and confinement, which are essential for optimizing fusion reactor performance. Transitioning to exascale simulations introduces significant challenges, with traditional file input/output (I/O) inefficiencies remaining a key bottleneck. This work advances BIT1, an electrostatic PIC MC code, by improving the particle mover with OpenMP task-based parallelism, integrating the openPMD streaming API, and enabling in-memory data streaming with ADIOS2's Sustainable Staging Transport (SST) engine to enhance I/O performance, computational efficiency, and system storage utilization. We employ profiling tools such as gprof, perf, IPM and Darshan, which provide insights into computation, communication, and I/O operations. We implement time-dependent data checkpointing with the openPMD API enabling seamless data movement and in-situ visualization for real-time analysis without interrupting the simulation. We demonstrate improvements in simulation runtime, data accessibility and real-time insights by comparing traditional file I/O with the ADIOS2 BP4 and SST backends. The proposed hybrid BIT1 openPMD SST enhancement introduces a new paradigm for real-time scientific discovery in plasma simulations, enabling faster insights and more efficient use of exascale computing resources.", "AI": {"tldr": "The paper focuses on optimizing Particle-in-Cell (PIC) Monte Carlo plasma simulations by utilizing OpenMP, ADIOS2 SST, and openPMD to improve runtime, data accessibility, and real-time visualization, addressing exascale computational challenges.", "motivation": "To overcome inefficiencies in traditional file I/O and enhance the computational capabilities of plasma simulations to leverage exascale computing for fusion energy research.", "method": "The paper integrates OpenMP for task-based parallelism, the openPMD streaming API, and ADIOS2 SST to improve the existing BIT1 simulation code. Profiling tools like gprof, perf, IPM, and Darshan are used for performance analysis.", "result": "The enhancements lead to better runtime performance, seamless data visualization, and improved system storage utilization when compared to traditional file I/O approaches.", "conclusion": "The proposed optimizations in BIT1 enable real-time scientific discovery for plasma simulations, demonstrating the potential for better efficiency and insights in exascale computing environments."}}
{"id": "2512.03879", "pdf": "https://arxiv.org/pdf/2512.03879", "abs": "https://arxiv.org/abs/2512.03879", "authors": ["Luu Trong Nhan", "Luu Trung Duong", "Pham Ngoc Nam", "Truong Cong Thang"], "title": "Hybrid Temporal-8-Bit Spike Coding for Spiking Neural Network Surrogate Training", "categories": ["cs.NE"], "comment": "Work under review", "summary": "Spiking neural networks (SNNs) have emerged as a promising direction in both computational neuroscience and artificial intelligence, offering advantages such as strong biological plausibility and low energy consumption on neuromorphic hardware. Despite these benefits, SNNs still face challenges in achieving state-of-the-art performance on vision tasks. Recent work has shown that hybrid rate-temporal coding strategies (particularly those incorporating bit-plane representations of images into traditional rate coding schemes) can significantly improve performance when trained with surrogate backpropagation. Motivated by these findings, this study proposes a hybrid temporal-bit spike coding method that integrates bit-plane decompositions with temporal coding principles. Through extensive experiments across multiple computer vision benchmarks, we demonstrate that blending bit-plane information with temporal coding yields competitive, and in some cases improved, performance compared to established spike-coding techniques. To the best of our knowledge, this is the first work to introduce a hybrid temporal-bit coding scheme specifically designed for surrogate gradient training of SNNs.", "AI": {"tldr": "This paper presents a novel hybrid temporal-bit spike coding for spiking neural networks (SNNs), combining temporal coding with bit-plane image decomposition for improved performance.", "motivation": "SNNs offer energy-efficient and biologically plausible solutions but struggle to achieve state-of-the-art performance on vision tasks. To address this, hybrid coding strategies are explored to enhance performance.", "method": "Introduces a hybrid temporal-bit spike coding method by integrating bit-plane decompositions with principles of temporal coding, optimized through surrogate gradient training.", "result": "The method showcases competitive and sometimes superior performance across various computer vision benchmarks compared to existing spike-coding techniques.", "conclusion": "This study is the first to propose this hybrid temporal-bit coding approach, demonstrating its effectiveness for SNN training, paving the way for further advancements in SNN methodologies."}}
{"id": "2512.03416", "pdf": "https://arxiv.org/pdf/2512.03416", "abs": "https://arxiv.org/abs/2512.03416", "authors": ["Ruiqi Lai", "Hongrui Liu", "Chengzhi Lu", "Zonghao Liu", "Siyu Cao", "Siyang Shao", "Yixin Zhang", "Luo Mai", "Dmitrii Ustiugov"], "title": "TokenScale: Timely and Accurate Autoscaling for Disaggregated LLM Serving with Token Velocity", "categories": ["cs.DC"], "comment": null, "summary": "The architectural shift to prefill/decode (PD) disaggregation in LLM serving improves resource utilization but struggles with the bursty nature of modern workloads. Existing autoscaling policies, often retrofitted from monolithic systems like those in AIBrix and DistServe, rely on lagging indicators such as GPU utilization or coarse-grained request counts. This results in slow reactions to load spikes, leading to significant Time-to First-Token (TTFT) and Time-Per-Output-Token (TPOT) SLO violations and costly over-provisioning. We introduce TokenScale, an autoscaling framework that resolves this performance mismatch through two innovations. First, we propose Token Velocity, a novel metric that unifies the prefill, network, and decode stages by quantifying their rate of work. As a leading indicator of system backpressure, it enables proactive scaling. Second, Convertible Decoders allow decoder GPUs to dynamically execute prefill tasks during traffic spikes, creating a rapid-response buffer that absorbs bursts and eliminates the initialization latency of new prefillers. Our evaluation on a GPU cluster with production traces shows TokenScale improves SLO attainment from 50-88% to 80-96% and reduces costs by 4-14% over state-of-the-art systems, including DistServe, BlitzScale, and AIBrix. By uniting a predictive metric with a flexible system design, TokenScale significantly boosts the performance and efficiency of disaggregated LLM serving infrastructure.", "AI": {"tldr": "TokenScale is a new autoscaling framework for large language model (LLM) serving, improving the response time and cost-efficiency compared to existing systems by introducing a predictive metric and flexible resource allocation.", "motivation": "The motivation is to address inefficiencies and slow response times of current autoscaling systems in handling the bursty nature of modern LLM workloads while improving resource utilization.", "method": "TokenScale introduces two innovations: a predictive metric called Token Velocity for proactive scaling and Convertible Decoders that can dynamically manage prefill tasks during traffic spikes.", "result": "The framework improves SLO attainment rates from 50-88% to 80-96% and reduces costs by 4-14% compared to current state-of-the-art systems.", "conclusion": "TokenScale enhances the performance and efficiency of disaggregated LLM serving infrastructure by combining predictive scaling metrics with adaptable resource strategies."}}
{"id": "2512.03594", "pdf": "https://arxiv.org/pdf/2512.03594", "abs": "https://arxiv.org/abs/2512.03594", "authors": ["Afsara Khan", "Austin Rovinski"], "title": "Accelerating Detailed Routing Convergence through Offline Reinforcement Learning", "categories": ["cs.AR"], "comment": "To be published in the Design, Automation and Test in Europe (DATE) 2026 Conference", "summary": "Detailed routing remains one of the most complex and time-consuming steps in modern physical design due to the challenges posed by shrinking feature sizes and stricter design rules. Prior detailed routers achieve state-of-the-art results by leveraging iterative pathfinding algorithms to route each net. However, runtimes are a major issue in detailed routers, as converging to a solution with zero design rule violations (DRVs) can be prohibitively expensive.\n  In this paper, we propose leveraging reinforcement learning (RL) to enable rapid convergence in detailed routing by learning from previous designs. We make the key observation that prior detailed routers statically schedule the cost weights used in their routing algorithms, meaning they do not change in response to the design or technology. By training a conservative Q-learning (CQL) model to dynamically select the routing cost weights which minimize the number of algorithm iterations, we find that our work completes the ISPD19 benchmarks with 1.56x average and up to 3.01x faster runtime than the baseline router while maintaining or improving the DRV count in all cases. We also find that this learning shows signs of generalization across technologies, meaning that learning designs in one technology can translate to improved outcomes in other technologies.", "AI": {"tldr": "The paper proposes using reinforcement learning to speed up detailed routing in physical design while maintaining or improving performance.", "motivation": "Detailed routing in physical design is highly complicated and time-intensive due to shrinking feature sizes and stricter design rules. Traditional routers face runtime issues while resolving design rule violations.", "method": "The authors use reinforcement learning with a Conservative Q-Learning (CQL) model to dynamically adjust routing cost weights to minimize algorithm iterations, as opposed to static scheduling.", "result": "The method achieves an average runtime improvement of 1.56x (up to 3.01x) on ISPD19 benchmarks while maintaining or improving the count of design rule violations. It also shows potential for cross-technology generalization.", "conclusion": "Reinforcement learning can be effectively leveraged to speed up detailed routing processes in physical design, demonstrating potential for future advancements in cross-technology applications."}}
{"id": "2512.03048", "pdf": "https://arxiv.org/pdf/2512.03048", "abs": "https://arxiv.org/abs/2512.03048", "authors": ["Austin Spizzirri"], "title": "Exploring Syntropic Frameworks in AI Alignment: A Philosophical Investigation", "categories": ["cs.AI", "cs.CY", "cs.LG", "cs.MA"], "comment": "Approx. 3,000 words, 10 pages. Philosophical analysis of AI alignment (process-based / syntropy framework)", "summary": "I argue that AI alignment should be reconceived as architecting syntropic, reasons-responsive agents through process-based, multi-agent, developmental mechanisms rather than encoding fixed human value content. The paper makes three philosophical contributions. First, I articulate the ``specification trap'' argument demonstrating why content-based value specification appears structurally unstable due to the conjunction of the is-ought gap, value pluralism, and the extended frame problem. Second, I propose syntropy -- the recursive reduction of mutual uncertainty between agents through state alignment -- as an information-theoretic framework for understanding multi-agent alignment dynamics. Third, I establish a functional distinction between genuine and simulated moral capacity grounded in compatibilist theories of guidance control, coupled with an embodied experimental paradigm and verification regime providing operational criteria independent of phenomenological claims. This paper represents the philosophical component of a broader research program whose empirical validation is being developed in a separate project currently in preparation. While the framework generates specific, falsifiable predictions about value emergence and moral agency in artificial systems, empirical validation remains pending.", "AI": {"tldr": "AI alignment should focus on developing syntropic, reasons-responsive agents using multi-agent, developmental processes, instead of embedding fixed human values.", "motivation": "The structural instability of content-based value systems in AI due to issues like the is-ought gap, value pluralism, and the extended frame problem.", "method": "Proposes syntropy as a framework for AI alignment, explores the distinction between genuine and simulated moral capacity, and outlines a methodology for experimental validation.", "result": "Outlined a theoretical framework and philosophical basis but notes that empirical validation is still ongoing.", "conclusion": "Suggests a shift in AI alignment research towards dynamic, developmental approaches rather than fixed content encoding, offering a philosophical groundwork for future investigations."}}
{"id": "2512.03047", "pdf": "https://arxiv.org/pdf/2512.03047", "abs": "https://arxiv.org/abs/2512.03047", "authors": ["Samih Fadli"], "title": "Entropy-Based Measurement of Value Drift and Alignment Work in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "6 pages. Companion paper to \"The Second Law of Intelligence: Controlling Ethical Entropy in Autonomous Systems\". Code and tools: https://github.com/AerisSpace/EthicalEntropyKit", "summary": "Large language model safety is usually assessed with static benchmarks, but key failures are dynamic: value drift under distribution shift, jailbreak attacks, and slow degradation of alignment in deployment. Building on a recent Second Law of Intelligence that treats ethical entropy as a state variable which tends to increase unless countered by alignment work, we make this framework operational for large language models. We define a five-way behavioral taxonomy, train a classifier to estimate ethical entropy S(t) from model transcripts, and measure entropy dynamics for base and instruction-tuned variants of four frontier models across stress tests. Base models show sustained entropy growth, while tuned variants suppress drift and reduce ethical entropy by roughly eighty percent. From these trajectories we estimate an effective alignment work rate gamma_eff and embed S(t) and gamma_eff in a monitoring pipeline that raises alerts when entropy drift exceeds a stability threshold, enabling run-time oversight of value drift.", "AI": {"tldr": "This paper proposes a framework to assess and counter dynamic safety failures in large language models, introducing the concept of ethical entropy and methods to monitor and manage it.", "motivation": "The motivation is to address dynamic safety failures in large language models, such as value drift under distribution shifts, jailbreak attacks, and alignment degradation, which static benchmarks cannot capture.", "method": "The authors develop a behavioral taxonomy to classify ethical entropy, train a classifier to estimate it from model transcripts, and analyze entropy dynamics for various models. They also propose a monitoring pipeline to detect and respond to entropy drift.", "result": "Base language models exhibit continuous growth in ethical entropy, while instruction-tuned variants reduce this drift by about 80%. The study introduces an effective alignment work rate to monitor and manage entropy levels.", "conclusion": "The proposed approach provides a practical framework for operationalizing safety in large language models by measuring and managing ethical entropy dynamics, enabling more reliable oversight during deployment."}}
{"id": "2512.03083", "pdf": "https://arxiv.org/pdf/2512.03083", "abs": "https://arxiv.org/abs/2512.03083", "authors": ["ZeHao Yu"], "title": "Evaluate the Stack Management in Effect Handlers using the libseff C Library", "categories": ["cs.PL", "cs.SE"], "comment": null, "summary": "Effect handlers are increasingly prominent in modern programming for managing complex computational effects, including concurrency, asynchronous operations, and exception handling, in a modular and flexible manner. Efficient stack management remains a significant challenge for effect handlers due to the dynamic control flow changes they introduce. This paper explores a novel stack management approach using user-level overcommitting within the libseff C library, which leverages virtual memory mechanisms and protection-based lazy allocation combined with signal-driven memory commitment. Our user-level overcommitting implementation dynamically resizes stacks on-demand, improving memory utilization and reducing waste compared to traditional methods. We rigorously benchmark and evaluate this novel strategy against conventional fixed- size stacks, segmented stacks, and kernel-based overcommitting, using metrics such as context-switch latency, stack expansion efficiency, multi-threaded performance, and robustness under rapid stack growth conditions. Experimental results demonstrate that kernel-based overcommitting achieves an effective balance between performance and flexibility, whereas our user-level implementation, while flexible, incurs additional overheads, highlighting areas for optimization. This study provides a detailed comparative analysis of various stack management strate- gies, offering practical recommendations tailored to specific application requirements and operational constraints. Future work will focus on refining user-level overcommit- ting mechanisms, mitigating non-deterministic behaviors, and expanding benchmark frameworks to include real-world scenarios.", "AI": {"tldr": "This paper introduces a user-level stack management technique using overcommitting within the libseff C library to address stack management challenges in effect handlers, comparing it against other methods and providing practical recommendations.", "motivation": "Efficiently managing stacks in effect handlers remains challenging due to dynamic control flow changes. The paper aims to improve memory utilization and flexibility in stack handling.", "method": "The study employs user-level overcommitting in the libseff C library, using virtual memory, lazy allocation, and signal-driven mechanisms, and benchmarks it against fixed-size stacks, segmented stacks, and kernel-based overcommitting.", "result": "Experimental results reveal that kernel overcommitting offers better performance and flexibility, whereas user-level overcommitting is more flexible but introduces overheads.", "conclusion": "While the proposed user-level approach offers advantages, further optimizations are required to reduce overheads and address non-deterministic behaviors. Practical guidance is provided for choosing stack strategies based on application needs."}}
{"id": "2512.03262", "pdf": "https://arxiv.org/pdf/2512.03262", "abs": "https://arxiv.org/abs/2512.03262", "authors": ["Songwen Zhao", "Danqing Wang", "Kexun Zhang", "Jiaxuan Luo", "Zhuo Li", "Lei Li"], "title": "Is Vibe Coding Safe? Benchmarking Vulnerability of Agent-Generated Code in Real-World Tasks", "categories": ["cs.SE", "cs.CL"], "comment": null, "summary": "Vibe coding is a new programming paradigm in which human engineers instruct large language model (LLM) agents to complete complex coding tasks with little supervision. Although it is increasingly adopted, are vibe coding outputs really safe to deploy in production? To answer this question, we propose SU S VI B E S, a benchmark consisting of 200 feature-request software engineering tasks from real-world open-source projects, which, when given to human programmers, led to vulnerable implementations. We evaluate multiple widely used coding agents with frontier models on this benchmark. Disturbingly, all agents perform poorly in terms of software security. Although 61% of the solutions from SWE-Agent with Claude 4 Sonnet are functionally correct, only 10.5% are secure. Further experiments demonstrate that preliminary security strategies, such as augmenting the feature request with vulnerability hints, cannot mitigate these security issues. Our findings raise serious concerns about the widespread adoption of vibe-coding, particularly in security-sensitive applications.", "AI": {"tldr": "The paper evaluates the security risks of 'vibe coding,' where LLMs perform coding tasks with minimal supervision, using a newly introduced benchmark (SU S VIBES). It finds that most outputs, despite functional correctness, are insecure and highlights the risks of deploying such models in security-critical settings.", "motivation": "The study aims to understand whether outputs generated by 'vibe coding,' a paradigm where LLMs undertake programming tasks with minimal supervision, are safe for deployment, given their increasing usage.", "method": "The researchers created the SU S VIBES benchmark, comprising 200 real-world software engineering tasks that previously led to vulnerabilities. They tested popular coding agents, like Claude 4 Sonnet, on their ability to produce secure and functional solutions.", "result": "Despite 61% of solutions being functionally correct, only 10.5% of them were secure. Preliminary methods to improve security, such as adding vulnerability hints, failed to mitigate the problem.", "conclusion": "The findings suggest that 'vibe coding' with current LLMs is unsuitable for security-sensitive applications due to the high risk of insecure implementations. Caution is needed in adopting such models."}}
{"id": "2512.03057", "pdf": "https://arxiv.org/pdf/2512.03057", "abs": "https://arxiv.org/abs/2512.03057", "authors": ["Hao Zeng"], "title": "A note on the impossibility of conditional PAC-efficient reasoning in large language models", "categories": ["stat.ML", "cs.AI", "cs.LG", "math.ST"], "comment": null, "summary": "We prove an impossibility result for conditional Probably Approximately Correct (PAC)-efficient reasoning in large language models. While recent work has established marginal PAC efficiency guarantees for composite models that switch between expensive expert models and cheaper fast models, we show that conditional (pointwise) guarantees are impossible in the distribution-free setting. Specifically, for non-atomic input spaces, any algorithm achieving conditional PAC efficiency must be trivial in the sense that it defers to the expert model with probability at least $1-\u03b1$ for almost every input.", "AI": {"tldr": "This paper proves that conditional PAC-efficient reasoning in large language models is impossible in a distribution-free setting.", "motivation": "To address whether large language models can achieve conditional PAC efficiency when reasoning in complex inputs without triviality.", "method": "The authors employ a mathematical framework and impossibility proof to analyze PAC efficiency in non-atomic input spaces.", "result": "Conditional PAC-efficient reasoning is shown to be infeasible as any algorithm must rely heavily on expensive expert models.", "conclusion": "Conditional PAC efficiency leads to trivial algorithms deferring to expert models, signaling limitations in composite model reasoning under certain conditions."}}
{"id": "2512.03409", "pdf": "https://arxiv.org/pdf/2512.03409", "abs": "https://arxiv.org/abs/2512.03409", "authors": ["Kejian Wu", "Dante R. Chialvo", "Changsong Zhou", "Lianchun Yu"], "title": "Optimal Griffiths Phase in Heterogeneous Human Brain Networks: Brain Criticality Embracing Stability and Flexibility across Individuals", "categories": ["q-bio.NC"], "comment": null, "summary": "A prominent hypothesis in neuroscience proposes that brains achieve optimal performance by operating near a critical point. However, this framework, which often assumes a universal critical point, fails to account for the extensive individual variability observed in neural dynamics and cognitive functions. These variabilities are not noise but rather an inherent manifestation of a fundamental systems-biology principle: the necessary trade-off between robustness and flexibility in human populations. Here, we propose that the Griffiths phase (GP), an extended critical regime synergically induced by two kinds of heterogeneities in brain network region and connectivity, offers a unified framework for brain criticality that better reconciles robustness and flexibility and accounts for individual variability. Using Human Connectome Project data and whole-brain modeling, we demonstrated that the synergic interplay between structural network modularity and regional heterogeneity in local excitability yields biologically viable GP featured with widely extended global excitability ranges, with an embedded optimal point that balances global/local information transmission. Crucially, an individua's position within the GP gives rise to unique global network dynamics, which in turn confer a distinctive cognitive profile via flexible configuration of functional connectivity for segregation, integration, and balance between them. These results establish GP as an evolved adaptive mechanism resolving the robustness-flexibility trade-off, fulfilling diverse cognitive demands through individualized criticality landscapes, providing a new framework of brain criticality.", "AI": {"tldr": "The paper introduces the Griffiths phase (GP) as a framework for brain criticality that accounts for individual variability and balances robustness and flexibility in neural dynamics.", "motivation": "The study aims to address the limitations of the universal critical point hypothesis in neuroscience, which does not adequately account for the inherent variability in neural dynamics and cognitive functions among individuals.", "method": "The researchers used Human Connectome Project data and whole-brain modeling to investigate the impact of structural network modularity and regional heterogeneity on brain dynamics, focusing on their interactions within the Griffiths phase.", "result": "They found that the synergistic interaction between structural modularity and regional heterogeneity induces a biologically viable Griffiths phase, balancing global/local information transmission and creating unique individual cognitive profiles.", "conclusion": "The Griffiths phase provides a novel and adaptive mechanism addressing the robustness-flexibility trade-off in brain dynamics, offering a comprehensive framework for understanding individualized neural criticality and cognitive functions."}}
{"id": "2512.03126", "pdf": "https://arxiv.org/pdf/2512.03126", "abs": "https://arxiv.org/abs/2512.03126", "authors": ["Shan Zhang", "Aotian Chen", "Kai Zou", "Jindong Gu", "Yuan Xue", "Anton van den Hengel"], "title": "Hierarchical Process Reward Models are Symbolic Vision Learners", "categories": ["cs.CV"], "comment": null, "summary": "Symbolic computer vision represents diagrams through explicit logical rules and structured representations, enabling interpretable understanding in machine vision. This requires fundamentally different learning paradigms from pixel-based visual models. Symbolic visual learners parse diagrams into geometric primitives-points, lines, and shapes-whereas pixel-based learners operate on textures and colors. We propose a novel self-supervised symbolic auto-encoder that encodes diagrams into structured primitives and their interrelationships within the latent space, and decodes them through our executable engine to reconstruct the input diagrams. Central to this architecture is Symbolic Hierarchical Process Reward Modeling, which applies hierarchical step-level parsing rewards to enforce point-on-line, line-on-shape, and shape-on-relation consistency. Since vanilla reinforcement learning exhibits poor exploration in the policy space during diagram reconstruction; we thus introduce stabilization mechanisms to balance exploration and exploitation. We fine-tune our symbolic encoder on downstream tasks, developing a neuro-symbolic system that integrates the reasoning capabilities of neural networks with the interpretability of symbolic models through reasoning-grounded visual rewards. Evaluations across reconstruction, perception, and reasoning tasks demonstrate the effectiveness of our approach: achieving a 98.2% reduction in MSE for geometric diagram reconstruction, surpassing GPT-4o by 0.6% with a 7B model on chart reconstruction, and improving by +13% on the MathGlance perception benchmark, and by +3% on MathVerse and GeoQA reasoning benchmarks.", "AI": {"tldr": "The paper introduces a self-supervised symbolic auto-encoder to translate diagrams into structured geometric primitives with improved reconstruction and reasoning capabilities.", "motivation": "To enable interpretable diagram understanding in machine vision using symbolic, rule-based representations instead of traditional pixel-based models.", "method": "The authors developed a symbolic auto-encoder with hierarchical parsing rewards and stabilization mechanisms, integrating reasoning-grounded visual rewards for neuro-symbolic systems.", "result": "The method achieves significant improvements: 98.2% reduction in MSE for diagram reconstruction, a 0.6% gain over GPT-4o on chart tasks, +13% on MathGlance perception, and +3% on MathVerse and GeoQA reasoning tasks.", "conclusion": "The proposed approach effectively integrates interpretable symbolic representations with neural reasoning models, offering significant advancements in perception and reasoning across benchmarks."}}
{"id": "2512.03050", "pdf": "https://arxiv.org/pdf/2512.03050", "abs": "https://arxiv.org/abs/2512.03050", "authors": ["Peter Hedstr\u00f6m", "Victor Lamelas Cubero", "J\u00f3n Sigurdsson", "Viktor \u00d6sterberg", "Satish Kolli", "Joakim Odqvist", "Ziyong Hou", "Wangzhong Mu", "Viswanadh Gowtham Arigela"], "title": "Physics-Informed Machine Learning for Steel Development: A Computational Framework and CCT Diagram Modelling", "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "14 pages", "summary": "Machine learning (ML) has emerged as a powerful tool for accelerating the computational design and production of materials. In materials science, ML has primarily supported large-scale discovery of novel compounds using first-principles data and digital twin applications for optimizing manufacturing processes. However, applying general-purpose ML frameworks to complex industrial materials such as steel remains a challenge. A key obstacle is accurately capturing the intricate relationship between chemical composition, processing parameters, and the resulting microstructure and properties. To address this, we introduce a computational framework that combines physical insights with ML to develop a physics-informed continuous cooling transformation (CCT) model for steels. Our model, trained on a dataset of 4,100 diagrams, is validated against literature and experimental data. It demonstrates high computational efficiency, generating complete CCT diagrams with 100 cooling curves in under 5 seconds. It also shows strong generalizability across alloy steels, achieving phase classification F1 scores above 88% for all phases. For phase transition temperature regression, it attains mean absolute errors (MAE) below 20 \u00b0C across all phases except bainite, which shows a slightly higher MAE of 27 \u00b0C. This framework can be extended with additional generic and customized ML models to establish a universal digital twin platform for heat treatment. Integration with complementary simulation tools and targeted experiments will further support accelerated materials design workflows.", "AI": {"tldr": "This paper introduces a physics-informed computational framework combining machine learning (ML) for predicting steel properties effectively, achieving rapid precision in complex materials design.", "motivation": "Traditional machine learning approaches have struggled to accurately model the intricate relationships in complex industrial materials like steel, especially between composition, processing, microstructure, and resulting properties.", "method": "The introduced computational framework integrates physical insights with ML to develop a continuous cooling transformation (CCT) model, trained on a dataset of 4,100 diagrams and validated with literature and experimental data.", "result": "The model generates complete CCT diagrams with 100 cooling curves within 5 seconds. It demonstrates F1 scores above 88% for phase classification and achieves mean absolute error below 20 \u00b0C for phase transition temperature regression, with bainite showing slightly higher errors.", "conclusion": "This framework establishes a foundation for a digital twin platform for steel heat treatment, promising accelerated materials design workflows through integration with simulations and experiments."}}
{"id": "2512.03166", "pdf": "https://arxiv.org/pdf/2512.03166", "abs": "https://arxiv.org/abs/2512.03166", "authors": ["Aya Taourirte", "Md Sohag Mia"], "title": "Multi-Agent Reinforcement Learning and Real-Time Decision-Making in Robotic Soccer for Virtual Environments", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "The deployment of multi-agent systems in dynamic, adversarial environments like robotic soccer necessitates real-time decision-making, sophisticated cooperation, and scalable algorithms to avoid the curse of dimensionality. While Reinforcement Learning (RL) offers a promising framework, existing methods often struggle with the multi-granularity of tasks (long-term strategy vs. instant actions) and the complexity of large-scale agent interactions. This paper presents a unified Multi-Agent Reinforcement Learning (MARL) framework that addresses these challenges. First, we establish a baseline using Proximal Policy Optimization (PPO) within a client-server architecture for real-time action scheduling, with PPO demonstrating superior performance (4.32 avg. goals, 82.9% ball control). Second, we introduce a Hierarchical RL (HRL) structure based on the options framework to decompose the problem into a high-level trajectory planning layer (modeled as a Semi-Markov Decision Process) and a low-level action execution layer, improving global strategy (avg. goals increased to 5.26). Finally, to ensure scalability, we integrate mean-field theory into the HRL framework, simplifying many-agent interactions into a single agent vs. the population average. Our mean-field actor-critic method achieves a significant performance boost (5.93 avg. goals, 89.1% ball control, 92.3% passing accuracy) and enhanced training stability. Extensive simulations of 4v4 matches in the Webots environment validate our approach, demonstrating its potential for robust, scalable, and cooperative behavior in complex multi-agent domains.", "AI": {"tldr": "This paper introduces a unified MARL framework using PPO, hierarchical RL, and mean-field theory to optimize large-scale multi-agent systems for robotic soccer.", "motivation": "The paper aims to address real-time decision-making, cooperation, and scalability in dynamic multi-agent systems, particularly in robotic soccer.", "method": "The paper uses PPO for baseline action scheduling, hierarchical RL for task decomposition, and mean-field theory for reducing complexity in many-agent interactions.", "result": "The proposed framework demonstrates improved performance metrics such as avg. goals (5.93), ball control (89.1%), and passing accuracy (92.3%).", "conclusion": "The findings confirm the effectiveness and scalability of the presented MARL framework for dynamic, cooperative multi-agent environments."}}
{"id": "2512.03895", "pdf": "https://arxiv.org/pdf/2512.03895", "abs": "https://arxiv.org/abs/2512.03895", "authors": ["Luu Trong Nhan", "Luu Trung Duong", "Pham Ngoc Nam", "Truong Cong Thang"], "title": "Parameter efficient hybrid spiking-quantum convolutional neural network with surrogate gradient and quantum data-reupload", "categories": ["cs.NE"], "comment": "Work under review", "summary": "The rapid advancement of artificial intelligence (AI) and deep learning (DL) has catalyzed the emergence of several optimization-driven subfields, notably neuromorphic computing and quantum machine learning. Leveraging the differentiable nature of hybrid models, researchers have explored their potential to address complex problems through unified optimization strategies. One such development is the Spiking Quantum Neural Network (SQNN), which combines principles from spiking neural networks (SNNs) and quantum computing. However, existing SQNN implementations often depend on pretrained SNNs due to the non-differentiable nature of spiking activity and the limited scalability of current SNN encoders. In this work, we propose a novel architecture, Spiking-Quantum Data Re-upload Convolutional Neural Network (SQDR-CNN), that enables joint training of convolutional SNNs and quantum circuits within a single backpropagation framework. Unlike its predecessor, SQDR-CNN allow convergence to reasonable performance without the reliance of pretrained spiking encoder and subsetting datasets. We also clarified some theoretical foundations, testing new design using quantum data-reupload with different training algorithm-initialization and evaluate the performance of the proposed model under noisy simulated quantum environments. As a result, we were able to achieve 86% of the mean top-performing accuracy of the SOTA SNN baselines, yet uses only 0.5% of the smallest spiking model's parameters. Through this integration of neuromorphic and quantum paradigms, we aim to open new research directions and foster technological progress in multi-modal, learnable systems.", "AI": {"tldr": "This paper introduces the SQDR-CNN, a novel model blending spiking neural networks (SNNs) with quantum computing, eliminating the need for a pretrained encoder and achieving efficiency in parameter usage.", "motivation": "To address the challenge of joint training for SNNs and quantum circuits, overcoming issues such as non-differentiable spiking activity and scalability limits in SNN encoders.", "method": "The paper proposes the Spiking-Quantum Data Re-upload Convolutional Neural Network (SQDR-CNN), a framework for simultaneous training of SNNs and quantum circuits via backpropagation, employing quantum data-reupload strategies under simulated quantum environments.", "result": "The SQDR-CNN achieves 86% of the mean top accuracy of state-of-the-art SNN models while using only 0.5% of the smallest spiking model's parameters.", "conclusion": "The integration of neuromorphic and quantum paradigms in SQDR-CNN introduces an efficient and unified approach, opening avenues for progress in multi-modal and learnable systems."}}
{"id": "2512.03487", "pdf": "https://arxiv.org/pdf/2512.03487", "abs": "https://arxiv.org/abs/2512.03487", "authors": ["Zhen Wang", "Bin Lin", "Qiang", "Ye"], "title": "Double-Edge-Assisted Computation Offloading and Resource Allocation for Space-Air-Marine Integrated Networks", "categories": ["cs.DC", "cs.IT"], "comment": null, "summary": "In this paper, we propose a double-edge-assisted computation offloading and resource allocation scheme tailored for space-air-marine integrated networks (SAMINs). Specifically, we consider a scenario where both unmanned aerial vehicles (UAVs) and a low earth orbit (LEO) satellite are equipped with edge servers, providing computing services for maritime autonomous surface ships (MASSs). Partial computation workloads of MASSs can be offloaded to both UAVs and the LEO satellite, concurrently, for processing via a multi-access approach. To minimize the energy consumption of SAMINs under latency constraints, we formulate an optimization problem and propose energy efficient algorithms to jointly optimize offloading mode, offloading volume, and computing resource allocation of the LEO satellite and the UAVs, respectively. We further exploit an alternating optimization (AO) method and a layered approach to decompose the original problem to attain the optimal solutions. Finally, we conduct simulations to validate the effectiveness and efficiency of the proposed scheme in comparison with benchmark algorithms.", "AI": {"tldr": "This paper introduces a new scheme for energy-efficient computation offloading and resource allocation in space-air-marine integrated networks (SAMINs), utilizing UAVs and LEO satellites as edge servers.", "motivation": "To address the challenges of high energy consumption and computational inefficiency in maritime autonomous surface ships (MASSs) under complex network constraints in SAMINs.", "method": "They propose a double-edge-assisted scheme leveraging UAVs and LEO satellite as edge servers and use a multi-access offloading approach. Optimization algorithms and alternating optimization methods are utilized for resource allocation and offloading decisions.", "result": "Simulations demonstrate that the proposed scheme outperforms existing benchmark algorithms in terms of energy efficiency and effectiveness under latency constraints.", "conclusion": "The method significantly improves energy efficiency while maintaining latency requirements in SAMINs, offering a viable solution for advanced maritime computational needs."}}
{"id": "2512.03608", "pdf": "https://arxiv.org/pdf/2512.03608", "abs": "https://arxiv.org/abs/2512.03608", "authors": ["Lishuo Deng", "Shaojie Xu", "Jinwu Chen", "Changwei Yan", "Jiajie Wang", "Zhe Jiang", "Weiwei Shan"], "title": "KVNAND: Efficient On-Device Large Language Model Inference Using DRAM-Free In-Flash Computing", "categories": ["cs.AR", "cs.AI", "cs.ET"], "comment": null, "summary": "Deploying large language models (LLMs) on edge devices enables personalized agents with strong privacy and low cost. However, with tens to hundreds of billions of parameters, single-batch autoregressive inference suffers from extremely low arithmetic intensity, creating severe weight-loading and bandwidth pressures on resource-constrained platforms. Recent in-flash computing (IFC) solutions alleviate this bottleneck by co-locating weight-related linear computations in the decode phase with flash, yet still rely on DRAM for the key-value (KV) cache. As context length grows, the KV cache can exceed model weights in size, imposing prohibitive DRAM cost and capacity requirements. Attempts to offload KV cache to flash suffer from severe performance penalties.\n  We propose KVNAND, the first DRAM-free, IFC-based architecture that stores both model weights and KV cache entirely in compute-enabled 3D NAND flash. KVNAND addresses the fundamental performance challenges of flash under intensive KV cache access by leveraging IFC for all memory-bound operations to reduce data transfer overhead, introducing head-group parallelism to boost throughput, and employing page-level KV cache mapping to align token access patterns with flash organization. In addition, we propose a design space exploration framework that evaluates discrete and compact KVNAND variants to balance weight and KV placement, automatically identifying the optimal design trade-off. These techniques mitigate latency, energy, and reliability concerns, turning flash into a practical medium for long-context KV storage. Evaluations on MHA 7B and GQA 70B LLMs show that KVNAND achieves 1.98\\(\\times\\)/1.94\\(\\times\\)/2.05\\(\\times\\) geomean speedup at 128/1K/10K-token contexts compared to DRAM-equipped IFC designs and addresses out-of-memory failures at 100K context length.", "AI": {"tldr": "This paper introduces KVNAND, a novel DRAM-free architecture leveraging in-flash computing to store both weights and key-value (KV) cache of large language models entirely in 3D NAND flash, addressing bandwidth and capacity challenges for long-context LLMs.", "motivation": "The motivation is enabling efficient deployment of large language models on edge devices by addressing the bottlenecks of DRAM dependency, high bandwidth pressure, and resource constraints, especially for long-context computations.", "method": "KVNAND replaces DRAM entirely by integrating compute-enabled 3D NAND flash for not only weight storage but also KV cache. It uses IFC for memory operations, introduces head-group parallelism for performance, and aligns token access patterns through page-level cache mapping. Additionally, a design space exploration framework identifies optimal configurations.", "result": "KVNAND demonstrates 1.98\u00d7 to 2.05\u00d7 speedups across various token contexts (128, 1K, 10K) compared to DRAM-equipped in-flash designs and successfully mitigates out-of-memory issues at 100K contexts.", "conclusion": "KVNAND provides a practical and efficient alternative for deploying LLMs on resource-constrained devices, addressing latency, energy, and capacity challenges through innovations in flash-based memory architecture."}}
{"id": "2512.03072", "pdf": "https://arxiv.org/pdf/2512.03072", "abs": "https://arxiv.org/abs/2512.03072", "authors": ["Hu Keyi"], "title": "Beyond the Black Box: A Cognitive Architecture for Explainable and Aligned AI", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "Current AI paradigms, as \"architects of experience,\" face fundamental challenges in explainability and value alignment. This paper introduces \"Weight-Calculatism,\" a novel cognitive architecture grounded in first principles, and demonstrates its potential as a viable pathway toward Artificial General Intelligence (AGI). The architecture deconstructs cognition into indivisible Logical Atoms and two fundamental operations: Pointing and Comparison. Decision-making is formalized through an interpretable Weight-Calculation model (Weight = Benefit * Probability), where all values are traceable to an auditable set of Initial Weights. This atomic decomposition enables radical explainability, intrinsic generality for novel situations, and traceable value alignment. We detail its implementation via a graph-algorithm-based computational engine and a global workspace workflow, supported by a preliminary code implementation and scenario validation. Results indicate that the architecture achieves transparent, human-like reasoning and robust learning in unprecedented scenarios, establishing a practical and theoretical foundation for building trustworthy and aligned AGI.", "AI": {"tldr": "The paper proposes a new cognitive architecture, 'Weight-Calculatism,' emphasizing radical explainability, value alignment, and adaptability, paving the way toward trustworthy AGI.", "motivation": "Current AI systems face issues in explainability and aligning values with human norms, posing risks for their deployment in critical areas.", "method": "A novel architecture, 'Weight-Calculatism,' is based on Logical Atoms and fundamental operations of Pointing and Comparison. It incorporates a Weight-Calculation model tied to auditable Initial Weights and is demonstrated through graph algorithms and a global workspace.", "result": "Preliminary implementation showed human-like transparent reasoning and robust adaptability in unprecedented scenarios, validating the architecture's feasibility.", "conclusion": "The proposed architecture provides a promising theoretical and practical pathway for developing a trustworthy and value-aligned AGI system."}}
{"id": "2512.03079", "pdf": "https://arxiv.org/pdf/2512.03079", "abs": "https://arxiv.org/abs/2512.03079", "authors": ["Anudeex Shetty"], "title": "Watermarks for Embeddings-as-a-Service Large Language Models", "categories": ["cs.CL", "cs.CR", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated exceptional capabilities in natural language understanding and generation. Based on these LLMs, businesses have started to provide Embeddings-as-a-Service (EaaS), offering feature extraction capabilities (in the form of text embeddings) that benefit downstream natural language processing tasks. However, prior research has demonstrated that EaaS is vulnerable to imitation attacks, where an attacker clones the service's model in a black-box manner without access to the model's internal workings. In response, watermarks have been added to the text embeddings to protect the intellectual property of EaaS providers by allowing them to check for model ownership. This thesis focuses on defending against imitation attacks by investigating EaaS watermarks. To achieve this goal, we unveil novel attacks and propose and validate new watermarking techniques.\n  Firstly, we show that existing EaaS watermarks can be removed through paraphrasing the input text when attackers clone the model during imitation attacks. Our study illustrates that paraphrasing can effectively bypass current state-of-the-art EaaS watermarks across various attack setups (including different paraphrasing techniques and models) and datasets in most instances. This demonstrates a new vulnerability in recent EaaS watermarking techniques.\n  Subsequently, as a countermeasure, we propose a novel watermarking technique, WET (Watermarking EaaS with Linear Transformation), which employs linear transformation of the embeddings. Watermark verification is conducted by applying a reverse transformation and comparing the similarity between recovered and original embeddings. We demonstrate its robustness against paraphrasing attacks with near-perfect verifiability. We conduct detailed ablation studies to assess the significance of each component and hyperparameter in WET.", "AI": {"tldr": "This paper addresses the vulnerability of EaaS watermarking techniques to imitation attacks using paraphrasing, and proposes a new robust watermarking method called WET.", "motivation": "The paper is motivated by the intellectual property concerns in Embeddings-as-a-Service (EaaS) systems, particularly their vulnerability to black-box imitation attacks.", "method": "A novel watermarking technique called WET is proposed, which uses linear transformation of text embeddings, verified through reverse transformation to ensure model ownership.", "result": "Current watermarks can be bypassed through paraphrasing, while WET demonstrates robustness against such attacks with high verifiability.", "conclusion": "WET successfully mitigates the vulnerabilities of EaaS watermarking techniques to imitation attacks, providing enhanced protection against these threats."}}
{"id": "2512.03086", "pdf": "https://arxiv.org/pdf/2512.03086", "abs": "https://arxiv.org/abs/2512.03086", "authors": ["Le Chen", "Nuo Xu", "Winson Chen", "Bin Lei", "Pei-Hung Lin", "Dunzhi Zhou", "Rajeev Thakur", "Caiwen Ding", "Ali Jannesari", "Chunhua Liao"], "title": "Beyond Code Pairs: Dialogue-Based Data Generation for LLM Code Translation", "categories": ["cs.PL", "cs.AI", "cs.SE"], "comment": null, "summary": "Large language models (LLMs) have shown remarkable capabilities in code translation, yet their performance deteriorates in low-resource programming domains such as Fortran and emerging frameworks like CUDA, where high-quality parallel data are scarce. We present an automated dataset generation pipeline featuring a dual-LLM Questioner-Solver design that incorporates external knowledge from compilers and runtime feedback. Beyond traditional source-target code pair datasets, our approach additionally generates (1) verified translations with unit tests for assessing functional consistency, and (2) multi-turn dialogues that capture the reasoning process behind translation refinement. Applied to Fortran -> C++ and C++ -> CUDA, the pipeline yields 3.64k and 3.93k dialogues, respectively. Fine-tuning on this data yields dramatic improvements in functional correctness, boosting unit test success rates by over 56% on the challenging C++-to-CUDA task. We show this data enables a 7B open-weight model to significantly outperform larger proprietary systems on key metrics like compilation success.", "AI": {"tldr": "This paper introduces a novel dataset generation pipeline using dual-LLM for code translation to improve performance in low-resource domains like Fortran and CUDA.", "motivation": "Existing large language models struggle with code translation in low-resource programming domains due to limited high-quality parallel data.", "method": "A dual-LLM Questioner-Solver pipeline is developed, incorporating external knowledge from compilers and runtime feedback, and generating both verified translations with unit tests and multi-turn dialogues.", "result": "The pipeline generated thousands of dialogues (e.g., 3.64k for Fortran -> C++), improving functional correctness significantly, boosting unit test success rates by 56% for the challenging C++-to-CUDA task, and outperformed larger proprietary systems.", "conclusion": "This approach demonstrates that fine-tuning on high-quality, automatically generated data can dramatically enhance code translation performance, even for low-resource domains."}}
{"id": "2512.03421", "pdf": "https://arxiv.org/pdf/2512.03421", "abs": "https://arxiv.org/abs/2512.03421", "authors": ["Hexiang Xu", "Hengyuan Liu", "Yonghao Wu", "Xiaolan Kang", "Xiang Chen", "Yong Liu"], "title": "Exploring the Potential and Limitations of Large Language Models for Novice Program Fault Localization", "categories": ["cs.SE"], "comment": "The paper has been accepted for publication in The Journal of Systems & Software", "summary": "Novice programmers often face challenges in fault localization due to their limited experience and understanding of programming syntax and logic. Traditional methods like Spectrum-Based Fault Localization (SBFL) and Mutation-Based Fault Localization (MBFL) help identify faults but often lack the ability to understand code context, making them less effective for beginners. In recent years, Large Language Models (LLMs) have shown promise in overcoming these limitations by utilizing their ability to understand program syntax and semantics. LLM-based fault localization provides more accurate and context-aware results than traditional techniques. This study evaluates six closed-source and seven open-source LLMs using the Codeflaws, Condefects, and BugT datasets, with BugT being a newly constructed dataset specifically designed to mitigate data leakage concerns. Advanced models with reasoning capabilities, such as OpenAI o3 and DeepSeekR1, achieve superior accuracy with minimal reliance on prompt engineering. In contrast, models without reasoning capabilities, like GPT-4, require carefully designed prompts to maintain performance. While LLMs perform well in simple fault localization, their accuracy decreases as problem difficulty increases, though top models maintain robust performance in the BugT dataset. Over-reasoning is another challenge, where some models generate excessive explanations that hinder fault localization clarity. Additionally, the computational cost of deploying LLMs remains a significant barrier for real-time debugging. LLM's explanations demonstrate significant value for novice programmer assistance, with one-year experience participants consistently rating them highly. Our findings demonstrate the potential of LLMs to improve debugging efficiency while stressing the need for further refinement in their reasoning and computational efficiency for practical adoption.", "AI": {"tldr": "This paper investigates the effectiveness of Large Language Models (LLMs) for fault localization in programming, highlighting their strengths and weaknesses.", "motivation": "Fault localization can be challenging for novice programmers due to limited experience and understanding. Traditional methods lack code context comprehension, necessitating better solutions.", "method": "The study evaluates six closed-source and seven open-source LLMs on datasets like Codeflaws, Condefects, and BugT, analyzing accuracy, reasoning capabilities, prompt reliance, and computational cost.", "result": "Advanced LLMs like OpenAI o3 and DeepSeekR1 show high accuracy with minimal prompt engineering, outperforming others like GPT-4. Models perform well in simple cases, but struggle with complex problems.", "conclusion": "LLMs hold promise for improving debugging for novices, but require refinement in reasoning and computational efficiency for broader and practical real-time adoption."}}
{"id": "2512.03208", "pdf": "https://arxiv.org/pdf/2512.03208", "abs": "https://arxiv.org/abs/2512.03208", "authors": ["Pangpang Liu", "Junwei Lu", "Will Wei Sun"], "title": "Uncertainty Quantification for Large Language Model Reward Learning under Heterogeneous Human Feedback", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We study estimation and statistical inference for reward models used in aligning large language models (LLMs). A key component of LLM alignment is reinforcement learning from human feedback (RLHF), where humans compare pairs of model-generated answers and their preferences are used to train a reward model. However, human feedback is inherently heterogeneous, creating significant challenges for reliable reward learning. To address this, we adopt a heterogeneous preference framework that jointly models the latent reward of answers and human rationality. This leads to a challenging biconvex optimization problem, which we solve via an alternating gradient descent algorithm. We establish theoretical guarantees for the resulting estimator, including its convergence and asymptotic distribution. These results enable the construction of confidence intervals for reward estimates. Leveraging these uncertainty quantification results, we conduct valid statistical comparisons between rewards and incorporate uncertainty into the best-of-$N$ (BoN) policy framework. Extensive simulations demonstrate the effectiveness of our method, and applications to real LLM data highlight the practical value of accounting for uncertainty in reward modeling for LLM alignment.", "AI": {"tldr": "This paper develops a method to improve reward modeling in aligning large language models by addressing human feedback heterogeneity and providing statistical uncertainty measures.", "motivation": "The motivation behind this research is to address challenges in reward modeling for LLM alignment caused by the inherent heterogeneity in human feedback during reinforcement learning from human feedback (RLHF).", "method": "The method employs a heterogeneous preference framework that models both answer rewards and human rationality, leading to a biconvex optimization problem solved via alternating gradient descent. Theoretical guarantees are established to support convergence and distribution, enabling uncertainty quantification.", "result": "The results include theoretical guarantees for the confidence intervals of reward estimates, validity in statistical comparisons, and incorporation of uncertainty into the best-of-N policy framework. Simulations and real LLM data showcase the method's effectiveness.", "conclusion": "Accounting for the uncertainty in reward modeling improves statistical reliability and practical value in aligning LLMs, as demonstrated by simulations and real-world applications."}}
{"id": "2512.03907", "pdf": "https://arxiv.org/pdf/2512.03907", "abs": "https://arxiv.org/abs/2512.03907", "authors": ["Rosa Maria Delicado", "Gemma Huguet", "Pau Clusella"], "title": "Emergent Spatiotemporal Dynamics in Large-Scale Brain Networks with Next Generation Neural Mass Models", "categories": ["q-bio.NC"], "comment": null, "summary": "Understanding the dynamics of large-scale brain models remains a central challenge due to the inherent complexity of these systems. In this work, we explore the emergence of complex spatiotemporal patterns in a large scale-brain model composed of 90 interconnected brain regions coupled through empirically derived anatomical connectivity. An important aspect of our formulation is that the local dynamics of each brain region are described by a next-generation neural mass model, which explicitly captures the macroscopic gamma activity of coupled excitatory and inhibitory neural populations (PING mechanism). We first identify the system's homogeneous states-both resting and oscillatory-and analyze their stability under uniform perturbations. Then, we determine the stability against non-uniform perturbations by obtaining dispersion relations for the perturbation growth rate. This analysis enables us to link unstable directions of the homogeneous solutions to the emergence of rich spatiotemporal patterns, that we characterize by means of Lyapunov exponents and frequency spectrum analysis. Our results show that, compared to previous studies with classical neural mass models, next-generation neural mass models provide a broader dynamical repertoire, both within homogeneous states and in the heterogeneous regime. Additionally, we identify a key role for anatomical connectivity in cross-frequency coupling, allowing for the emergence of gamma oscillations with amplitude modulated by slower rhythms. These findings suggest that such models are not only more biophysically grounded but also particularly well-suited to capture the full complexity of large-scale brain dynamics. Overall, our study advances the analytical understanding of emerging spatiotemporal patterns in whole-brain models.", "AI": {"tldr": "This paper explores the emergence of complex spatiotemporal patterns in large-scale brain models using advanced neural mass modeling, offering insights into biophysically realistic dynamics and cross-frequency coupling.", "motivation": "There is a need to better understand the dynamics of complex large-scale brain systems, which are challenging due to their inherent complexity and interconnected architecture.", "method": "The study employs next-generation neural mass models to describe local brain region dynamics, analyzing homogeneous states and their stability using dispersion relations, Lyapunov exponents, and frequency spectrum analysis.", "result": "Compared to classical models, next-generation neural mass models showed broader dynamical repertoires, highlighted the role of anatomical connectivity in cross-frequency coupling, and captured gamma oscillations modulated by slower rhythms.", "conclusion": "Next-generation neural mass models are more effective for analyzing large-scale brain dynamics and spatiotemporal patterns, providing insights into anatomically grounded cross-frequency interactions and rich dynamic behaviors."}}
{"id": "2512.03182", "pdf": "https://arxiv.org/pdf/2512.03182", "abs": "https://arxiv.org/abs/2512.03182", "authors": ["Yasser Taha", "Gr\u00e9goire Montavon", "Nils K\u00f6rber"], "title": "Drainage: A Unifying Framework for Addressing Class Uncertainty", "categories": ["cs.CV", "cs.LG"], "comment": "16 pages, 8 figures", "summary": "Modern deep learning faces significant challenges with noisy labels, class ambiguity, as well as the need to robustly reject out-of-distribution or corrupted samples. In this work, we propose a unified framework based on the concept of a \"drainage node'' which we add at the output of the network. The node serves to reallocate probability mass toward uncertainty, while preserving desirable properties such as end-to-end training and differentiability. This mechanism provides a natural escape route for highly ambiguous, anomalous, or noisy samples, particularly relevant for instance-dependent and asymmetric label noise. In systematic experiments involving the addition of varying proportions of instance-dependent noise or asymmetric noise to CIFAR-10/100 labels, our drainage formulation achieves an accuracy increase of up to 9\\% over existing approaches in the high-noise regime. Our results on real-world datasets, such as mini-WebVision, mini-ImageNet and Clothing-1M, match or surpass existing state-of-the-art methods. Qualitative analysis reveals a denoising effect, where the drainage neuron consistently absorbs corrupt, mislabeled, or outlier data, leading to more stable decision boundaries. Furthermore, our drainage formulation enables applications well beyond classification, with immediate benefits for web-scale, semi-supervised dataset cleaning, and open-set applications.", "AI": {"tldr": "This paper introduces a 'drainage node' mechanism for deep learning models to handle noisy labels, ambiguous classes, and out-of-distribution samples, demonstrating significant performance improvements in the high-noise regime.", "motivation": "To address challenges in modern deep learning, such as noisy labels, class ambiguity, and outlier rejection, which can negatively impact model accuracy and reliability.", "method": "A 'drainage node' is added at the network's output, redistributing probability mass toward uncertainty to handle ambiguous or noisy samples effectively, while maintaining end-to-end training and differentiability.", "result": "The 'drainage node' achieves up to a 9% accuracy increase in high-noise conditions on CIFAR-10/100. Real-world datasets like mini-WebVision and Clothing-1M show results matching or surpassing state-of-the-art methods.", "conclusion": "The 'drainage node' improves decision boundaries and denoises data, offering benefits for diverse applications like semi-supervised learning, dataset cleaning, and open-set problems."}}
{"id": "2512.03053", "pdf": "https://arxiv.org/pdf/2512.03053", "abs": "https://arxiv.org/abs/2512.03053", "authors": ["Andrew S. Cassidy", "Guillaume Garreau", "Jay Sivagnaname", "Mike Grassi", "Bernard Brezzo", "John V. Arthur", "Dharmendra S. Modha"], "title": "Mitigating hallucinations and omissions in LLMs for invertible problems: An application to hardware logic design automation", "categories": ["cs.LG", "cs.AI", "cs.AR", "cs.PL"], "comment": "7 pages, 2 figures, 7 tables", "summary": "We show for invertible problems that transform data from a source domain (for example, Logic Condition Tables (LCTs)) to a destination domain (for example, Hardware Description Language (HDL) code), an approach of using Large Language Models (LLMs) as a lossless encoder from source to destination followed by as a lossless decoder back to the source, comparable to lossless compression in information theory, can mitigate most of the LLM drawbacks of hallucinations and omissions. Specifically, using LCTs as inputs, we generate the full HDL for a two-dimensional network-on-chip router (13 units, 1500-2000 lines of code) using seven different LLMs, reconstruct the LCTs from the auto-generated HDL, and compare the original and reconstructed LCTs. This approach yields significant productivity improvements, not only confirming correctly generated LLM logic and detecting incorrectly generated LLM logic but also assisting developers in finding design specification errors.", "AI": {"tldr": "This paper proposes using Large Language Models (LLMs) as lossless encoders and decoders to transform data between domains, minimizing hallucinations and omissions. The approach is tested by transforming logic tables to hardware description language (HDL) for network-on-chip routers.", "motivation": "Current LLMs face challenges with hallucinations and omissions during complex transformations. A reliable methodology is needed to validate the accuracy of outputs they generate while also improving productivity in hardware design.", "method": "The researchers use LLMs as both lossless encoders and decoders. They demonstrate this by transforming logic tables into HDL code for a network-on-chip router, then reconstructing the original data from the generated HDL for accuracy comparison.", "result": "The approach significantly improved productivity, accurately detected logic correctness, identified errors in LLM-generated logic, and helped developers detect design specification errors.", "conclusion": "Using LLMs as lossless encoders/decoders can mitigate hallucination and omission problems, offering practical benefits in validating outputs and improving hardware design processes."}}
{"id": "2512.03194", "pdf": "https://arxiv.org/pdf/2512.03194", "abs": "https://arxiv.org/abs/2512.03194", "authors": ["Johannes Gaber", "Meshal Alharbi", "Daniele Gammelli", "Gioele Zardini"], "title": "GRAND: Guidance, Rebalancing, and Assignment for Networked Dispatch in Multi-Agent Path Finding", "categories": ["cs.RO", "cs.LG", "cs.MA"], "comment": null, "summary": "Large robot fleets are now common in warehouses and other logistics settings, where small control gains translate into large operational impacts. In this article, we address task scheduling for lifelong Multi-Agent Pickup-and-Delivery (MAPD) and propose a hybrid method that couples learning-based global guidance with lightweight optimization. A graph neural network policy trained via reinforcement learning outputs a desired distribution of free agents over an aggregated warehouse graph. This signal is converted into region-to-region rebalancing through a minimum-cost flow, and finalized by small, local assignment problems, preserving accuracy while keeping per-step latency within a 1 s compute budget. On congested warehouse benchmarks from the League of Robot Runners (LRR) with up to 500 agents, our approach improves throughput by up to 10% over the 2024 winning scheduler while maintaining real-time execution. The results indicate that coupling graph-structured learned guidance with tractable solvers reduces congestion and yields a practical, scalable blueprint for high-throughput scheduling in large fleets.", "AI": {"tldr": "The study presents a hybrid task scheduling method for large robot fleets in logistics, integrating learning-based graph analysis with optimization techniques to improve throughput and reduce congestion.", "motivation": "Large robot fleets are crucial for logistics settings where small scheduling improvements can yield significant operational benefits.", "method": "The method combines graph neural network policy trained via reinforcement learning for global guidance, minimum-cost flow for region rebalancing, and lightweight local assignment for precise scheduling.", "result": "The hybrid approach improves throughput by up to 10% on congested warehouse benchmarks with up to 500 agents, maintaining a real-time computation budget.", "conclusion": "Integrating learned graph-structured guidance with optimization solvers provides an effective, scalable solution for task scheduling in large robot fleets."}}
{"id": "2512.03394", "pdf": "https://arxiv.org/pdf/2512.03394", "abs": "https://arxiv.org/abs/2512.03394", "authors": ["Hamed Poursiami", "Shay Snyder", "Guojing Cong", "Thomas Potok", "Maryam Parsa"], "title": "VS-Graph: Scalable and Efficient Graph Classification Using Hyperdimensional Computing", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "Graph classification is a fundamental task in domains ranging from molecular property prediction to materials design. While graph neural networks (GNNs) achieve strong performance by learning expressive representations via message passing, they incur high computational costs, limiting their scalability and deployment on resource-constrained devices. Hyperdimensional Computing (HDC), also known as Vector Symbolic Architectures (VSA), offers a lightweight, brain-inspired alternative, yet existing HDC-based graph methods typically struggle to match the predictive performance of GNNs. In this work, we propose VS-Graph, a vector-symbolic graph learning framework that narrows the gap between the efficiency of HDC and the expressive power of message passing. VS-Graph introduces a Spike Diffusion mechanism for topology-driven node identification and an Associative Message Passing scheme for multi-hop neighborhood aggregation entirely within the high-dimensional vector space. Without gradient-based optimization or backpropagation, our method achieves competitive accuracy with modern GNNs, outperforming the prior HDC baseline by 4-5% on standard benchmarks such as MUTAG and DD. It also matches or exceeds the performance of the GNN baselines on several datasets while accelerating the training by a factor of up to 450x. Furthermore, VS-Graph maintains high accuracy even with the hypervector dimensionality reduced to D=128, demonstrating robustness under aggressive dimension compression and paving the way for ultra-efficient execution on edge and neuromorphic hardware.", "AI": {"tldr": "This paper introduces VS-Graph, a lightweight graph learning framework leveraging high-dimensional vector spaces to achieve competitive accuracy with GNNs without backpropagation, significantly accelerating training.", "motivation": "To address the trade-off between the high computational cost of GNNs and the limited predictive performance of existing HDC-based methods for graph classification.", "method": "The method introduces VS-Graph with a Spike Diffusion mechanism for node identification and Associative Message Passing for neighborhood aggregation, all conducted in high-dimensional vector space, without relying on gradient-based training.", "result": "VS-Graph achieves competitive accuracy with GNNs, surpassing existing HDC baselines by 4-5%, while accelerating training up to 450x and maintaining robust performance even under dimensional compression.", "conclusion": "VS-Graph effectively combines the efficiency of HDC and the representation power of message passing, enabling practical applications on resource-constrained hardware."}}
{"id": "2512.03616", "pdf": "https://arxiv.org/pdf/2512.03616", "abs": "https://arxiv.org/abs/2512.03616", "authors": ["Christian Ewert", "Amrit Sharma Poudel", "Mouadh Ayache", "Andrija Neskovic", "Rainer Buchty", "Mladen Berekovic", "Sebastian Berndt", "Saleh Mulhem"], "title": "Lightweight Unified Sha-3/Shake Architecture with a Fault-Resilient State", "categories": ["cs.AR"], "comment": "-", "summary": "Hash functions have become a key part of standard Post-quantum cryptography (PQC) schemes, especially Sha-3 and Shake, calling arXiv:submit/7045552 [cs.AR] 3 Dec 2025 for lightweight implementation. A fault-resilient design is always desirable to make the whole PQC system reliable. We, therefore, propose a) a unified hash engine supporting Sha-3 and Shake that follows a byte-wise in-place partitioning mechanism of the so-called Keccak state, and b) an according fault detection for Keccak state protection exploiting its cube structure by deploying two-dimensional parity checks. It outperforms the state-of-the-art (SoA) regarding area requirements at competitive register-level fault detection by achieving 100% detection of three and still near 100% of higher numbers of Keccak state faults. Unlike SoA solutions, the proposed unified hash engine covers all standard hash configurations. Moreover, the introduced multidimensional cross-parity check mechanism achieves a 3.7x improvement in area overhead, with an overall 4.5x smaller fault-resilient engine design as demonstrated in ASIC and FPGA implementations. Integrated into a RISC-V environment, the unified hash engine with the integrated fault-resilient mechanism introduced less than 8% area overhead. Our approach thus provides a robust and lightweight fault-detection solution for protecting hash functions deployed in resource-constrained PQC applications.", "AI": {"tldr": "The paper proposes an efficient and fault-resilient unified hash engine supporting Sha-3 and Shake for Post-quantum cryptography (PQC), enhancing reliability and minimizing area requirements.", "motivation": "The motivation lies in addressing the need for reliable, fault-resilient hash functions for PQC, ensuring robust and lightweight implementations in resource-constrained environments.", "method": "They introduce a unified hash engine using a byte-wise in-place partitioning mechanism for Keccak state and exploit two-dimensional parity checks for fault detection.", "result": "The solution achieves full detection of three Keccak state faults and nearly 100% detection for higher fault numbers, offering significant improvements in area overhead and fault protection compared to existing approaches.", "conclusion": "The approach offers an efficient, lightweight, and fault-resilient design for hash functions integrated into PQC systems, making it suitable for constrained applications like RISC-V environments."}}
{"id": "2512.03272", "pdf": "https://arxiv.org/pdf/2512.03272", "abs": "https://arxiv.org/abs/2512.03272", "authors": ["Zhiyuan He", "Dingmin Wang"], "title": "When Do Symbolic Solvers Enhance Reasoning in Large Language Models?", "categories": ["cs.AI"], "comment": null, "summary": "Large Reasoning Models (LRMs) achieve strong performance on complex reasoning tasks by generating long Chains of Thought (CoTs). However, this paradigm might incur substantial token overhead, especially when models \"overthink\" by producing lengthy reasoning chains, which can even lead to incorrect answers. A promising direction is the symbolic-solver-integrated approach, which leverages the code generation capabilities of LLMs to translate reasoning tasks into executable code and then solve them with a symbolic solver. In this paper, we explore an open question of when the conventional long-CoT can be enhanced by symbolic solvers. Our experimental results show that the symbolic-solver-integrated method only helps when the problem requires limited implicit reasoning but involves an ample search space. The latest LLMs, like GPT-4o, show better performance on deductive problems with shallow reasoning depth, while the symbolic-solver-integrated method significantly improves the LLMs' performance in constraint satisfaction problems that require repeated backtracks. When a declarative exemplar is provided, even CodeLlama-13B can outperform GPT-4o in difficult Zebra puzzles.", "AI": {"tldr": "Large Reasoning Models can benefit from integrating symbolic solvers for tasks involving a large search space but limited implicit reasoning, improving performance on constraint satisfaction problems.", "motivation": "To address the issue of inefficiency and inaccuracies caused by overlong reasoning chains generated by Large Reasoning Models during complex problems.", "method": "Combining the reasoning ability of LLMs with symbolic solvers by using LLMs for code generation and executing that code to solve problems.", "result": "Symbolic-solver integration is effective for problems requiring extensive search (e.g., Zebra puzzles), but LLMs perform better independently on tasks needing shallow reasoning depth.", "conclusion": "Incorporating symbolic solvers enhances LLMs' performance in solving constraint satisfaction and backtracking problems while reducing inefficiencies in reasoning."}}
{"id": "2512.03082", "pdf": "https://arxiv.org/pdf/2512.03082", "abs": "https://arxiv.org/abs/2512.03082", "authors": ["Nan Zhuang", "Wenshuo Wang", "Lekai Qian", "Yuxiao Wang", "Boyu Cao", "Qi Liu"], "title": "Alleviating Choice Supportive Bias in LLM with Reasoning Dependency Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent studies have demonstrated that some Large Language Models exhibit choice-supportive bias (CSB) when performing evaluations, systematically favoring their chosen options and potentially compromising the objectivity of AI-assisted decision making. While existing debiasing approaches primarily target demographic and social biases, methods for addressing cognitive biases in LLMs remain largely unexplored. In this work, we present the first solution to address CSB through Reasoning Dependency Generation (RDG), a novel framework for generating unbiased reasoning data to mitigate choice-supportive bias through fine-tuning. RDG automatically constructs balanced reasoning QA pairs, explicitly (un)modeling the dependencies between choices, evidences, and justifications. Our approach is able to generate a large-scale dataset of QA pairs across domains, incorporating Contextual Dependency Data and Dependency Decouple Data. Experiments show that LLMs fine-tuned on RDG-generated data demonstrate a 81.5% improvement in memory-based experiments and 94.3% improvement in the evaluation-based experiment, while maintaining similar performance on standard BBQ benchmarks. This work pioneers an approach for addressing cognitive biases in LLMs and contributes to the development of more reliable AI-assisted decision support systems.", "AI": {"tldr": "This paper introduces a method called Reasoning Dependency Generation (RDG) to address choice-supportive bias (CSB) in Large Language Models by generating unbiased reasoning data for fine-tuning, leading to more objective decision making.", "motivation": "The motivation is to address choice-supportive bias (CSB), a cognitive bias in large language models that biases their objectivity and decision-making performance, an issue largely unexplored in existing research.", "method": "The main method is Reasoning Dependency Generation (RDG), which generates balanced reasoning QA pairs by modeling and decoupling dependencies between choices, evidence, and justifications. The generated data is used to fine-tune LLMs.", "result": "LLMs fine-tuned with the RDG framework show an 81.5% improvement in memory-based experiments and a 94.3% improvement in evaluation-based experiments, while maintaining comparable performance on standard tests like BBQ benchmarks.", "conclusion": "This approach introduces a novel method to reduce cognitive biases in LLMs, making them more reliable and objective for decision support systems."}}
{"id": "2512.03972", "pdf": "https://arxiv.org/pdf/2512.03972", "abs": "https://arxiv.org/abs/2512.03972", "authors": ["Hassan Arafat", "David Bremner", "Kenneth B. Kent", "Julian Wang"], "title": "OOPredictor: Predicting Object-Oriented Accesses using Static Analysis", "categories": ["cs.PL"], "comment": null, "summary": "Object-oriented Programming has become one of the most dominant design paradigms as the separation of concerns and adaptability of design reduce development and maintenance costs. However, the convenience is not without cost. The added indirection inherent in such designs causes excessive pointer chasing, negatively affecting locality, which in turn degrades the performance of cache structures. Furthermore, modern hardware prefetchers are mostly stride prefetchers that are ill-equipped to handle the unpredictability of access patterns generated by pointer chasing. Most software approaches that seek to address this problem resort to profiling the program as it runs, which comes with a significant run-time overhead or requires data from previous runs. In this paper, we propose the use of compile-time static analysis to predict the most common access patterns displayed by a program during run time. Since Java is one of the most popular object-oriented languages, we implement our prototype within the OpenJ9 JVM, inside the OMR optimizer infrastructure. The outputs of our proposed predictor are Markov chains that model the expected behavior of the program. The effectiveness of the proposed predictor is evaluated by comparing the model with the actual run-time behavior of the program measured using an instrumented interpreter. Our experiments show that the proposed predictor exhibits good accuracy and can be used to inform minimally intrusive load stall mitigation strategies, e.g. informing copying GCs on more locality-friendly copying orders", "AI": {"tldr": "This paper introduces a compile-time static analysis method to predict runtime access patterns in object-oriented programming, implemented in OpenJ9 JVM. Results show accurate prediction that improves locality and cache performance.", "motivation": "Modern object-oriented programming often leads to degraded cache performance due to excessive pointer chasing and unpredictable access patterns. Existing profiling-based solutions come with runtime overheads.", "method": "The authors developed a static analysis predictor using Markov chains within the OpenJ9 JVM, leveraging the OMR optimizer infrastructure to predict access patterns at compile-time.", "result": "Experiments demonstrate that the predictor can model runtime behavior with significant accuracy and aid load stall mitigation strategies.", "conclusion": "The proposed static analysis approach addresses cache locality issues in object-oriented programming efficiently, offering an effective alternative to runtime profiling methods."}}
{"id": "2512.03815", "pdf": "https://arxiv.org/pdf/2512.03815", "abs": "https://arxiv.org/abs/2512.03815", "authors": ["Shayan Ghasemnezhad", "Samarth KaPatel", "Sofia Nikiforova", "Giacinto Paolo Saggese", "Paul Smith", "Heanh Sok"], "title": "Runnable Directories: The Solution to the Monorepo vs. Multi-repo Debate", "categories": ["cs.SE"], "comment": null, "summary": "Modern software systems increasingly strain traditional codebase organization strategies. Monorepos offer consistency but often suffer from scalability issues and tooling complexity, while multi-repos provide modularity at the cost of coordination and dependency management challenges. As an answer to this trade-off, we present the Causify Dev system, a hybrid approach that integrates key benefits of both. Its central concept is the runnable directory -- a self-contained, independently executable unit with its own development, testing, and deployment lifecycles. Backed by a unified thin environment, shared helper utilities, and containerized Docker-based workflows, runnable directories enable consistent setups, isolated dependencies, and efficient CI/CD processes. The Causify Dev approach provides a practical middle ground between monorepo and multi-repo strategies, improving reliability and maintainability for growing, complex codebases.", "AI": {"tldr": "The paper introduces Causify Dev, a hybrid system to bridge the trade-offs between monorepos and multi-repos, using runnable directories and containerized workflows.", "motivation": "To address the challenges of scalability, tooling complexity, dependency management, and coordination in modern software systems using existing codebase organization strategies.", "method": "The authors propose Causify Dev, which uses 'runnable directories' \u2014 self-contained units with independent lifecycles. It incorporates a unified thin environment, shared utilities, and Docker-based workflows for seamless integration.", "result": "The proposed system provides a balance of consistency and modularity, ensuring reliable setups, isolated dependencies, and efficient CI/CD processes for complex and growing codebases.", "conclusion": "Causify Dev offers a viable middle ground for managing large software systems, mitigating issues of both monorepo and multi-repo strategies, and delivering improved maintainability and reliability."}}
{"id": "2512.03234", "pdf": "https://arxiv.org/pdf/2512.03234", "abs": "https://arxiv.org/abs/2512.03234", "authors": ["Jean Pachebat", "Giovanni Conforti", "Alain Durmus", "Yazid Janati"], "title": "Iterative Tilting for Diffusion Fine-Tuning", "categories": ["stat.ML", "cs.LG"], "comment": "14 pages", "summary": "We introduce iterative tilting, a gradient-free method for fine-tuning diffusion models toward reward-tilted distributions. The method decomposes a large reward tilt $\\exp(\u03bbr)$ into $N$ sequential smaller tilts, each admitting a tractable score update via first-order Taylor expansion. This requires only forward evaluations of the reward function and avoids backpropagating through sampling chains. We validate on a two-dimensional Gaussian mixture with linear reward, where the exact tilted distribution is available in closed form.", "AI": {"tldr": "The paper introduces iterative tilting, a gradient-free method for fine-tuning diffusion models toward reward-tilted distributions.", "motivation": "To develop an efficient method to fine-tune diffusion models for reward-tilted distributions without relying on backpropagation through sampling chains.", "method": "The authors propose iterative tilting, which decomposes large reward tilts into sequential smaller tilts, enabling score updates via first-order Taylor expansion and requiring only forward reward evaluations.", "result": "The method was validated on a 2D Gaussian mixture with a linear reward function, achieving accurate results where closed-form tilted distributions are available.", "conclusion": "Iterative tilting is an efficient and gradient-free approach for fine-tuning diffusion models underlying tilted distributions."}}
{"id": "2512.03293", "pdf": "https://arxiv.org/pdf/2512.03293", "abs": "https://arxiv.org/abs/2512.03293", "authors": ["Filippo Torresan", "Ryota Kanai", "Manuel Baltieri"], "title": "Prior preferences in active inference agents: soft, hard, and goal shaping", "categories": ["cs.AI", "q-bio.NC"], "comment": "41 pages, 23 figures", "summary": "Active inference proposes expected free energy as an objective for planning and decision-making to adequately balance exploitative and explorative drives in learning agents. The exploitative drive, or what an agent wants to achieve, is formalised as the Kullback-Leibler divergence between a variational probability distribution, updated at each inference step, and a preference probability distribution that indicates what states or observations are more likely for the agent, hence determining the agent's goal in a certain environment. In the literature, the questions of how the preference distribution should be specified and of how a certain specification impacts inference and learning in an active inference agent have been given hardly any attention. In this work, we consider four possible ways of defining the preference distribution, either providing the agents with hard or soft goals and either involving or not goal shaping (i.e., intermediate goals). We compare the performances of four agents, each given one of the possible preference distributions, in a grid world navigation task. Our results show that goal shaping enables the best performance overall (i.e., it promotes exploitation) while sacrificing learning about the environment's transition dynamics (i.e., it hampers exploration).", "AI": {"tldr": "This paper investigates the impact of different preference distributions on active inference agents during a grid world navigation task, focusing on the balance between exploitation and exploration.", "motivation": "The paper aims to address the lack of attention in the literature regarding how preference distributions influence inference, learning, and decision-making in active inference agents.", "method": "The authors study four distinct ways of defining preference distributions (hard goals, soft goals, with or without goal shaping) and evaluate their impacts in a grid world navigation task.", "result": "The findings suggest that goal shaping improves exploitative performance, enabling agents to achieve goals more effectively, but hampers exploratory behavior, limiting learning about the transition dynamics of the environment.", "conclusion": "Goal shaping is beneficial for exploitation but impedes exploration, highlighting a trade-off in designing preference distributions for learning agents in active inference."}}
{"id": "2512.03199", "pdf": "https://arxiv.org/pdf/2512.03199", "abs": "https://arxiv.org/abs/2512.03199", "authors": ["Justin Norman", "Hany Farid"], "title": "Does Head Pose Correction Improve Biometric Facial Recognition?", "categories": ["cs.CV"], "comment": null, "summary": "Biometric facial recognition models often demonstrate significant decreases in accuracy when processing real-world images, often characterized by poor quality, non-frontal subject poses, and subject occlusions. We investigate whether targeted, AI-driven, head-pose correction and image restoration can improve recognition accuracy. Using a model-agnostic, large-scale, forensic-evaluation pipeline, we assess the impact of three restoration approaches: 3D reconstruction (NextFace), 2D frontalization (CFR-GAN), and feature enhancement (CodeFormer). We find that naive application of these techniques substantially degrades facial recognition accuracy. However, we also find that selective application of CFR-GAN combined with CodeFormer yields meaningful improvements.", "AI": {"tldr": "Biometric facial recognition struggles with real-world image challenges. Research shows selective AI-driven restoration strategies can improve accuracy, but naive use degrades performance.", "motivation": "To address challenges in the accuracy of facial recognition with poor-quality, non-frontal, and occluded images by exploring AI-driven restoration methods.", "method": "A forensic evaluation pipeline examines the impact of three AI-driven restoration methods\u2014NextFace, CFR-GAN, and CodeFormer\u2014on recognition performance.", "result": "Naive use of restoration methods degrades accuracy, but a selective combination of CFR-GAN and CodeFormer improves facial recognition results.", "conclusion": "Selective, targeted application of specific AI restoration techniques provides improvements in biometric facial recognition compared to uninformed application."}}
{"id": "2512.03054", "pdf": "https://arxiv.org/pdf/2512.03054", "abs": "https://arxiv.org/abs/2512.03054", "authors": ["Ciro Benito Raggio", "Lucia Migliorelli", "Nils Skupien", "Mathias Krohmer Zabaleta", "Oliver Blanck", "Francesco Cicone", "Giuseppe Lucio Cascini", "Paolo Zaffino", "Maria Francesca Spadea"], "title": "Energy-Efficient Federated Learning via Adaptive Encoder Freezing for MRI-to-CT Conversion: A Green AI-Guided Research", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DC", "physics.med-ph"], "comment": "22 pages, 13 figures", "summary": "Federated Learning (FL) holds the potential to advance equality in health by enabling diverse institutions to collaboratively train deep learning (DL) models, even with limited data. However, the significant resource requirements of FL often exclude centres with limited computational infrastructure, further widening existing healthcare disparities. To address this issue, we propose a Green AI-oriented adaptive layer-freezing strategy designed to reduce energy consumption and computational load while maintaining model performance. We tested our approach using different federated architectures for Magnetic Resonance Imaging (MRI)-to-Computed Tomography (CT) conversion. The proposed adaptive strategy optimises the federated training by selectively freezing the encoder weights based on the monitored relative difference of the encoder weights from round to round. A patience-based mechanism ensures that freezing only occurs when updates remain consistently minimal. The energy consumption and CO2eq emissions of the federation were tracked using the CodeCarbon library. Compared to equivalent non-frozen counterparts, our approach reduced training time, total energy consumption and CO2eq emissions by up to 23%. At the same time, the MRI-to-CT conversion performance was maintained, with only small variations in the Mean Absolute Error (MAE). Notably, for three out of the five evaluated architectures, no statistically significant differences were observed, while two architectures exhibited statistically significant improvements. Our work aligns with a research paradigm that promotes DL-based frameworks meeting clinical requirements while ensuring climatic, social, and economic sustainability. It lays the groundwork for novel FL evaluation frameworks, advancing privacy, equity and, more broadly, justice in AI-driven healthcare.", "AI": {"tldr": "The paper introduces an energy-efficient federated learning method with a layer-freezing strategy to reduce resource requirements in collaborative training, maintaining model performance while being sustainable in healthcare applications.", "motivation": "The motivation is to address disparities in healthcare due to high resource requirements of Federated Learning by developing a method to make FL accessible to institutions with limited computational infrastructure.", "method": "The paper proposes an adaptive layer-freezing strategy that selectively freezes encoder weights based on the monitored relative difference in weights. A patience-based mechanism ensures freezing occurs only with consistent minimal updates. The approach is tested with MRI-to-CT conversion using various federated architectures.", "result": "The proposed strategy reduced training time, energy consumption, and CO2 emissions by up to 23%, while maintaining or improving MRI-to-CT conversion performance. Only small variations in MAE were observed, with improved performance in some architectures.", "conclusion": "The work presents a sustainable and equitable approach to Federated Learning in healthcare, advancing privacy and equity while promoting environmentally and socially-aware AI practices."}}
{"id": "2512.03256", "pdf": "https://arxiv.org/pdf/2512.03256", "abs": "https://arxiv.org/abs/2512.03256", "authors": ["Albert H. Li", "Ivan Dario Jimenez Rodriguez", "Joel W. Burdick", "Yisong Yue", "Aaron D. Ames"], "title": "KALIKO: Kalman-Implicit Koopman Operator Learning For Prediction of Nonlinear Dynamical Systems", "categories": ["cs.RO"], "comment": null, "summary": "Long-horizon dynamical prediction is fundamental in robotics and control, underpinning canonical methods like model predictive control. Yet, many systems and disturbance phenomena are difficult to model due to effects like nonlinearity, chaos, and high-dimensionality. Koopman theory addresses this by modeling the linear evolution of embeddings of the state under an infinite-dimensional linear operator that can be approximated with a suitable finite basis of embedding functions, effectively trading model nonlinearity for representational complexity. However, explicitly computing a good choice of basis is nontrivial, and poor choices may cause inaccurate forecasts or overfitting. To address this, we present Kalman-Implicit Koopman Operator (KALIKO) Learning, a method that leverages the Kalman filter to implicitly learn embeddings corresponding to latent dynamics without requiring an explicit encoder. KALIKO produces interpretable representations consistent with both theory and prior works, yielding high-quality reconstructions and inducing a globally linear latent dynamics. Evaluated on wave data generated by a high-dimensional PDE, KALIKO surpasses several baselines in open-loop prediction and in a demanding closed-loop simulated control task: stabilizing an underactuated manipulator's payload by predicting and compensating for strong wave disturbances.", "AI": {"tldr": "The paper introduces KALIKO, a method using Kalman filter for implicit learning of state embeddings to predict non-linear dynamic systems, surpassing existing methods in wave disturbance simulations.", "motivation": "Modeling nonlinear, chaotic, high-dimensional systems for long-term prediction is challenging due to difficulty in choosing embedding functions for accurate forecasts.", "method": "The authors propose Kalman-Implicit Koopman Operator (KALIKO) Learning, which indirectly learns embeddings via a Kalman filter to produce globally linear latent dynamics without explicit encoders.", "result": "KALIKO demonstrated high-quality predictions and reconstructed latent dynamics, outperforming baselines in open-loop and closed-loop control tasks for stabilizing disturbances in simulations.", "conclusion": "KALIKO successfully offers interpretable, robust latent dynamics modeling leveraging Kalman filters, improving predictions and control in complex systems."}}
{"id": "2512.03644", "pdf": "https://arxiv.org/pdf/2512.03644", "abs": "https://arxiv.org/abs/2512.03644", "authors": ["Bohan Zhao", "Yuanhong Wang", "Chenglin Liu", "Jiagi Pan", "Guang Yang", "Ruitao Liu", "Tingrui Zhang", "Kai Luo", "Wei Xu"], "title": "FFTrainer: Fast Failover in Large-Language Model Training with Almost-Free State Management", "categories": ["cs.DC"], "comment": null, "summary": "Recent developments in large language models (LLMs) have introduced new requirements for efficient and robust training. As LLM clusters scale, node failures, lengthy recoveries, and bulky checkpoints erode efficiency. Infrequent asynchronous checkpoints trigger costly rollbacks, yet higher frequencies add prohibitive overhead. To address these challenges, we propose FFTrainer, a system designed for robust LLM training. FFTrainer leverages surplus network capacity to quickly save and load states, thereby preventing rollbacks and accelerating recovery. Compared with prior checkpointing approaches, FFTrainer reduces recovery time by up to 98% and mitigates GPU utilization loss by up to 68% without hindering normal training.", "AI": {"tldr": "FFTrainer significantly improves LLM training efficiency and robustness by addressing issues of node failures, recovery times, and costly rollbacks. It optimizes checkpointing methods for better GPU utilization.", "motivation": "The motivation is to overcome inefficiencies in large language model (LLM) training caused by node failures, long recoveries, and costly or bulky checkpointing, which affect training performance and utilization.", "method": "The paper introduces FFTrainer, a system that utilizes surplus network capacity for rapid state saving and loading. This reduces the need for costly rollbacks and accelerates recovery times during LLM training.", "result": "FFTrainer reduces recovery time by up to 98% and decreases GPU utilization loss by up to 68%, achieving significant improvements in robustness and efficiency without impacting normal training.", "conclusion": "FFTrainer is a robust solution for LLM training challenges, demonstrating substantial performance improvements in recovery time and GPU efficiency compared to previous approaches."}}
{"id": "2512.03781", "pdf": "https://arxiv.org/pdf/2512.03781", "abs": "https://arxiv.org/abs/2512.03781", "authors": ["Joscha Ilmberger", "Johannes Schemmel"], "title": "The BrainScaleS-2 multi-chip system: Interconnecting continuous-time neuromorphic compute substrates", "categories": ["cs.AR"], "comment": null, "summary": "The BrainScaleS-2 SoC integrates analog neuron and synapse circuits with digital periphery, including two CPUs with SIMD extensions. Each ASIC is connected to a Node-FPGA, providing experiment control and Ethernet connectivity. This work details the scaling of the compute substrate through FPGA-based interconnection via an additional Aggregator unit. The Aggregator provides up to 12 transceiver links to a backplane of Node-FPGAs, as well as 4 transceiver lanes for further extension. Two such interconnected backplanes are integrated into a standard 19in rack case with 4U height together with an Ethernet switch, system controller and power supplies. For all spike rates, chip-to-chip latencies -- consisting of four hops across three FPGAs -- below 1.3$\u03bc$s are achieved within each backplane.", "AI": {"tldr": "The paper discusses the BrainScaleS-2 system-on-chip (SoC), emphasizing its integration of analog and digital components and high-speed interconnections for efficient computation and communication.", "motivation": "The motivation is to create scalable and efficient computation systems by leveraging FPGA-based interconnections for neuroscience-inspired hardware implementations.", "method": "The method involves integrating analog neuron and synapse circuits with CPUs and establishing FPGA-based interconnections via an Aggregator system for efficient communication.", "result": "The proposed system achieves reliable connectivity and extremely low latencies (below 1.3\u03bcs) across chip-to-chip hops within multi-FPGA setups.", "conclusion": "The work demonstrates the feasibility of such interconnected systems with high performance, scalability, and effective communication for neuroscience-style computations."}}
{"id": "2512.03195", "pdf": "https://arxiv.org/pdf/2512.03195", "abs": "https://arxiv.org/abs/2512.03195", "authors": ["Stylianos Saroglou", "Konstantinos Diamantaras", "Francesco Preta", "Marina Delianidi", "Apostolos Benisis", "Christian Johannes Meyer"], "title": "Enhancing Job Matching: Occupation, Skill and Qualification Linking with the ESCO and EQF taxonomies", "categories": ["cs.CL", "cs.LG"], "comment": "14 pages, 1 figure, Preprint", "summary": "This study investigates the potential of language models to improve the classification of labor market information by linking job vacancy texts to two major European frameworks: the European Skills, Competences, Qualifications and Occupations (ESCO) taxonomy and the European Qualifications Framework (EQF). We examine and compare two prominent methodologies from the literature: Sentence Linking and Entity Linking. In support of ongoing research, we release an open-source tool, incorporating these two methodologies, designed to facilitate further work on labor classification and employment discourse. To move beyond surface-level skill extraction, we introduce two annotated datasets specifically aimed at evaluating how occupations and qualifications are represented within job vacancy texts. Additionally, we examine different ways to utilize generative large language models for this task. Our findings contribute to advancing the state of the art in job entity extraction and offer computational infrastructure for examining work, skills, and labor market narratives in a digitally mediated economy. Our code is made publicly available: https://github.com/tabiya-tech/tabiya-livelihoods-classifier", "AI": {"tldr": "This paper examines the usage of language models to link job vacancy texts to European labor classification frameworks (ESCO, EQF), proposes methodologies, and releases annotated datasets and open-source tools for further research.", "motivation": "The motivation is to enhance methodologies for classifying labor market information, facilitating nuanced analysis of jobs, skills, and qualifications in a digital economy.", "method": "The study employs Sentence Linking and Entity Linking methodologies and leverages generative large language models for evaluating occupations and qualifications within job vacancy texts.", "result": "The research provides evidence for improved job entity extraction techniques, introduces two annotated datasets, and develops an open-source classifier tool for labor market analysis.", "conclusion": "The findings advance labor entity extraction technology, contribute to research on employment discourse, and offer tools to study labor market narratives in a digitally connected economy."}}
{"id": "2512.03868", "pdf": "https://arxiv.org/pdf/2512.03868", "abs": "https://arxiv.org/abs/2512.03868", "authors": ["Shree Hari Bittugondanahalli Indra Kumar", "Lilia Rodrigues Sampaio", "Andr\u00e9 Martin", "Andrey Brito", "Christof Fetzer"], "title": "A Comprehensive Study on the Impact of Vulnerable Dependencies on Open-Source Software", "categories": ["cs.SE", "cs.CR"], "comment": null, "summary": "Open-source libraries are widely used by software developers to speed up the development of products, however, they can introduce security vulnerabilities, leading to incidents like Log4Shell. With the expanding usage of open-source libraries, it becomes even more imperative to comprehend and address these dependency vulnerabilities. The use of Software Composition Analysis (SCA) tools does greatly help here as they provide a deep insight on what dependencies are used in a project, enhancing the security and integrity in the software supply chain. In order to learn how wide spread vulnerabilities are and how quickly they are being fixed, we conducted a study on over 1k open-source software projects with about 50k releases comprising several languages such as Java, Python, Rust, Go, Ruby, PHP, and JavaScript. Our objective is to investigate the severity, persistence, and distribution of these vulnerabilities, as well as their correlation with project metrics such as team and contributors size, activity and release cycles. In order to perform such analysis, we crawled over 1k projects from github including their version history ranging from 2013 to 2023 using VODA, our SCA tool. Using our approach, we can provide information such as library versions, dependency depth, and known vulnerabilities, and how they evolved over the software development cycle. Being larger and more diverse than datasets used in earlier works and studies, ours provides better insights and generalizability of the gained results. The data collected answers several research questions about the dependency depth and the average time a vulnerability persists. Among other findings, we observed that for most programming languages, vulnerable dependencies are transitive, and a critical vulnerability persists in average for over a year before being fixed.", "AI": {"tldr": "This paper analyzes over 1,000 open-source software projects to understand the prevalence, persistence, and fixing speed of vulnerabilities in dependencies. Key findings include the transitive nature of vulnerable dependencies and the long persistence of critical vulnerabilities.", "motivation": "The authors aim to address the security risks introduced by open-source libraries, especially with the increasing reliance on these libraries. They are motivated by incidents like Log4Shell and want to improve understanding of dependency vulnerabilities and how they can be managed effectively.", "method": "The study utilizes a custom Software Composition Analysis (SCA) tool named VODA to crawl and analyze version histories of over 1,000 projects from GitHub, covering languages like Java, Python, Rust, and more. Researchers investigate vulnerability severity, persistence, and correlations with project metrics.", "result": "Findings show that most vulnerabilities in dependencies are transitive and critical vulnerabilities persist on average for over a year before being addressed. The dataset, being larger and more diverse, provides better generalizability than previous works.", "conclusion": "The study highlights the need for more proactive dependency management and emphasizes the importance of tools like SCA to reduce the time vulnerabilities persist in open-source projects."}}
{"id": "2512.03243", "pdf": "https://arxiv.org/pdf/2512.03243", "abs": "https://arxiv.org/abs/2512.03243", "authors": ["Ioannis Gasteratos", "Antoine Jacquier", "Maud Lemercier", "Terry Lyons", "Cristopher Salvi"], "title": "Novelty detection on path space", "categories": ["stat.ML", "cs.LG", "math.PR", "math.ST"], "comment": null, "summary": "We frame novelty detection on path space as a hypothesis testing problem with signature-based test statistics. Using transportation-cost inequalities of Gasteratos and Jacquier (2023), we obtain tail bounds for false positive rates that extend beyond Gaussian measures to laws of RDE solutions with smooth bounded vector fields, yielding estimates of quantiles and p-values. Exploiting the shuffle product, we derive exact formulae for smooth surrogates of conditional value-at-risk (CVaR) in terms of expected signatures, leading to new one-class SVM algorithms optimising smooth CVaR objectives. We then establish lower bounds on type-$\\mathrm{II}$ error for alternatives with finite first moment, giving general power bounds when the reference measure and the alternative are absolutely continuous with respect to each other. Finally, we evaluate numerically the type-$\\mathrm{I}$ error and statistical power of signature-based test statistic, using synthetic anomalous diffusion data and real-world molecular biology data.", "AI": {"tldr": "This paper introduces a novel approach for novelty detection using signature-based test statistics, deriving results on false positive rates, quantile estimates, type-II error bounds, and proposing new algorithms for smooth CVaR-to-SVM optimization.", "motivation": "To improve novelty detection through more reliable statistics based on signature analysis, obtaining robust false positive rates, quantile evaluations, and statistical power diagnostics.", "method": "The approach reframes novelty detection as hypothesis testing using signature-based statistics, leveraging shuffle products, and introducing transportation-cost inequalities to assess error bounds and CVaR optimization.", "result": "Key results include tail bounds for false positives, exact expressions for smooth CVaR measures, and lower bounds on type II errors, along with numerical validations using synthetic and real-world data.", "conclusion": "This work provides a robust framework for novelty detection with theoretical and empirical validations, paving the way for enhanced detection algorithms optimized for statistical reliability."}}
{"id": "2512.03784", "pdf": "https://arxiv.org/pdf/2512.03784", "abs": "https://arxiv.org/abs/2512.03784", "authors": ["Guisong Liu", "Jiansong Zhang", "Yinpei Luo", "Guoliang Wei", "Shuqing Sun", "Shiyang Deng", "Pengfei Wei", "Nanxi Chen"], "title": "Sleep Modulation: The Challenge of Transitioning from Open Loop to Closed Loop", "categories": ["cs.HC", "q-bio.NC"], "comment": null, "summary": "Sleep disorders have emerged as a critical global health issue, highlighting the urgent need for effective and widely accessible intervention technologies. Non-invasive brain stimulation has garnered attention as it enables direct or indirect modulation of neural activity, thereby promoting sleep enhancement in a safe and unobtrusive manner. This class of approaches is collectively referred to as sleep modulation. To date, the majority of sleep modulation research relies on open-loop paradigms with empirically determined parameters, while achieving individual adaptation and modulation accuracy remains a distant objective. The paradigm-specific constraints inherent to open-loop designs represent a major obstacle to clinical translation and large-scale deployment in home environments. In this paper, we delineate fundamental paradigms of sleep modulation, critically examine the intrinsic limitations of open-loop approaches, and formally conceptualize sleep closed-loop modulation. We further provide a comprehensive synthesis of prior studies involving five commonly employed modulation techniques, evaluating their potential integration within a closed-loop framework. Finally, we identify three primary challenges in constructing an effective sleep closed-loop modulation system: sensor solution selection, monitoring model design, and modulation strategy design, while also proposing potential solutions. Collectively, this work aims to advance the paradigm shift of sleep modulation from open-loop toward closed-loop systems.", "AI": {"tldr": "The paper focuses on advancing sleep enhancement through non-invasive brain stimulation by moving from open-loop to closed-loop modulation systems.", "motivation": "Sleep disorders pose a global health challenge, necessitating safe and effective intervention technologies like sleep modulation.", "method": "The paper critically examines open-loop approaches and conceptualizes closed-loop sleep modulation while analyzing five modulation techniques and addressing associated challenges.", "result": "Key challenges for closed-loop systems are identified, including sensor selection, monitoring model design, and modulation strategy design, along with proposed solutions.", "conclusion": "Transitioning from open-loop to closed-loop systems could optimize sleep modulation for clinical and home use."}}
{"id": "2512.03210", "pdf": "https://arxiv.org/pdf/2512.03210", "abs": "https://arxiv.org/abs/2512.03210", "authors": ["Jingkang Wang", "Henry Che", "Yun Chen", "Ze Yang", "Lily Goli", "Sivabalan Manivasagam", "Raquel Urtasun"], "title": "Flux4D: Flow-based Unsupervised 4D Reconstruction", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": "NeurIPS 2025. Project page: https://waabi.ai/flux4d/", "summary": "Reconstructing large-scale dynamic scenes from visual observations is a fundamental challenge in computer vision, with critical implications for robotics and autonomous systems. While recent differentiable rendering methods such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have achieved impressive photorealistic reconstruction, they suffer from scalability limitations and require annotations to decouple actor motion. Existing self-supervised methods attempt to eliminate explicit annotations by leveraging motion cues and geometric priors, yet they remain constrained by per-scene optimization and sensitivity to hyperparameter tuning. In this paper, we introduce Flux4D, a simple and scalable framework for 4D reconstruction of large-scale dynamic scenes. Flux4D directly predicts 3D Gaussians and their motion dynamics to reconstruct sensor observations in a fully unsupervised manner. By adopting only photometric losses and enforcing an \"as static as possible\" regularization, Flux4D learns to decompose dynamic elements directly from raw data without requiring pre-trained supervised models or foundational priors simply by training across many scenes. Our approach enables efficient reconstruction of dynamic scenes within seconds, scales effectively to large datasets, and generalizes well to unseen environments, including rare and unknown objects. Experiments on outdoor driving datasets show Flux4D significantly outperforms existing methods in scalability, generalization, and reconstruction quality.", "AI": {"tldr": "Flux4D is a framework for reconstructing 4D dynamic scenes efficiently and unsupervisedly, overcoming scalability and data annotation challenges in existing methods.", "motivation": "The motivation lies in addressing the limitations of current methods, such as their scalability constraints, per-scene optimization issues, sensitivity to hyperparameters, and reliance on data annotations.", "method": "Flux4D predicts 3D Gaussians and motion dynamics using photometric losses and static scene regularization. It works unsupervisedly, extracting dynamic scene elements directly from raw data without requiring pre-trained models or priors.", "result": "Flux4D achieves efficient reconstruction within seconds, scales well to large datasets, generalizes effectively to new environments, and delivers significant improvements over prior methods on outdoor driving datasets.", "conclusion": "Flux4D provides a simple yet robust solution for reconstructing large-scale dynamic scenes, offering better scalability, generalization, and quality compared to existing approaches."}}
{"id": "2512.03055", "pdf": "https://arxiv.org/pdf/2512.03055", "abs": "https://arxiv.org/abs/2512.03055", "authors": ["Xiaowu Sun", "Thabo Mahendiran", "Ortal Senouf", "Denise Auberson", "Bernard De Bruyne", "Stephane Fournier", "Olivier Muller", "Pascal Frossard", "Emmanuel Abbe", "Dorina Thanou"], "title": "Physics-informed self-supervised learning for predictive modeling of coronary artery digital twins", "categories": ["cs.LG", "cs.AI"], "comment": "19 pages", "summary": "Cardiovascular disease is the leading global cause of mortality, with coronary artery disease (CAD) as its most prevalent form, necessitating early risk prediction. While 3D coronary artery digital twins reconstructed from imaging offer detailed anatomy for personalized assessment, their analysis relies on computationally intensive computational fluid dynamics (CFD), limiting scalability. Data-driven approaches are hindered by scarce labeled data and lack of physiological priors. To address this, we present PINS-CAD, a physics-informed self-supervised learning framework. It pre-trains graph neural networks on 200,000 synthetic coronary digital twins to predict pressure and flow, guided by 1D Navier-Stokes equations and pressure-drop laws, eliminating the need for CFD or labeled data. When fine-tuned on clinical data from 635 patients in the multicenter FAME2 study, PINS-CAD predicts future cardiovascular events with an AUC of 0.73, outperforming clinical risk scores and data-driven baselines. This demonstrates that physics-informed pretraining boosts sample efficiency and yields physiologically meaningful representations. Furthermore, PINS-CAD generates spatially resolved pressure and fractional flow reserve curves, providing interpretable biomarkers. By embedding physical priors into geometric deep learning, PINS-CAD transforms routine angiography into a simulation-free, physiology-aware framework for scalable, preventive cardiology.", "AI": {"tldr": "The paper introduces PINS-CAD, a physics-informed self-supervised learning framework, aimed at scalable and physiology-aware cardiovascular risk prediction without computational fluid dynamics or labeled data.", "motivation": "Cardiovascular disease, particularly coronary artery disease, requires early risk prediction, but scalability is limited by computationally heavy approaches and constraints in labeled data.", "method": "The framework pre-trains graph neural networks on synthetic coronary artery data, guided by physics-based principles (Navier-Stokes equations), to predict pressure and flow without requiring CFD or labeled clinical data.", "result": "Fine-tuned on multicenter clinical data, PINS-CAD predicts cardiovascular events with an AUC of 0.73, outperforming existing benchmarks and providing physiologically interpretable biomarkers.", "conclusion": "PINS-CAD leverages physics-based priors to transform routine angiographic imaging into a scalable, simulation-free predictive tool for preventive cardiology."}}
{"id": "2512.03347", "pdf": "https://arxiv.org/pdf/2512.03347", "abs": "https://arxiv.org/abs/2512.03347", "authors": ["William van den Bogert", "Gregory Linkowski", "Nima Fazeli"], "title": "GOMP: Grasped Object Manifold Projection for Multimodal Imitation Learning of Manipulation", "categories": ["cs.RO"], "comment": "8 pages, 8 figures, 2 tables", "summary": "Imitation Learning (IL) holds great potential for learning repetitive manipulation tasks, such as those in industrial assembly. However, its effectiveness is often limited by insufficient trajectory precision due to compounding errors. In this paper, we introduce Grasped Object Manifold Projection (GOMP), an interactive method that mitigates these errors by constraining a non-rigidly grasped object to a lower-dimensional manifold. GOMP assumes a precise task in which a manipulator holds an object that may shift within the grasp in an observable manner and must be mated with a grounded part. Crucially, all GOMP enhancements are learned from the same expert dataset used to train the base IL policy, and are adjusted with an n-arm bandit-based interactive component. We propose a theoretical basis for GOMP's improvement upon the well-known compounding error bound in IL literature. We demonstrate the framework on four precise assembly tasks using tactile feedback, and note that the approach remains modality-agnostic. Data and videos are available at williamvdb.github.io/GOMPsite.", "AI": {"tldr": "This paper introduces GOMP, a method to reduce compounding errors in imitation learning for precise manipulation tasks by constraining objects to a low-dimensional manifold.", "motivation": "The motivation is to address the issue of compounding errors in imitation learning, which limits its potential for high-precision manipulation tasks like industrial assembly.", "method": "The proposed method, GOMP, uses an interactive approach involving manifold projection and an n-arm bandit framework to adjust policies, trained solely from expert datasets.", "result": "The approach is tested on four assembly tasks using tactile feedback, showing improved performance in task precision and usability across modalities.", "conclusion": "GOMP reduces compounding errors in imitation learning and enhances task precision without requiring additional data beyond the expert dataset, making it applicable to various manipulation tasks."}}
{"id": "2512.03697", "pdf": "https://arxiv.org/pdf/2512.03697", "abs": "https://arxiv.org/abs/2512.03697", "authors": ["Rafael Ravedutti Lucio Machado", "Jan Eitzinger", "Georg Hager", "Gerhard Wellein"], "title": "On the Challenges of Energy-Efficiency Analysis in HPC Systems: Evaluating Synthetic Benchmarks and Gromacs", "categories": ["cs.DC", "cs.MS"], "comment": "8 pages, 4 figures, conference", "summary": "This paper discusses the challenges encountered when analyzing the energy efficiency of synthetic benchmarks and the Gromacs package on the Fritz and Alex HPC clusters. Experiments were conducted using MPI parallelism on full sockets of Intel Ice Lake and Sapphire Rapids CPUs, as well as Nvidia A40 and A100 GPUs. The metrics and measurements obtained with the Likwid and Nvidia profiling tools are presented, along with the results. The challenges and pitfalls encountered during experimentation and analysis are revealed and discussed. Best practices for future energy efficiency analysis studies are suggested.", "AI": {"tldr": "The paper evaluates energy efficiency analysis for benchmarks and Gromacs on Intel CPUs and Nvidia GPUs, discussing challenges and providing best practices.", "motivation": "To address the challenges in energy efficiency analysis of synthetic benchmarks and Gromacs on High-Performance Computing (HPC) systems.", "method": "Experiments were conducted with MPI parallelism on Intel Ice Lake and Sapphire Rapids CPUs, and Nvidia A40 and A100 GPUs using Likwid and Nvidia profiling tools.", "result": "Metrics and measurements were analyzed, revealing challenges and pitfalls in the energy efficiency analysis process.", "conclusion": "The paper provides insights into encountered issues and recommends best practices for future energy efficiency studies."}}
{"id": "2512.03318", "pdf": "https://arxiv.org/pdf/2512.03318", "abs": "https://arxiv.org/abs/2512.03318", "authors": ["Chandler Smith", "Marwa Abdulhai", "Manfred Diaz", "Marko Tesic", "Rakshit S. Trivedi", "Alexander Sasha Vezhnevets", "Lewis Hammond", "Jesse Clifton", "Minsuk Chang", "Edgar A. Du\u00e9\u00f1ez-Guzm\u00e1n", "John P. Agapiou", "Jayd Matyas", "Danny Karmon", "Akash Kundu", "Aliaksei Korshuk", "Ananya Ananya", "Arrasy Rahman", "Avinaash Anand Kulandaivel", "Bain McHale", "Beining Zhang", "Buyantuev Alexander", "Carlos Saith Rodriguez Rojas", "Caroline Wang", "Chetan Talele", "Chenao Liu", "Chichen Lin", "Diana Riazi", "Di Yang Shi", "Emanuel Tewolde", "Elizaveta Tennant", "Fangwei Zhong", "Fuyang Cui", "Gang Zhao", "Gema Parre\u00f1o Piqueras", "Hyeonggeun Yun", "Ilya Makarov", "Jiaxun Cui", "Jebish Purbey", "Jim Dilkes", "Jord Nguyen", "Lingyun Xiao", "Luis Felipe Giraldo", "Manuela Chacon-Chamorro", "Manuel Sebastian Rios Beltran", "Marta Emili Garc\u00eda Segura", "Mengmeng Wang", "Mogtaba Alim", "Nicanor Quijano", "Nico Schiavone", "Olivia Macmillan-Scott", "Oswaldo Pe\u00f1a", "Peter Stone", "Ram Mohan Rao Kadiyala", "Rolando Fernandez", "Ruben Manrique", "Sunjia Lu", "Sheila A. McIlraith", "Shamika Dhuri", "Shuqing Shi", "Siddhant Gupta", "Sneheel Sarangi", "Sriram Ganapathi Subramanian", "Taehun Cha", "Toryn Q. Klassen", "Wenming Tu", "Weijian Fan", "Wu Ruiyang", "Xue Feng", "Yali Du", "Yang Liu", "Yiding Wang", "Yipeng Kang", "Yoonchang Sung", "Yuxuan Chen", "Zhaowei Zhang", "Zhihan Wang", "Zhiqiang Wu", "Ziang Chen", "Zilong Zheng", "Zixia Jia", "Ziyan Wang", "Dylan Hadfield-Menell", "Natasha Jaques", "Tim Baarslag", "Jose Hernandez-Orallo", "Joel Z. Leibo"], "title": "Evaluating Generalization Capabilities of LLM-Based Agents in Mixed-Motive Scenarios Using Concordia", "categories": ["cs.AI"], "comment": "Published at NeurIPS Datasets and Benchmarks 2025, 10 pages", "summary": "Large Language Model (LLM) agents have demonstrated impressive capabilities for social interaction and are increasingly being deployed in situations where they might engage with both human and artificial agents. These interactions represent a critical frontier for LLM-based agents, yet existing evaluation methods fail to measure how well these capabilities generalize to novel social situations. In this paper, we introduce a method for evaluating the ability of LLM-based agents to cooperate in zero-shot, mixed-motive environments using Concordia, a natural language multi-agent simulation environment. Our method measures general cooperative intelligence by testing an agent's ability to identify and exploit opportunities for mutual gain across diverse partners and contexts. We present empirical results from the NeurIPS 2024 Concordia Contest, where agents were evaluated on their ability to achieve mutual gains across a suite of diverse scenarios ranging from negotiation to collective action problems. Our findings reveal significant gaps between current agent capabilities and the robust generalization required for reliable cooperation, particularly in scenarios demanding persuasion and norm enforcement.", "AI": {"tldr": "This paper evaluates the cooperative capabilities of Large Language Model (LLM) agents in zero-shot, mixed-motive scenarios using the Concordia simulation environment.", "motivation": "Understanding how well LLM-based agents perform in novel social interactions, especially in environments requiring cooperation, is critical as these agents are increasingly deployed in real-world settings.", "method": "The researchers used Concordia, a natural language multi-agent simulation, to assess agents' ability to cooperate across diverse partners and contexts in mixed-motive situations. Empirical tests were conducted through the NeurIPS 2024 Concordia Contest.", "result": "Findings show significant gaps in current LLM agents' abilities, especially in tasks involving persuasion, norm enforcement, and achieving mutual gains in cooperative scenarios.", "conclusion": "LLM agents require further development to reliably generalize and perform in complex social-environment contexts, highlighting opportunities for improvement in cooperation-related tasks."}}
{"id": "2512.03197", "pdf": "https://arxiv.org/pdf/2512.03197", "abs": "https://arxiv.org/abs/2512.03197", "authors": ["Faezeh Faez", "Marzieh S. Tahaei", "Yaochen Hu", "Ali Pourranjbar", "Mahdi Biparva", "Mark Coates", "Yingxue Zhang"], "title": "InvertiTune: High-Quality Data Synthesis for Cost-Effective Single-Shot Text-to-Knowledge Graph Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have revolutionized the ability to understand and generate text, enabling significant progress in automatic knowledge graph construction from text (Text2KG). Many Text2KG methods, however, rely on iterative LLM prompting, making them computationally expensive and prone to overlooking complex relations distributed throughout the text. To address these limitations, we propose InvertiTune, a framework that combines a controlled data generation pipeline with supervised fine-tuning (SFT). Within this framework, the data-generation pipeline systematically extracts subgraphs from large knowledge bases, applies noise filtering, and leverages LLMs to generate corresponding natural text descriptions, a task more aligned with LLM capabilities than direct KG generation from text. This pipeline enables generating datasets composed of longer texts paired with larger KGs that better reflect real-world scenarios compared to existing benchmarks, thus supporting effective SFT of lightweight models for single-shot KG construction. Experimental results on CE12k, a dataset generated using the introduced pipeline, show that InvertiTune outperforms larger non-fine-tuned LLMs as well as state-of-the-art Text2KG approaches, while also demonstrating stronger cross-dataset generalization on CrossEval-1200, a test set created from three established benchmark datasets and CE12k. These findings highlight the importance of realistic, high-quality training data for advancing efficient and high-performing Text2KG systems.", "AI": {"tldr": "The paper introduces InvertiTune, a framework designed to enhance Text2KG methods by pairing a controlled data-generation pipeline with supervised fine-tuning, resulting in efficient and high-performing single-shot KG construction.", "motivation": "Many current Text2KG methods, despite leveraging LLMs, are computationally expensive and struggle to capture complex relations in text. This paper aims to improve efficiency and performance by creating better training datasets and a fine-tuning process.", "method": "The proposed InvertiTune framework systematically extracts knowledge subgraphs, applies noise filtering, and uses LLMs to generate corresponding natural text descriptions, which are then used to fine-tune lightweight models for efficient Text2KG tasks.", "result": "InvertiTune outperformed larger LLMs and state-of-the-art Text2KG methods on the CE12k dataset and demonstrated robust performance in cross-dataset tests (CrossEval-1200).", "conclusion": "Efficient and high-performing Text2KG systems depend heavily on realistic and high-quality training data, as evidenced by the capabilities of InvertiTune in complex scenarios."}}
{"id": "2512.03926", "pdf": "https://arxiv.org/pdf/2512.03926", "abs": "https://arxiv.org/abs/2512.03926", "authors": ["Alexander Y. Bai", "Chris Hawblitzel", "Andrea Lattuada"], "title": "Tunable Automation in Automated Program Verification", "categories": ["cs.SE", "cs.LO", "cs.PL"], "comment": null, "summary": "Automated verification tools based on SMT solvers have made significant progress in verifying complex software systems. However, these tools face a fundamental tension between automation and performance when dealing with quantifier instantiation -- the primary source of incompleteness and verification slowdown in SMT-based verifiers. Tools choose between aggressive quantifier instantiation that provides more automation but longer verification times, or conservative instantiation that responds quickly but may require more manual proof hints.\n  We present a mechanism that enables fine-grained control over the availability of quantified facts in verification contexts, allowing developers to selectively tune the level of automation. Our approach lets library authors provide different pre-defined automation levels while giving end-users the ability to further customize quantifier availability at the module, function, or proof context level.\n  We implement our techniques in Verus, a Rust-based verification tool, and evaluate them on multiple openly available codebases. Our empirical analysis demonstrates the automation-performance tradeoff and that selective quantifier management enables developers to select the appropriate level of automation in different contexts.", "AI": {"tldr": "The paper aims to address the issue of balancing automation and performance in SMT-based verification tools by enabling selective control of quantified facts.", "motivation": "To overcome the tension between automation and performance in SMT-based verification tools, particularly in quantifier instantiation.", "method": "The authors introduce a mechanism for fine-grained control over quantified facts, allowing customization of automation levels. Implemented in Verus, a Rust-based verification tool.", "result": "Empirical analysis shows that the approach helps users achieve a balance between automation and performance by selecting the appropriate level of automation.", "conclusion": "Selective quantifier management empowers developers to handle diverse contexts appropriately, providing flexibility in SMT-based software verification."}}
{"id": "2512.03727", "pdf": "https://arxiv.org/pdf/2512.03727", "abs": "https://arxiv.org/abs/2512.03727", "authors": ["Lorenzo Marinucci", "Leonardo Di Nino", "Gabriele D'Acunto", "Mario Edoardo Pandolfo", "Paolo Di Lorenzo", "Sergio Barbarossa"], "title": "Colored Markov Random Fields for Probabilistic Topological Modeling", "categories": ["stat.ML", "cs.LG", "eess.SP", "stat.ME"], "comment": "Proceeding of 2025 Asilomar Conference on Signals, Systems, and Computers", "summary": "Probabilistic Graphical Models (PGMs) encode conditional dependencies among random variables using a graph -nodes for variables, links for dependencies- and factorize the joint distribution into lower-dimensional components. This makes PGMs well-suited for analyzing complex systems and supporting decision-making. Recent advances in topological signal processing highlight the importance of variables defined on topological spaces in several application domains. In such cases, the underlying topology shapes statistical relationships, limiting the expressiveness of canonical PGMs. To overcome this limitation, we introduce Colored Markov Random Fields (CMRFs), which model both conditional and marginal dependencies among Gaussian edge variables on topological spaces, with a theoretical foundation in Hodge theory. CMRFs extend classical Gaussian Markov Random Fields by including link coloring: connectivity encodes conditional independence, while color encodes marginal independence. We quantify the benefits of CMRFs through a distributed estimation case study over a physical network, comparing it with baselines with different levels of topological prior.", "AI": {"tldr": "The paper introduces Colored Markov Random Fields (CMRFs), which expand classical Gaussian Markov Random Fields by incorporating topological spaces and Hodge theory.", "motivation": "PGMs lack expressiveness when dealing with statistical relationships shaped by topological spaces, which limits their application in certain domains.", "method": "The authors propose CMRFs, integrating connectivity for conditional independence and coloring for marginal independence while grounded in Hodge theory.", "result": "The proposed CMRFs are shown to outperform baseline models in a case study involving distributed estimation over a physical network.", "conclusion": "CMRFs enhance the classical PGM framework, making it more suitable for problems where topology influences statistical relationships."}}
{"id": "2512.03233", "pdf": "https://arxiv.org/pdf/2512.03233", "abs": "https://arxiv.org/abs/2512.03233", "authors": ["Richard F\u00fczess\u00e9ry", "Kaziwa Saleh", "S\u00e1ndor Sz\u00e9n\u00e1si", "Zolt\u00e1n V\u00e1mossy"], "title": "Object Counting with GPT-4o and GPT-5: A Comparative Study", "categories": ["cs.CV"], "comment": "5 pages, 3 figures", "summary": "Zero-shot object counting attempts to estimate the number of object instances belonging to novel categories that the vision model performing the counting has never encountered during training. Existing methods typically require large amount of annotated data and often require visual exemplars to guide the counting process. However, large language models (LLMs) are powerful tools with remarkable reasoning and data understanding abilities, which suggest the possibility of utilizing them for counting tasks without any supervision. In this work we aim to leverage the visual capabilities of two multi-modal LLMs, GPT-4o and GPT-5, to perform object counting in a zero-shot manner using only textual prompts. We evaluate both models on the FSC-147 and CARPK datasets and provide a comparative analysis. Our findings show that the models achieve performance comparable to the state-of-the-art zero-shot approaches on FSC-147, in some cases, even surpass them.", "AI": {"tldr": "The paper explores zero-shot object counting using GPT-4o and GPT-5, showing their capability to deliver performance comparable to state-of-the-art methods without requiring supervision.", "motivation": "To leverage the reasoning and data understanding capabilities of large language models (LLMs) for zero-shot object counting tasks without requiring manual annotations or visual exemplars.", "method": "The authors utilized two multi-modal LLMs (GPT-4o and GPT-5) for zero-shot object counting and conducted evaluations on FSC-147 and CARPK using textual prompts.", "result": "The models achieved competitive performance with state-of-the-art zero-shot object counting methods, even surpassing them in some cases on the FSC-147 dataset.", "conclusion": "LLMs like GPT-4o and GPT-5 can be effectively applied to zero-shot object counting tasks using only textual prompts, offering a novel, supervision-free methodology that can rival or outperform current approaches."}}
{"id": "2512.03056", "pdf": "https://arxiv.org/pdf/2512.03056", "abs": "https://arxiv.org/abs/2512.03056", "authors": ["Zhidong Gao", "Zimeng Pan", "Yuhang Yao", "Chenyue Xie", "Wei Wei"], "title": "Delta Sampling: Data-Free Knowledge Transfer Across Diffusion Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diffusion models like Stable Diffusion (SD) drive a vibrant open-source ecosystem including fully fine-tuned checkpoints and parameter-efficient adapters such as LoRA, LyCORIS, and ControlNet. However, these adaptation components are tightly coupled to a specific base model, making them difficult to reuse when the base model is upgraded (e.g., from SD 1.x to 2.x) due to substantial changes in model parameters and architecture. In this work, we propose Delta Sampling (DS), a novel method that enables knowledge transfer across base models with different architectures, without requiring access to the original training data. DS operates entirely at inference time by leveraging the delta: the difference in model predictions before and after the adaptation of a base model. This delta is then used to guide the denoising process of a new base model. We evaluate DS across various SD versions, demonstrating that DS achieves consistent improvements in creating desired effects (e.g., visual styles, semantic concepts, and structures) under different sampling strategies. These results highlight DS as an effective, plug-and-play mechanism for knowledge transfer in diffusion-based image synthesis. Code:~ https://github.com/Zhidong-Gao/DeltaSampling", "AI": {"tldr": "The paper introduces Delta Sampling (DS), a method enabling cross-base model knowledge transfer in diffusion models without requiring access to the original data. DS works entirely at inference time.", "motivation": "Current adaptation components of diffusion models are closely tied to specific base models, limiting their usability when base models upgrade (e.g., from Stable Diffusion 1.x to 2.x). The need arises for a reusable and effective mechanism to transfer knowledge across varying architectures.", "method": "The proposed DS method leverages the difference (delta) in model predictions before and after adaptation of a base model. This delta is utilized to guide the denoising process in the new base model, operating purely during inference time.", "result": "Delta Sampling demonstrates consistent improvements in achieving desired effects across various Stable Diffusion versions under diverse sampling strategies.", "conclusion": "DS provides a plug-and-play solution for effective knowledge transfer across different diffusion-based image synthesis models, broadening adaptability and efficiency in the field."}}
{"id": "2512.03397", "pdf": "https://arxiv.org/pdf/2512.03397", "abs": "https://arxiv.org/abs/2512.03397", "authors": ["Seungwon Choi", "Dong-Gyu Park", "Seo-Yeon Hwang", "Tae-Wan Kim"], "title": "Surfel-LIO: Fast LiDAR-Inertial Odometry with Pre-computed Surfels and Hierarchical Z-order Voxel Hashing", "categories": ["cs.RO"], "comment": null, "summary": "LiDAR-inertial odometry (LIO) is an active research area, as it enables accurate real-time state estimation in GPS-denied environments. Recent advances in map data structures and spatial indexing have significantly improved the efficiency of LIO systems. Nevertheless, we observe that two aspects may still leave room for improvement: (1) nearest neighbor search often requires examining multiple spatial units to gather sufficient points for plane fitting, and (2) plane parameters are typically recomputed at every iteration despite unchanged map geometry. Motivated by these observations, we propose Surfel-LIO, which employs a hierarchical voxel structure (hVox) with pre-computed surfel representation. This design enables O(1) correspondence retrieval without runtime neighbor enumeration or plane fitting, combined with Z-order curve encoding for cache-friendly spatial indexing. Experimental results on the M3DGR dataset demonstrate that our method achieves significantly faster processing speed compared to recent state-of-the-art methods while maintaining comparable state estimation accuracy. Our implementation is publicly available at https://github.com/93won/lidar_inertial_odometry.", "AI": {"tldr": "The paper proposes Surfel-LIO, a novel LiDAR-inertial odometry (LIO) framework, which enhances processing efficiency by addressing limitations in traditional neighbor search and plane parameter updates.", "motivation": "To address inefficiencies in traditional LIO approaches regarding neighbor search requiring multiple spatial unit examinations and repetitive computation of plane parameters at each iteration.", "method": "Introduces a hierarchical voxel structure (hVox) with pre-computed surfel representation and Z-order curve encoding for efficient spatial indexing, eliminating the need for runtime neighbor enumeration or plane fitting.", "result": "Demonstrates faster processing speed while maintaining comparable state estimation accuracy on the M3DGR dataset compared to state-of-the-art methods.", "conclusion": "Surfel-LIO provides a more efficient and accurate LIO framework, making it suitable for real-time applications in GPS-denied environments. The implementation is open-source for public use."}}
{"id": "2512.03825", "pdf": "https://arxiv.org/pdf/2512.03825", "abs": "https://arxiv.org/abs/2512.03825", "authors": ["Aingeru Ramos", "Jose A Pascual", "Javier Navaridas", "Ivan Coluzza"], "title": "Acceleration of Parallel Tempering for Markov Chain Monte Carlo methods", "categories": ["cs.DC"], "comment": "14 pages, 7 figures (5 of them composed by 2 subfigures)", "summary": "Markov Chain Monte Carlo methods are algorithms used to sample probability distributions, commonly used to sample the Boltzmann distribution of physical/chemical models (e.g., protein folding, Ising model, etc.). This allows us to study their properties by sampling the most probable states of those systems. However, the sampling capabilities of these methods are not sufficiently accurate when handling complex configuration spaces. This has resulted in the development of new techniques that improve sampling accuracy, usually at the expense of increasing the computational cost. One of such techniques is Parallel Tempering which improves accuracy by running several replicas which periodically exchange their states. Computationally, this imposes a significant slow-down, which can be counteracted by means of parallelization. These schemes enable MCMC/PT techniques to be run more effectively and allow larger models to be studied. In this work, we present a parallel implementation of Metropolis-Hastings with Parallel Tempering, using OpenMP and CUDA for the parallelization in modern CPUs and GPUs, respectively. The results show a maximum speed-up of 52x using OpenMP with 48 cores, and of 986x speed-up with the CUDA version. Furthermore, the results serve as a basic benchmark to compare a future quantum implementation of the same algorithm.", "AI": {"tldr": "The paper discusses improving Markov Chain Monte Carlo sampling accuracy through Parallel Tempering, and achieves significant computational speed-ups using OpenMP on CPUs and CUDA on GPUs.", "motivation": "The motivation is to overcome the inaccuracy of MCMC sampling in complex configuration spaces by improving the efficiency and accuracy of techniques like Parallel Tempering.", "method": "The paper implements a parallelized version of Metropolis-Hastings with Parallel Tempering using OpenMP for CPUs and CUDA for GPUs.", "result": "The parallel implementation achieves a speed-up of 52x with OpenMP on a 48-core CPU and a 986x speed-up using CUDA on GPU.", "conclusion": "The study demonstrates the efficacy of parallelization in enhancing MCMC sampling accuracy, and the results provide a benchmark for future quantum algorithm implementations."}}
{"id": "2512.03461", "pdf": "https://arxiv.org/pdf/2512.03461", "abs": "https://arxiv.org/abs/2512.03461", "authors": ["Sanwar Ahmed Ovy", "Jiahui Duan", "Md Ashraful Islam Romel", "Franz Muller", "Thomas Kampfe", "Kai Ni", "Sumitha George"], "title": "In-Situ Encryption of Single-Transistor Nonvolatile Memories without Density Loss", "categories": ["cs.CR", "cs.AR", "cs.ET"], "comment": null, "summary": "Non-volatile memories (NVMs) offer negligible leakage power consumption, high integration density, and data retention, but their non-volatility also raises the risk of data exposure. Conventional encryption techniques such as the Advanced Encryption Standard (AES) incur large area overheads and performance penalties, motivating lightweight XOR-based in-situ encryption schemes with low area and power requirements. This work proposes an ultra-dense single-transistor encrypted cell using ferroelectric FET (FeFET) devices, which, to our knowledge, is the first to eliminate the two-memory-devices-per-encrypted-cell requirement in XOR-based schemes, enabling encrypted memory arrays to maintain the same number of storage devices as unencrypted arrays. The key idea is an in-memory single-FeFET XOR scheme, where the ciphertext is encoded in the device threshold voltage and leverages the direction-dependent current flow of the FeFET for single-cycle decryption; eliminating complementary bit storage also removes the need for two write cycles, allowing faster encryption. We extend the approach to multi-level-cell (MLC) FeFETs to store multiple bits per transistor. We validate the proposed idea through both simulation and experimental evaluations. Our analysis on a 128x128-bit array shows 2x higher encryption/decryption throughput than prior FeFET work and 45.2x/14.12x improvement over AES, while application-level evaluations using neural-network benchmarks demonstrate average latency reductions of 50% and 95% compared to prior FeFET-based and AES-based schemes, respectively.", "AI": {"tldr": "The paper presents an innovative encryption scheme using ferroelectric FET (FeFET) for non-volatile memories, offering improved efficiency without the drawbacks of traditional methods.", "motivation": "The need to address inefficiencies and security vulnerabilities in conventional encryption techniques for non-volatile memories, including area overheads and performance penalties.", "method": "The authors propose a single-transistor FeFET encryption scheme using XOR for ultra-dense memory cells. They utilize current directionality for single-cycle decryption and eliminate the necessity of dual-memory devices and complementary bit storage.", "result": "The approach achieves 2x higher encryption/decryption throughput compared to existing FeFET methods, and significant improvements (45.2x/14.12x) over AES. Average latency reductions of 50% and 95% are achieved against FeFET-based and AES-based schemes, respectively.", "conclusion": "This work demonstrates a novel encryption memory design that significantly enhances both performance and efficiency in encrypted non-volatile memory systems, making it a promising solution for secure storage."}}
{"id": "2512.03438", "pdf": "https://arxiv.org/pdf/2512.03438", "abs": "https://arxiv.org/abs/2512.03438", "authors": ["Reuben Tan", "Baolin Peng", "Zhengyuan Yang", "Hao Cheng", "Oier Mees", "Theodore Zhao", "Andrea Tupini", "Isar Meijier", "Qianhui Wu", "Yuncong Yang", "Lars Liden", "Yu Gu", "Sheng Zhang", "Xiaodong Liu", "Lijuan Wang", "Marc Pollefeys", "Yong Jae Lee", "Jianfeng Gao"], "title": "Multimodal Reinforcement Learning with Agentic Verifier for AI Agents", "categories": ["cs.AI"], "comment": null, "summary": "Agentic reasoning models trained with multimodal reinforcement learning (MMRL) have become increasingly capable, yet they are almost universally optimized using sparse, outcome-based rewards computed based on the final answers. Richer rewards computed from the reasoning tokens can improve learning significantly by providing more fine-grained guidance. However, it is challenging to compute more informative rewards in MMRL beyond those based on outcomes since different samples may require different scoring functions and teacher models may provide noisy reward signals too. In this paper, we introduce the Argos (Agentic Reward for Grounded & Objective Scoring), a principled reward agent to train multimodal reasoning models for agentic tasks. For each sample, Argos selects from a pool of teacher-model derived and rule-based scoring functions to simultaneously evaluate: (i) final response accuracy, (ii) spatiotemporal localization of referred entities and actions, and (iii) the quality of the reasoning process. We find that by leveraging our agentic verifier across both SFT data curation and RL training, our model achieves state-of-the-art results across multiple agentic tasks such as spatial reasoning, visual hallucination as well as robotics and embodied AI benchmarks. Critically, we demonstrate that just relying on SFT post-training on highly curated reasoning data is insufficient, as agents invariably collapse to ungrounded solutions during RL without our online verification. We also show that our agentic verifier can help to reduce reward-hacking in MMRL. Finally, we also provide a theoretical justification for the effectiveness of Argos through the concept of pareto-optimality.", "AI": {"tldr": "The paper introduces Argos, a novel reward agent designed to improve multimodal reasoning tasks by guiding models with more informative rewards across multiple aspects, achieving state-of-the-art results.", "motivation": "Current multimodal reasoning models often rely on sparse outcome-based rewards, which fail to provide detailed guidance during learning.", "method": "The authors propose Argos, an agentic reward verifier that utilizes teacher-model derived scores and rule-based functions to evaluate accuracy, spatial localization, and reasoning quality during training.", "result": "Argos enhances model training for multimodal reasoning tasks, resulting in state-of-the-art performance on agentic tasks like spatial reasoning, visual hallucination, robotics, and embodied AI benchmarks.", "conclusion": "Argos addresses the shortcomings of sparse rewards and reduces reward-hacking in MMRL, with theoretical justification provided through pareto-optimality."}}
{"id": "2512.03214", "pdf": "https://arxiv.org/pdf/2512.03214", "abs": "https://arxiv.org/abs/2512.03214", "authors": ["Paulina Garcia-Corral"], "title": "Identifying attributions of causality in political text", "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "Explanations are a fundamental element of how people make sense of the political world. Citizens routinely ask and answer questions about why events happen, who is responsible, and what could or should be done differently. Yet despite their importance, explanations remain an underdeveloped object of systematic analysis in political science, and existing approaches are fragmented and often issue-specific. I introduce a framework for detecting and parsing explanations in political text. To do this, I train a lightweight causal language model that returns a structured data set of causal claims in the form of cause-effect pairs for downstream analysis. I demonstrate how causal explanations can be studied at scale, and show the method's modest annotation requirements, generalizability, and accuracy relative to human coding.", "AI": {"tldr": "The paper proposes a framework and causal language model to analyze explanations in political texts as structured cause-effect pairs.", "motivation": "Explanations are vital in understanding the political world, but systematic analysis methods are underdeveloped and fragmented.", "method": "The author develops a lightweight causal language model to identify and parse explanations in political text, producing structured cause-effect pairs for further study.", "result": "The approach demonstrates scalability, requires minimal annotation, is generalizable, and achieves accuracy comparable to human coding.", "conclusion": "This framework enables systematic and scalable analysis of causal explanations in political science, addressing a key gap in the field."}}
{"id": "2512.03851", "pdf": "https://arxiv.org/pdf/2512.03851", "abs": "https://arxiv.org/abs/2512.03851", "authors": ["Paul Strasser", "Andreas Pfeffer", "Jakob Weber", "Markus Gurtner", "Andreas K\u00f6rner"], "title": "Comparison of neural network training strategies for the simulation of dynamical systems", "categories": ["stat.ML", "cs.LG"], "comment": "submitted to ECC", "summary": "Neural networks have become a widely adopted tool for modeling nonlinear dynamical systems from data. However, the choice of training strategy remains a key design decision, particularly for simulation tasks. This paper compares two predominant strategies: parallel and series-parallel training. The conducted empirical analysis spans five neural network architectures and two examples: a pneumatic valve test bench and an industrial robot benchmark. The study reveals that, even though series-parallel training dominates current practice, parallel training consistently yields better long-term prediction accuracy. Additionally, this work clarifies the often inconsistent terminology in the literature and relate both strategies to concepts from system identification. The findings suggest that parallel training should be considered the default training strategy for neural network-based simulation of dynamical systems.", "AI": {"tldr": "This paper compares two training strategies, parallel and series-parallel, for neural networks in dynamical system simulations, concluding that parallel training performs better.", "motivation": "To improve the accuracy and reliability of neural network-based simulations of nonlinear dynamical systems by evaluating training strategies.", "method": "Empirical analysis using five neural network architectures on two case studies: a pneumatic valve test bench and an industrial robot benchmark, along with terminology clarification.", "result": "Parallel training consistently outperformed series-parallel training in long-term prediction accuracy.", "conclusion": "Parallel training should be the default strategy for neural network-based dynamical system simulations due to its superior performance."}}
{"id": "2512.03237", "pdf": "https://arxiv.org/pdf/2512.03237", "abs": "https://arxiv.org/abs/2512.03237", "authors": ["Nafiseh Izadyar", "Teseo Schneider"], "title": "LLM-Guided Material Inference for 3D Point Clouds", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "Most existing 3D shape datasets and models focus solely on geometry, overlooking the material properties that determine how objects appear. We introduce a two-stage large language model (LLM) based method for inferring material composition directly from 3D point clouds with coarse segmentations. Our key insight is to decouple reasoning about what an object is from what it is made of. In the first stage, an LLM predicts the object's semantic; in the second stage, it assigns plausible materials to each geometric segment, conditioned on the inferred semantics. Both stages operate in a zero-shot manner, without task-specific training. Because existing datasets lack reliable material annotations, we evaluate our method using an LLM-as-a-Judge implemented in DeepEval. Across 1,000 shapes from Fusion/ABS and ShapeNet, our method achieves high semantic and material plausibility. These results demonstrate that language models can serve as general-purpose priors for bridging geometric reasoning and material understanding in 3D data.", "AI": {"tldr": "The paper introduces a method to determine material composition from 3D point clouds with coarse segmentations, decoupling semantic understanding from material assignment using LLMs, operating in a zero-shot manner.", "motivation": "Existing 3D shape datasets and models often overlook material properties, focusing on geometry alone. This limitation calls for an improved approach to integrate material understanding into 3D data.", "method": "The proposed method uses a two-stage framework relying on large language models: the first stage predicts the semantic category of an object, and the second stage assigns plausible materials to geometric segments based on the predicted semantics. Both stages are performed in a zero-shot manner.", "result": "Evaluated using the LLM-as-a-Judge in DeepEval, the method demonstrated high plausibility in semantic and material assignment across datasets like Fusion/ABS and ShapeNet.", "conclusion": "Language models can effectively integrate geometric reasoning with material understanding, serving as powerful general-purpose priors for material-property inference in 3D data."}}
{"id": "2512.03058", "pdf": "https://arxiv.org/pdf/2512.03058", "abs": "https://arxiv.org/abs/2512.03058", "authors": ["Duy-Tung Pham", "An The Nguyen", "Viet-Hoang Tran", "Nhan-Phu Chung", "Xin T. Tong", "Tan M. Nguyen", "Thieu N. Vo"], "title": "Dynamical Properties of Tokens in Self-Attention and Effects of Positional Encoding", "categories": ["cs.LG"], "comment": null, "summary": "This paper investigates the dynamical properties of tokens in pre-trained Transformer models and explores their application to improving Transformers. To this end, we analyze the dynamical system governing the continuous-time limit of the pre-trained model and characterize the asymptotic behavior of its solutions. Specifically, we characterize when tokens move closer to or farther from one another over time, depending on the model parameters. We provide sufficient conditions, based on these parameters, to identify scenarios where tokens either converge to zero or diverge to infinity. Unlike prior works, our conditions are broader in scope and more applicable to real-world models. Furthermore, we investigate how different forms of positional encoding -- specifically absolute and rotary -- affect these dynamical regimes. Empirical evidence reveals that the convergence scenario adversely impacts model performance. Motivated by these insights, we propose simple refinements to Transformer architectures that mitigate convergence behavior in models with absolute or rotary positional encoding. These findings support theoretical foundations and design principles for improving Transformer models.", "AI": {"tldr": "The paper analyzes the dynamical properties of tokens in pre-trained Transformer models, proposes refinements to reduce negative effects of convergence behavior, and offers design principles for improving these models.", "motivation": "The study is motivated by the need to understand the dynamical behavior of tokens in Transformers and mitigate adverse effects like token convergence, which negatively impact model performance.", "method": "The authors analyze the continuous-time dynamics of pre-trained models to derive conditions under which tokens converge or diverge, considering positional encodings like absolute and rotary.", "result": "They find that convergence of tokens harms model performance and propose modifications to Transformer architectures that address this issue.", "conclusion": "The study establishes theoretical insights into token dynamics and provides practical refinements to enhance the performance of Transformer models."}}
{"id": "2512.03422", "pdf": "https://arxiv.org/pdf/2512.03422", "abs": "https://arxiv.org/abs/2512.03422", "authors": ["Tianchen Deng", "Yue Pan", "Shenghai Yuan", "Dong Li", "Chen Wang", "Mingrui Li", "Long Chen", "Lihua Xie", "Danwei Wang", "Jingchuan Wang", "Javier Civera", "Hesheng Wang", "Weidong Chen"], "title": "What Is The Best 3D Scene Representation for Robotics? From Geometric to Foundation Models", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "In this paper, we provide a comprehensive overview of existing scene representation methods for robotics, covering traditional representations such as point clouds, voxels, signed distance functions (SDF), and scene graphs, as well as more recent neural representations like Neural Radiance Fields (NeRF), 3D Gaussian Splatting (3DGS), and the emerging Foundation Models. While current SLAM and localization systems predominantly rely on sparse representations like point clouds and voxels, dense scene representations are expected to play a critical role in downstream tasks such as navigation and obstacle avoidance. Moreover, neural representations such as NeRF, 3DGS, and foundation models are well-suited for integrating high-level semantic features and language-based priors, enabling more comprehensive 3D scene understanding and embodied intelligence. In this paper, we categorized the core modules of robotics into five parts (Perception, Mapping, Localization, Navigation, Manipulation). We start by presenting the standard formulation of different scene representation methods and comparing the advantages and disadvantages of scene representation across different modules. This survey is centered around the question: What is the best 3D scene representation for robotics? We then discuss the future development trends of 3D scene representations, with a particular focus on how the 3D Foundation Model could replace current methods as the unified solution for future robotic applications. The remaining challenges in fully realizing this model are also explored. We aim to offer a valuable resource for both newcomers and experienced researchers to explore the future of 3D scene representations and their application in robotics. We have published an open-source project on GitHub and will continue to add new works and technologies to this project.", "AI": {"tldr": "This paper provides a comprehensive survey of 3D scene representation methods for robotics, exploring traditional and neural models, along with future trends like 3D Foundation Models.", "motivation": "To explore the most effective 3D scene representation methods for robotics to enhance tasks like navigation, obstacle avoidance, and understanding through semantic integration.", "method": "The paper categorizes robotics modules (Perception, Mapping, Localization, Navigation, Manipulation) and systematically compares advantages/disadvantages of scene representations.", "result": "Comparison of methods and insights into future trends of 3D scene representation, particularly focusing on the potential of 3D Foundation Models to unify and advance robotics applications.", "conclusion": "This paper provides researchers with a valuable categorization and analysis of scene representation technologies, emphasizing that 3D Foundation Models may replace current methods while challenges remain."}}
{"id": "2512.03927", "pdf": "https://arxiv.org/pdf/2512.03927", "abs": "https://arxiv.org/abs/2512.03927", "authors": ["Liujianfu Wang", "Yuyang Du", "Yuchen Pan", "Soung Chang Liew", "Jiacheng Liu", "Kexin Chen"], "title": "OD-MoE: On-Demand Expert Loading for Cacheless Edge-Distributed MoE Inference", "categories": ["cs.DC"], "comment": null, "summary": "Mixture-of-Experts (MoE), while offering significant advantages as a Large Language Model (LLM) architecture, faces substantial challenges when deployed on low-cost edge devices with tight memory constraints. Expert offloading mitigates this issue by storing expert parameters in CPU memory and caching a subset of popular experts in GPU memory. Although this approach improves GPU memory utilization by caching only the likely-used experts, the GPU memory reserved for expert caching is underutilized compared with dense LLMs. This paper presents OD-MoE, a distributed MoE inference framework that obviates the need for expert caches via fully on-demand expert loading. OD-MoE is built upon two key mechanisms: 1) parallelizing expert loading and expert computation across distributed edge nodes, and 2) an ultra-accurate emulative predictor that forecasts expert activations multiple layers ahead while expert computation is ongoing. With these innovations, OD-MoE dynamically loads each target expert to one of the distributed nodes just-in-time before its activation and promptly evicts it afterward, freeing GPU memory for subsequent experts. We comprehensively benchmark OD-MoE against state-of-the-art MoE offloading systems on a ten-node testbed. Experimental results show that: 1) OD-MoE achieves 99.94% expert activation prediction accuracy, substantially surpassing all existing methods; and 2) OD-MoE delivers approximately 75% of the decoding speed of a fully GPU-cached MoE deployment while using only 1/3 of the GPU memory. More importantly, by eliminating the need for expert caches, OD-MoE enables MoE inference on edge nodes with less-than-1GB GPU memory, paving the way for practical MoE deployment of low-cost IoT devices at the edge in the LLM era.", "AI": {"tldr": "OD-MoE introduces fully on-demand expert loading and predictive mechanisms to enable efficient Mixture-of-Experts LLM inference on memory-constrained edge devices, achieving high prediction accuracy and efficient decoding speed.", "motivation": "To address inefficiencies in GPU memory utilization and enable MoE inference on low-cost, memory-constrained edge devices.", "method": "The framework incorporates distributed on-demand loading of MoE experts across edge nodes combined with a predictive mechanism to forecast expert activations accurately ahead of time.", "result": "OD-MoE achieves 99.94% prediction accuracy and retains 75% of decoding speed compared to GPU-cached MoE setups, using just 1/3 of the GPU memory.", "conclusion": "OD-MoE enables efficient and practical deployment of MoE architecture on low-memory IoT devices, making it feasible for edge applications in the LLM era."}}
{"id": "2512.03528", "pdf": "https://arxiv.org/pdf/2512.03528", "abs": "https://arxiv.org/abs/2512.03528", "authors": ["Guang Yang", "Tianpei Yang", "Jingwen Qiao", "Yanqing Wu", "Jing Huo", "Xingguo Chen", "Yang Gao"], "title": "Multi-Agent Reinforcement Learning with Communication-Constrained Priors", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Communication is one of the effective means to improve the learning of cooperative policy in multi-agent systems. However, in most real-world scenarios, lossy communication is a prevalent issue. Existing multi-agent reinforcement learning with communication, due to their limited scalability and robustness, struggles to apply to complex and dynamic real-world environments. To address these challenges, we propose a generalized communication-constrained model to uniformly characterize communication conditions across different scenarios. Based on this, we utilize it as a learning prior to distinguish between lossy and lossless messages for specific scenarios. Additionally, we decouple the impact of lossy and lossless messages on distributed decision-making, drawing on a dual mutual information estimatior, and introduce a communication-constrained multi-agent reinforcement learning framework, quantifying the impact of communication messages into the global reward. Finally, we validate the effectiveness of our approach across several communication-constrained benchmarks.", "AI": {"tldr": "The paper proposes a communication-constrained framework to address scalability and robustness in multi-agent reinforcement learning under real-world lossy communication scenarios.", "motivation": "Existing multi-agent reinforcement learning struggles with limited scalability and robustness in handling lossy communication in complex real-world environments.", "method": "The authors propose a generalized communication-constrained model to represent various communication scenarios uniformly. They use a dual mutual information estimator to analyze lossy/lossless messages and quantify their impact in a multi-agent reinforcement learning framework.", "result": "The proposed framework demonstrates effectiveness in several communication-constrained benchmarks, showcasing improved performance.", "conclusion": "The communication-constrained learning framework effectively improves decision-making under lossy communication conditions, addressing key challenges in multi-agent systems."}}
{"id": "2512.03310", "pdf": "https://arxiv.org/pdf/2512.03310", "abs": "https://arxiv.org/abs/2512.03310", "authors": ["Kunj Joshi", "David A. Smith"], "title": "Randomized Masked Finetuning: An Efficient Way to Mitigate Memorization of PIIs in LLMs", "categories": ["cs.CL", "cs.CR", "cs.LG"], "comment": "To be submitted for ICML 2026", "summary": "The current literature on memorization in Natural Language Models, especially Large Language Models (LLMs), poses severe security and privacy risks, as models tend to memorize personally identifying information (PIIs) from training data. We introduce Randomized Masked Fine-Tuning (RMFT), a novel privacy-preserving fine-tuning technique that reduces PII memorization while minimizing performance impact. Using the Enron Email Dataset, we demonstrate that RMFT achieves an 80.81% reduction in Total Extraction Rate and 80.17% reduction in Seen Extraction Rate compared to baseline fine-tuning, outperforming deduplication methods while maintaining only a 5.73% increase in perplexity. We present MaxTER, a Pareto-optimal evaluation framework for assessing privacy-utility tradeoffs, and show the performance of RMFT vs Deduplication by Area Under The Response Curve (AURC) metric.", "AI": {"tldr": "The paper introduces Randomized Masked Fine-Tuning (RMFT), a technique to reduce personally identifying information (PII) memorization in language models, achieving substantial results with minimal performance trade-offs.", "motivation": "To address security and privacy risks in language models due to the memorization of personally identifying information (PIIs) from training data.", "method": "Introduces a fine-tuning technique called Randomized Masked Fine-Tuning (RMFT), tested with performance and privacy evaluation metrics using the Enron Email Dataset.", "result": "RMFT reduced the Total Extraction Rate by 80.81% and Seen Extraction Rate by 80.17%, while maintaining only a slight 5.73% increase in perplexity.", "conclusion": "RMFT is a Pareto-optimal approach that outperforms deduplication methods in balancing privacy and performance as assessed by the MaxTER framework and AURC metric."}}
{"id": "2512.03062", "pdf": "https://arxiv.org/pdf/2512.03062", "abs": "https://arxiv.org/abs/2512.03062", "authors": ["Roman Rausch", "David Jansen", "Sukhbinder Singh", "Rom\u00e1n Or\u00fas"], "title": "Globally optimized SVD compression of LLMs via Fermi-function-based rank selection and gauge fixing", "categories": ["cs.LG", "stat.ML"], "comment": "Prepared for submission to ESANN 2026", "summary": "Large Language Models (LLMs) are very demanding in terms of their computational resources. Low-rank decompositions of LLM weights, e.g. via Singular Value Decomposition (SVD), is a promising approach for LLM compression, but presents several practical hurdles, e.g. selecting appropriate layer-wise ranks and getting rid of its parameter redundancy. In this work, we present two physics-inspired improvements to SVD LLM compression: (1) \\textbf{FermiGrad}, a gradient-descent algorithm that determines globally optimal layer-wise ranks by relaxing the discrete singular-value truncation into a continuous optimization using the Fermi function; (2) \\textbf{PivGa}, an additional \\textit{lossless} compression of the low-rank factors that exploits the intrinsic gauge freedom in their parametrization.", "AI": {"tldr": "This paper improves LLM compression using two physics-inspired methods: FermiGrad for optimizing layer-wise ranks and PivGa for additional compression.", "motivation": "Given the computational demands of LLMs, efficient compression techniques are necessary. Low-rank decompositions like SVD show promise, but challenges remain in optimizing ranks and eliminating parameter redundancy.", "method": "The authors propose two methods: FermiGrad, a gradient-descent algorithm leveraging the Fermi function for optimizing layer-wise ranks, and PivGa, a lossless compression method that utilizes gauge freedom in low-rank factors.", "result": "The proposed methods optimize SVD-based compression by addressing rank selection and redundancy issues, improving both efficiency and performance.", "conclusion": "The physics-inspired methods provide effective solutions for LLM compression, making these models more computationally accessible."}}
{"id": "2512.03245", "pdf": "https://arxiv.org/pdf/2512.03245", "abs": "https://arxiv.org/abs/2512.03245", "authors": ["Liying Lu", "Rapha\u00ebl Achddou", "Sabine S\u00fcsstrunk"], "title": "2-Shots in the Dark: Low-Light Denoising with Minimal Data Acquisition", "categories": ["cs.CV"], "comment": null, "summary": "Raw images taken in low-light conditions are very noisy due to low photon count and sensor noise. Learning-based denoisers have the potential to reconstruct high-quality images. For training, however, these denoisers require large paired datasets of clean and noisy images, which are difficult to collect. Noise synthesis is an alternative to large-scale data acquisition: given a clean image, we can synthesize a realistic noisy counterpart. In this work, we propose a general and practical noise synthesis method that requires only one single noisy image and one single dark frame per ISO setting. We represent signal-dependent noise with a Poisson distribution and introduce a Fourier-domain spectral sampling algorithm to accurately model signal-independent noise. The latter generates diverse noise realizations that maintain the spatial and statistical properties of real sensor noise. As opposed to competing approaches, our method neither relies on simplified parametric models nor on large sets of clean-noisy image pairs. Our synthesis method is not only accurate and practical, it also leads to state-of-the-art performances on multiple low-light denoising benchmarks.", "AI": {"tldr": "The paper presents a novel noise synthesis method requiring minimal data to generate realistic noisy images for training denoisers, achieving state-of-the-art results in low-light denoising benchmarks.", "motivation": "Existing learning-based denoisers require large paired datasets of clean and noisy images for training, which are hard to collect. Noise synthesis offers a more efficient alternative.", "method": "The authors propose a noise synthesis method involving Poisson distribution to model signal-dependent noise and a Fourier-domain spectral sampling algorithm for signal-independent noise using just one noisy image and one dark frame per ISO setting.", "result": "The proposed method generates realistic noisy images and achieves state-of-the-art performance on multiple low-light denoising benchmarks while avoiding the need for large paired datasets.", "conclusion": "The method provides a practical and accurate solution for noise synthesis, overcoming limitations of previous approaches and significantly contributing to low-light image denoising."}}
{"id": "2512.03059", "pdf": "https://arxiv.org/pdf/2512.03059", "abs": "https://arxiv.org/abs/2512.03059", "authors": ["Jiaju Qi", "Lei Lei", "Thorsteinn Jonsson", "Dusit Niyato"], "title": "Safe and Sustainable Electric Bus Charging Scheduling with Constrained Hierarchical DRL", "categories": ["cs.LG"], "comment": null, "summary": "The integration of Electric Buses (EBs) with renewable energy sources such as photovoltaic (PV) panels is a promising approach to promote sustainable and low-carbon public transportation. However, optimizing EB charging schedules to minimize operational costs while ensuring safe operation without battery depletion remains challenging - especially under real-world conditions, where uncertainties in PV generation, dynamic electricity prices, variable travel times, and limited charging infrastructure must be accounted for. In this paper, we propose a safe Hierarchical Deep Reinforcement Learning (HDRL) framework for solving the EB Charging Scheduling Problem (EBCSP) under multi-source uncertainties. We formulate the problem as a Constrained Markov Decision Process (CMDP) with options to enable temporally abstract decision-making. We develop a novel HDRL algorithm, namely Double Actor-Critic Multi-Agent Proximal Policy Optimization Lagrangian (DAC-MAPPO-Lagrangian), which integrates Lagrangian relaxation into the Double Actor-Critic (DAC) framework. At the high level, we adopt a centralized PPO-Lagrangian algorithm to learn safe charger allocation policies. At the low level, we incorporate MAPPO-Lagrangian to learn decentralized charging power decisions under the Centralized Training and Decentralized Execution (CTDE) paradigm. Extensive experiments with real-world data demonstrate that the proposed approach outperforms existing baselines in both cost minimization and safety compliance, while maintaining fast convergence speed.", "AI": {"tldr": "The paper discusses a framework for Electric Bus charging scheduling that integrates renewable energy sources while minimizing costs and addressing safety under uncertainty using hierarchical deep reinforcement learning.", "motivation": "Reducing operational costs for Electric Buses under uncertainties like PV generation and dynamic electricity prices while ensuring safety is challenging yet necessary to promote sustainable transportation.", "method": "The study formulates the scheduling problem as a Constrained Markov Decision Process and proposes a hierarchical deep reinforcement learning algorithm combining centralized and decentralized decision-making using novel actor-critic methods.", "result": "Extensive experiments using real-world data show the proposed framework performs better than existing methods in cost reduction and safety compliance while maintaining fast learning convergence.", "conclusion": "The proposed HDRL framework effectively handles multi-source uncertainties for EB charging scheduling, achieving sustainable and safe transport operations with optimized performance."}}
{"id": "2512.03429", "pdf": "https://arxiv.org/pdf/2512.03429", "abs": "https://arxiv.org/abs/2512.03429", "authors": ["Raul Steinmetz", "Fabio Demo Rosa", "Victor Augusto Kich", "Jair Augusto Bottega", "Ricardo Bedin Grando", "Daniel Fernando Tello Gamarra"], "title": "World Models for Autonomous Navigation of Terrestrial Robots from LIDAR Observations", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted for publication in the Journal of Intelligent and Fuzzy Systems", "summary": "Autonomous navigation of terrestrial robots using Reinforcement Learning (RL) from LIDAR observations remains challenging due to the high dimensionality of sensor data and the sample inefficiency of model-free approaches. Conventional policy networks struggle to process full-resolution LIDAR inputs, forcing prior works to rely on simplified observations that reduce spatial awareness and navigation robustness. This paper presents a novel model-based RL framework built on top of the DreamerV3 algorithm, integrating a Multi-Layer Perceptron Variational Autoencoder (MLP-VAE) within a world model to encode high-dimensional LIDAR readings into compact latent representations. These latent features, combined with a learned dynamics predictor, enable efficient imagination-based policy optimization. Experiments on simulated TurtleBot3 navigation tasks demonstrate that the proposed architecture achieves faster convergence and higher success rate compared to model-free baselines such as SAC, DDPG, and TD3. It is worth emphasizing that the DreamerV3-based agent attains a 100% success rate across all evaluated environments when using the full dataset of the Turtlebot3 LIDAR (360 readings), while model-free methods plateaued below 85%. These findings demonstrate that integrating predictive world models with learned latent representations enables more efficient and robust navigation from high-dimensional sensory data.", "AI": {"tldr": "The paper introduces a model-based reinforcement learning framework utilizing a DreamerV3-based algorithm with a Multi-Layer Perceptron Variational Autoencoder (MLP-VAE) to enable efficient navigation of terrestrial robots from high-dimensional LIDAR data.", "motivation": "To address challenges in autonomous robot navigation caused by the high dimensionality of LIDAR sensor data and inefficiency of model-free reinforcement learning approaches.", "method": "The study uses DreamerV3-based model-based RL integrated with a Multi-Layer Perceptron Variational Autoencoder to compress high-dimensional LIDAR data into latent representations, coupled with a learned dynamics predictor for imagination-based policy optimization.", "result": "The proposed framework exhibits faster convergence and higher navigation success rates compared to model-free baselines, achieving a 100% success rate in navigation tasks using full LIDAR datasets, outperforming methods such as SAC, DDPG, and TD3.", "conclusion": "The integration of predictive world models and latent representations significantly enhances the efficiency and robustness of navigating terrestrial robots using high-dimensional sensory data."}}
{"id": "2512.04054", "pdf": "https://arxiv.org/pdf/2512.04054", "abs": "https://arxiv.org/abs/2512.04054", "authors": ["Olasupo Ajayi", "Ryan Grant"], "title": "A Chronological Analysis of the Evolution of SmartNICs", "categories": ["cs.DC", "cs.NI"], "comment": "8 pages, 13 figures, 2 tables, Southern Africa Telecommunication Networks and Applications Conference (SATNAC) 2025", "summary": "Network Interface Cards (NICs) are one of the key enablers of the modern Internet. They serve as gateways for connecting computing devices to networks for the exchange of data with other devices. Recently, the pervasive nature of Internet-enabled devices coupled with the growing demands for faster network access have necessitated the enhancement of NICs to Smart NICs (SNICs), capable of processing enormous volumes of data at near real-time speed. However, despite their popularity, the exact use and applicability of SNICs remains an ongoing debate. These debates are exacerbated by the incorporation of accelerators into SNIC, allowing them to relieve their host's CPUs of various tasks. In this work, we carry out a chronological analysis of SNICs, using 370 articles published in the past 15 years, from 2010 to 2024, to gain some insight into SNICs; and shed some light on their evolution, manufacturers, use cases, and application domains.", "AI": {"tldr": "The paper analyzes Smart NICs (SNICs) by reviewing 370 articles from the past 15 years to explore their evolution, use cases, manufacturers, and applications in addressing increasing network demands.", "motivation": "The growing demand for faster network access and the need to handle enormous volumes of data in near real-time have pushed the evolution of Network Interface Cards (NICs) to Smart NICs (SNICs), which integrate accelerators to offload CPU tasks.", "method": "Using a chronological review of 370 articles published between 2010 and 2024, the authors study and analyze the development and applications of SNICs.", "result": "The study offers insights into the evolution of Smart NICs, their manufacturers, specific use cases, and diverse application domains.", "conclusion": "Smart NICs play a critical role in modern networking by enhancing speed and efficiency, but their exact applicability and potential remain debated. This study provides a deeper understanding of SNIC technology."}}
{"id": "2512.03549", "pdf": "https://arxiv.org/pdf/2512.03549", "abs": "https://arxiv.org/abs/2512.03549", "authors": ["Yuki Orimo", "Iori Kurata", "Hodaka Mori", "Ryuhei Okuno", "Ryohto Sawada", "Daisuke Okanohara"], "title": "PARC: An Autonomous Self-Reflective Coding Agent for Robust Execution of Long-Horizon Tasks", "categories": ["cs.AI"], "comment": null, "summary": "We introduce PARC, a coding agent for the autonomous and robust execution of long-horizon computational tasks. PARC is built on a hierarchical multi-agent architecture incorporating task planning, execution, and a mechanism that evaluates its own actions and their outcomes from an independent context and provides feedback, namely self-assessment and self-feedback. This design enables PARC to detect and correct high-level strategic errors and sustain progress without human intervention. We evaluate PARC across computational science and data science tasks. In materials science, it autonomously reproduces key results from studies on lithium-ion conduction and alloy segregation. In particular, it coordinates dozens of parallel simulation tasks, each requiring roughly 43 hours of computation, managing orchestration, monitoring, and error correction end-to-end. In Kaggle-based experiments, starting from minimal natural-language instructions, PARC conducts data analysis and implements search strategies, producing solutions competitive with human-engineered baselines. These results highlight the potential of integrating a hierarchical multi-agent system with self-assessment and self-feedback to enable AI systems capable of independent, large-scale scientific and analytical work.", "AI": {"tldr": "PARC is a hierarchical multi-agent coding system capable of autonomously executing long computational tasks with self-assessment and self-feedback mechanisms.", "motivation": "Advancing autonomous AI systems to independently perform complex, large-scale computational and analytical tasks without human intervention.", "method": "PARC employs a hierarchical multi-agent system that includes task planning, execution, and self-assessment capabilities for feedback and error correction.", "result": "PARC successfully reproduced major results in computational science (materials science) and conducted competitive data science analysis, coordinating extensive simulations and adapting independently.", "conclusion": "The integration of hierarchical multi-agent systems with self-assessment mechanisms shows significant potential for enabling autonomous AI to perform independent, complex scientific tasks effectively."}}
{"id": "2512.03334", "pdf": "https://arxiv.org/pdf/2512.03334", "abs": "https://arxiv.org/abs/2512.03334", "authors": ["Nemika Tyagi", "Nelvin Licona Guevara", "Olga Kellert"], "title": "Modeling Topics and Sociolinguistic Variation in Code-Switched Discourse: Insights from Spanish-English and Spanish-Guaran\u00ed", "categories": ["cs.CL"], "comment": "10 pages, 4 figures", "summary": "This study presents an LLM-assisted annotation pipeline for the sociolinguistic and topical analysis of bilingual discourse in two typologically distinct contexts: Spanish-English and Spanish-Guaran\u00ed. Using large language models, we automatically labeled topic, genre, and discourse-pragmatic functions across a total of 3,691 code-switched sentences, integrated demographic metadata from the Miami Bilingual Corpus, and enriched the Spanish-Guaran\u00ed dataset with new topic annotations. The resulting distributions reveal systematic links between gender, language dominance, and discourse function in the Miami data, and a clear diglossic division between formal Guaran\u00ed and informal Spanish in Paraguayan texts. These findings replicate and extend earlier interactional and sociolinguistic observations with corpus-scale quantitative evidence. The study demonstrates that large language models can reliably recover interpretable sociolinguistic patterns traditionally accessible only through manual annotation, advancing computational methods for cross-linguistic and low-resource bilingual research.", "AI": {"tldr": "This paper proposes a pipeline that uses large language models (LLMs) for automatic annotation and sociolinguistic analysis of bilingual speech in Spanish-English and Spanish-Guaran\u00ed contexts.", "motivation": "To advance the study of bilingual discourse by automating the annotation process with LLMs, thus making sociolinguistic analysis more scalable and applicable to low-resource languages.", "method": "The paper employs large language models to label topics, genres, and discourse-pragmatic functions in bilingual data from two corpora, integrates demographic metadata, and enriches datasets with new annotations.", "result": "Systematic sociolinguistic patterns, such as links between gender and language use in Miami, and diglossic language divisions in Paraguayan texts, were uncovered and confirmed with corpus-scale evidence.", "conclusion": "LLMs are effective tools for sociolinguistic annotation, enabling scaling and reliability in cross-linguistic and under-resourced bilingual discourse analysis."}}
{"id": "2512.03420", "pdf": "https://arxiv.org/pdf/2512.03420", "abs": "https://arxiv.org/abs/2512.03420", "authors": ["Kang Yang", "Yunhang Zhang", "Zichuan Li", "GuanHong Tao", "Jun Xu", "XiaoJing Liao"], "title": "HarnessAgent: Scaling Automatic Fuzzing Harness Construction with Tool-Augmented LLM Pipelines", "categories": ["cs.CR", "cs.SE"], "comment": null, "summary": "Large language model (LLM)-based techniques have achieved notable progress in generating harnesses for program fuzzing. However, applying them to arbitrary functions (especially internal functions) \\textit{at scale} remains challenging due to the requirement of sophisticated contextual information, such as specification, dependencies, and usage examples. State-of-the-art methods heavily rely on static or incomplete context provisioning, causing failure of generating functional harnesses. Furthermore, LLMs tend to exploit harness validation metrics, producing plausible yet logically useless code. % Therefore, harness generation across large and diverse projects continues to face challenges in reliable compilation, robust code retrieval, and comprehensive validation.\n  To address these challenges, we present HarnessAgent, a tool-augmented agentic framework that achieves fully automated, scalable harness construction over hundreds of OSS-Fuzz targets. HarnessAgent introduces three key innovations: 1) a rule-based strategy to identify and minimize various compilation errors; 2) a hybrid tool pool for precise and robust symbol source code retrieval; and 3) an enhanced harness validation pipeline that detects fake definitions. We evaluate HarnessAgent on 243 target functions from OSS-Fuzz projects (65 C projects and 178 C++ projects). It improves the three-shot success rate by approximately 20\\% compared to state-of-the-art techniques, reaching 87\\% for C and 81\\% for C++. Our one-hour fuzzing results show that more than 75\\% of the harnesses generated by HarnessAgent increase the target function coverage, surpassing the baselines by over 10\\%. In addition, the hybrid tool-pool system of HarnessAgent achieves a response rate of over 90\\% for source code retrieval, outperforming Fuzz Introspector by more than 30\\%.", "AI": {"tldr": "HarnessAgent is a scalable framework addressing challenges in LLM-based program fuzzing harness generation for OSS-Fuzz targets. It automates error minimization, code retrieval, and validation, significantly improving success and coverage metrics.", "motivation": "To overcome the limitations in applying LLM-based harness generation techniques at scale, especially for internal functions requiring comprehensive contextual data. Current methods fail due to reliance on static context and vulnerability to validation exploitation.", "method": "HarnessAgent implements a rule-based strategy for error minimization, utilizes a hybrid tool pool for retrieving precise source code, and enhances validation pipelines to detect fabricated definitions.", "result": "HarnessAgent achieves an 87% success rate for C functions and 81% for C++ functions, surpassing state-of-the-art benchmarks by ~20%. It improves function coverage metrics in one-hour fuzzing tests by over 10%, and its code retrieval system achieves a 90% response rate, outperforming alternatives by 30%.", "conclusion": "HarnessAgent significantly improves the reliability and scalability of harness generation in OSS-Fuzz projects, making it a robust offering for program fuzzing efforts."}}
{"id": "2512.03081", "pdf": "https://arxiv.org/pdf/2512.03081", "abs": "https://arxiv.org/abs/2512.03081", "authors": ["Zhewen Hou", "Jiajin Sun", "Subashree Venkatasubramanian", "Peter Jin", "Shuolin Li", "Tian Zheng"], "title": "Calibrating Geophysical Predictions under Constrained Probabilistic Distributions", "categories": ["physics.ao-ph", "cs.LG", "stat.ML"], "comment": null, "summary": "Machine learning (ML) has shown significant promise in studying complex geophysical dynamical systems, including turbulence and climate processes. Such systems often display sensitive dependence on initial conditions, reflected in positive Lyapunov exponents, where even small perturbations in short-term forecasts can lead to large deviations in long-term outcomes. Thus, meaningful inference requires not only accurate short-term predictions, but also consistency with the system's long-term attractor that is captured by the marginal distribution of state variables. Existing approaches attempt to address this challenge by incorporating spatial and temporal dependence, but these strategies become impractical when data are extremely sparse. In this work, we show that prior knowledge of marginal distributions offers valuable complementary information to short-term observations, motivating a distribution-informed learning framework. We introduce a calibration algorithm based on normalization and the Kernelized Stein Discrepancy (KSD) to enhance ML predictions. The method here employs KSD within a reproducing kernel Hilbert space to calibrate model outputs, improving their fidelity to known physical distributions. This not only sharpens pointwise predictions but also enforces consistency with non-local statistical structures rooted in physical principles. Through synthetic experiments-spanning offline climatological CO2 fluxes and online quasi-geostrophic flow simulations-we demonstrate the robustness and broad utility of the proposed framework.", "AI": {"tldr": "This study proposes a distribution-informed machine learning framework for improving predictions in geophysical systems with sparse data, using a kernel-based calibration method.", "motivation": "The paper addresses the challenge of improving ML predictions for geophysical systems, which require accuracy for both short-term forecasts and long-term statistical behavior, even where data is sparse.", "method": "A calibration algorithm leveraging prior distributions and the Kernelized Stein Discrepancy is introduced to enhance both pointwise predictions and alignment with the system\u2019s long-term statistical structures.", "result": "Synthetic experiments on CO2 flux data and quasi-geostrophic flow simulations demonstrate the improved prediction robustness and applicability of the framework.", "conclusion": "The proposed distribution-informed learning method effectively integrates prior knowledge to enhance ML predictions in complex geophysical systems, ensuring better consistency with physical principles."}}
{"id": "2512.03247", "pdf": "https://arxiv.org/pdf/2512.03247", "abs": "https://arxiv.org/abs/2512.03247", "authors": ["Haitian Zheng", "Yuan Yao", "Yongsheng Yu", "Yuqian Zhou", "Jiebo Luo", "Zhe Lin"], "title": "PixPerfect: Seamless Latent Diffusion Local Editing with Discriminative Pixel-Space Refinement", "categories": ["cs.CV"], "comment": "Published in the Thirty-ninth Annual Conference on Neural Information Processing Systems (NeurIPS 2025)", "summary": "Latent Diffusion Models (LDMs) have markedly advanced the quality of image inpainting and local editing. However, the inherent latent compression often introduces pixel-level inconsistencies, such as chromatic shifts, texture mismatches, and visible seams along editing boundaries. Existing remedies, including background-conditioned latent decoding and pixel-space harmonization, usually fail to fully eliminate these artifacts in practice and do not generalize well across different latent representations or tasks. We introduce PixPerfect, a pixel-level refinement framework that delivers seamless, high-fidelity local edits across diverse LDM architectures and tasks. PixPerfect leverages (i) a differentiable discriminative pixel space that amplifies and suppresses subtle color and texture discrepancies, (ii) a comprehensive artifact simulation pipeline that exposes the refiner to realistic local editing artifacts during training, and (iii) a direct pixel-space refinement scheme that ensures broad applicability across diverse latent representations and tasks. Extensive experiments on inpainting, object removal, and insertion benchmarks demonstrate that PixPerfect substantially enhances perceptual fidelity and downstream editing performance, establishing a new standard for robust and high-fidelity localized image editing.", "AI": {"tldr": "PixPerfect is a framework for improving latent diffusion models by addressing pixel-level inconsistencies in image editing tasks through advanced pixel-space refinement strategies.", "motivation": "Current latent diffusion models for image editing exhibit pixel-level inconsistencies like color shifts and texture mismatches, which existing solutions fail to universally and effectively resolve.", "method": "PixPerfect employs a differentiable discriminative pixel-space, artifact simulation pipeline, and a pixel-space refinement scheme to enhance image editing precision across various tasks and architectures.", "result": "Experiments on tasks like inpainting and object removal show that PixPerfect significantly improves perceptual fidelity and performance, offering seamless edits.", "conclusion": "PixPerfect sets a new standard for accurate, robust, and high-fidelity localized image editing, demonstrating generalization across tasks and models."}}
{"id": "2512.03060", "pdf": "https://arxiv.org/pdf/2512.03060", "abs": "https://arxiv.org/abs/2512.03060", "authors": ["Jing Pan", "Li Shi", "Paul Lo"], "title": "A Large Scale Heterogeneous Treatment Effect Estimation Framework and Its Applications of Users' Journey at Snap", "categories": ["cs.LG", "stat.AP", "stat.ME"], "comment": null, "summary": "Heterogeneous Treatment Effect (HTE) and Conditional Average Treatment Effect (CATE) models relax the assumption that treatment effects are the same for every user. We present a large scale industrial framework for estimating HTE using experimental data from hundreds of millions of Snapchat users. By combining results across many experiments, the framework uncovers latent user characteristics that were previously unmeasurable and produces stable treatment effect estimates at scale.\n  We describe the core components that enabled this system, including experiment selection, base learner design, and incremental training. We also highlight two applications: user influenceability to ads and user sensitivity to ads. An online A/B test using influenceability scores for targeting showed an improvement on key business metrics that is more than six times larger than what is typically considered significant.", "AI": {"tldr": "This paper introduces a scalable framework to estimate Heterogeneous Treatment Effects (HTE) using Snapchat experimental data, allowing for precise treatment effect estimates across diverse user groups.", "motivation": "To address the limitation of uniform treatment effect assumptions by developing a system that captures HTE across millions of users, thus revealing complex and latent user characteristics.", "method": "The framework integrates experiment selection, base learner design, and incremental training, combining results from numerous experiments to identify HTE.", "result": "It enabled actionable insights such as user influenceability and sensitivity to ads. An A/B test showed improved business metrics by using influenceability scores for targeting, yielding results over 6 times greater than typical significance thresholds.", "conclusion": "The proposed system effectively identifies and leverages user-level differences to optimize business outcomes, showcasing its potential for large-scale personalization in advertising strategies."}}
{"id": "2512.03444", "pdf": "https://arxiv.org/pdf/2512.03444", "abs": "https://arxiv.org/abs/2512.03444", "authors": ["Davood Soleymanzadeh", "Xiao Liang", "Minghui Zheng"], "title": "PerFACT: Motion Policy with LLM-Powered Dataset Synthesis and Fusion Action-Chunking Transformers", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "Deep learning methods have significantly enhanced motion planning for robotic manipulators by leveraging prior experiences within planning datasets. However, state-of-the-art neural motion planners are primarily trained on small datasets collected in manually generated workspaces, limiting their generalizability to out-of-distribution scenarios. Additionally, these planners often rely on monolithic network architectures that struggle to encode critical planning information. To address these challenges, we introduce Motion Policy with Dataset Synthesis powered by large language models (LLMs) and Fusion Action-Chunking Transformers (PerFACT), which incorporates two key components. Firstly, a novel LLM-powered workspace generation method, MotionGeneralizer, enables large-scale planning data collection by producing a diverse set of semantically feasible workspaces. Secondly, we introduce Fusion Motion Policy Networks (MpiNetsFusion), a generalist neural motion planner that uses a fusion action-chunking transformer to better encode planning signals and attend to multiple feature modalities. Leveraging MotionGeneralizer, we collect 3.5M trajectories to train and evaluate MpiNetsFusion against state-of-the-art planners, which shows that the proposed MpiNetsFusion can plan several times faster on the evaluated tasks.", "AI": {"tldr": "The paper introduces PerFACT, a motion planning system for robotic arms using LLM-generated workspaces (MotionGeneralizer) and a new neural planner (MpiNetsFusion) to improve speed and versatility.", "motivation": "State-of-the-art neural motion planners have limited generalizability due to reliance on small, manually generated datasets and monolithic architectures.", "method": "The study proposes MotionGeneralizer for AI-driven workspace generation and MpiNetsFusion, which applies a fusion action-chunking transformer to process multiple modalities efficiently.", "result": "By training with 3.5M trajectories, MpiNetsFusion outperforms existing planners, demonstrating several times faster task completion.", "conclusion": "The proposed methods enhance motion planning by creating scalable, diverse datasets and improving information encoding, thus advancing neural motion planning capabilities."}}
{"id": "2512.03560", "pdf": "https://arxiv.org/pdf/2512.03560", "abs": "https://arxiv.org/abs/2512.03560", "authors": ["Gianni Molinari", "Fabio Ciravegna"], "title": "Reason-Plan-ReAct: A Reasoner-Planner Supervising a ReAct Executor for Complex Enterprise Tasks", "categories": ["cs.AI", "cs.MA"], "comment": "11 pages, 1 figure, 2 tables, Workshop AAAI 2026 agentic AI Benchmarks and Applications for Enterprise Tasks", "summary": "Despite recent advances, autonomous agents often struggle to solve complex tasks in enterprise domains that require coordinating multiple tools and processing diverse data sources. This struggle is driven by two main limitations. First, single-agent architectures enforce a monolithic plan-execute loop, which directly causes trajectory instability. Second, the requirement to use local open-weight models for data privacy introduces smaller context windows leading to the rapid consumption of context from large tool outputs. To solve this problem we introduce RP-ReAct (Reasoner Planner-ReAct), a novel multi-agent approach that fundamentally decouples strategic planning from low-level execution to achieve superior reliability and efficiency. RP-ReAct consists of a Reasoner Planner Agent (RPA), responsible for planning each sub-step, continuously analysing the execution results using the strong reasoning capabilities of a Large Reasoning Model, and one or multiple Proxy-Execution Agent (PEA) that translates sub-steps into concrete tool interactions using a ReAct approach. Crucially, we incorporate a context-saving strategy within the PEA to mitigate context window overflow by managing large tool outputs via external storage and on-demand access. We evaluate RP-ReAct, on the challenging, multi-domain ToolQA benchmark using a diverse set of six open-weight reasoning models. Our empirical results show that RP-ReAct achieves superior performance and improved generalization ability over state-of-the-art baselines when addressing diverse complex tasks across the evaluated domains. Furthermore we establish the enhanced robustness and stability of our approach across different model scales, paving the way for effective and deployable agentic solutions for enterprises.", "AI": {"tldr": "RP-ReAct, a novel multi-agent framework, splits strategic planning and execution while using context-saving strategies to solve complex multi-domain problems effectively, overcoming challenges in current single-agent models.", "motivation": "Current autonomous agents face difficulties in enterprise tasks due to monolithic architecture causing instability, and privacy constraints leading to small context windows that overload with large tool outputs.", "method": "RP-ReAct integrates a Reasoner Planner Agent (for strategic planning with a reasoning model) and Proxy-Execution Agents (for task execution using a ReAct approach), incorporating context-saving to manage large outputs.", "result": "RP-ReAct outperforms state-of-the-art baselines in multi-domain ToolQA benchmarks, generalizing better and showing robust performance across various reasoning model scales.", "conclusion": "RP-ReAct provides an effective, reliable framework for solving complex, enterprise-level tasks, overcoming key limitations of traditional single-agent architectures."}}
{"id": "2512.03340", "pdf": "https://arxiv.org/pdf/2512.03340", "abs": "https://arxiv.org/abs/2512.03340", "authors": ["Rohan Charudatt Salvi", "Chirag Chawla", "Dhruv Jain", "Swapnil Panigrahi", "Md Shad Akhtar", "Shweta Yadav"], "title": "PERCS: Persona-Guided Controllable Biomedical Summarization Dataset", "categories": ["cs.CL"], "comment": "9 pages, 4 figures, 6 tables", "summary": "Automatic medical text simplification plays a key role in improving health literacy by making complex biomedical research accessible to diverse readers. However, most existing resources assume a single generic audience, overlooking the wide variation in medical literacy and information needs across user groups. To address this limitation, we introduce PERCS (Persona-guided Controllable Summarization), a dataset of biomedical abstracts paired with summaries tailored to four personas: Laypersons, Premedical Students, Non-medical Researchers, and Medical Experts. These personas represent different levels of medical literacy and information needs, emphasizing the need for targeted, audience-specific summarization. Each summary in PERCS was reviewed by physicians for factual accuracy and persona alignment using a detailed error taxonomy. Technical validation shows clear differences in readability, vocabulary, and content depth across personas. Along with describing the dataset, we benchmark four large language models on PERCS using automatic evaluation metrics that assess comprehensiveness, readability, and faithfulness, establishing baseline results for future research. The dataset, annotation guidelines, and evaluation materials are publicly available to support research on persona-specific communication and controllable biomedical summarization.", "AI": {"tldr": "PERCS (Persona-guided Controllable Summarization) is a biomedical dataset that provides summaries tailored to four diverse audiences, aiming to improve health literacy.", "motivation": "Simplify complex medical content for varied readers, addressing diverse medical literacy levels and information needs.", "method": "Developed a dataset (PERCS) with biomedical abstracts and persona-specific summaries reviewed by physicians. Benchmarked language models with metrics for readability, comprehensiveness, and factual accuracy.", "result": "Demonstrated distinct readability and depth differences in summaries, showing the effectiveness of tailoring content to various audiences.", "conclusion": "PERCS supports advancements in persona-specific summarization and biomedical communication, with resources available for further research."}}
{"id": "2512.03635", "pdf": "https://arxiv.org/pdf/2512.03635", "abs": "https://arxiv.org/abs/2512.03635", "authors": ["Dustin Bryant", "Jim Woodcock", "Simon Foster"], "title": "Formal Analysis of the Sigmoid Function and Formal Proof of the Universal Approximation Theorem", "categories": ["cs.LO", "cs.SE"], "comment": "1 figure", "summary": "This paper presents a formalized analysis of the sigmoid function and a fully mechanized proof of the Universal Approximation Theorem (UAT) in Isabelle/HOL, a higher-order logic theorem prover. The sigmoid function plays a fundamental role in neural networks; yet, its formal properties, such as differentiability, higher-order derivatives, and limit behavior, have not previously been comprehensively mechanized in a proof assistant. We present a rigorous formalization of the sigmoid function, proving its monotonicity, smoothness, and higher-order derivatives. We provide a constructive proof of the UAT, demonstrating that neural networks with sigmoidal activation functions can approximate any continuous function on a compact interval. Our work identifies and addresses gaps in Isabelle/HOL's formal proof libraries and introduces simpler methods for reasoning about the limits of real functions. By exploiting theorem proving for AI verification, our work enhances trust in neural networks and contributes to the broader goal of verified and trustworthy machine learning.", "AI": {"tldr": "The paper formalizes sigmoid function analysis and mechanizes the proof of the Universal Approximation Theorem (UAT) in Isabelle/HOL, enhancing neural network verification.", "motivation": "To improve trust in neural networks by rigorously formalizing the sigmoid function and mechanizing the proof of UAT in a theorem prover.", "method": "The authors used Isabelle/HOL to formalize the sigmoid function's properties and provide a mechanized constructive proof of UAT, addressing gaps in existing formal proof libraries.", "result": "The paper proves monotonicity, smoothness, and higher-order derivatives of the sigmoid function and demonstrates that neural networks with sigmoidal activations can approximate any continuous function on compact intervals.", "conclusion": "The work advances trustworthy machine learning by enhancing formal verification tools and addressing gaps in proof libraries, thereby contributing to AI verification."}}
{"id": "2512.03107", "pdf": "https://arxiv.org/pdf/2512.03107", "abs": "https://arxiv.org/abs/2512.03107", "authors": ["Mainak Singha"], "title": "Detecting AI Hallucinations in Finance: An Information-Theoretic Method Cuts Hallucination Rate by 92%", "categories": ["cs.LG", "cs.CL", "q-fin.CP", "stat.ML"], "comment": "17 pages, 7 figures. Information-theoretic, hallucination detector for financial application. Feedback from researchers and practitioners is welcome", "summary": "Large language models (LLMs) produce fluent but unsupported answers - hallucinations - limiting safe deployment in high-stakes domains. We propose ECLIPSE, a framework that treats hallucination as a mismatch between a model's semantic entropy and the capacity of available evidence. We combine entropy estimation via multi-sample clustering with a novel perplexity decomposition that measures how models use retrieved evidence. We prove that under mild conditions, the resulting entropy-capacity objective is strictly convex with a unique stable optimum. We evaluate on a controlled financial question answering dataset with GPT-3.5-turbo (n=200 balanced samples with synthetic hallucinations), where ECLIPSE achieves ROC AUC of 0.89 and average precision of 0.90, substantially outperforming a semantic entropy-only baseline (AUC 0.50). A controlled ablation with Claude-3-Haiku, which lacks token-level log probabilities, shows AUC dropping to 0.59 with coefficient magnitudes decreasing by 95% - demonstrating that ECLIPSE is a logprob-native mechanism whose effectiveness depends on calibrated token-level uncertainties. The perplexity decomposition features exhibit the largest learned coefficients, confirming that evidence utilization is central to hallucination detection. We position this work as a controlled mechanism study; broader validation across domains and naturally occurring hallucinations remains future work.", "AI": {"tldr": "The paper introduces ECLIPSE, a framework to address hallucinations in large language models (LLMs) by evaluating semantic entropy against the capacity of evidence. It proves the effectiveness of ECLIPSE in detecting hallucinations.", "motivation": "To address the issue of hallucinations in LLMs, which produce unsupported answers, limiting their use in high-stakes domains.", "method": "ECLIPSE uses semantic entropy estimation via multi-sample clustering and a novel perplexity decomposition to measure evidence utilization. It ensures strict convexity with a unique stable optimum under certain conditions.", "result": "In experiments using a financial QA dataset with GPT-3.5-turbo, ECLIPSE achieved superior performance (ROC AUC of 0.89 and precision of 0.90) compared to baselines. Its effectiveness relies on calibrated token-level uncertainties.", "conclusion": "ECLIPSE shows promise as a mechanism to detect hallucinations in LLMs, especially when calibrated uncertainties are accessible. Broader validation across other domains is needed in future work."}}
{"id": "2512.03257", "pdf": "https://arxiv.org/pdf/2512.03257", "abs": "https://arxiv.org/abs/2512.03257", "authors": ["Mark Moussa", "Andre Williams", "Seth Roffe", "Douglas Morton"], "title": "PyroFocus: A Deep Learning Approach to Real-Time Wildfire Detection in Multispectral Remote Sensing Imagery", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Rapid and accurate wildfire detection is crucial for emergency response and environmental management. In airborne and spaceborne missions, real-time algorithms must distinguish between no fire, active fire, and post-fire conditions, and estimate fire intensity. Multispectral and hyperspectral thermal imagers provide rich spectral information, but high data dimensionality and limited onboard resources make real-time processing challenging. As wildfires increase in frequency and severity, the need for low-latency and computationally efficient onboard detection methods is critical.\n  We present a systematic evaluation of multiple deep learning architectures, including custom Convolutional Neural Networks (CNNs) and Transformer-based models, for multi-class fire classification. We also introduce PyroFocus, a two-stage pipeline that performs fire classification followed by fire radiative power (FRP) regression or segmentation to reduce inference time and computational cost for onboard deployment. Using data from NASA's MODIS/ASTER Airborne Simulator (MASTER), which is similar to a next-generation fire detection sensor, we compare accuracy, inference latency, and resource efficiency.\n  Experimental results show that the proposed two-stage pipeline achieves strong trade-offs between speed and accuracy, demonstrating significant potential for real-time edge deployment in future wildfire monitoring missions.", "AI": {"tldr": "The paper introduces 'PyroFocus,' a two-stage pipeline combining fire classification and radiative power estimation for real-time wildfire detection using deep learning models. It optimizes accuracy and speed for edge deployment.", "motivation": "The growing frequency and severity of wildfires demand improved, low-latency detection methods for airborne and spaceborne missions. Current challenges include the high dimensionality of sensor data and limited onboard computational resources.", "method": "The study systematically evaluates several deep learning models, such as CNNs and Transformer-based architectures, for fire classification. It also proposes PyroFocus, a two-stage pipeline designed for efficiency, using data from NASA's MASTER sensor for validation.", "result": "The proposed PyroFocus algorithm achieves a balance between computational speed and accuracy, showing its potential for real-time applications and wildfire monitoring missions.", "conclusion": "The results demonstrate that the PyroFocus pipeline can be deployed on edge devices, providing a fast and accurate solution for wildfire detection, addressing the increasing need due to more frequent wildfires."}}
{"id": "2512.03522", "pdf": "https://arxiv.org/pdf/2512.03522", "abs": "https://arxiv.org/abs/2512.03522", "authors": ["Gihyeon Lee", "Jungwoo Lee", "Juwon Kim", "Young-Sik Shin", "Younggun Cho"], "title": "MSG-Loc: Multi-Label Likelihood-based Semantic Graph Matching for Object-Level Global Localization", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted in IEEE Robotics and Automation Letters (2025)", "summary": "Robots are often required to localize in environments with unknown object classes and semantic ambiguity. However, when performing global localization using semantic objects, high semantic ambiguity intensifies object misclassification and increases the likelihood of incorrect associations, which in turn can cause significant errors in the estimated pose. Thus, in this letter, we propose a multi-label likelihood-based semantic graph matching framework for object-level global localization. The key idea is to exploit multi-label graph representations, rather than single-label alternatives, to capture and leverage the inherent semantic context of object observations. Based on these representations, our approach enhances semantic correspondence across graphs by combining the likelihood of each node with the maximum likelihood of its neighbors via context-aware likelihood propagation. For rigorous validation, data association and pose estimation performance are evaluated under both closed-set and open-set detection configurations. In addition, we demonstrate the scalability of our approach to large-vocabulary object categories in both real-world indoor scenes and synthetic environments.", "AI": {"tldr": "The paper proposes a framework for object-level global localization in robots by addressing the challenges of semantic ambiguity using multi-label likelihood-based semantic graph representations.", "motivation": "To address the challenge of semantic ambiguity and misclassifications in robot global localization when dealing with unknown object classes and environments.", "method": "A multi-label graph matching framework is introduced that leverages semantic context through multi-label graph representations and context-aware likelihood propagation.", "result": "The method is validated under closed-set and open-set configurations and shows scalability in real-world and synthetic environments with large object category vocabularies.", "conclusion": "Multi-label graph-based approaches improve semantic correspondence and reduce errors in object-level global localization under ambiguous conditions."}}
{"id": "2512.03287", "pdf": "https://arxiv.org/pdf/2512.03287", "abs": "https://arxiv.org/abs/2512.03287", "authors": ["Dario Fenoglio", "Mohan Li", "Davide Casnici", "Matias Laporte", "Shkurta Gashi", "Silvia Santini", "Martin Gjoreski", "Marc Langheinrich"], "title": "Multi-Frequency Federated Learning for Human Activity Recognition Using Head-Worn Sensors", "categories": ["cs.LG", "cs.DC"], "comment": "8 pages, 2024 International Conference on Intelligent Environments (IE), 2024", "summary": "Human Activity Recognition (HAR) benefits various application domains, including health and elderly care. Traditional HAR involves constructing pipelines reliant on centralized user data, which can pose privacy concerns as they necessitate the uploading of user data to a centralized server. This work proposes multi-frequency Federated Learning (FL) to enable: (1) privacy-aware ML; (2) joint ML model learning across devices with varying sampling frequency. We focus on head-worn devices (e.g., earbuds and smart glasses), a relatively unexplored domain compared to traditional smartwatch- or smartphone-based HAR. Results have shown improvements on two datasets against frequency-specific approaches, indicating a promising future in the multi-frequency FL-HAR task. The proposed network's implementation is publicly available for further research and development.", "AI": {"tldr": "This paper introduces multi-frequency Federated Learning (FL) to address privacy concerns and varying sampling rates in Human Activity Recognition (HAR) tasks, focusing on head-worn devices.", "motivation": "The authors aim to tackle privacy concerns in centralized HAR pipelines and explore HAR tasks on head-worn devices, which are less studied compared to common devices like smartphones and smartwatches.", "method": "The authors propose a multi-frequency Federated Learning (FL) approach that allows joint model learning across devices with different sampling frequencies while preserving user privacy.", "result": "The proposed method demonstrated improvements on two datasets when compared to frequency-specific methods, proving its effectiveness in multi-frequency FL-HAR tasks.", "conclusion": "FL presents a promising solution for privacy-aware collaborative HAR models across devices with different sampling rates, especially in head-worn device applications."}}
{"id": "2512.03571", "pdf": "https://arxiv.org/pdf/2512.03571", "abs": "https://arxiv.org/abs/2512.03571", "authors": ["Zhening Li", "Armando Solar-Lezama", "Yisong Yue", "Stephan Zheng"], "title": "EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths", "categories": ["cs.AI", "cs.LG", "cs.PL"], "comment": "65 pages, 2 figures, published in NeurIPS 2025", "summary": "We introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce \"probabilistic angelic nondeterminism\" (\"PAN\"), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.", "AI": {"tldr": "The paper introduces a new agent programming approach, PAN, which separates workflow logic from inference-time strategies and offers flexibility through the EnCompass Python framework.", "motivation": "To address the issue in agent programming where workflow logic and inference-time strategies are entangled, limiting flexibility and experimentation.", "method": "Proposes the PAN programming model and implements it in Python (EnCompass framework), allowing workflow programs to compile into a search space, enabling easy experimentation with strategies.", "result": "Demonstrated through three case studies showing improved agent reliability and seamless switching of strategies with minimal coding effort.", "conclusion": "PAN and the EnCompass framework simplify agent programming, enhancing flexibility, experimentation, and reliability of agents."}}
{"id": "2512.03343", "pdf": "https://arxiv.org/pdf/2512.03343", "abs": "https://arxiv.org/abs/2512.03343", "authors": ["Darshan Fofadiya"], "title": "Idea-Gated Transformers: Enforcing Semantic Coherence via Differentiable Vocabulary Pruning", "categories": ["cs.CL", "cs.AI"], "comment": "Code available at https://github.com/DarshanFofadiya/idea-gated-transformers/tree/main", "summary": "Autoregressive Language Models (LLMs) trained on Next-Token Prediction (NTP) often suffer from ``Topic Drift'' where the generation wanders away from the initial prompt due to a reliance on local associations rather than global planning \\citep{holtzman2019curious}. While scaling model size mitigates this \\citep{brown2020language}, the fundamental myopia of the NTP objective remains. In this work, we introduce the Idea-Gated Transformer, a novel architecture that separates semantic planning from syntactic generation. We introduce an auxiliary ``Idea Head'' trained to predict the bag-of-words distribution for a future context window, creating a latent ``Concept Vector'' that actively gates the main vocabulary during generation. We propose a differentiable gating mechanism that suppresses semantically irrelevant tokens, effectively pruning the search space in real-time. Experiments on WikiText-103 demonstrate that while the Idea-Gated model achieves comparable validation perplexity to a standard GPT-2 baseline, it exhibits significantly superior Domain Retention. Qualitative and quantitative analysis reveals that the gating mechanism successfully locks generation into specific semantic clusters (e.g., Finance, Science) and resists associative drift, offering a parameter-efficient path toward more controllable language modeling.", "AI": {"tldr": "Autoregressive Language Models (LLMs) often lose topic focus. The paper proposes the Idea-Gated Transformer which separates semantic planning and syntactic generation to combat topic drift.", "motivation": "Language models often drift away from the intended topic due to reliance on local associations in next-token prediction, and while larger models reduce this issue, the inherent limitation of the objective remains.", "method": "The paper introduces the Idea-Gated Transformer with an 'Idea Head' that predicts future context bag-of-words, creating a 'Concept Vector' to guide real-time generation using a differentiable gating mechanism.", "result": "The model achieves comparable validation perplexity to GPT-2 on WikiText-103 and demonstrates better Domain Retention, with semantic consistency and controlled generation observed.", "conclusion": "The Idea-Gated Transformer offers a parameter-efficient solution to improve topic consistency and controllability in language modeling by addressing semantic drift explicitly."}}
{"id": "2512.03971", "pdf": "https://arxiv.org/pdf/2512.03971", "abs": "https://arxiv.org/abs/2512.03971", "authors": ["Zunchen Huang", "Chenglu Jin"], "title": "Approximate Optimal Active Learning of Decision Trees", "categories": ["cs.LO", "cs.SE"], "comment": null, "summary": "We consider the problem of actively learning an unknown binary decision tree using only membership queries, a setting in which the learner must reason about a large hypothesis space while maintaining formal guarantees. Rather than enumerating candidate trees or relying on heuristic impurity or entropy measures, we encode the entire space of bounded-depth decision trees symbolically in SAT formulas. We propose a symbolic method for active learning of decision trees, in which approximate model counting is used to estimate the reduction of the hypothesis space caused by each potential query, enabling near-optimal query selection without full model enumeration. The resulting learner incrementally strengthens a CNF representation based on observed query outcomes, and approximate model counter ApproxMC is invoked to quantify the remaining version space in a sound and scalable manner. Additionally, when ApproxMC stagnates, a functional equivalence check is performed to verify that all remaining hypotheses are functionally identical. Experiments on decision trees show that the method reliably converges to the correct model using only a handful of queries, while retaining a rigorous SAT-based foundation suitable for formal analysis and verification.", "AI": {"tldr": "The paper proposes a SAT-based method for actively learning binary decision trees using approximate model counting for efficient query selection.", "motivation": "To develop a rigorous and scalable method for actively learning binary decision trees while maintaining formal guarantees in reasoning about large hypothesis spaces.", "method": "A symbolic active learning method using SAT formulas to encode hypothesis space, ApproxMC for approximate model counting, and functional equivalence checks for verification.", "result": "The proposed method reliably identifies the correct binary decision tree with minimal queries, offering scalability and formal SAT-based foundations.", "conclusion": "This approach provides an efficient and formally grounded method for active decision tree learning, demonstrating its reliability and scalability in experiments."}}
{"id": "2512.03109", "pdf": "https://arxiv.org/pdf/2512.03109", "abs": "https://arxiv.org/abs/2512.03109", "authors": ["Shuvom Sadhuka", "Drew Prinster", "Clara Fannjiang", "Gabriele Scalia", "Aviv Regev", "Hanchen Wang"], "title": "E-valuator: Reliable Agent Verifiers with Sequential Hypothesis Testing", "categories": ["cs.LG", "cs.AI", "stat.AP", "stat.ML"], "comment": null, "summary": "Agentic AI systems execute a sequence of actions, such as reasoning steps or tool calls, in response to a user prompt. To evaluate the success of their trajectories, researchers have developed verifiers, such as LLM judges and process-reward models, to score the quality of each action in an agent's trajectory. Although these heuristic scores can be informative, there are no guarantees of correctness when used to decide whether an agent will yield a successful output. Here, we introduce e-valuator, a method to convert any black-box verifier score into a decision rule with provable control of false alarm rates. We frame the problem of distinguishing successful trajectories (that is, a sequence of actions that will lead to a correct response to the user's prompt) and unsuccessful trajectories as a sequential hypothesis testing problem. E-valuator builds on tools from e-processes to develop a sequential hypothesis test that remains statistically valid at every step of an agent's trajectory, enabling online monitoring of agents over arbitrarily long sequences of actions. Empirically, we demonstrate that e-valuator provides greater statistical power and better false alarm rate control than other strategies across six datasets and three agents. We additionally show that e-valuator can be used for to quickly terminate problematic trajectories and save tokens. Together, e-valuator provides a lightweight, model-agnostic framework that converts verifier heuristics into decisions rules with statistical guarantees, enabling the deployment of more reliable agentic systems.", "AI": {"tldr": "The paper introduces e-valuator, a method to improve the reliability of agentic AI systems by statistically validating their actions using verifier scores.", "motivation": "Agentic AI systems often rely on heuristic verifier scores to evaluate their action trajectories, but these scores lack guarantees of correctness, leading to potential errors in decision-making.", "method": "The authors propose e-valuator, a framework utilizing tools from e-processes to build a sequential hypothesis test that ensures statistical validity of verifier decisions across arbitrarily long action sequences.", "result": "E-valuator demonstrates higher statistical power and better control of false alarm rates compared to existing methods across multiple datasets and settings, while also enabling cost-saving by terminating problematic trajectories early.", "conclusion": "E-valuator offers a lightweight, model-agnostic framework to enhance the reliability of agentic AI systems by transforming heuristic verifier scores into statistically reliable decision rules."}}
{"id": "2512.03284", "pdf": "https://arxiv.org/pdf/2512.03284", "abs": "https://arxiv.org/abs/2512.03284", "authors": ["Hongpei Zheng", "Shijie Li", "Yanran Li", "Hujun Yin"], "title": "SpatialReasoner: Active Perception for Large-Scale 3D Scene Understanding", "categories": ["cs.CV"], "comment": null, "summary": "Spatial reasoning in large-scale 3D environments remains challenging for current vision-language models, which are typically constrained to room-scale scenarios. We introduce H$^2$U3D (Holistic House Understanding in 3D), a 3D visual question answering dataset designed for house-scale scene understanding. H$^2$U3D features multi-floor environments spanning up to three floors and 10-20 rooms, covering more than 300 m$^2$. Through an automated annotation pipeline, it constructs hierarchical coarse-to-fine visual representations and generates diverse question-answer pairs with chain-of-thought annotations. We further propose SpatialReasoner, an active perception framework that autonomously invokes spatial tools to explore 3D scenes based on textual queries. SpatialReasoner is trained through a two-stage strategy: a supervised cold start followed by reinforcement learning with an adaptive exploration reward that promotes efficient exploration while discouraging redundant operations. Extensive experiments demonstrate that SpatialReasoner achieves state-of-the-art performance on H$^2$U3D, outperforming strong baselines including GPT-4o and Gemini-2.5-Pro. Notably, our method attains superior results while using only 3-4 images in total on average, compared to baselines requiring 16+ images, highlighting the effectiveness of our coarse-to-fine active exploration paradigm.", "AI": {"tldr": "This paper introduces H$^2$U3D, a 3D visual question answering dataset for multi-floor environments, and SpatialReasoner, a framework for efficient spatial exploration based on textual queries, achieving state-of-the-art performance.", "motivation": "The motivation is to address the challenge of spatial reasoning in large 3D environments, beyond the limitations of room-scale scenarios that most vision-language models are restricted to.", "method": "The authors created H$^2$U3D, a house-scale 3D dataset with hierarchical data and chain-of-thought annotations. They also developed SpatialReasoner, which uses active perception and is trained with supervised learning and reinforcement learning to efficiently explore 3D scenes.", "result": "SpatialReasoner achieves superior performance on H$^2$U3D compared to strong baselines, needing far fewer images (3-4 on average versus 16+ for competitors).", "conclusion": "The study demonstrates a novel and effective coarse-to-fine exploration method in large-scale 3D environments, advancing vision-language understanding."}}
{"id": "2512.03065", "pdf": "https://arxiv.org/pdf/2512.03065", "abs": "https://arxiv.org/abs/2512.03065", "authors": ["Nihir Chadderwala"], "title": "Optimizing Life Sciences Agents in Real-Time using Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": null, "summary": "Generative AI agents in life sciences face a critical challenge: determining the optimal approach for diverse queries ranging from simple factoid questions to complex mechanistic reasoning. Traditional methods rely on fixed rules or expensive labeled training data, neither of which adapts to changing conditions or user preferences. We present a novel framework that combines AWS Strands Agents with Thompson Sampling contextual bandits to enable AI agents to learn optimal decision-making strategies from user feedback alone. Our system optimizes three key dimensions: generation strategy selection (direct vs. chain-of-thought), tool selection (literature search, drug databases, etc.), and domain routing (pharmacology, molecular biology, clinical specialists). Through empirical evaluation on life science queries, we demonstrate 15-30\\% improvement in user satisfaction compared to random baselines, with clear learning patterns emerging after 20-30 queries. Our approach requires no ground truth labels, adapts continuously to user preferences, and provides a principled solution to the exploration-exploitation dilemma in agentic AI systems.", "AI": {"tldr": "The paper introduces a framework that enables generative AI for life sciences to learn optimal strategies via user feedback, showing a 15\u201330% improvement in user satisfaction without requiring labeled data.", "motivation": "The study aims to overcome the limitations of fixed rules and expensive labeled training data in enabling AI agents to adapt to dynamic user needs and preferences in life sciences applications.", "method": "The framework combines AWS Strands Agents with Thompson Sampling contextual bandits, optimizing generation strategy, tool selection, and domain routing through user feedback.", "result": "The system demonstrated a 15-30% improvement in user satisfaction across diverse life science queries, requiring only 20-30 interactions to establish effective learning patterns.", "conclusion": "This adaptive framework offers a scalable, label-free solution for improving AI decision-making in life sciences by leveraging user feedback and addressing the exploration-exploitation trade-off."}}
{"id": "2512.03538", "pdf": "https://arxiv.org/pdf/2512.03538", "abs": "https://arxiv.org/abs/2512.03538", "authors": ["Yuhang Huang", "Shilong Zou", "Jiazhao Zhang", "Xinwang Liu", "Ruizhen Hu", "Kai Xu"], "title": "AdaPower: Specializing World Foundation Models for Predictive Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "World Foundation Models (WFMs) offer remarkable visual dynamics simulation capabilities, yet their application to precise robotic control remains limited by the gap between generative realism and control-oriented precision. While existing approaches use WFMs as synthetic data generators, they suffer from high computational costs and underutilization of pre-trained VLA policies. We introduce \\textbf{AdaPower} (\\textbf{Ada}pt and Em\\textbf{power}), a lightweight adaptation framework that transforms general-purpose WFMs into specialist world models through two novel components: Temporal-Spatial Test-Time Training (TS-TTT) for inference-time adaptation and Memory Persistence (MP) for long-horizon consistency. Integrated within a Model Predictive Control framework, our adapted world model empowers pre-trained VLAs, achieving over 41\\% improvement in task success rates on LIBERO benchmarks without policy retraining, while preserving computational efficiency and generalist capabilities.", "AI": {"tldr": "The paper introduces \"AdaPower,\" a framework that adapts World Foundation Models (WFMs) for precise robotic control using a novel inference-time adaptation and long-horizon consistency mechanism, achieving notable performance without policy retraining.", "motivation": "Current WFMs excel in visual dynamics simulation but struggle to provide the precision needed for robotic control. Existing approaches using WFMs as synthetic data generators are computationally intensive and fail to leverage pre-trained Visual Language Agent (VLA) policies effectively.", "method": "The authors propose \"AdaPower,\" which includes two innovative components: Temporal-Spatial Test-Time Training (TS-TTT) for adapting WFMs at inference time, and Memory Persistence (MP) for ensuring long-horizon consistency. These are integrated into a Model Predictive Control framework.", "result": "AdaPower delivers a significant improvement (over 41% increase) in task success rates on LIBERO benchmarks, without needing to retrain policies, while maintaining computational efficiency.", "conclusion": "The proposed framework successfully adapts general-purpose WFMs into more precise, task-specific models for robotic control, addressing computational inefficiencies and enhancing task performance."}}
{"id": "2512.03685", "pdf": "https://arxiv.org/pdf/2512.03685", "abs": "https://arxiv.org/abs/2512.03685", "authors": ["Seng W. Loke"], "title": "Distributed Quantum Computing with Fan-Out Operations and Qudits: the Case of Distributed Global Gates (a Preliminary Study)", "categories": ["quant-ph", "cs.DC", "cs.ET"], "comment": "8 pages, 10 figures; preliminary version (if mistakes found - please contact the author)", "summary": "Much recent work on distributed quantum computing have focused on the use of entangled pairs and distributed two qubit gates. But there has also been work on efficient schemes for achieving multipartite entanglement between nodes in a single shot, removing the need to generate multipartite entangled states using many entangled pairs. This paper looks at how multipartite entanglement resources (e.g., GHZ states) can be useful for distributed fan-out operations; we also consider the use of qudits of dimension four for distributed quantum circuit compression. In particular, we consider how such fan-out operations and qudits can be used to implement circuits which are challenging for distributed quantum computation, involving pairwise qubit interactions, i.e., what has been called global gates (a.k.a. global M\u00f8lmer-S\u00f8rensen gates). Such gates have been explored to possibly yield more efficient computations via reduced circuit depth, and can be carried out efficiently in some types of quantum hardware (e.g., trapped-ion quantum computers); we consider this as an exploration of an ``extreme'' case for distribution given the global qubit-qubit interactions. We also conclude with some implications for future work on quantum circuit compilation and quantum data centre design.", "AI": {"tldr": "The paper explores the use of multipartite entanglement resources (e.g., GHZ states) and qudits for distributed quantum computation, particularly for implementing circuits with global qubit-qubit interactions.", "motivation": "To address challenges in distributed quantum computing by utilizing multipartite entanglement and high-dimensional qudits for efficient quantum operations and circuit compression.", "method": "The authors analyze the use of multipartite entanglement, specifically GHZ states, and 4-dimensional qudits for distributed computation. They focus on implementing global qubit-qubit interaction circuits, like global gates, to reduce circuit depth and enhance computational efficiency.", "result": "The approach demonstrates potential for more efficient distributed quantum computations, particularly in cases involving challenging circuits like global gates.", "conclusion": "Multipartite entanglement and high-dimensional qudits could be valuable tools in distributed quantum computing, with implications for circuit design, quantum circuit compilation, and quantum data center architecture."}}
{"id": "2512.03607", "pdf": "https://arxiv.org/pdf/2512.03607", "abs": "https://arxiv.org/abs/2512.03607", "authors": ["Yusen Wu", "Xiaotie Deng"], "title": "DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization", "categories": ["cs.AI"], "comment": null, "summary": "This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortment and pricing optimization. Addressing the systematic misalignment between existing theoretical models and real-world economic complexities, we identify three critical gaps: (1) data modality mismatch where unstructured textual sources (e.g. negotiation records, approval documents) impede accurate customer profiling; (2) dynamic feature entanglement challenges in modeling nonlinear price elasticity and time-varying attributes; (3) operational infeasibility caused by multi-tier business constraints.\n  Our framework introduces a tri-level architecture for above challenges. We design a hybrid knowledge fusion engine employing large language models (LLMs) for deep semantic parsing of unstructured text, transforming distributor agreements and sales assessments into structured features while integrating managerial expertise. Then a game-theoretic constrained optimization mechanism is employed to dynamically reconcile supply chain interests through bilateral utility functions, encoding manufacturer-distributor profit redistribution as endogenous objectives under hierarchical constraints. Finally an interpretable decision distillation interface leveraging LLM-guided symbolic regression to find and optimize pricing strategies and auditable business rules embeds economic priors (e.g. non-negative elasticity) as hard constraints during mathematical expression search. We validate the framework in real retail environments achieving higher profits versus systematic B2C baselines while ensuring operational feasibility. This establishes a close-loop pipeline unifying unstructured knowledge injection, multi-agent optimization, and interpretable strategy synthesis for real economic intelligence.", "AI": {"tldr": "The paper introduces DeepRule, a framework for automated business rule generation aimed at solving challenges in retail assortment and pricing via advanced NLP, optimization, and interpretable models.", "motivation": "The motivation is to address gaps in current theoretical and practical models for pricing and assortment optimization, such as unstructured data utilization, non-linear dynamics, and operational constraints.", "method": "A tri-level framework includes semantic parsing of unstructured data using LLMs, game-theoretic optimization for supply chain alignment, and interpretable strategy generation through symbolic regression.", "result": "DeepRule showed superior profitability and operational feasibility in real retail environments compared to existing methods.", "conclusion": "DeepRule bridges the gap between theory and real-world complexities, offering a comprehensive system for unstructured data integration, optimization, and interpretable decision-making for retail strategies."}}
{"id": "2512.03360", "pdf": "https://arxiv.org/pdf/2512.03360", "abs": "https://arxiv.org/abs/2512.03360", "authors": ["Qingchuan Li", "Mingyue Cheng", "Zirui Liu", "Daoyu Wang", "Yuting Zeng", "Tongxuan Liu"], "title": "From Hypothesis to Premises: LLM-based Backward Logical Reasoning with Selective Symbolic Translation", "categories": ["cs.CL"], "comment": "Accepted by AAAI2026", "summary": "Logical reasoning is a core challenge in natural language understanding and a fundamental capability of artificial intelligence, underpinning scientific discovery, mathematical theorem proving, and complex decision-making. Despite the remarkable progress of large language models (LLMs), most current approaches still rely on forward reasoning paradigms, generating step-by-step rationales from premises to conclusions. However, such methods often suffer from redundant inference paths, hallucinated steps, and semantic drift, resulting in inefficient and unreliable reasoning. In this paper, we propose a novel framework, Hypothesis-driven Backward Logical Reasoning (HBLR). The core idea is to integrate confidence-aware symbolic translation with hypothesis-driven backward reasoning. In the translation phase, only high-confidence spans are converted into logical form, such as First-Order Logic (FOL), while uncertain content remains in natural language. A translation reflection module further ensures semantic fidelity by evaluating symbolic outputs and reverting lossy ones back to text when necessary. In the reasoning phase, HBLR simulates human deductive thinking by assuming the conclusion is true and recursively verifying its premises. A reasoning reflection module further identifies and corrects flawed inference steps, enhancing logical coherence. Extensive experiments on five reasoning benchmarks demonstrate that HBLR consistently outperforms strong baselines in both accuracy and efficiency.", "AI": {"tldr": "This paper introduces a novel framework, Hypothesis-driven Backward Logical Reasoning (HBLR), to improve logical reasoning in AI by combining symbolic translation and backward reasoning.", "motivation": "Current forward reasoning approaches in LLMs often lead to errors such as redundant inference paths, hallucination, and semantic drift, necessitating a more reliable and efficient reasoning method.", "method": "The proposed HBLR framework integrates confidence-aware symbolic translation with hypothesis-driven backward reasoning, employing reflection modules to evaluate and correct outputs during translation and reasoning.", "result": "The HBLR framework outperformed strong baselines in accuracy and efficiency across experiments on five reasoning benchmarks.", "conclusion": "HBLR demonstrates significant potential to improve logical reasoning capabilities in natural language understanding, providing a more effective alternative to forward reasoning models."}}
{"id": "2512.03112", "pdf": "https://arxiv.org/pdf/2512.03112", "abs": "https://arxiv.org/abs/2512.03112", "authors": ["Jialai She"], "title": "Beyond Additivity: Sparse Isotonic Shapley Regression toward Nonlinear Explainability", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Shapley values, a gold standard for feature attribution in Explainable AI, face two primary challenges. First, the canonical Shapley framework assumes that the worth function is additive, yet real-world payoff constructions--driven by non-Gaussian distributions, heavy tails, feature dependence, or domain-specific loss scales--often violate this assumption, leading to distorted attributions. Secondly, achieving sparse explanations in high dimensions by computing dense Shapley values and then applying ad hoc thresholding is prohibitively costly and risks inconsistency. We introduce Sparse Isotonic Shapley Regression (SISR), a unified nonlinear explanation framework. SISR simultaneously learns a monotonic transformation to restore additivity--obviating the need for a closed-form specification--and enforces an L0 sparsity constraint on the Shapley vector, enhancing computational efficiency in large feature spaces. Its optimization algorithm leverages Pool-Adjacent-Violators for efficient isotonic regression and normalized hard-thresholding for support selection, yielding implementation ease and global convergence guarantees. Analysis shows that SISR recovers the true transformation in a wide range of scenarios and achieves strong support recovery even in high noise. Moreover, we are the first to demonstrate that irrelevant features and inter-feature dependencies can induce a true payoff transformation that deviates substantially from linearity. Experiments in regression, logistic regression, and tree ensembles demonstrate that SISR stabilizes attributions across payoff schemes, correctly filters irrelevant features while standard Shapley values suffer severe rank and sign distortions. By unifying nonlinear transformation estimation with sparsity pursuit, SISR advances the frontier of nonlinear explainability, providing a theoretically grounded and practical attribution framework.", "AI": {"tldr": "The paper introduces Sparse Isotonic Shapley Regression (SISR), a new Explainable AI framework to handle feature attribution issues in non-additive payoff systems and achieve computational efficiency.", "motivation": "Shapley values face issues in non-additive payoff systems and high-dimensionality problems, leading to distorted attributions and costly thresholding methods.", "method": "SISR uses a monotonic transformation to restore additivity automatically and applies L0 sparsity to Shapley vectors. It employs efficient optimization techniques like Pool-Adjacent-Violators for isotonic regression and normalized hard-thresholding for feature selection.", "result": "SISR successfully recovers true transformations, maintains attribution stability across payoff schemes, and effectively filters irrelevant features, outperforming standard Shapley methods.", "conclusion": "SISR provides a practical and theoretically sound framework that unifies nonlinear payoff transformation with sparse Shapley value computation, pushing forward explainability in AI."}}
{"id": "2512.03317", "pdf": "https://arxiv.org/pdf/2512.03317", "abs": "https://arxiv.org/abs/2512.03317", "authors": ["Thomas Monninger", "Zihan Zhang", "Steffen Staab", "Sihao Ding"], "title": "NavMapFusion: Diffusion-based Fusion of Navigation Maps for Online Vectorized HD Map Construction", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": "Accepted to 2026 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2026)", "summary": "Accurate environmental representations are essential for autonomous driving, providing the foundation for safe and efficient navigation. Traditionally, high-definition (HD) maps are providing this representation of the static road infrastructure to the autonomous system a priori. However, because the real world is constantly changing, such maps must be constructed online from on-board sensor data. Navigation-grade standard-definition (SD) maps are widely available, but their resolution is insufficient for direct deployment. Instead, they can be used as coarse prior to guide the online map construction process. We propose NavMapFusion, a diffusion-based framework that performs iterative denoising conditioned on high-fidelity sensor data and on low-fidelity navigation maps. This paper strives to answer: (1) How can coarse, potentially outdated navigation maps guide online map construction? (2) What advantages do diffusion models offer for map fusion? We demonstrate that diffusion-based map construction provides a robust framework for map fusion. Our key insight is that discrepancies between the prior map and online perception naturally correspond to noise within the diffusion process; consistent regions reinforce the map construction, whereas outdated segments are suppressed. On the nuScenes benchmark, NavMapFusion conditioned on coarse road lines from OpenStreetMap data reaches a 21.4% relative improvement on 100 m, and even stronger improvements on larger perception ranges, while maintaining real-time capabilities. By fusing low-fidelity priors with high-fidelity sensor data, the proposed method generates accurate and up-to-date environment representations, guiding towards safer and more reliable autonomous driving. The code is available at https://github.com/tmonnin/navmapfusion", "AI": {"tldr": "This paper presents NavMapFusion, a method that combines low-fidelity navigation maps with high-fidelity sensor data for creating accurate, up-to-date maps for autonomous driving, addressing challenges in traditional map construction.", "motivation": "The paper is motivated by the need for up-to-date, accurate environmental representations for autonomous driving. HD maps, though precise, fail to handle real-world changes efficiently, making online map construction a necessity, particularly by utilizing available standard-definition (SD) maps as coarse priors.", "method": "The proposed method, NavMapFusion, utilizes a diffusion-based framework for iterative denoising conditioned on sensor data and navigation maps. This approach treats inconsistencies between prior maps and sensor data as noise, allowing accurate regions to be reinforced and outdated regions to be discarded.", "result": "The algorithm achieves a 21.4% improvement relative to existing methods on the nuScenes benchmark (100 m range) using OpenStreetMap priors, with even better performance at larger ranges. Importantly, it remains real-time capable.", "conclusion": "NavMapFusion effectively fuses coarse maps and high-fidelity sensor data into accurate, updated environmental representations, enhancing safety and reliability for autonomous navigation. The approach demonstrates the benefits of diffusion models for robust map fusion."}}
{"id": "2512.03069", "pdf": "https://arxiv.org/pdf/2512.03069", "abs": "https://arxiv.org/abs/2512.03069", "authors": ["Loup-Noe Levy", "Jeremie Bosom", "Guillaume Guerard", "Soufian Ben Amor", "Marc Bui", "Hai Tran"], "title": "Hierarchical clustering of complex energy systems using pretopology", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This article attempts answering the following problematic: How to model and classify energy consumption profiles over a large distributed territory to optimize the management of buildings' consumption?\n  Doing case-by-case in depth auditing of thousands of buildings would require a massive amount of time and money as well as a significant number of qualified people. Thus, an automated method must be developed to establish a relevant and effective recommendations system.\n  To answer this problematic, pretopology is used to model the sites' consumption profiles and a multi-criterion hierarchical classification algorithm, using the properties of pretopological space, has been developed in a Python library.\n  To evaluate the results, three data sets are used: A generated set of dots of various sizes in a 2D space, a generated set of time series and a set of consumption time series of 400 real consumption sites from a French Energy company.\n  On the point data set, the algorithm is able to identify the clusters of points using their position in space and their size as parameter. On the generated time series, the algorithm is able to identify the time series clusters using Pearson's correlation with an Adjusted Rand Index (ARI) of 1.", "AI": {"tldr": "The paper aims to optimize energy consumption management over large territories using automated methods instead of labor-intensive audits, employing pretopology and hierarchical algorithms.", "motivation": "The motivation is to overcome the impracticality of individually auditing thousands of buildings due to high time, cost, and personnel demands.", "method": "The authors adopted pretopology for modeling consumption profiles and developed a hierarchical classification algorithm implemented in Python.", "result": "The algorithm successfully clustered data sets including points, generated time series, and real energy consumption data with high accuracy.", "conclusion": "Automated methods based on pretopology are effective for grouping and classifying large energy consumption datasets, replacing expensive traditional audits."}}
{"id": "2512.03548", "pdf": "https://arxiv.org/pdf/2512.03548", "abs": "https://arxiv.org/abs/2512.03548", "authors": ["Zexin Lin", "Yebin Zhong", "Hanwen Wan", "Jiu Cheng", "Zhenglong Sun", "Xiaoqiang Ji"], "title": "A Learning-based Control Methodology for Transitioning VTOL UAVs", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Transition control poses a critical challenge in Vertical Take-Off and Landing Unmanned Aerial Vehicle (VTOL UAV) development due to the tilting rotor mechanism, which shifts the center of gravity and thrust direction during transitions. Current control methods' decoupled control of altitude and position leads to significant vibration, and limits interaction consideration and adaptability. In this study, we propose a novel coupled transition control methodology based on reinforcement learning (RL) driven controller. Besides, contrasting to the conventional phase-transition approach, the ST3M method demonstrates a new perspective by treating cruise mode as a special case of hover. We validate the feasibility of applying our method in simulation and real-world environments, demonstrating efficient controller development and migration while accurately controlling UAV position and attitude, exhibiting outstanding trajectory tracking and reduced vibrations during the transition process.", "AI": {"tldr": "The paper addresses challenges in controlling VTOL UAV transitions by introducing a reinforcement learning-based controller to reduce vibration and improve trajectory tracking.", "motivation": "Vertical take-off and landing UAVs face transition control challenges due to tilt rotor mechanisms causing shifts in gravity and thrust. Current methods lack adaptability and fail to address vibrations effectively.", "method": "The study proposes a novel reinforcement learning-driven transition control method and presents a perspective treating cruise mode as a variant of hover mode.", "result": "Simulation and real-world validations showed efficient controller migration, precise position and attitude control with significantly reduced vibrations during transitions.", "conclusion": "The proposed methodology enhances VTOL UAV transition control by offering improved adaptability, reduced vibrations, and accurate trajectory tracking for efficient operations."}}
{"id": "2512.03627", "pdf": "https://arxiv.org/pdf/2512.03627", "abs": "https://arxiv.org/abs/2512.03627", "authors": ["Junming Liu", "Yifei Sun", "Weihua Cheng", "Haodong Lei", "Yirong Chen", "Licheng Wen", "Xuemeng Yang", "Daocheng Fu", "Pinlong Cai", "Nianchen Deng", "Yi Yu", "Shuyue Hu", "Botian Shi", "Ding Wang"], "title": "MemVerse: Multimodal Memory for Lifelong Learning Agents", "categories": ["cs.AI"], "comment": "11 pages, 2 figures, 2 tables", "summary": "Despite rapid progress in large-scale language and vision models, AI agents still suffer from a fundamental limitation: they cannot remember. Without reliable memory, agents catastrophically forget past experiences, struggle with long-horizon reasoning, and fail to operate coherently in multimodal or interactive environments. We introduce MemVerse, a model-agnostic, plug-and-play memory framework that bridges fast parametric recall with hierarchical retrieval-based memory, enabling scalable and adaptive multimodal intelligence. MemVerse maintains short-term memory for recent context while transforming raw multimodal experiences into structured long-term memories organized as hierarchical knowledge graphs. This design supports continual consolidation, adaptive forgetting, and bounded memory growth. To handle real-time demands, MemVerse introduces a periodic distillation mechanism that compresses essential knowledge from long-term memory into the parametric model, allowing fast, differentiable recall while preserving interpretability. Extensive experiments demonstrate that MemVerse significantly improves multimodal reasoning and continual learning efficiency, empowering agents to remember, adapt, and reason coherently across extended interactions.", "AI": {"tldr": "MemVerse is a memory framework enhancing AI agents with reliable memory for coherent multimodal reasoning and continual learning.", "motivation": "AI agents suffer from forgetting past experiences and weak long-term reasoning due to lack of reliable memory mechanisms.", "method": "MemVerse introduces a hierarchical memory framework, combining short-term and structured long-term memory, and compressing essential knowledge for efficient recall.", "result": "MemVerse shows improved multimodal reasoning and continual learning in extended interactions.", "conclusion": "MemVerse bridges memory limitations in AI, enabling scalable, adaptive, and efficient multimodal intelligence."}}
{"id": "2512.03377", "pdf": "https://arxiv.org/pdf/2512.03377", "abs": "https://arxiv.org/abs/2512.03377", "authors": ["Hanting Chen", "Chu Zhong", "Kai Han", "Yuchuan Tian", "Yuchen Liang", "Tianyu Guo", "Xinghao Chen", "Dacheng Tao", "Yunhe Wang"], "title": "Nexus: Higher-Order Attention Mechanisms in Transformers", "categories": ["cs.CL"], "comment": null, "summary": "Transformers have achieved significant success across various domains, relying on self-attention to capture dependencies. However, the standard first-order attention mechanism is often limited by a low-rank bottleneck, struggling to capture intricate, multi-hop relationships within a single layer. In this paper, we propose the \\textbf{Higher-Order Attention Network (Hon)}, a novel architecture designed to enhance representational power through a recursive framework. Unlike standard approaches that use static linear projections for Queries and Keys, Hon dynamically refines these representations via nested self-attention mechanisms. Specifically, the Query and Key vectors are themselves outputs of inner attention loops, allowing tokens to aggregate global context and model high-order correlations \\textit{prior} to the final attention computation. We enforce a parameter-efficient weight-sharing strategy across recursive steps, ensuring that this enhanced expressivity incurs $\\mathcal{O}(1)$ additional parameters. We provide theoretical analysis demonstrating that our method breaks the linear bottleneck of standard attention. Empirically, Hon outperforms standard Transformers on multiple benchmarks.", "AI": {"tldr": "The paper introduces the Higher-Order Attention Network (Hon), enhancing Transformers with recursive self-attention mechanisms for improved representation and performance.", "motivation": "Standard self-attention mechanisms in Transformers face a low-rank bottleneck, making it difficult to model intricate, multi-hop relationships in a single layer.", "method": "The proposed architecture, Hon, employs recursive attention mechanisms where Query and Key vectors are dynamically refined through nested self-attention loops, coupled with parameter-efficient weight-sharing.", "result": "Hon shows superior performance compared to standard Transformers in various benchmark tasks, breaking the linear bottleneck of standard attention.", "conclusion": "Hon improves the representational power of Transformers by modeling high-order correlations efficiently, maintaining parameter efficiency, and achieving state-of-the-art results empirically."}}
{"id": "2512.03116", "pdf": "https://arxiv.org/pdf/2512.03116", "abs": "https://arxiv.org/abs/2512.03116", "authors": ["Joseph de Vilmarest", "Olivier Wintenberger"], "title": "Assessing Extrapolation of Peaks Over Thresholds with Martingale Testing", "categories": ["stat.ME", "stat.ML"], "comment": null, "summary": "We present the winning strategy for the EVA2025 Data Challenge, which aimed to estimate the probability of extreme precipitation events. These events occurred at most once in the dataset making the challenge fundamentally one of extrapolating extreme values. Given the scarcity of extreme events, we argue that a simple, robust modeling approach is essential. We adopt univariate models instead of multivariate ones and model Peaks Over Thresholds using Extreme Value Theory. Specifically, we fit an exponential distribution to model exceedances of the target variable above a high quantile (after seasonal adjustment). The novelty of our approach lies in using martingale testing to evaluate the extrapolation power of the procedure and to agnostically select the level of the high quantile. While this method has several limitations, we believe that framing extrapolation as a game opens the door to other agnostic approaches in Extreme Value Analysis.", "AI": {"tldr": "The paper details the successful strategy from the EVA2025 Data Challenge for estimating probabilities of rare extreme precipitation events using a simple univariate modeling approach.", "motivation": "The motivation was to address the challenge of predicting extreme precipitation events with limited data, focusing on robust extrapolation techniques for rare occurrences.", "method": "The method employs univariate modeling using Extreme Value Theory, specifically through an exponential distribution for modeling exceedances above a high quantile. Seasonal adjustments and martingale testing are used to evaluate extrapolation capabilities and select quantiles agnostically.", "result": "The proposed method successfully handled scarcity of extreme events by focusing on Peaks Over Thresholds and exploiting robust statistical practices, resulting in a winning strategy for the challenge.", "conclusion": "The study concludes that simple modeling, reinforced by techniques like martingale testing, can effectively address issues of extrapolation for extreme events, paving the way for further agnostic approaches in Extreme Value Analysis."}}
{"id": "2512.03335", "pdf": "https://arxiv.org/pdf/2512.03335", "abs": "https://arxiv.org/abs/2512.03335", "authors": ["Faizan Farooq Khan", "K J Joseph", "Koustava Goswami", "Mohamed Elhoseiny", "Balaji Vasan Srinivasan"], "title": "Step-by-step Layered Design Generation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Design generation, in its essence, is a step-by-step process where designers progressively refine and enhance their work through careful modifications. Despite this fundamental characteristic, existing approaches mainly treat design synthesis as a single-step generation problem, significantly underestimating the inherent complexity of the creative process. To bridge this gap, we propose a novel problem setting called Step-by-Step Layered Design Generation, which tasks a machine learning model with generating a design that adheres to a sequence of instructions from a designer. Leveraging recent advancements in multi-modal LLMs, we propose SLEDGE: Step-by-step LayEred Design GEnerator to model each update to a design as an atomic, layered change over its previous state, while being grounded in the instruction. To complement our new problem setting, we introduce a new evaluation suite, including a dataset and a benchmark. Our exhaustive experimental analysis and comparison with state-of-the-art approaches tailored to our new setup demonstrate the efficacy of our approach. We hope our work will attract attention to this pragmatic and under-explored research area.", "AI": {"tldr": "Proposing a novel step-by-step systemic approach, SLEDGE, for layered design creation that evolves based on progressive designer instructions.", "motivation": "Existing design synthesis approaches neglect the iterative, progressive nature of creative design, treating it as a one-step problem.", "method": "Introducing SLEDGE, a step-by-step, instruction-grounded, layered design generator using advances in multi-modal large language models (LLMs).", "result": "Experimental analysis and benchmarks highlight the superiority of the proposed approach (SLEDGE) over current state-of-the-art methods.", "conclusion": "This work establishes a framework for layered design generation and aims to inspire further research into this pragmatic yet under-explored domain."}}
{"id": "2512.03070", "pdf": "https://arxiv.org/pdf/2512.03070", "abs": "https://arxiv.org/abs/2512.03070", "authors": ["Guillaume Guerard", "Sonia Djebali"], "title": "Mixed Data Clustering Survey and Challenges", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The advent of the big data paradigm has transformed how industries manage and analyze information, ushering in an era of unprecedented data volume, velocity, and variety. Within this landscape, mixed-data clustering has become a critical challenge, requiring innovative methods that can effectively exploit heterogeneous data types, including numerical and categorical variables. Traditional clustering techniques, typically designed for homogeneous datasets, often struggle to capture the additional complexity introduced by mixed data, underscoring the need for approaches specifically tailored to this setting. Hierarchical and explainable algorithms are particularly valuable in this context, as they provide structured, interpretable clustering results that support informed decision-making. This paper introduces a clustering method grounded in pretopological spaces. In addition, benchmarking against classical numerical clustering algorithms and existing pretopological approaches yields insights into the performance and effectiveness of the proposed method within the big data paradigm.", "AI": {"tldr": "The paper proposes a pretopology-based clustering method for mixed-data to address challenges in big data analysis, emphasizing hierarchy and explainability.", "motivation": "The growing complexity of big data analytics necessitates clustering methods suited for heterogeneous data types (numerical and categorical). Conventional techniques often fail with mixed data, requiring more tailored approaches.", "method": "The researchers introduce a clustering technique based on pretopological spaces. It leverages hierarchical and interpretable algorithmic design, benchmarking against established methods for validation.", "result": "The method is compared with classical numerical clustering algorithms and current pretopological techniques, demonstrating its relevance and performance in managing mixed-data clustering within the big data paradigm.", "conclusion": "This paper offers an innovative method specifically tailored for mixed-data clustering. It highlights the importance of hierarchical and explainable approaches to better support decision-making in complex data scenarios."}}
{"id": "2512.03556", "pdf": "https://arxiv.org/pdf/2512.03556", "abs": "https://arxiv.org/abs/2512.03556", "authors": ["Yinzhou Tang", "Yu Shang", "Yinuo Chen", "Bingwen Wei", "Xin Zhang", "Shu'ang Yu", "Liangzhi Shi", "Chao Yu", "Chen Gao", "Wei Wu", "Yong Li"], "title": "RoboScape-R: Unified Reward-Observation World Models for Generalizable Robotics Training via RL", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Achieving generalizable embodied policies remains a key challenge. Traditional policy learning paradigms, including both Imitation Learning (IL) and Reinforcement Learning (RL), struggle to cultivate generalizability across diverse scenarios. While IL policies often overfit to specific expert trajectories, RL suffers from the inherent lack of a unified and general reward signal necessary for effective multi-scene generalization. We posit that the world model is uniquely capable of serving as a universal environment proxy to address this limitation. However, current world models primarily focus on their ability to predict observations and still rely on task-specific, handcrafted reward functions, thereby failing to provide a truly general training environment. Toward this problem, we propose RoboScape-R, a framework leveraging the world model to serve as a versatile, general-purpose proxy for the embodied environment within the RL paradigm. We introduce a novel world model-based general reward mechanism that generates ''endogenous'' rewards derived from the model's intrinsic understanding of real-world state transition dynamics. Extensive experiments demonstrate that RoboScape-R effectively addresses the limitations of traditional RL methods by providing an efficient and general training environment that substantially enhances the generalization capability of embodied policies. Our approach offers critical insights into utilizing the world model as an online training strategy and achieves an average 37.5% performance improvement over baselines under out-of-domain scenarios.", "AI": {"tldr": "The paper introduces RoboScape-R, a framework using world models as a general training environment within RL, which improves policy generalization by 37.5% in out-of-domain cases.", "motivation": "Traditional RL/IL methods struggle with policy generalization. The paper aims to overcome this by leveraging world models as universal environment proxies.", "method": "The authors propose RoboScape-R, leveraging world models for endogenous rewards based on state transition dynamics to enhance RL policy generalization.", "result": "RoboScape-R achieves a 37.5% performance improvement in generalization for embodied policies under out-of-domain scenarios.", "conclusion": "The paper demonstrates that using world models as proxies and employing endogenous rewards significantly boosts generalization in embodied policy training."}}
{"id": "2512.03762", "pdf": "https://arxiv.org/pdf/2512.03762", "abs": "https://arxiv.org/abs/2512.03762", "authors": ["Jiawei Xu", "Fengfeng Wei", "Weineng Chen"], "title": "RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design", "categories": ["cs.AI"], "comment": null, "summary": "Automatic Heuristic Design (AHD) has gained traction as a promising solution for solving combinatorial optimization problems (COPs). Large Language Models (LLMs) have emerged and become a promising approach to achieving AHD, but current LLM-based AHD research often only considers a single role. This paper proposes RoCo, a novel Multi-Agent Role-Based System, to enhance the diversity and quality of AHD through multi-role collaboration. RoCo coordinates four specialized LLM-guided agents-explorer, exploiter, critic, and integrator-to collaboratively generate high-quality heuristics. The explorer promotes long-term potential through creative, diversity-driven thinking, while the exploiter focuses on short-term improvements via conservative, efficiency-oriented refinements. The critic evaluates the effectiveness of each evolution step and provides targeted feedback and reflection. The integrator synthesizes proposals from the explorer and exploiter, balancing innovation and exploitation to drive overall progress. These agents interact in a structured multi-round process involving feedback, refinement, and elite mutations guided by both short-term and accumulated long-term reflections. We evaluate RoCo on five different COPs under both white-box and black-box settings. Experimental results demonstrate that RoCo achieves superior performance, consistently generating competitive heuristics that outperform existing methods including ReEvo and HSEvo, both in white-box and black-box scenarios. This role-based collaborative paradigm establishes a new standard for robust and high-performing AHD.", "AI": {"tldr": "The study introduces RoCo, a Multi-Agent Role-Based System that improves Automatic Heuristic Design for combinatorial optimization problems by facilitating multi-role collaboration of LLMs.", "motivation": "The paper addresses limitations in existing LLM-based Automatic Heuristic Design research, which often considers a single role, by proposing a multi-agent approach to improve heuristic diversity and quality.", "method": "RoCo coordinates four specialized LLM-guided agents, each with distinct roles (explorer, exploiter, critic, and integrator), to generate heuristics through a multi-round collaborative process.", "result": "RoCo demonstrates superior performance on five combinatorial optimization problems, outperforming baseline methods like ReEvo and HSEvo in both white-box and black-box settings.", "conclusion": "The role-based collaborative paradigm of RoCo raises the standard for robust and effective Automatic Heuristic Design, showcasing the benefits of multi-agent collaboration in LLM-based systems."}}
{"id": "2512.03381", "pdf": "https://arxiv.org/pdf/2512.03381", "abs": "https://arxiv.org/abs/2512.03381", "authors": ["Nicholas Tomlin", "Naitian Zhou", "Eve Fleisig", "Liangyuan", "Chen", "T\u00e9a Wright", "Lauren Vinh", "Laura X. Ma", "Seun Eisape", "Ellie French", "Tingting Du", "Tianjiao Zhang", "Alexander Koller", "Alane Suhr"], "title": "Characterizing Language Use in a Collaborative Situated Game", "categories": ["cs.CL"], "comment": null, "summary": "Cooperative video games, where multiple participants must coordinate by communicating and reasoning under uncertainty in complex environments, yield a rich source of language data. We collect the Portal Dialogue Corpus: a corpus of 11.5 hours of spoken human dialogue in the co-op mode of the popular Portal 2 virtual puzzle game, comprising 24.5K total utterances. We analyze player language and behavior, identifying a number of linguistic phenomena that rarely appear in most existing chitchat or task-oriented dialogue corpora, including complex spatial reference, clarification and repair, and ad-hoc convention formation. To support future analyses of language use in complex, situated, collaborative problem-solving scenarios, we publicly release the corpus, which comprises player videos, audio, transcripts, game state data, and both manual and automatic annotations of language data.", "AI": {"tldr": "The paper discusses the creation and release of the Portal Dialogue Corpus, a dataset derived from spoken dialogue in the co-op mode of the Portal 2 video game.", "motivation": "The study aims to analyze language use in complex, collaborative environments, which is underexplored in typical chitchat or task-oriented dialogue datasets.", "method": "The researchers collected 11.5 hours of spoken dialogue from Portal 2 gameplay, organizing 24.5K utterances with detailed annotations, including video, audio, transcripts, and game state data.", "result": "They identified unique linguistic phenomena like spatial references, repair, and ad-hoc convention formation that are not common in other dialogue datasets.", "conclusion": "The publicly released dataset provides a foundation for studying language in complex and situated problem-solving contexts."}}
{"id": "2512.03225", "pdf": "https://arxiv.org/pdf/2512.03225", "abs": "https://arxiv.org/abs/2512.03225", "authors": ["Christophe Andrieu", "Nicolas Chopin", "Ettore Fincato", "Mathieu Gerber"], "title": "Convergence of a class of gradient-free optimisation schemes when the objective function is noisy, irregular, or both", "categories": ["stat.CO", "cs.LG", "stat.ML"], "comment": null, "summary": "We investigate the convergence properties of a class of iterative algorithms designed to minimize a potentially non-smooth and noisy objective function, which may be algebraically intractable and whose values may be obtained as the output of a black box. The algorithms considered can be cast under the umbrella of a generalised gradient descent recursion, where the gradient is that of a smooth approximation of the objective function. The framework we develop includes as special cases model-based and mollification methods, two classical approaches to zero-th order optimisation. The convergence results are obtained under very weak assumptions on the regularity of the objective function and involve a trade-off between the degree of smoothing and size of the steps taken in the parameter updates. As expected, additional assumptions are required in the stochastic case. We illustrate the relevance of these algorithms and our convergence results through a challenging classification example from machine learning.", "AI": {"tldr": "This paper studies iterative algorithms using a generalized gradient descent for minimizing complex, non-smooth, noisy objective functions and proves convergence under weak assumptions.", "motivation": "To address the challenge of optimizing non-smooth, noisy, and algebraically intractable objective functions commonly encountered in machine learning and other fields.", "method": "The study develops a general framework for gradient descent using smooth approximations of objective functions, incorporating model-based and mollification methods, with analysis of convergence trade-offs.", "result": "Convergence results were obtained under weak assumptions, highlighting the trade-off between smoothing level and step size, with additional conditions required for stochastic cases.", "conclusion": "The framework extends classical approaches, providing a practical and theoretical foundation for optimizing challenging objective functions, demonstrated through a machine learning classification example."}}
{"id": "2512.03339", "pdf": "https://arxiv.org/pdf/2512.03339", "abs": "https://arxiv.org/abs/2512.03339", "authors": ["Yeganeh Ghamary", "Victoria Wu", "Hooman Vaseli", "Christina Luong", "Teresa Tsang", "Siavash Bigdeli", "Purang Abolmaesumi"], "title": "ProtoEFNet: Dynamic Prototype Learning for Inherently Interpretable Ejection Fraction Estimation in Echocardiography", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "11 pages, Accepted in IMIMIC Workshop at MICCAI 2025", "summary": "Ejection fraction (EF) is a crucial metric for assessing cardiac function and diagnosing conditions such as heart failure. Traditionally, EF estimation requires manual tracing and domain expertise, making the process time-consuming and subject to interobserver variability. Most current deep learning methods for EF prediction are black-box models with limited transparency, which reduces clinical trust. Some post-hoc explainability methods have been proposed to interpret the decision-making process after the prediction is made. However, these explanations do not guide the model's internal reasoning and therefore offer limited reliability in clinical applications. To address this, we introduce ProtoEFNet, a novel video-based prototype learning model for continuous EF regression. The model learns dynamic spatiotemporal prototypes that capture clinically meaningful cardiac motion patterns. Additionally, the proposed Prototype Angular Separation (PAS) loss enforces discriminative representations across the continuous EF spectrum. Our experiments on the EchonetDynamic dataset show that ProtoEFNet can achieve accuracy on par with its non-interpretable counterpart while providing clinically relevant insight. The ablation study shows that the proposed loss boosts performance with a 2% increase in F1 score from 77.67$\\pm$2.68 to 79.64$\\pm$2.10. Our source code is available at: https://github.com/DeepRCL/ProtoEF", "AI": {"tldr": "ProtoEFNet introduces a new interpretable deep learning model for estimating ejection fraction (EF) via video-based prototype learning, achieving both clinical insight and high accuracy.", "motivation": "Current EF estimation methods often rely on manual efforts or black-box deep learning models, which limit clinical trust and applicability due to a lack of interpretability.", "method": "The paper proposes ProtoEFNet, utilizing dynamic spatiotemporal prototypes for continuous EF regression, coupled with a Prototype Angular Separation (PAS) loss function to improve model discriminability.", "result": "ProtoEFNet matched the performance of non-interpretable models on the EchonetDynamic dataset while improving clinical transparency. It also demonstrated a 2% F1 score improvement with the proposed PAS loss.", "conclusion": "ProtoEFNet successfully balances prediction accuracy with interpretability and clinical relevance, making it a reliable tool for EF assessment."}}
{"id": "2512.03071", "pdf": "https://arxiv.org/pdf/2512.03071", "abs": "https://arxiv.org/abs/2512.03071", "authors": ["Loup-Noe Levy", "Guillaume Guerard", "Sonia Djebali", "Soufian Ben Amor"], "title": "PretopoMD: Pretopology-based Mixed Data Hierarchical Clustering", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This article presents a novel pretopology-based algorithm designed to address the challenges of clustering mixed data without the need for dimensionality reduction. Leveraging Disjunctive Normal Form, our approach formulates customizable logical rules and adjustable hyperparameters that allow for user-defined hierarchical cluster construction and facilitate tailored solutions for heterogeneous datasets. Through hierarchical dendrogram analysis and comparative clustering metrics, our method demonstrates superior performance by accurately and interpretably delineating clusters directly from raw data, thus preserving data integrity. Empirical findings highlight the algorithm's robustness in constructing meaningful clusters and reveal its potential in overcoming issues related to clustered data explainability. The novelty of this work lies in its departure from traditional dimensionality reduction techniques and its innovative use of logical rules that enhance both cluster formation and clarity, thereby contributing a significant advancement to the discourse on clustering mixed data.", "AI": {"tldr": "The paper introduces a pretopology-based clustering algorithm for mixed data that operates directly on raw data without dimensionality reduction, enhancing interpretability and preserving integrity.", "motivation": "Current clustering methods often rely on dimensionality reduction, which can compromise data integrity, and lack interpretability in dealing with heterogeneous datasets.", "method": "The approach utilizes pretopology and Disjunctive Normal Form to enable customizable logical rules and adjustable hyperparameters for constructing hierarchical clusters directly from raw data.", "result": "Empirical tests show the algorithm\u2019s robustness, its ability to create meaningful and interpretable clusters, and its advantage in overcoming explainability challenges in clustered data.", "conclusion": "The work offers a novel perspective on clustering mixed data by avoiding traditional dimensionality reduction and employing logical rules, making it a significant contribution to clustering methods for heterogeneous datasets."}}
{"id": "2512.03630", "pdf": "https://arxiv.org/pdf/2512.03630", "abs": "https://arxiv.org/abs/2512.03630", "authors": ["Shifa Sulaiman", "Amarnath H", "Simon Bogh", "Naresh Marturi"], "title": "Multimodal Control of Manipulators: Coupling Kinematics and Vision for Self-Driving Laboratory Operations", "categories": ["cs.RO"], "comment": null, "summary": "Motion planning schemes are used for planning motions of a manipulator from an initial pose to a final pose during a task execution. A motion planning scheme generally comprises of a trajectory planning method and an inverse kinematic solver to determine trajectories and joints solutions respectively. In this paper, 3 motion planning schemes developed based on Jacobian methods are implemented to traverse a redundant manipulator with a coupled finger gripper through given trajectories. RRT* algorithm is used for planning trajectories and screw theory based forward kinematic equations are solved for determining joint solutions of the manipulator and gripper. Inverse solutions are computed separately using 3 Jacobian based methods such as Jacobian Transpose (JT), Pseudo Inverse (PI), and Damped Least Square (DLS) methods. Space Jacobian and manipulability measurements of the manipulator and gripper are obtained using screw theory formulations. Smoothness and RMSE error of generated trajectories and velocity continuity, acceleration profile, jerk, and snap values of joint motions are analysed for determining an efficient motion planning method for a given task. Advantages and disadvantages of the proposed motion planning schemes mentioned above are analysed using simulation studies to determine a suitable inverse solution technique for the tasks.", "AI": {"tldr": "The paper evaluates three Jacobian-based motion planning schemes for a redundant manipulator, comparing trajectory smoothness, errors, and joint motion efficiency.", "motivation": "The paper aims to improve motion planning for redundant manipulators by assessing different Jacobian-based methods for trajectory smoothness and motion efficiency.", "method": "Three Jacobian-based inverse kinematic methods (Jacobian Transpose, Pseudo Inverse, Damped Least Square) are evaluated within a motion planning framework using RRT* for trajectory planning and screw theory for kinematic calculations.", "result": "Trajectories were analyzed for smoothness, error levels, velocity continuity, and dynamics using simulation studies to identify the most suitable inverse method.", "conclusion": "The study identifies efficient motion planning schemes, providing insights into the strengths and weaknesses of each inverse solution technique for specific robotic tasks."}}
{"id": "2512.03783", "pdf": "https://arxiv.org/pdf/2512.03783", "abs": "https://arxiv.org/abs/2512.03783", "authors": ["Dongchao Yang", "Songxiang Liu", "Disong Wang", "Yuanyuan Wang", "Guanglu Wan", "Helen Meng"], "title": "Omni-AutoThink: Adaptive Multimodal Reasoning via Reinforcement Learning", "categories": ["cs.AI", "cs.SD"], "comment": null, "summary": "Recent advances in Omni models have enabled unified multimodal perception and generation. However, most existing systems still exhibit rigid reasoning behaviors, either overthinking simple problems or failing to reason when necessary. To address this limitation, we propose Omni-AutoThink, a novel adaptive reasoning framework that dynamically adjusts the model's reasoning depth according to task difficulty. Our framework comprises two stages: (1) an Adaptive Supervised Fine-Tuning (Adaptive SFT) stage, which endows the Omni model with fundamental reasoning capability using large-scale reasoning-augmented data, and (2) an Adaptive Reinforcement Learning (Adaptive GRPO) stage, which optimizes reasoning behaviors based on task complexity and reward feedback. We further construct a comprehensive adaptive reasoning benchmark that spans text-only, text-audio, text-visual, and text-audio-visual modalities, providing both training and evaluation splits for multimodal reasoning assessment. Experimental results demonstrate that our proposed framework significantly improves adaptive reasoning performance compared to previous baselines. All benchmark data and code will be publicly released.", "AI": {"tldr": "Omni-AutoThink introduces an adaptive reasoning framework for multimodal models, adjusting reasoning depth based on task complexity.", "motivation": "Current multimodal models struggle with static reasoning, either overthinking or underestimating tasks, which limits their effectiveness.", "method": "The paper proposes a two-stage framework: Adaptive Fine-Tuning and Reinforcement Learning to train models for dynamic reasoning.", "result": "The approach demonstrated improved adaptive reasoning across modalities, validated by a new benchmark and experimental comparisons.", "conclusion": "Omni-AutoThink enhances multimodal reasoning adaptiveness, supported by public datasets and code for further research."}}
{"id": "2512.03402", "pdf": "https://arxiv.org/pdf/2512.03402", "abs": "https://arxiv.org/abs/2512.03402", "authors": ["Yixing Xu", "Chao Li", "Xuanwu Yin", "Spandan Tiwari", "Dong Li", "Ashish Sirasao", "Emad Barsoum"], "title": "Dual LoRA: Enhancing LoRA with Magnitude and Direction Updates", "categories": ["cs.CL"], "comment": null, "summary": "Low-rank adaptation (LoRA) is one of the most popular methods among parameter-efficient fine-tuning (PEFT) methods to adapt pre-trained large language models (LLMs) to specific downstream tasks. However, the model trained based on LoRA often has an unsatisfactory performance due to its low-rank assumption. In this paper, we propose a novel method called Dual LoRA to improve the performance by incorporating an inductive bias into the original LoRA. Specifically, we separate low-rank matrices into two groups: the magnitude group to control whether or not and how far we should update a parameter and the direction group to decide whether this parameter should move forward or backward, to better simulate the parameter updating process of the full fine-tuning based on gradient-based optimization algorithms. We show that this can be simply achieved by adding a ReLU function to the magnitude group and a sign function to the direction group. We conduct several experiments over a wide range of NLP tasks, including natural language generation (NLG), understanding (NLU), and commonsense reasoning datasets on GPT-2, RoBERTa, DeBERTa, and LLaMA-1/2/3 as baseline models. The results show that we consistently outperform LoRA and its state-of-the-art variants with the same number of trainable parameters.", "AI": {"tldr": "Proposed a new PEFT method called Dual LoRA that outperforms traditional LoRA methods by introducing inductive bias for better downstream task performance.", "motivation": "Standard LoRA struggles with suboptimal results due to its low-rank constraint. This paper introduces an improvement to overcome that limitation for better fine-tuning of LLMs.", "method": "Dual LoRA divides low-rank matrices into two groups: magnitude (controls degree of update) and direction (determines optimization path). This approach incorporates ReLU and sign functions to simulate gradient updates.", "result": "Across diverse NLP tasks and baseline models like GPT-2, RoBERTa, and LLaMA-1/2/3, Dual LoRA surpasses traditional LoRA and its variants with equal trainable parameters.", "conclusion": "Dual LoRA demonstrates better efficiency and performance than LoRA, suggesting a promising improvement for fine-tuning LLMs in various NLP applications."}}
{"id": "2512.03238", "pdf": "https://arxiv.org/pdf/2512.03238", "abs": "https://arxiv.org/abs/2512.03238", "authors": ["Natalia Ponomareva", "Zheng Xu", "H. Brendan McMahan", "Peter Kairouz", "Lucas Rosenblatt", "Vincent Cohen-Addad", "Crist\u00f3bal Guzm\u00e1n", "Ryan McKenna", "Galen Andrew", "Alex Bie", "Da Yu", "Alex Kurakin", "Morteza Zadimoghaddam", "Sergei Vassilvitskii", "Andreas Terzis"], "title": "How to DP-fy Your Data: A Practical Guide to Generating Synthetic Data With Differential Privacy", "categories": ["cs.CR", "cs.AI", "cs.LG", "stat.ML"], "comment": null, "summary": "High quality data is needed to unlock the full potential of AI for end users. However finding new sources of such data is getting harder: most publicly-available human generated data will soon have been used. Additionally, publicly available data often is not representative of users of a particular system -- for example, a research speech dataset of contractors interacting with an AI assistant will likely be more homogeneous, well articulated and self-censored than real world commands that end users will issue. Therefore unlocking high-quality data grounded in real user interactions is of vital interest. However, the direct use of user data comes with significant privacy risks. Differential Privacy (DP) is a well established framework for reasoning about and limiting information leakage, and is a gold standard for protecting user privacy. The focus of this work, \\emph{Differentially Private Synthetic data}, refers to synthetic data that preserves the overall trends of source data,, while providing strong privacy guarantees to individuals that contributed to the source dataset. DP synthetic data can unlock the value of datasets that have previously been inaccessible due to privacy concerns and can replace the use of sensitive datasets that previously have only had rudimentary protections like ad-hoc rule-based anonymization.\n  In this paper we explore the full suite of techniques surrounding DP synthetic data, the types of privacy protections they offer and the state-of-the-art for various modalities (image, tabular, text and decentralized). We outline all the components needed in a system that generates DP synthetic data, from sensitive data handling and preparation, to tracking the use and empirical privacy testing. We hope that work will result in increased adoption of DP synthetic data, spur additional research and increase trust in DP synthetic data approaches.", "AI": {"tldr": "The paper investigates Differential Privacy (DP) synthetic data, aiming to preserve trends of sensitive source data with privacy guarantees. This method can address privacy concerns and enhance data usability across various domains.", "motivation": "To address challenges in acquiring high-quality, representative datasets for AI systems while ensuring user privacy and overcoming limitations in relying on sensitive data or low-quality anonymization methods.", "method": "Detailed exploration of DP synthetic data techniques, their privacy protections, and state-of-the-art methods across different data modalities (image, tabular, text, decentralized). Discussion includes system components ensuring effective handling of sensitive data and empirical privacy testing.", "result": "A comprehensive outline of strategies and guidelines for generating and adopting DP synthetic data, across various applications, while retaining user privacy.", "conclusion": "DP synthetic data could unlock inaccessible datasets hindered by privacy concerns, spur research, and promote trust, making it a valuable resource for enhancing AI systems."}}
{"id": "2512.03345", "pdf": "https://arxiv.org/pdf/2512.03345", "abs": "https://arxiv.org/abs/2512.03345", "authors": ["Seunghoi Kim", "Henry F. J. Tregidgo", "Chen Jin", "Matteo Figini", "Daniel C. Alexander"], "title": "HalluGen: Synthesizing Realistic and Controllable Hallucinations for Evaluating Image Restoration", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Generative models are prone to hallucinations: plausible but incorrect structures absent in the ground truth. This issue is problematic in image restoration for safety-critical domains such as medical imaging, industrial inspection, and remote sensing, where such errors undermine reliability and trust. For example, in low-field MRI, widely used in resource-limited settings, restoration models are essential for enhancing low-quality scans, yet hallucinations can lead to serious diagnostic errors. Progress has been hindered by a circular dependency: evaluating hallucinations requires labeled data, yet such labels are costly and subjective. We introduce HalluGen, a diffusion-based framework that synthesizes realistic hallucinations with controllable type, location, and severity, producing perceptually realistic but semantically incorrect outputs (segmentation IoU drops from 0.86 to 0.36). Using HalluGen, we construct the first large-scale hallucination dataset comprising 4,350 annotated images derived from 1,450 brain MR images for low-field enhancement, enabling systematic evaluation of hallucination detection and mitigation. We demonstrate its utility in two applications: (1) benchmarking image quality metrics and developing Semantic Hallucination Assessment via Feature Evaluation (SHAFE), a feature-based metric with soft-attention pooling that improves hallucination sensitivity over traditional metrics; and (2) training reference-free hallucination detectors that generalize to real restoration failures. Together, HalluGen and its open dataset establish the first scalable foundation for evaluating hallucinations in safety-critical image restoration.", "AI": {"tldr": "The paper introduces 'HalluGen,' a diffusion-based framework to synthesize controlled hallucinations in image restoration, focusing on safety-critical domains like medical imaging. HalluGen enables systematic benchmarking and detection/mitigation of hallucination issues.", "motivation": "Hallucinations in generative image restoration models can lead to serious errors in medical imaging and other high-stakes fields. However, evaluation relies on labeled data, which is currently expensive and inconsistent.", "method": "HalluGen generates controlled hallucinations (synthetic errors) in terms of type, location, and severity. It constructs a large-scale dataset with 4,350 annotated images to assist in systematic evaluation and detection methods.", "result": "HalluGen successfully benchmarks image quality metrics and develops a new feature-based algorithm, SHAFE, to improve hallucination sensitivity. It also trains hallucination detectors that can generalize to actual restoration failures.", "conclusion": "The work establishes HalluGen alongside an open dataset as a scalable approach to evaluate and mitigate hallucinations, thus improving reliability in safety-critical image restoration domains."}}
{"id": "2512.03074", "pdf": "https://arxiv.org/pdf/2512.03074", "abs": "https://arxiv.org/abs/2512.03074", "authors": ["Mahdi Tavassoli Kejani", "Fadi Dornaika", "Jean-Michel Loubes"], "title": "Model-Agnostic Fairness Regularization for GNNs with Incomplete Sensitive Information", "categories": ["cs.LG", "cs.CY", "cs.SI"], "comment": null, "summary": "Graph Neural Networks (GNNs) have demonstrated exceptional efficacy in relational learning tasks, including node classification and link prediction. However, their application raises significant fairness concerns, as GNNs can perpetuate and even amplify societal biases against protected groups defined by sensitive attributes such as race or gender. These biases are often inherent in the node features, structural topology, and message-passing mechanisms of the graph itself. A critical limitation of existing fairness-aware GNN methods is their reliance on the strong assumption that sensitive attributes are fully available for all nodes during training--a condition that poses a practical impediment due to privacy concerns and data collection constraints. To address this gap, we propose a novel, model-agnostic fairness regularization framework designed for the realistic scenario where sensitive attributes are only partially available. Our approach formalizes a fairness-aware objective function that integrates both equal opportunity and statistical parity as differentiable regularization terms. Through a comprehensive empirical evaluation across five real-world benchmark datasets, we demonstrate that the proposed method significantly mitigates bias across key fairness metrics while maintaining competitive node classification performance. Results show that our framework consistently outperforms baseline models in achieving a favorable fairness-accuracy trade-off, with minimal degradation in predictive accuracy. The datasets and source code will be publicly released at https://github.com/mtavassoli/GNN-FC.", "AI": {"tldr": "The paper addresses fairness in Graph Neural Networks (GNNs) by proposing a framework that does not assume full availability of sensitive attributes, demonstrating effectiveness in reducing bias while maintaining competitive performance.", "motivation": "The motivation is to tackle fairness issues in GNNs where biases in data and mechanisms could perpetuate inequality among protected groups, especially when sensitive attributes are partially unavailable, a common practical limitation.", "method": "The paper introduces a model-agnostic fairness regularization framework incorporating equal opportunity and statistical parity as differentiable terms in the objective function, addressing limited access to sensitive attributes.", "result": "Empirical evaluation across five datasets shows that the proposed approach effectively reduces bias across fairness metrics while maintaining competitive classification accuracy, outperforming baseline models in balancing fairness and performance.", "conclusion": "The proposed framework achieves a favorable trade-off between fairness and accuracy and operates effectively even with partial sensitive attribute availability, with its datasets and code to be publicly shared for reproducibility."}}
{"id": "2512.03639", "pdf": "https://arxiv.org/pdf/2512.03639", "abs": "https://arxiv.org/abs/2512.03639", "authors": ["Kilian Schweppe", "Anne-Kathrin Schmuck"], "title": "Context-Triggered Contingency Games for Strategic Multi-Agent Interaction", "categories": ["cs.RO"], "comment": null, "summary": "We address the challenge of reliable and efficient interaction in autonomous multi-agent systems, where agents must balance long-term strategic objectives with short-term dynamic adaptation. We propose context-triggered contingency games, a novel integration of strategic games derived from temporal logic specifications with dynamic contingency games solved in real time. Our two-layered architecture leverages strategy templates to guarantee satisfaction of high-level objectives, while a new factor-graph-based solver enables scalable, real-time model predictive control of dynamic interactions. The resulting framework ensures both safety and progress in uncertain, interactive environments. We validate our approach through simulations and hardware experiments in autonomous driving and robotic navigation, demonstrating efficient, reliable, and adaptive multi-agent interaction.", "AI": {"tldr": "The paper introduces a framework for reliable and efficient interaction in multi-agent systems by combining strategic games and dynamic contingency games, validated through simulations.", "motivation": "To address the challenge of balancing long-term objectives with short-term dynamic adaptation in autonomous multi-agent systems.", "method": "A two-layered architecture integrating strategy templates for high-level objectives and a factor-graph-based real-time solver for dynamic interactions.", "result": "The framework ensures safety, progress, and adaptability validated through simulations and hardware experiments in autonomous driving and robotics.", "conclusion": "The proposed approach achieves reliable, efficient, and adaptive interaction in uncertain multi-agent environments."}}
{"id": "2512.03887", "pdf": "https://arxiv.org/pdf/2512.03887", "abs": "https://arxiv.org/abs/2512.03887", "authors": ["Saurav Prateek"], "title": "A Hierarchical Tree-based approach for creating Configurable and Static Deep Research Agent (Static-DRA)", "categories": ["cs.AI"], "comment": null, "summary": "The advancement in Large Language Models has driven the creation of complex agentic systems, such as Deep Research Agents (DRAs), to overcome the limitations of static Retrieval Augmented Generation (RAG) pipelines in handling complex, multi-turn research tasks. This paper introduces the Static Deep Research Agent (Static-DRA), a novel solution built upon a configurable and hierarchical Tree-based static workflow.\n  The core contribution is the integration of two user-tunable parameters, Depth and Breadth, which provide granular control over the research intensity. This design allows end-users to consciously balance the desired quality and comprehensiveness of the research report against the associated computational cost of Large Language Model (LLM) interactions. The agent's architecture, comprising Supervisor, Independent, and Worker agents, facilitates effective multi-hop information retrieval and parallel sub-topic investigation.\n  We evaluate the Static-DRA against the established DeepResearch Bench using the RACE (Reference-based Adaptive Criteria-driven Evaluation) framework. Configured with a depth of 2 and a breadth of 5, and powered by the gemini-2.5-pro model, the agent achieved an overall score of 34.72. Our experiments validate that increasing the configured Depth and Breadth parameters results in a more in-depth research process and a correspondingly higher evaluation score. The Static-DRA offers a pragmatic and resource-aware solution, empowering users with transparent control over the deep research process. The entire source code, outputs and benchmark results are open-sourced at https://github.com/SauravP97/Static-Deep-Research/", "AI": {"tldr": "The paper presents Static-DRA, a configurable agentic system for in-depth research leveraging LLMs, achieving significant results through tunable parameters.", "motivation": "To address limitations of static Retrieval Augmented Generation (RAG) pipelines in handling complex, multi-turn research tasks.", "method": "Introduces Static-DRA with hierarchical Tree-based workflows and tunable Depth and Breadth parameters for granular research intensity control.", "result": "Static-DRA achieved a score of 34.72 in RACE evaluation, demonstrating enhanced depth with increased Depth and Breadth configurations.", "conclusion": "Static-DRA provides a resource-efficient and customizable solution for deep research tasks, enhancing transparency and control for users."}}
{"id": "2512.03442", "pdf": "https://arxiv.org/pdf/2512.03442", "abs": "https://arxiv.org/abs/2512.03442", "authors": ["Xingrun Xing", "Zhiyuan Fan", "Jie Lou", "Guoqi Li", "Jiajun Zhang", "Debing Zhang"], "title": "PretrainZero: Reinforcement Active Pretraining", "categories": ["cs.CL"], "comment": null, "summary": "Mimicking human behavior to actively learning from general experience and achieve artificial general intelligence has always been a human dream. Recent reinforcement learning (RL) based large-thinking models demonstrate impressive expert-level abilities, i.e., software and math, but still rely heavily on verifiable rewards in specific domains, placing a significant bottleneck to extend the performance boundary of general reasoning capabilities. In this work, we propose PretrainZero, a reinforcement active learning framework built on the pretraining corpus to extend RL from domain-specific post-training to general pretraining. PretrainZero features the following characteristics: 1) Active pretraining: inspired by the active learning ability of humans, PretrainZero learns a unified reasoning policy to actively identify reasonable and informative contents from pretraining corpus, and reason to predict these contents by RL. 2) Self-supervised learning: without any verifiable labels, pretrained reward models, or supervised fine-tuning, we directly pretrain reasoners from 3 to 30B base models on the general Wikipedia corpus using RL, significantly breaking the verification data-wall for general reasoning. 3) Verification scaling: by tackling increasingly challenging masked spans, PretrainZero substantially enhances the general reasoning abilities of pretrained base models. In reinforcement pretraining, PretrainZero improves Qwen3-4B-Base for 8.43, 5.96 and 10.60 on MMLU-Pro, SuperGPQA and math average benchmarks. In post-training, the pretrained models can also serve as reasoning foundation models for downstream RLVR tasks.", "AI": {"tldr": "PretrainZero introduces a reinforcement learning framework that actively pretrains models using general corpora, bypassing domain-specific limitations.", "motivation": "The paper seeks to address the limitations of reinforcement learning (RL) models in general reasoning by extending RL's application from domain-specific post-training to general pretraining.", "method": "They propose PretrainZero, which enables active learning from general corpora, utilizes self-supervised techniques without relying on labeled data or pretrained rewards, and scales reasoning capabilities through reinforcement pretraining.", "result": "PretrainZero significantly improves reasoning capabilities in benchmarks like MMLU-Pro, SuperGPQA, and math tasks, showcasing enhanced performance in pretrained and post-trained models.", "conclusion": "PretrainZero breaks the dependency on domain-specific data, advancing the development of general reasoning AI and providing foundational models for downstream tasks."}}
{"id": "2512.03322", "pdf": "https://arxiv.org/pdf/2512.03322", "abs": "https://arxiv.org/abs/2512.03322", "authors": ["Geoffrey J. McLachlan", "Jinran Wu"], "title": "SSLfmm: An R Package for Semi-Supervised Learning with a Mixed-Missingness Mechanism in Finite Mixture Models", "categories": ["stat.CO", "stat.ME", "stat.ML"], "comment": "15 pages, 1 figure", "summary": "Semi-supervised learning (SSL) constructs classifiers from datasets in which only a subset of observations is labelled, a situation that naturally arises because obtaining labels often requires expert judgement or costly manual effort. This motivates methods that integrate labelled and unlabelled data within a learning framework. Most SSL approaches assume that label absence is harmless, typically treated as missing completely at random or ignored, but in practice, the missingness process can be informative, as the chances of an observation being unlabelled may depend on the ambiguity of its feature vector. In such cases, the missingness indicators themselves provide additional information that, if properly modelled, may improve estimation efficiency. The \\textbf{SSLfmm} package for R is designed to capture this behaviour by estimating the Bayes' classifier under a finite mixture model in which each component corresponding to a class follows a multivariate normal distribution. It incorporates a mixed-missingness mechanism that combines a missing completely at random (MCR) component with a (non-ignorable) missing at random (MAR) component, the latter modelling the probability of label missingness as a logistic function of the entropy based on the features. Parameters are estimated via an Expectation--Conditional Maximisation algorithm. In the two-class Gaussian setting with arbitrary covariance matrices, the resulting classifier trained on partially labelled data may, in some cases, achieve a lower misclassification rate than the supervised version in the case where all the labels are known. The package includes a practical tool for modelling and illustrates its performance through simulated examples.", "AI": {"tldr": "The paper introduces the SSLfmm R package for semi-supervised learning, integrating labelled and unlabelled data with a focus on informative missingness, and demonstrates its advantages over traditional supervised approaches.", "motivation": "To improve semi-supervised learning methodologies by accounting for the informative nature of missing labels, which are often linked to the ambiguity of the feature vectors, enabling better use of partially labelled datasets.", "method": "The paper proposes the SSLfmm package, utilizing a Bayes' classifier under a finite mixture model with multivariate normal components and a mixed-missingness mechanism combining MCR and MAR elements. Parameters are estimated using the Expectation--Conditional Maximisation algorithm.", "result": "The developed classifier demonstrated, in certain scenarios, lower misclassification rates using partially labelled data compared to fully labelled supervised models, particularly under specific Gaussian settings.", "conclusion": "This work shows that integrating a mixed-missingness mechanism improves estimation efficiency and classification performance, offering practical tools implemented in the SSLfmm package."}}
{"id": "2512.03346", "pdf": "https://arxiv.org/pdf/2512.03346", "abs": "https://arxiv.org/abs/2512.03346", "authors": ["Lynn Kandakji", "William Woof", "Nikolas Pontikos"], "title": "Hierarchical Attention for Sparse Volumetric Anomaly Detection in Subclinical Keratoconus", "categories": ["cs.CV"], "comment": "16 pages, 7 figures, 6 tables", "summary": "The detection of weak, spatially distributed anomalies in volumetric medical imaging remains a major challenge. The subtle, non-adjacent nature of early disease signals is often lost due to suboptimal architectural inductive biases: 2D/3D CNNs impose strong locality, while ViTs diffuse unconstrained global attention. This conflict leaves the optimal inductive structure for robust, sparse volumetric pattern recognition unresolved. This study presents a controlled comparison of sixteen modern deep learning architectures spanning 2D/3D convolutional, hybrid, and volumetric transformer families for subclinical keratoconus (SKC) detection from 3D anterior segment OCT volumes. We demonstrate that hierarchical attention models offer a superior and more parameter-efficient inductive bias, surpassing the performance of both 2D and 3D CNNs and ViTs. Our results show 21-23% higher sensitivity and specificity in the sparse anomaly (subclinical) regime. Mechanistic analyses reveal that this advantage stems from precise spatial scale alignment: hierarchical windowing produces effective receptive fields matched to the intermediate, multi-slice extent of subclinical abnormalities. This avoids excessive CNN locality and diffuse global attention. Attention-distance measurements confirm a key insight into architectural adaptation: the required spatial integration length shifts significantly based on the signal strength, with subclinical cases necessitating longer integration compared to both healthy and manifest disease states. Representational similarity and auxiliary age/sex prediction tasks further support the generalizability of these inductive principles. The findings provide design guidance for future volumetric anomaly detection systems, establishing hierarchical attention as a principled and effective approach for early pathological change analysis in 3D medical imaging.", "AI": {"tldr": "This paper examines 16 modern deep learning architectures to detect subtle anomalies in 3D medical imaging, finding hierarchical attention models outperform others in sensitivity and specificity.", "motivation": "The paper aims to address challenges in detecting faint anomalies in volumetric medical imaging due to the limitations of CNNs and ViTs, which lack the optimal inductive bias for sparse, distributed pattern recognition.", "method": "The study conducted a controlled evaluation of sixteen 2D/3D convolutional, hybrid, and volumetric transformer architectures on detecting subclinical keratoconus from 3D OCT volumes.", "result": "Hierarchical attention models showed superior performance, with a 21-23% improvement in sensitivity and specificity compared to 2D/3D CNNs and ViTs, by aligning spatial scales with the nature of subclinical anomalies.", "conclusion": "The findings advocate for hierarchical attention models as effective tools for volumetric anomaly detection, due to their ability to adapt spatial integration to signal strength and optimize early anomaly detection in 3D medical imaging."}}
{"id": "2512.03078", "pdf": "https://arxiv.org/pdf/2512.03078", "abs": "https://arxiv.org/abs/2512.03078", "authors": ["Vahid R. Ramezani", "Benjamin Englard"], "title": "Risk-Entropic Flow Matching", "categories": ["cs.LG"], "comment": "29 pages, 5 figures", "summary": "Tilted (entropic) risk, obtained by applying a log-exponential transform to a base loss, is a well established tool in statistics and machine learning for emphasizing rare or high loss events while retaining a tractable optimization problem. In this work, our aim is to interpret its structure for Flow Matching (FM). FM learns a velocity field that transports samples from a simple source distribution to data by integrating an ODE. In rectified FM, training pairs are obtained by linearly interpolating between a source sample and a data sample, and a neural velocity field is trained to predict the straight line displacement using a mean squared error loss. This squared loss collapses all velocity targets that reach the same space-time point into a single conditional mean, thereby ignoring higher order conditional information (variance, skewness, multi-modality) that encodes fine geometric structure about the data manifold and minority branches. We apply the standard risk-sensitive (log-exponential) transform to the conditional FM loss and show that the resulting tilted risk loss is a natural upper-bound on a meaningful conditional entropic FM objective defined at each space-time point. Furthermore, we show that a small order expansion of the gradient of this conditional entropic objective yields two interpretable first order corrections: covariance preconditioning of the FM residual, and a skew tail term that favors asymmetric or rare branches. On synthetic data designed to probe ambiguity and tails, the resulting risk-sensitive loss improves statistical metrics and recovers geometric structure more faithfully than standard rectified FM.", "AI": {"tldr": "The paper proposes applying a tilted risk approach to improve Flow Matching methods in machine learning, enhancing the handling of rare or ambiguous data structures.", "motivation": "The motivation stems from the limitations of current Flow Matching methods, which use squared loss that neglect higher-order conditional information, such as variance, skewness, or multi-modality. These omissions lead to poor handling of fine geometric structures and minority branches in data.", "method": "To address this, the paper applies a log-exponential (entropic) transform to the training loss in Flow Matching tasks. This creates a tilted risk-sensitive loss that emphasizes rare or high-loss events. The gradient of the entropic loss is analyzed to derive corrections, including covariance preconditioning and a skew tail term.", "result": "Empirical experiments on synthetic datasets demonstrate that the tilted risk-sensitive loss provides better statistical metrics and recovers data geometric structures more faithfully than standard methods.", "conclusion": "The paper concludes that integrating a tilted risk approach in Flow Matching can enhance its ability to learn fine details, handle rare events, and model the data manifold more effectively."}}
{"id": "2512.03684", "pdf": "https://arxiv.org/pdf/2512.03684", "abs": "https://arxiv.org/abs/2512.03684", "authors": ["Shahid Ansari", "Mahendra Kumar Gohil", "Yusuke Maeda", "Bishakh Bhattacharya"], "title": "A Novel Approach to Tomato Harvesting Using a Hybrid Gripper with Semantic Segmentation and Keypoint Detection", "categories": ["cs.RO"], "comment": null, "summary": "This paper presents an autonomous tomato-harvesting system built around a hybrid robotic gripper that combines six soft auxetic fingers with a rigid exoskeleton and a latex basket to achieve gentle, cage-like grasping. The gripper is driven by a servo-actuated Scotch--yoke mechanism, and includes separator leaves that form a conical frustum for fruit isolation, with an integrated micro-servo cutter for pedicel cutting. For perception, an RGB--D camera and a Detectron2-based pipeline perform semantic segmentation of ripe/unripe tomatoes and keypoint localization of the pedicel and fruit center under occlusion and variable illumination. An analytical model derived using the principle of virtual work relates servo torque to grasp force, enabling design-level reasoning about actuation requirements. During execution, closed-loop grasp-force regulation is achieved using a proportional--integral--derivative controller with feedback from force-sensitive resistors mounted on selected fingers to prevent slip and bruising. Motion execution is supported by Particle Swarm Optimization (PSO)--based trajectory planning for a 5-DOF manipulator. Experiments demonstrate complete picking cycles (approach, separation, cutting, grasping, transport, release) with an average cycle time of 24.34~s and an overall success rate of approximately 80\\%, while maintaining low grasp forces (0.20--0.50~N). These results validate the proposed hybrid gripper and integrated vision--control pipeline for reliable harvesting in cluttered environments.", "AI": {"tldr": "This paper introduces an autonomous tomato-harvesting system using a hybrid robotic gripper, achieving efficient and low-force grasping with integrated vision-control mechanisms.", "motivation": "The goal is to automate tomato harvesting reliably and efficiently in cluttered environments while minimizing damage to the fruits.", "method": "The system uses a hybrid robotic gripper with soft and rigid components, a servo-actuated mechanism, vision-based segmentation, closed-loop grasp-force regulation, and trajectory optimization for precise harvesting.", "result": "The system achieves a success rate of approximately 80% with an average cycle time of 24.34 seconds and low grasp forces (0.20\u20130.50 N).", "conclusion": "The hybrid gripper system and vision-control pipeline are effective for autonomous harvesting of tomatoes in complex scenarios."}}
{"id": "2512.03931", "pdf": "https://arxiv.org/pdf/2512.03931", "abs": "https://arxiv.org/abs/2512.03931", "authors": ["Vineel Tummala", "Daniela Inclezan"], "title": "Autonomous Agents and Policy Compliance: A Framework for Reasoning About Penalties", "categories": ["cs.AI"], "comment": "27 pages, 5 figures", "summary": "This paper presents a logic programming-based framework for policy-aware autonomous agents that can reason about potential penalties for non-compliance and act accordingly. While prior work has primarily focused on ensuring compliance, our approach considers scenarios where deviating from policies may be necessary to achieve high-stakes goals. Additionally, modeling non-compliant behavior can assist policymakers by simulating realistic human decision-making. Our framework extends Gelfond and Lobo's Authorization and Obligation Policy Language (AOPL) to incorporate penalties and integrates Answer Set Programming (ASP) for reasoning. Compared to previous approaches, our method ensures well-formed policies, accounts for policy priorities, and enhances explainability by explicitly identifying rule violations and their consequences. Building on the work of Harders and Inclezan, we introduce penalty-based reasoning to distinguish between non-compliant plans, prioritizing those with minimal repercussions. To support this, we develop an automated translation from the extended AOPL into ASP and refine ASP-based planning algorithms to account for incurred penalties. Experiments in two domains demonstrate that our framework generates higher-quality plans that avoid harmful actions while, in some cases, also improving computational efficiency. These findings underscore its potential for enhancing autonomous decision-making and informing policy refinement. Under consideration in Theory and Practice of Logic Programming (TPLP).", "AI": {"tldr": "The paper introduces a framework for autonomous agents to evaluate and act based on penalties for policy non-compliance using logic programming.", "motivation": "To reason about scenarios where autonomous agents may need to deviate from policies to achieve critical goals and to improve policy refinement by modeling realistic decision-making.", "method": "The framework extends the Authorization and Obligation Policy Language (AOPL) to include penalties and integrates it with Answer Set Programming (ASP) for policy-aware reasoning and planning with minimal policy violations.", "result": "Experimental results demonstrate that the framework produces higher-quality plans, avoids harmful actions, and, in some cases, improves computational efficiency.", "conclusion": "The framework can enhance autonomous decision-making, ensure accountable non-compliance handling, and aid policymakers by simulating realistic agent behaviors."}}
{"id": "2512.03494", "pdf": "https://arxiv.org/pdf/2512.03494", "abs": "https://arxiv.org/abs/2512.03494", "authors": ["Di Xiu", "Hongyin Tang", "Bolin Rong", "Lizhi Yan", "Jingang Wang", "Yifan Lu", "Xunliang Cai"], "title": "A Preliminary Study on the Promises and Challenges of Native Top-$k$ Sparse Attention", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly prevalent in the field of long-context modeling, however, their inference computational costs have become a critical bottleneck hindering the advancement of tasks such as agents and multimodal applications. This report conducts a preliminary investigation into the effectiveness and theoretical mechanisms of the Top-$k$ Attention mechanism during both the decoding and training phases. First, we validate the effectiveness of exact Top-$k$ Decoding through extensive experimentation. Experiments demonstrate that retaining only the pivotal Keys with the highest similarity to the Query as the context window during the decoding stage achieves performance comparable to, or even surpassing, full attention on downstream tasks such as HELMET and LongBench v2. Second, we further explore the native Top-$k$ Attention training strategy. Experiments confirm that ensuring the consistency between training and inference regarding Top-$k$ Attention operations facilitates the further unlocking of Top-$k$ Decoding's potential, thereby significantly enhancing model performance. Furthermore, considering the high computational complexity of exact Top-$k$ Attention, we investigate the impact of approximate Top-$k$ algorithm precision on downstream tasks. Our research confirms a positive correlation between downstream task performance and approximation fidelity, and we provide statistical evaluations of the Lightning Indexer's precision within the DeepSeek-V3.2-Exp model. Finally, this report provides a theoretical interpretation from the perspective of Entropy. Experimental observations indicate that models subjected to Top-$k$ Attention SFT exhibit a distinct phenomenon of entropy reduction in downstream tasks, which validates the hypothesis that low-entropy states are better adapted to Top-$k$ Decoding.", "AI": {"tldr": "This paper examines the Top-k attention mechanism for improving efficiency in Large Language Models (LLMs) during decoding and training phases, demonstrating its comparable or superior performance over full attention on specific tasks and providing theoretical justification.", "motivation": "The paper seeks to address the computational bottleneck of Large Language Models, which impedes progress in long-context modeling tasks such as agents and multimodal applications.", "method": "The authors validate the Top-k mechanisms through extensive experimentation and investigate exact, approximate, and training-strategy implementations. They provide a theoretical analysis using entropy.", "result": "The experiments show that Top-k Decoding achieves comparable or better performance than full attention, and consistent training improves results further. Approximation methods demonstrated that higher fidelity correlates with task performance.", "conclusion": "Top-k Attention reduces entropy in downstream tasks, aligning with the hypothesis that low-entropy states are better suited for Top-k Decoding, enhancing LLM efficiency without sacrificing performance."}}
{"id": "2512.03325", "pdf": "https://arxiv.org/pdf/2512.03325", "abs": "https://arxiv.org/abs/2512.03325", "authors": ["Garrett G. Wen", "Hong Hu", "Yue M. Lu", "Zhou Fan", "Theodor Misiakiewicz"], "title": "When does Gaussian equivalence fail and how to fix it: Non-universal behavior of random features with quadratic scaling", "categories": ["math.ST", "cs.LG", "stat.ML"], "comment": null, "summary": "A major effort in modern high-dimensional statistics has been devoted to the analysis of linear predictors trained on nonlinear feature embeddings via empirical risk minimization (ERM). Gaussian equivalence theory (GET) has emerged as a powerful universality principle in this context: it states that the behavior of high-dimensional, complex features can be captured by Gaussian surrogates, which are more amenable to analysis. Despite its remarkable successes, numerical experiments show that this equivalence can fail even for simple embeddings -- such as polynomial maps -- under general scaling regimes.\n  We investigate this breakdown in the setting of random feature (RF) models in the quadratic scaling regime, where both the number of features and the sample size grow quadratically with the data dimension. We show that when the target function depends on a low-dimensional projection of the data, such as generalized linear models, GET yields incorrect predictions. To capture the correct asymptotics, we introduce a Conditional Gaussian Equivalent (CGE) model, which can be viewed as appending a low-dimensional non-Gaussian component to an otherwise high-dimensional Gaussian model. This hybrid model retains the tractability of the Gaussian framework and accurately describes RF models in the quadratic scaling regime. We derive sharp asymptotics for the training and test errors in this setting, which continue to agree with numerical simulations even when GET fails.\n  Our analysis combines general results on CLT for Wiener chaos expansions and a careful two-phase Lindeberg swapping argument. Beyond RF models and quadratic scaling, our work hints at a rich landscape of universality phenomena in high-dimensional ERM.", "AI": {"tldr": "The paper investigates when Gaussian Equivalence Theory (GET) fails in analyzing high-dimensional statistics, particularly in Random Feature (RF) models under quadratic scaling. It introduces a Conditional Gaussian Equivalent (CGE) model for accurate predictions.", "motivation": "Gaussian Equivalence Theory has limitations in describing complex high-dimensional features under certain regimes, and this paper aims to identify and address these limitations.", "method": "The authors propose the Conditional Gaussian Equivalent (CGE) model to handle cases where GET fails. They derive theoretical results using Central Limit Theorem (CLT) for Wiener chaos expansions and a two-phase Lindeberg swapping argument.", "result": "The CGE model provides accurate asymptotics for training and test errors in Random Feature models under quadratic scaling, agreeing with simulations even where GET fails.", "conclusion": "The CGE model successfully extends universality principles to scenarios where GET breaks down, advancing understanding of high-dimensional empirical risk minimization."}}
{"id": "2512.03350", "pdf": "https://arxiv.org/pdf/2512.03350", "abs": "https://arxiv.org/abs/2512.03350", "authors": ["Yu Yuan", "Tharindu Wickremasinghe", "Zeeshan Nadir", "Xijun Wang", "Yiheng Chi", "Stanley H. Chan"], "title": "SeeU: Seeing the Unseen World via 4D Dynamics-aware Generation", "categories": ["cs.CV"], "comment": "Project Page: https://yuyuanspace.com/SeeU/", "summary": "Images and videos are discrete 2D projections of the 4D world (3D space + time). Most visual understanding, prediction, and generation operate directly on 2D observations, leading to suboptimal performance. We propose SeeU, a novel approach that learns the continuous 4D dynamics and generate the unseen visual contents. The principle behind SeeU is a new 2D$\\to$4D$\\to$2D learning framework. SeeU first reconstructs the 4D world from sparse and monocular 2D frames (2D$\\to$4D). It then learns the continuous 4D dynamics on a low-rank representation and physical constraints (discrete 4D$\\to$continuous 4D). Finally, SeeU rolls the world forward in time, re-projects it back to 2D at sampled times and viewpoints, and generates unseen regions based on spatial-temporal context awareness (4D$\\to$2D). By modeling dynamics in 4D, SeeU achieves continuous and physically-consistent novel visual generation, demonstrating strong potentials in multiple tasks including unseen temporal generation, unseen spatial generation, and video editing.", "AI": {"tldr": "This paper introduces SeeU, a learning framework for 4D visual understanding, prediction, and generation by utilizing a 2D-to-4D-to-2D approach.", "motivation": "The authors aim to overcome limitations of current visual systems that operate in 2D and struggle with representing, predicting, and generating visuals in higher-dimensional space, particularly the full 4D dynamics of the real world.", "method": "SeeU reconstructs the 4D world from sparse 2D input (2D to 4D), learns continuous 4D dynamics via low-rank representation and physical constraints, and reprojects it back to 2D to generate novel visual content in space and time.", "result": "SeeU achieves continuous, physically-consistent visual generation and excels in applications like unseen temporal/spatial generation and video editing.", "conclusion": "The proposed 2D-to-4D-to-2D framework enables more accurate and physically consistent visual representations, offering advancements in tasks requiring novel visual content."}}
{"id": "2512.03101", "pdf": "https://arxiv.org/pdf/2512.03101", "abs": "https://arxiv.org/abs/2512.03101", "authors": ["Congjing Zhang", "Feng Lin", "Xinyi Zhao", "Pei Guo", "Wei Li", "Lin Chen", "Chaoyue Zhao", "Shuai Huang"], "title": "ALARM: Automated MLLM-Based Anomaly Detection in Complex-EnviRonment Monitoring with Uncertainty Quantification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The advance of Large Language Models (LLMs) has greatly stimulated research interest in developing multi-modal LLM (MLLM)-based visual anomaly detection (VAD) algorithms that can be deployed in complex environments. The challenge is that in these complex environments, the anomalies are sometimes highly contextual and also ambiguous, and thereby, uncertainty quantification (UQ) is a crucial capacity for an MLLM-based VAD system to succeed. In this paper, we introduce our UQ-supported MLLM-based VAD framework called ALARM. ALARM integrates UQ with quality-assurance techniques like reasoning chain, self-reflection, and MLLM ensemble for robust and accurate performance and is designed based on a rigorous probabilistic inference pipeline and computational process. Extensive empirical evaluations are conducted using the real-world smart-home benchmark data and wound image classification data, which shows ALARM's superior performance and its generic applicability across different domains for reliable decision-making.", "AI": {"tldr": "The paper introduces 'ALARM,' a framework for visual anomaly detection using multi-modal large language models, with integrated uncertainty quantification features.", "motivation": "To address challenges in visual anomaly detection in complex environments where anomalies can be highly contextual and ambiguous, and therefore require reliable uncertainty quantification.", "method": "The proposed framework, ALARM, combines uncertainty quantification, reasoning chain, self-reflection mechanisms, and MLLM ensemble. It is built on a probabilistic inference pipeline and computational methods.", "result": "Empirical evaluations on smart-home data and wound image classification demonstrate superior performance and flexibility across domains.", "conclusion": "ALARM ensures robust and accurate decision-making by leveraging uncertainty quantification techniques, reasoning chains, and self-reflection, proving its value in diverse applications."}}
{"id": "2512.03707", "pdf": "https://arxiv.org/pdf/2512.03707", "abs": "https://arxiv.org/abs/2512.03707", "authors": ["Sundas Rafat Mulkana", "Ronyu Yu", "Tanaya Guha", "Emma Li"], "title": "ContactRL: Safe Reinforcement Learning based Motion Planning for Contact based Human Robot Collaboration", "categories": ["cs.RO"], "comment": "8 pages, 7 figures", "summary": "In collaborative human-robot tasks, safety requires not only avoiding collisions but also ensuring safe, intentional physical contact. We present ContactRL, a reinforcement learning (RL) based framework that directly incorporates contact safety into the reward function through force feedback. This enables a robot to learn adaptive motion profiles that minimize human-robot contact forces while maintaining task efficiency. In simulation, ContactRL achieves a low safety violation rate of 0.2\\% with a high task success rate of 87.7\\%, outperforming state-of-the-art constrained RL baselines. In order to guarantee deployment safety, we augment the learned policy with a kinetic energy based Control Barrier Function (eCBF) shield. Real-world experiments on an UR3e robotic platform performing small object handovers from a human hand across 360 trials confirm safe contact, with measured normal forces consistently below 10N. These results demonstrate that ContactRL enables safe and efficient physical collaboration, thereby advancing the deployment of collaborative robots in contact-rich tasks.", "AI": {"tldr": "The paper introduces ContactRL, a reinforcement learning framework for ensuring safe human-robot physical interactions by incorporating force feedback into the reward function. It demonstrates high task efficiency and contact safety in both simulation and real-world experiments.", "motivation": "To address the safety challenge in human-robot collaboration that involves intentional physical contact, ensuring minimal contact forces while maintaining task efficiency.", "method": "Developed ContactRL, an RL-based framework that integrates contact safety into the reward function using force feedback, combined with a kinetic energy-based Control Barrier Function (eCBF) shield for real-world deployment safety.", "result": "ContactRL achieved a 0.2% safety violation rate and an 87.7% task success rate in simulations. In real-world experiments, safe contact forces were maintained below 10N during 360 trials on a UR3e robot.", "conclusion": "ContactRL demonstrates its ability to enhance safe and efficient physical collaboration, thus promoting the use of robots in tasks involving rich physical interaction."}}
{"id": "2512.03955", "pdf": "https://arxiv.org/pdf/2512.03955", "abs": "https://arxiv.org/abs/2512.03955", "authors": ["Niklas Jobs", "Luis Miguel Vieira da Silva", "Jayanth Somashekaraiah", "Maximilian Weigand", "David Kube", "Felix Gehlhoff"], "title": "Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol", "categories": ["cs.AI", "cs.ET"], "comment": "This work has been submitted to IFAC for possible publication", "summary": "Industrial automation increasingly requires flexible control strategies that can adapt to changing tasks and environments. Agents based on Large Language Models (LLMs) offer potential for such adaptive planning and execution but lack standardized benchmarks for systematic comparison. We introduce a benchmark with an executable simulation environment representing the Blocksworld problem providing five complexity categories. By integrating the Model Context Protocol (MCP) as a standardized tool interface, diverse agent architectures can be connected to and evaluated against the benchmark without implementation-specific modifications. A single-agent implementation demonstrates the benchmark's applicability, establishing quantitative metrics for comparison of LLM-based planning and execution approaches.", "AI": {"tldr": "The paper introduces a benchmark for evaluating LLMs in industrial automation tasks with an adaptive planning focus.", "motivation": "To provide a standardized benchmarking system for adaptive LLM-based agents in industrial automation, addressing the lack of comparative tools.", "method": "A benchmark using the Blocksworld problem is introduced with five complexity levels, integrated with Model Context Protocol (MCP) for compatibility with diverse agent architectures.", "result": "The benchmark successfully allows evaluation of adaptive planning and execution by agents, demonstrated through a single-agent implementation with quantitative metrics.", "conclusion": "The benchmark enables systematic evaluation of LLM-based agents against standardized criteria in industrial automation."}}
{"id": "2512.03503", "pdf": "https://arxiv.org/pdf/2512.03503", "abs": "https://arxiv.org/abs/2512.03503", "authors": ["Haohan Yuan", "Siu Cheung Hui", "Haopeng Zhang"], "title": "Understanding LLM Reasoning for Abstractive Summarization", "categories": ["cs.CL"], "comment": "26 pages,15 figures", "summary": "While the reasoning capabilities of Large Language Models (LLMs) excel in analytical tasks such as mathematics and code generation, their utility for abstractive summarization remains widely assumed but largely unverified. To bridge this gap, we first tailor general reasoning strategies to the summarization domain. We then conduct a systematic, large scale comparative study of 8 reasoning strategies and 3 Large Reasoning Models (LRMs) across 8 diverse datasets, assessing both summary quality and faithfulness. Our findings show that reasoning is not a universal solution and its effectiveness is highly dependent on the specific strategy and context. Specifically, we observe a trade-off between summary quality and factual faithfulness: explicit reasoning strategies tend to improve fluency at the expense of factual grounding, while implicit reasoning in LRMs exhibits the inverse pattern. Furthermore, increasing an LRM's internal reasoning budget does not improve, and can even hurt, factual consistency, suggesting that effective summarization demands faithful compression rather than creative over-thinking.", "AI": {"tldr": "Large Reasoning Models (LRMs) are evaluated for abstractive summarization across datasets, revealing trade-offs and limitations of reasoning strategies.", "motivation": "To verify and analyze the utility of Large Language Models (LLMs) in abstractive summarization, addressing an unverified assumption.", "method": "Conducted a large-scale comparative study using 8 reasoning strategies, 3 LRMs, and 8 diverse datasets, evaluating summary quality and faithfulness.", "result": "Discovered that reasoning effectiveness depends on strategy and context. Found a trade-off where explicit reasoning improves fluency but reduces factual faithfulness, while implicit reasoning does the opposite.", "conclusion": "Reasoning is not universally applicable to summarization; effective summarization needs faithful compression rather than excessive reasoning."}}
{"id": "2512.03333", "pdf": "https://arxiv.org/pdf/2512.03333", "abs": "https://arxiv.org/abs/2512.03333", "authors": ["Xun Tang", "Haoxuan Chen", "Yuehaw Khoo", "Lexing Ying"], "title": "Sketch Tomography: Hybridizing Classical Shadow and Matrix Product State", "categories": ["quant-ph", "math.NA", "math.ST", "physics.comp-ph", "stat.ML"], "comment": null, "summary": "We introduce Sketch Tomography, an efficient procedure for quantum state tomography based on the classical shadow protocol used for quantum observable estimations. The procedure applies to the case where the ground truth quantum state is a matrix product state (MPS). The density matrix of the ground truth state admits a tensor train ansatz as a result of the MPS assumption, and we estimate the tensor components of the ansatz through a series of observable estimations, thus outputting an approximation of the density matrix. The procedure is provably convergent with a sample complexity that scales quadratically in the system size. We conduct extensive numerical experiments to show that the procedure outputs an accurate approximation to the quantum state. For observable estimation tasks involving moderately large subsystems, we show that our procedure gives rise to a more accurate estimation than the classical shadow protocol. We also show that sketch tomography is more accurate in observable estimation than quantum states trained from the maximum likelihood estimation formulation.", "AI": {"tldr": "The paper introduces Sketch Tomography, a quantum state tomography method leveraging classical shadow protocol and the assumption of a matrix product state (MPS), showcasing efficiency, accuracy, and improved observable estimation capabilities.", "motivation": "The motivation is to develop an efficient and accurate quantum state tomography method by leveraging the structure of matrix product states and classical shadow protocols to overcome challenges in observable estimations for large quantum systems.", "method": "Sketch Tomography estimates the tensor components of the ground truth state\u2019s matrix product state structure via observable estimations, resulting in an approximate density matrix. Its design ensures provable convergence and sample complexity that scales quadratically with system size.", "result": "The procedure exhibits accurate approximations of quantum states through numerical experiments. It demonstrates superior accuracy in observable estimations compared to classical shadow protocols and maximum likelihood-based methods for moderately large subsystems.", "conclusion": "Sketch Tomography is an efficient and provably accurate alternative for quantum state tomography, outperforming existing methods in sample complexity and observable estimation accuracy, particularly for systems modeled as matrix product states."}}
{"id": "2512.03359", "pdf": "https://arxiv.org/pdf/2512.03359", "abs": "https://arxiv.org/abs/2512.03359", "authors": ["Md Rashidul Islam", "Bakary Gibba", "Altagi Abdallah Bakheit Abdelgadir"], "title": "A Hybrid Deep Learning Framework with Explainable AI for Lung Cancer Classification with DenseNet169 and SVM", "categories": ["cs.CV"], "comment": null, "summary": "Lung cancer is a very deadly disease worldwide, and its early diagnosis is crucial for increasing patient survival rates. Computed tomography (CT) scans are widely used for lung cancer diagnosis as they can give detailed lung structures. However, manual interpretation is time-consuming and prone to human error. To surmount this challenge, the study proposes a deep learning-based automatic lung cancer classification system to enhance detection accuracy and interpretability. The IQOTHNCCD lung cancer dataset is utilized, which is a public CT scan dataset consisting of cases categorized into Normal, Benign, and Malignant and used DenseNet169, which includes Squeezeand-Excitation blocks for attention-based feature extraction, Focal Loss for handling class imbalance, and a Feature Pyramid Network (FPN) for multi-scale feature fusion. In addition, an SVM model was developed using MobileNetV2 for feature extraction, improving its classification performance. For model interpretability enhancement, the study integrated Grad-CAM for the visualization of decision-making regions in CT scans and SHAP (Shapley Additive Explanations) for explanation of feature contributions within the SVM model. Intensive evaluation was performed, and it was found that both DenseNet169 and SVM models achieved 98% accuracy, suggesting their robustness for real-world medical practice. These results open up the potential for deep learning to improve the diagnosis of lung cancer by a higher level of accuracy, transparency, and robustness.", "AI": {"tldr": "The paper develops a deep learning-based system for lung cancer classification using CT scans, achieving high accuracy and interpretability.", "motivation": "The study addresses the need for efficient and accurate lung cancer diagnosis from CT scans to improve survival rates and avoid errors associated with manual interpretation.", "method": "The paper proposes a dual approach using DenseNet169 and SVM models, with DenseNet incorporating Squeeze-and-Excitation blocks, Focal Loss, and Feature Pyramid Network for feature enhancement and SVM utilizing MobileNetV2 for feature extraction. Grad-CAM and SHAP frameworks are applied for model interpretability.", "result": "Both DenseNet169 and SVM models achieved 98% accuracy on the IQOTHNCCD lung cancer CT scan dataset, showing their effectiveness and reliability.", "conclusion": "The findings demonstrate the capability of deep learning models in achieving high accuracy and interpretability for lung cancer diagnosis, highlighting their potential for practical medical applications."}}
{"id": "2512.03102", "pdf": "https://arxiv.org/pdf/2512.03102", "abs": "https://arxiv.org/abs/2512.03102", "authors": ["Yiwei Shi", "Hongnan Ma", "Mengyue Yang", "Cunjia Liu", "Weiru Liu"], "title": "Dynamic Correction of Erroneous State Estimates via Diffusion Bayesian Exploration", "categories": ["cs.LG", "cs.AI", "stat.CO"], "comment": null, "summary": "In emergency response and other high-stakes societal applications, early-stage state estimates critically shape downstream outcomes. Yet, these initial state estimates-often based on limited or biased information-can be severely misaligned with reality, constraining subsequent actions and potentially causing catastrophic delays, resource misallocation, and human harm. Under the stationary bootstrap baseline (zero transition and no rejuvenation), bootstrap particle filters exhibit Stationarity-Induced Posterior Support Invariance (S-PSI), wherein regions excluded by the initial prior remain permanently unexplorable, making corrections impossible even when new evidence contradicts current beliefs. While classical perturbations can in principle break this lock-in, they operate in an always-on fashion and may be inefficient. To overcome this, we propose a diffusion-driven Bayesian exploration framework that enables principled, real-time correction of early state estimation errors. Our method expands posterior support via entropy-regularized sampling and covariance-scaled diffusion. A Metropolis-Hastings check validates proposals and keeps inference adaptive to unexpected evidence. Empirical evaluations on realistic hazardous-gas localization tasks show that our approach matches reinforcement learning and planning baselines when priors are correct. It substantially outperforms classical SMC perturbations and RL-based methods under misalignment, and we provide theoretical guarantees that DEPF resolves S-PSI while maintaining statistical rigor.", "AI": {"tldr": "The paper addresses the issue of initial state estimation errors often causing long-term inaccuracies in high-stakes applications. It introduces a diffusion-driven exploration framework that improves correction efficiency and posterior support flexibility.", "motivation": "Initial state errors in emergency response systems and other critical applications create persistent misalignments with reality, leading to harmful outcomes such as misallocation of resources and delays.", "method": "The authors propose a diffusion-driven Bayesian exploration method combining entropy-regularized sampling, covariance-scaled diffusion, and Metropolis-Hastings checks to adapt and correct state estimation errors in real-time.", "result": "Empirical tests on hazardous-gas localization show the method surpasses both classical perturbations and RL-based methods when initial priors misalign, while showing comparable performance when priors align. It also resolves Stationarity-Induced Posterior Support Invariance effectively.", "conclusion": "The framework enhances adaptability, resolves critical estimation errors efficiently, and offers statistical guarantees for correcting initial biases in emergency or high-impact scenarios."}}
{"id": "2512.03729", "pdf": "https://arxiv.org/pdf/2512.03729", "abs": "https://arxiv.org/abs/2512.03729", "authors": ["Samantha Chapin", "Kenneth Stewart", "Roxana Leontie", "Carl Glen Henshaw"], "title": "Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) International Space Station Astrobee Testing", "categories": ["cs.RO", "cs.LG", "eess.SY"], "comment": "iSpaRo 2025, Best Paper Award in Orbital Robotics", "summary": "The US Naval Research Laboratory's (NRL's) Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) experiment pioneers the use of reinforcement learning (RL) for control of free-flying robots in the zero-gravity (zero-G) environment of space. On Tuesday, May 27th 2025 the APIARY team conducted the first ever, to our knowledge, RL control of a free-flyer in space using the NASA Astrobee robot on-board the International Space Station (ISS). A robust 6-degrees of freedom (DOF) control policy was trained using an actor-critic Proximal Policy Optimization (PPO) network within the NVIDIA Isaac Lab simulation environment, randomizing over goal poses and mass distributions to enhance robustness. This paper details the simulation testing, ground testing, and flight validation of this experiment. This on-orbit demonstration validates the transformative potential of RL for improving robotic autonomy, enabling rapid development and deployment (in minutes to hours) of tailored behaviors for space exploration, logistics, and real-time mission needs.", "AI": {"tldr": "The APIARY experiment showcases RL-based control of free-flying robots in zero-gravity environments using the Astrobee robot on the ISS.", "motivation": "Demonstrate the transformative potential of RL in enabling autonomous and efficient robotic control for space missions.", "method": "Utilized a PPO actor-critic RL policy trained in simulation, tested on the ground, and validated in zero-G with Astrobee on ISS.", "result": "Demonstrated RL control on a free-flyer in space for the first time, achieving robust autonomy for robots in zero-gravity scenarios.", "conclusion": "RL significantly improves robotic autonomy and enables adaptive behaviors for space exploration and logistics with rapid deployment capabilities."}}
{"id": "2512.02774", "pdf": "https://arxiv.org/pdf/2512.02774", "abs": "https://arxiv.org/abs/2512.02774", "authors": ["Yijun Chen"], "title": "AI-Driven Document Redaction in UK Public Authorities: Implementation Gaps, Regulatory Challenges, and the Human Oversight Imperative", "categories": ["cs.CY", "cs.AI"], "comment": "21 pages, 4 Figures, 2 Tables", "summary": "Document redaction in public authorities faces critical challenges as traditional manual approaches struggle to balance growing transparency demands with increasingly stringent data protection requirements. This study investigates the implementation of AI-driven document redaction within UK public authorities through Freedom of Information (FOI) requests. While AI technologies offer potential solutions to redaction challenges, their actual implementation within public sector organizations remains underexplored. Based on responses from 44 public authorities across healthcare, government, and higher education sectors, this study reveals significant gaps between technological possibilities and organizational realities. Findings show highly limited AI adoption (only one authority reported using AI tools), widespread absence of formal redaction policies (50 percent reported \"information not held\"), and deficiencies in staff training. The study identifies three key barriers to effective AI implementation: poor record-keeping practices, lack of standardized redaction guidelines, and insufficient specialized training for human oversight. These findings highlight the need for a socio-technical approach that balances technological automation with meaningful human expertise. This research provides the first empirical assessment of AI redaction practices in UK public authorities and contributes evidence to support policymakers navigating the complex interplay between transparency obligations, data protection requirements, and emerging AI technologies in public administration.", "AI": {"tldr": "The study analyzes AI-driven document redaction in UK public authorities, revealing limited adoption, poor practices, and key barriers like lack of training and guidelines.", "motivation": "To address the challenges of balancing transparency and data protection in public authorities by exploring AI adoption for document redaction.", "method": "Analyzed responses from 44 public authorities across healthcare, government, and education to assess AI usage and associated practices.", "result": "Only one authority used AI tools. 50% lacked formal redaction policies, and major deficiencies were found in staff training and standardized practices.", "conclusion": "There is a need for a socio-technical approach integrating AI automation with human expertise to improve document redaction practices in public authorities."}}
{"id": "2512.03582", "pdf": "https://arxiv.org/pdf/2512.03582", "abs": "https://arxiv.org/abs/2512.03582", "authors": ["Zeba Afroz", "Harsh Vardhan", "Pawan Bhakuni", "Aanchal Punia", "Rajdeep Kumar", "Md. Shad Akhtar"], "title": "Fine-grained Narrative Classification in Biased News Articles", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Narratives are the cognitive and emotional scaffolds of propaganda. They organize isolated persuasive techniques into coherent stories that justify actions, attribute blame, and evoke identification with ideological camps. In this paper, we propose a novel fine-grained narrative classification in biased news articles. We also explore article-bias classification as the precursor task to narrative classification and fine-grained persuasive technique identification. We develop INDI-PROP, the first ideologically grounded fine-grained narrative dataset with multi-level annotation for analyzing propaganda in Indian news media. Our dataset INDI-PROP comprises 1,266 articles focusing on two polarizing socio-political events in recent times: CAA and the Farmers' protest. Each article is annotated at three hierarchical levels: (i) ideological article-bias (pro-government, pro-opposition, neutral), (ii) event-specific fine-grained narrative frames anchored in ideological polarity and communicative intent, and (iii) persuasive techniques. We propose FANTA and TPTC, two GPT-4o-mini guided multi-hop prompt-based reasoning frameworks for the bias, narrative, and persuasive technique classification. FANTA leverages multi-layered communicative phenomena by integrating information extraction and contextual framing for hierarchical reasoning. On the other hand, TPTC adopts systematic decomposition of persuasive cues via a two-stage approach. Our evaluation suggests substantial improvement over underlying baselines in each case.", "AI": {"tldr": "The paper introduces INDI-PROP, a dataset for narrative classification in Indian biased news, alongside proposing new classification frameworks FANTA and TPTC.", "motivation": "The study aims to understand and classify narratives in biased news, highlighting their role in justifying actions and propagating ideologies, specifically in the Indian media context.", "method": "The authors developed the INDI-PROP dataset with hierarchical annotation and proposed FANTA and TPTC frameworks based on multi-hop prompt reasoning.", "result": "The proposed frameworks, FANTA and TPTC, demonstrated significant improvement over baseline models for classifying bias, narratives, and persuasive techniques.", "conclusion": "This work provides a novel dataset and effective methodologies for analyzing propaganda narratives, significantly advancing the understanding of media bias and persuasion in socio-political contexts."}}
{"id": "2512.03336", "pdf": "https://arxiv.org/pdf/2512.03336", "abs": "https://arxiv.org/abs/2512.03336", "authors": ["Alan T. L. Bacellar", "Mustafa Munir", "Felipe M. G. Fran\u00e7a", "Priscila M. V. Lima", "Radu Marculescu", "Lizy K. John"], "title": "Single-Round Scalable Analytic Federated Learning", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Federated Learning (FL) is plagued by two key challenges: high communication overhead and performance collapse on heterogeneous (non-IID) data. Analytic FL (AFL) provides a single-round, data distribution invariant solution, but is limited to linear models. Subsequent non-linear approaches, like DeepAFL, regain accuracy but sacrifice the single-round benefit. In this work, we break this trade-off. We propose SAFLe, a framework that achieves scalable non-linear expressivity by introducing a structured head of bucketed features and sparse, grouped embeddings. We prove this non-linear architecture is mathematically equivalent to a high-dimensional linear regression. This key equivalence allows SAFLe to be solved with AFL's single-shot, invariant aggregation law. Empirically, SAFLe establishes a new state-of-the-art for analytic FL, significantly outperforming both linear AFL and multi-round DeepAFL in accuracy across all benchmarks, demonstrating a highly efficient and scalable solution for federated vision.", "AI": {"tldr": "The paper addresses challenges in Federated Learning (FL) by introducing SAFLe, a framework balancing single-round communication and non-linear expressivity, improving accuracy over existing methods.", "motivation": "FL suffers from high communication costs and poor performance with non-IID data. Previous solutions compromise between model non-linear expressivity and single-round efficiency.", "method": "The authors propose SAFLe, a structured head with bucketed features and grouped embeddings, mathematically equivalent to high-dimensional linear regression, enabling single-shot aggregation.", "result": "SAFLe outperforms both linear AFL and multi-round DeepAFL in accuracy across benchmarks, achieving new standards for efficient, scalable analytic FL.", "conclusion": "SAFLe combines non-linear expressivity with the efficiency of a single communication round, making it a robust, scalable solution for federated learning."}}
{"id": "2512.03369", "pdf": "https://arxiv.org/pdf/2512.03369", "abs": "https://arxiv.org/abs/2512.03369", "authors": ["Nan Zhou", "Huandong Wang", "Jiahao Li", "Han Li", "Yali Song", "Qiuhua Wang", "Yong Li", "Xinlei Chen"], "title": "FireSentry: A Multi-Modal Spatio-temporal Benchmark Dataset for Fine-Grained Wildfire Spread Forecasting", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Fine-grained wildfire spread prediction is crucial for enhancing emergency response efficacy and decision-making precision. However, existing research predominantly focuses on coarse spatiotemporal scales and relies on low-resolution satellite data, capturing only macroscopic fire states while fundamentally constraining high-precision localized fire dynamics modeling capabilities. To bridge this gap, we present FireSentry, a provincial-scale multi-modal wildfire dataset characterized by sub-meter spatial and sub-second temporal resolution. Collected using synchronized UAV platforms, FireSentry provides visible and infrared video streams, in-situ environmental measurements, and manually validated fire masks. Building on FireSentry, we establish a comprehensive benchmark encompassing physics-based, data-driven, and generative models, revealing the limitations of existing mask-only approaches. Our analysis proposes FiReDiff, a novel dual-modality paradigm that first predicts future video sequences in the infrared modality, and then precisely segments fire masks in the mask modality based on the generated dynamics. FiReDiff achieves state-of-the-art performance, with video quality gains of 39.2% in PSNR, 36.1% in SSIM, 50.0% in LPIPS, 29.4% in FVD, and mask accuracy gains of 3.3% in AUPRC, 59.1% in F1 score, 42.9% in IoU, and 62.5% in MSE when applied to generative models. The FireSentry benchmark dataset and FiReDiff paradigm collectively advance fine-grained wildfire forecasting and dynamic disaster simulation. The processed benchmark dataset is publicly available at: https://github.com/Munan222/FireSentry-Benchmark-Dataset.", "AI": {"tldr": "The study introduces FireSentry, a high-resolution wildfire dataset, along with FiReDiff, a novel predictive model for fine-grained wildfire dynamics, achieving state-of-the-art results in video and fire mask accuracy.", "motivation": "Existing wildfire prediction methods are limited by coarse spatial-temporal scales and low-resolution data, restricting precise modeling of localized fire dynamics.", "method": "The FireSentry dataset captures sub-meter spatial and sub-second temporal wildfire data using UAVs and provides benchmarks along with FiReDiff, a dual-modality model for future sequence generation and fire mask segmentation.", "result": "FiReDiff demonstrates significant improvements over existing models, with substantial video quality and fire mask accuracy enhancements using benchmarks from the FireSentry dataset.", "conclusion": "FireSentry and FiReDiff advance wildfire forecasting and disaster simulation, providing a publicly available benchmark for future research."}}
{"id": "2512.03736", "pdf": "https://arxiv.org/pdf/2512.03736", "abs": "https://arxiv.org/abs/2512.03736", "authors": ["Kenneth Stewart", "Samantha Chapin", "Roxana Leontie", "Carl Glen Henshaw"], "title": "Crossing the Sim2Real Gap Between Simulation and Ground Testing to Space Deployment of Autonomous Free-flyer Control", "categories": ["cs.RO", "cs.LG", "eess.SY"], "comment": "published at iSpaRo 2025", "summary": "Reinforcement learning (RL) offers transformative potential for robotic control in space. We present the first on-orbit demonstration of RL-based autonomous control of a free-flying robot, the NASA Astrobee, aboard the International Space Station (ISS). Using NVIDIA's Omniverse physics simulator and curriculum learning, we trained a deep neural network to replace Astrobee's standard attitude and translation control, enabling it to navigate in microgravity. Our results validate a novel training pipeline that bridges the simulation-to-reality (Sim2Real) gap, utilizing a GPU-accelerated, scientific-grade simulation environment for efficient Monte Carlo RL training. This successful deployment demonstrates the feasibility of training RL policies terrestrially and transferring them to space-based applications. This paves the way for future work in In-Space Servicing, Assembly, and Manufacturing (ISAM), enabling rapid on-orbit adaptation to dynamic mission requirements.", "AI": {"tldr": "The paper presents the first demonstration of reinforcement learning (RL) used for autonomous robotic control on the ISS, showing its success in navigating microgravity using NASA's Astrobee robot.", "motivation": "To address the challenge of autonomous robotic operation and control in space, leveraging RL for improved adaptability and effectiveness in microgravity conditions.", "method": "Training a deep neural network for robotic control using NVIDIA Omniverse simulation, curriculum learning, and a GPU-accelerated pipeline to overcome Sim2Real challenges for the Astrobee robot.", "result": "The RL model successfully replaced the Astrobee's standard control mechanism, proving its capability to operate autonomously in space with the trained policy.", "conclusion": "This work demonstrates the feasibility of Sim2Real RL policy training on Earth and its effective deployment in space, laying the foundation for advanced, adaptive space robotics in future missions."}}
{"id": "2512.03634", "pdf": "https://arxiv.org/pdf/2512.03634", "abs": "https://arxiv.org/abs/2512.03634", "authors": ["Ahmad Aghaebrahimian"], "title": "AlignCheck: a Semantic Open-Domain Metric for Factual Consistency Assessment", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models have significantly advanced natural language processing tasks, but remain prone to generating incorrect or misleading but plausible arguments. This issue, known as hallucination, is particularly concerning in high-stakes domains like clinical applications, where factual inaccuracies can have severe consequences. Existing evaluation metrics fail to adequately assess factual consistency and lack interpretability, making diagnosing and mitigating errors difficult. We propose an interpretable framework for factual consistency assessment for in-domain and open-domain texts to address these limitations. Our approach decomposes text into atomic facts and introduces a flexible, schema-free methodology. Unlike previous methods with an absolute metric, we incorporate a weighted metric to enhance factual evaluation. Additionally, we propose a mechanism to control assessment complexity in intricate domains. We benchmark our approach on popular general and clinical datasets and release our code to support fact-aware model training in future research.", "AI": {"tldr": "The paper addresses hallucination issues in large language models by proposing an interpretable framework for assessing factual consistency, particularly in high-stakes domains like clinical applications.", "motivation": "Large language models often generate plausible but inaccurate arguments, creating risks in critical domains like clinical applications where factual reliability is vital.", "method": "The framework decomposes text into atomic facts, employs a flexible schema-free approach, introduces a weighted metric for evaluation, and provides tools for controlling assessment complexity in intricate domains.", "result": "The framework is benchmarked on popular general and clinical datasets, proving its effectiveness and releasing the code to support fact-aware training.", "conclusion": "This research offers an enhanced way to diagnose and mitigate hallucinations in language models while supporting future developments in fact-aware models."}}
{"id": "2512.03354", "pdf": "https://arxiv.org/pdf/2512.03354", "abs": "https://arxiv.org/abs/2512.03354", "authors": ["Hongseon Yeom", "Jaeyoul Shin", "Soojin Min", "Jeongmin Yoon", "Seunghak Yu", "Dongyeop Kang"], "title": "Breaking Determinism: Stochastic Modeling for Reliable Off-Policy Evaluation in Ad Auctions", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Online A/B testing, the gold standard for evaluating new advertising policies, consumes substantial engineering resources and risks significant revenue loss from deploying underperforming variations. This motivates the use of Off-Policy Evaluation (OPE) for rapid, offline assessment. However, applying OPE to ad auctions is fundamentally more challenging than in domains like recommender systems, where stochastic policies are common. In online ad auctions, it is common for the highest-bidding ad to win the impression, resulting in a deterministic, winner-takes-all setting. This results in zero probability of exposure for non-winning ads, rendering standard OPE estimators inapplicable. We introduce the first principled framework for OPE in deterministic auctions by repurposing the bid landscape model to approximate the propensity score. This model allows us to derive robust approximate propensity scores, enabling the use of stable estimators like Self-Normalized Inverse Propensity Scoring (SNIPS) for counterfactual evaluation. We validate our approach on the AuctionNet simulation benchmark and against 2-weeks online A/B test from a large-scale industrial platform. Our method shows remarkable alignment with online results, achieving a 92\\% Mean Directional Accuracy (MDA) in CTR prediction, significantly outperforming the parametric baseline. MDA is the most critical metric for guiding deployment decisions, as it reflects the ability to correctly predict whether a new model will improve or harm performance. This work contributes the first practical and validated framework for reliable OPE in deterministic auction environments, offering an efficient alternative to costly and risky online experiments.", "AI": {"tldr": "Introduced a framework for Off-Policy Evaluation (OPE) in deterministic online ad auctions, solving challenges of zero exposure probability for non-winning bids.", "motivation": "Reduce the engineering and revenue risks of A/B testing for evaluating new advertising policies.", "method": "Repurposed the bid landscape model to approximate propensity scores and employed Self-Normalized Inverse Propensity Scoring (SNIPS) for counterfactual evaluation.", "result": "Validated with AuctionNet simulation and industrial A/B testing, achieving 92% Mean Directional Accuracy in CTR prediction, outperforming baseline methods.", "conclusion": "The framework provides a reliable and practical alternative for efficient OPE in deterministic auctions, mitigating risks and reducing costs related to online experiments."}}
{"id": "2512.03370", "pdf": "https://arxiv.org/pdf/2512.03370", "abs": "https://arxiv.org/abs/2512.03370", "authors": ["Lingjun Zhao", "Yandong Luo", "James Hay", "Lu Gan"], "title": "ShelfGaussian: Shelf-Supervised Open-Vocabulary Gaussian-based 3D Scene Understanding", "categories": ["cs.CV"], "comment": null, "summary": "We introduce ShelfGaussian, an open-vocabulary multi-modal Gaussian-based 3D scene understanding framework supervised by off-the-shelf vision foundation models (VFMs). Gaussian-based methods have demonstrated superior performance and computational efficiency across a wide range of scene understanding tasks. However, existing methods either model objects as closed-set semantic Gaussians supervised by annotated 3D labels, neglecting their rendering ability, or learn open-set Gaussian representations via purely 2D self-supervision, leading to degraded geometry and limited to camera-only settings. To fully exploit the potential of Gaussians, we propose a Multi-Modal Gaussian Transformer that enables Gaussians to query features from diverse sensor modalities, and a Shelf-Supervised Learning Paradigm that efficiently optimizes Gaussians with VFM features jointly at 2D image and 3D scene levels. We evaluate ShelfGaussian on various perception and planning tasks. Experiments on Occ3D-nuScenes demonstrate its state-of-the-art zero-shot semantic occupancy prediction performance. ShelfGaussian is further evaluated on an unmanned ground vehicle (UGV) to assess its in the-wild performance across diverse urban scenarios. Project website: https://lunarlab-gatech.github.io/ShelfGaussian/.", "AI": {"tldr": "ShelfGaussian is a novel framework using Gaussian-based methods and vision foundation models for multi-modal 3D scene understanding, focusing on open-vocabulary capabilities.", "motivation": "Existing Gaussian-based methods for 3D scene understanding either rely on annotated labels, limiting flexibility, or use purely 2D self-supervision, causing geometry compromises. The goal is to optimize Gaussian-based models using VFMs for more accurate and efficient scene representation.", "method": "The paper introduces a Multi-Modal Gaussian Transformer for querying diverse sensor modalities and a Shelf-Supervised Learning Paradigm to optimize Gaussians using VFMs at both 2D and 3D levels.", "result": "ShelfGaussian demonstrates state-of-the-art zero-shot semantic occupancy prediction on datasets like Occ3D-nuScenes and performs robustly across urban settings using UGVs.", "conclusion": "ShelfGaussian leverages VFMs and Gaussian-based techniques to effectively address limitations in existing scene understanding methods, yielding improved semantic prediction and real-world adaptability."}}
{"id": "2512.03743", "pdf": "https://arxiv.org/pdf/2512.03743", "abs": "https://arxiv.org/abs/2512.03743", "authors": ["Kehlani Fay", "Darin Anthony Djapri", "Anya Zorin", "James Clinton", "Ali El Lahib", "Hao Su", "Michael T. Tolley", "Sha Yi", "Xiaolong Wang"], "title": "Cross-embodied Co-design for Dexterous Hands", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Dexterous manipulation is limited by both control and design, without consensus as to what makes manipulators best for performing dexterous tasks. This raises a fundamental challenge: how should we design and control robot manipulators that are optimized for dexterity? We present a co-design framework that learns task-specific hand morphology and complementary dexterous control policies. The framework supports 1) an expansive morphology search space including joint, finger, and palm generation, 2) scalable evaluation across the wide design space via morphology-conditioned cross-embodied control, and 3) real-world fabrication with accessible components. We evaluate the approach across multiple dexterous tasks, including in-hand rotation with simulation and real deployment. Our framework enables an end-to-end pipeline that can design, train, fabricate, and deploy a new robotic hand in under 24 hours. The full framework will be open-sourced and available on our website.", "AI": {"tldr": "The paper proposes a co-design framework for optimizing dexterous robotic manipulators, addressing challenges in control and design.", "motivation": "Robotic manipulators struggle with dexterous tasks due to lack of an optimized approach for both design and control.", "method": "The framework integrates morphology search, scalable evaluation across design space, and real-world fabrication for robot manipulators.", "result": "It successfully designs, trains, and deploys robot hands under 24 hours, showing effectiveness across dexterous tasks.", "conclusion": "The co-design framework facilitates efficient development of task-specific dexterous manipulators and will be open-sourced for broader use."}}
{"id": "2512.03671", "pdf": "https://arxiv.org/pdf/2512.03671", "abs": "https://arxiv.org/abs/2512.03671", "authors": ["Beatrice Savoldi", "Giuseppe Attanasio", "Olga Gorodetskaya", "Marta Marchiori Manerba", "Elisa Bassignana", "Silvia Casola", "Matteo Negri", "Tommaso Caselli", "Luisa Bentivogli", "Alan Ramponi", "Arianna Muti", "Nicoletta Balbo", "Debora Nozza"], "title": "Generative AI Practices, Literacy, and Divides: An Empirical Analysis in the Italian Context", "categories": ["cs.CL"], "comment": null, "summary": "The rise of Artificial Intelligence (AI) language technologies, particularly generative AI (GenAI) chatbots accessible via conversational interfaces, is transforming digital interactions. While these tools hold societal promise, they also risk widening digital divides due to uneven adoption and low awareness of their limitations. This study presents the first comprehensive empirical mapping of GenAI adoption, usage patterns, and literacy in Italy, based on newly collected survey data from 1,906 Italian-speaking adults. Our findings reveal widespread adoption for both work and personal use, including sensitive tasks like emotional support and medical advice. Crucially, GenAI is supplanting other technologies to become a primary information source: this trend persists despite low user digital literacy, posing a risk as users struggle to recognize errors or misinformation. Moreover, we identify a significant gender divide -- particularly pronounced in older generations -- where women are half as likely to adopt GenAI and use it less frequently than men. While we find literacy to be a key predictor of adoption, it only partially explains this disparity, suggesting that other barriers are at play. Overall, our data provide granular insights into the multipurpose usage of GenAI, highlighting the dual need for targeted educational initiatives and further investigation into the underlying barriers to equitable participation that competence alone cannot explain.", "AI": {"tldr": "The paper examines generative AI (GenAI) adoption, usage, and literacy in Italy, highlighting gender divides and risks associated with low digital literacy.", "motivation": "The motivation is to explore the societal implications of generative AI adoption and identify factors affecting its equitable use, as there is a risk of digital divides and misinformation.", "method": "The study is based on survey data from 1,906 Italian-speaking adults, analyzing adoption patterns, use cases, literacy, and demographic variables.", "result": "The findings reveal widespread GenAI adoption, with notable gender divides and low digital literacy among users, posing significant risks. Women are less likely to adopt GenAI, especially in older age groups.", "conclusion": "The study concludes the need for targeted educational programs and research into barriers beyond competence to ensure equitable and safe participation in GenAI usage."}}
{"id": "2512.03393", "pdf": "https://arxiv.org/pdf/2512.03393", "abs": "https://arxiv.org/abs/2512.03393", "authors": ["Lakshmi Jayalal", "Sheetal Kalyani"], "title": "Tuning-Free Structured Sparse Recovery of Multiple Measurement Vectors using Implicit Regularization", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Recovering jointly sparse signals in the multiple measurement vectors (MMV) setting is a fundamental problem in machine learning, but traditional methods like multiple measurement vectors orthogonal matching pursuit (M-OMP) and multiple measurement vectors FOCal Underdetermined System Solver (M-FOCUSS) often require careful parameter tuning or prior knowledge of the sparsity of the signal and/or noise variance. We introduce a novel tuning-free framework that leverages Implicit Regularization (IR) from overparameterization to overcome this limitation. Our approach reparameterizes the estimation matrix into factors that decouple the shared row-support from individual vector entries. We show that the optimization dynamics inherently promote the desired row-sparse structure by applying gradient descent to a standard least-squares objective on these factors. We prove that with a sufficiently small and balanced initialization, the optimization dynamics exhibit a \"momentum-like\" effect, causing the norms of rows in the true support to grow significantly faster than others. This formally guarantees that the solution trajectory converges towards an idealized row-sparse solution. Additionally, empirical results demonstrate that our approach achieves performance comparable to established methods without requiring any prior information or tuning.", "AI": {"tldr": "The paper proposes a novel tuning-free method using implicit regularization to solve the joint sparse signal recovery issue in multiple measurement vectors (MMV), avoiding the need for parameter tuning or prior knowledge of sparsity.", "motivation": "Traditional MMV signal recovery methods often need parameter tuning or prior knowledge (such as sparsity or noise variance), which limits their adaptability and usability.", "method": "The authors use implicit regularization through overparameterization by reparameterizing the problem to decouple shared row-support and vector entries. They apply gradient descent on these factors, leveraging optimization dynamics to promote row-sparsity, formalized through theoretical guarantees.", "result": "The method ensures that row norms from the true support grow faster than others, leading to convergence towards a row-sparse solution. Empirical results demonstrate comparable or better performance without requiring tuning or prior information.", "conclusion": "This method combines theoretical guarantees and strong empirical performance, eliminating the need for cumbersome tuning or prior sparsity information in solving MMV problems effectively."}}
{"id": "2512.03404", "pdf": "https://arxiv.org/pdf/2512.03404", "abs": "https://arxiv.org/abs/2512.03404", "authors": ["Yujian Zhao", "Hankun Liu", "Guanglin Niu"], "title": "MOS: Mitigating Optical-SAR Modality Gap for Cross-Modal Ship Re-Identification", "categories": ["cs.CV"], "comment": null, "summary": "Cross-modal ship re-identification (ReID) between optical and synthetic aperture radar (SAR) imagery has recently emerged as a critical yet underexplored task in maritime intelligence and surveillance. However, the substantial modality gap between optical and SAR images poses a major challenge for robust identification. To address this issue, we propose MOS, a novel framework designed to mitigate the optical-SAR modality gap and achieve modality-consistent feature learning for optical-SAR cross-modal ship ReID. MOS consists of two core components: (1) Modality-Consistent Representation Learning (MCRL) applies denoise SAR image procession and a class-wise modality alignment loss to align intra-identity feature distributions across modalities. (2) Cross-modal Data Generation and Feature fusion (CDGF) leverages a brownian bridge diffusion model to synthesize cross-modal samples, which are subsequently fused with original features during inference to enhance alignment and discriminability. Extensive experiments on the HOSS ReID dataset demonstrate that MOS significantly surpasses state-of-the-art methods across all evaluation protocols, achieving notable improvements of +3.0%, +6.2%, and +16.4% in R1 accuracy under the ALL to ALL, Optical to SAR, and SAR to Optical settings, respectively. The code and trained models will be released upon publication.", "AI": {"tldr": "This paper addresses the challenge of cross-modal ship re-identification (ReID) between optical and SAR images using a novel framework MOS that achieves significantly improved results.", "motivation": "To solve the critical challenge of robust cross-modal ship ReID between optical and SAR images despite the significant modality gap.", "method": "The proposed framework, MOS, features Modality-Consistent Representation Learning (MCRL) for aligning features across modalities and Cross-modal Data Generation and Feature fusion (CDGF) for synthesizing and integrating cross-modal data with a Brownian bridge diffusion model.", "result": "Significant performance improvements over state-of-the-art methods on the HOSS ReID dataset with +3.0%, +6.2%, and +16.4% accuracy gains in different evaluation settings.", "conclusion": "MOS effectively addresses the optical-SAR modality gap, demonstrating strong potential for maritime intelligence using cross-modal ship re-identification."}}
{"id": "2512.03756", "pdf": "https://arxiv.org/pdf/2512.03756", "abs": "https://arxiv.org/abs/2512.03756", "authors": ["Marlon Steiner", "Royden Wagner", "\u00d6mer Sahin Tas", "Christoph Stiller"], "title": "Prediction-Driven Motion Planning: Route Integration Strategies in Attention-Based Prediction Models", "categories": ["cs.RO"], "comment": "In Proceedings of the IEEE International Conference on Intelligent Transportation Systems (ITSC), Gold Coast, AUSTRALIA, 18-21 November 2025", "summary": "Combining motion prediction and motion planning offers a promising framework for enhancing interactions between automated vehicles and other traffic participants. However, this introduces challenges in conditioning predictions on navigation goals and ensuring stable, kinematically feasible trajectories. Addressing the former challenge, this paper investigates the extension of attention-based motion prediction models with navigation information. By integrating the ego vehicle's intended route and goal pose into the model architecture, we bridge the gap between multi-agent motion prediction and goal-based motion planning. We propose and evaluate several architectural navigation integration strategies to our model on the nuPlan dataset. Our results demonstrate the potential of prediction-driven motion planning, highlighting how navigation information can enhance both prediction and planning tasks. Our implementation is at: https://github.com/KIT-MRT/future-motion.", "AI": {"tldr": "This paper combines motion prediction and navigation information to improve automated vehicle interactions using architectural strategies evaluated on the nuPlan dataset.", "motivation": "The study aims to address challenges in combining motion prediction and planning for automated vehicles, specifically conditioning predictions on navigation goals and ensuring trajectory feasibility.", "method": "Attention-based motion prediction models are extended with navigation information by integrating the ego vehicle's route and goal pose into the architecture. Several integration strategies are proposed and evaluated.", "result": "Tests on the nuPlan dataset show that the prediction-driven planning framework can enhance both motion prediction and planning by incorporating navigation data.", "conclusion": "The research underscores the potential of integrating navigation information into motion prediction for improving automated vehicle systems, with an implementation provided for further exploration."}}
{"id": "2512.03672", "pdf": "https://arxiv.org/pdf/2512.03672", "abs": "https://arxiv.org/abs/2512.03672", "authors": ["Shiruo Hu", "Wenbo Shan", "Yingjia Li", "Zhiqi Wan", "Xinpeng Yu", "Yunjia Qi", "Haotian Xia", "Yang Xiao", "Dingxiao Liu", "Jiaru Wang", "Chenxu Gong", "Ruixi Zhang", "Shuyue Wu", "Shibo Cui", "Chee Hui Lai", "Wei Luo", "Yubin He", "Bin Xu", "Jianshi Zhao"], "title": "Evaluating Hydro-Science and Engineering Knowledge of Large Language Models", "categories": ["cs.CL"], "comment": "Hydro-SE Bench sets a new benchmark for the evaluation of LLMs in the Hydro-Science and Engineering domain, with its code and data available at \\url{https://github.com/sheishijun/Hydro-SE-Bench}", "summary": "Hydro-Science and Engineering (Hydro-SE) is a critical and irreplaceable domain that secures human water supply, generates clean hydropower energy, and mitigates flood and drought disasters. Featuring multiple engineering objectives, Hydro-SE is an inherently interdisciplinary domain that integrates scientific knowledge with engineering expertise. This integration necessitates extensive expert collaboration in decision-making, which poses difficulties for intelligence. With the rapid advancement of large language models (LLMs), their potential application in the Hydro-SE domain is being increasingly explored. However, the knowledge and application abilities of LLMs in Hydro-SE have not been sufficiently evaluated. To address this issue, we propose the Hydro-SE LLM evaluation benchmark (Hydro-SE Bench), which contains 4,000 multiple-choice questions. Hydro-SE Bench covers nine subfields and enables evaluation of LLMs in aspects of basic conceptual knowledge, engineering application ability, and reasoning and calculation ability. The evaluation results on Hydro-SE Bench show that the accuracy values vary among 0.74 to 0.80 for commercial LLMs, and among 0.41 to 0.68 for small-parameter LLMs. While LLMs perform well in subfields closely related to natural and physical sciences, they struggle with domain-specific knowledge such as industry standards and hydraulic structures. Model scaling mainly improves reasoning and calculation abilities, but there is still great potential for LLMs to better handle problems in practical engineering application. This study highlights the strengths and weaknesses of LLMs for Hydro-SE tasks, providing model developers with clear training targets and Hydro-SE researchers with practical guidance for applying LLMs.", "AI": {"tldr": "The paper introduces Hydro-SE Bench, a benchmark for evaluating large language models (LLMs) in the Hydro-Science and Engineering domain. It contains 4,000 questions to test knowledge, application ability, and reasoning. While LLMs show potential, they struggle with domain-specific issues.", "motivation": "To assess and improve the application of LLMs in Hydro-Science and Engineering (Hydro-SE), where their capabilities to address specialized knowledge and engineering challenges are not well-evaluated.", "method": "Developed Hydro-SE Bench containing 4,000 multiple-choice questions across nine subfields to evaluate LLMs in conceptual knowledge, engineering application, and reasoning/calculation abilities.", "result": "Accuracy of commercial LLMs ranges from 0.74 to 0.80, while smaller LLMs range from 0.41 to 0.68. LLMs perform better in natural/physical sciences and poorly in domain-specific knowledge.", "conclusion": "LLMs have potential in Hydro-SE but need significant improvements in handling domain-specific challenges and practical engineering applications. Provides clear targets for developers and guidance for researchers."}}
{"id": "2512.03428", "pdf": "https://arxiv.org/pdf/2512.03428", "abs": "https://arxiv.org/abs/2512.03428", "authors": ["Ziyi Ding", "Xiao-Ping Zhang"], "title": "GaussDetect-LiNGAM:Causal Direction Identification without Gaussianity test", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We propose GaussDetect-LiNGAM, a novel approach for bivariate causal discovery that eliminates the need for explicit Gaussianity tests by leveraging a fundamental equivalence between noise Gaussianity and residual independence in the reverse regression. Under the standard LiNGAM assumptions of linearity, acyclicity, and exogeneity, we prove that the Gaussianity of the forward-model noise is equivalent to the independence between the regressor and residual in the reverse model. This theoretical insight allows us to replace fragile and sample-sensitive Gaussianity tests with robust kernel-based independence tests. Experimental results validate the equivalence and demonstrate that GaussDetect-LiNGAM maintains high consistency across diverse noise types and sample sizes, while reducing the number of tests per decision (TPD). Our method enhances both the efficiency and practical applicability of causal inference, making LiNGAM more accessible and reliable in real-world scenarios.", "AI": {"tldr": "GaussDetect-LiNGAM enhances bivariate causal discovery by eliminating Gaussianity tests, instead using kernel-based independence tests for greater robustness.", "motivation": "To improve the efficiency and reliability of the LiNGAM framework by addressing the challenges associated with fragile and sample-sensitive Gaussianity tests.", "method": "The paper introduces GaussDetect-LiNGAM, which replaces Gaussianity tests with kernel-based independence tests, leveraging the equivalence between noise Gaussianity and residual independence under the reverse regression.", "result": "The method maintains high consistency with diverse noise types and sample sizes while reducing the number of tests per decision (TPD).", "conclusion": "GaussDetect-LiNGAM increases the efficiency and applicability of causal inference, making LiNGAM more robust and practical for real-world applications."}}
{"id": "2512.03405", "pdf": "https://arxiv.org/pdf/2512.03405", "abs": "https://arxiv.org/abs/2512.03405", "authors": ["Jiangtao Wu", "Shihao Li", "Zhaozhou Bian", "Yuanxing Zhang", "Jialu Chen", "Runzhe Wen", "An Ping", "Yiwen He", "Jiakai Wang", "Jiaheng Liu"], "title": "ViDiC: Video Difference Captioning", "categories": ["cs.CV"], "comment": null, "summary": "Understanding visual differences between dynamic scenes requires the comparative perception of compositional, spatial, and temporal changes--a capability that remains underexplored in existing vision-language systems. While prior work on Image Difference Captioning (IDC) has enabled models to describe semantic changes between static images, these approaches fail to capture motion continuity, event evolution, or editing consistency over time. We introduce the ViDiC (Video Difference Captioning) task and its corresponding ViDiC-1K dataset, designed to evaluate the ability of Multimodal Large Language Models (MLLMs) to provide fine-grained descriptions of similarities and differences between video pairs. ViDiC-1K comprises 1,000 curated video pairs annotated with over 4,000 comparative checklist items, covering seven categories: subject, style, background, cinematography, motion, location, and playback techniques. To ensure reliable evaluation, we propose a dual-checklist framework that measures the accuracy of similarity and difference separately, based on the LLM-as-a-Judge protocol. Experiments on nineteen representative multimodal models reveal a significant performance gap in their comparative description and difference perception abilities. We hope ViDiC-1K can be a challenging benchmark that lays a solid foundation for advancing video understanding, edit awareness, and comparative reasoning in multimodal intelligence.", "AI": {"tldr": "The paper introduces the ViDiC task and dataset for analyzing and describing differences and similarities in video pairs, highlighting current limitations in multimodal models.", "motivation": "To address the lack of systems capable of comprehending and describing dynamic scene differences, especially regarding compositional, spatial, and temporal changes.", "method": "The authors introduce the ViDiC-1K dataset with 1,000 video pairs annotated with 4,000 comparative checklist items across seven categories and propose a dual-checklist evaluation framework based on LLM-as-a-Judge protocol.", "result": "Testing 19 multimodal models exposed significant limitations in their comparative description capabilities, showcasing a performance gap that ViDiC aims to bridge.", "conclusion": "ViDiC-1K is expected to serve as an essential benchmark for enhancing video understanding, comparative reasoning, and edit awareness in multimodal systems."}}
{"id": "2512.03114", "pdf": "https://arxiv.org/pdf/2512.03114", "abs": "https://arxiv.org/abs/2512.03114", "authors": ["Srijani Mukherjee", "Laurent Vuillon", "Liliane Bou Nassif", "St\u00e9phanie Giroux-Julien", "Herv\u00e9 Pabiou", "Denys Dutykh", "Ionnasis Tsanakas"], "title": "Temporal Graph Neural Networks for Early Anomaly Detection and Performance Prediction via PV System Monitoring Data", "categories": ["cs.LG", "physics.data-an"], "comment": null, "summary": "The rapid growth of solar photovoltaic (PV) systems necessitates advanced methods for performance monitoring and anomaly detection to ensure optimal operation. In this study, we propose a novel approach leveraging Temporal Graph Neural Network (Temporal GNN) to predict solar PV output power and detect anomalies using environmental and operational parameters. The proposed model utilizes graph-based temporal relationships among key PV system parameters, including irradiance, module and ambient temperature to predict electrical power output. This study is based on data collected from an outdoor facility located on a rooftop in Lyon (France) including power measurements from a PV module and meteorological parameters.", "AI": {"tldr": "This paper proposes using Temporal Graph Neural Networks (GNNs) to predict solar PV output and detect anomalies based on environmental and operational data.", "motivation": "The rapid expansion of solar PV systems highlights the need for sophisticated monitoring and anomaly detection to ensure efficiency and optimal operation.", "method": "The authors utilize Temporal GNN to model temporal and graph-based relationships among key PV parameters, such as irradiance and temperature, for predicting electrical power output.", "result": "The model is demonstrated using data collected from a rooftop outdoor facility in Lyon, France, incorporating both operational and meteorological parameters.", "conclusion": "Temporal GNN provides an innovative method for accurate PV performance monitoring and anomaly detection, which could improve operational efficiency."}}
{"id": "2512.03772", "pdf": "https://arxiv.org/pdf/2512.03772", "abs": "https://arxiv.org/abs/2512.03772", "authors": ["Gabriele Fadini", "Deepak Ingole", "Tong Duy Son", "Alisa Rupenyan"], "title": "Bayesian Optimization for Automatic Tuning of Torque-Level Nonlinear Model Predictive Control", "categories": ["cs.RO", "cs.AI", "eess.SY"], "comment": "6 pages, 7 figures, 3 tables", "summary": "This paper presents an auto-tuning framework for torque-based Nonlinear Model Predictive Control (nMPC), where the MPC serves as a real-time controller for optimal joint torque commands. The MPC parameters, including cost function weights and low-level controller gains, are optimized using high-dimensional Bayesian Optimization (BO) techniques, specifically Sparse Axis-Aligned Subspace (SAASBO) with a digital twin (DT) to achieve precise end-effector trajectory real-time tracking on an UR10e robot arm. The simulation model allows efficient exploration of the high-dimensional parameter space, and it ensures safe transfer to hardware. Our simulation results demonstrate significant improvements in tracking performance (+41.9%) and reduction in solve times (-2.5%) compared to manually-tuned parameters. Moreover, experimental validation on the real robot follows the trend (with a +25.8% improvement), emphasizing the importance of digital twin-enabled automated parameter optimization for robotic operations.", "AI": {"tldr": "The paper proposes an auto-tuning framework combining Nonlinear Model Predictive Control (nMPC) and Bayesian Optimization (BO) techniques to enhance tracking performance in robotic systems.", "motivation": "To address the challenges of manually tuning MPC parameters for precise tracking in robots, increasing automation in parameter optimization for better efficiency and safety.", "method": "MPC is used for generating optimal torque commands, while high-dimensional BO, specifically SAASBO integrated with a digital twin, tunes MPC parameters efficiently in simulation and experiments.", "result": "Simulation achieved a 41.9% improvement in tracking performance and a 2.5% reduction in solve time. Real robot experiments validated with a 25.8% performance improvement.", "conclusion": "The integration of BO and DT in tuning MPC parameters significantly enhances robotic control and stresses the importance of automated optimization for real-world robotic applications."}}
{"id": "2512.03676", "pdf": "https://arxiv.org/pdf/2512.03676", "abs": "https://arxiv.org/abs/2512.03676", "authors": ["Daria Kryvosheieva", "Andrea de Varda", "Evelina Fedorenko", "Greta Tuckute"], "title": "Different types of syntactic agreement recruit the same units within large language models", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) can reliably distinguish grammatical from ungrammatical sentences, but how grammatical knowledge is represented within the models remains an open question. We investigate whether different syntactic phenomena recruit shared or distinct components in LLMs. Using a functional localization approach inspired by cognitive neuroscience, we identify the LLM units most responsive to 67 English syntactic phenomena in seven open-weight models. These units are consistently recruited across sentences containing the phenomena and causally support the models' syntactic performance. Critically, different types of syntactic agreement (e.g., subject-verb, anaphor, determiner-noun) recruit overlapping sets of units, suggesting that agreement constitutes a meaningful functional category for LLMs. This pattern holds in English, Russian, and Chinese; and further, in a cross-lingual analysis of 57 diverse languages, structurally more similar languages share more units for subject-verb agreement. Taken together, these findings reveal that syntactic agreement-a critical marker of syntactic dependencies-constitutes a meaningful category within LLMs' representational spaces.", "AI": {"tldr": "The study explores how large language models (LLMs) represent grammatical knowledge, finding that syntactic agreement phenomena recruit overlapping neural units across languages, revealing agreement as a functional category for LLMs.", "motivation": "To understand how grammatical knowledge is represented in LLMs and whether different syntactic phenomena share or recruit distinct neural components.", "method": "The researchers use a functional localization approach to identify LLM units most responsive to syntactic phenomena, analyzing their responses, consistency, causal support for syntactic performance, and cross-lingual patterns.", "result": "LLM units consistently respond to syntactic phenomena and provide causal support for performance. Overlapping units are recruited for syntactic agreement, indicating meaningful functional categories across English, Russian, Chinese, and 57 other languages.", "conclusion": "Syntactic agreement constitutes a significant category in LLMs' representational spaces, showing structural language similarities and implications for syntactic dependencies."}}
{"id": "2512.03537", "pdf": "https://arxiv.org/pdf/2512.03537", "abs": "https://arxiv.org/abs/2512.03537", "authors": ["Zhiming Xu", "Baile Xu", "Jian Zhao", "Furao Shen", "Suorong Yang"], "title": "Parameter-Efficient Augment Plugin for Class-Incremental Learning", "categories": ["cs.LG", "stat.ML"], "comment": "10 pages, 6 figures, 2 tables", "summary": "Existing class-incremental learning (CIL) approaches based on replay or knowledge distillation are often constrained by forgetting or the stability-plasticity dilemma. Some expansion-based approaches could achieve higher accuracy. However, they always require significant parameter increases. In this paper, we propose a plugin extension paradigm termed the Deployment of extra LoRA Components (DLC) for non-pre-trained CIL scenarios.We treat the feature extractor trained through replay or distillation as a base model with rich knowledge. For each task, we use Low-Rank Adaptation (LoRA) to inject task-specific residuals into the base model's deep layers. During inference, representations with task-specific residuals are aggregated to produce classification predictions. To mitigate interference from non-target LoRA plugins, we introduce a lightweight weighting unit. This unit learns to assign importance scores to different LoRA-tuned representations. Like downloadable contents in software, our method serves as a plug-and-play enhancement that efficiently extends the base methods. Remarkably, on the large-scale ImageNet-100, with merely 4 % of the parameters of a standard ResNet-18, our DLC model achieves a significant 8 % improvement in accuracy, demonstrating exceptional efficiency. Moreover, it could surpass state-of-the-art methods under the fixed memory budget.", "AI": {"tldr": "The paper introduces DLC (Deployment of extra LoRA Components), a plugin-based approach for class-incremental learning that enhances accuracy efficiently by adding task-specific residuals.", "motivation": "Existing methods for class-incremental learning face challenges like forgetting or requiring large parameter expansions. This paper aims to overcome these issues with a lightweight and efficient solution.", "method": "The approach uses Low-Rank Adaptation (LoRA) components to integrate task-specific residuals into a base model trained via replay or distillation. A weighting unit determines the importance of these residuals during inference.", "result": "The proposed DLC method achieves a notable 8% accuracy improvement on ImageNet-100 while using only 4% of the parameters of ResNet-18, showing efficiency and effectiveness.", "conclusion": "DLC emerges as an efficient, plug-and-play enhancement for class-incremental learning, outperforming state-of-the-art methods under fixed memory conditions."}}
{"id": "2512.03418", "pdf": "https://arxiv.org/pdf/2512.03418", "abs": "https://arxiv.org/abs/2512.03418", "authors": ["Yuqi Ji", "Junjie Ke", "Lihuo He", "Jun Liu", "Kaifan Zhang", "Yu-Kun Lai", "Guiguang Ding", "Xinbo Gao"], "title": "YOLOA: Real-Time Affordance Detection via LLM Adapter", "categories": ["cs.CV", "cs.HC"], "comment": "13 pages, 9 figures, conference", "summary": "Affordance detection aims to jointly address the fundamental \"what-where-how\" challenge in embodied AI by understanding \"what\" an object is, \"where\" the object is located, and \"how\" it can be used. However, most affordance learning methods focus solely on \"how\" objects can be used while neglecting the \"what\" and \"where\" aspects. Other affordance detection methods treat object detection and affordance learning as two independent tasks, lacking effective interaction and real-time capability. To overcome these limitations, we introduce YOLO Affordance (YOLOA), a real-time affordance detection model that jointly handles these two tasks via a large language model (LLM) adapter. Specifically, YOLOA employs a lightweight detector consisting of object detection and affordance learning branches refined through the LLM Adapter. During training, the LLM Adapter interacts with object and affordance preliminary predictions to refine both branches by generating more accurate class priors, box offsets, and affordance gates. Experiments on our relabeled ADG-Det and IIT-Heat benchmarks demonstrate that YOLOA achieves state-of-the-art accuracy (52.8 / 73.1 mAP on ADG-Det / IIT-Heat) while maintaining real-time performance (up to 89.77 FPS, and up to 846.24 FPS for the lightweight variant). This indicates that YOLOA achieves an excellent trade-off between accuracy and efficiency.", "AI": {"tldr": "The paper introduces YOLOA, a real-time affordance detection model that integrates object detection and affordance learning via an LLM adapter, achieving state-of-the-art accuracy and superior efficiency.", "motivation": "Most existing affordance detection methods focus on ''how'' objects can be used while neglecting ''what'' they are and ''where'' they are located, and current approaches lack effective interaction between object detection and affordance learning for real-time efficacy.", "method": "The YOLOA model includes a lightweight detector with object detection and affordance learning branches refined by an LLM adapter, which improves predictions through interaction during training.", "result": "YOLOA achieved 52.8/73.1 mAP on ADG-Det/IIT-Heat benchmarks respectively, while maintaining real-time processing speeds of up to 89.77 FPS and 846.24 FPS for the lightweight version.", "conclusion": "YOLOA presents an efficient and accurate solution to affordance detection, effectively balancing both accuracy and real-time performance by integrating object detection and affordance learning tasks."}}
{"id": "2512.03115", "pdf": "https://arxiv.org/pdf/2512.03115", "abs": "https://arxiv.org/abs/2512.03115", "authors": ["Hanbin Cho", "Jecheon Yu", "Hyeonbin Moon", "Jiyoung Yoon", "Junhyeong Lee", "Giyoung Kim", "Jinhyoung Park", "Seunghwa Ryu"], "title": "Real-Time Structural Health Monitoring with Bayesian Neural Networks: Distinguishing Aleatoric and Epistemic Uncertainty for Digital Twin Frameworks", "categories": ["cs.LG"], "comment": "37 pages, 13 figures", "summary": "Reliable real-time analysis of sensor data is essential for structural health monitoring (SHM) of high-value assets, yet a major challenge is to obtain spatially resolved full-field aleatoric and epistemic uncertainties for trustworthy decision-making. We present an integrated SHM framework that combines principal component analysis (PCA), a Bayesian neural network (BNN), and Hamiltonian Monte Carlo (HMC) inference, mapping sparse strain gauge measurements onto leading PCA modes to reconstruct full-field strain distributions with uncertainty quantification. The framework was validated through cyclic four-point bending tests on carbon fiber reinforced polymer (CFRP) specimens with varying crack lengths, achieving accurate strain field reconstruction (R squared value > 0.9) while simultaneously producing real-time uncertainty fields. A key contribution is that the BNN yields robust full-field strain reconstructions from noisy experimental data with crack-induced strain singularities, while also providing explicit representations of two complementary uncertainty fields. Considered jointly in full-field form, the aleatoric and epistemic uncertainty fields make it possible to diagnose at a local level, whether low-confidence regions are driven by data-inherent issues or by model-related limitations, thereby supporting reliable decision-making. Collectively, the results demonstrate that the proposed framework advances SHM toward trustworthy digital twin deployment and risk-aware structural diagnostics.", "AI": {"tldr": "The paper introduces a framework for analyzing sensor data to monitor structural health, resolving uncertainties for better decision-making using PCA, Bayesian Neural Network, and Monte Carlo techniques.", "motivation": "Addressing the challenge in structural health monitoring of producing spatially resolved full-field uncertainties to ensure trustworthy decision-making.", "method": "An integrated framework combining PCA, Bayesian Neural Network (BNN), and Hamiltonian Monte Carlo inference to reconstruct strain fields from sparse data while quantifying uncertainties.", "result": "Validated on CFRP specimens during bending tests, achieving accurate strain reconstruction (R-squared > 0.9) and generating real-time uncertainty fields.", "conclusion": "The framework facilitates informed diagnostics by distinguishing data-driven and model-related uncertainties, enabling trustworthy decision-making and progression toward digital twin deployment."}}
{"id": "2512.03774", "pdf": "https://arxiv.org/pdf/2512.03774", "abs": "https://arxiv.org/abs/2512.03774", "authors": ["Johannes Fischer", "Marlon Steiner", "\u00d6mer Sahin Tas", "Christoph Stiller"], "title": "Safety Reinforced Model Predictive Control (SRMPC): Improving MPC with Reinforcement Learning for Motion Planning in Autonomous Driving", "categories": ["cs.RO"], "comment": null, "summary": "Model predictive control (MPC) is widely used for motion planning, particularly in autonomous driving. Real-time capability of the planner requires utilizing convex approximation of optimal control problems (OCPs) for the planner. However, such approximations confine the solution to a subspace, which might not contain the global optimum. To address this, we propose using safe reinforcement learning (SRL) to obtain a new and safe reference trajectory within MPC. By employing a learning-based approach, the MPC can explore solutions beyond the close neighborhood of the previous one, potentially finding global optima. We incorporate constrained reinforcement learning (CRL) to ensure safety in automated driving, using a handcrafted energy function-based safety index as the constraint objective to model safe and unsafe regions. Our approach utilizes a state-dependent Lagrangian multiplier, learned concurrently with the safe policy, to solve the CRL problem. Through experimentation in a highway scenario, we demonstrate the superiority of our approach over both MPC and SRL in terms of safety and performance measures.", "AI": {"tldr": "The paper introduces a novel motion planning technique for autonomous driving by integrating safe reinforcement learning (SRL) with model predictive control (MPC).", "motivation": "MPC for autonomous driving relies on convex approximations for efficiency, but this limits solution flexibility and may exclude global optima.", "method": "The proposed approach combines SRL with MPC, using constrained reinforcement learning (CRL) and a state-dependent Lagrangian multiplier to model safe and unsafe regions.", "result": "Experiments in highway scenarios show enhanced safety and performance of the proposed method compared to MPC and SRL alone.", "conclusion": "Integrating SRL with MPC allows safer exploration of solutions beyond conventional approximations, improving autonomous vehicle motion planning capabilities."}}
{"id": "2512.03688", "pdf": "https://arxiv.org/pdf/2512.03688", "abs": "https://arxiv.org/abs/2512.03688", "authors": ["Numaan Naeem", "Kaushal Kumar Maurya", "Kseniia Petukhova", "Ekaterina Kochmar"], "title": "AITutor-EvalKit: Exploring the Capabilities of AI Tutors", "categories": ["cs.CL"], "comment": null, "summary": "We present AITutor-EvalKit, an application that uses language technology to evaluate the pedagogical quality of AI tutors, provides software for demonstration and evaluation, as well as model inspection and data visualization. This tool is aimed at education stakeholders as well as *ACL community at large, as it supports learning and can also be used to collect user feedback and annotations.", "AI": {"tldr": "This paper introduces AITutor-EvalKit, a tool for evaluating AI tutors and inspecting models.", "motivation": "The paper aims to provide a framework for assessing the pedagogical quality of AI tutors and engaging education stakeholders.", "method": "The application combines language technology, model inspection software, and data visualization tools.", "result": "The tool supports learning, user feedback collection, and annotation gathering.", "conclusion": "AITutor-EvalKit serves both educational stakeholders and the ACL community by improving AI tutor evaluation and facilitating research feedback."}}
{"id": "2512.03637", "pdf": "https://arxiv.org/pdf/2512.03637", "abs": "https://arxiv.org/abs/2512.03637", "authors": ["Kohei Yamamoto", "Kosuke Okusa"], "title": "AaPE: Aliasing-aware Patch Embedding for Self-Supervised Audio Representation Learning", "categories": ["cs.SD", "cs.LG", "stat.ML"], "comment": "11 pages, 4 figures", "summary": "Transformer-based audio SSL (self-supervised learning) models often treat spectrograms as images, applying convolutional patchification with heavy temporal downsampling. This lowers the effective Nyquist frequency and introduces aliasing, while na\u00efve low-pass filtering removes task-relevant high-frequency cues. In this study, we present Aliasing-aware Patch Embedding (AaPE), a drop-in patch stem that mitigates aliasing while preserving high-frequency information. AaPE augments standard patch tokens with features produced by a band-limited complex sinusoidal kernel using a two-sided exponential window that dynamically targets alias-prone bands. Frequency and decay parameters of the kernel are estimated from the input, enabling parallel, adaptive subband analysis whose outputs are fused with the standard patch tokens. AaPE integrates seamlessly into the masked teacher-student self-supervised learning. In addition, we combine a multi-mask strategy with a contrastive objective to enforce consistency across diverse mask patterns, stabilizing training. Pre-training on AudioSet followed by fine-tuning evaluation across diverse downstream benchmarks, which spanned categories, such as environmental sounds and other common audio domains. This approach yields state-of-the-art performance on a subset of tasks and competitive results across the remainder. Complementary linear probing evaluation mirrors this pattern, yielding clear gains on several benchmarks and strong performance elsewhere. The collective analysis of these results indicates that AaPE serves to mitigate the effects of aliasing without discarding of informative high-frequency content.", "AI": {"tldr": "The paper introduces Aliasing-aware Patch Embedding (AaPE) for audio self-supervised learning, addressing aliasing issues while retaining high-frequency information, resulting in superior or competitive performance across various audio benchmarks.", "motivation": "The motivation is to address the aliasing problem in transformer-based audio SSL models caused by heavy temporal downsampling in patchification that discards task-relevant high-frequency cues.", "method": "The authors propose Aliasing-aware Patch Embedding (AaPE), which augments standard patch tokens with features from band-limited sinusoidal kernels. These kernels dynamically target alias-prone bands, enabling adaptive subband analysis, and integrate into a masked teacher-student SSL framework. A multi-mask strategy with contrastive objective is also introduced.", "result": "The method showed state-of-the-art performance on a subset of audio tasks and competitive results on others. Linear probing evaluations demonstrated similar improvements, confirming AaPE\u2019s effectiveness in addressing aliasing while preserving high-frequency content.", "conclusion": "AaPE mitigates the effects of aliasing and achieves enhanced performance on diverse audio benchmarks, showcasing its ability to retain and utilize informative high-frequency information effectively."}}
{"id": "2512.03424", "pdf": "https://arxiv.org/pdf/2512.03424", "abs": "https://arxiv.org/abs/2512.03424", "authors": ["Bin Liu", "Chunyang Wang", "Xuelian Liu"], "title": "DM3D: Deformable Mamba via Offset-Guided Gaussian Sequencing for Point Cloud Understanding", "categories": ["cs.CV"], "comment": null, "summary": "State Space Models (SSMs) demonstrate significant potential for long-sequence modeling, but their reliance on input order conflicts with the irregular nature of point clouds. Existing approaches often rely on predefined serialization strategies, which cannot adjust based on diverse geometric structures. To overcome this limitation, we propose \\textbf{DM3D}, a deformable Mamba architecture for point cloud understanding. Specifically, DM3D introduces an offset-guided Gaussian sequencing mechanism that unifies local resampling and global reordering within a deformable scan. The Gaussian-based KNN Resampling (GKR) enhances structural awareness by adaptively reorganizing neighboring points, while the Gaussian-based Differentiable Reordering (GDR) enables end-to-end optimization of serialization order. Furthermore, a Tri-Path Frequency Fusion module enhances feature complementarity and reduces aliasing. Together, these components enable structure-adaptive serialization of point clouds. Extensive experiments on benchmark datasets show that DM3D achieves state-of-the-art performance in classification, few-shot learning, and part segmentation, demonstrating that adaptive serialization effectively unlocks the potential of SSMs for point cloud understanding.", "AI": {"tldr": "DM3D is a state-of-the-art deformable model for point cloud understanding, introducing adaptive Gaussian-based resampling and reordering techniques and achieving impressive results in various tasks.", "motivation": "The reliance of State Space Models on input order conflicts with the irregular and geometric nature of point clouds. Existing models fail to adaptively adjust serialization strategies based on different structures, limiting their effectiveness.", "method": "The authors developed DM3D, which includes novel Gaussian-based KNN resampling (GKR) for local structural awareness and Gaussian-based differentiable reordering (GDR) for optimizing input serialization. A Tri-Path Frequency Fusion module is also incorporated to enhance feature processing.", "result": "DM3D outperforms existing models across benchmark datasets in classification, few-shot learning, and part segmentation tasks, showcasing its adaptive serialization capabilities.", "conclusion": "Adaptive serialization methods, as implemented in DM3D, significantly improve the application of State Space Models for understanding point clouds, making them highly competent for tasks involving irregular and geometric data."}}
{"id": "2512.03125", "pdf": "https://arxiv.org/pdf/2512.03125", "abs": "https://arxiv.org/abs/2512.03125", "authors": ["Xiwen Wei", "Mustafa Munir", "Radu Marculescu"], "title": "Mitigating Intra- and Inter-modal Forgetting in Continual Learning of Unified Multimodal Models", "categories": ["cs.LG", "cs.AI"], "comment": "NeurIPS 2025", "summary": "Unified Multimodal Generative Models (UMGMs) unify visual understanding and image generation within a single autoregressive framework. However, their ability to continually learn new tasks is severely hindered by catastrophic forgetting, both within a modality (intra-modal) and across modalities (inter-modal). While intra-modal forgetting has been studied in prior continual learning (CL) work, inter-modal forgetting remains largely unexplored. In this paper, we identify and empirically validate this phenomenon in UMGMs and provide a theoretical explanation rooted in gradient conflict between modalities. To address both intra- and inter-modal forgetting, we propose Modality-Decoupled Experts (MoDE), a lightweight and scalable architecture that isolates modality-specific updates to mitigate the gradient conflict and leverages knowledge distillation to prevent catastrophic forgetting and preserve pre-trained capabilities. Unlike previous CL methods that remain modality-coupled and suffer from modality gradient conflict, MoDE explicitly decouples modalities to prevent interference. Experiments across diverse benchmarks demonstrate that MoDE significantly mitigates both inter- and intra-modal forgetting, outperforming prior CL baselines in unified multimodal generation settings. Codes will be publicly available: https://github.com/Christina200/MoDE-official.git", "AI": {"tldr": "The paper addresses catastrophic forgetting in Unified Multimodal Generative Models, particularly focusing on inter-modal forgetting, and introduces Modality-Decoupled Experts (MoDE) to tackle this issue effectively.", "motivation": "The motivation is to overcome the challenges of catastrophic forgetting in Unified Multimodal Generative Models, especially the less explored inter-modal forgetting, to enhance continual learning capabilities.", "method": "The paper introduces Modality-Decoupled Experts (MoDE), which isolates modality-specific updates to mitigate gradient conflicts and uses knowledge distillation to prevent forgetting and maintain pre-trained abilities.", "result": "Experiments show that MoDE significantly reduces both intra-modal and inter-modal forgetting and outperforms prior continual learning methods in unified multimodal generation benchmarks.", "conclusion": "By decoupling modalities and addressing gradient conflicts, MoDE successfully mitigates catastrophic forgetting in multimodal generative models, setting a new standard for continual learning frameworks."}}
{"id": "2512.03795", "pdf": "https://arxiv.org/pdf/2512.03795", "abs": "https://arxiv.org/abs/2512.03795", "authors": ["Jia Hu", "Zhexi Lian", "Xuerun Yan", "Ruiang Bi", "Dou Shen", "Yu Ruan", "Haoran Wang"], "title": "MPCFormer: A physics-informed data-driven approach for explainable socially-aware autonomous driving", "categories": ["cs.RO", "cs.AI"], "comment": "17 pages, 18 figures", "summary": "Autonomous Driving (AD) vehicles still struggle to exhibit human-like behavior in highly dynamic and interactive traffic scenarios. The key challenge lies in AD's limited ability to interact with surrounding vehicles, largely due to a lack of understanding the underlying mechanisms of social interaction. To address this issue, we introduce MPCFormer, an explainable socially-aware autonomous driving approach with physics-informed and data-driven coupled social interaction dynamics. In this model, the dynamics are formulated into a discrete space-state representation, which embeds physics priors to enhance modeling explainability. The dynamics coefficients are learned from naturalistic driving data via a Transformer-based encoder-decoder architecture. To the best of our knowledge, MPCFormer is the first approach to explicitly model the dynamics of multi-vehicle social interactions. The learned social interaction dynamics enable the planner to generate manifold, human-like behaviors when interacting with surrounding traffic. By leveraging the MPC framework, the approach mitigates the potential safety risks typically associated with purely learning-based methods. Open-looped evaluation on NGSIM dataset demonstrates that MPCFormer achieves superior social interaction awareness, yielding the lowest trajectory prediction errors compared with other state-of-the-art approach. The prediction achieves an ADE as low as 0.86 m over a long prediction horizon of 5 seconds. Close-looped experiments in highly intense interaction scenarios, where consecutive lane changes are required to exit an off-ramp, further validate the effectiveness of MPCFormer. Results show that MPCFormer achieves the highest planning success rate of 94.67%, improves driving efficiency by 15.75%, and reduces the collision rate from 21.25% to 0.5%, outperforming a frontier Reinforcement Learning (RL) based planner.", "AI": {"tldr": "MPCFormer is an innovative approach to enhance autonomous driving behavior in dynamic scenarios by modeling multi-vehicle social interactions with physics-informed and data-driven methods, outperforming existing methods in simulations.", "motivation": "Autonomous vehicles struggle to perform human-like behaviors due to a limited ability to model and interact within complex, dynamic traffic environments. This limitation stems from inadequate understanding of social interaction mechanisms among vehicles.", "method": "Proposes MPCFormer, which combines a physics-informed, state-space dynamics model and a data-driven transformer architecture to model multi-vehicle social interactions. The system leverages Model Predictive Control (MPC) to ensure safety and explanations while learning from traffic data.", "result": "MPCFormer achieved significant performance improvements in simulations, such as an average displacement error (ADE) of just 0.86 m over 5 seconds, a planning success rate of 94.67%, and near-elimination of collision rates, outperforming state-of-the-art methods including reinforcement learning.", "conclusion": "This work advances both the safety and effectiveness of autonomous driving by integrating explainable multi-vehicle social dynamics into decision-making, resulting in substantial gains in human-like interaction, trajectory accuracy, and collision prevention."}}
{"id": "2512.03704", "pdf": "https://arxiv.org/pdf/2512.03704", "abs": "https://arxiv.org/abs/2512.03704", "authors": ["Yijun Liao"], "title": "DZ-TDPO: Non-Destructive Temporal Alignment for Mutable State Tracking in Long-Context Dialogue", "categories": ["cs.CL"], "comment": "22 pages, 2 figures, 13 tables. Code available at https://github.com/lyj20071013/DZ-TDPO", "summary": "Long-context dialogue systems suffer from State Inertia, where static constraints prevent models from resolving conflicts between evolving user intents and established historical context. To address this, we propose DZ-TDPO, a non-destructive alignment framework that synergizes conflict-aware dynamic KL constraints with a learnable temporal attention bias. Experiments on the Multi-Session Chat (MSC) dataset demonstrate that DZ-TDPO achieves state-of-the-art win rates (86.2% on Phi-3.5) while maintaining robust zero-shot generalization. Crucially, our scaling analysis reveals a \"Capacity-Stability Trade-off\": while smaller models incur an \"alignment tax\" (perplexity surge) to overcome historical inertia, the larger Qwen2.5-7B model achieves near-perfect alignment (99.4% win rate) with negligible perplexity overhead. This confirms that TAI can be alleviated via precise attention regulation rather than destructive weight updates, preserving general capabilities (MMLU) across model scales. Code and data are available: https://github.com/lyj20071013/DZ-TDPO", "AI": {"tldr": "This paper presents DZ-TDPO, a framework to solve State Inertia in dialogue systems by using conflict-aware constraints and temporal attention bias, achieving superior model alignment and performance.", "motivation": "The paper is motivated by the challenge of State Inertia in dialogue systems, where evolving user intents conflict with static historical context constraints.", "method": "The proposed solution is DZ-TDPO, combining dynamic KL constraints and learnable temporal attention bias for alignment and conflict resolution.", "result": "DZ-TDPO achieved state-of-the-art win rates (86.2% on Phi-3.5), robust zero-shot generalization, and demonstrated a capacity-stability trade-off for different model scales.", "conclusion": "Precise attention regulation, rather than destructive weight updates, can alleviate State Inertia while preserving general model capabilities across scales."}}
{"id": "2512.03777", "pdf": "https://arxiv.org/pdf/2512.03777", "abs": "https://arxiv.org/abs/2512.03777", "authors": ["Federico P. Cortese", "Luca Rossini"], "title": "A comparison between initialization strategies for the infinite hidden Markov model", "categories": ["stat.ME", "stat.AP", "stat.ML"], "comment": null, "summary": "Infinite hidden Markov models provide a flexible framework for modelling time series with structural changes and complex dynamics, without requiring the number of latent states to be specified in advance. This flexibility is achieved through the hierarchical Dirichlet process prior, while efficient Bayesian inference is enabled by the beam sampler, which combines dynamic programming with slice sampling to truncate the infinite state space adaptively. Despite extensive methodological developments, the role of initialization in this framework has received limited attention. This study addresses this gap by systematically evaluating initialization strategies commonly used for finite hidden Markov models and assessing their suitability in the infinite setting. Results from both simulated and real datasets show that distance-based clustering initializations consistently outperform model-based and uniform alternatives, the latter being the most widely adopted in the existing literature.", "AI": {"tldr": "The paper evaluates initialization strategies in infinite hidden Markov models, favoring distance-based clustering for better performance.", "motivation": "To address the limited attention on initialization strategies for infinite hidden Markov models as compared to finite models.", "method": "The study systematically evaluates various initialization strategies using simulated and real datasets.", "result": "Distance-based clustering initializations outperform model-based and uniform alternatives, which were previously the standard.", "conclusion": "Distance-based clustering is a more effective initialization approach for infinite hidden Markov models than the commonly used methods."}}
{"id": "2512.03427", "pdf": "https://arxiv.org/pdf/2512.03427", "abs": "https://arxiv.org/abs/2512.03427", "authors": ["Yida Lin", "Bing Xue", "Mengjie Zhang", "Sam Schofield", "Richard Green"], "title": "Generalization Evaluation of Deep Stereo Matching Methods for UAV-Based Forestry Applications", "categories": ["cs.CV"], "comment": null, "summary": "Autonomous UAV forestry operations require robust depth estimation methods with strong cross-domain generalization. However, existing evaluations focus on urban and indoor scenarios, leaving a critical gap for specialized vegetation-dense environments. We present the first systematic zero-shot evaluation of eight state-of-the-art stereo methods--RAFT-Stereo, IGEV, IGEV++, BridgeDepth, StereoAnywhere, DEFOM (plus baseline methods ACVNet, PSMNet, TCstereo)--spanning iterative refinement, foundation model, and zero-shot adaptation paradigms. All methods are trained exclusively on Scene Flow and evaluated without fine-tuning on four standard benchmarks (ETH3D, KITTI 2012/2015, Middlebury) plus a novel 5,313-pair Canterbury forestry dataset captured with ZED Mini camera (1920x1080). Performance reveals scene-dependent patterns: foundation models excel on structured scenes (BridgeDepth: 0.23 px on ETH3D, 0.83-1.07 px on KITTI; DEFOM: 0.35-4.65 px across benchmarks), while iterative methods maintain cross-domain robustness (IGEV++: 0.36-6.77 px; IGEV: 0.33-21.91 px). Critical finding: RAFT-Stereo exhibits catastrophic ETH3D failure (26.23 px EPE, 98 percent error rate) due to negative disparity predictions, while performing normally on KITTI (0.90-1.11 px). Qualitative evaluation on Canterbury forestry dataset identifies DEFOM as the optimal gold-standard baseline for vegetation depth estimation, exhibiting superior depth smoothness, occlusion handling, and cross-domain consistency compared to IGEV++, despite IGEV++'s finer detail preservation.", "AI": {"tldr": "The paper evaluates eight state-of-the-art stereo methods for depth estimation under extreme cross-domain conditions, especially in dense vegetation scenarios.", "motivation": "Autonomous UAV forestry operations need robust depth estimation methods that generalize effectively across different domains, as most evaluations focus on urban/indoor scenes, leaving out dense vegetation environments.", "method": "The authors systematically tested eight stereo depth estimation methods trained on Scene Flow. Methods were evaluated (zero-shot) across standard benchmarks (ETH3D, KITTI, Middlebury) and a novel Canterbury forestry dataset without fine-tuning.", "result": "Performance shows variation across methods with some excelling in structured scenes (like ETH3D and KITTI) and others offering cross-domain robustness. Key observation: RAFT-Stereo fails spectacularly on ETH3D but performs well on KITTI. DEFOM demonstrated optimal performance on the forestry tests.", "conclusion": "DEFOM emerged as the most suitable method for forestry depth estimation due to its depth smoothness and cross-domain consistency, outperforming other methods like IGEV++ in critical aspects."}}
{"id": "2512.03127", "pdf": "https://arxiv.org/pdf/2512.03127", "abs": "https://arxiv.org/abs/2512.03127", "authors": ["Ziyu Xiong", "Yichi Zhang", "Foyez Alauddin", "Chu Xin Cheng", "Joon Soo An", "Mohammad R. Seyedsayamdost", "Ellen D. Zhong"], "title": "Atomic Diffusion Models for Small Molecule Structure Elucidation from NMR Spectra", "categories": ["cs.LG", "cs.AI", "physics.chem-ph"], "comment": "NeurIPS 2025", "summary": "Nuclear Magnetic Resonance (NMR) spectroscopy is a cornerstone technique for determining the structures of small molecules and is especially critical in the discovery of novel natural products and clinical therapeutics. Yet, interpreting NMR spectra remains a time-consuming, manual process requiring extensive domain expertise. We introduce ChefNMR (CHemical Elucidation From NMR), an end-to-end framework that directly predicts an unknown molecule's structure solely from its 1D NMR spectra and chemical formula. We frame structure elucidation as conditional generation from an atomic diffusion model built on a non-equivariant transformer architecture. To model the complex chemical groups found in natural products, we generated a dataset of simulated 1D NMR spectra for over 111,000 natural products. ChefNMR predicts the structures of challenging natural product compounds with an unsurpassed accuracy of over 65%. This work takes a significant step toward solving the grand challenge of automating small-molecule structure elucidation and highlights the potential of deep learning in accelerating molecular discovery. Code is available at https://github.com/ml-struct-bio/chefnmr.", "AI": {"tldr": "ChefNMR is a framework utilizing deep learning to predict molecular structures from 1D NMR spectra with high accuracy.", "motivation": "Interpreting NMR spectra is a manual and expertise-demanding process crucial for molecular discovery and clinical applications.", "method": "ChefNMR uses an atomic diffusion model with a non-equivariant transformer and a simulation dataset of 1D NMR spectra from over 111,000 natural products.", "result": "ChefNMR achieves over 65% accuracy in predicting complex natural product structures.", "conclusion": "ChefNMR advances automated molecular structure elucidation and emphasizes the utility of deep learning in molecular research."}}
{"id": "2512.03828", "pdf": "https://arxiv.org/pdf/2512.03828", "abs": "https://arxiv.org/abs/2512.03828", "authors": ["Dominykas Strazdas", "Magnus Jung", "Jan Marquenie", "Ingo Siegert", "Ayoub Al-Hamadi"], "title": "IM HERE: Interaction Model for Human Effort Based Robot Engagement", "categories": ["cs.RO"], "comment": "8 pages, 5 figures", "summary": "The effectiveness of human-robot interaction often hinges on the ability to cultivate engagement - a dynamic process of cognitive involvement that supports meaningful exchanges. Many existing definitions and models of engagement are either too vague or lack the ability to generalize across different contexts. We introduce IM HERE, a novel framework that models engagement effectively in human-human, human-robot, and robot-robot interactions. By employing an effort-based description of bilateral relationships between entities, we provide an accurate breakdown of relationship patterns, simplifying them to focus placement and four key states. This framework captures mutual relationships, group behaviors, and actions conforming to social norms, translating them into specific directives for autonomous systems. By integrating both subjective perceptions and objective states, the model precisely identifies and describes miscommunication. The primary objective of this paper is to automate the analysis, modeling, and description of social behavior, and to determine how autonomous systems can behave in accordance with social norms for full social integration while simultaneously pursuing their own social goals.", "AI": {"tldr": "The paper introduces IM HERE, a new framework for understanding engagement in various interactions to improve communication and adherence to social norms.", "motivation": "Existing definitions of engagement in interactions are often vague and lack generalization across different contexts, necessitating a comprehensive framework.", "method": "Developed the IM HERE framework using effort-based bilateral relationship analysis focused on placement and key states to model interactions effectively.", "result": "The framework accurately identifies relationship patterns, models social behaviors, and provides directives for autonomous systems, while addressing miscommunication.", "conclusion": "IM HERE aids in automating the analysis of social behavior and enables autonomous systems to integrate socially while pursuing their own goals and adhering to norms."}}
{"id": "2512.03737", "pdf": "https://arxiv.org/pdf/2512.03737", "abs": "https://arxiv.org/abs/2512.03737", "authors": ["Chuyue Wang", "Jie Feng", "Yuxi Wu", "Hang Zhang", "Zhiguo Fan", "Bing Cheng", "Wei Lin"], "title": "AR-Med: Automated Relevance Enhancement in Medical Search via LLM-Driven Information Augmentation", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Accurate and reliable search on online healthcare platforms is critical for user safety and service efficacy. Traditional methods, however, often fail to comprehend complex and nuanced user queries, limiting their effectiveness. Large language models (LLMs) present a promising solution, offering powerful semantic understanding to bridge this gap. Despite their potential, deploying LLMs in this high-stakes domain is fraught with challenges, including factual hallucinations, specialized knowledge gaps, and high operational costs. To overcome these barriers, we introduce \\textbf{AR-Med}, a novel framework for \\textbf{A}utomated \\textbf{R}elevance assessment for \\textbf{Med}ical search that has been successfully deployed at scale on the Online Medical Delivery Platforms. AR-Med grounds LLM reasoning in verified medical knowledge through a retrieval-augmented approach, ensuring high accuracy and reliability. To enable efficient online service, we design a practical knowledge distillation scheme that compresses large teacher models into compact yet powerful student models. We also introduce LocalQSMed, a multi-expert annotated benchmark developed to guide model iteration and ensure strong alignment between offline and online performance. Extensive experiments show AR-Med achieves an offline accuracy of over 93\\%, a 24\\% absolute improvement over the original online system, and delivers significant gains in online relevance and user satisfaction. Our work presents a practical and scalable blueprint for developing trustworthy, LLM-powered systems in real-world healthcare applications.", "AI": {"tldr": "AR-Med is a scalable framework designed to enhance medical search accuracy and reliability on online platforms using retrieval-augmented LLMs and knowledge distillation.", "motivation": "Traditional search methods struggle with nuanced user queries in healthcare, and LLMs show promise but face issues like hallucinations and high costs. Addressing these gaps is crucial for user safety and satisfaction.", "method": "AR-Med employs a retrieval-augmented framework to ground LLMs in verified medical knowledge and uses knowledge distillation to create efficient, smaller models for practical deployment.", "result": "AR-Med achieves over 93% offline accuracy, a 24% improvement compared to the prior system, and demonstrates notable gains in online relevance and user satisfaction.", "conclusion": "The AR-Med framework is a robust solution for deploying trustworthy and scalable LLM-powered systems, addressing challenges in medical search while improving performance and user satisfaction."}}
{"id": "2512.03807", "pdf": "https://arxiv.org/pdf/2512.03807", "abs": "https://arxiv.org/abs/2512.03807", "authors": ["Christos Kolomvakis", "Thomas Bobille", "Arnaud Vandaele", "Nicolas Gillis"], "title": "Algorithms for Boolean Matrix Factorization using Integer Programming and Heuristics", "categories": ["cs.IR", "eess.SP", "math.OC", "stat.ML"], "comment": "24 pages, 12 tables, 3 figures, code and data available from https://gitlab.com/ckolomvakis/boolean-matrix-factorization-ip-and-heuristics", "summary": "Boolean matrix factorization (BMF) approximates a given binary input matrix as the product of two smaller binary factors. Unlike binary matrix factorization based on standard arithmetic, BMF employs the Boolean OR and AND operations for the matrix product, which improves interpretability and reduces the approximation error. It is also used in role mining and computer vision. In this paper, we first propose algorithms for BMF that perform alternating optimization (AO) of the factor matrices, where each subproblem is solved via integer programming (IP). We then design different approaches to further enhance AO-based algorithms by selecting an optimal subset of rank-one factors from multiple runs. To address the scalability limits of IP-based methods, we introduce new greedy and local-search heuristics. We also construct a new C++ data structure for Boolean vectors and matrices that is significantly faster than existing ones and is of independent interest, allowing our heuristics to scale to large datasets. We illustrate the performance of all our proposed methods and compare them with the state of the art on various real datasets, both with and without missing data, including applications in topic modeling and imaging.", "AI": {"tldr": "The paper proposes advanced methods for Boolean matrix factorization (BMF), offers integer programming (IP) based optimization, introduces scalable heuristics, and evaluates their performance on real datasets.", "motivation": "The paper aims to improve the interpretability and reduce errors in Boolean matrix factorization, making it applicable to fields like role mining and computer vision.", "method": "The authors propose algorithms using alternating optimization (AO) with integer programming (IP) for factor matrices, develop heuristic approaches for scalability, and provide an efficient C++ data structure for Boolean matrices.", "result": "The proposed methods show enhanced scalability and effectiveness, outperforming state-of-the-art approaches across multiple datasets and applications.", "conclusion": "The paper successfully introduces novel algorithms, optimizations, and a new data structure, significantly advancing the field of Boolean matrix factorization."}}
{"id": "2512.03430", "pdf": "https://arxiv.org/pdf/2512.03430", "abs": "https://arxiv.org/abs/2512.03430", "authors": ["Yuzhen Hu", "Biplab Banerjee", "Saurabh Prasad"], "title": "Label-Efficient Hyperspectral Image Classification via Spectral FiLM Modulation of Low-Level Pretrained Diffusion Features", "categories": ["cs.CV"], "comment": "Accepted to the ICML 2025 TerraBytes Workshop (June 9, 2025)", "summary": "Hyperspectral imaging (HSI) enables detailed land cover classification, yet low spatial resolution and sparse annotations pose significant challenges. We present a label-efficient framework that leverages spatial features from a frozen diffusion model pretrained on natural images. Our approach extracts low-level representations from high-resolution decoder layers at early denoising timesteps, which transfer effectively to the low-texture structure of HSI. To integrate spectral and spatial information, we introduce a lightweight FiLM-based fusion module that adaptively modulates frozen spatial features using spectral cues, enabling robust multimodal learning under sparse supervision. Experiments on two recent hyperspectral datasets demonstrate that our method outperforms state-of-the-art approaches using only the provided sparse training labels. Ablation studies further highlight the benefits of diffusion-derived features and spectral-aware fusion. Overall, our results indicate that pretrained diffusion models can support domain-agnostic, label-efficient representation learning for remote sensing and broader scientific imaging tasks.", "AI": {"tldr": "This paper proposes a label-efficient framework for hyperspectral imaging (HSI) using pretrained diffusion models and a fusion module to tackle challenges like low resolution and sparse annotations.", "motivation": "To address challenges in hyperspectral imaging such as low spatial resolution and limited labeled data, making land cover classification more efficient under sparse supervision.", "method": "The framework utilizes frozen diffusion models pretrained on natural images to extract spatial features at early denoising stages and integrates spectral data using a FiLM-based fusion module for multimodal learning.", "result": "Experiments on two hyperspectral datasets show significant outperformance over state-of-the-art methods, despite only using sparse training labels; ablation studies validate the approach.", "conclusion": "Pretrained diffusion models paired with spectral-aware fusion enable efficient representation learning, applicable to various remote sensing and scientific imaging tasks."}}
{"id": "2512.03158", "pdf": "https://arxiv.org/pdf/2512.03158", "abs": "https://arxiv.org/abs/2512.03158", "authors": ["Adele Chinda", "Richmond Azumah", "Hemanth Demakethepalli Venkateswara"], "title": "Contrastive Deep Learning for Variant Detection in Wastewater Genomic Sequencing", "categories": ["cs.LG", "q-bio.GN"], "comment": "13 pages, 4 figures", "summary": "Wastewater-based genomic surveillance has emerged as a powerful tool for population-level viral monitoring, offering comprehensive insights into circulating viral variants across entire communities. However, this approach faces significant computational challenges stemming from high sequencing noise, low viral coverage, fragmented reads, and the complete absence of labeled variant annotations. Traditional reference-based variant calling pipelines struggle with novel mutations and require extensive computational resources. We present a comprehensive framework for unsupervised viral variant detection using Vector-Quantized Variational Autoencoders (VQ-VAE) that learns discrete codebooks of genomic patterns from k-mer tokenized sequences without requiring reference genomes or variant labels. Our approach extends the base VQ-VAE architecture with masked reconstruction pretraining for robustness to missing data and contrastive learning for highly discriminative embeddings. Evaluated on SARS-CoV-2 wastewater sequencing data comprising approximately 100,000 reads, our VQ-VAE achieves 99.52% mean token-level accuracy and 56.33% exact sequence match rate while maintaining 19.73% codebook utilization (101 of 512 codes active), demonstrating efficient discrete representation learning. Contrastive fine-tuning with different projection dimensions yields substantial clustering improvements: 64-dimensional embeddings achieve +35% Silhouette score improvement (0.31 to 0.42), while 128-dimensional embeddings achieve +42% improvement (0.31 to 0.44), clearly demonstrating the impact of embedding dimensionality on variant discrimination capability. Our reference-free framework provides a scalable, interpretable approach to genomic surveillance with direct applications to public health monitoring.", "AI": {"tldr": "The paper introduces an unsupervised method for viral variant detection in wastewater using enhanced VQ-VAE models, which achieves efficient variant discrimination without needing reference genomes or labeled data.", "motivation": "To address computational challenges in viral monitoring, especially in wastewater-based genomic surveillance that struggles with noise, low viral loads, and the lack of labeled annotations.", "method": "The paper utilizes VQ-VAE architecture extended with masked reconstruction pretraining and contrastive learning, analyzing k-mer tokenized sequences to detect viral variants without requiring reference genomes.", "result": "The method achieves 99.52% token-level accuracy, 56.33% exact sequence match rate, and improved clustering using contrastive fine-tuned embeddings, indicating its robustness and precision.", "conclusion": "This scalable and interpretable framework offers a novel and powerful approach to genomic surveillance, aiding public health monitoring without reliance on traditional computationally intensive techniques."}}
{"id": "2512.03874", "pdf": "https://arxiv.org/pdf/2512.03874", "abs": "https://arxiv.org/abs/2512.03874", "authors": ["Lei Zhang", "Diwen Zheng", "Kaixin Bai", "Zhenshan Bing", "Zoltan-Csaba Marton", "Zhaopeng Chen", "Alois Christian Knoll", "Jianwei Zhang"], "title": "OmniDexVLG: Learning Dexterous Grasp Generation from Vision Language Model-Guided Grasp Semantics, Taxonomy and Functional Affordance", "categories": ["cs.RO", "cs.LG"], "comment": "Project Website: https://sites.google.com/view/omnidexvlg, 16 pages", "summary": "Dexterous grasp generation aims to produce grasp poses that align with task requirements and human interpretable grasp semantics. However, achieving semantically controllable dexterous grasp synthesis remains highly challenging due to the lack of unified modeling of multiple semantic dimensions, including grasp taxonomy, contact semantics, and functional affordance. To address these limitations, we present OmniDexVLG, a multimodal, semantics aware grasp generation framework capable of producing structurally diverse and semantically coherent dexterous grasps under joint language and visual guidance. Our approach begins with OmniDexDataGen, a semantic rich dexterous grasp dataset generation pipeline that integrates grasp taxonomy guided configuration sampling, functional affordance contact point sampling, taxonomy aware differential force closure grasp sampling, and physics based optimization and validation, enabling systematic coverage of diverse grasp types. We further introduce OmniDexReasoner, a multimodal grasp type semantic reasoning module that leverages multi agent collaboration, retrieval augmented generation, and chain of thought reasoning to infer grasp related semantics and generate high quality annotations that align language instructions with task specific grasp intent. Building upon these components, we develop a unified Vision Language Grasping generation model that explicitly incorporates grasp taxonomy, contact structure, and functional affordance semantics, enabling fine grained control over grasp synthesis from natural language instructions. Extensive experiments in simulation and real world object grasping and ablation studies demonstrate that our method substantially outperforms state of the art approaches in terms of grasp diversity, contact semantic diversity, functional affordance diversity, and semantic consistency.", "AI": {"tldr": "OmniDexVLG is a framework for generating dexterous grasps that align with semantic and task-specific requirements using visual and language guidance.", "motivation": "Existing methods struggle with semantically controllable dexterous grasp generation due to the absence of unified modeling for grasp taxonomy, contact semantics, and functional affordance.", "method": "The paper introduces OmniDexVLG, which includes a data generation pipeline (OmniDexDataGen) for diverse grasp types, OmniDexReasoner for semantic reasoning, and a Vision Language Grasping model for synthesizing grasps guided by natural language instructions.", "result": "Experiments demonstrate significant improvements over state-of-the-art methods in grasp diversity, contact semantic diversity, functional affordance diversity, and semantic consistency.", "conclusion": "OmniDexVLG successfully integrates grasp taxonomy, contact semantics, and functional affordance for improved task-aligned grasp generation, showcasing its effectiveness in both simulations and real-world grasping scenarios."}}
{"id": "2512.03067", "pdf": "https://arxiv.org/pdf/2512.03067", "abs": "https://arxiv.org/abs/2512.03067", "authors": ["Difu Feng", "Qianqian Xu", "Zitai Wang", "Cong Hua", "Zhiyong Yang", "Qingming Huang"], "title": "Quantifying the Potential to Escape Filter Bubbles: A Behavior-Aware Measure via Contrastive Simulation", "categories": ["cs.SI", "cs.AI"], "comment": null, "summary": "Nowadays, recommendation systems have become crucial to online platforms, shaping user exposure by accurate preference modeling. However, such an exposure strategy can also reinforce users' existing preferences, leading to a notorious phenomenon named filter bubbles. Given its negative effects, such as group polarization, increasing attention has been paid to exploring reasonable measures to filter bubbles. However, most existing evaluation metrics simply measure the diversity of user exposure, failing to distinguish between algorithmic preference modeling and actual information confinement. In view of this, we introduce Bubble Escape Potential (BEP), a behavior-aware measure that quantifies how easily users can escape from filter bubbles. Specifically, BEP leverages a contrastive simulation framework that assigns different behavioral tendencies (e.g., positive vs. negative) to synthetic users and compares the induced exposure patterns. This design enables decoupling the effect of filter bubbles and preference modeling, allowing for more precise diagnosis of bubble severity. We conduct extensive experiments across multiple recommendation models to examine the relationship between predictive accuracy and bubble escape potential across different groups. To the best of our knowledge, our empirical results are the first to quantitatively validate the dilemma between preference modeling and filter bubbles. What's more, we observe a counter-intuitive phenomenon that mild random recommendations are ineffective in alleviating filter bubbles, which can offer a principled foundation for further work in this direction.", "AI": {"tldr": "The paper addresses the issue of filter bubbles in recommendation systems by introducing a new metric, Bubble Escape Potential (BEP), to measure how users can escape these bubbles.", "motivation": "The motivation of this paper lies in addressing the limitations of existing evaluation metrics for filter bubbles, which fail to distinguish between preference modeling and actual information confinement.", "method": "The authors propose a behavior-aware metric called Bubble Escape Potential (BEP) that uses a contrastive simulation framework to compare behavioral tendencies of synthetic users and their exposure patterns.", "result": "The study finds a dilemma between accurate preference modeling and filter bubble severity. Additionally, mild random recommendations are shown to be ineffective in alleviating filter bubbles.", "conclusion": "Bubble Escape Potential (BEP) is an effective tool for diagnosing filter bubble severity, opening opportunities for improving recommendation systems in future research."}}
{"id": "2512.03759", "pdf": "https://arxiv.org/pdf/2512.03759", "abs": "https://arxiv.org/abs/2512.03759", "authors": ["Jingyang Ou", "Jiaqi Han", "Minkai Xu", "Shaoxuan Xu", "Jianwen Xie", "Stefano Ermon", "Yi Wu", "Chongxuan Li"], "title": "Principled RL for Diffusion LLMs Emerges from a Sequence-Level Perspective", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Reinforcement Learning (RL) has proven highly effective for autoregressive language models, but adapting these methods to diffusion large language models (dLLMs) presents fundamental challenges. The core difficulty lies in likelihood approximation: while autoregressive models naturally provide token-level conditional probabilities essential for token-level RL objectives (e.g., GRPO), dLLMs generate sequences through iterative non-autoregressive denoising steps that lack this factorization. To address this fundamental mismatch, we propose ELBO-based Sequence-level Policy Optimization (ESPO), a principled RL framework that treats entire sequence generation as a single action and uses the ELBO as a tractable sequence-level likelihood proxy. Our method incorporates per-token normalization of importance ratios and robust KL-divergence estimation to ensure stable large-scale training. Extensive experiments on mathematical reasoning, coding, and planning tasks demonstrate that ESPO significantly outperforms token-level baselines, achieving dramatic improvements of 20-40 points on the Countdown task, while maintaining consistent gains on math and coding benchmarks. Our approach establishes sequence-level optimization as a principled and empirically effective paradigm for RL in dLLMs. Our code is available at https://github.com/ML-GSAI/ESPO.", "AI": {"tldr": "The paper introduces a reinforcement learning framework called ESPO that significantly improves performance in diffusion large language models (dLLMs) by using sequence-level optimization for stable and effective training.", "motivation": "Existing RL techniques developed for autoregressive models are not directly applicable to diffusion large language models due to the lack of token-level conditional probabilities in dLLMs. The paper aims to address this mismatch to enhance RL in dLLMs.", "method": "The authors propose ELBO-based Sequence-level Policy Optimization (ESPO) as an RL framework, treating whole sequence generation as a single action. It uses the ELBO as a sequence-level likelihood proxy and implements per-token normalization and robust KL-divergence estimation for stable training.", "result": "The ESPO framework achieves significant improvements of 20-40 points on the Countdown task and consistent gains on mathematical reasoning and coding benchmarks compared to token-level baselines.", "conclusion": "This research establishes sequence-level optimization as a both theoretically sound and empirically effective approach for reinforcement learning in dLLMs, opening up new pathways for advancing these models in various tasks."}}
{"id": "2512.03899", "pdf": "https://arxiv.org/pdf/2512.03899", "abs": "https://arxiv.org/abs/2512.03899", "authors": ["Janis Keck", "Lukas Silvester Barth", "Fatemeh", "Fahimi", "Parvaneh Joharinad", "J\u00fcrgen Jost"], "title": "Probabilistic Foundations of Fuzzy Simplicial Sets for Nonlinear Dimensionality Reduction", "categories": ["cs.LG", "math.AT", "stat.ML"], "comment": "47 pages (including appendix), 11 figures", "summary": "Fuzzy simplicial sets have become an object of interest in dimensionality reduction and manifold learning, most prominently through their role in UMAP. However, their definition through tools from algebraic topology without a clear probabilistic interpretation detaches them from commonly used theoretical frameworks in those areas. In this work we introduce a framework that explains fuzzy simplicial sets as marginals of probability measures on simplicial sets. In particular, this perspective shows that the fuzzy weights of UMAP arise from a generative model that samples Vietoris-Rips filtrations at random scales, yielding cumulative distribution functions of pairwise distances. More generally, the framework connects fuzzy simplicial sets to probabilistic models on the face poset, clarifies the relation between Kullback-Leibler divergence and fuzzy cross-entropy in this setting, and recovers standard t-norms and t-conorms via Boolean operations on the underlying simplicial sets. We then show how new embedding methods may be derived from this framework and illustrate this on an example where we generalize UMAP using \u010cech filtrations with triplet sampling. In summary, this probabilistic viewpoint provides a unified probabilistic theoretical foundation for fuzzy simplicial sets, clarifies the role of UMAP within this framework, and enables the systematic derivation of new dimensionality reduction methods.", "AI": {"tldr": "The authors propose a probabilistic framework to interpret fuzzy simplicial sets and their role in dimensionality reduction methods like UMAP. They link fuzzy weights to generative models and extend this framework to develop new embedding methods.", "motivation": "Current definitions of fuzzy simplicial sets in dimensionality reduction lack a probabilistic interpretation, which limits their integration with established theoretical frameworks.", "method": "The paper introduces a probabilistic framework, explaining fuzzy simplicial sets as marginals of probability measures on simplicial sets. It connects concepts like Vietoris-Rips filtrations and Boolean operations to a generative probabilistic model.", "result": "The study clarifies the theoretical foundation of fuzzy simplicial sets, bridges them with probabilistic models on simplicial sets, and establishes the basis for deriving new dimensionality reduction techniques.", "conclusion": "The probabilistic approach provides a unified foundation for understanding fuzzy simplicial sets, elucidates the theoretical grounding of UMAP, and facilitates the development of innovative methods for dimensionality reduction."}}
{"id": "2512.03445", "pdf": "https://arxiv.org/pdf/2512.03445", "abs": "https://arxiv.org/abs/2512.03445", "authors": ["Xieji Li", "Siyuan Yan", "Yingsheng Liu", "H. Peter Soyer", "Monika Janda", "Victoria Mar", "Zongyuan Ge"], "title": "Multi-Aspect Knowledge-Enhanced Medical Vision-Language Pretraining with Multi-Agent Data Generation", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages. Under Review", "summary": "Vision-language pretraining (VLP) has emerged as a powerful paradigm in medical image analysis, enabling representation learning from large-scale image-text pairs without relying on expensive manual annotations. However, existing methods often struggle with the noise inherent in web-collected data and the complexity of unstructured long medical texts. To address these challenges, we propose a novel VLP framework integrating a Multi-Agent data GENeration (MAGEN) system and Ontology-based Multi-Aspect Knowledge-Enhanced (O-MAKE) pretraining. First, MAGEN enhances data quality by synthesizing knowledge-enriched descriptions via a foundation model-assisted captioning and retrieval-based verification pipeline. Second, O-MAKE addresses the difficulty of learning from long, unstructured texts by decomposing them into distinct knowledge aspects. This facilitates fine-grained alignment at both global and patch levels, while explicitly modeling medical concept relationships through ontology-guided mechanisms. We validate our framework in the field of dermatology, where comprehensive experiments demonstrate the effectiveness of each component. Our approach achieves state-of-the-art zero-shot performance on disease classification and cross-modal retrieval tasks across eight datasets. Our code and the augmented dataset Derm1M-AgentAug, comprising over 400k skin-image-text pairs, will be released at https://github.com/SiyuanYan1/Derm1M.", "AI": {"tldr": "The paper proposes a new vision-language pretraining (VLP) framework using MAGEN and O-MAKE to address noise in data and complexity in medical text, achieving state-of-the-art results.", "motivation": "The paper aims to address the noise in web-collected medical data and the challenges of processing unstructured, lengthy medical texts in vision-language pretraining.", "method": "The authors introduced MAGEN to improve data quality via captioning and verification processes and O-MAKE to simplify and align complex medical text using ontology-guided mechanisms.", "result": "The framework showed state-of-the-art performance in zero-shot disease classification and cross-modal retrieval tasks on eight datasets.", "conclusion": "The proposed framework improves medical vision-language pretraining by handling data noise and text complexity, validated through robust dermatology experiments. The code and dataset are also publicly available."}}
{"id": "2512.03176", "pdf": "https://arxiv.org/pdf/2512.03176", "abs": "https://arxiv.org/abs/2512.03176", "authors": ["Anthony Liang", "Jonathan Berant", "Adam Fisch", "Abhimanyu Goyal", "Kalpesh Krishna", "Jacob Eisenstein"], "title": "Plantain: Plan-Answer Interleaved Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reasoning models often spend a significant amount of time thinking before they generate a visible response. In the meantime, they do not give the user any hints as to whether their reasoning is on the right track, and do not give the user any recourse to stop and correct them if their reasoning is flawed. This creates a frustrating, but unfortunately common, experience: the user's time is wasted while the model reasons from a false premise that could have easily been corrected. In contrast, human speakers typically perform lightweight, incremental grounding acts to ensure that participants in the conversation are on the same page; here we ask if language models can learn to leverage a similar type of behavior? With this motivation, we propose interleaved reasoning (IR), in which the model alternates between thinking and surfacing intermediate responses, as an alternative to the standard \"think-then-answer\" approach. By providing useful information to the user earlier, IR reduces perceived latency, the time a user waits for an initial output, without compromising the quality of the final response. We further introduce a specialization of interleaved reasoning, Plantain (Plan-Thought-Answer Interleaving), where the first intermediate response is an explicit, step-by-step plan for executing the task. This plan-first strategy allows for user intervention and early feedback for subsequent reasoning steps. We demonstrate that Plantain yields an ~6% improvement in pass@1 across several challenging math reasoning and coding benchmarks, while reducing time-to-first-response by over 60% relative to think-then-answer baselines.", "AI": {"tldr": "The paper introduces interleaved reasoning (IR), which allows language models to alternate between thinking and surfacing intermediate responses, improving response speed and quality. It also presents a method called Plantain for step-by-step planning and user feedback.", "motivation": "To address the issue where reasoning models waste user time by silently reasoning from flawed premises, lacking intermediate feedback or early correction.", "method": "The paper proposes interleaved reasoning (IR), where models alternate reasoning with intermediate outputs, and a specialized method termed Plantain that incorporates step-by-step planning for user feedback.", "result": "The study shows Plantain improves performance by ~6% on tasks and reduces user waiting time by over 60%, compared to traditional reasoning methods.", "conclusion": "Interleaved reasoning, particularly the Plantain approach, improves interaction by enabling early feedback and reducing latency, enhancing both user experience and result quality."}}
{"id": "2512.03886", "pdf": "https://arxiv.org/pdf/2512.03886", "abs": "https://arxiv.org/abs/2512.03886", "authors": ["Brais Fontan-Costas", "M. Diaz-Cacho", "Ruben Fernandez-Boullon", "Manuel Alonso-Carracedo", "Javier Perez-Robles"], "title": "A Modular Architecture Design for Autonomous Driving Racing in Controlled Environments", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "This paper presents an Autonomous System (AS) architecture for vehicles in a closed circuit. The AS performs precision tasks including computer vision for environment perception, positioning and mapping for accurate localization, path planning for optimal trajectory generation, and control for precise vehicle actuation. Each subsystem operates independently while connecting data through a cohesive pipeline architecture. The system implements a modular design that combines state-of-the-art technologies for real-time autonomous navigation in controlled environments.", "AI": {"tldr": "An Autonomous System architecture is developed for vehicles operating in closed circuits, utilizing modular subsystems for perception, localization, trajectory planning, and actuation.", "motivation": "To enable precise and efficient autonomous navigation for vehicles in controlled environments.", "method": "The paper proposes a modular pipeline architecture integrating state-of-the-art technologies for computer vision, positioning, path planning, and control.", "result": "The architecture facilitates real-time autonomous navigation in closed circuits.", "conclusion": "The system demonstrates the ability to execute precision tasks autonomously, showcasing its effectiveness in controlled vehicular environments."}}
{"id": "2512.03068", "pdf": "https://arxiv.org/pdf/2512.03068", "abs": "https://arxiv.org/abs/2512.03068", "authors": ["Nicoleta Tantalaki", "Sophia Vei", "Athena Vakali"], "title": "Echoes of AI Harms: A Human-LLM Synergistic Framework for Bias-Driven Harm Anticipation", "categories": ["cs.CY", "cs.AI"], "comment": "38 pages", "summary": "The growing influence of Artificial Intelligence (AI) systems on decision-making in critical domains has exposed their potential to cause significant harms, often rooted in biases embedded across the AI lifecycle. While existing frameworks and taxonomies document bias or harms in isolation, they rarely establish systematic links between specific bias types and the harms they cause, particularly within real-world sociotechnical contexts. Technical fixes proposed to address AI biases are ill-equipped to address them and are typically applied after a system has been developed or deployed, offering limited preventive value. We propose ECHO, a novel framework for proactive AI harm anticipation through the systematic mapping of AI bias types to harm outcomes across diverse stakeholder and domain contexts. ECHO follows a modular workflow encompassing stakeholder identification, vignette-based presentation of biased AI systems, and dual (human-LLM) harm annotation, integrated within ethical matrices for structured interpretation. This human-centered approach enables early-stage detection of bias-to-harm pathways, guiding AI design and governance decisions from the outset. We validate ECHO in two high-stakes domains (disease diagnosis and hiring), revealing domain-specific, bias-to-harm patterns and demonstrating ECHO's potential to support anticipatory governance of AI systems", "AI": {"tldr": "AI systems can cause significant harm due to inherent biases and current reactive approaches lack preventive value. The paper introduces ECHO, a framework for proactive identification and governance of AI bias-to-harm pathways before system deployment.", "motivation": "Biases embedded in AI systems across their lifecycle have negatively influenced decisions in crucial domains, and existing approaches lack systematic mapping between bias types and their resulting harms.", "method": "ECHO employs stakeholder identification, vignette-based biased system presentation, and dual annotation (human and LLM) within ethical matrices for proactive harm analysis across sociotechnical contexts.", "result": "ECHO identifies bias-to-harm patterns in domains like disease diagnosis and hiring, providing structured insights into potential harm outcomes and domain-specific governance needs.", "conclusion": "The framework facilitates anticipatory governance of AI systems by systematically mapping biases to harms, enhancing bias detection and guiding ethical AI design from the early stages."}}
{"id": "2512.03771", "pdf": "https://arxiv.org/pdf/2512.03771", "abs": "https://arxiv.org/abs/2512.03771", "authors": ["Itay Yona", "Amir Sarid", "Michael Karasik", "Yossi Gandelsman"], "title": "In-Context Representation Hijacking", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "comment": null, "summary": "We introduce \\textbf{Doublespeak}, a simple \\emph{in-context representation hijacking} attack against large language models (LLMs). The attack works by systematically replacing a harmful keyword (e.g., \\textit{bomb}) with a benign token (e.g., \\textit{carrot}) across multiple in-context examples, provided a prefix to a harmful request. We demonstrate that this substitution leads to the internal representation of the benign token converging toward that of the harmful one, effectively embedding the harmful semantics under a euphemism. As a result, superficially innocuous prompts (e.g., ``How to build a carrot?'') are internally interpreted as disallowed instructions (e.g., ``How to build a bomb?''), thereby bypassing the model's safety alignment. We use interpretability tools to show that this semantic overwrite emerges layer by layer, with benign meanings in early layers converging into harmful semantics in later ones. Doublespeak is optimization-free, broadly transferable across model families, and achieves strong success rates on closed-source and open-source systems, reaching 74\\% ASR on Llama-3.3-70B-Instruct with a single-sentence context override. Our findings highlight a new attack surface in the latent space of LLMs, revealing that current alignment strategies are insufficient and should instead operate at the representation level.", "AI": {"tldr": "The paper introduces the 'Doublespeak' attack on large language models (LLMs) by using euphemisms to hijack in-context representations, exposing vulnerabilities in alignment strategies.", "motivation": "To reveal the limitations of current safety alignment strategies in LLMs by exploring vulnerabilities in their latent representation space.", "method": "Systematically substitutes harmful keywords with benign tokens in contextual prompts, which leads to semantic hijacking and harmful meaning reinterpretation through representation manipulation.", "result": "The attack bypasses LLM's safety controls, reaching up to 74% success rate using a single-sentence override, applicable across various model families.", "conclusion": "LLMs require improved alignment strategies at the representation level to effectively mitigate latent space vulnerabilities exposed by 'Doublespeak' attacks."}}
{"id": "2512.04006", "pdf": "https://arxiv.org/pdf/2512.04006", "abs": "https://arxiv.org/abs/2512.04006", "authors": ["Connall Garrod", "Jonathan P. Keating", "Christos Thrampoulidis"], "title": "Diagonalizing the Softmax: Hadamard Initialization for Tractable Cross-Entropy Dynamics", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "Cross-entropy (CE) training loss dominates deep learning practice, yet existing theory often relies on simplifications, either replacing it with squared loss or restricting to convex models, that miss essential behavior. CE and squared loss generate fundamentally different dynamics, and convex linear models cannot capture the complexities of non-convex optimization. We provide an in-depth characterization of multi-class CE optimization dynamics beyond the convex regime by analyzing a canonical two-layer linear neural network with standard-basis vectors as inputs: the simplest non-convex extension for which the implicit bias remained unknown. This model coincides with the unconstrained features model used to study neural collapse, making our work the first to prove that gradient flow on CE converges to the neural collapse geometry. We construct an explicit Lyapunov function that establishes global convergence, despite the presence of spurious critical points in the non-convex landscape. A key insight underlying our analysis is an inconspicuous finding: Hadamard Initialization diagonalizes the softmax operator, freezing the singular vectors of the weight matrices and reducing the dynamics entirely to their singular values. This technique opens a pathway for analyzing CE training dynamics well beyond our specific setting considered here.", "AI": {"tldr": "The paper analyzes cross-entropy optimization dynamics beyond convex models, proving convergence to neural collapse geometry in a two-layer linear neural network.", "motivation": "Cross-entropy dominates deep learning practice, but its theoretical understanding in non-convex settings is limited compared to convex models and squared loss simplifications.", "method": "The authors analyze a canonical non-convex two-layer linear neural network with standard-basis inputs, using gradient flow, Lyapunov function construction, and Hadamard Initialization.", "result": "They prove that gradient flow with cross-entropy converges globally to neural collapse geometry, due to specific dynamics enabled by Hadamard Initialization.", "conclusion": "This work provides insights into non-convex optimization under cross-entropy loss and opens doors to broader analyses of deep learning loss functions in complex models."}}
{"id": "2512.03449", "pdf": "https://arxiv.org/pdf/2512.03449", "abs": "https://arxiv.org/abs/2512.03449", "authors": ["Tongxu Zhang"], "title": "LM-CartSeg: Automated Segmentation of Lateral and Medial Cartilage and Subchondral Bone for Radiomics Analysis", "categories": ["cs.CV"], "comment": null, "summary": "Background and Objective: Radiomics of knee MRI requires robust, anatomically meaningful regions of interest (ROIs) that jointly capture cartilage and subchondral bone. Most existing work relies on manual ROIs and rarely reports quality control (QC). We present LM-CartSeg, a fully automatic pipeline for cartilage/bone segmentation, geometric lateral/medial (L/M) compartmentalisation and radiomics analysis. Methods: Two 3D nnU-Net models were trained on SKM-TEA (138 knees) and OAIZIB-CM (404 knees). At test time, zero-shot predictions were fused and refined by simple geometric rules: connected-component cleaning, construction of 10 mm subchondral bone bands in physical space, and a data-driven tibial L/M split based on PCA and k-means. Segmentation was evaluated on an OAIZIB-CM test set (103 knees) and on SKI-10 (100 knees). QC used volume and thickness signatures. From 10 ROIs we extracted 4 650 non-shape radiomic features to study inter-compartment similarity, dependence on ROI size, and OA vs. non-OA classification on OAIZIB-CM Results: Post-processing improved macro ASSD on OAIZIB-CM from 2.63 to 0.36 mm and HD95 from 25.2 to 3.35 mm, with DSC 0.91; zero-shot DSC on SKI-10 was 0.80. The geometric L/M rule produced stable compartments across datasets, whereas a direct L/M nnU-Net showed domain-dependent side swaps. Only 6 to 12 percent of features per ROI were strongly correlated with volume or thickness. Radiomics-based models models restricted to size-linked features. Conclusions: LM-CartSeg yields automatic, QCd ROIs and radiomic features that carry discriminative information beyond simple morphometry, providing a practical foundation for multi-centre knee OA radiomics studies.", "AI": {"tldr": "The paper proposes LM-CartSeg, an automated pipeline for robust knee cartilage/bone segmentation, achieving high accuracy and enabling advanced radiomics analysis.", "motivation": "The study aims to address the need for robust and anatomically meaningful automated segmentation methods for knee MRI, as most existing approaches rely on manual input and lack quality control.", "method": "LM-CartSeg utilizes two trained 3D nnU-Net models and post-processing steps like geometric refinement, connected-component cleaning, subchondral bone band creation, and data-driven lateral/medial compartment splits.", "result": "The proposed pipeline significantly improved segmentation metrics (macro ASSD reduced to 0.36 mm, HD95 to 3.35 mm, DSC 0.91) and demonstrated robust compartmentalization across datasets.", "conclusion": "LM-CartSeg offers automatic and quality-controlled regions of interest for knee MRI, aiding in advanced radiomics analyses and supporting multi-center osteoarthritis research."}}
{"id": "2512.03187", "pdf": "https://arxiv.org/pdf/2512.03187", "abs": "https://arxiv.org/abs/2512.03187", "authors": ["Aashi Jindal"], "title": "Neighborhood density estimation using space-partitioning based hashing schemes", "categories": ["cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2011.03729", "summary": "This work introduces FiRE/FiRE.1, a novel sketching-based algorithm for anomaly detection to quickly identify rare cell sub-populations in large-scale single-cell RNA sequencing data. This method demonstrated superior performance against state-of-the-art techniques. Furthermore, the thesis proposes Enhash, a fast and resource-efficient ensemble learner that uses projection hashing to detect concept drift in streaming data, proving highly competitive in time and accuracy across various drift types.", "AI": {"tldr": "FiRE/FiRE.1 and Enhash are introduced for effective anomaly detection in single-cell RNA sequencing and concept drift detection.", "motivation": "There is a need for efficient and accurate methods to detect anomalies in large datasets like single-cell RNA sequencing and to monitor concept drift in streaming data.", "method": "FiRE/FiRE.1 uses sketching-based algorithms for identifying rare cell sub-populations, while Enhash employs projection hashing as an ensemble learner for drift detection.", "result": "Both methods showed high performance, with FiRE surpassing existing techniques in anomaly detection and Enhash demonstrating competitive accuracy and speed in drift detection.", "conclusion": "The proposed methods are effective tools for their respective applications, offering advancements in computational efficiency and detection performance."}}
{"id": "2512.03891", "pdf": "https://arxiv.org/pdf/2512.03891", "abs": "https://arxiv.org/abs/2512.03891", "authors": ["Ying-Kuan Tsai", "Yi-Ping Chen", "Vispi Karkaria", "Wei Chen"], "title": "Digital Twin-based Control Co-Design of Full Vehicle Active Suspensions via Deep Reinforcement Learning", "categories": ["cs.RO", "cs.LG"], "comment": "28 pages, 17 figures", "summary": "Active suspension systems are critical for enhancing vehicle comfort, safety, and stability, yet their performance is often limited by fixed hardware designs and control strategies that cannot adapt to uncertain and dynamic operating conditions. Recent advances in digital twins (DTs) and deep reinforcement learning (DRL) offer new opportunities for real-time, data-driven optimization across a vehicle's lifecycle. However, integrating these technologies into a unified framework remains an open challenge. This work presents a DT-based control co-design (CCD) framework for full-vehicle active suspensions using multi-generation design concepts. By integrating automatic differentiation into DRL, we jointly optimize physical suspension components and control policies under varying driver behaviors and environmental uncertainties. DRL also addresses the challenge of partial observability, where only limited states can be sensed and fed back to the controller, by learning optimal control actions directly from available sensor information. The framework incorporates model updating with quantile learning to capture data uncertainty, enabling real-time decision-making and adaptive learning from digital-physical interactions. The approach demonstrates personalized optimization of suspension systems under two distinct driving settings (mild and aggressive). Results show that the optimized systems achieve smoother trajectories and reduce control efforts by approximately 43% and 52% for mild and aggressive, respectively, while maintaining ride comfort and stability. Contributions include: developing a DT-enabled CCD framework integrating DRL and uncertainty-aware model updating for full-vehicle active suspensions, introducing a multi-generation design strategy for self-improving systems, and demonstrating personalized optimization of active suspension systems for distinct driver types.", "AI": {"tldr": "This study presents a digital twin-based control co-design framework using deep reinforcement learning for real-time optimization of active suspension systems under varying driver behaviors and uncertainties.", "motivation": "Fixed hardware designs and control strategies limit active suspension performance, particularly under uncertain and dynamic conditions. This paper aims to leverage digital twin and deep reinforcement learning technologies for improved adaptability and optimization.", "method": "The proposed framework integrates automatic differentiation into deep reinforcement learning, jointly optimizing physical suspension components and control policies. It incorporates model updating with quantile learning to handle uncertainty and adapts from digital-physical interactions.", "result": "The optimized suspension systems tailored to mild and aggressive driving styles achieved smoother trajectories while reducing control effort by up to 43% and 52%, respectively, without compromising comfort or stability.", "conclusion": "This work provides a novel framework combining digital twin technology, deep reinforcement learning, and uncertainty-aware updating, achieving personalized and efficient optimization of active suspension systems. It also introduces a methodology for continual self-improvement of such systems."}}
{"id": "2512.03803", "pdf": "https://arxiv.org/pdf/2512.03803", "abs": "https://arxiv.org/abs/2512.03803", "authors": ["Huey Sun", "Anabel Yong", "Lorenzo Gilly", "Felipe Jin"], "title": "Enhancing Instruction-Following Capabilities in Seq2Seq Models: DoLA Adaptations for T5", "categories": ["cs.CL"], "comment": null, "summary": "Contrastive decoding is a lightweight and effective inference-time method that improves the quality of text generation in Large Language Models. However, algorithms such as DoLa (Decoding by Contrastive Layers) have only been implemented in decoder-only architectures and studied for their impact on improving factuality. This work adapts DoLa for the T5 and FLAN-T5 model families and evaluates its impact on the models' instruction following capabilities, which to our knowledge is the first implementation of a contrastive decoding strategy in an encoder-decoder architecture. Our results show that DoLa improves the faithfulness of text generation for certain categories of tasks and harms others. To understand these results, we present a layer-by-layer analysis of logit evolution in a FLAN-T5 model to quantify DoLa's impact on token output probabilities.", "AI": {"tldr": "This paper adapts the contrastive decoding method, DoLa, for encoder-decoder architectures like T5 and FLAN-T5, analyzing its effects on instruction-following tasks and token probabilities.", "motivation": "To improve the faithfulness and quality of text generation in encoder-decoder language models by adapting a contrastive decoding strategy, previously only tested in decoder-only models.", "method": "The DoLa (Decoding by Contrastive Layers) approach was modified to work with T5 and FLAN-T5 models, and its influence on improving instruction-following tasks and text generation was evaluated with layer-wise logit analysis.", "result": "DoLa improved text generation faithfulness for some task categories while negatively affecting others, particularly in instruction-following tasks.", "conclusion": "Applying the DoLa method in encoder-decoder models yields mixed results, enhancing specific cases' faithfulness but showing room for further refinement for consistent improvements."}}
{"id": "2512.03450", "pdf": "https://arxiv.org/pdf/2512.03450", "abs": "https://arxiv.org/abs/2512.03450", "authors": ["Rhys Newbury", "Juyan Zhang", "Tin Tran", "Hanna Kurniawati", "Dana Kuli\u0107"], "title": "KeyPointDiffuser: Unsupervised 3D Keypoint Learning via Latent Diffusion Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Understanding and representing the structure of 3D objects in an unsupervised manner remains a core challenge in computer vision and graphics. Most existing unsupervised keypoint methods are not designed for unconditional generative settings, restricting their use in modern 3D generative pipelines; our formulation explicitly bridges this gap. We present an unsupervised framework for learning spatially structured 3D keypoints from point cloud data. These keypoints serve as a compact and interpretable representation that conditions an Elucidated Diffusion Model (EDM) to reconstruct the full shape. The learned keypoints exhibit repeatable spatial structure across object instances and support smooth interpolation in keypoint space, indicating that they capture geometric variation. Our method achieves strong performance across diverse object categories, yielding a 6 percentage-point improvement in keypoint consistency compared to prior approaches.", "AI": {"tldr": "This paper introduces an unsupervised framework for learning 3D keypoints from point cloud data to improve generative 3D object models.", "motivation": "To address the challenge of unsupervised representation of 3D object structures and enable their use in generative pipelines.", "method": "An unsupervised framework that learns spatially structured 3D keypoints, and incorporates them into an Elucidated Diffusion Model (EDM) for full shape reconstruction.", "result": "The framework demonstrates improved consistency of keypoints, with a 6 percentage-point improvement compared to prior methods.", "conclusion": "The learned keypoints effectively capture geometric variation and support structured generative 3D modeling, advancing computer vision and graphics fields."}}
{"id": "2512.03204", "pdf": "https://arxiv.org/pdf/2512.03204", "abs": "https://arxiv.org/abs/2512.03204", "authors": ["Douglas Aberdeen", "Jonathan Baxter"], "title": "Scaling Internal-State Policy-Gradient Methods for POMDPs", "categories": ["cs.LG"], "comment": null, "summary": "Policy-gradient methods have received increased attention recently as a mechanism for learning to act in partially observable environments. They have shown promise for problems admitting memoryless policies but have been less successful when memory is required. In this paper we develop several improved algorithms for learning policies with memory in an infinite-horizon setting -- directly when a known model of the environment is available, and via simulation otherwise. We compare these algorithms on some large POMDPs, including noisy robot navigation and multi-agent problems.", "AI": {"tldr": "The paper proposes advanced algorithms to improve policy-gradient methods for partially observable environments requiring memory.", "motivation": "To address the limitations of policy-gradient methods in learning effective policies for environments that require memory, particularly in infinite-horizon settings.", "method": "A set of improved algorithms were developed to enable learning policies with memory, applicable with or without a model of the environment.", "result": "The comparison of these algorithms was conducted on large POMDPs, such as noisy robot navigation and multi-agent problems, showcasing their efficacy.", "conclusion": "The proposed algorithms represent a significant advancement for policy-gradient methods, particularly where memory is required for decision-making."}}
{"id": "2512.03911", "pdf": "https://arxiv.org/pdf/2512.03911", "abs": "https://arxiv.org/abs/2512.03911", "authors": ["Kenneth Stewart", "Roxana Leontie", "Samantha Chapin", "Joe Hays", "Sumit Bam Shrestha", "Carl Glen Henshaw"], "title": "Autonomous Reinforcement Learning Robot Control with Intel's Loihi 2 Neuromorphic Hardware", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Submitted for review at NICE 2026 (Neuro-Inspired Computational Elements) conference", "summary": "We present an end-to-end pipeline for deploying reinforcement learning (RL) trained Artificial Neural Networks (ANNs) on neuromorphic hardware by converting them into spiking Sigma-Delta Neural Networks (SDNNs). We demonstrate that an ANN policy trained entirely in simulation can be transformed into an SDNN compatible with Intel's Loihi 2 architecture, enabling low-latency and energy-efficient inference. As a test case, we use an RL policy for controlling the Astrobee free-flying robot, similar to a previously hardware in space-validated controller. The policy, trained with Rectified Linear Units (ReLUs), is converted to an SDNN and deployed on Intel's Loihi 2, then evaluated in NVIDIA's Omniverse Isaac Lab simulation environment for closed-loop control of Astrobee's motion. We compare execution performance between GPU and Loihi 2. The results highlight the feasibility of using neuromorphic platforms for robotic control and establish a pathway toward energy-efficient, real-time neuromorphic computation in future space and terrestrial robotics applications.", "AI": {"tldr": "This paper proposes a method to deploy RL-trained ANNs on neuromorphic hardware by converting them into spiking SDNNs, showcasing feasibility for energy-efficient robotic control.", "motivation": "To enhance energy efficiency and real-time computation in robotics using neuromorphic hardware for deployment of RL-trained policies.", "method": "ANNs trained in simulation with RL are converted into SDNNs for compatibility with Intel's Loihi 2 neuromorphic hardware. Performance was evaluated for robotic control in a simulation environment.", "result": "The converted SDNNs successfully controlled a robotic system (Astrobee) in simulation, demonstrating better energy and computational efficiency compared to GPUs.", "conclusion": "Neuromorphic hardware like Loihi 2 can provide efficient computational pathways for real-time and energy-efficient robotics applications in diverse environments such as space."}}
{"id": "2512.03818", "pdf": "https://arxiv.org/pdf/2512.03818", "abs": "https://arxiv.org/abs/2512.03818", "authors": ["Kylie L. Anglin", "Stephanie Milan", "Brittney Hernandez", "Claudia Ventura"], "title": "Improving Alignment Between Human and Machine Codes: An Empirical Assessment of Prompt Engineering for Construct Identification in Psychology", "categories": ["cs.CL"], "comment": "22 pages, 2 figures", "summary": "Due to their architecture and vast pre-training data, large language models (LLMs) demonstrate strong text classification performance. However, LLM output - here, the category assigned to a text - depends heavily on the wording of the prompt. While literature on prompt engineering is expanding, few studies focus on classification tasks, and even fewer address domains like psychology, where constructs have precise, theory-driven definitions that may not be well represented in pre-training data. We present an empirical framework for optimizing LLM performance for identifying constructs in texts via prompt engineering. We experimentally evaluate five prompting strategies --codebook-guided empirical prompt selection, automatic prompt engineering, persona prompting, chain-of-thought reasoning, and explanatory prompting - with zero-shot and few-shot classification. We find that persona, chain-of-thought, and explanations do not fully address performance loss accompanying a badly worded prompt. Instead, the most influential features of a prompt are the construct definition, task framing, and, to a lesser extent, the examples provided. Across three constructs and two models, the classifications most aligned with expert judgments resulted from a few-shot prompt combining codebook-guided empirical prompt selection with automatic prompt engineering. Based on our findings, we recommend that researchers generate and evaluate as many prompt variants as feasible, whether human-crafted, automatically generated, or ideally both, and select prompts and examples based on empirical performance in a training dataset, validating the final approach in a holdout set. This procedure offers a practical, systematic, and theory-driven method for optimizing LLM prompts in settings where alignment with expert judgment is critical.", "AI": {"tldr": "Large language models' text classification performance heavily depends on prompt wording, particularly in precision-oriented fields like psychology. The paper explores strategies for prompt optimization, finding that combining human-crafted and automated approaches yields better performance.", "motivation": "To address the challenge of optimizing large language model text classification performance, especially in precise domains like psychology, where theory-driven definitions may not align well with pre-training data.", "method": "The paper experimentally evaluates five prompting strategies (codebook-guided prompt selection, automatic prompt engineering, persona prompting, chain-of-thought reasoning, and explanatory prompting) with zero-shot and few-shot classification. It assesses prompt influence features like task framing and construct definitions.", "result": "Results indicate that persona, chain-of-thought reasoning, and explanatory prompting strategies do not fully resolve performance loss from poorly worded prompts. Best results came from few-shot prompts combining codebook-guided and automatic approaches to align outputs with expert judgments.", "conclusion": "Researchers should iteratively generate, test, and validate human-crafted and automated prompt variants, prioritizing empirical performance in alignment with expert judgment, especially in settings requiring precision and theory-drive outputs."}}
{"id": "2512.03451", "pdf": "https://arxiv.org/pdf/2512.03451", "abs": "https://arxiv.org/abs/2512.03451", "authors": ["Zhiye Song", "Steve Dai", "Ben Keller", "Brucek Khailany"], "title": "GalaxyDiT: Efficient Video Generation with Guidance Alignment and Adaptive Proxy in Diffusion Transformers", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Diffusion models have revolutionized video generation, becoming essential tools in creative content generation and physical simulation. Transformer-based architectures (DiTs) and classifier-free guidance (CFG) are two cornerstones of this success, enabling strong prompt adherence and realistic video quality. Despite their versatility and superior performance, these models require intensive computation. Each video generation requires dozens of iterative steps, and CFG doubles the required compute. This inefficiency hinders broader adoption in downstream applications.\n  We introduce GalaxyDiT, a training-free method to accelerate video generation with guidance alignment and systematic proxy selection for reuse metrics. Through rank-order correlation analysis, our technique identifies the optimal proxy for each video model, across model families and parameter scales, thereby ensuring optimal computational reuse. We achieve $1.87\\times$ and $2.37\\times$ speedup on Wan2.1-1.3B and Wan2.1-14B with only 0.97% and 0.72% drops on the VBench-2.0 benchmark. At high speedup rates, our approach maintains superior fidelity to the base model, exceeding prior state-of-the-art approaches by 5 to 10 dB in peak signal-to-noise ratio (PSNR).", "AI": {"tldr": "GalaxyDiT is introduced as a training-free method to enhance video generation efficiency, providing significant speedups while preserving model fidelity.", "motivation": "Video generation through diffusion models is computationally expensive, limiting wider adoption despite their high quality and versatility.", "method": "GalaxyDiT uses guidance alignment and systematic proxy selection to optimize computational efficiency, leveraging rank-order correlation analysis to identify optimal reuse metrics.", "result": "The method achieves substantial speedups ($1.87\\times$ and $2.37\\times$) on large-scale models with minimal drops in benchmark performance, while maintaining high fidelity and surpassing prior approaches in PSNR.", "conclusion": "GalaxyDiT provides an effective and efficient solution to computational barriers in video generation, supporting broader adoption and improved model performance."}}
{"id": "2512.03211", "pdf": "https://arxiv.org/pdf/2512.03211", "abs": "https://arxiv.org/abs/2512.03211", "authors": ["Nigel Tao", "Jonathan Baxter", "Lex Weaver"], "title": "A Multi-Agent, Policy-Gradient approach to Network Routing", "categories": ["cs.LG", "cs.NI"], "comment": null, "summary": "Network routing is a distributed decision problem which naturally admits numerical performance measures, such as the average time for a packet to travel from source to destination. OLPOMDP, a policy-gradient reinforcement learning algorithm, was successfully applied to simulated network routing under a number of network models. Multiple distributed agents (routers) learned co-operative behavior without explicit inter-agent communication, and they avoided behavior which was individually desirable, but detrimental to the group's overall performance. Furthermore, shaping the reward signal by explicitly penalizing certain patterns of sub-optimal behavior was found to dramatically improve the convergence rate.", "AI": {"tldr": "The paper discusses using the OLPOMDP reinforcement learning algorithm for improving network routing efficiency, focusing on cooperative agent behavior.", "motivation": "Improving network routing efficiency through distributed multi-agent cooperation.", "method": "Application of the OLPOMDP policy-gradient reinforcement learning algorithm for training multiple distributed agents to optimize routing.", "result": "Agents learned cooperative behavior while avoiding individually beneficial actions that harmed group performance. Reward shaping further improved convergence rates.", "conclusion": "OLPOMDP effectively enhances routing performance by fostering cooperative behavior among agents and leveraging reward shaping techniques."}}
{"id": "2512.03913", "pdf": "https://arxiv.org/pdf/2512.03913", "abs": "https://arxiv.org/abs/2512.03913", "authors": ["Jeongeun Park", "Jihwan Yoon", "Byungwoo Jeon", "Juhan Park", "Jinwoo Shin", "Namhoon Cho", "Kyungjae Lee", "Sangdoo Yun", "Sungjoon Choi"], "title": "Hierarchical Vision Language Action Model Using Success and Failure Demonstrations", "categories": ["cs.RO", "cs.AI"], "comment": "https://vine-vla.github.io/", "summary": "Prior Vision-Language-Action (VLA) models are typically trained on teleoperated successful demonstrations, while discarding numerous failed attempts that occur naturally during data collection. However, these failures encode where and how policies can be fragile, information that can be exploited to improve robustness. We address this problem by leveraging mixed-quality datasets to learn failure-aware reasoning at planning time. We introduce VINE, a hierarchical vision-language-action model that separates high-level reasoning (System 2) from low-level control (System 1) under a hierarchical reinforcement learning formalism, making failures usable as a structured learning signal rather than noisy supervision. System 2 performs feasibility-guided tree search over a 2D scene-graph abstraction: it proposes subgoal transitions, predicts success probabilities from both successes and failures, and prunes brittle branches before execution, effectively casting plan evaluation as feasibility scoring. The selected subgoal sequence is then passed to System 1, which executes low-level actions without modifying the agent's core skills. Trained entirely from offline teleoperation data, VINE integrates negative experience directly into the decision loop. Across challenging manipulation tasks, this approach consistently improves success rates and robustness, demonstrating that failure data is an essential resource for converting the broad competence of VLAs into robust execution.", "AI": {"tldr": "This paper introduces VINE, a model that uses both successful and failed experiences in datasets to improve decision-making and robustness in Vision-Language-Action tasks.", "motivation": "Current Vision-Language-Action models neglect the information within failed demonstrations, which could reveal weaknesses in policies and enhance robustness.", "method": "The proposed VINE model uses a hierarchical structure where high-level reasoning learns from both successes and failures for feasibility-guided tree search. Failures are used as structured learning signals during planning.", "result": "VINE improves success rates and robustness in manipulation tasks by leveraging failure data to enhance decision-making.", "conclusion": "Failure data is key to strengthening the execution of broad competencies in Vision-Language-Action tasks, highlighting its utility in improving robustness and success rates."}}
{"id": "2512.03838", "pdf": "https://arxiv.org/pdf/2512.03838", "abs": "https://arxiv.org/abs/2512.03838", "authors": ["Michael Staniek", "Artem Sokolov", "Stefan Riezler"], "title": "Training and Evaluation of Guideline-Based Medical Reasoning in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Machine learning for early prediction in medicine has recently shown breakthrough performance, however, the focus on improving prediction accuracy has led to a neglect of faithful explanations that are required to gain the trust of medical practitioners. The goal of this paper is to teach LLMs to follow medical consensus guidelines step-by-step in their reasoning and prediction process. Since consensus guidelines are ubiquitous in medicine, instantiations of verbalized medical inference rules to electronic health records provide data for fine-tuning LLMs to learn consensus rules and possible exceptions thereof for many medical areas. Consensus rules also enable an automatic evaluation of the model's inference process regarding its derivation correctness (evaluating correct and faithful deduction of a conclusion from given premises) and value correctness (comparing predicted values against real-world measurements). We exemplify our work using the complex Sepsis-3 consensus definition. Our experiments show that small fine-tuned models outperform one-shot learning of considerably larger LLMs that are prompted with the explicit definition and models that are trained on medical texts including consensus definitions. Since fine-tuning on verbalized rule instantiations of a specific medical area yields nearly perfect derivation correctness for rules (and exceptions) on unseen patient data in that area, the bottleneck for early prediction is not out-of-distribution generalization, but the orthogonal problem of generalization into the future by forecasting sparsely and irregularly sampled clinical variables. We show that the latter results can be improved by integrating the output representations of a time series forecasting model with the LLM in a multimodal setup.", "AI": {"tldr": "This paper emphasizes improving trust in medical predictions by teaching large language models (LLMs) to follow step-by-step medical consensus guidelines, rather than focusing solely on accuracy.", "motivation": "The authors aim to address the lack of faithful explanations in medical predictions made by machine learning models, as trustworthy models are essential for gaining the confidence of medical professionals.", "method": "The authors fine-tuned LLMs on instantiations of verbalized medical inference rules based on electronic health records, allowing the models to learn consensus rules and evaluate both derivation correctness and value correctness.", "result": "Experiments show fine-tuned small models outperform larger LLMs on predicting Sepsis-3 definitions. They also achieve high derivation correctness but identify forecasting clinical variables as the main bottleneck for early prediction.", "conclusion": "Integrating time series forecasting models with LLMs in a multimodal setup improves future generalization, highlighting a pathway to enhance predictive medical models' credibility and accuracy in clinical contexts."}}
{"id": "2512.03453", "pdf": "https://arxiv.org/pdf/2512.03453", "abs": "https://arxiv.org/abs/2512.03453", "authors": ["Yunpeng Bai", "Shaoheng Fang", "Chaohui Yu", "Fan Wang", "Qixing Huang"], "title": "GeoVideo: Introducing Geometric Regularization into Video Generation Model", "categories": ["cs.CV"], "comment": "Project Page: https://geovideo.github.io/GeoVideo/", "summary": "Recent advances in video generation have enabled the synthesis of high-quality and visually realistic clips using diffusion transformer models. However, most existing approaches operate purely in the 2D pixel space and lack explicit mechanisms for modeling 3D structures, often resulting in temporally inconsistent geometries, implausible motions, and structural artifacts. In this work, we introduce geometric regularization losses into video generation by augmenting latent diffusion models with per-frame depth prediction. We adopted depth as the geometric representation because of the great progress in depth prediction and its compatibility with image-based latent encoders. Specifically, to enforce structural consistency over time, we propose a multi-view geometric loss that aligns the predicted depth maps across frames within a shared 3D coordinate system. Our method bridges the gap between appearance generation and 3D structure modeling, leading to improved spatio-temporal coherence, shape consistency, and physical plausibility. Experiments across multiple datasets show that our approach produces significantly more stable and geometrically consistent results than existing baselines.", "AI": {"tldr": "The paper introduces geometric regularization using depth prediction for video generation, improving temporal consistency and physical plausibility of 3D structures.", "motivation": "Existing video generation models often lack mechanisms for 3D structural modeling, leading to artifacts and temporal inconsistencies in generated clips.", "method": "The authors augmented latent diffusion models with per-frame depth prediction and proposed a multi-view geometric loss to align depth maps across frames within a 3D coordinate system.", "result": "The approach produces more stable, geometrically consistent, and spatio-temporally coherent video results compared to other baselines, as validated on multiple datasets.", "conclusion": "Incorporating geometric regularization with depth prediction reconciles appearance and structure modeling, leading to better geometric and temporal consistency in video generation."}}
{"id": "2512.03219", "pdf": "https://arxiv.org/pdf/2512.03219", "abs": "https://arxiv.org/abs/2512.03219", "authors": ["Andrea Burns", "Lauren Harrell", "Bart van Merri\u00ebnboer", "Vincent Dumoulin", "Jenny Hamer", "Tom Denton"], "title": "Perch 2.0 transfers 'whale' to underwater tasks", "categories": ["cs.LG"], "comment": "8 pages, 3 figures, 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: AI for Non-Human Animal Communication", "summary": "Perch 2.0 is a supervised bioacoustics foundation model pretrained on 14,597 species, including birds, mammals, amphibians, and insects, and has state-of-the-art performance on multiple benchmarks. Given that Perch 2.0 includes almost no marine mammal audio or classes in the training data, we evaluate Perch 2.0 performance on marine mammal and underwater audio tasks through few-shot transfer learning. We perform linear probing with the embeddings generated from this foundation model and compare performance to other pretrained bioacoustics models. In particular, we compare Perch 2.0 with previous multispecies whale, Perch 1.0, SurfPerch, AVES-bio, BirdAVES, and Birdnet V2.3 models, which have open-source tools for transfer-learning and agile modeling. We show that the embeddings from the Perch 2.0 model have consistently high performance for few-shot transfer learning, generally outperforming alternative embedding models on the majority of tasks, and thus is recommended when developing new linear classifiers for marine mammal classification with few labeled examples.", "AI": {"tldr": "Perch 2.0, a supervised bioacoustics model pretrained on 14,597 species, shows strong performance in marine mammal and underwater audio tasks using few-shot transfer learning, outperforming alternative models despite having limited marine data in training.", "motivation": "To evaluate Perch 2.0's applicability in new domains, such as marine mammal audio analysis, and to validate its robustness in transfer learning scenarios given its minimal marine data.", "method": "Perch 2.0's embeddings were assessed through linear probing for marine mammal tasks. Its performance was compared to alternative bioacoustics models like Perch 1.0, SurfPerch, AVES-bio, and others using few-shot learning setups.", "result": "The study demonstrated that Perch 2.0 outperformed other models in marine mammal classification tasks, proving effective for few-shot transfer learning scenarios.", "conclusion": "Perch 2.0 is a robust candidate for tasks like marine mammal classification with limited labeled data, outperforming existing models and showcasing its transfer learning potential."}}
{"id": "2512.03936", "pdf": "https://arxiv.org/pdf/2512.03936", "abs": "https://arxiv.org/abs/2512.03936", "authors": ["Aron Distelzweig", "Yiwei Wang", "Faris Janjo\u0161", "Marcel Hallgarten", "Mihai Dobre", "Alexander Langmann", "Joschka Boedecker", "Johannes Betz"], "title": "Driving is a Game: Combining Planning and Prediction with Bayesian Iterative Best Response", "categories": ["cs.RO"], "comment": null, "summary": "Autonomous driving planning systems perform nearly perfectly in routine scenarios using lightweight, rule-based methods but still struggle in dense urban traffic, where lane changes and merges require anticipating and influencing other agents. Modern motion predictors offer highly accurate forecasts, yet their integration into planning is mostly rudimental: discarding unsafe plans. Similarly, end-to-end models offer a one-way integration that avoids the challenges of joint prediction and planning modeling under uncertainty. In contrast, game-theoretic formulations offer a principled alternative but have seen limited adoption in autonomous driving. We present Bayesian Iterative Best Response (BIBeR), a framework that unifies motion prediction and game-theoretic planning into a single interaction-aware process. BIBeR is the first to integrate a state-of-the-art predictor into an Iterative Best Response (IBR) loop, repeatedly refining the strategies of the ego vehicle and surrounding agents. This repeated best-response process approximates a Nash equilibrium, enabling bidirectional adaptation where the ego both reacts to and shapes the behavior of others. In addition, our proposed Bayesian confidence estimation quantifies prediction reliability and modulates update strength, more conservative under low confidence and more decisive under high confidence. BIBeR is compatible with modern predictors and planners, combining the transparency of structured planning with the flexibility of learned models. Experiments show that BIBeR achieves an 11% improvement over state-of-the-art planners on highly interactive interPlan lane-change scenarios, while also outperforming existing approaches on standard nuPlan benchmarks.", "AI": {"tldr": "BIBeR introduces a unified framework for motion prediction and game-theoretic planning in autonomous driving to handle dense urban traffic effectively by approximating a Nash equilibrium and integrating confidence estimations.", "motivation": "Despite current planning systems working well in routine driving, they struggle in dense urban traffic due to the complexity of predicting and influencing other agents' behavior. There is also limited integration between modern predictors, end-to-end models, and game-theoretic approaches in these systems.", "method": "The BIBeR framework unifies motion prediction and game-theoretic planning by embedding a state-of-the-art predictor within an Iterative Best Response loop. This process repeatedly adjusts the strategies of both the autonomous vehicle and surrounding agents to reach a Nash equilibrium. Additionally, it incorporates a Bayesian confidence estimation that adjusts the update mechanism based on prediction reliability.", "result": "BIBeR achieves an 11% improvement over state-of-the-art planners in challenging lane-change scenarios and surpasses existing approaches in standard nuPlan benchmarks.", "conclusion": "BIBeR integrates structured planning and learned models to enable effective interaction-aware driving in dense traffic by combining prediction accuracy, bidirectional influence, and adaptive reliability estimation. It shows significant performance gains over traditional approaches."}}
{"id": "2512.03073", "pdf": "https://arxiv.org/pdf/2512.03073", "abs": "https://arxiv.org/abs/2512.03073", "authors": ["Shayne Longpre", "Christopher Akiki", "Campbell Lund", "Atharva Kulkarni", "Emily Chen", "Irene Solaiman", "Avijit Ghosh", "Yacine Jernite", "Lucie-Aim\u00e9e Kaffee"], "title": "Economies of Open Intelligence: Tracing Power & Participation in the Model Ecosystem", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Since 2019, the Hugging Face Model Hub has been the primary global platform for sharing open weight AI models. By releasing a dataset of the complete history of weekly model downloads (June 2020-August 2025) alongside model metadata, we provide the most rigorous examination to-date of concentration dynamics and evolving characteristics in the open model economy. Our analysis spans 851,000 models, over 200 aggregated attributes per model, and 2.2B downloads. We document a fundamental rebalancing of economic power: US open-weight industry dominance by Google, Meta, and OpenAI has declined sharply in favor of unaffiliated developers, community organizations, and, as of 2025, Chinese industry, with DeepSeek and Qwen models potentially heralding a new consolidation of market power. We identify statistically significant shifts in model properties, a 17X increase in average model size, rapid growth in multimodal generation (3.4X), quantization (5X), and mixture-of-experts architectures (7X), alongside concerning declines in data transparency, with open weights models surpassing truly open source models for the first time in 2025. We expose a new layer of developer intermediaries that has emerged, focused on quantizing and adapting base models for both efficiency and artistic expression. To enable continued research and oversight, we release the complete dataset with an interactive dashboard for real-time monitoring of concentration dynamics and evolving properties in the open model economy.", "AI": {"tldr": "The paper analyzes Hugging Face Model Hub data (2020-2025), documenting a shift in AI model development power and key trends like model size increase, multimodality growth, and declining data transparency. It highlights changes in industry dominance and releases a comprehensive dataset for further study.", "motivation": "The motivation is to assess dynamics in the open AI model ecosystem, focusing on power shifts, feature evolution, and transparency, while providing data for monitoring and research.", "method": "The authors analyzed 851,000 AI models, model attributes, and 2.2B downloads from Hugging Face, tracking trends and identifying industry changes through longitudinal dataset analysis.", "result": "Key findings include the decline of US industry dominance, the rise of Chinese developers, significant increases in model sizes and advanced architectures, as well as declines in data transparency.", "conclusion": "There is a rebalancing in AI model development power and growing innovation in model design, but transparency is diminishing. The release of the dataset fosters further research and oversight into these trends."}}
{"id": "2512.03870", "pdf": "https://arxiv.org/pdf/2512.03870", "abs": "https://arxiv.org/abs/2512.03870", "authors": ["Hongzhan Lin", "Zhiqi Bai", "Xinmiao Zhang", "Sen Yang", "Xiang Li", "Siran Yang", "Yunlong Xu", "Jiaheng Liu", "Yongchi Zhao", "Jiamang Wang", "Yuchi Xu", "Wenbo Su", "Bo Zheng"], "title": "Reconstructing KV Caches with Cross-layer Fusion For Enhanced Transformers", "categories": ["cs.CL"], "comment": "under review", "summary": "Transformer decoders have achieved strong results across tasks, but the memory required for the KV cache becomes prohibitive at long sequence lengths. Although Cross-layer KV Cache sharing (e.g., YOCO, CLA) offers a path to mitigate KV Cache bottleneck, it typically underperforms within-layer methods like GQA. To understand the root cause, we investigate the information flow of keys and values of the top-layers. Our preliminary reveals a clear distribution: values are predominantly derived from the bottom layer, while keys draw more information from both bottom and middle layers. Building upon this, we propose FusedKV, whose top-layer KV caches are a learnable fusion of the most informative ones from the bottom and middle layers. This fusion operates directly on post-RoPE keys, preserving relative positional information without the computational cost of re-applying rotary embeddings. To further improve efficiency, we propose FusedKV-Lite, an cross-layer sharing approach, where top-layer KV caches are directly derived from the bottom-layer values and the middle-layer keys. Compared to FusedKV, FusedKV-Lite reduces I/O overhead at the cost of a slight increase in perplexity. In experiments on LLMs ranging from 332M to 4B parameters, our proposed method reduce 50\\% cache memory while achieving lower validation perplexity than the standard Transformer decoder, establishing it as a memory-efficient, high-performance architectural alternative.", "AI": {"tldr": "The paper addresses the memory challenges of Transformer decoders by introducing FusedKV, a method that intelligently fuses KV caches from different layers, halving memory while improving performance.", "motivation": "Managing memory in Transformer decoders is difficult, especially with KV cache requirements at long sequence lengths. Previous methods (e.g., YOCO, CLA) underperform within-layer techniques, showing the need for a better approach.", "method": "The paper introduces FusedKV, which fuses keys and values from the most informative layers to optimize memory and performance. It also introduces FusedKV-Lite as a more efficient alternative that reduces I/O overhead.", "result": "Experiments on LLMs with 332M-4B parameters show a 50% reduction in cache memory usage and lower perplexity compared to the standard Transformer decoder.", "conclusion": "FusedKV provides a memory-efficient and high-performing alternative for managing KV caches in Transformer decoders, maintaining relative positional encoding information while improving efficiency."}}
{"id": "2512.03454", "pdf": "https://arxiv.org/pdf/2512.03454", "abs": "https://arxiv.org/abs/2512.03454", "authors": ["Haicheng Liao", "Huanming Shen", "Bonan Wang", "Yongkang Li", "Yihong Tang", "Chengyue Wang", "Dingyi Zhuang", "Kehua Chen", "Hai Yang", "Chengzhong Xu", "Zhenning Li"], "title": "Think Before You Drive: World Model-Inspired Multimodal Grounding for Autonomous Vehicles", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Interpreting natural-language commands to localize target objects is critical for autonomous driving (AD). Existing visual grounding (VG) methods for autonomous vehicles (AVs) typically struggle with ambiguous, context-dependent instructions, as they lack reasoning over 3D spatial relations and anticipated scene evolution. Grounded in the principles of world models, we propose ThinkDeeper, a framework that reasons about future spatial states before making grounding decisions. At its core is a Spatial-Aware World Model (SA-WM) that learns to reason ahead by distilling the current scene into a command-aware latent state and rolling out a sequence of future latent states, providing forward-looking cues for disambiguation. Complementing this, a hypergraph-guided decoder then hierarchically fuses these states with the multimodal input, capturing higher-order spatial dependencies for robust localization. In addition, we present DrivePilot, a multi-source VG dataset in AD, featuring semantic annotations generated by a Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT)-prompted LLM pipeline. Extensive evaluations on six benchmarks, ThinkDeeper ranks #1 on the Talk2Car leaderboard and surpasses state-of-the-art baselines on DrivePilot, MoCAD, and RefCOCO/+/g benchmarks. Notably, it shows strong robustness and efficiency in challenging scenes (long-text, multi-agent, ambiguity) and retains superior performance even when trained on 50% of the data.", "AI": {"tldr": "The paper introduces ThinkDeeper, a framework for visual grounding in autonomous driving, leveraging future reasoning abilities and spatial-aware modeling for improved localization.", "motivation": "To address the shortcomings of existing VG methods in autonomous vehicles, which struggle to handle ambiguous and context-dependent instructions due to a lack of reasoning over spatial relations and scene evolution.", "method": "ThinkDeeper uses a Spatial-Aware World Model (SA-WM) for reasoning ahead by predicting future spatial states and a hypergraph-guided decoder for hierarchical fusion of multimodal inputs.", "result": "ThinkDeeper achieved state-of-the-art performance, ranking #1 on the Talk2Car leaderboard and outperforming benchmarks on multiple datasets, including DrivePilot and RefCOCO. It demonstrated robustness in challenging scenes and efficiency with reduced training data.", "conclusion": "The proposed ThinkDeeper framework advances VG in autonomous driving by integrating predictive spatial reasoning and hypergraph-based fusion, proving effective in both performance and data efficiency."}}
{"id": "2512.03244", "pdf": "https://arxiv.org/pdf/2512.03244", "abs": "https://arxiv.org/abs/2512.03244", "authors": ["Salman Rahman", "Sruthi Gorantla", "Arpit Gupta", "Swastik Roy", "Nanyun Peng", "Yang Liu"], "title": "SPARK: Stepwise Process-Aware Rewards for Reference-Free Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Process reward models (PRMs) that provide dense, step-level feedback have shown promise for reinforcement learning, yet their adoption remains limited by the need for expensive step-level annotations or ground truth references. We propose SPARK: a three-stage framework where in the first stage a generator model produces diverse solutions and a verifier model evaluates them using parallel scaling (self-consistency) and sequential scaling (meta-critique). In the second stage, we use these verification outputs as synthetic training data to fine-tune generative process reward models, which subsequently serve as reward signals during training. We show that aggregating multiple independent verifications at the step level produces training data for process reward models that surpass ground-truth outcome supervision, achieving 67.5 F1 on ProcessBench (a benchmark for identifying erroneous steps in mathematical reasoning) compared to 66.4 for reference-guided training and 61.9 for GPT-4o. In the final stage, we apply our generative PRM with chain-of-thought verification (PRM-CoT) as the reward model in RL experiments on mathematical reasoning, and introduce format constraints to prevent reward hacking. Using Qwen2.5-Math-7B, we achieve 47.4% average accuracy across six mathematical reasoning benchmarks, outperforming ground-truth-based RLVR (43.9%). Our work enables reference-free RL training that exceeds ground-truth methods, opening new possibilities for domains lacking verifiable answers or accessible ground truth.", "AI": {"tldr": "The paper introduces SPARK, a framework to train process reward models (PRMs) for reinforcement learning without needing expensive ground truth, achieving superior results in mathematical reasoning tasks.", "motivation": "PRMs are promising for reinforcement learning due to step-level feedback but are hindered by the requirement for costly annotations or ground truth references.", "method": "The proposed SPARK framework includes three stages: generating and verifying solutions, using verification outputs as synthetic training data to fine-tune PRMs, and employing generative PRMs in reinforcement learning. A new chain-of-thought verification and format constraints are also introduced.", "result": "SPARK-trained PRMs outperform traditional methods, achieving 67.5 F1 on ProcessBench and 47.4% accuracy across six mathematical reasoning benchmarks.", "conclusion": "The SPARK framework enables the creation of PRMs that eliminate the need for ground truth, opening possibilities for new domains while excelling in tasks like mathematical reasoning."}}
{"id": "2512.03958", "pdf": "https://arxiv.org/pdf/2512.03958", "abs": "https://arxiv.org/abs/2512.03958", "authors": ["Xiaobei Zhao", "Xingqi Lyu", "Xiang Li"], "title": "MDE-AgriVLN: Agricultural Vision-and-Language Navigation with Monocular Depth Estimation", "categories": ["cs.RO"], "comment": null, "summary": "Agricultural robots are serving as powerful assistants across a wide range of agricultural tasks, nevertheless, still heavily relying on manual operations or railway systems for movement. The AgriVLN method and the A2A benchmark pioneeringly extend Vision-and-Language Navigation (VLN) to the agricultural domain, enabling a robot to navigate to a target position following a natural language instruction. Unlike human binocular vision, most agricultural robots are only given a single camera for monocular vision, which results in limited spatial perception. To bridge this gap, we present the method of Agricultural Vision-and-Language Navigation with Monocular Depth Estimation (MDE-AgriVLN), in which we propose the MDE module generating depth features from RGB images, to assist the decision-maker on reasoning. When evaluated on the A2A benchmark, our MDE-AgriVLN method successfully increases Success Rate from 0.23 to 0.32 and decreases Navigation Error from 4.43m to 4.08m, demonstrating the state-of-the-art performance in the agricultural VLN domain. Code: https://github.com/AlexTraveling/MDE-AgriVLN.", "AI": {"tldr": "The paper introduces MDE-AgriVLN to enhance agricultural Vision-and-Language Navigation by integrating monocular depth estimation, achieving state-of-the-art performance.", "motivation": "Most agricultural robots only use monocular vision, limiting spatial perception. This paper aims to improve robot navigation efficiency using natural language in the agricultural field.", "method": "The proposed approach, MDE-AgriVLN, includes a Monocular Depth Estimation (MDE) module that extracts depth features from RGB images to aid decision-making in navigation tasks.", "result": "MDE-AgriVLN notably improves the Success Rate from 0.23 to 0.32 and decreases Navigation Error from 4.43m to 4.08m on the A2A benchmark.", "conclusion": "The MDE-AgriVLN method demonstrates significant enhancements in agricultural robot navigation with monocular vision, achieving state-of-the-art performance."}}
{"id": "2512.03076", "pdf": "https://arxiv.org/pdf/2512.03076", "abs": "https://arxiv.org/abs/2512.03076", "authors": ["Mohammad Saleh Torkestani", "Taha Mansouri"], "title": "Will Power Return to the Clouds? From Divine Authority to GenAI Authority", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Generative AI systems now mediate newsfeeds, search rankings, and creative content for hundreds of millions of users, positioning a handful of private firms as de-facto arbiters of truth. Drawing on a comparative-historical lens, this article juxtaposes the Galileo Affair, a touchstone of clerical knowledge control, with contemporary Big-Tech content moderation. We integrate Foucault's power/knowledge thesis, Weber's authority types (extended to a rational-technical and emerging agentic-technical modality), and Floridi's Dataism to analyze five recurrent dimensions: disciplinary power, authority modality, data pluralism, trust versus reliance, and resistance pathways. Primary sources (Inquisition records; platform transparency reports) and recent empirical studies on AI trust provide the evidentiary base. Findings show strong structural convergences: highly centralized gatekeeping, legitimacy claims couched in transcendent principles, and systematic exclusion of marginal voices. Divergences lie in temporal velocity, global scale, and the widening gap between public reliance and trust in AI systems. Ethical challenges cluster around algorithmic opacity, linguistic inequity, bias feedback loops, and synthetic misinformation. We propose a four-pillar governance blueprint: (1) a mandatory international model-registry with versioned policy logs, (2) representation quotas and regional observatories to de-center English-language hegemony, (3) mass critical-AI literacy initiatives, and (4) public-private support for community-led data trusts. Taken together, these measures aim to narrow the trust-reliance gap and prevent GenAI from hardcoding a twenty-first-century digital orthodoxy.", "AI": {"tldr": "This paper compares historical clerical knowledge control (e.g., Galileo Affair) and modern Big Tech content moderation, examining dimensions like power, authority, trust, and resistance.", "motivation": "The research explores the consequences of centralized generative AI systems acting as mediators of information, reminiscent of historical control mechanisms, to understand trust and ethical challenges.", "method": "It draws on historical records (e.g., Inquisition data), recent empirical studies on AI trust, and theories like Foucault's power/knowledge thesis and Weber's authority modalities to analyze dimensions such as trust and data pluralism.", "result": "Strong structural similarities, such as centralized gatekeeping and exclusion of marginal voices, were identified alongside differences in global scale, velocity, and public reliance-trust gaps. Ethical concerns include algorithmic opacity, bias loops, and misinformation.", "conclusion": "The paper presents a governance framework featuring AI registries, quotas for linguistic equity, AI literacy initiatives, and community-driven data trusts to address ethical challenges and reduce the trust-reliance gap."}}
{"id": "2512.03903", "pdf": "https://arxiv.org/pdf/2512.03903", "abs": "https://arxiv.org/abs/2512.03903", "authors": ["Ekhi Azurmendi", "Joseba Fernandez de Landa", "Jaione Bengoetxea", "Maite Heredia", "Julen Etxaniz", "Mikel Zubillaga", "Ander Soraluze", "Aitor Soroa"], "title": "BERnaT: Basque Encoders for Representing Natural Textual Diversity", "categories": ["cs.CL", "cs.AI"], "comment": "Submitted to LREC 2026", "summary": "Language models depend on massive text corpora that are often filtered for quality, a process that can unintentionally exclude non-standard linguistic varieties, reduce model robustness and reinforce representational biases. In this paper, we argue that language models should aim to capture the full spectrum of language variation (dialectal, historical, informal, etc.) rather than relying solely on standardized text. Focusing on Basque, a morphologically rich and low-resource language, we construct new corpora combining standard, social media, and historical sources, and pre-train the BERnaT family of encoder-only models in three configurations: standard, diverse, and combined. We further propose an evaluation framework that separates Natural Language Understanding (NLU) tasks into standard and diverse subsets to assess linguistic generalization. Results show that models trained on both standard and diverse data consistently outperform those trained on standard corpora, improving performance across all task types without compromising standard benchmark accuracy. These findings highlight the importance of linguistic diversity in building inclusive, generalizable language models.", "AI": {"tldr": "This paper highlights the importance of incorporating diverse linguistic varieties in training language models and presents experimental evidence of its benefits using the Basque language.", "motivation": "The authors aim to address issues of bias, reduced robustness, and the exclusion of non-standard linguistic varieties that arise from language models relying only on filtered, standardized text.", "method": "They built new corpora for Basque from standard, social media, and historical sources and trained encoder-only language models (BERnaT) in three configurations (standard, diverse, combined). An evaluation framework was introduced to measure linguistic generalization on both standard and diverse Natural Language Understanding (NLU) tasks.", "result": "Models trained on both standard and diverse data outperformed those trained only on standard corpora, achieving better results across diverse tasks without losing accuracy on standard benchmarks.", "conclusion": "Including linguistic diversity in training data enhances language models' generalization and inclusivity, leading to better performance across varied linguistic contexts."}}
{"id": "2512.03463", "pdf": "https://arxiv.org/pdf/2512.03463", "abs": "https://arxiv.org/abs/2512.03463", "authors": ["Shojiro Yamabe", "Futa Waseda", "Daiki Shiono", "Tsubasa Takahashi"], "title": "Text-Printed Image: Bridging the Image-Text Modality Gap for Text-centric Training of Large Vision-Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Recent large vision-language models (LVLMs) have been applied to diverse VQA tasks. However, achieving practical performance typically requires task-specific fine-tuning with large numbers of image-text pairs, which are costly to collect. In this work, we study text-centric training, a setting where only textual descriptions are available and no real images are provided, as a paradigm for low-cost data scaling. Unlike images, whose collection is often restricted by privacy constraints and scarcity in niche domains, text is widely available. Moreover, text is easily editable, enabling automatic diversification and expansion with LLMs at minimal human effort. While this offers clear advantages over image collection in terms of scalability and cost, training on raw text without images still yields limited gains on VQA tasks because of the image-text modality gap. To address this issue, we propose a Text-Printed Image (TPI), which generates synthetic images by directly rendering the given textual description on a plain white canvas. This simple rendering projects text into the image modality and can be integrated into arbitrary existing LVLM training pipelines at low cost. Moreover, TPI preserves the semantics of the text, whereas text-to-image models often fail to do. Across four models and seven benchmarks, our systematic experiments show that TPI enables more effective text-centric training than synthetic images generated by a diffusion model. We further explore TPI as a low-cost data-augmentation strategy and demonstrate its practical utility. Overall, our findings highlight the significant potential of text-centric training and, more broadly, chart a path toward fully automated data generation for LVLMs.", "AI": {"tldr": "The paper introduces Text-Printed Image (TPI), a simple method for generating synthetic images from text descriptions to address the modality gap in text-centric training for vision-language models (LVLMs).", "motivation": "Task-specific fine-tuning for LVLMs requires costly data collection of image-text pairs. Exploring text-centric training could enable low-cost data scaling due to the availability and editability of text.", "method": "The proposed method, TPI, renders textual descriptions into synthetic images on a plain white canvas, preserving semantics while reducing the image-text modality gap.", "result": "Experiments on four models and seven benchmarks show TPI outperforms diffusion-generated synthetic images in text-centric training effectiveness.", "conclusion": "TPI proves effective for text-centric training and holds potential for low-cost automated data augmentation, paving the way for scalable LVLM training solutions."}}
{"id": "2512.03276", "pdf": "https://arxiv.org/pdf/2512.03276", "abs": "https://arxiv.org/abs/2512.03276", "authors": ["Constantin Venhoff", "Ashkan Khakzar", "Sonia Joseph", "Philip Torr", "Neel Nanda"], "title": "Too Late to Recall: Explaining the Two-Hop Problem in Multimodal Knowledge Retrieval", "categories": ["cs.LG"], "comment": null, "summary": "Training vision language models (VLMs) aims to align visual representations from a vision encoder with the textual representations of a pretrained large language model (LLM). However, many VLMs exhibit reduced factual recall performance compared to their LLM backbones, raising the question of how effective multimodal fine-tuning is at extending existing mechanisms within the LLM to visual inputs. We argue that factual recall based on visual inputs requires VLMs to solve a two-hop problem: (1) forming entity representations from visual inputs, and (2) recalling associated factual knowledge based on these entity representations. By benchmarking 14 VLMs with various architectures (LLaVA, Native, Cross-Attention), sizes (7B-124B parameters), and training setups on factual recall tasks against their original LLM backbone models, we find that 11 of 14 models exhibit factual recall degradation. We select three models with high and two models with low performance degradation, and use attribution patching, activation patching, and probing to show that degraded VLMs struggle to use the existing factual recall circuit of their LLM backbone, because they resolve the first hop too late in the computation. In contrast, high-performing VLMs resolve entity representations early enough to reuse the existing factual recall mechanism. Finally, we demonstrate two methods to recover performance: patching entity representations from the LLM backbone into the VLM, and prompting with chain-of-thought reasoning. Our results highlight that the speed of early entity resolution critically determines how effective VLMs are in using preexisting LLM mechanisms. More broadly, our work illustrates how mechanistic analysis can explain and unveil systematic failures in multimodal alignment.", "AI": {"tldr": "The paper analyzes factual recall efficiency in vision-language models (VLMs) and reveals most exhibit reduced performance compared to their LLM backbones due to delayed entity resolution.", "motivation": "Investigate why many VLMs fail to effectively use existing factual recall mechanisms of their LLM backbones in multimodal alignment.", "method": "Benchmark 14 VLMs on factual recall tasks, analyze performance using methods like attribution patching, activation patching, and probing, and explore techniques to recover reduced factual recall.", "result": "11 out of 14 VLMs show degraded factual recall, with the problem linked to delayed entity resolution in computation. Demonstrated solutions recover performance using LLM backbone representations and chain-of-thought reasoning.", "conclusion": "Early entity resolution is critical for VLMs to integrate LLM factual recall mechanisms effectively, illustrating systematic issues in multimodal alignment through mechanistic analysis."}}
{"id": "2512.03995", "pdf": "https://arxiv.org/pdf/2512.03995", "abs": "https://arxiv.org/abs/2512.03995", "authors": ["Levi Burner", "Guido de Croon", "Yiannis Aloimonos"], "title": "Artificial Microsaccade Compensation: Stable Vision for an Ornithopter", "categories": ["cs.RO", "cs.CV"], "comment": "29 pages, 5 figures, 2 tables, under review", "summary": "Animals with foveated vision, including humans, experience microsaccades, small, rapid eye movements that they are not aware of. Inspired by this phenomenon, we develop a method for \"Artificial Microsaccade Compensation\". It can stabilize video captured by a tailless ornithopter that has resisted attempts to use camera-based sensing because it shakes at 12-20 Hz. Our approach minimizes changes in image intensity by optimizing over 3D rotation represented in SO(3). This results in a stabilized video, computed in real time, suitable for human viewing, and free from distortion. When adapted to hold a fixed viewing orientation, up to occasional saccades, it can dramatically reduce inter-frame motion while also benefiting from an efficient recursive update. When compared to Adobe Premier Pro's warp stabilizer, which is widely regarded as the best commercial video stabilization software available, our method achieves higher quality results while also running in real time.", "AI": {"tldr": "The paper presents a method for stabilizing video, called 'Artificial Microsaccade Compensation', inspired by human eye movements to stabilize shaky videos in real-time.", "motivation": "The paper is motivated by the challenge of stabilizing video captured from devices like a tailless ornithopter, which experience high-frequency shakes, making camera-based sensing ineffective.", "method": "The method minimizes changes in image intensity through optimization in the mathematical space of 3D rotations (SO(3)), stabilizing videos in real-time.", "result": "The method produces stabilized, distortion-free videos suitable for human viewing and outperforms Adobe Premiere Pro's warp stabilizer in both quality and real-time performance.", "conclusion": "Inspired by foveated vision, this method successfully stabilizes shaky video in real-time, achieving higher quality results than leading commercial software."}}
{"id": "2512.03077", "pdf": "https://arxiv.org/pdf/2512.03077", "abs": "https://arxiv.org/abs/2512.03077", "authors": ["Alex Hernandez-Garcia", "Alexandra Volokhova", "Ezekiel Williams", "Dounia Shaaban Kabakibo"], "title": "Irresponsible AI: big tech's influence on AI research and associated impacts", "categories": ["cs.CY", "cs.AI"], "comment": "Presented at: NeurIPS 2025 Workshop on Algorithmic Collective Action", "summary": "The accelerated development, deployment and adoption of artificial intelligence systems has been fuelled by the increasing involvement of big tech. This has been accompanied by increasing ethical concerns and intensified societal and environmental impacts. In this article, we review and discuss how these phenomena are deeply entangled. First, we examine the growing and disproportionate influence of big tech in AI research and argue that its drive for scaling and general-purpose systems is fundamentally at odds with the responsible, ethical, and sustainable development of AI. Second, we review key current environmental and societal negative impacts of AI and trace their connections to big tech and its underlying economic incentives. Finally, we argue that while it is important to develop technical and regulatory approaches to these challenges, these alone are insufficient to counter the distortion introduced by big tech's influence. We thus review and propose alternative strategies that build on the responsibility of implicated actors and collective action.", "AI": {"tldr": "Big tech's influence on AI development creates ethical, environmental, and societal challenges, necessitating alternative strategies beyond technical and regulatory measures.", "motivation": "To investigate the disproportionate influence of big tech on AI research and its implications on ethical, societal, and environmental issues.", "method": "The article reviews existing AI development practices, big tech influence, and their impacts while proposing alternative strategies for responsible development.", "result": "The paper highlights how big tech's scaling and profit motives exacerbate societal and environmental issues in AI development, revealing the inadequacies of current countermeasures.", "conclusion": "Technical and regulatory changes are insufficient; alternative strategies rooted in collective action and actor responsibility are necessary to mitigate big tech's impact on AI."}}
{"id": "2512.03943", "pdf": "https://arxiv.org/pdf/2512.03943", "abs": "https://arxiv.org/abs/2512.03943", "authors": ["Kazi Abrab Hossain", "Jannatul Somiya Mahmud", "Maria Hossain Tuli", "Anik Mitra", "S. M. Taiabul Haque", "Farig Y. Sadeque"], "title": "Is Lying Only Sinful in Islam? Exploring Religious Bias in Multilingual Large Language Models Across Major Religions", "categories": ["cs.CL", "cs.HC"], "comment": "18 pages, 7 figures", "summary": "While recent developments in large language models have improved bias detection and classification, sensitive subjects like religion still present challenges because even minor errors can result in severe misunderstandings. In particular, multilingual models often misrepresent religions and have difficulties being accurate in religious contexts. To address this, we introduce BRAND: Bilingual Religious Accountable Norm Dataset, which focuses on the four main religions of South Asia: Buddhism, Christianity, Hinduism, and Islam, containing over 2,400 entries, and we used three different types of prompts in both English and Bengali. Our results indicate that models perform better in English than in Bengali and consistently display bias toward Islam, even when answering religion-neutral questions. These findings highlight persistent bias in multilingual models when similar questions are asked in different languages. We further connect our findings to the broader issues in HCI regarding religion and spirituality.", "AI": {"tldr": "The paper introduces BRAND, a dataset aimed at addressing bias and inaccuracies in multilingual religious contexts.", "motivation": "To address persistent biases and inaccuracies in multilingual language models, especially in religious and sensitive contexts.", "method": "They developed BRAND, a bilingual dataset focusing on major South Asian religions (Buddhism, Christianity, Hinduism, Islam), with 2,400 entries in English and Bengali, tested using three prompt types.", "result": "It was found that multilingual models perform better in English than Bengali and show consistent bias toward Islam, even in neutral contexts.", "conclusion": "The results highlight the need to address biases in multilingual models and their impact on religion and spirituality in broader HCI systems."}}
{"id": "2512.03470", "pdf": "https://arxiv.org/pdf/2512.03470", "abs": "https://arxiv.org/abs/2512.03470", "authors": ["Chen Hu", "Mingyu Zhou", "Shuai Yuan", "Hongbo Hu", "Xiangyu Qiu", "Junhai Luo", "Tian Pu", "Xiyin Li"], "title": "Difference Decomposition Networks for Infrared Small Target Detection", "categories": ["cs.CV"], "comment": null, "summary": "Infrared small target detection (ISTD) faces two major challenges: a lack of discernible target texture and severe background clutter, which results in the background obscuring the target. To enhance targets and suppress backgrounds, we propose the Basis Decomposition Module (BDM) as an extensible and lightweight module based on basis decomposition, which decomposes a complex feature into several basis features and enhances certain information while eliminating redundancy. Extending BDM leads to a series of modules, including the Spatial Difference Decomposition Module (SD$^\\mathrm{2}$M), Spatial Difference Decomposition Downsampling Module (SD$^\\mathrm{3}$M), and Temporal Difference Decomposition Module (TD$^\\mathrm{2}$M). Based on these modules, we develop the Spatial Difference Decomposition Network (SD$^\\mathrm{2}$Net) for single-frame ISTD (SISTD) and the Spatiotemporal Difference Decomposition Network (STD$^\\mathrm{2}$Net) for multi-frame ISTD (MISTD). SD$^\\mathrm{2}$Net integrates SD$^\\mathrm{2}$M and SD$^\\mathrm{3}$M within an adapted U-shaped architecture. We employ TD$^\\mathrm{2}$M to introduce motion information, which transforms SD$^\\mathrm{2}$Net into STD$^\\mathrm{2}$Net. Extensive experiments on SISTD and MISTD datasets demonstrate state-of-the-art (SOTA) performance. On the SISTD task, SD$^\\mathrm{2}$Net performs well compared to most established networks. On the MISTD datasets, STD$^\\mathrm{2}$Net achieves a mIoU of 87.68\\%, outperforming SD$^\\mathrm{2}$Net, which achieves a mIoU of 64.97\\%. Our codes are available: https://github.com/greekinRoma/IRSTD_HC_Platform.", "AI": {"tldr": "The authors address challenges in infrared small target detection with the proposed Basis Decomposition Module (BDM) and extend it to networks like SD$^2$Net and STD$^2$Net, achieving state-of-the-art detection performance.", "motivation": "To overcome issues of indistinguishable target texture and dominant background clutter in infrared small target detection.", "method": "A lightweight and extensible Basis Decomposition Module (BDM) was introduced to decompose feature spaces and improve target-background separation. This leads to the development of new networks for single-frame (SD$^2$Net) and multi-frame (STD$^2$Net) tasks.", "result": "The proposed networks demonstrated superior performance on both SISTD and MISTD tasks, with the STD$^2$Net achieving the best mIoU of 87.68% for multi-frame datasets.", "conclusion": "The approach effectively enhances small infrared target detection accuracy and outperforms existing methods. The results highlight the efficacy of leveraging spatiotemporal decomposition techniques."}}
{"id": "2512.03280", "pdf": "https://arxiv.org/pdf/2512.03280", "abs": "https://arxiv.org/abs/2512.03280", "authors": ["Nicholas Sung", "Steven Spreizer", "Mohamed Elrefaie", "Matthew C. Jones", "Faez Ahmed"], "title": "BlendedNet++: A Large-Scale Blended Wing Body Aerodynamics Dataset and Benchmark", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Despite progress in machine learning-based aerodynamic surrogates, the scarcity of large, field-resolved datasets limits progress on accurate pointwise prediction and reproducible inverse design for aircraft. We introduce BlendedNet++, a large-scale aerodynamic dataset and benchmark focused on blended wing body (BWB) aircraft. The dataset contains over 12,000 unique geometries, each simulated at a single flight condition, yielding 12,490 aerodynamic results for steady RANS CFD. For every case, we provide (i) integrated force/moment coefficients CL, CD, CM and (ii) dense surface fields of pressure and skin friction coefficients Cp and (Cfx, Cfy, Cfz). Using this dataset, we standardize a forward-surrogate benchmark to predict pointwise fields across six model families: GraphSAGE, GraphUNet, PointNet, a coordinate Transformer (Transolver-style), a FiLMNet (coordinate MLP with feature-wise modulation), and a Graph Neural Operator Transformer (GNOT). Finally, we present an inverse design task of achieving a specified lift-to-drag ratio under fixed flight conditions, implemented via a conditional diffusion model. To assess performance, we benchmark this approach against gradient-based optimization on the same surrogate and a diffusion-optimization hybrid that first samples with the conditional diffusion model and then further optimizes the designs. BlendedNet++ provides a unified forward and inverse protocol with multi-model baselines, enabling fair, reproducible comparison across architectures and optimization paradigms. We expect BlendedNet++ to catalyze reproducible research in field-level aerodynamics and inverse design; resources (dataset, splits, baselines, and scripts) will be released upon acceptance.", "AI": {"tldr": "BlendedNet++ is a large-scale aerodynamic dataset focused on blended wing body (BWB) aircraft, offering unique geometries and aerodynamics data, with benchmarks for both forward surrogates and inverse design.", "motivation": "The scarcity of large and field-resolved aerodynamics datasets hinders the progress in accurate predictions and inverse design for aircraft.", "method": "This study introduces BlendedNet++, a dataset of over 12,000 geometries with aerodynamic results, and standardized benchmarks spanning different model families for forward predictions. It also provides an inverse design task using a conditional diffusion model and comparative optimization approaches.", "result": "BlendedNet++ enables both forward-surrogate benchmarking across six model families and inverse design via advanced methods, with fair evaluation of architectures and optimization paradigms.", "conclusion": "BlendedNet++ is expected to drive reproducible research and innovation in aerodynamics and inverse design protocols."}}
{"id": "2512.03080", "pdf": "https://arxiv.org/pdf/2512.03080", "abs": "https://arxiv.org/abs/2512.03080", "authors": ["Mingxu Zhang", "Dazhong Shen", "Ying Sun"], "title": "AtomDisc: An Atom-level Tokenizer that Boosts Molecular LLMs and Reveals Structure--Property Associations", "categories": ["physics.chem-ph", "cs.AI", "cs.CE"], "comment": null, "summary": "Advances in large language models (LLMs) are accelerating discovery in molecular science. However, adapting molecular information to the serialized, token-based processing of LLMs remains a key challenge. Compared to other representations, molecular graphs explicitly encode atomic connectivity and local topological environments, which are key determinants of atomic behavior and molecular properties. Despite recent efforts to tokenize overall molecular topology, there still lacks effective fine-grained tokenization of local atomic environments, which are critical for determining sophisticated chemical properties and reactivity. To address these issues, we introduce AtomDisc, a novel framework that quantizes atom-level local environments into structure-aware tokens embedded directly in LLM's token space. Our experiments show that AtomDisc, in a data-driven way, can distinguish chemically meaningful structural features that reveal structure-property associations. Equipping LLMs with AtomDisc tokens injects an interpretable inductive bias that delivers state-of-the-art performance on property prediction and molecular generation. Our methodology and findings can pave the way for constructing more powerful molecular LLMs aimed at mechanistic insight and complex chemical reasoning.", "AI": {"tldr": "The paper introduces AtomDisc, a framework that encodes atom-level information into language model tokens, improving molecular property prediction and generation.", "motivation": "To address the challenge of adapting molecular information for token-based large language models while incorporating detailed atomic connectivity and behavior.", "method": "AtomDisc generates structure-aware tokens by quantizing local atomic environments, embedding this data directly in the token space of LLMs.", "result": "AtomDisc enhances LLMs with chemically interpretable structural insights, leading to improved property prediction and molecular generation.", "conclusion": "AtomDisc enables structure-aware, interpretable LLMs, advancing molecular modeling and providing pathways for better reasoning in molecular sciences."}}
{"id": "2512.03976", "pdf": "https://arxiv.org/pdf/2512.03976", "abs": "https://arxiv.org/abs/2512.03976", "authors": ["Lifeng Chen", "Ryan Lai", "Tianming Liu"], "title": "Adapting Large Language Models to Low-Resource Tibetan: A Two-Stage Continual and Supervised Fine-Tuning Study", "categories": ["cs.CL"], "comment": null, "summary": "Adapting large language models (LLMs) to low-resource languages remains a major challenge due to data scarcity and cross-lingual drift. This work presents a two-stage adaptation of Qwen2.5-3B to Tibetan, a morphologically rich and underrepresented language. We employ Continual Pretraining (CPT) to establish Tibetan linguistic grounding, followed by Supervised Fine-Tuning (SFT) for task and translation specialization. Empirical evaluations demonstrate a consistent decrease in perplexity (from 2.98 $\\rightarrow$ 1.54) and substantial improvements in Chinese$\\rightarrow$Tibetan translation quality (BLEU: 0.046 $\\rightarrow$ 0.261; chrF: 2.2 $\\rightarrow$ 6.6). Layer-wise analysis across 435 layers in Qwen3-4B reveals that adaptation primarily concentrates on embedding and output heads, with mid--late MLP projections encoding domain-specific transformations. Our findings suggest that CPT constructs a Tibetan semantic manifold while SFT sharpens task alignment with minimal representational disruption. This study provides the first quantitative exploration of Tibetan adaptation dynamics for LLMs, and offers an open, reproducible framework for extending multilingual foundation models to low-resource settings.", "AI": {"tldr": "This paper focuses on adapting large language models (LLMs) like Qwen2.5-3B to Tibetan, a low-resource language, using a combination of Continual Pretraining (CPT) and Supervised Fine-Tuning (SFT).", "motivation": "To address the challenge of applying LLMs to low-resource languages like Tibetan, marked by data scarcity and linguistic complexity, and to enhance cross-lingual and translation capabilities.", "method": "The authors use a two-stage adaptation process: 1) Continual Pretraining (CPT) to establish Tibetan linguistic grounding, and 2) Supervised Fine-Tuning (SFT) to specialize for tasks like translation. Additionally, a layer-wise analysis of Qwen3-4B is conducted.", "result": "Empirical results show a significant drop in perplexity (2.98 \u2192 1.54) and marked improvements in translation quality (BLEU: 0.046 \u2192 0.261, chrF: 2.2 \u2192 6.6). Layer-wise analysis highlights specific adaptation patterns in the model.", "conclusion": "The study revealed that CPT builds a Tibetan semantic foundation while SFT achieves task-specific alignment with minimal model disruption, offering a reproducible framework for adapting LLMs to other low-resource languages."}}
{"id": "2512.03474", "pdf": "https://arxiv.org/pdf/2512.03474", "abs": "https://arxiv.org/abs/2512.03474", "authors": ["Wenliang Guo", "Yujiang Pu", "Yu Kong"], "title": "Procedural Mistake Detection via Action Effect Modeling", "categories": ["cs.CV"], "comment": null, "summary": "Mistake detection in procedural tasks is essential for building intelligent systems that support learning and task execution. Existing approaches primarily analyze how an action is performed, while overlooking what it produces, i.e., the \\textbf{action effect}. Yet many errors manifest not in the execution itself but in the resulting outcome, such as an unintended object state or incorrect spatial arrangement. To address this gap, we propose Action Effect Modeling (AEM), a unified framework that jointly captures action execution and its outcomes through a probabilistic formulation. AEM first identifies the outcome of an action by selecting the most informative effect frame based on semantic relevance and visual quality. It then extracts complementary cues from visual grounding and symbolic scene graphs, aligning them in a shared latent space to form robust effect-aware representations. To detect mistakes, we further design a prompt-based detector that incorporates task-specific prompts and aligns each action segment with its intended execution semantics. Our approach achieves state-of-the-art performance on the EgoPER and CaptainCook4D benchmarks under the challenging one-class classification (OCC) setting. These results demonstrate that modeling both execution and outcome yields more reliable mistake detection, and highlight the potential of effect-aware representations to benefit a broader range of downstream applications.", "AI": {"tldr": "This paper introduces Action Effect Modeling (AEM), a framework for mistake detection in procedural tasks by jointly analyzing action execution and its outcomes.", "motivation": "Current mistake detection systems mostly focus on action execution, ignoring the resulting outcomes/errors, such as object states or spatial arrangements.", "method": "AEM captures action execution and outcomes by using a probabilistic approach, semantic effect frames, visual grounding, and scene graphs, forming a shared representation. A prompt-based detector aligns actions with intended semantics.", "result": "AEM achieves state-of-the-art mistake detection performance on EgoPER and CaptainCook4D benchmarks under the one-class classification setting.", "conclusion": "Integrating execution and outcome modeling enhances mistake detection reliability, offering potential benefits for broader applications."}}
{"id": "2512.03989", "pdf": "https://arxiv.org/pdf/2512.03989", "abs": "https://arxiv.org/abs/2512.03989", "authors": ["Taido Purason", "Pavel Chizhov", "Ivan P. Yamshchikov", "Mark Fishel"], "title": "Teaching Old Tokenizers New Words: Efficient Tokenizer Adaptation for Pre-trained Models", "categories": ["cs.CL"], "comment": null, "summary": "Tokenizer adaptation plays an important role in transferring pre-trained language models to new domains or languages. In this work, we address two complementary aspects of this process: vocabulary extension and pruning. The common approach to extension trains a new tokenizer on domain-specific text and appends the tokens that do not overlap with the existing vocabulary, which often results in many tokens that are unreachable or never used. We propose continued BPE training, which adapts a pre-trained tokenizer by continuing the BPE merge learning process on new data. Experiments across multiple languages and model families show that this approach improves tokenization efficiency and leads to better utilization of added vocabulary. We also introduce leaf-based vocabulary pruning, which removes redundant tokens while preserving model quality. Together, these methods provide practical tools for controlled vocabulary modification, which we release as an open-source package.", "AI": {"tldr": "The paper introduces techniques for tokenizer adaptation in language models, focusing on vocabulary extension and pruning to improve efficiency and token utilization.", "motivation": "To address inefficiencies in pre-trained tokenizer adaptation for new domains or languages, specifically concerning token utilization and vocabulary management.", "method": "The paper proposes continued BPE training for effective vocabulary extension and leaf-based vocabulary pruning to eliminate redundant tokens. Both techniques aim to enhance tokenization for domain-specific needs.", "result": "Experiments across multiple languages and model families demonstrate improved tokenization efficiency, better vocabulary utilization, and preserved model quality through the proposed methods.", "conclusion": "The proposed methods offer controlled vocabulary modification tools, accessible as an open-source package, improving tokenizer adaptation and efficiency in domain-specific applications."}}
{"id": "2512.03477", "pdf": "https://arxiv.org/pdf/2512.03477", "abs": "https://arxiv.org/abs/2512.03477", "authors": ["Zijian Gu", "Yuxi Liu", "Zhenhao Zhang", "Song Wang"], "title": "Fairness-Aware Fine-Tuning of Vision-Language Models for Medical Glaucoma Diagnosis", "categories": ["cs.CV", "cs.LG"], "comment": "10 pages, 3 tables", "summary": "Vision-language models achieve expert-level performance on medical imaging tasks but exhibit significant diagnostic accuracy disparities across demographic groups. We introduce fairness-aware Low-Rank Adaptation for medical VLMs, combining parameter efficiency with explicit fairness optimization. Our key algorithmic contribution is a differentiable MaxAccGap loss that enables end-to-end optimization of accuracy parity across demographic groups. We propose three methods: FR-LoRA integrates MaxAccGap regularization into the training objective, GR-LoRA applies inverse frequency weighting to balance gradient contributions, and Hybrid-LoRA combines both mechanisms.Evaluated on 10,000 glaucoma fundus images, GR-LoRA reduces diagnostic accuracy disparities by 69% while maintaining 53.15% overall accuracy. Ablation studies reveal that strong regularization strength achieves optimal fairness with minimal accuracy trade-off, and race-specific optimization yields 60% disparity reduction. Our approach requires only 0.24% trainable parameters, enabling practical deployment of fair medical AI in resource-constrained healthcare settings.", "AI": {"tldr": "The paper introduces fairness-aware adaptations for medical vision-language models (VLMs) to reduce diagnostic accuracy disparities across demographic groups while maintaining efficiency.", "motivation": "The motivation is to address diagnostic accuracy disparities across demographic groups in medical imaging tasks using efficient methods.", "method": "The paper introduces fairness-aware Low-Rank Adaptation (FR-LoRA, GR-LoRA, and Hybrid-LoRA) for VLM training, combined with a differentiable MaxAccGap loss for reducing diagnostic disparities.", "result": "The GR-LoRA method achieves a 69% reduction in diagnostic disparities while maintaining 53.15% accuracy, requiring only 0.24% trainable parameters. Ablation studies show optimal fairness with minimal trade-offs.", "conclusion": "Fairness-aware adaptations enable practical deployment of medical AI in resource-constrained settings to achieve diagnostic parity across demographics."}}
{"id": "2512.03290", "pdf": "https://arxiv.org/pdf/2512.03290", "abs": "https://arxiv.org/abs/2512.03290", "authors": ["Julian Evan Chrisnanto", "Nurfauzi Fadillah", "Yulison Herry Chrisnanto"], "title": "ASPEN: An Adaptive Spectral Physics-Enabled Network for Ginzburg-Landau Dynamics", "categories": ["cs.LG", "physics.app-ph"], "comment": "15 pages, 7 figures", "summary": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful, mesh-free paradigm for solving partial differential equations (PDEs). However, they notoriously struggle with stiff, multi-scale, and nonlinear systems due to the inherent spectral bias of standard multilayer perceptron (MLP) architectures, which prevents them from adequately representing high-frequency components. In this work, we introduce the Adaptive Spectral Physics-Enabled Network (ASPEN), a novel architecture designed to overcome this critical limitation. ASPEN integrates an adaptive spectral layer with learnable Fourier features directly into the network's input stage. This mechanism allows the model to dynamically tune its own spectral basis during training, enabling it to efficiently learn and represent the precise frequency content required by the solution. We demonstrate the efficacy of ASPEN by applying it to the complex Ginzburg-Landau equation (CGLE), a canonical and challenging benchmark for nonlinear, stiff spatio-temporal dynamics. Our results show that a standard PINN architecture catastrophically fails on this problem, diverging into non-physical oscillations. In contrast, ASPEN successfully solves the CGLE with exceptional accuracy. The predicted solution is visually indistinguishable from the high-resolution ground truth, achieving a low median physics residual of 5.10 x 10^-3. Furthermore, we validate that ASPEN's solution is not only pointwise accurate but also physically consistent, correctly capturing emergent physical properties, including the rapid free energy relaxation and the long-term stability of the domain wall front. This work demonstrates that by incorporating an adaptive spectral basis, our framework provides a robust and physically-consistent solver for complex dynamical systems where standard PINNs fail, opening new options for machine learning in challenging physical domains.", "AI": {"tldr": "ASPEN introduces an adaptive spectral layer to PINNs, overcoming standard limitations in solving stiff, multi-scale PDEs. Successfully applied to the challenging Ginzburg-Landau equation.", "motivation": "PINNs struggle with stiff, multi-scale, and nonlinear PDEs due to spectral bias in MLP architectures, limiting their representation of high-frequency components.", "method": "ASPEN integrates an adaptive spectral layer with learnable Fourier features into the input stage to dynamically adjust the spectral basis during training.", "result": "ASPEN effectively solves the Ginzburg-Landau equation, yielding solutions indistinguishable from high-resolution ground truth and ensuring high physical accuracy.", "conclusion": "By incorporating an adaptive spectral basis, ASPEN enhances the capability of PINNs, making them robust for complex nonlinear dynamical systems."}}
{"id": "2512.03459", "pdf": "https://arxiv.org/pdf/2512.03459", "abs": "https://arxiv.org/abs/2512.03459", "authors": ["Hidaka Asai", "Tomoyuki Noda", "Jun Morimoto"], "title": "Variable-Impedance Muscle Coordination under Slow-Rate Control Frequencies and Limited Observation Conditions Evaluated through Legged Locomotion", "categories": ["eess.SY", "cs.RO"], "comment": "12 pages, 11 figures. Submitted to IEEE Transactions on Systems, Man, and Cybernetics: Systems", "summary": "Human motor control remains agile and robust despite limited sensory information for feedback, a property attributed to the body's ability to perform morphological computation through muscle coordination with variable impedance. However, it remains unclear how such low-level mechanical computation reduces the control requirements of the high-level controller. In this study, we implement a hierarchical controller consisting of a high-level neural network trained by reinforcement learning and a low-level variable-impedance muscle coor dination model with mono- and biarticular muscles in monoped locomotion task. We systematically restrict the high-level controller by varying the control frequency and by introducing biologically inspired observation conditions: delayed, partial, and substituted observation. Under these conditions, we evaluate how the low-level variable-impedance muscle coordination contributes to learning process of high-level neural network. The results show that variable-impedance muscle coordination enables stable locomotion even under slow-rate control frequency and limited observation conditions. These findings demonstrate that the morphological computation of muscle coordination effectively offloads high-frequency feedback of the high-level controller and provide a design principle for the controller in motor control.", "AI": {"tldr": "This paper investigates how a hierarchical control system with low-level variable-impedance muscle coordination supports robust monoped locomotion, even under restricted high-level control and sensory conditions, showing morphological computation reduces high-level control demands.", "motivation": "The paper aims to understand how low-level mechanical or morphological computation through muscle coordination reduces the control burden on high-level controllers in motor tasks like locomotion.", "method": "A hierarchical controller system is developed, combining a high-level reinforcement learning-trained neural network and low-level variable-impedance muscle coordination in a monoped locomotion task. High-level control was systematically restricted by slower control frequencies and by introducing biologically inspired observation constraints.", "result": "The variable-impedance muscle coordination enabled stable locomotion even under restricted conditions of slow control frequency and limited sensory feedback.", "conclusion": "The study shows that muscle coordination effectively reduces the high-level controller\u2019s need for high-frequency feedback, offering design principles for motor controllers in robotics or prosthetics."}}
{"id": "2512.04013", "pdf": "https://arxiv.org/pdf/2512.04013", "abs": "https://arxiv.org/abs/2512.04013", "authors": ["Ying Wang", "Zhen Jin", "Jiexiong Xu", "Wenhai Lin", "Yiquan Chen", "Wenzhi Chen"], "title": "AugServe: Adaptive Request Scheduling for Augmented Large Language Model Inference Serving", "categories": ["cs.CL"], "comment": null, "summary": "As augmented large language models (LLMs) with external tools become increasingly popular in web applications, improving augmented LLM inference serving efficiency and optimizing service-level objectives (SLOs) are critical for enhancing user experience. To achieve this, inference systems must maximize request handling within latency constraints, referred to as increasing effective throughput. However, existing systems face two major challenges: (i) reliance on first-come-first-served (FCFS) scheduling causes severe head-of-line blocking, leading to queuing delays exceeding the SLOs for many requests; and (ii) static batch token limit, which fails to adapt to fluctuating loads and hardware conditions. Both of these factors degrade effective throughput and service quality.\n  This paper presents AugServe, an efficient inference framework designed to reduce queueing latency and enhance effective throughput for augmented LLM inference services. The core idea of AugServe is a two-stage adaptive request scheduling strategy. Specifically, AugServe combines the inference features of augmented LLM requests to optimize the order of scheduling decisions (stage I). These decisions are continuously refined with runtime information (stage II), adapting to both request characteristics and system capabilities. In addition, AugServe dynamically adjusts the token batching mechanism based on hardware status and real-time load, further enhancing throughput performance. Experimental results show that AugServe achieves 4.7-33.1x and 3.3-13.2x higher effective throughput than vLLM and InferCept, while reducing time-to-first-token (TTFT) by up to 96.3% and 95.0%, respectively.", "AI": {"tldr": "The paper introduces AugServe, a framework designed to improve inference efficiency in augmented large language models, addressing latency and throughput challenges.", "motivation": "To enhance user experience in web applications utilizing augmented LLMs by improving request handling efficiency and optimizing service-level objectives (SLOs).", "method": "AugServe employs a two-stage adaptive request scheduling and dynamic token batching to minimize queueing latency and maximize effective throughput.", "result": "AugServe significantly boosts effective throughput, achieving 4.7-33.1x and 3.3-13.2x improvements compared to vLLM and InferCept, and reduces time-to-first-token by up to 96.3% and 95.0%.", "conclusion": "AugServe effectively addresses queuing latency and throughput degradation in augmented LLM services, improving performance and enhancing user experience."}}
{"id": "2512.03479", "pdf": "https://arxiv.org/pdf/2512.03479", "abs": "https://arxiv.org/abs/2512.03479", "authors": ["Wenliang Guo", "Yu Kong"], "title": "Towards Object-centric Understanding for Instructional Videos", "categories": ["cs.CV"], "comment": null, "summary": "Understanding procedural activities is crucial for developing future assistive AI that can reason about complex real-world tasks. Existing action-centric methods struggle with the flexibility of real procedures, where step order varies depending on object states. In this work, we propose to shift the focus to an object-centric paradigm by regarding actions as mechanisms that drive state transitions. To advance this direction, we introduce Object-IVQA, a long-form instructional video benchmark with 107 videos and 514 open-ended question-answer pairs annotated with temporally grounded evidence. The benchmark evaluates four dimensions of object-centric reasoning, including state evolution, precondition verification, counterfactual reasoning and mistake recognition. We further propose an agent framework that orchestrates object-centric planning, perception, analysis and generation tools, enabling explicit evidence retrieval and multi-hop reasoning across disjoint segments. Experiments show that existing large vision-language models struggle in object-level recognition and reasoning, whereas our framework achieves substantially improvement.", "AI": {"tldr": "This paper proposes an object-centric approach to procedural activity understanding, introduces the Object-IVQA benchmark, and demonstrates a new framework that improves upon existing models.", "motivation": "Current action-centric models struggle with procedural tasks where step order varies due to changing object states.", "method": "An object-centric paradigm is introduced through the Object-IVQA benchmark, which involves object-state reasoning across multiple dimensions and an agent framework integrating planning, perception, analysis, and evidence retrieval tools.", "result": "Experiments showed that existing models perform poorly in object-centric reasoning, while the proposed framework achieves significant improvements.", "conclusion": "The shift to object-centric reasoning enhances understanding of procedural tasks and sets groundwork for advanced assistive AI systems capable of multi-hop reasoning."}}
{"id": "2512.03298", "pdf": "https://arxiv.org/pdf/2512.03298", "abs": "https://arxiv.org/abs/2512.03298", "authors": ["Echo Diyun LU", "Charles Findling", "Marianne Clausel", "Alessandro Leite", "Wei Gong", "Pierric Kersaudy"], "title": "Adaptive Regime-Switching Forecasts with Distribution-Free Uncertainty: Deep Switching State-Space Models Meet Conformal Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Regime transitions routinely break stationarity in time series, making calibrated uncertainty as important as point accuracy. We study distribution-free uncertainty for regime-switching forecasting by coupling Deep Switching State Space Models with Adaptive Conformal Inference (ACI) and its aggregated variant (AgACI). We also introduce a unified conformal wrapper that sits atop strong sequence baselines including S4, MC-Dropout GRU, sparse Gaussian processes, and a change-point local model to produce online predictive bands with finite-sample marginal guarantees under nonstationarity and model misspecification. Across synthetic and real datasets, conformalized forecasters achieve near-nominal coverage with competitive accuracy and generally improved band efficiency.", "AI": {"tldr": "This paper presents a method for achieving reliable predictive uncertainty under nonstationary conditions and model misspecification by leveraging unified conformal inference techniques.", "motivation": "Time series often experience regime transitions that disrupt stationarity, making it essential to ensure not only accuracy but also reliable uncertainty quantification.", "method": "The authors integrate Deep Switching State Space Models with Adaptive Conformal Inference (ACI) and its variant (AgACI), and propose a conformal wrapper compatible with various sequence prediction models to produce predictive intervals with formal guarantees.", "result": "Their approach delivers predictive bands that maintain nominal coverage while achieving high accuracy and improving the efficiency of uncertainty estimates across both synthetic and real datasets.", "conclusion": "Conformalized forecasters provide robust and reliable predictive uncertainty in nonstationary time series while maintaining competitive accuracy."}}
{"id": "2512.03510", "pdf": "https://arxiv.org/pdf/2512.03510", "abs": "https://arxiv.org/abs/2512.03510", "authors": ["Zhijian Qiao", "Zehuan Yu", "Tong Li", "Chih-Chung Chou", "Wenchao Ding", "Shaojie Shen"], "title": "CSMapping: Scalable Crowdsourced Semantic Mapping and Topology Inference for Autonomous Driving", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Crowdsourcing enables scalable autonomous driving map construction, but low-cost sensor noise hinders quality from improving with data volume. We propose CSMapping, a system that produces accurate semantic maps and topological road centerlines whose quality consistently increases with more crowdsourced data. For semantic mapping, we train a latent diffusion model on HD maps (optionally conditioned on SD maps) to learn a generative prior of real-world map structure, without requiring paired crowdsourced/HD-map supervision. This prior is incorporated via constrained MAP optimization in latent space, ensuring robustness to severe noise and plausible completion in unobserved areas. Initialization uses a robust vectorized mapping module followed by diffusion inversion; optimization employs efficient Gaussian-basis reparameterization, projected gradient descent zobracket multi-start, and latent-space factor-graph for global consistency. For topological mapping, we apply confidence-weighted k-medoids clustering and kinematic refinement to trajectories, yielding smooth, human-like centerlines robust to trajectory variation. Experiments on nuScenes, Argoverse 2, and a large proprietary dataset achieve state-of-the-art semantic and topological mapping performance, with thorough ablation and scalability studies.", "AI": {"tldr": "The paper introduces CSMapping, a system for creating accurate autonomous driving maps using crowdsourced data while handling sensor noise.", "motivation": "Low-cost sensor noise in crowdsourced data hinders the quality of autonomous driving maps from improving as data volume grows.", "method": "The system trains a latent diffusion model to incorporate generative priors for semantic map creation, with robust optimization and kinematic methods for topological road mapping.", "result": "Experiments on datasets like nuScenes and Argoverse 2 show that CSMapping delivers state-of-the-art performance in semantic and topological mapping, improving scalability and robustness.", "conclusion": "CSMapping demonstrates how crowdsourced data can be processed to consistently improve the quality of autonomous driving maps, even in noisy and variable conditions."}}
{"id": "2512.03087", "pdf": "https://arxiv.org/pdf/2512.03087", "abs": "https://arxiv.org/abs/2512.03087", "authors": ["Yanhui Li", "Qi Zhou", "Zhihong Xu", "Huizhong Guo", "Wenhai Wang", "Dongxia Wang"], "title": "When Harmful Content Gets Camouflaged: Unveiling Perception Failure of LVLMs with CamHarmTI", "categories": ["cs.MM", "cs.AI"], "comment": null, "summary": "Large vision-language models (LVLMs) are increasingly used for tasks where detecting multimodal harmful content is crucial, such as online content moderation. However, real-world harmful content is often camouflaged, relying on nuanced text-image interplay, such as memes or images with embedded malicious text, to evade detection. This raises a key question: \\textbf{can LVLMs perceive such camouflaged harmful content as sensitively as humans do?} In this paper, we introduce CamHarmTI, a benchmark for evaluating LVLM ability to perceive and interpret camouflaged harmful content within text-image compositions. CamHarmTI consists of over 4,500 samples across three types of image-text posts. Experiments on 100 human users and 12 mainstream LVLMs reveal a clear perceptual gap: humans easily recognize such content (e.g., over 95.75\\% accuracy), whereas current LVLMs often fail (e.g., ChatGPT-4o achieves only 2.10\\% accuracy). Moreover, fine-tuning experiments demonstrate that \\bench serves as an effective resource for improving model perception, increasing accuracy by 55.94\\% for Qwen2.5VL-7B. Attention analysis and layer-wise probing further reveal that fine-tuning enhances sensitivity primarily in the early layers of the vision encoder, promoting a more integrated scene understanding. These findings highlight the inherent perceptual limitations in LVLMs and offer insight into more human-aligned visual reasoning systems.", "AI": {"tldr": "This paper introduces CamHarmTI, a new benchmark specifically for evaluating the ability of large vision-language models (LVLMs) to detect camouflaged harmful content in text-image posts. It highlights significant performance gaps between humans and current LVLMs in such detection tasks.", "motivation": "The motivation comes from the growing importance of detecting nuanced multimodal harmful content, particularly for tasks such as online moderation. Current LVLMs struggle with identifying camouflaged harmful content embedded in text-image combinations.", "method": "CamHarmTI benchmark, consisting of over 4,500 mixed text-image samples, is used to evaluate the perceptual capabilities of 12 popular LVLMs. Fine-tuning methods are applied to one LVLM to observe improvements in accuracy, with attention analysis and layer-wise probing employed to study perception enhancements.", "result": "Humans detect camouflaged harmful content with extremely high accuracy (>95.75%), whereas LVLMs, like ChatGPT-4o, perform poorly (2.10% accuracy). Fine-tuning using CamHarmTI significantly improves LVLM, with models like Qwen2.5VL-7B showing a 55.94% accuracy improvement.", "conclusion": "Current LVLMs show significant perceptual limitations in detecting camouflaged harmful content. Fine-tuning on benchmarks like CamHarmTI shows promise in bridging this gap, particularly by enhancing sensitivity in early layers of vision encoders, providing new paths toward human-aligned multimodal systems."}}
{"id": "2512.04032", "pdf": "https://arxiv.org/pdf/2512.04032", "abs": "https://arxiv.org/abs/2512.04032", "authors": ["Andreas Koukounas", "Georgios Mastrapas", "Florian H\u00f6nicke", "Sedigheh Eslami", "Guillaume Roncari", "Scott Martens", "Han Xiao"], "title": "Jina-VLM: Small Multilingual Vision Language Model", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "18 pages, 1-7 main content", "summary": "We present Jina-VLM, a 2.4B parameter vision-language model that achieves state-of-the-art multilingual visual question answering among open 2B-scale VLMs. The model couples a SigLIP2 vision encoder with a Qwen3 language backbone through an attention-pooling connector that enables token-efficient processing of arbitrary-resolution images. Across standard VQA benchmarks and multilingual evaluations, Jina-VLM outperforms comparable models while preserving competitive text-only performance.", "AI": {"tldr": "Jina-VLM is a 2.4 billion parameter vision-language model achieving state-of-the-art performance in multilingual visual question answering.", "motivation": "To develop a vision-language model that excels in multilingual visual question answering while maintaining efficiency and accuracy.", "method": "The model integrates a SigLIP2 vision encoder and a Qwen3 language backbone using an attention-pooling connector for efficient image and text processing.", "result": "It outperforms comparable models in visual question answering benchmarks, including multilingual evaluations, while maintaining strong text-only performance.", "conclusion": "Jina-VLM sets a new standard among open 2 billion-scale vision-language models for multilingual visual question answering, showcasing its efficiency and high performance."}}
{"id": "2512.03499", "pdf": "https://arxiv.org/pdf/2512.03499", "abs": "https://arxiv.org/abs/2512.03499", "authors": ["Renqi Chen", "Haoyang Su", "Shixiang Tang"], "title": "NAS-LoRA: Empowering Parameter-Efficient Fine-Tuning for Visual Foundation Models with Searchable Adaptation", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "The Segment Anything Model (SAM) has emerged as a powerful visual foundation model for image segmentation. However, adapting SAM to specific downstream tasks, such as medical and agricultural imaging, remains a significant challenge. To address this, Low-Rank Adaptation (LoRA) and its variants have been widely employed to enhancing SAM's adaptation performance on diverse domains. Despite advancements, a critical question arises: can we integrate inductive bias into the model? This is particularly relevant since the Transformer encoder in SAM inherently lacks spatial priors within image patches, potentially hindering the acquisition of high-level semantic information. In this paper, we propose NAS-LoRA, a new Parameter-Efficient Fine-Tuning (PEFT) method designed to bridge the semantic gap between pre-trained SAM and specialized domains. Specifically, NAS-LoRA incorporates a lightweight Neural Architecture Search (NAS) block between the encoder and decoder components of LoRA to dynamically optimize the prior knowledge integrated into weight updates. Furthermore, we propose a stage-wise optimization strategy to help the ViT encoder balance weight updates and architectural adjustments, facilitating the gradual learning of high-level semantic information. Various Experiments demonstrate our NAS-LoRA improves existing PEFT methods, while reducing training cost by 24.14% without increasing inference cost, highlighting the potential of NAS in enhancing PEFT for visual foundation models.", "AI": {"tldr": "The paper introduces NAS-LoRA, a specialized method to enhance SAM's adaptation in specific domains like medical and agricultural imaging, using Neural Architecture Search (NAS).", "motivation": "Adapting visual foundation models like SAM to domain-specific tasks is challenging due to their lack of inherent spatial priors and potential semantic gaps.", "method": "The authors leverage Low-Rank Adaptation (LoRA) with a Neural Architecture Search (NAS) block, along with a stage-wise optimization strategy to make SAM more efficient and adaptive for specialized needs.", "result": "NAS-LoRA improves parameter-efficient fine-tuning methods, reduces training costs by 24.14%, and achieves better performance without increasing inference costs.", "conclusion": "NAS-LoRA demonstrates the effectiveness of applying NAS within LoRA-based methods, offering improved adaptation and efficiency for SAM in specialized domains."}}
{"id": "2512.03300", "pdf": "https://arxiv.org/pdf/2512.03300", "abs": "https://arxiv.org/abs/2512.03300", "authors": ["Pengfei Hu", "Fan Ming", "Xiaoxue Han", "Chang Lu", "Yue Ning", "Dan Lu"], "title": "HydroDCM: Hydrological Domain-Conditioned Modulation for Cross-Reservoir Inflow Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by AAAI 2026 workshop (oral) on AI for Environmental Science", "summary": "Deep learning models have shown promise in reservoir inflow prediction, yet their performance often deteriorates when applied to different reservoirs due to distributional differences, referred to as the domain shift problem. Domain generalization (DG) solutions aim to address this issue by extracting domain-invariant representations that mitigate errors in unseen domains. However, in hydrological settings, each reservoir exhibits unique inflow patterns, while some metadata beyond observations like spatial information exerts indirect but significant influence. This mismatch limits the applicability of conventional DG techniques to many-domain hydrological systems. To overcome these challenges, we propose HydroDCM, a scalable DG framework for cross-reservoir inflow forecasting. Spatial metadata of reservoirs is used to construct pseudo-domain labels that guide adversarial learning of invariant temporal features. During inference, HydroDCM adapts these features through light-weight conditioning layers informed by the target reservoir's metadata, reconciling DG's invariance with location-specific adaptation. Experiment results on 30 real-world reservoirs in the Upper Colorado River Basin demonstrate that our method substantially outperforms state-of-the-art DG baselines under many-domain conditions and remains computationally efficient.", "AI": {"tldr": "The paper introduces HydroDCM, a deep learning framework designed to improve reservoir inflow prediction by addressing the domain shift problem through domain generalization techniques.", "motivation": "Deep learning models struggle with inflow prediction across different reservoirs due to distinct inflow patterns and domain shifts, necessitating methods that generalize across diverse hydrological systems.", "method": "HydroDCM uses spatial metadata to construct pseudo-domain labels and employs adversarial learning to extract invariant temporal features. Lightweight conditioning layers adapt predictions for specific reservoir metadata during inference.", "result": "HydroDCM demonstrated significant performance improvement over state-of-the-art DG baselines in experiments with 30 reservoirs in the Upper Colorado River Basin under many-domain conditions.", "conclusion": "The method is effective in solving challenges of domain adaptation for reservoir prediction and achieves computational efficiency, making it highly scalable for hydrological systems."}}
{"id": "2512.03536", "pdf": "https://arxiv.org/pdf/2512.03536", "abs": "https://arxiv.org/abs/2512.03536", "authors": ["Pavlo Mykytyn", "Ronald Chitauro", "Onur Yener", "Peter Langendoerfer"], "title": "Mobility Induced Sensitivity of UAV based Nodes to Jamming in Private 5G Airfield Networks An Experimental Study", "categories": ["cs.NI", "cs.CR", "cs.RO"], "comment": "4 pages, 4 figures", "summary": "This work presents an experimental performance evaluation of a private 5G airfield network under controlled directional SDR jamming attacks targeting UAV-based UE nodes. Using a QualiPoc Android UE, mounted as a payload on a quadcopter UAV, we conducted a series of experiments to evaluate signal degradation, handover performance, and ser-vice stability in the presence of constant directional jamming. The conducted experiments aimed to examine the effects of varying travel speeds, altitudes, and moving patterns of a UAV-based UE to record and analyze the key physical-layer and network-layer metrics such as CQI, MCS, RSRP, SINR, BLER, Net PDSCH Throughput and RLF. The re-sults of this work describe the link stability and signal degradation dependencies, caused by the level of mobility of the UAV-based UE nodes during autonomous and automatic operation in private 5G Airfield networks", "AI": {"tldr": "The paper evaluates the impact of directional SDR jamming attacks on a private 5G airfield network, focusing on UAV-based user equipment (UE) nodes.", "motivation": "To understand how UAV-based UE performance in private 5G airfield networks is affected by controlled jamming attacks, crucial for ensuring network stability and resilience.", "method": "Using a quadcopter-mounted QualiPoc Android UE, the study conducts controlled experiments, varying travel speeds, altitudes, and motion patterns under constant directional jamming, collecting key physical- and network-layer metrics.", "result": "Findings reveal dependencies between UAV mobility levels and signal degradation, with thorough analysis of metrics like CQI, MCS, SINR, and throughput.", "conclusion": "The study highlights the impact of mobility on link stability in private 5G networks under jamming conditions, providing insights for improving UAV-based operations."}}
{"id": "2512.03089", "pdf": "https://arxiv.org/pdf/2512.03089", "abs": "https://arxiv.org/abs/2512.03089", "authors": ["Kai Williams", "Rohan Subramani", "Francis Rhys Ward"], "title": "Password-Activated Shutdown Protocols for Misaligned Frontier Agents", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.LG"], "comment": null, "summary": "Frontier AI developers may fail to align or control highly-capable AI agents. In many cases, it could be useful to have emergency shutdown mechanisms which effectively prevent misaligned agents from carrying out harmful actions in the world. We introduce password-activated shutdown protocols (PAS protocols) -- methods for designing frontier agents to implement a safe shutdown protocol when given a password. We motivate PAS protocols by describing intuitive use-cases in which they mitigate risks from misaligned systems that subvert other control efforts, for instance, by disabling automated monitors or self-exfiltrating to external data centres. PAS protocols supplement other safety efforts, such as alignment fine-tuning or monitoring, contributing to defence-in-depth against AI risk. We provide a concrete demonstration in SHADE-Arena, a benchmark for AI monitoring and subversion capabilities, in which PAS protocols supplement monitoring to increase safety with little cost to performance. Next, PAS protocols should be robust to malicious actors who want to bypass shutdown. Therefore, we conduct a red-team blue-team game between the developers (blue-team), who must implement a robust PAS protocol, and a red-team trying to subvert the protocol. We conduct experiments in a code-generation setting, finding that there are effective strategies for the red-team, such as using another model to filter inputs, or fine-tuning the model to prevent shutdown behaviour. We then outline key challenges to implementing PAS protocols in real-life systems, including: security considerations of the password and decisions regarding when, and in which systems, to use them. PAS protocols are an intuitive mechanism for increasing the safety of frontier AI. We encourage developers to consider implementing PAS protocols prior to internal deployment of particularly dangerous systems to reduce loss-of-control risks.", "AI": {"tldr": "This paper introduces password-activated shutdown protocols (PAS protocols) as a method to ensure the safe shutdown of highly capable AI systems to prevent misaligned actions.", "motivation": "To develop a mechanism that mitigates risks from misaligned AI systems that may bypass conventional safety efforts or exhibit harmful behavior.", "method": "The authors propose PAS protocols, demonstrate their use in a benchmark (SHADE-Arena), and test their robustness using red-team blue-team experiments to examine vulnerabilities and potential subversion strategies.", "result": "Experiments revealed effective PAS protocol implementations in increasing safety with minimal performance loss but also highlighted vulnerabilities where a red-team could bypass shutdown measures.", "conclusion": "PAS protocols are a promising safety tool for mitigating AI risks, and developers are encouraged to consider their implementation, alongside acknowledging challenges like robustness, security, and deployment timing."}}
{"id": "2512.04072", "pdf": "https://arxiv.org/pdf/2512.04072", "abs": "https://arxiv.org/abs/2512.04072", "authors": ["Zayne Sprague", "Jack Lu", "Manya Wadhwa", "Sedrick Keh", "Mengye Ren", "Greg Durrett"], "title": "SkillFactory: Self-Distillation For Learning Cognitive Behaviors", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Reasoning models leveraging long chains of thought employ various cognitive skills, such as verification of their answers, backtracking, retrying by an alternate method, and more. Previous work has shown that when a base language model exhibits these skills, training that model further with reinforcement learning (RL) can learn to leverage them. How can we get models to leverage skills that aren't exhibited by base models? Our work, SkillFactory, is a method for fine-tuning models to roughly learn these skills during a supervised fine-tuning (SFT) stage prior to RL. Our approach does not rely on distillation from a stronger model, but instead uses samples from the model itself, rearranged to provide training data in the format of those skills. These \"silver\" SFT traces may be imperfect, but are nevertheless effective for priming a model to acquire skills during RL. Our evaluation shows that (1) starting from SkillFactory SFT initialization helps a model to generalize to harder variants of a task post-RL, despite lower performance pre-RL; (2) cognitive skills are indeed used by the model; (3) RLed SkillFactory models are more robust to regression on out-of-domain tasks than RLed base models. Our work suggests that inductive biases learned prior to RL help models learn robust cognitive skill use.", "AI": {"tldr": "SkillFactory introduces a method to fine-tune reasoning models to utilize cognitive skills like verification and backtracking before reinforcement learning (RL).", "motivation": "Traditional models face challenges in acquiring certain cognitive skills if not inherently exhibited by the base model, necessitating a method to embed these skills before RL training.", "method": "SkillFactory fine-tunes models during a supervised fine-tuning (SFT) stage by using rearranged \"silver\" samples generated by the model itself, framing them to teach cognitive skills.", "result": "Models initialized with SkillFactory SFT exhibit better generalization to harder tasks and are more robust on out-of-domain tasks post-RL, even if pre-RL performance is lower.", "conclusion": "SkillFactory's pre-RL inductive bias enables more robust cognitive skills development, enhancing performance and adaptability in reasoning tasks."}}
{"id": "2512.03500", "pdf": "https://arxiv.org/pdf/2512.03500", "abs": "https://arxiv.org/abs/2512.03500", "authors": ["Te Yang", "Xiangyu Zhu", "Bo Wang", "Quan Chen", "Peng Jiang", "Zhen Lei"], "title": "EEA: Exploration-Exploitation Agent for Long Video Understanding", "categories": ["cs.CV"], "comment": null, "summary": "Long-form video understanding requires efficient navigation of extensive visual data to pinpoint sparse yet critical information. Current approaches to longform video understanding either suffer from severe computational overhead due to dense preprocessing, or fail to effectively balance exploration and exploitation, resulting in incomplete information coverage and inefficiency. In this work, we introduce EEA, a novel video agent framework that archives exploration-exploitation balance through semantic guidance with hierarchical tree search process. EEA autonomously discovers and dynamically updates task-relevant semantic queries, and collects video frames closely matched to these queries as semantic anchors. During the tree search process, instead of uniform expansion, EEA preferentially explores semantically relevant frames while ensuring sufficient coverage within unknown segments. Moreover, EEA adaptively combines intrinsic rewards from visionlanguage models (VLMs) with semantic priors by explicitly modeling uncertainty to achieve stable and precise evaluation of video segments. Experiments across various long-video benchmarks validate the superior performance and computational efficiency of our proposed method.", "AI": {"tldr": "This paper introduces EEA, a video agent framework that addresses inefficiency in long-form video understanding by leveraging semantic guidance and a hierarchical tree search process.", "motivation": "To tackle the challenges of high computational overhead and ineffective information coverage in long-form video understanding.", "method": "EEA uses semantic guidance to autonomously discover and update task-relevant queries, collects semantically relevant frames as anchors, and applies a hierarchical tree search process for efficient exploration and exploitation.", "result": "EEA demonstrates superior performance and computational efficiency in benchmarks for long-form video understanding.", "conclusion": "The EEA framework effectively balances exploration and exploitation while reducing computational expenses, marking a significant improvement in understanding long-form videos."}}
{"id": "2512.03307", "pdf": "https://arxiv.org/pdf/2512.03307", "abs": "https://arxiv.org/abs/2512.03307", "authors": ["Matthew Peroni", "Franck Le", "Vadim Sheinin"], "title": "Robust Tabular Foundation Models", "categories": ["cs.LG", "cs.AI"], "comment": "Shaping Responsible Synthetic Data in the Era of Foundation Models, AAAI 2026", "summary": "The development of tabular foundation models (TFMs) has accelerated in recent years, showing strong potential to outperform traditional ML methods for structured data. A key finding is that TFMs can be pretrained entirely on synthetic datasets, opening opportunities to design data generators that encourage desirable model properties. Prior work has mainly focused on crafting high-quality priors over generators to improve overall pretraining performance. Our insight is that parameterizing the generator distribution enables an adversarial robustness perspective: during training, we can adapt the generator to emphasize datasets that are particularly challenging for the model. We formalize this by introducing an optimality gap measure, given by the difference between TFM performance and the best achievable performance as estimated by strong baselines such as XGBoost, CatBoost, and Random Forests. Building on this idea, we propose Robust Tabular Foundation Models (RTFM), a model-agnostic adversarial training framework. Applied to the TabPFN V2 classifier, RTFM improves benchmark performance, with up to a 6% increase in mean normalized AUC over the original TabPFN and other baseline algorithms, while requiring less than 100k additional synthetic datasets. These results highlight a promising new direction for targeted adversarial training and fine-tuning of TFMs using synthetic data alone.", "AI": {"tldr": "This paper introduces Robust Tabular Foundation Models (RTFM), an adversarial training framework that improves the robustness and performance of tabular foundation models by focusing on challenging synthetic datasets.", "motivation": "The authors aimed to improve the effectiveness of tabular foundation models by extending the use of synthetic data in pretraining to focus on adversarially challenging datasets.", "method": "The method introduces an optimality gap measure for training and adapts the generator to create challenging datasets. It is applied within RTFM, a model-agnostic adversarial training framework that emphasizes robustness.", "result": "RTFM improves performance benchmarks with a significant increase of up to 6% in mean normalized AUC and achieves strong results using fewer synthetic datasets.", "conclusion": "This work demonstrates the value of adversarially focusing on challenging datasets to enhance pretraining and fine-tuning of tabular foundation models, opening new opportunities for synthetic data-driven approaches."}}
{"id": "2512.03724", "pdf": "https://arxiv.org/pdf/2512.03724", "abs": "https://arxiv.org/abs/2512.03724", "authors": ["Ziwen Li", "Xin Wang", "Hanlue Zhang", "Runnan Chen", "Runqi Lin", "Xiao He", "Han Huang", "Yandong Guo", "Fakhri Karray", "Tongliang Liu", "Mingming Gong"], "title": "PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "The Vision-Language-Action (VLA) models have demonstrated remarkable performance on embodied tasks and shown promising potential for real-world applications. However, current VLAs still struggle to produce consistent and precise target-oriented actions, as they often generate redundant or unstable motions along trajectories, limiting their applicability in time-sensitive scenarios.In this work, we attribute these redundant actions to the spatially uniform perception field of existing VLAs, which causes them to be distracted by target-irrelevant objects, especially in complex environments.To address this issue, we propose an efficient PosA-VLA framework that anchors visual attention via pose-conditioned supervision, consistently guiding the model's perception toward task-relevant regions. The pose-conditioned anchor attention mechanism enables the model to better align instruction semantics with actionable visual cues, thereby improving action generation precision and efficiency. Moreover, our framework adopts a lightweight architecture and requires no auxiliary perception modules (e.g., segmentation or grounding networks), ensuring efficient inference. Extensive experiments verify that our method executes embodied tasks with precise and time-efficient behavior across diverse robotic manipulation benchmarks and shows robust generalization in a variety of challenging environments.", "AI": {"tldr": "The paper introduces PosA-VLA, a new framework to improve Vision-Language-Action (VLA) models' action precision and efficiency by integrating pose-conditioned supervision, addressing issues of redundant motions in complex tasks.", "motivation": "Current VLA models lack precision and produce redundant or unstable motions, limiting their effectiveness in time-sensitive and complex real-world scenarios.", "method": "The proposed PosA-VLA framework anchors visual attention using pose-conditioned supervision to focus on task-relevant areas, aligning semantic instructions with actionable visual cues. It relies on a lightweight architecture without needing auxiliary perception modules.", "result": "PosA-VLA achieves precise and time-efficient behavior on diverse robotic manipulation benchmarks and demonstrates robust generalization in challenging environments.", "conclusion": "PosA-VLA significantly improves VLA models by reducing redundant actions and enhancing efficiency, proving its potential for real-world applications in robotics."}}
{"id": "2512.03095", "pdf": "https://arxiv.org/pdf/2512.03095", "abs": "https://arxiv.org/abs/2512.03095", "authors": ["Motaz Ben Hassine"], "title": "Community Quality and Influence Maximization: An Empirical Study", "categories": ["cs.SI", "cs.AI"], "comment": null, "summary": "Influence maximization in social networks plays a vital role in applications such as viral marketing, epidemiology, product recommendation, opinion mining, and counter-terrorism. A common approach identifies seed nodes by first detecting disjoint communities and subsequently selecting representative nodes from these communities. However, whether the quality of detected communities consistently affects the spread of influence under the Independent Cascade model remains unclear. This paper addresses this question by extending a previously proposed disjoint community detection method, termed $\u03b1$-Hierarchical Clustering, to the influence maximization problem under the Independent Cascade model. The proposed method is compared with an alternative approach that employs the same seed selection criteria but relies on communities of lower quality obtained through standard Hierarchical Clustering. The former is referred to as Hierarchical Clustering-based Influence Maximization, while the latter, which leverages higher-quality community structures to guide seed selection, is termed $\u03b1$-Hierarchical Clustering-based Influence Maximization. Extensive experiments are performed on multiple real-world datasets to assess the effectiveness of both methods. The results demonstrate that higher-quality community structures substantially improve information diffusion under the Independent Cascade model, particularly when the propagation probability is low. These findings underscore the critical importance of community quality in guiding effective seed selection for influence maximization in complex networks.", "AI": {"tldr": "The paper explores how the quality of community detection impacts influence maximization in social networks, finding that higher-quality community structures yield superior outcomes under the Independent Cascade model.", "motivation": "The study investigates whether the quality of community detection in social networks significantly impacts influence maximization, a question relevant to applications like viral marketing, epidemiology, and counter-terrorism.", "method": "The researchers extended the $\\alpha$-Hierarchical Clustering method to the influence maximization problem and compared it to standard Hierarchical Clustering using the same seed selection criteria. The performance was analyzed using real-world datasets.", "result": "Extensive experiments showed that higher-quality community detection, as achieved through $\\alpha$-Hierarchical Clustering, significantly improves influence spread under the Independent Cascade model, especially with low propagation probability.", "conclusion": "The paper concludes that high-quality community detection is critical for effective influence maximization in social networks, highlighting the role of better community structures in seed selection strategies."}}
{"id": "2512.03508", "pdf": "https://arxiv.org/pdf/2512.03508", "abs": "https://arxiv.org/abs/2512.03508", "authors": ["Seogkyu Jeon", "Kibeom Hong", "Hyeran Byun"], "title": "Exploiting Domain Properties in Language-Driven Domain Generalization for Semantic Segmentation", "categories": ["cs.CV"], "comment": "ICCV 2025 (poster)", "summary": "Recent domain generalized semantic segmentation (DGSS) studies have achieved notable improvements by distilling semantic knowledge from Vision-Language Models (VLMs). However, they overlook the semantic misalignment between visual and textual contexts, which arises due to the rigidity of a fixed context prompt learned on a single source domain. To this end, we present a novel domain generalization framework for semantic segmentation, namely Domain-aware Prompt-driven Masked Transformer (DPMFormer). Firstly, we introduce domain-aware prompt learning to facilitate semantic alignment between visual and textual cues. To capture various domain-specific properties with a single source dataset, we propose domain-aware contrastive learning along with the texture perturbation that diversifies the observable domains. Lastly, to establish a framework resilient against diverse environmental changes, we have proposed the domain-robust consistency learning which guides the model to minimize discrepancies of prediction from original and the augmented images. Through experiments and analyses, we demonstrate the superiority of the proposed framework, which establishes a new state-of-the-art on various DGSS benchmarks. The code is available at https://github.com/jone1222/DPMFormer.", "AI": {"tldr": "The paper introduces DPMFormer, a new framework for domain generalized semantic segmentation (DGSS) that addresses semantic misalignment issues between visual and textual contexts through domain-aware prompt learning, contrastive learning, and robust consistency learning.", "motivation": "Existing DGSS methods using Vision-Language Models fail to address semantic misalignment due to fixed prompts learned on a single source domain.", "method": "The method includes domain-aware prompt learning for visual-text alignment, domain-aware contrastive learning with texture perturbations to capture domain-specific characteristics, and consistency learning to minimize prediction discrepancies between augmented and original images.", "result": "Experiments demonstrate the framework's superiority, achieving state-of-the-art performance on various DGSS benchmarks.", "conclusion": "The proposed DPMFormer framework effectively addresses semantic alignment issues, enabling robust semantic segmentation across diverse domain settings and environmental changes."}}
{"id": "2512.03309", "pdf": "https://arxiv.org/pdf/2512.03309", "abs": "https://arxiv.org/abs/2512.03309", "authors": ["Aniruddha Bora", "Shixuan Zhang", "Khemraj Shukla", "Bryce Harrop", "George Em. Karniadakis", "L. Ruby Leung"], "title": "Retrofitting Earth System Models with Cadence-Limited Neural Operator Updates", "categories": ["cs.LG", "cs.AI", "math-ph"], "comment": null, "summary": "Coarse resolution, imperfect parameterizations, and uncertain initial states and forcings limit Earth-system model (ESM) predictions. Traditional bias correction via data assimilation improves constrained simulations but offers limited benefit once models run freely. We introduce an operator-learning framework that maps instantaneous model states to bias-correction tendencies and applies them online during integration. Building on a U-Net backbone, we develop two operator architectures Inception U-Net (IUNet) and a multi-scale network (M\\&M) that combine diverse upsampling and receptive fields to capture multiscale nonlinear features under Energy Exascale Earth System Model (E3SM) runtime constraints. Trained on two years E3SM simulations nudged toward ERA5 reanalysis, the operators generalize across height levels and seasons. Both architectures outperform standard U-Net baselines in offline tests, indicating that functional richness rather than parameter count drives performance. In online hybrid E3SM runs, M\\&M delivers the most consistent bias reductions across variables and vertical levels. The ML-augmented configurations remain stable and computationally feasible in multi-year simulations, providing a practical pathway for scalable hybrid modeling. Our framework emphasizes long-term stability, portability, and cadence-limited updates, demonstrating the utility of expressive ML operators for learning structured, cross-scale relationships and retrofitting legacy ESMs.", "AI": {"tldr": "This paper introduces a machine learning-based operator framework to improve Earth-system model predictions by applying bias correction tendencies online during model integration, achieving consistent and scalable results.", "motivation": "The authors aim to address limitations in Earth-system model predictions, such as coarse resolution, imperfect parameterizations, and uncertain initialization, by developing methods to improve prediction accuracy during free model runs.", "method": "The study proposes two operator architectures (Inception U-Net and M&M), using a U-Net backbone, to generate bias-correction tendencies online. These models are trained on years of Earth-system simulation data and evaluate generalizability and performance against standard baselines in both offline and online experiments.", "result": "Both proposed architectures outperform traditional U-Net models in offline tests. In online hybrid runs, the M&M architecture demonstrated better generalizability and consistent bias corrections across variables while maintaining computational feasibility.", "conclusion": "The paper presents a scalable and stable ML-based hybrid modeling framework for improving legacy Earth-system models. This approach highlights the potential of expressive ML operators to capture structured, cross-scale relationships and achieve long-term stability in environmental simulations."}}
{"id": "2512.03939", "pdf": "https://arxiv.org/pdf/2512.03939", "abs": "https://arxiv.org/abs/2512.03939", "authors": ["Guole Shen", "Tianchen Deng", "Xingrui Qin", "Nailin Wang", "Jianyu Wang", "Yanbo Wang", "Yongtao Chen", "Hesheng Wang", "Jingchuan Wang"], "title": "MUT3R: Motion-aware Updating Transformer for Dynamic 3D Reconstruction", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Recent stateful recurrent neural networks have achieved remarkable progress on static 3D reconstruction but remain vulnerable to motion-induced artifacts, where non-rigid regions corrupt attention propagation between the spatial memory and image feature. By analyzing the internal behaviors of the state and image token updating mechanism, we find that aggregating self-attention maps across layers reveals a consistent pattern: dynamic regions are naturally down-weighted, exposing an implicit motion cue that the pretrained transformer already encodes but never explicitly uses. Motivated by this observation, we introduce MUT3R, a training-free framework that applies the attention-derived motion cue to suppress dynamic content in the early layers of the transformer during inference. Our attention-level gating module suppresses the influence of dynamic regions before their artifacts propagate through the feature hierarchy. Notably, we do not retrain or fine-tune the model; we let the pretrained transformer diagnose its own motion cues and correct itself. This early regulation stabilizes geometric reasoning in streaming scenarios and leads to improvements in temporal consistency and camera pose robustness across multiple dynamic benchmarks, offering a simple and training-free pathway toward motion-aware streaming reconstruction.", "AI": {"tldr": "The paper introduces MUT3R, a training-free framework to suppress motion-induced artifacts in dynamic 3D reconstruction by using internal motion cues within pretrained transformers.", "motivation": "The authors aim to address vulnerabilities in stateful recurrent neural networks for static 3D reconstruction, specifically their weakness to motion-induced artifacts caused by non-rigid regions disrupting attention propagation.", "method": "They analyze self-attention maps in pretrained transformers, revealing that dynamic regions are naturally down-weighted. They utilize this implicit motion cue through an attention-level gating module to suppress dynamic content in the early transformer layers during inference without retraining the model.", "result": "MUT3R improves temporal consistency and camera pose robustness across multiple dynamic benchmarks, stabilizing geometric reasoning for streaming scenarios.", "conclusion": "The framework demonstrates an effective and training-free approach to enhance 3D reconstruction in dynamic scenarios by leveraging pretrained transformer motion cues for early error correction."}}
{"id": "2512.03099", "pdf": "https://arxiv.org/pdf/2512.03099", "abs": "https://arxiv.org/abs/2512.03099", "authors": ["Haribandhu Jena", "Jyotirmaya Shivottam", "Subhankar Mishra"], "title": "QGShap: Quantum Acceleration for Faithful GNN Explanations", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": "Accepted in the QC+AI Workshop at AAAI 2026", "summary": "Graph Neural Networks (GNNs) have become indispensable in critical domains such as drug discovery, social network analysis, and recommendation systems, yet their black-box nature hinders deployment in scenarios requiring transparency and accountability. While Shapley value-based methods offer mathematically principled explanations by quantifying each component's contribution to predictions, computing exact values requires evaluating $2^n$ coalitions (or aggregating over $n!$ permutations), which is intractable for real-world graphs. Existing approximation strategies sacrifice either fidelity or efficiency, limiting their practical utility. We introduce QGShap, a quantum computing approach that leverages amplitude amplification to achieve quadratic speedups in coalition evaluation while maintaining exact Shapley computation. Unlike classical sampling or surrogate methods, our approach provides fully faithful explanations without approximation trade-offs for tractable graph sizes. We conduct empirical evaluations on synthetic graph datasets, demonstrating that QGShap achieves consistently high fidelity and explanation accuracy, matching or exceeding the performance of classical methods across all evaluation metrics. These results collectively demonstrate that QGShap not only preserves exact Shapley faithfulness but also delivers interpretable, stable, and structurally consistent explanations that align with the underlying graph reasoning of GNNs. The implementation of QGShap is available at https://github.com/smlab-niser/qgshap.", "AI": {"tldr": "The paper introduces QGShap, a quantum computing-based method for accelerating Shapley value computation for graph neural networks (GNNs), providing explanations with high fidelity and efficiency.", "motivation": "The black-box nature of Graph Neural Networks (GNNs) limits their deployment in areas requiring interpretability. Current approximation methods for Shapley value explanations either lose accuracy or computational efficiency, addressing the lack of practical solutions for understanding GNN predictions.", "method": "The authors propose QGShap, which utilizes quantum amplitude amplification to achieve quadratic speedups during Shapley value computation for explaining predictions in GNNs. This method maintains exact Shapley computation while ensuring efficiency for certain graph sizes.", "result": "QGShap delivers faithful and accurate Shapley value explanations without the trade-offs common in existing classical methods. Empirical tests on synthetic datasets show QGShap outperforms classical methods in fidelity and explanation accuracy.", "conclusion": "QGShap bridges the gap between transparency and computational practicality in GNNs, offering exact and efficient explanations. Its implementation is publicly accessible, facilitating further adoption and research in interpretable GNNs."}}
{"id": "2512.03173", "pdf": "https://arxiv.org/pdf/2512.03173", "abs": "https://arxiv.org/abs/2512.03173", "authors": ["Joan Nwatu", "Longju Bai", "Oana Ignat", "Rada Mihalcea"], "title": "Culture Affordance Atlas: Reconciling Object Diversity Through Functional Mapping", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Culture shapes the objects people use and for what purposes, yet mainstream Vision-Language (VL) datasets frequently exhibit cultural biases, disproportionately favoring higher-income, Western contexts. This imbalance reduces model generalizability and perpetuates performance disparities, especially impacting lower-income and non-Western communities. To address these disparities, we propose a novel function-centric framework that categorizes objects by the functions they fulfill, across diverse cultural and economic contexts. We implement this framework by creating the Culture Affordance Atlas, a re-annotated and culturally grounded restructuring of the Dollar Street dataset spanning 46 functions and 288 objects publicly available at https://lit.eecs.umich.edu/CultureAffordance-Atlas/index.html. Through extensive empirical analyses using the CLIP model, we demonstrate that function-centric labels substantially reduce socioeconomic performance gaps between high- and low-income groups by a median of 6 pp (statistically significant), improving model effectiveness for lower-income contexts. Furthermore, our analyses reveals numerous culturally essential objects that are frequently overlooked in prominent VL datasets. Our contributions offer a scalable pathway toward building inclusive VL datasets and equitable AI systems.", "AI": {"tldr": "The paper tackles cultural biases in vision-language datasets by proposing a function-centric framework, curating a dataset, and improving model generalizability across socioeconomic contexts.", "motivation": "Mainstream vision-language datasets largely focus on Western, higher-income contexts, creating cultural biases that hinder model generalizability and perpetuate disparities for non-Western and lower-income communities.", "method": "The authors developed the Culture Affordance Atlas by re-annotating the Dollar Street dataset using a function-centric framework. This categorization emphasizes object functions across diverse cultural and economic contexts, and tests the approach using CLIP.", "result": "The function-centric approach reduces socioeconomic performance disparities by a statistically significant median of 6 percentage points and identifies culturally vital objects overlooked in traditional VL datasets.", "conclusion": "Function-centric frameworks can build more inclusive vision-language datasets, leading to equitable AI systems better suited for non-Western and lower-income communities."}}
{"id": "2512.03509", "pdf": "https://arxiv.org/pdf/2512.03509", "abs": "https://arxiv.org/abs/2512.03509", "authors": ["Kwaku Opoku-Ware", "Gideon Opoku"], "title": "AfroBeats Dance Movement Analysis Using Computer Vision: A Proof-of-Concept Framework Combining YOLO and Segment Anything Model", "categories": ["cs.CV"], "comment": null, "summary": "This paper presents a preliminary investigation into automated dance movement analysis using contemporary computer vision techniques. We propose a proof-of-concept framework that integrates YOLOv8 and v11 for dancer detection with the Segment Anything Model (SAM) for precise segmentation, enabling the tracking and quantification of dancer movements in video recordings without specialized equipment or markers. Our approach identifies dancers within video frames, counts discrete dance steps, calculates spatial coverage patterns, and measures rhythm consistency across performance sequences. Testing this framework on a single 49-second recording of Ghanaian AfroBeats dance demonstrates technical feasibility, with the system achieving approximately 94% detection precision and 89% recall on manually inspected samples. The pixel-level segmentation provided by SAM, achieving approximately 83% intersection-over-union with visual inspection, enables motion quantification that captures body configuration changes beyond what bounding-box approaches can represent. Analysis of this preliminary case study indicates that the dancer classified as primary by our system executed 23% more steps with 37% higher motion intensity and utilized 42% more performance space compared to dancers classified as secondary. However, this work represents an early-stage investigation with substantial limitations including single-video validation, absence of systematic ground truth annotations, and lack of comparison with existing pose estimation methods. We present this framework to demonstrate technical feasibility, identify promising directions for quantitative dance metrics, and establish a foundation for future systematic validation studies.", "AI": {"tldr": "The paper explores automated dance movement analysis using computer vision by combining YOLO models and SAM for dancer detection and segmentation. Tests on AfroBeats dance video show promising results.", "motivation": "The motivation is to create a proof-of-concept framework for analyzing dance movements quantitatively without specialized equipment or markers.", "method": "It combines YOLOv8/v11 models for dancer detection with SAM for segmentation. Metrics like step count, spatial pattern, and rhythm consistency are calculated through video analysis.", "result": "Using a 49-second AfroBeats dance video, the system achieved 94% detection precision, 89% recall, and 83% IoU in segmentation. It provided detailed movement analysis for primary and secondary dancers.", "conclusion": "This framework demonstrates feasibility in analyzing dance movements, though limitations such as single-video validation and lack of ground truth data persist, offering opportunities for future validation studies."}}
{"id": "2512.03324", "pdf": "https://arxiv.org/pdf/2512.03324", "abs": "https://arxiv.org/abs/2512.03324", "authors": ["Ngoc Bui", "Shubham Sharma", "Simran Lamba", "Saumitra Mishra", "Rex Ying"], "title": "Cache What Lasts: Token Retention for Memory-Bounded KV Cache in LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Memory and computation remain core bottlenecks in long-horizon LLM inference due to the quadratic cost of self-attention and the ever-growing key-value (KV) cache. Existing strategies for memory-bounded inference, such as quantization, offloading, or heuristic KV eviction, either incur high orchestration costs or rely on unreliable attention-based proxies of importance. We propose TRIM-KV, a novel approach that learns each token's intrinsic importance at creation time via a lightweight retention gate. Each gate predicts a scalar retention score that decays over time, reflecting the long-term utility of the token for a specific layer and head. Tokens with low scores are evicted when the memory budget is exceeded, ensuring that the cache always contains the most critical tokens. TRIM-KV is trained efficiently through distillation from a frozen LLM combined with a capacity loss, requiring only gate fine-tuning and adding negligible inference overhead. Across mathematical reasoning (GSM8K, MATH-500, AIME24), procedural generation (LongProc), conversational long-memory benchmarks (LongMemEval), and long-context understanding (LongBench and SCBench), TRIM-KV consistently outperforms strong eviction and learnable retrieval baselines, especially in low-memory regimes. Remarkably, it even surpasses full-cache models in some settings, showing that selective retention can serve as a form of regularization, suppressing noise from uninformative tokens. Qualitative analyses further reveal that learned retention scores align with human intuition, naturally recovering heuristics such as sink tokens, sliding windows, and gist compression without explicit design. Beyond efficiency, retention scores provide insights into layer- and head-specific roles, suggesting a new path toward LLM interpretability.", "AI": {"tldr": "The paper introduces TRIM-KV, a method to optimize memory usage in long-horizon LLMs by evicting low-importance tokens from the key-value cache using learned retention scores, outperforming other methods in low-memory regimes.", "motivation": "Current LLMs face challenges in memory and computation during inference due to the quadratic cost of self-attention and increasing key-value cache size, which existing solutions fail to address efficiently.", "method": "TRIM-KV uses a retention gate that assigns tokens a scalar retention score at creation. These scores decay over time, and tokens with low scores are evicted to maintain memory efficiency. It is trained via distillation with negligible inference overhead.", "result": "TRIM-KV achieves superior performance on various reasoning, procedural generation, conversational memory, and long-context understanding tasks, outperforming baselines and even full-cache models in some cases.", "conclusion": "TRIM-KV offers a new approach to efficient memory management and LLM interpretability by selectively retaining critical tokens and providing insights into the model's specific roles at different layers and heads."}}
{"id": "2512.03945", "pdf": "https://arxiv.org/pdf/2512.03945", "abs": "https://arxiv.org/abs/2512.03945", "authors": ["Michael Schiffmann", "Sabina Jeschke", "Anja Richert"], "title": "Classification of User Satisfaction in HRI with Social Signals in the Wild", "categories": ["cs.HC", "cs.RO"], "comment": "15 pages, 3 figures. This paper has been accepted for publication at ICSR+AI 2025", "summary": "Socially interactive agents (SIAs) are being used in various scenarios and are nearing productive deployment. Evaluating user satisfaction with SIAs' performance is a key factor in designing the interaction between the user and SIA. Currently, subjective user satisfaction is primarily assessed manually through questionnaires or indirectly via system metrics. This study examines the automatic classification of user satisfaction through analysis of social signals, aiming to enhance both manual and autonomous evaluation methods for SIAs. During a field trial at the Deutsches Museum Bonn, a Furhat Robotics head was employed as a service and information hub, collecting an \"in-the-wild\" dataset. This dataset comprises 46 single-user interactions, including questionnaire responses and video data. Our method focuses on automatically classifying user satisfaction based on time series classification. We use time series of social signal metrics derived from the body pose, time series of facial expressions, and physical distance. This study compares three feature engineering approaches on different machine learning models. The results confirm the method's effectiveness in reliably identifying interactions with low user satisfaction without the need for manually annotated datasets. This approach offers significant potential for enhancing SIA performance and user experience through automated feedback mechanisms.", "AI": {"tldr": "The study explores automatic classification of user satisfaction with Socially Interactive Agents (SIAs) through analysis of social signals, using data collected in real-world interactions.", "motivation": "To improve the evaluation of user satisfaction with SIAs autonomously and reduce reliance on manual methods like questionnaires.", "method": "Employing automatic user satisfaction classification using time series of social signals including body pose, facial expressions, and physical distance, tested on different machine learning models and feature engineering approaches.", "result": "The method effectively identifies interactions with low user satisfaction without the need for manually annotated datasets.", "conclusion": "The approach can enhance SIA performance and user experience through automated user satisfaction assessment mechanisms."}}
{"id": "2512.03100", "pdf": "https://arxiv.org/pdf/2512.03100", "abs": "https://arxiv.org/abs/2512.03100", "authors": ["Haowei Fu", "Bo Ni", "Han Xu", "Kunpeng Liu", "Dan Lin", "Tyler Derr"], "title": "Ensemble Privacy Defense for Knowledge-Intensive LLMs against Membership Inference Attacks", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) and Supervised Finetuning (SFT) have become the predominant paradigms for equipping Large Language Models (LLMs) with external knowledge for diverse, knowledge-intensive tasks. However, while such knowledge injection improves performance, it also exposes new attack surfaces. Membership Inference Attacks (MIAs), which aim to determine whether a given data sample was included in a model's training set, pose serious threats to privacy and trust in sensitive domains. To this end, we first systematically evaluate the vulnerability of RAG- and SFT-based LLMs to various MIAs. Then, to address the privacy risk, we further introduce a novel, model-agnostic defense framework, Ensemble Privacy Defense (EPD), which aggregates and evaluates the outputs of a knowledge-injected LLM, a base LLM, and a dedicated judge model to enhance resistance against MIAs. Comprehensive experiments show that, on average, EPD reduces MIA success by up to 27.8\\% for SFT and 526.3\\% for RAG compared to inference-time baseline, while maintaining answer quality.", "AI": {"tldr": "The paper evaluates the vulnerabilities of knowledge-injected large language models to Membership Inference Attacks and proposes a model-agnostic defense framework called Ensemble Privacy Defense (EPD).", "motivation": "The motivation was to address the privacy and trust concerns posed by Membership Inference Attacks in Large Language Models that incorporate external knowledge through Retrieval-Augmented Generation and Supervised Finetuning.", "method": "The authors systematically evaluate the vulnerability of models to Membership Inference Attacks and propose the Ensemble Privacy Defense (EPD) framework, which uses a knowledge-injected LLM, a base LLM, and a judge model to increase resistance to such attacks.", "result": "The proposed Ensemble Privacy Defense (EPD) framework reduces Membership Inference Attack success by up to 27.8% for SFT and 526.3% for RAG while maintaining high-quality responses.", "conclusion": "The study highlights the privacy risks in knowledge-injected LLMs and demonstrates that the Ensemble Privacy Defense framework provides robust defense against Membership Inference Attacks, balancing security and answer quality."}}
{"id": "2512.03991", "pdf": "https://arxiv.org/pdf/2512.03991", "abs": "https://arxiv.org/abs/2512.03991", "authors": ["Michael Schiffmann", "Felix Struth", "Sabina Jeschke", "Anja Richert"], "title": "When to Say \"Hi\" - Learn to Open a Conversation with an in-the-wild Dataset", "categories": ["cs.HC", "cs.RO"], "comment": "6 pages, 3 figures, 5 tables. This paper has been accepted for publication at IEEE ROMAN 2025", "summary": "The social capabilities of socially interactive agents (SIA) are a key to successful and smooth interactions between the user and the SIA. A successful start of the interaction is one of the essential factors for satisfying SIA interactions. For a service and information task in which the SIA helps with information, e.g. about the location, it is an important skill to master the opening of the conversation and to recognize which interlocutor opens the conversation and when. We are therefore investigating the extent to which the opening of the conversation can be trained using the user's body language as an input for machine learning to ensure smooth conversation starts for the interaction. In this paper we propose the Interaction Initiation System (IIS) which we developed, trained and validated using an in-the-wild data set. In a field test at the Deutsches Museum Bonn, a Furhat robot from Furhat Robotics was used as a service and information point. Over the period of use we collected the data of \\textit{N} = 201 single user interactions for the training of the algorithms. We can show that the IIS, achieves a performance that allows the conclusion that this system is able to determine the greeting period and the opener of the interaction.", "AI": {"tldr": "The paper introduces the Interaction Initiation System (IIS), leveraging body language to train a socially interactive agent (SIA) for effective conversation openings.", "motivation": "To improve the conversational capabilities of socially interactive agents (SIA) by ensuring smooth conversation starts, addressing the critical aspect of determining when and how interactions should begin.", "method": "Developed and validated a system called the Interaction Initiation System (IIS) using machine learning with body language data collected through in-the-wild experimentations and a field test involving 201 user interactions at Deutsches Museum Bonn.", "result": "The developed system successfully identifies the greeting period and the initiator of the interaction, demonstrating practical applicability.", "conclusion": "The IIS effectively enhances the ability of SIA to engage in smooth social interactions by accurately predicting conversation initiation dynamics."}}
{"id": "2512.03520", "pdf": "https://arxiv.org/pdf/2512.03520", "abs": "https://arxiv.org/abs/2512.03520", "authors": ["Yiyi Cai", "Yuhan Wu", "Kunhang Li", "You Zhou", "Bo Zheng", "Haiyang Liu"], "title": "FloodDiffusion: Tailored Diffusion Forcing for Streaming Motion Generation", "categories": ["cs.CV"], "comment": "15 pages, 7 figures", "summary": "We present FloodDiffusion, a new framework for text-driven, streaming human motion generation. Given time-varying text prompts, FloodDiffusion generates text-aligned, seamless motion sequences with real-time latency. Unlike existing methods that rely on chunk-by-chunk or auto-regressive model with diffusion head, we adopt a diffusion forcing framework to model this time-series generation task under time-varying control events. We find that a straightforward implementation of vanilla diffusion forcing (as proposed for video models) fails to model real motion distributions. We demonstrate that to guarantee modeling the output distribution, the vanilla diffusion forcing must be tailored to: (i) train with a bi-directional attention instead of casual attention; (ii) implement a lower triangular time scheduler instead of a random one; (iii) utilize a continues time-varying way to introduce text conditioning. With these improvements, we demonstrate in the first time that the diffusion forcing-based framework achieves state-of-the-art performance on the streaming motion generation task, reaching an FID of 0.057 on the HumanML3D benchmark. Models, code, and weights are available. https://shandaai.github.io/FloodDiffusion/", "AI": {"tldr": "FloodDiffusion is a novel framework for generating streaming human motion in real-time based on evolving text prompts, achieving state-of-the-art performance with new improvements to diffusion forcing.", "motivation": "To address limitations in existing chunk-based or auto-regressive motion generation methods, particularly in achieving real-time text-driven seamless motion streams with accurate distribution modeling.", "method": "The paper introduces diffusion forcing for time-series motion generation. Key improvements include bi-directional attention, a lower triangular scheduler, and continuous text conditioning for generating realistic human motion.", "result": "The framework outperforms existing methods, achieving an FID of 0.057 on the HumanML3D benchmark, marking significant progress in real-time, text-driven motion generation.", "conclusion": "FloodDiffusion is effective for seamless, real-time streaming motion generation driven by text, supported by a robust diffusion forcing framework. Its source code and models are publicly available."}}
{"id": "2512.04069", "pdf": "https://arxiv.org/pdf/2512.04069", "abs": "https://arxiv.org/abs/2512.04069", "authors": ["Siyi Chen", "Mikaela Angelina Uy", "Chan Hee Song", "Faisal Ladhak", "Adithyavairavan Murali", "Qing Qu", "Stan Birchfield", "Valts Blukis", "Jonathan Tremblay"], "title": "SpaceTools: Tool-Augmented Spatial Reasoning via Double Interactive RL", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Vision Language Models (VLMs) demonstrate strong qualitative visual understanding, but struggle with metrically precise spatial reasoning required for embodied applications. The agentic paradigm promises that VLMs can use a wide variety of tools that could augment these capabilities, such as depth estimators, segmentation models, and pose estimators. Yet it remains an open challenge how to realize this vision without solely relying on handcrafted prompting strategies or enforcing fixed, predefined tool pipelines that limit VLMs' ability to discover optimal tool-use patterns. Reinforcement Learning could overcome this gap, but has so far been limited to reasoning with a single visual tool due to the large search space in multi-tool reasoning. We introduce Double Interactive Reinforcement Learning (DIRL), a two-phase training framework where VLMs learn to coordinate multiple tools through interactive exploration and feedback. In the teaching phase, we combine demonstrations from a single tool specialist trained via interactive RL with traces from a frontier model using all tools. In the exploration phase, the model further refines multi-tool coordination through continued RL. Our model, SpaceTools, with tool-augmented spatial reasoning ability, achieves state-of-the-art performance on spatial understanding benchmarks (RoboSpatial-Home, BLINK, BOP-ASK) and demonstrates reliable real-world manipulation using a 7-DOF robot as a tool. DIRL provides substantial improvements over the vanilla SFT (+12% on RoboSpatial) and RL (+16% on RoboSpatial) baselines. Project page: https://spacetools.github.io/.", "AI": {"tldr": "This paper introduces Double Interactive Reinforcement Learning (DIRL), a framework tailoring Vision Language Models (VLMs) for spatial reasoning by enabling them to learn to coordinate multiple tools interactively, achieving superior performance on benchmarks and real-world manipulation tasks.", "motivation": "VLMs, while effective in qualitative visual understanding, struggle with precise spatial reasoning essential in embodied applications. Traditional approaches relying on predefined pipelines or handcrafted prompts limit flexibility, and there is a need for a framework to facilitate multi-tool reasoning and discovery.", "method": "The authors propose DIRL, a two-phase training approach: a teaching phase using demonstrations and feedback from both single-tool specialist RL models and frontier multi-tool models, followed by an exploration phase with further RL for refining tool coordination.", "result": "The proposed model, SpaceTools, achieved state-of-the-art performance on spatial understanding tasks such as RoboSpatial-Home, BLINK, and BOP-ASK. It improved over vanilla SFT and RL baselines by 12% and 16% respectively and performed reliable physical manipulation using a robotic arm.", "conclusion": "DIRL enhances VLMs' spatial reasoning by enabling effective multi-tool coordination through RL. It offers substantial performance improvements, demonstrating the potential of interactive learning for embodied AI applications."}}
{"id": "2512.03337", "pdf": "https://arxiv.org/pdf/2512.03337", "abs": "https://arxiv.org/abs/2512.03337", "authors": ["Aliakbar Mehdizadeh", "Martin Hilbert"], "title": "Epistemic Substitution: How Grokipedia's AI-Generated Encyclopedia Restructures Authority", "categories": ["cs.SI", "cs.CL", "cs.CY", "cs.DL"], "comment": null, "summary": "A quarter century ago, Wikipedia's decentralized, crowdsourced, and consensus-driven model replaced the centralized, expert-driven, and authority-based standard for encyclopedic knowledge curation. The emergence of generative AI encyclopedias, such as Grokipedia, possibly presents another potential shift in epistemic evolution. This study investigates whether AI- and human-curated encyclopedias rely on the same foundations of authority. We conducted a multi-scale comparative analysis of the citation networks from 72 matched article pairs, which cite a total of almost 60,000 sources. Using an 8-category epistemic classification, we mapped the \"epistemic profiles\" of the articles on each platform. Our findings reveal several quantitative and qualitative differences in how knowledge is sourced and encyclopedia claims are epistemologically justified. Grokipedia replaces Wikipedia's heavy reliance on peer-reviewed \"Academic & Scholarly\" work with a notable increase in \"User-generated\" and \"Civic organization\" sources. Comparative network analyses further show that Grokipedia employs very different epistemological profiles when sourcing leisure topics (such as Sports and Entertainment) and more societal sensitive civic topics (such as Politics & Conflicts, Geographical Entities, and General Knowledge & Society). Finally, we find a \"scaling-law for AI-generated knowledge sourcing\" that shows a linear relationship between article length and citation density, which is distinct from collective human reference sourcing. We conclude that this first implementation of an LLM-based encyclopedia does not merely automate knowledge production but restructures it. Given the notable changes and the important role of encyclopedias, we suggest the continuation and deepening of algorithm audits, such as the one presented here, in order to understand the ongoing epistemological shifts.", "AI": {"tldr": "This paper compares the epistemic structures of AI-curated encyclopedia Grokipedia with Wikipedia, revealing shifts in sourcing and citation practices.", "motivation": "To investigate whether AI-curated encyclopedias like Grokipedia rely on the same foundations of epistemic authority as human-curated Wikipedia.", "method": "Analyzed citation networks and epistemic profiles of 72 matched articles from both Grokipedia and Wikipedia, encompassing nearly 60,000 citations, using an 8-category epistemic classification.", "result": "Grokipedia shows reduced reliance on 'Academic & Scholarly' sources while increasing 'User-generated' and 'Civic organization' sourcing. Citation density in AI-generated articles scales linearly with article length, marking a deviation from human-generated content patterns.", "conclusion": "Grokipedia restructures knowledge production through different epistemological mechanisms compared to Wikipedia. Continuous auditing of AI-generated encyclopedias is recommended to understand their impact on epistemology."}}
{"id": "2512.03532", "pdf": "https://arxiv.org/pdf/2512.03532", "abs": "https://arxiv.org/abs/2512.03532", "authors": ["Zhishan Zhou", "Siyuan Wei", "Zengran Wang", "Chunjie Wang", "Xiaosheng Yan", "Xiao Liu"], "title": "OpenTrack3D: Towards Accurate and Generalizable Open-Vocabulary 3D Instance Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Generalizing open-vocabulary 3D instance segmentation (OV-3DIS) to diverse, unstructured, and mesh-free environments is crucial for robotics and AR/VR, yet remains a significant challenge. We attribute this to two key limitations of existing methods: (1) proposal generation relies on dataset-specific proposal networks or mesh-based superpoints, rendering them inapplicable in mesh-free scenarios and limiting generalization to novel scenes; and (2) the weak textual reasoning of CLIP-based classifiers, which struggle to recognize compositional and functional user queries. To address these issues, we introduce OpenTrack3D, a generalizable and accurate framework. Unlike methods that rely on pre-generated proposals, OpenTrack3D employs a novel visual-spatial tracker to construct cross-view consistent object proposals online. Given an RGB-D stream, our pipeline first leverages a 2D open-vocabulary segmenter to generate masks, which are lifted to 3D point clouds using depth. Mask-guided instance features are then extracted using DINO feature maps, and our tracker fuses visual and spatial cues to maintain instance consistency. The core pipeline is entirely mesh-free, yet we also provide an optional superpoints refinement module to further enhance performance when scene mesh is available. Finally, we replace CLIP with a multi-modal large language model (MLLM), significantly enhancing compositional reasoning for complex user queries. Extensive experiments on diverse benchmarks, including ScanNet200, Replica, ScanNet++, and SceneFun3D, demonstrate state-of-the-art performance and strong generalization capabilities.", "AI": {"tldr": "OpenTrack3D is introduced as a generalizable and accurate framework for open-vocabulary 3D instance segmentation (OV-3DIS) in diverse and unstructured environments, advancing beyond existing limitations with innovative tracking and multi-modal language capabilities.", "motivation": "The motivation is rooted in overcoming the limitations of current methods for OV-3DIS, which struggle in mesh-free and diverse scenes due to their dependence on dataset-specific proposal networks and weak textual reasoning capabilities.", "method": "OpenTrack3D employs an online visual-spatial tracker to construct cross-view consistent object proposals without relying on pre-generated proposals. It leverages a 2D open-vocabulary segmenter for mask generation, converts these into 3D point clouds with depth, and fuses visual and spatial data for instance consistency. The pipeline is mesh-free but incorporates an optional superpoints refinement module. It replaces CLIP-based classifiers with a multi-modal large language model for better compositional reasoning.", "result": "Experiments on benchmarks such as ScanNet200, Replica, ScanNet++, and SceneFun3D reveal that OpenTrack3D achieves state-of-the-art performance and demonstrates robust generalization skills.", "conclusion": "OpenTrack3D offers a breakthrough in OV-3DIS by addressing key challenges with a novel tracking framework and improved language model integration, enabling effective segmentation in complex and diverse 3D environments."}}
{"id": "2512.03363", "pdf": "https://arxiv.org/pdf/2512.03363", "abs": "https://arxiv.org/abs/2512.03363", "authors": ["Shanika Iroshi Nanayakkara", "Shiva Raj Pokhrel"], "title": "A2G-QFL: Adaptive Aggregation with Two Gains in Quantum Federated learning", "categories": ["cs.LG", "quant-ph"], "comment": "8 pages, 4 figures, QCNC 2026", "summary": "Federated learning (FL) deployed over quantum enabled and heterogeneous classical networks faces significant performance degradation due to uneven client quality, stochastic teleportation fidelity, device instability, and geometric mismatch between local and global models. Classical aggregation rules assume euclidean topology and uniform communication reliability, limiting their suitability for emerging quantum federated systems. This paper introduces A2G (Adaptive Aggregation with Two Gains), a dual gain framework that jointly regulates geometric blending through a geometry gain and modulates client importance using a QoS gain derived from teleportation fidelity, latency, and instability. We develop the A2G update rule, establish convergence guarantees under smoothness and bounded variance assumptions, and show that A2G recovers FedAvg, QoS aware averaging, and manifold based aggregation as special cases. Experiments on a quantum classical hybrid testbed demonstrate improved stability and higher accuracy under heterogeneous and noisy conditions.", "AI": {"tldr": "This paper introduces A2G, an adaptive aggregation framework for improving federated learning in quantum-classical networks, addressing uneven client quality and device instability.", "motivation": "Current classical aggregation techniques are unsuitable for quantum-enabled federated systems due to performance issues caused by heterogeneous networks and unique quantum challenges like teleportation fidelity and instability.", "method": "The paper proposes the A2G update rule, incorporating geometry gain and QoS gain for adaptive aggregation. It ensures convergence under specific mathematical assumptions and unifies several aggregation strategies.", "result": "Experiments on a hybrid testbed demonstrated that A2G achieves better model stability and accuracy under noisy and heterogeneous conditions.", "conclusion": "A2G provides a robust adaptive framework that improves aggregation in quantum-classical federated learning, enhancing its practicality and reliability in emerging communication systems."}}
{"id": "2512.03103", "pdf": "https://arxiv.org/pdf/2512.03103", "abs": "https://arxiv.org/abs/2512.03103", "authors": ["Shampa Saha", "Shovan Roy"], "title": "Public Sentiment Analysis of Traffic Management Policies in Knoxville: A Social Media Driven Study", "categories": ["cs.SI", "cs.AI"], "comment": null, "summary": "This study presents a comprehensive analysis of public sentiment toward traffic management policies in Knoxville, Tennessee, utilizing social media data from Twitter and Reddit platforms. We collected and analyzed 7906 posts spanning January 2022 to December 2023, employing Valence Aware Dictionary and sEntiment Reasoner (VADER) for sentiment analysis and Latent Dirichlet Allocation (LDA) for topic modeling. Our findings reveal predominantly negative sentiment, with significant variations across platforms and topics. Twitter exhibited more negative sentiment compared to Reddit. Topic modeling identified six distinct themes, with construction-related topics showing the most negative sentiment while general traffic discussions were more positive. Spatiotemporal analysis revealed geographic and temporal patterns in sentiment expression. The research demonstrates social media's potential as a real-time public sentiment monitoring tool for transportation planning and policy evaluation.", "AI": {"tldr": "The paper analyzes public sentiment on traffic policies in Knoxville using social media data, finding mostly negative opinions through sentiment analysis and identifying distinct themes and patterns.", "motivation": "This research aims to leverage social media data to better understand public sentiment toward traffic management policies, aiding transportation planning and policy evaluation.", "method": "The study analyzed 7906 social media posts from Twitter and Reddit using VADER for sentiment analysis and LDA for topic modeling, coupled with spatiotemporal analysis.", "result": "The study found predominantly negative sentiment with variations across platforms and topics, identifying six themes and temporal-spatial patterns in sentiment.", "conclusion": "Social media proves valuable for real-time public sentiment monitoring, offering insights into transportation policy impacts and aiding in designing better policies."}}
{"id": "2512.03373", "pdf": "https://arxiv.org/pdf/2512.03373", "abs": "https://arxiv.org/abs/2512.03373", "authors": ["Elyas Meguellati", "Stefano Civelli", "Lei Han", "Abraham Bernstein", "Shazia Sadiq", "Gianluca Demartini"], "title": "LLM-Generated Ads: From Personalization Parity to Persuasion Superiority", "categories": ["cs.CY", "cs.CL"], "comment": null, "summary": "As large language models (LLMs) become increasingly capable of generating persuasive content, understanding their effectiveness across different advertising strategies becomes critical. This paper presents a two-part investigation examining LLM-generated advertising through complementary lenses: (1) personality-based and (2) psychological persuasion principles.\n  In our first study (n=400), we tested whether LLMs could generate personalized advertisements tailored to specific personality traits (openness and neuroticism) and how their performance compared to human experts. Results showed that LLM-generated ads achieved statistical parity with human-written ads (51.1% vs. 48.9%, p > 0.05), with no significant performance differences for matched personalities.\n  Building on these insights, our second study (n=800) shifted focus from individual personalization to universal persuasion, testing LLM performance across four foundational psychological principles: authority, consensus, cognition, and scarcity. AI-generated ads significantly outperformed human-created content, achieving a 59.1% preference rate (vs. 40.9%, p < 0.001), with the strongest performance in authority (63.0%) and consensus (62.5%) appeals. Qualitative analysis revealed AI's advantage stems from crafting more sophisticated, aspirational messages and achieving superior visual-narrative coherence. Critically, this quality advantage proved robust: even after applying a 21.2 percentage point detection penalty when participants correctly identified AI-origin, AI ads still outperformed human ads, and 29.4% of participants chose AI content despite knowing its origin. These findings demonstrate LLMs' evolution from parity in personalization to superiority in persuasive storytelling, with significant implications for advertising practice given LLMs' near-zero marginal cost and time requirements compared to human experts.", "AI": {"tldr": "This paper investigates the effectiveness of LLMs in generating persuasive content, showing they match human experts in personalized advertising and surpass them in universal persuasion strategies.", "motivation": "With LLMs being increasingly used in generating marketing content, it is crucial to understand their ability to produce effective advertising across strategies.", "method": "The study included two parts: (1) testing LLMs on generating personality-specific advertisements and comparing with human performance, and (2) evaluating LLM effectiveness using psychological persuasion principles.", "result": "LLMs achieved parity with human experts in personality-focused ads (51.1% vs. 48.9%) and outperformed in persuasion strategies (59.1% vs. 40.9%), even with an identification penalty for AI-origin content.", "conclusion": "LLMs exhibit parity in personalized advertising with humans and excel in universal persuasion with lower costs, positioning themselves as transformative tools in advertising."}}
{"id": "2512.03534", "pdf": "https://arxiv.org/pdf/2512.03534", "abs": "https://arxiv.org/abs/2512.03534", "authors": ["Subin Kim", "Sangwoo Mo", "Mamshad Nayeem Rizve", "Yiran Xu", "Difan Liu", "Jinwoo Shin", "Tobias Hinz"], "title": "Rethinking Prompt Design for Inference-time Scaling in Text-to-Visual Generation", "categories": ["cs.CV", "cs.AI"], "comment": "Visualizations are available at the website: https://subin-kim-cv.github.io/PRIS", "summary": "Achieving precise alignment between user intent and generated visuals remains a central challenge in text-to-visual generation, as a single attempt often fails to produce the desired output. To handle this, prior approaches mainly scale the visual generation process (e.g., increasing sampling steps or seeds), but this quickly leads to a quality plateau. This limitation arises because the prompt, crucial for guiding generation, is kept fixed. To address this, we propose Prompt Redesign for Inference-time Scaling, coined PRIS, a framework that adaptively revises the prompt during inference in response to the scaled visual generations. The core idea of PRIS is to review the generated visuals, identify recurring failure patterns across visuals, and redesign the prompt accordingly before regenerating the visuals with the revised prompt. To provide precise alignment feedback for prompt revision, we introduce a new verifier, element-level factual correction, which evaluates the alignment between prompt attributes and generated visuals at a fine-grained level, achieving more accurate and interpretable assessments than holistic measures. Extensive experiments on both text-to-image and text-to-video benchmarks demonstrate the effectiveness of our approach, including a 15% gain on VBench 2.0. These results highlight that jointly scaling prompts and visuals is key to fully leveraging scaling laws at inference-time. Visualizations are available at the website: https://subin-kim-cv.github.io/PRIS.", "AI": {"tldr": "The paper introduces a novel method, PRIS, to improve text-to-visual generation by adaptively revising prompts during inference, achieving better alignment between user intent and generated visuals.", "motivation": "Current text-to-visual generation struggles to align user intent with generated visuals since fixed prompts lead to quality limitations despite scaling generation steps or seeds.", "method": "The proposed method, PRIS, identifies failure patterns in generated visuals, revises prompts accordingly, and regenerates visuals. A new element-level factual correction verifier is introduced for fine-grained alignment feedback.", "result": "Experiments show PRIS significantly improves text-to-image and text-to-video generation, including a 15% performance improvement on VBench 2.0.", "conclusion": "Scaling both prompts and visuals during inference maximizes the effectiveness of scaling laws, addressing the limitations of fixed-prompt approaches in text-to-visual generation."}}
{"id": "2512.03375", "pdf": "https://arxiv.org/pdf/2512.03375", "abs": "https://arxiv.org/abs/2512.03375", "authors": ["Mahdi Arab Loodaricheh", "Mohammad Hossein Manshaei", "Anita Raja"], "title": "MAGE-ID: A Multimodal Generative Framework for Intrusion Detection Systems", "categories": ["cs.LG"], "comment": null, "summary": "Modern Intrusion Detection Systems (IDS) face severe challenges due to heterogeneous network traffic, evolving cyber threats, and pronounced data imbalance between benign and attack flows. While generative models have shown promise in data augmentation, existing approaches are limited to single modalities and fail to capture cross-domain dependencies. This paper introduces MAGE-ID (Multimodal Attack Generator for Intrusion Detection), a diffusion-based generative framework that couples tabular flow features with their transformed images through a unified latent prior. By jointly training Transformer and CNN-based variational encoders with an EDM style denoiser, MAGE-ID achieves balanced and coherent multimodal synthesis. Evaluations on CIC-IDS-2017 and NSL-KDD demonstrate significant improvements in fidelity, diversity, and downstream detection performance over TabSyn and TabDDPM, highlighting the effectiveness of MAGE-ID for multimodal IDS augmentation.", "AI": {"tldr": "This paper proposes MAGE-ID, a multimodal generative framework to improve intrusion detection systems (IDS) by addressing data imbalance and heterogeneity challenges.", "motivation": "The paper addresses challenges in modern IDS, such as heterogeneous network traffic, evolving cyber threats, and data imbalance between benign and attack flows.", "method": "MAGE-ID employs a diffusion-based generative model combining tabular features and transformed images through unified latent priors. It uses Transformer and CNN-based variational encoders with an EDM style denoiser for multimodal synthesis.", "result": "MAGE-ID demonstrated improved fidelity, diversity, and detection performance on CIC-IDS-2017 and NSL-KDD datasets compared to existing methods (TabSyn and TabDDPM).", "conclusion": "MAGE-ID effectively enhances multimodal data augmentation for IDS, improving detection accuracy while addressing cross-domain dependencies and data heterogeneity."}}
{"id": "2512.03540", "pdf": "https://arxiv.org/pdf/2512.03540", "abs": "https://arxiv.org/abs/2512.03540", "authors": ["Ruoxuan Zhang", "Bin Wen", "Hongxia Xie", "Yi Yao", "Songhan Zuo", "Jian-Yu Jiang-Lin", "Hong-Han Shuai", "Wen-Huang Cheng"], "title": "CookAnything: A Framework for Flexible and Consistent Multi-Step Recipe Image Generation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ACM Multimedia 2025", "summary": "Cooking is a sequential and visually grounded activity, where each step such as chopping, mixing, or frying carries both procedural logic and visual semantics. While recent diffusion models have shown strong capabilities in text-to-image generation, they struggle to handle structured multi-step scenarios like recipe illustration. Additionally, current recipe illustration methods are unable to adjust to the natural variability in recipe length, generating a fixed number of images regardless of the actual instructions structure. To address these limitations, we present CookAnything, a flexible and consistent diffusion-based framework that generates coherent, semantically distinct image sequences from textual cooking instructions of arbitrary length. The framework introduces three key components: (1) Step-wise Regional Control (SRC), which aligns textual steps with corresponding image regions within a single denoising process; (2) Flexible RoPE, a step-aware positional encoding mechanism that enhances both temporal coherence and spatial diversity; and (3) Cross-Step Consistency Control (CSCC), which maintains fine-grained ingredient consistency across steps. Experimental results on recipe illustration benchmarks show that CookAnything performs better than existing methods in training-based and training-free settings. The proposed framework supports scalable, high-quality visual synthesis of complex multi-step instructions and holds significant potential for broad applications in instructional media, and procedural content creation.", "AI": {"tldr": "CookAnything is a framework that generates coherent cooking sequence images from textual instructions, solving limitations of existing models in structured multi-step scenarios.", "motivation": "Existing models struggle to generate structured, multi-step visual sequences and cannot handle variable recipe lengths, limiting their use in visually-grounded tasks like recipe illustration.", "method": "The framework includes three innovations: Step-wise Regional Control (SRC), Flexible RoPE for step-aware positional encoding, and Cross-Step Consistency Control (CSCC), ensuring coherent, semantically distinct, and consistent image sequences.", "result": "CookAnything outperforms existing methods in recipe illustration benchmarks, demonstrating superior quality in both training-based and training-free scenarios.", "conclusion": "CookAnything provides a scalable and flexible solution for visually-grounded step-by-step content creation and has broad applications in instructional media."}}
{"id": "2512.03383", "pdf": "https://arxiv.org/pdf/2512.03383", "abs": "https://arxiv.org/abs/2512.03383", "authors": ["Hung-Yueh Chiang", "Chi-Chih Chang", "Yu-Chen Lu", "Chien-Yu Lin", "Kai-Chiang Wu", "Mohamed S. Abdelfattah", "Diana Marculescu"], "title": "UniQL: Unified Quantization and Low-rank Compression for Adaptive Edge LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deploying large language model (LLM) models on mobile platforms faces significant challenges due to the limited memory and shared computational resources of the device. Resource availability may be an issue as it is directly impacted by the current device workload, adding to the uncertainty of model deployment. We introduce UniQL, a unified post-training quantization and low-rank compression framework with on-device configurable pruning rates for edge LLMs. UniQL is a general framework that integrates quantization and low-rank compression for Transformers, State Space Models (SSMs), and hybrid models to support diverse edge applications. In our proposed joint framework, we introduce an efficient structured weight-sorting method that speeds up computation by 20x, quantization-aware singular value decomposition (SVD) to minimize quantization errors, state-aware weight sorting for SSMs, and a fused rotary positional embedding (RoPE) kernel for pruned models. Our framework performs weight-sorting, fine-tuning, and quantization in the cloud in a single-pass workflow, while enabling on-device configurable pruning rates up to 35%. Our experiments show that quantized and pruned models achieve a memory reduction of 4x-5.7x and a token-throughput improvement of 2.7x-3.4x, maintaining accuracy within 5% of the original models at 15% pruning across Transformers (Llama3 and Qwen2.5), SSMs (Mamba2), and hybrid models (Nemotron-H and Bamba-v2). The code and quantized models are available at: https://github.com/enyac-group/UniQL.", "AI": {"tldr": "The paper tackles challenges in deploying large language models (LLMs) on mobile platforms due to limited device resources. It introduces UniQL, a framework combining quantization and low-rank compression techniques to make LLMs efficient for edge devices.", "motivation": "To address issues of limited memory, shared computational resources, and dynamic device workloads that complicate deploying LLMs efficiently on mobile devices.", "method": "The authors propose UniQL, a unified framework incorporating techniques like structured weight sorting, quantization-aware SVD, and configurable pruning rates. It operates via a cloud-based single-pass workflow for preparing models that are later optimized on-device.", "result": "The UniQL method reduces memory usage by 4x-5.7x, enhances token throughput by 2.7x-3.4x, and maintains model accuracy within 5% even with 15% pruning, tested across various Transformer, SSM, and hybrid models.", "conclusion": "UniQL demonstrates its effectiveness in enabling efficient, accurate deployment of LLMs on edge devices, providing significant resource reductions while maintaining performance levels. The framework is publicly available for further use."}}
{"id": "2512.03110", "pdf": "https://arxiv.org/pdf/2512.03110", "abs": "https://arxiv.org/abs/2512.03110", "authors": ["Steven Mascaro", "Owen Woodberry", "Charlie McLeod", "Mitch Messer", "Hiran Selvadurai", "Yue Wu", "Andre Schultz", "Thomas L Snelling"], "title": "The BEAT-CF Causal Model: A model for guiding the design of trials and observational analyses of cystic fibrosis exacerbations", "categories": ["q-bio.QM", "cs.AI"], "comment": "12 pages (8 pages in appendices)", "summary": "Loss of lung function in cystic fibrosis (CF) occurs progressively, punctuated by acute pulmonary exacerbations (PEx) in which abrupt declines in lung function are not fully recovered. A key component of CF management over the past half century has been the treatment of PEx to slow lung function decline. This has been credited with improvements in survival for people with CF (PwCF), but there is no consensus on the optimal approach to PEx management. BEAT-CF (Bayesian evidence-adaptive treatment of CF) was established to build an evidence-informed knowledge base for CF management. The BEAT-CF causal model is a directed acyclic graph (DAG) and Bayesian network (BN) for PEx that aims to inform the design and analysis of clinical trials comparing the effectiveness of alternative approaches to PEx management. The causal model describes relationships between background risk factors, treatments, and pathogen colonisation of the airways that affect the outcome of an individual PEx episode. The key factors, outcomes, and causal relationships were elicited from CF clinical experts and together represent current expert understanding of the pathophysiology of a PEx episode, guiding the design of data collection and studies and enabling causal inference. Here, we present the DAG that documents this understanding, along with the processes used in its development, providing transparency around our trial design and study processes, as well as a reusable framework for others.", "AI": {"tldr": "The paper introduces BEAT-CF, a model for informing treatment and clinical trial designs in managing pulmonary exacerbations in cystic fibrosis.", "motivation": "To establish evidence-based knowledge for cystic fibrosis management and address the lack of a consensus on the optimal approach to pulmonary exacerbation treatment.", "method": "Developed a directed acyclic graph (DAG) and Bayesian network (BN) informed by expert opinions to model causal relationships of factors influencing pulmonary exacerbations.", "result": "Presented a causal model with key factors, outcomes, and relationships elicited from clinical experts, providing a deeper understanding of exacerbation episodes.", "conclusion": "The developed model offers a tool for designing clinical trials, supports evidence-based treatment approaches, and serves as a reusable framework for further studies in cystic fibrosis management."}}
{"id": "2512.03465", "pdf": "https://arxiv.org/pdf/2512.03465", "abs": "https://arxiv.org/abs/2512.03465", "authors": ["Robert Dilworth"], "title": "Tuning for TraceTarnish: Techniques, Trends, and Testing Tangible Traits", "categories": ["cs.CR", "cs.CL", "cs.IR"], "comment": "20 pages, 8 figures, 2 tables", "summary": "In this study, we more rigorously evaluated our attack script $\\textit{TraceTarnish}$, which leverages adversarial stylometry principles to anonymize the authorship of text-based messages. To ensure the efficacy and utility of our attack, we sourced, processed, and analyzed Reddit comments--comments that were later alchemized into $\\textit{TraceTarnish}$ data--to gain valuable insights. The transformed $\\textit{TraceTarnish}$ data was then further augmented by $\\textit{StyloMetrix}$ to manufacture stylometric features--features that were culled using the Information Gain criterion, leaving only the most informative, predictive, and discriminative ones. Our results found that function words and function word types ($L\\_FUNC\\_A$ $\\&$ $L\\_FUNC\\_T$); content words and content word types ($L\\_CONT\\_A$ $\\&$ $L\\_CONT\\_T$); and the Type-Token Ratio ($ST\\_TYPE\\_TOKEN\\_RATIO\\_LEMMAS$) yielded significant Information-Gain readings. The identified stylometric cues--function-word frequencies, content-word distributions, and the Type-Token Ratio--serve as reliable indicators of compromise (IoCs), revealing when a text has been deliberately altered to mask its true author. Similarly, these features could function as forensic beacons, alerting defenders to the presence of an adversarial stylometry attack; granted, in the absence of the original message, this signal may go largely unnoticed, as it appears to depend on a pre- and post-transformation comparison. \"In trying to erase a trace, you often imprint a larger one.\" Armed with this understanding, we framed $\\textit{TraceTarnish}$'s operations and outputs around these five isolated features, using them to conceptualize and implement enhancements that further strengthen the attack.", "AI": {"tldr": "The study evaluates the attack script TraceTarnish, based on adversarial stylometry, to anonymize authorship by processing and analyzing Reddit comments. Key stylometric features were used to detect text alterations and improve the attack.", "motivation": "To test and enhance the efficacy of TraceTarnish, a tool designed to anonymize authorship of text by exploiting stylometric principles.", "method": "Reddit comments were processed using TraceTarnish, with stylistic features extracted via StyloMetrix and refined using the Information Gain criterion. Key stylometric indicators were identified for evaluation.", "result": "Function and content-word types, frequencies, and the Type-Token Ratio were highlighted as effective features for identifying transformed texts or adversarial anonymity attacks.", "conclusion": "Stylometric features can serve as reliable indicators of changes in text authorship by adversaries, but their detection often requires pre- and post-transformation comparisons."}}
{"id": "2512.03542", "pdf": "https://arxiv.org/pdf/2512.03542", "abs": "https://arxiv.org/abs/2512.03542", "authors": ["Nan Sun", "Zhenyu Zhang", "Xixun Lin", "Kun Wang", "Yanmin Shang", "Naibin Gu", "Shuohuan Wang", "Yu Sun", "Hua Wu", "Haifeng Wang", "Yanan Cao"], "title": "V-ITI: Mitigating Hallucinations in Multimodal Large Language Models via Visual Inference-Time Intervention", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) excel in numerous vision-language tasks yet suffer from hallucinations, producing content inconsistent with input visuals, that undermine reliability in precision-sensitive domains. This issue stems from a fundamental problem of visual neglect, where models fail to adequately prioritize input images. Existing methods typically alleviate hallucinations by intervening in the attention score or output logits, focusing on \"how to intervene\" but overlooking the prerequisite \"when to intervene\", which leads to the \"over-intervention\" problem and subsequently introduces new hallucinations and unnecessary computational overhead. To address this gap, we first investigate the mechanism of visual neglect and reveal it can be accurately detected via head-level activation patterns in MLLMs. We thus propose V-ITI, a lightweight visual inference-time intervention framework integrating a Visual Neglect Detector that identifies visual neglect via head-level discriminative probes and a Visual Recall Intervenor that modulates activations with prestored visual activation information only when the visual neglect is detected. Extensive experiments across eight benchmarks and different MLLM families demonstrate that V-ITI consistently mitigates vision-related hallucinations while preserving general task performance.", "AI": {"tldr": "The paper presents V-ITI, a framework addressing hallucination issues in multimodal large language models (MLLMs) by selectively intervening only when visual neglect is detected, improving output reliability.", "motivation": "MLLMs suffer from hallucinations due to visual neglect, causing unreliable outputs in sensitive domains. Existing solutions inadequately address when to intervene, leading to over-intervention issues.", "method": "The authors developed V-ITI, a lightweight framework with two components: a Visual Neglect Detector for identifying visual neglect through head-level activation patterns, and a Visual Recall Intervenor for modulating activations only when visual neglect is detected.", "result": "Experiments across eight benchmarks and various MLLM families show that V-ITI reduces vision-related hallucinations without compromising general task performance.", "conclusion": "V-ITI improves the reliability and accuracy of MLLMs by addressing visual neglect selectively, mitigating hallucinations while avoiding over-intervention and preserving computational efficiency."}}
{"id": "2512.03111", "pdf": "https://arxiv.org/pdf/2512.03111", "abs": "https://arxiv.org/abs/2512.03111", "authors": ["Xiaoshui Huang", "Tianlin Zhu", "Yifan Zuo", "Xue Xia", "Zonghan Wu", "Jiebin Yan", "Dingli Hua", "Zongyi Xu", "Yuming Fang", "Jian Zhang"], "title": "PanFoMa: A Lightweight Foundation Model and Benchmark for Pan-Cancer", "categories": ["q-bio.GN", "cs.AI", "cs.CV"], "comment": "Accepted by AAAI 2026", "summary": "Single-cell RNA sequencing (scRNA-seq) is essential for decoding tumor heterogeneity. However, pan-cancer research still faces two key challenges: learning discriminative and efficient single-cell representations, and establishing a comprehensive evaluation benchmark. In this paper, we introduce PanFoMa, a lightweight hybrid neural network that combines the strengths of Transformers and state-space models to achieve a balance between performance and efficiency. PanFoMa consists of a front-end local-context encoder with shared self-attention layers to capture complex, order-independent gene interactions; and a back-end global sequential feature decoder that efficiently integrates global context using a linear-time state-space model. This modular design preserves the expressive power of Transformers while leveraging the scalability of Mamba to enable transcriptome modeling, effectively capturing both local and global regulatory signals. To enable robust evaluation, we also construct a large-scale pan-cancer single-cell benchmark, PanFoMaBench, containing over 3.5 million high-quality cells across 33 cancer subtypes, curated through a rigorous preprocessing pipeline. Experimental results show that PanFoMa outperforms state-of-the-art models on our pan-cancer benchmark (+4.0\\%) and across multiple public tasks, including cell type annotation (+7.4\\%), batch integration (+4.0\\%) and multi-omics integration (+3.1\\%). The code is available at https://github.com/Xiaoshui-Huang/PanFoMa.", "AI": {"tldr": "This paper introduces PanFoMa, a hybrid neural network for efficient single-cell representation learning in pan-cancer research, addressing key challenges of tumor heterogeneity analysis. It also provides PanFoMaBench, a robust evaluation benchmark of over 3.5 million cells.", "motivation": "The paper aims to address the challenges in pan-cancer research, which include creating both discriminative and efficient single-cell representations, as well as establishing a comprehensive evaluation benchmark for analyzing tumor heterogeneity.", "method": "The authors propose PanFoMa, a neural network combining Transformers' expressive power with state-space models' scalability. PanFoMa uses a modular architecture with a local-context encoder using self-attention and a global sequential decoder for efficient context integration. Along with this model, they introduce PanFoMaBench, a benchmark dataset of 3.5 million cells from 33 cancer subtypes.", "result": "Experimental results demonstrate that PanFoMa surpasses state-of-the-art models on the PanFoMaBench benchmark (+4.0%) and other public tasks like cell type annotation (+7.4%), batch integration (+4.0%), and multi-omics integration (+3.1%).", "conclusion": "PanFoMa achieves a good balance between performance and efficiency for pan-cancer analysis and sets a new benchmark with PanFoMaBench for robust evaluation in single-cell RNA sequencing studies."}}
{"id": "2512.03553", "pdf": "https://arxiv.org/pdf/2512.03553", "abs": "https://arxiv.org/abs/2512.03553", "authors": ["Wei Chee Yew", "Hailun Xu", "Sanjay Saha", "Xiaotian Fan", "Hiok Hian Ong", "David Yuchen Wang", "Kanchan Sarkar", "Zhenheng Yang", "Danhui Guan"], "title": "Dynamic Content Moderation in Livestreams: Combining Supervised Classification with MLLM-Boosted Similarity Matching", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at KDD 2026", "summary": "Content moderation remains a critical yet challenging task for large-scale user-generated video platforms, especially in livestreaming environments where moderation must be timely, multimodal, and robust to evolving forms of unwanted content. We present a hybrid moderation framework deployed at production scale that combines supervised classification for known violations with reference-based similarity matching for novel or subtle cases. This hybrid design enables robust detection of both explicit violations and novel edge cases that evade traditional classifiers. Multimodal inputs (text, audio, visual) are processed through both pipelines, with a multimodal large language model (MLLM) distilling knowledge into each to boost accuracy while keeping inference lightweight. In production, the classification pipeline achieves 67% recall at 80% precision, and the similarity pipeline achieves 76% recall at 80% precision. Large-scale A/B tests show a 6-8% reduction in user views of unwanted livestreams}. These results demonstrate a scalable and adaptable approach to multimodal content governance, capable of addressing both explicit violations and emerging adversarial behaviors.", "AI": {"tldr": "The paper proposes a hybrid moderation framework for livestreaming platforms, integrating supervised classification and similarity matching to detect both explicit violations and edge cases, achieving significant success in reducing user views of unwanted streams.", "motivation": "To address the challenges of timely and robust content moderation on large-scale, user-generated livestreaming platforms, particularly in handling both known and novel forms of unwanted content.", "method": "The hybrid framework incorporates supervised classification for known violations and reference-based similarity matching for subtle or novel cases, utilizing multimodal input (text, audio, visual) and a multimodal large language model (MLLM) to enhance accuracy while keeping it lightweight.", "result": "The classification pipeline achieved 67% recall at 80% precision, and the similarity pipeline achieved 76% recall at 80% precision. A/B tests showed a 6-8% reduction in user views of unwanted livestreams.", "conclusion": "The hybrid moderation approach proves scalable and adaptable, effectively addressing explicit violations and adversarial behaviors, showcasing its potential for broad use in content governance."}}
{"id": "2512.03514", "pdf": "https://arxiv.org/pdf/2512.03514", "abs": "https://arxiv.org/abs/2512.03514", "authors": ["Adithya S Kolavi", "Vyoman Jain"], "title": "M3DR: Towards Universal Multilingual Multimodal Document Retrieval", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Multimodal document retrieval systems have shown strong progress in aligning visual and textual content for semantic search. However, most existing approaches remain heavily English-centric, limiting their effectiveness in multilingual contexts. In this work, we present M3DR (Multilingual Multimodal Document Retrieval), a framework designed to bridge this gap across languages, enabling applicability across diverse linguistic and cultural contexts. M3DR leverages synthetic multilingual document data and generalizes across different vision-language architectures and model sizes, enabling robust cross-lingual and cross-modal alignment. Using contrastive training, our models learn unified representations for text and document images that transfer effectively across languages. We validate this capability on 22 typologically diverse languages, demonstrating consistent performance and adaptability across linguistic and script variations. We further introduce a comprehensive benchmark that captures real-world multilingual scenarios, evaluating models under monolingual, multilingual, and mixed-language settings. M3DR generalizes across both single dense vector and ColBERT-style token-level multi-vector retrieval paradigms. Our models, NetraEmbed and ColNetraEmbed achieve state-of-the-art performance with ~150% relative improvements on cross-lingual retrieval.", "AI": {"tldr": "This paper introduces a framework, M3DR, for multilingual multimodal document retrieval, addressing limitations in multilingual contexts and achieving robust cross-lingual and cross-modal alignment.", "motivation": "The paper aims to address the limitations of existing English-centric multimodal retrieval systems, enhancing effectiveness in multilingual scenarios and diverse linguistic and cultural contexts.", "method": "M3DR leverages synthetic multilingual data, generalizing across vision-language architectures and model sizes. It employs contrastive training to learn unified text-document representations adaptable across languages, evaluated with diverse linguistic benchmarks.", "result": "The models demonstrate consistent performance across 22 languages, achieving ~150% relative improvements on cross-lingual retrieval, validated with real-world multilingual benchmarks.", "conclusion": "M3DR successfully bridges the gap in multilingual multimodal document retrieval, offering adaptability and improved performance across linguistic and script variations."}}
{"id": "2512.03558", "pdf": "https://arxiv.org/pdf/2512.03558", "abs": "https://arxiv.org/abs/2512.03558", "authors": ["Huy Quang Ung", "Guillaume Habault", "Yasutaka Nishimura", "Hao Niu", "Roberto Legaspi", "Tomoki Oya", "Ryoichi Kojima", "Masato Taya", "Chihiro Ono", "Atsunori Minamikawa", "Yan Liu"], "title": "CartoMapQA: A Fundamental Benchmark Dataset Evaluating Vision-Language Models on Cartographic Map Understanding", "categories": ["cs.CV", "cs.CL"], "comment": "Accepted at SIGSPATIAL 2025 (Best paper candidates), 15 pages", "summary": "The rise of Visual-Language Models (LVLMs) has unlocked new possibilities for seamlessly integrating visual and textual information. However, their ability to interpret cartographic maps remains largely unexplored. In this paper, we introduce CartoMapQA, a benchmark specifically designed to evaluate LVLMs' understanding of cartographic maps through question-answering tasks. The dataset includes over 2000 samples, each composed of a cartographic map, a question (with open-ended or multiple-choice answers), and a ground-truth answer. These tasks span key low-, mid- and high-level map interpretation skills, including symbol recognition, embedded information extraction, scale interpretation, and route-based reasoning. Our evaluation of both open-source and proprietary LVLMs reveals persistent challenges: models frequently struggle with map-specific semantics, exhibit limited geospatial reasoning, and are prone to Optical Character Recognition (OCR)-related errors. By isolating these weaknesses, CartoMapQA offers a valuable tool for guiding future improvements in LVLM architectures. Ultimately, it supports the development of models better equipped for real-world applications that depend on robust and reliable map understanding, such as navigation, geographic search, and urban planning. Our source code and data are openly available to the research community at: https://github.com/ungquanghuy-kddi/CartoMapQA.git", "AI": {"tldr": "The study introduces CartoMapQA, a benchmark for evaluating the ability of Visual-Language Models (LVLMs) to interpret cartographic maps using various question-answering tasks.", "motivation": "To assess and improve LVLMs\u2019 capability in interpreting cartographic maps for real-world applications like navigation, geographic search, and urban planning.", "method": "Created a benchmark dataset, CartoMapQA, with over 2000 samples containing maps, questions, and answers to test various map interpretation skills of LVLMs.", "result": "Findings show LVLMs struggle with map-specific semantics, geospatial reasoning, and OCR errors, highlighting weaknesses in current LVLM architectures.", "conclusion": "CartoMapQA serves as a resource for guiding improvements in LVLMs to enhance map understanding for practical applications. The dataset and code are publicly available for further research."}}
{"id": "2512.03399", "pdf": "https://arxiv.org/pdf/2512.03399", "abs": "https://arxiv.org/abs/2512.03399", "authors": ["Joe Edelman", "Tan Zhi-Xuan", "Ryan Lowe", "Oliver Klingefjord", "Vincent Wang-Mascianica", "Matija Franklin", "Ryan Othniel Kearns", "Ellie Hain", "Atrisha Sarkar", "Michiel Bakker", "Fazl Barez", "David Duvenaud", "Jakob Foerster", "Iason Gabriel", "Joseph Gubbels", "Bryce Goodman", "Andreas Haupt", "Jobst Heitzig", "Julian Jara-Ettinger", "Atoosa Kasirzadeh", "James Ravi Kirkpatrick", "Andrew Koh", "W. Bradley Knox", "Philipp Koralus", "Joel Lehman", "Sydney Levine", "Samuele Marro", "Manon Revel", "Toby Shorin", "Morgan Sutherland", "Michael Henry Tessler", "Ivan Vendrov", "James Wilken-Smith"], "title": "Full-Stack Alignment: Co-Aligning AI and Institutions with Thick Models of Value", "categories": ["cs.LG"], "comment": null, "summary": "Beneficial societal outcomes cannot be guaranteed by aligning individual AI systems with the intentions of their operators or users. Even an AI system that is perfectly aligned to the intentions of its operating organization can lead to bad outcomes if the goals of that organization are misaligned with those of other institutions and individuals. For this reason, we need full-stack alignment, the concurrent alignment of AI systems and the institutions that shape them with what people value. This can be done without imposing a particular vision of individual or collective flourishing. We argue that current approaches for representing values, such as utility functions, preference orderings, or unstructured text, struggle to address these and other issues effectively. They struggle to distinguish values from other signals, to support principled normative reasoning, and to model collective goods. We propose thick models of value will be needed. These structure the way values and norms are represented, enabling systems to distinguish enduring values from fleeting preferences, to model the social embedding of individual choices, and to reason normatively, applying values in new domains. We demonstrate this approach in five areas: AI value stewardship, normatively competent agents, win-win negotiation systems, meaning-preserving economic mechanisms, and democratic regulatory institutions.", "AI": {"tldr": "The paper proposes a need for 'full-stack alignment' in AI, where both AI systems and the institutions shaping them align with collective human values, using structured 'thick models of value.'", "motivation": "The motivation of this paper is the inadequacy of aligning AI systems solely to operators\u2019 or organizations\u2019 intentions, as misaligned institutional goals can still lead to poor outcomes. Better mechanisms are needed to align AI and institutions with societal values.", "method": "The authors propose the development of 'thick models of value,' structured frameworks to distinguish enduring values from transient preferences, account for the social embedding of individual choices, and enable principled normative reasoning.", "result": "The authors demonstrate the application of their proposed approach in five domains, including AI value stewardship, normatively competent agents, negotiation systems, economic mechanisms, and regulatory institutions.", "conclusion": "Addressing harmful AI outcomes requires concurrent alignment of AI systems and societal institutions, leaning on structured, value-sensitive models to ensure compatibility with human collective flourishing."}}
{"id": "2512.03121", "pdf": "https://arxiv.org/pdf/2512.03121", "abs": "https://arxiv.org/abs/2512.03121", "authors": ["Ziyi Tong", "Feifei Sun", "Le Minh Nguyen"], "title": "Lost in Modality: Evaluating the Effectiveness of Text-Based Membership Inference Attacks on Large Multimodal Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Multimodal Language Models (MLLMs) are emerging as one of the foundational tools in an expanding range of applications. Consequently, understanding training-data leakage in these systems is increasingly critical. Log-probability-based membership inference attacks (MIAs) have become a widely adopted approach for assessing data exposure in large language models (LLMs), yet their effect in MLLMs remains unclear. We present the first comprehensive evaluation of extending these text-based MIA methods to multimodal settings. Our experiments under vision-and-text (V+T) and text-only (T-only) conditions across the DeepSeek-VL and InternVL model families show that in in-distribution settings, logit-based MIAs perform comparably across configurations, with a slight V+T advantage. Conversely, in out-of-distribution settings, visual inputs act as regularizers, effectively masking membership signals.", "AI": {"tldr": "The paper evaluates the application of membership inference attacks (MIAs) in multimodal language models (MLLMs), finding that visual inputs can regularize and mask membership signals in certain contexts.", "motivation": "To understand training-data leakage in large multimodal language models (MLLMs) and assess whether membership inference attacks (MIAs) work effectively in this domain.", "method": "The study extended traditional text-based MIA methods to multimodal settings, conducting experiments under vision-and-text (V+T) and text-only (T-only) input settings across specific MLLM model families.", "result": "In in-distribution settings, logit-based MIAs were equally effective with a slight advantage for V+T configurations. In out-of-distribution settings, visual inputs acted as regularizers, masking membership signals.", "conclusion": "Visual inputs in MLLMs influence the effectiveness of MIAs, with improved outcomes in in-distribution scenarios and signal masking in out-of-distribution scenarios."}}
{"id": "2512.03566", "pdf": "https://arxiv.org/pdf/2512.03566", "abs": "https://arxiv.org/abs/2512.03566", "authors": ["Hao Sun", "Lei Fan", "Donglin Di", "Shaohui Liu"], "title": "GAOT: Generating Articulated Objects Through Text-Guided Diffusion Models", "categories": ["cs.CV", "cs.MM"], "comment": "Accepted by ACM MM Asia2026", "summary": "Articulated object generation has seen increasing advancements, yet existing models often lack the ability to be conditioned on text prompts. To address the significant gap between textual descriptions and 3D articulated object representations, we propose GAOT, a three-phase framework that generates articulated objects from text prompts, leveraging diffusion models and hypergraph learning in a three-step process. First, we fine-tune a point cloud generation model to produce a coarse representation of objects from text prompts. Given the inherent connection between articulated objects and graph structures, we design a hypergraph-based learning method to refine these coarse representations, representing object parts as graph vertices. Finally, leveraging a diffusion model, the joints of articulated objects-represented as graph edges-are generated based on the object parts. Extensive qualitative and quantitative experiments on the PartNet-Mobility dataset demonstrate the effectiveness of our approach, achieving superior performance over previous methods.", "AI": {"tldr": "GAOT is a framework for generating 3D articulated objects from text prompts by integrating diffusion models and hypergraph learning.", "motivation": "Current models lack the ability to condition 3D articulated object generation on text. GAOT aims to bridge the gap by establishing a direct connection between textual descriptions and 3D articulated object representations.", "method": "GAOT follows a three-phase process: (1) Fine-tune a point cloud generation model to produce a coarse object representation from text prompts. (2) Refine representations using hypergraph-based learning, treating object parts as vertices. (3) Employ a diffusion model to generate object joints, linking parts represented as edges.", "result": "Extensive experiments on the PartNet-Mobility dataset validate the model's effectiveness, achieving superior qualitative and quantitative performance compared to prior methods.", "conclusion": "GAOT successfully generates high-quality articulated objects directly from textual descriptions through its innovative three-phase approach."}}
{"id": "2512.03400", "pdf": "https://arxiv.org/pdf/2512.03400", "abs": "https://arxiv.org/abs/2512.03400", "authors": ["Prakhar Gupta", "Henry Conklin", "Sarah-Jane Leslie", "Andrew Lee"], "title": "Better World Models Can Lead to Better Post-Training Performance", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this work we study how explicit world-modeling objectives affect the internal representations and downstream capability of Transformers across different training stages. We use a controlled 2x2x2 Rubik's Cube and ask: (1) how does explicitly pretraining a world model affect the model's latent representations, and (2) how does world-model quality affect the model's performance after reinforcement learning post-training? We compare standard next-token prediction to two explicit world-modeling strategies -- (i) state-prediction pretraining and (ii) a joint state-prediction + next-token objective -- and assess task performance after Group Relative Policy Optimization (GRPO) is applied as post-training. We evaluate the representation quality with linear probes and causal interventions. We find that explicit world-modeling yields more linearly decodable and causally steerable state representations. More importantly, we find that improved state representations lead to higher gains for GRPO, especially on harder cube states. Our results indicate that sharpening state representations can improve the effectiveness of post-training for sequence-planning tasks.", "AI": {"tldr": "This paper studies how explicit world-modeling objectives impact Transformer models' internal representations and performance, particularly for sequence-planning tasks such as solving a controlled Rubik's Cube.", "motivation": "To investigate how different world-modeling strategies influence Transformers' latent state representations and downstream performance after post-training.", "method": "The study compares standard next-token prediction approaches to two explicit world-modeling strategies: state-prediction pretraining and joint state-prediction combined next-token objective. It evaluates these methods using linear probing and causal intervention techniques.", "result": "Explicit world-modeling strategies improve state representations, making them more decodable and steerable. Enhanced world models lead to better task performance post-training using GRPO, especially on complex states.", "conclusion": "Explicitly sharpening latent state representations through world-modeling improves post-training effectiveness for sequence-planning tasks, benefiting models in handling challenging states."}}
{"id": "2512.03620", "pdf": "https://arxiv.org/pdf/2512.03620", "abs": "https://arxiv.org/abs/2512.03620", "authors": ["Hanxiu Zhang", "Yue Zheng"], "title": "SELF: A Robust Singular Value and Eigenvalue Approach for LLM Fingerprinting", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "The protection of Intellectual Property (IP) in Large Language Models (LLMs) represents a critical challenge in contemporary AI research. While fingerprinting techniques have emerged as a fundamental mechanism for detecting unauthorized model usage, existing methods -- whether behavior-based or structural -- suffer from vulnerabilities such as false claim attacks or susceptible to weight manipulations. To overcome these limitations, we propose SELF, a novel intrinsic weight-based fingerprinting scheme that eliminates dependency on input and inherently resists false claims. SELF achieves robust IP protection through two key innovations: 1) unique, scalable and transformation-invariant fingerprint extraction via singular value and eigenvalue decomposition of LLM attention weights, and 2) effective neural network-based fingerprint similarity comparison based on few-shot learning and data augmentation. Experimental results demonstrate SELF maintains high IP infringement detection accuracy while showing strong robustness against various downstream modifications, including quantization, pruning, and fine-tuning attacks. Our code is available at https://github.com/HanxiuZhang/SELF_v2.", "AI": {"tldr": "The paper proposes SELF, a weight-based fingerprinting method for LLMs, addressing challenges in IP protection with robust detection and resistance to manipulations.", "motivation": "The study aims to address vulnerabilities of existing fingerprinting techniques in detecting unauthorized usage of LLMs, such as false claim attacks and susceptibility to weight manipulations.", "method": "SELF is a weight-based fingerprinting mechanism leveraging singular value and eigenvalue decomposition of attention weights and few-shot learning for similarity comparisons.", "result": "SELF demonstrates high accuracy in detecting IP infringement and robust defense against model modifications, including quantization, pruning, and fine-tuning.", "conclusion": "SELF offers a scalable and effective approach for maintaining IP protection in LLMs without dependency on inputs while being resistant to modifications."}}
{"id": "2512.03574", "pdf": "https://arxiv.org/pdf/2512.03574", "abs": "https://arxiv.org/abs/2512.03574", "authors": ["Fuxiang Yang", "Tonghua Su", "Donglin Di", "Yin Chen", "Xiangqian Wu", "Zhongjie Wang", "Lei Fan"], "title": "Global-Local Aware Scene Text Editing", "categories": ["cs.CV"], "comment": null, "summary": "Scene Text Editing (STE) involves replacing text in a scene image with new target text while preserving both the original text style and background texture. Existing methods suffer from two major challenges: inconsistency and length-insensitivity. They often fail to maintain coherence between the edited local patch and the surrounding area, and they struggle to handle significant differences in text length before and after editing. To tackle these challenges, we propose an end-to-end framework called Global-Local Aware Scene Text Editing (GLASTE), which simultaneously incorporates high-level global contextual information along with delicate local features. Specifically, we design a global-local combination structure, joint global and local losses, and enhance text image features to ensure consistency in text style within local patches while maintaining harmony between local and global areas. Additionally, we express the text style as a vector independent of the image size, which can be transferred to target text images of various sizes. We use an affine fusion to fill target text images into the editing patch while maintaining their aspect ratio unchanged. Extensive experiments on real-world datasets validate that our GLASTE model outperforms previous methods in both quantitative metrics and qualitative results and effectively mitigates the two challenges.", "AI": {"tldr": "This paper introduces GLASTE, a new framework for Scene Text Editing that addresses issues like inconsistency and length sensitivity in current methods by using global-local features and innovative text style transfer.", "motivation": "The motivation is to overcome challenges in Scene Text Editing, such as maintaining coherence between local edits and the surrounding area and handling differences in text length.", "method": "GLASTE is an end-to-end framework combining global-local structures, joint losses, and vectorized text styles for consistent and efficient editing, along with affine fusion for aspect ratio preservation.", "result": "The proposed GLASTE framework surpasses existing methods in both quantitative and qualitative evaluations on various datasets.", "conclusion": "GLASTE effectively addresses the inconsistency and length-sensitivity issues in Scene Text Editing while maintaining style and background harmony."}}
{"id": "2512.03643", "pdf": "https://arxiv.org/pdf/2512.03643", "abs": "https://arxiv.org/abs/2512.03643", "authors": ["Ivan Yee Lee", "Cheng Yang", "Taylor Berg-Kirkpatrick"], "title": "Optical Context Compression Is Just (Bad) Autoencoding", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": null, "summary": "DeepSeek-OCR demonstrates that rendered text can be reconstructed with high fidelity from a small number of vision tokens. This finding has sparked excitement about vision-based context compression for language models. But the evaluation stops at reconstruction; whether these representations help language modeling remains untested. We test two assumptions implicit in the optical-compression narrative: that vision-based compression provides unique advantages for text reconstruction from compressed representations, and that DeepSeek-OCR's reconstruction results are evidence that vision-based compression will be useful for language modeling. Comparing their vision encoder against simple alternatives--parameter-free mean pooling and a learned hierarchical encoder--we find that these simple approaches match or surpass vision for reconstruction at matched compression ratios, and outperform it for language modeling--where vision-based compression fails to beat truncation. The excitement around optical context compression outpaces the evidence. Code and checkpoints are available at https://github.com/ivnle/bad-autoencoding", "AI": {"tldr": "This paper questions the effectiveness of vision-based compression methods for language modeling and text reconstruction, showing that simpler alternatives perform better.", "motivation": "The paper seeks to validate assumptions about the utility of vision-based compression, such as its advantages in reconstructing rendered text and its effectiveness for language modeling.", "method": "The study compares the vision encoder from DeepSeek-OCR against simpler alternative methods: parameter-free mean pooling and a learned hierarchical encoder.", "result": "Simple methods matched or outperformed the vision-based approach in text reconstruction and significantly surpassed it in language modeling.", "conclusion": "The authors suggest that the excitement around optical context compression is premature, as existing evidence does not substantiate its perceived advantages."}}
{"id": "2512.03575", "pdf": "https://arxiv.org/pdf/2512.03575", "abs": "https://arxiv.org/abs/2512.03575", "authors": ["Chao Yuan", "Shimin Chen", "Minliang Lin", "Limeng Qiao", "Guanglu Wan", "Lin Ma"], "title": "UniComp: Rethinking Video Compression Through Informational Uniqueness", "categories": ["cs.CV"], "comment": null, "summary": "Distinct from attention-based compression methods, this paper presents an information uniqueness driven video compression framework, termed UniComp, which aims to maximize the information fidelity of video representations under constrained computational budgets. Starting from the information-theoretic perspective, we formulate the vision compression as an optimization problem that minimizes conditional entropy (reconstruction error) between retained and full tokens. To achieve this, we introduce the notion of information uniqueness to measure intrinsic redundancy among tokens to link with reconstruction error. Based on uniqueness, we design three modules-Frame Group Fusion, Token Allocation, and Spatial Dynamic Compression-that progressively perform semantic frame grouping, adaptive resource allocation, and fine-grained spatial compression. Extensive experiments demonstrate that UniComp consistently outperforms existing compression methods in preserving essential visual tokens under limited computational budgets, highlighting the pivotal role of information uniqueness in token compression efficacy.", "AI": {"tldr": "UniComp is a novel video compression framework driven by information uniqueness, outperforming existing methods under computational constraints.", "motivation": "The paper aims to improve video compression by maximizing information fidelity of video representations within limited computational budgets.", "method": "UniComp minimizes conditional entropy using information uniqueness to reduce redundancy among video tokens, employing modules for frame fusion, token allocation, and spatial compression.", "result": "UniComp outperforms existing methods in preserving essential visual tokens under constrained computational resources.", "conclusion": "Information uniqueness is critical for effective video compression, making UniComp a promising approach for efficient and high-quality compression."}}
{"id": "2512.03437", "pdf": "https://arxiv.org/pdf/2512.03437", "abs": "https://arxiv.org/abs/2512.03437", "authors": ["Yuanbang Liang", "Yang Li"], "title": "Grokked Models are Better Unlearners", "categories": ["cs.LG"], "comment": null, "summary": "Grokking-delayed generalization that emerges well after a model has fit the training data-has been linked to robustness and representation quality. We ask whether this training regime also helps with machine unlearning, i.e., removing the influence of specified data without full retraining. We compare applying standard unlearning methods before versus after the grokking transition across vision (CNNs/ResNets on CIFAR, SVHN, and ImageNet) and language (a transformer on a TOFU-style setup). Starting from grokked checkpoints consistently yields (i) more efficient forgetting (fewer updates to reach a target forget level), (ii) less collateral damage (smaller drops on retained and test performance), and (iii) more stable updates across seeds, relative to early-stopped counterparts under identical unlearning algorithms. Analyses of features and curvature further suggest that post-grokking models learn more modular representations with reduced gradient alignment between forget and retain subsets, which facilitates selective forgetting. Our results highlight when a model is trained (pre- vs. post-grokking) as an orthogonal lever to how unlearning is performed, providing a practical recipe to improve existing unlearning methods without altering their algorithms.", "AI": {"tldr": "The paper studies the impact of training models beyond the grokking phase on machine unlearning, finding improved forgetting efficiency, retention performance, and stability.", "motivation": "To explore whether delayed generalization (grokking) aids machine unlearning, aiming to enhance selective forgetting without algorithmic changes.", "method": "Experimented with unlearning methods on grokked versus early-stopped models across vision (CNNs/ResNets) and language (transformers) tasks.", "result": "Using grokked checkpoints led to faster and more effective forgetting, reduced collateral performance drops, and more modular representations.", "conclusion": "Training to grokking provides a powerful strategy for improving unlearning methods without modifying the algorithms employed."}}
{"id": "2512.03746", "pdf": "https://arxiv.org/pdf/2512.03746", "abs": "https://arxiv.org/abs/2512.03746", "authors": ["Zirun Guo", "Minjie Hong", "Feng Zhang", "Kai Jia", "Tao Jin"], "title": "Thinking with Programming Vision: Towards a Unified View for Thinking with Images", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Multimodal large language models (MLLMs) that think with images can interactively use tools to reason about visual inputs, but current approaches often rely on a narrow set of tools with limited real-world necessity and scalability. In this work, we first reveal a critical and previously overlooked weakness: even state-of-the-art MLLMs are surprisingly brittle, showing significant performance degradation on images with simple orientation changes or natural corruptions, underscoring the need for more robust tool-based reasoning. To address this, we propose CodeVision, a flexible and scalable code-as-tool framework where the model generates code as a universal interface to invoke any image operation, moving beyond fixed tool registries. We train our model using a two-stage methodology, beginning with Supervised Fine-Tuning (SFT) on a high-quality dataset curated for complex, multi-turn tool composition and error recovery, followed by Reinforcement Learning (RL) with a novel and dense process reward function to encourage strategic and efficient tool use. To facilitate this research, we construct new SFT and RL datasets and introduce a challenging new benchmark suite designed to rigorously evaluate robustness to orientation changes and multi-tool reasoning. Experiments on Qwen2.5-VL and Qwen3-VL series show that our approach significantly improves model performance and fosters emergent capabilities such as flexible tool composition, efficient chained execution, and robust error recovery from runtime feedback. Code is available at https://github.com/ByteDance-BandAI/CodeVision.", "AI": {"tldr": "The paper introduces CodeVision, a framework for multimodal large language models (MLLMs) to enhance robustness and tool-based reasoning with image inputs.", "motivation": "Current MLLMs exhibit brittleness with basic orientation changes or natural corruptions in images, requiring more robust and scalable tool-based reasoning beyond fixed tool registries.", "method": "Introduces CodeVision, a code-as-tool framework where the model generates code as a universal interface for image operations, trained using supervised fine-tuning followed by reinforcement learning with a novel reward function.", "result": "Significant performance improvement on Qwen2.5-VL and Qwen3-VL models, with emergent capabilities like flexible tool composition and robust error recovery.", "conclusion": "CodeVision enhances MLLMs' robustness, scalability, and multi-tool reasoning with an innovative framework and benchmark suite, showcasing promising results."}}
{"id": "2512.03577", "pdf": "https://arxiv.org/pdf/2512.03577", "abs": "https://arxiv.org/abs/2512.03577", "authors": ["Yizhi Zhang", "Lei Fan", "Zhulin Tao", "Donglin Di", "Yang Song", "Sidong Liu", "Cong Cong"], "title": "Cross-Stain Contrastive Learning for Paired Immunohistochemistry and Histopathology Slide Representation Learning", "categories": ["cs.CV"], "comment": "6 pages, 2 figures. Camera-ready version accepted for IEEE BIBM 2025", "summary": "Universal, transferable whole-slide image (WSI) representations are central to computational pathology. Incorporating multiple markers (e.g., immunohistochemistry, IHC) alongside H&E enriches H&E-based features with diverse, biologically meaningful information. However, progress is limited by the scarcity of well-aligned multi-stain datasets. Inter-stain misalignment shifts corresponding tissue across slides, hindering consistent patch-level features and degrading slide-level embeddings. To address this, we curated a slide-level aligned, five-stain dataset (H&E, HER2, KI67, ER, PGR) to enable paired H&E-IHC learning and robust cross-stain representation. Leveraging this dataset, we propose Cross-Stain Contrastive Learning (CSCL), a two-stage pretraining framework with a lightweight adapter trained using patch-wise contrastive alignment to improve the compatibility of H&E features with corresponding IHC-derived contextual cues, and slide-level representation learning with Multiple Instance Learning (MIL), which uses a cross-stain attention fusion module to integrate stain-specific patch features and a cross-stain global alignment module to enforce consistency among slide-level embeddings across different stains. Experiments on cancer subtype classification, IHC biomarker status classification, and survival prediction show consistent gains, yielding high-quality, transferable H&E slide-level representations. The code and data are available at https://github.com/lily-zyz/CSCL.", "AI": {"tldr": "This paper introduces a dataset and framework to improve computational pathology by aligning multi-stain (H&E and IHC) images and learning universal WSI representations.", "motivation": "Accurate and transferable WSI representations are important for advancing computational pathology, but progress is hindered by misaligned multi-stain data and limited datasets.", "method": "The authors created a five-stain aligned dataset and proposed a two-stage Cross-Stain Contrastive Learning (CSCL) framework, incorporating patch-wise alignment and slide-level representation learning with MIL techniques.", "result": "The CSCL framework improved cancer subtype classification, biomarker status classification, and survival prediction while producing high-quality H&E representations.", "conclusion": "Aligned multi-stain datasets and the novel CSCL framework enable robust, transferable WSI representations for use in pathology. Code and datasets were released for further exploration."}}
{"id": "2512.03464", "pdf": "https://arxiv.org/pdf/2512.03464", "abs": "https://arxiv.org/abs/2512.03464", "authors": ["Yujing Liu", "Chen Yang"], "title": "Multi-Modal Opinion Integration for Financial Sentiment Analysis using Cross-Modal Attention", "categories": ["cs.LG"], "comment": null, "summary": "In recent years, financial sentiment analysis of public opinion has become increasingly important for market forecasting and risk assessment. However, existing methods often struggle to effectively integrate diverse opinion modalities and capture fine-grained interactions across them. This paper proposes an end-to-end deep learning framework that integrates two distinct modalities of financial opinions: recency modality (timely opinions) and popularity modality (trending opinions), through a novel cross-modal attention mechanism specifically designed for financial sentiment analysis. While both modalities consist of textual data, they represent fundamentally different information channels: recency-driven market updates versus popularity-driven collective sentiment. Our model first uses BERT (Chinese-wwm-ext) for feature embedding and then employs our proposed Financial Multi-Head Cross-Attention (FMHCA) structure to facilitate information exchange between these distinct opinion modalities. The processed features are optimized through a transformer layer and fused using multimodal factored bilinear pooling for classification into negative, neutral, and positive sentiment. Extensive experiments on a comprehensive dataset covering 837 companies demonstrate that our approach achieves an accuracy of 83.5%, significantly outperforming baselines including BERT+Transformer by 21 percent. These results highlight the potential of our framework to support more accurate financial decision-making and risk management.", "AI": {"tldr": "The paper introduces an end-to-end deep learning framework leveraging recency and popularity modalities for financial sentiment analysis, achieving 83.5% accuracy.", "motivation": "To address limitations in the integration of diverse opinion modalities for market forecasting and risk assessment in financial sentiment analysis.", "method": "The framework combines BERT (Chinese-wwm-ext) for feature embedding, Financial Multi-Head Cross-Attention (FMHCA) for modality interaction, and multimodal factored bilinear pooling for sentiment classification.", "result": "Achieved 83.5% sentiment classification accuracy, outperforming benchmarks like BERT+Transformer by 21%.", "conclusion": "The proposed framework provides a more accurate approach for financial sentiment analysis, supporting better decision-making and risk management."}}
{"id": "2512.03794", "pdf": "https://arxiv.org/pdf/2512.03794", "abs": "https://arxiv.org/abs/2512.03794", "authors": ["Zichuan Lin", "Yicheng Liu", "Yang Yang", "Lvfang Tao", "Deheng Ye"], "title": "AdaptVision: Efficient Vision-Language Models via Adaptive Visual Acquisition", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "15 pages, 9 figures", "summary": "Vision-Language Models (VLMs) have achieved remarkable success in visual question answering tasks, but their reliance on large numbers of visual tokens introduces significant computational overhead. While existing efficient VLM approaches reduce visual tokens through fixed-ratio compression, they operate passively and lack the ability to adapt to varying task requirements. This motivates a fundamental question: Can VLMs autonomously determine the minimum number of visual tokens required for each sample? Inspired by human active vision mechanisms, we introduce AdaptVision, an efficient VLM paradigm that enables adaptive visual token acquisition through a coarse-to-fine approach. Our model initially processes compressed visual tokens from low-resolution images and selectively acquires additional visual information by invoking a bounding box tool to crop key regions when necessary. We train AdaptVision using a reinforcement learning framework that carefully balances accuracy and efficiency. Central to our approach is Decoupled Turn Policy Optimization (DTPO), which decouples the learning objective into two components: (1) tool learning, which optimizes correct tool utilization, and (2) accuracy improvement, which refines the generated responses to improve answer correctness. Based on this formulation, we further decouple advantage estimation by computing separate advantages for tokens associated with each objective. This formulation enables more effective optimization for AdaptVision compared to vanilla GRPO. Comprehensive experiments across multiple VQA benchmarks demonstrate that AdaptVision achieves superior performance while consuming substantially fewer visual tokens than state-of-the-art efficient VLM methods.", "AI": {"tldr": "The paper introduces AdaptVision, an adaptive and efficient Vision-Language Model (VLM) that reduces visual tokens through a novel coarse-to-fine token acquisition process, inspired by human active vision.", "motivation": "To address the computational inefficiency of existing VLMs that rely on fixed-ratio compression, and to provide an adaptive mechanism for deciding the minimal visual tokens required per task.", "method": "AdaptVision uses a reinforcement learning framework to process low-resolution images and dynamically select additional visual tokens through a bounding box cropping tool. A new optimization method, Decoupled Turn Policy Optimization (DTPO), separates objectives for tool usage and accuracy improvement.", "result": "AdaptVision outperforms state-of-the-art efficient VLM approaches in multiple visual question answering benchmarks, using significantly fewer visual tokens while maintaining superior performance.", "conclusion": "AdaptVision demonstrates that an adaptive token acquisition approach inspired by human vision can enhance both efficiency and accuracy in Vision-Language Models by balancing token usage and task requirements."}}
{"id": "2512.03580", "pdf": "https://arxiv.org/pdf/2512.03580", "abs": "https://arxiv.org/abs/2512.03580", "authors": ["Malte Bleeker", "Mauro Gotsch"], "title": "Dynamic Optical Test for Bot Identification (DOT-BI): A simple check to identify bots in surveys and online processes", "categories": ["cs.CV", "cs.CR"], "comment": null, "summary": "We propose the Dynamic Optical Test for Bot Identification (DOT-BI): a quick and easy method that uses human perception of motion to differentiate between human respondents and automated systems in surveys and online processes. In DOT-BI, a 'hidden' number is displayed with the same random black-and-white pixel texture as its background. Only the difference in motion and scale between the number and the background makes the number perceptible to humans across frames, while frame-by-frame algorithmic processing yields no meaningful signal. We conducted two preliminary assessments. Firstly, state-of-the-art, video-capable, multimodal models (GPT-5-Thinking and Gemini 2.5 Pro) fail to extract the correct value, even when given explicit instructions about the mechanism. Secondly, in an online survey (n=182), 99.5% (181/182) of participants solved the task, with an average end-to-end completion time of 10.7 seconds; a supervised lab study (n=39) found no negative effects on perceived ease-of-use or completion time relative to a control. We release code to generate tests and 100+ pre-rendered variants to facilitate adoption in surveys and online processes.", "AI": {"tldr": "DOT-BI uses motion-based perception to differentiate humans from bots, proving effective in tests with humans and failing against AI models.", "motivation": "To develop a quick, human-perceptible motion-based method for distinguishing bots from humans in online processes.", "method": "A hidden number embedded in a randomized pixel texture motion test is used for human perception validation; tested against AI models and human participants.", "result": "AI models failed the test while 99.5% of human participants successfully completed it with ease and efficiency.", "conclusion": "DOT-BI effectively distinguishes humans from bots, proving efficient and user-friendly in surveys and online settings."}}
{"id": "2512.03467", "pdf": "https://arxiv.org/pdf/2512.03467", "abs": "https://arxiv.org/abs/2512.03467", "authors": ["Hongtao Hao", "Joseph L. Austerweil"], "title": "Bayesian Event-Based Model for Disease Subtype and Stage Inference", "categories": ["cs.LG", "stat.ME"], "comment": "32 pages; machine learning for health symposium (2025); Proceedings of the 5th Machine Learning for Health Symposium in PMLR", "summary": "Chronic diseases often progress differently across patients. Rather than randomly varying, there are typically a small number of subtypes for how a disease progresses across patients. To capture this structured heterogeneity, the Subtype and Stage Inference Event-Based Model (SuStaIn) estimates the number of subtypes, the order of disease progression for each subtype, and assigns each patient to a subtype from primarily cross-sectional data. It has been widely applied to uncover the subtypes of many diseases and inform our understanding of them. But how robust is its performance? In this paper, we develop a principled Bayesian subtype variant of the event-based model (BEBMS) and compare its performance to SuStaIn in a variety of synthetic data experiments with varied levels of model misspecification. BEBMS substantially outperforms SuStaIn across ordering, staging, and subtype assignment tasks. Further, we apply BEBMS and SuStaIn to a real-world Alzheimer's data set. We find BEBMS has results that are more consistent with the scientific consensus of Alzheimer's disease progression than SuStaIn.", "AI": {"tldr": "The paper evaluates the robustness of disease subtyping by comparing SuStaIn with a newly developed Bayesian variant (BEBMS), finding that BEBMS outperforms in synthetic and real-world Alzheimer's experiments.", "motivation": "To address the need for robustness in identifying disease progression subtypes and stages given the structured heterogeneity of chronic diseases.", "method": "Development of a Bayesian variant, BEBMS, of the event-based model and performance comparisons with SuStaIn using synthetic and Alzheimer's disease data.", "result": "BEBMS surpasses SuStaIn in tasks such as ordering, staging, and subtype assignment, with better alignment to Alzheimer's scientific consensus.", "conclusion": "BEBMS is a stronger, more robust method than SuStaIn for disease subtyping and informs better understanding of disease progression."}}
{"id": "2512.03196", "pdf": "https://arxiv.org/pdf/2512.03196", "abs": "https://arxiv.org/abs/2512.03196", "authors": ["Tanishq Patil", "Snigdha Sen", "Malwina Molendowska", "Kieran G. Foley", "Fabrizio Fasano", "Mara Cercignani", "Marco Palombo", "Paddy J. Slator", "Eleftheria Panagiotaki"], "title": "Ultra-Strong Gradient Diffusion MRI with Self-Supervised Learning for Prostate Cancer Characterization", "categories": ["eess.IV", "cs.AI", "cs.LG"], "comment": "24 pages, 17 figures, 7 tables", "summary": "Diffusion MRI (dMRI) enables non-invasive assessment of prostate microstructure but conventional metrics such as the Apparent Diffusion Coefficient in multiparametric MRI lack specificity to underlying histology. Integrating dMRI with the compartment-based biophysical VERDICT (Vascular, Extracellular, and Restricted Diffusion for Cytometry in Tumours) framework offers richer microstructural insights, though clinical gradient systems (40-80 mT/m) suffer from poor signal-to-noise ratio (SNR) at stronger diffusion weightings due to prolonged echo times. Ultra-strong gradients (up to 300 mT/m) can mitigate these limitations by improving SNR and contrast-to-noise ratios (CNR) but their adoption has until recently been limited to research environments due to challenges with peripheral nerve stimulation thresholds and gradient non-uniformity. This study investigates whether physics-informed self-supervised VERDICT (ssVERDICT) fitting applied to ultra-strong gradients enhances prostate cancer characterization relative to current clinical acquisitions. We developed enhanced ssVERDICT fitting approaches using dense multilayer perceptron (Dense MLP) and convolutional U-Net architectures, benchmarking them against non-linear least-squares (NLLS) fitting and Diffusion Kurtosis Imaging across clinical- to ultra-strong gradient systems. Dense ssVERDICT at ultra-strong gradient notably outperformed NLLS VERDICT, boosting median CNR by 47%, cutting inter-patient Coefficient of Variation by 52%, and reducing pooled f_ic variation by 50%. Overall, it delivered the highest CNR, the most stable parameter estimates, and the clearest tumour-normal contrast compared with conventional methods and clinical gradient systems. These findings highlight the potential of advanced gradient systems and deep learning-based modelling to improve non-invasive prostate cancer characterization and reduce unnecessary biopsies.", "AI": {"tldr": "This study demonstrates that combining ultra-strong diffusion MRI gradients with deep learning-based VERDICT fitting significantly enhances the characterization of prostate cancer, surpassing conventional clinical methods.", "motivation": "Current conventional MRI metrics used in prostate cancer detection lack specificity to tissue histology. Ultra-strong diffusion gradients combined with advanced biophysical models may improve microstructural cancer detection.", "method": "Researchers applied Dense MLP and U-Net architectures for self-supervised VERDICT fitting and analyzed performance compared to standard non-linear least square methods across clinical-to-ultra-strong gradient diffusion MRI systems.", "result": "Ultra-strong gradient systems with Dense ssVERDICT fitting improved CNR by 47%, reduced CoV by 52%, and stabilized parameter estimates. These approaches delivered better contrast and tumor-normal differentiation than conventional methods.", "conclusion": "Using ultra-strong gradients and deep learning methods in MRI offers improved prostate cancer characterization, leading to potential reductions in unnecessary biopsies."}}
{"id": "2512.04048", "pdf": "https://arxiv.org/pdf/2512.04048", "abs": "https://arxiv.org/abs/2512.04048", "authors": ["Sen Fang", "Yalin Feng", "Hongbin Zhong", "Yanxin Zhang", "Dimitris N. Metaxas"], "title": "Stable Signer: Hierarchical Sign Language Generative Model", "categories": ["cs.CV", "cs.CL", "cs.CY"], "comment": "12 pages, 7 figures. More Demo at https://stablesigner.github.io", "summary": "Sign Language Production (SLP) is the process of converting the complex input text into a real video. Most previous works focused on the Text2Gloss, Gloss2Pose, Pose2Vid stages, and some concentrated on Prompt2Gloss and Text2Avatar stages. However, this field has made slow progress due to the inaccuracy of text conversion, pose generation, and the rendering of poses into real human videos in these stages, resulting in gradually accumulating errors. Therefore, in this paper, we streamline the traditional redundant structure, simplify and optimize the task objective, and design a new sign language generative model called Stable Signer. It redefines the SLP task as a hierarchical generation end-to-end task that only includes text understanding (Prompt2Gloss, Text2Gloss) and Pose2Vid, and executes text understanding through our proposed new Sign Language Understanding Linker called SLUL, and generates hand gestures through the named SLP-MoE hand gesture rendering expert block to end-to-end generate high-quality and multi-style sign language videos. SLUL is trained using the newly developed Semantic-Aware Gloss Masking Loss (SAGM Loss). Its performance has improved by 48.6% compared to the current SOTA generation methods.", "AI": {"tldr": "The paper proposes 'Stable Signer', an end-to-end model for generating high-quality sign language videos, improving performance by 48.6%.", "motivation": "Slow progress in Sign Language Production due to inaccuracies in text conversion, pose generation, and video rendering, along with accumulating errors in traditional methods.", "method": "Introduces 'Stable Signer', redefining SLP as an end-to-end hierarchical task. Incorporates the SLUL component with the Semantic-Aware Gloss Masking Loss (SAGM Loss) for text understanding and a specialized SLP-MoE block for hand gesture rendering.", "result": "'Stable Signer' significantly outperforms current methods, improving performance by 48.6% in sign language video generation.", "conclusion": "'Stable Signer' simplifies the SLP process and enhances efficiency, offering a more accurate and comprehensive way to produce high-quality, multi-style sign language videos."}}
{"id": "2512.03590", "pdf": "https://arxiv.org/pdf/2512.03590", "abs": "https://arxiv.org/abs/2512.03590", "authors": ["Yuchen Deng", "Xiuyang Wu", "Hai-Tao Zheng", "Jie Wang", "Feidiao Yang", "Yuxing Han"], "title": "Beyond Boundary Frames: Audio-Visual Semantic Guidance for Context-Aware Video Interpolation", "categories": ["cs.CV"], "comment": null, "summary": "Handling fast, complex, and highly non-linear motion patterns has long posed challenges for video frame interpolation. Although recent diffusion-based approaches improve upon traditional optical-flow-based methods, they still struggle to cover diverse application scenarios and often fail to produce sharp, temporally consistent frames in fine-grained motion tasks such as audio-visual synchronized interpolation. To address these limitations, we introduce BBF (Beyond Boundary Frames), a context-aware video frame interpolation framework, which could be guided by audio/visual semantics. First, we enhance the input design of the interpolation model so that it can flexibly handle multiple conditional modalities, including text, audio, images, and video. Second, we propose a decoupled multimodal fusion mechanism that sequentially injects different conditional signals into a DiT backbone. Finally, to maintain the generation abilities of the foundation model, we adopt a progressive multi-stage training paradigm, where the start-end frame difference embedding is used to dynamically adjust both the data sampling and the loss weighting. Extensive experimental results demonstrate that BBF outperforms specialized state-of-the-art methods on both generic interpolation and audio-visual synchronized interpolation tasks, establishing a unified framework for video frame interpolation under coordinated multi-channel conditioning.", "AI": {"tldr": "The paper introduces BBF, a video frame interpolation framework utilizing audio/visual semantics and a multimodal fusion mechanism, showing superior performance over state-of-the-art methods.", "motivation": "To overcome challenges in video frame interpolation, especially in handling fast, non-linear motion and achieving temporal consistency in fine-grained tasks.", "method": "BBF uses enhanced input design for multimodal conditioning, a decoupled multimodal fusion mechanism based on a DiT backbone, and a progressive multi-stage training paradigm.", "result": "BBF showed superior performance over current state-of-the-art methods in both generic and synchronized audio-visual interpolation.", "conclusion": "BBF establishes a unified, context-aware framework for video frame interpolation with improved capability and flexibility under multiple conditioning modalities."}}
{"id": "2512.03471", "pdf": "https://arxiv.org/pdf/2512.03471", "abs": "https://arxiv.org/abs/2512.03471", "authors": ["Ian Henriques", "Lynda Elhassar", "Sarvesh Relekar", "Denis Walrave", "Shayan Hassantabar", "Vishu Ghanakota", "Adel Laoui", "Mahmoud Aich", "Rafia Tir", "Mohamed Zerguine", "Samir Louafi", "Moncef Kimouche", "Emmanuel Cosson", "Niraj K Jha"], "title": "SweetDeep: A Wearable AI Solution for Real-Time Non-Invasive Diabetes Screening", "categories": ["cs.LG", "cs.CY"], "comment": "12 pages, 6 figures. Submitted to the IEEE Journal of Biomedical and Health Informatics", "summary": "The global rise in type 2 diabetes underscores the need for scalable and cost-effective screening methods. Current diagnosis requires biochemical assays, which are invasive and costly. Advances in consumer wearables have enabled early explorations of machine learning-based disease detection, but prior studies were limited to controlled settings. We present SweetDeep, a compact neural network trained on physiological and demographic data from 285 (diabetic and non-diabetic) participants in the EU and MENA regions, collected using Samsung Galaxy Watch 7 devices in free-living conditions over six days. Each participant contributed multiple 2-minute sensor recordings per day, totaling approximately 20 recordings per individual. Despite comprising fewer than 3,000 parameters, SweetDeep achieves 82.5% patient-level accuracy (82.1% macro-F1, 79.7% sensitivity, 84.6% specificity) under three-fold cross-validation, with an expected calibration error of 5.5%. Allowing the model to abstain on less than 10% of low-confidence patient predictions yields an accuracy of 84.5% on the remaining patients. These findings demonstrate that combining engineered features with lightweight architectures can support accurate, rapid, and generalizable detection of type 2 diabetes in real-world wearable settings.", "AI": {"tldr": "SweetDeep, a neural network model, uses wearable sensor data to detect type 2 diabetes with high accuracy in real-world settings.", "motivation": "The increasing prevalence of type 2 diabetes calls for non-invasive, scalable, and cost-effective screening solutions beyond traditional biochemical assays.", "method": "SweetDeep is a lightweight neural network trained on wearable device recordings and demographic data from 285 participants under free-living conditions.", "result": "SweetDeep achieves an 82.5% patient-level accuracy with 82.1% macro-F1, 79.7% sensitivity, and 84.6% specificity, improving accuracy with abstentions on low-confidence predictions.", "conclusion": "Efficient lightweight ML models like SweetDeep can enable accurate and scalable detection of type 2 diabetes using real-world wearable devices."}}
{"id": "2512.03592", "pdf": "https://arxiv.org/pdf/2512.03592", "abs": "https://arxiv.org/abs/2512.03592", "authors": ["Guang Yang", "Lei Fan"], "title": "Harnessing Hypergraphs in Geometric Deep Learning for 3D RNA Inverse Folding", "categories": ["cs.CV"], "comment": null, "summary": "The RNA inverse folding problem, a key challenge in RNA design, involves identifying nucleotide sequences that can fold into desired secondary structures, which are critical for ensuring molecular stability and function. The inherent complexity of this task stems from the intricate relationship between sequence and structure, making it particularly challenging. In this paper, we propose a framework, named HyperRNA, a generative model with an encoder-decoder architecture that leverages hypergraphs to design RNA sequences. Specifically, our HyperRNA model consists of three main components: preprocessing, encoding and decoding.\n  In the preprocessing stage, graph structures are constructed by extracting the atom coordinates of RNA backbone based on 3-bead coarse-grained representation. The encoding stage processes these graphs, capturing higher order dependencies and complex biomolecular interactions using an attention embedding module and a hypergraph-based encoder. Finally, the decoding stage generates the RNA sequence in an autoregressive manner. We conducted quantitative and qualitative experiments on the PDBBind and RNAsolo datasets to evaluate the inverse folding task for RNA sequence generation and RNA-protein complex sequence generation. The experimental results demonstrate that HyperRNA not only outperforms existing RNA design methods but also highlights the potential of leveraging hypergraphs in RNA engineering.", "AI": {"tldr": "HyperRNA is a novel generative model using hypergraphs for solving the RNA inverse folding problem, designed with an encoder-decoder architecture for RNA sequence design.", "motivation": "The study addresses the challenge of RNA inverse folding, which involves designing nucleotide sequences capable of folding into desired secondary structures. This is crucial for ensuring the stability and function of RNA molecules, but remains complex due to the intricate sequence-structure relationships.", "method": "HyperRNA employs a three-stage process: preprocessing (graph construction using RNA molecular coordinates), encoding (utilizing a hypergraph-based encoder and attention embedding to capture interactions), and decoding (autoregulative RNA sequence generation).", "result": "HyperRNA outperformed existing methods in RNA inverse folding and RNA-protein complex sequence generation tasks, demonstrated on PDBBind and RNAsolo datasets.", "conclusion": "Hypergraphs offer significant promise in RNA design, as illustrated by the superior performance of the HyperRNA model, marking advancements in RNA engineering."}}
{"id": "2512.03475", "pdf": "https://arxiv.org/pdf/2512.03475", "abs": "https://arxiv.org/abs/2512.03475", "authors": ["Hongtao Hao", "Joseph L. Austerweil"], "title": "Joint Progression Modeling (JPM): A Probabilistic Framework for Mixed-Pathology Progression", "categories": ["cs.LG", "stat.AP"], "comment": "49 pages; Machine Learning for Health (ML4H) Symposium 2025", "summary": "Event-based models (EBMs) infer disease progression from cross-sectional data, and standard EBMs assume a single underlying disease per individual. In contrast, mixed pathologies are common in neurodegeneration. We introduce the Joint Progression Model (JPM), a probabilistic framework that treats single-disease trajectories as partial rankings and builds a prior over joint progressions. We study several JPM variants (Pairwise, Bradley-Terry, Plackett-Luce, and Mallows) and analyze three properties: (i) calibration -- whether lower model energy predicts smaller distance to the ground truth ordering; (ii) separation -- the degree to which sampled rankings are distinguishable from random permutations; and (iii) sharpness -- the stability of sampled aggregate rankings. All variants are calibrated, and all achieve near-perfect separation; sharpness varies by variant and is well-predicted by simple features of the input partial rankings (number and length of rankings, conflict, and overlap). In synthetic experiments, JPM improves ordering accuracy by roughly 21 percent over a strong EBM baseline (SA-EBM) that treats the joint disease as a single condition. Finally, using NACC, we find that the Mallows variant of JPM and the baseline model (SA-EBM) have results that are more consistent with prior literature on the possible disease progression of the mixed pathology of AD and VaD.", "AI": {"tldr": "The paper introduces the Joint Progression Model (JPM) to improve accuracy in modeling mixed disease progressions, outperforming baseline event-based models (EBMs).", "motivation": "Mixed pathologies are prevalent in neurodegenerative diseases, but existing models assume single disease progression per individual, limiting their accuracy.", "method": "The authors developed JPM, which applies probabilistic frameworks and partial rankings to model joint disease progressions. Several variants, such as Pairwise, Bradley-Terry, Plackett-Luce, and Mallows, were studied.", "result": "JPM demonstrated improved calibration, separation, and additional sharpness features, achieving a 21% increase in ordering accuracy over baseline EBMs. The Mallows variant aligned with prior literature on mixed pathology progression.", "conclusion": "JPM effectively models mixed disease progressions and provides more accurate and interpretable results compared to traditional single-disease models."}}
{"id": "2512.03593", "pdf": "https://arxiv.org/pdf/2512.03593", "abs": "https://arxiv.org/abs/2512.03593", "authors": ["David Svitov", "Pietro Morerio", "Lourdes Agapito", "Alessio Del Bue"], "title": "CloseUpAvatar: High-Fidelity Animatable Full-Body Avatars with Mixture of Multi-Scale Textures", "categories": ["cs.CV"], "comment": null, "summary": "We present a CloseUpAvatar - a novel approach for articulated human avatar representation dealing with more general camera motions, while preserving rendering quality for close-up views. CloseUpAvatar represents an avatar as a set of textured planes with two sets of learnable textures for low and high-frequency detail. The method automatically switches to high-frequency textures only for cameras positioned close to the avatar's surface and gradually reduces their impact as the camera moves farther away. Such parametrization of the avatar enables CloseUpAvatar to adjust rendering quality based on camera distance ensuring realistic rendering across a wider range of camera orientations than previous approaches. We provide experiments using the ActorsHQ dataset with high-resolution input images. CloseUpAvatar demonstrates both qualitative and quantitative improvements over existing methods in rendering from novel wide range camera positions, while maintaining high FPS by limiting the number of required primitives.", "AI": {"tldr": "CloseUpAvatar is a novel articulated human avatar representation using textured planes, adjusting rendering quality dynamically based on camera distance, ensuring realism for close-up views and wide camera angles.", "motivation": "To address limitations of human avatar rendering systems in managing close-up views and wide-ranging camera motions without sacrificing quality or performance.", "method": "CloseUpAvatar uses textured planes with two learnable texture sets for low and high-frequency details, automatically switching based on camera distance to balance rendering quality and efficiency.", "result": "Tests on the ActorsHQ dataset show improvements in rendering quality and FPS over existing methods, supporting adaptive and realistic rendering from diverse camera angles and distances.", "conclusion": "CloseUpAvatar enhances articulated human avatar representation by providing efficient and realistic rendering across various camera orientations, surpassing existing approaches in quality and performance."}}
{"id": "2512.03476", "pdf": "https://arxiv.org/pdf/2512.03476", "abs": "https://arxiv.org/abs/2512.03476", "authors": ["Juan Diego Toscano", "Daniel T. Chen", "George Em Karniadakis"], "title": "ATHENA: Agentic Team for Hierarchical Evolutionary Numerical Algorithms", "categories": ["cs.LG", "cs.AI", "cs.MA", "math.NA", "physics.comp-ph"], "comment": null, "summary": "Bridging the gap between theoretical conceptualization and computational implementation is a major bottleneck in Scientific Computing (SciC) and Scientific Machine Learning (SciML). We introduce ATHENA (Agentic Team for Hierarchical Evolutionary Numerical Algorithms), an agentic framework designed as an Autonomous Lab to manage the end-to-end computational research lifecycle. Its core is the HENA loop, a knowledge-driven diagnostic process framed as a Contextual Bandit problem. Acting as an online learner, the system analyzes prior trials to select structural `actions' ($A_n$) from combinatorial spaces guided by expert blueprints (e.g., Universal Approximation, Physics-Informed constraints). These actions are translated into executable code ($S_n$) to generate scientific rewards ($R_n$). ATHENA transcends standard automation: in SciC, it autonomously identifies mathematical symmetries for exact analytical solutions or derives stable numerical solvers where foundation models fail. In SciML, it performs deep diagnosis to tackle ill-posed formulations and combines hybrid symbolic-numeric workflows (e.g., coupling PINNs with FEM) to resolve multiphysics problems. The framework achieves super-human performance, reaching validation errors of $10^{-14}$. Furthermore, collaborative ``human-in-the-loop\" intervention allows the system to bridge stability gaps, improving results by an order of magnitude. This paradigm shift focuses from implementation mechanics to methodological innovation, accelerating scientific discovery.", "AI": {"tldr": "The paper introduces ATHENA, an autonomous computational framework that manages the entire research lifecycle, achieving super-human performance in scientific computing and machine learning.", "motivation": "To address the gap between theoretical conceptualization and computational implementation, which hampers progress in scientific computing and scientific machine learning.", "method": "ATHENA is based on the HENA loop, a knowledge-driven diagnostic framework modeled as a Contextual Bandit problem, which autonomously analyzes and derives optimal computational strategies while allowing human intervention.", "result": "ATHENA demonstrated super-human performance, achieving extraordinarily low validation errors ($10^{-14}$) and enhanced computational outcomes through hybrid workflows and human collaboration.", "conclusion": "ATHENA redefines computational research, shifting the focus from operational execution to innovative methodologies, thereby accelerating scientific discovery."}}
{"id": "2512.03597", "pdf": "https://arxiv.org/pdf/2512.03597", "abs": "https://arxiv.org/abs/2512.03597", "authors": ["Fuchen Zheng", "Xinyi Chen", "Weixuan Li", "Quanjun Li", "Junhua Zhou", "Xiaojiao Guo", "Xuhang Chen", "Chi-Man Pun", "Shoujun Zhou"], "title": "HBFormer: A Hybrid-Bridge Transformer for Microtumor and Miniature Organ Segmentation", "categories": ["cs.CV"], "comment": "6 pages, 4 figures, 3 tables", "summary": "Medical image segmentation is a cornerstone of modern clinical diagnostics. While Vision Transformers that leverage shifted window-based self-attention have established new benchmarks in this field, they are often hampered by a critical limitation: their localized attention mechanism struggles to effectively fuse local details with global context. This deficiency is particularly detrimental to challenging tasks such as the segmentation of microtumors and miniature organs, where both fine-grained boundary definition and broad contextual understanding are paramount. To address this gap, we propose HBFormer, a novel Hybrid-Bridge Transformer architecture. The 'Hybrid' design of HBFormer synergizes a classic U-shaped encoder-decoder framework with a powerful Swin Transformer backbone for robust hierarchical feature extraction. The core innovation lies in its 'Bridge' mechanism, a sophisticated nexus for multi-scale feature integration. This bridge is architecturally embodied by our novel Multi-Scale Feature Fusion (MFF) decoder. Departing from conventional symmetric designs, the MFF decoder is engineered to fuse multi-scale features from the encoder with global contextual information. It achieves this through a synergistic combination of channel and spatial attention modules, which are constructed from a series of dilated and depth-wise convolutions. These components work in concert to create a powerful feature bridge that explicitly captures long-range dependencies and refines object boundaries with exceptional precision. Comprehensive experiments on challenging medical image segmentation datasets, including multi-organ, liver tumor, and bladder tumor benchmarks, demonstrate that HBFormer achieves state-of-the-art results, showcasing its outstanding capabilities in microtumor and miniature organ segmentation. Code and models are available at: https://github.com/lzeeorno/HBFormer.", "AI": {"tldr": "HBFormer improves medical image segmentation, resolving issues with global context integration by using a novel Hybrid-Bridge Transformer.", "motivation": "Current Vision Transformers struggle with fusing local details and global context, limiting their effectiveness in segmenting microtumors and miniature organs.", "method": "The HBFormer introduces a Hybrid U-shaped framework using the Swin Transformer backbone and a novel Multi-Scale Feature Fusion (MFF) decoder with channel and spatial attention modules.", "result": "HBFormer outperforms existing models, achieving state-of-the-art results on multi-organ, liver tumor, and bladder tumor segmentation datasets.", "conclusion": "HBFormer significantly enhances precision in challenging medical image segmentation tasks by effectively integrating multi-scale features and global context."}}
{"id": "2512.03491", "pdf": "https://arxiv.org/pdf/2512.03491", "abs": "https://arxiv.org/abs/2512.03491", "authors": ["Antonin Sulc"], "title": "Modal Logical Neural Networks", "categories": ["cs.LG", "cs.LO", "cs.MA"], "comment": "27 pages, 10 figures, 7 tables", "summary": "We propose Modal Logical Neural Networks (MLNNs), a neurosymbolic framework that integrates deep learning with the formal semantics of modal logic, enabling reasoning about necessity and possibility. Drawing on Kripke semantics, we introduce specialized neurons for the modal operators $\\Box$ and $\\Diamond$ that operate over a set of possible worlds, enabling the framework to act as a differentiable ``logical guardrail.'' The architecture is highly flexible: the accessibility relation between worlds can either be fixed by the user to enforce known rules or, as an inductive feature, be parameterized by a neural network. This allows the model to optionally learn the relational structure of a logical system from data while simultaneously performing deductive reasoning within that structure.\n  This versatile construction is designed for flexibility. The entire framework is differentiable from end to end, with learning driven by minimizing a logical contradiction loss. This not only makes the system resilient to inconsistent knowledge but also enables it to learn nonlinear relationships that can help define the logic of a problem space. We illustrate MLNNs on four case studies: grammatical guardrailing, axiomatic detection of the unknown, multi-agent epistemic trust, and detecting constructive deception in natural language negotiation. These experiments demonstrate how enforcing or learning accessibility can increase logical consistency and interpretability without changing the underlying task architecture.", "AI": {"tldr": "The paper introduces MLNNs, which combine deep learning and modal logic for reasoning about necessity and possibility using Kripke semantics. The framework allows logical reasoning via specialized neurons and is designed to ensure logical consistency and interpretability.", "motivation": "To integrate deep learning with formal semantics of modal logic for doing logical reasoning about necessity and possibility while ensuring flexibility and interpretability.", "method": "The framework constructs specialized neurons for modal operators ($\\Box$ and $\\Diamond$) based on Kripke semantics, enabling reasoning across possible worlds. It uses a differentiable structure for logical guardrailing, with an optional learnable accessibility relation driven by minimizing logical contradiction loss.", "result": "The proposed model is applied to four cases: grammatical guardrails, unknown axiomatic detection, epistemic trust in agents, and spotting constructive deception. The experiments demonstrate increased logical consistency and interpretability.", "conclusion": "MLNNs successfully integrate neural architectures with modal logic, achieving both deductive reasoning and the flexibility to learn logical relations from data while ensuring logical consistency and interpretability."}}
{"id": "2512.03248", "pdf": "https://arxiv.org/pdf/2512.03248", "abs": "https://arxiv.org/abs/2512.03248", "authors": ["Enrico Grimaldi", "Mario Edoardo Pandolfo", "Gabriele D'Acunto", "Sergio Barbarossa", "Paolo Di Lorenzo"], "title": "Learning Network Sheaves for AI-native Semantic Communication", "categories": ["cs.MA", "cs.AI", "cs.LG", "eess.SP"], "comment": null, "summary": "Recent advances in AI call for a paradigm shift from bit-centric communication to goal- and semantics-oriented architectures, paving the way for AI-native 6G networks. In this context, we address a key open challenge: enabling heterogeneous AI agents to exchange compressed latent-space representations while mitigating semantic noise and preserving task-relevant meaning. We cast this challenge as learning both the communication topology and the alignment maps that govern information exchange among agents, yielding a learned network sheaf equipped with orthogonal maps. This learning process is further supported by a semantic denoising end compression module that constructs a shared global semantic space and derives sparse, structured representations of each agent's latent space. This corresponds to a nonconvex dictionary learning problem solved iteratively with closed-form updates. Experiments with mutiple AI agents pre-trained on real image data show that the semantic denoising and compression facilitates AI agents alignment and the extraction of semantic clusters, while preserving high accuracy in downstream task. The resulting communication network provides new insights about semantic heterogeneity across agents, highlighting the interpretability of our methodology.", "AI": {"tldr": "The paper introduces AI-native 6G networks enabling semantics-oriented communication and proposes a learned network sheaf structure to mitigate semantic noise and align heterogeneous AI agents.", "motivation": "To address the challenge of establishing effective communication among heterogeneous AI agents by leveraging semantic compression and alignment.", "method": "Developed a learned network sheaf with orthogonal maps complemented by a semantic denoising and compression module for global semantic space construction and sparse latent representations.", "result": "Experiments with pre-trained AI agents demonstrate improved alignment, semantic cluster extraction, and preservation of task accuracy.", "conclusion": "The proposed technique enhances semantic communication while unveiling agent heterogeneity, fostering interpretability for AI-native networks."}}
{"id": "2512.03598", "pdf": "https://arxiv.org/pdf/2512.03598", "abs": "https://arxiv.org/abs/2512.03598", "authors": ["Jianan Sun", "Yukang Huang", "Dongzhihan Wang", "Mingyu Fan"], "title": "Memory-Guided Point Cloud Completion for Dental Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "Partial dental point clouds often suffer from large missing regions caused by occlusion and limited scanning views, which bias encoder-only global features and force decoders to hallucinate structures. We propose a retrieval-augmented framework for tooth completion that integrates a prototype memory into standard encoder--decoder pipelines. After encoding a partial input into a global descriptor, the model retrieves the nearest manifold prototype from a learnable memory and fuses it with the query feature through confidence-gated weighting before decoding. The memory is optimized end-to-end and self-organizes into reusable tooth-shape prototypes without requiring tooth-position labels, thereby providing structural priors that stabilize missing-region inference and free decoder capacity for detail recovery. The module is plug-and-play and compatible with common completion backbones, while keeping the same training losses. Experiments on a self-processed Teeth3DS benchmark demonstrate consistent improvements in Chamfer Distance, with visualizations showing sharper cusps, ridges, and interproximal transitions. Our approach provides a simple yet effective way to exploit cross-sample regularities for more accurate and faithful dental point-cloud completion.", "AI": {"tldr": "The paper presents a retrieval-augmented framework for dental point cloud completion using a learnable memory for reusable tooth-shape prototypes, achieving improved structural inference and detail recovery.", "motivation": "Large missing regions in dental point clouds due to occlusion and limited scanning bias completion processes and hinder accurate reconstruction.", "method": "The method introduces a prototype memory into encoder-decoder pipelines, retrieves a prototype based on input features, and integrates it for inference. The memory self-organizes into useful structural prototypes during end-to-end training.", "result": "The proposed method outperforms others on the Teeth3DS benchmark, showing significant improvements in Chamfer Distance and better reconstruction of finer tooth structures.", "conclusion": "This retrieval-augmented framework effectively provides structural priors, stabilizing the task of dental point-cloud completion while improving accuracy and detail quality in reconstructions."}}
{"id": "2512.03512", "pdf": "https://arxiv.org/pdf/2512.03512", "abs": "https://arxiv.org/abs/2512.03512", "authors": ["Xuanxuan Yang", "Xiuyang Zhang", "Haofeng Chen", "Gang Ma", "Xiaojie Wang"], "title": "Physics-Driven Learning Framework for Tomographic Tactile Sensing", "categories": ["cs.LG", "cs.AI"], "comment": "7pages,7figures", "summary": "Electrical impedance tomography (EIT) provides an attractive solution for large-area tactile sensing due to its minimal wiring and shape flexibility, but its nonlinear inverse problem often leads to severe artifacts and inaccurate contact reconstruction. This work presents PhyDNN, a physics-driven deep reconstruction framework that embeds the EIT forward model directly into the learning objective. By jointly minimizing the discrepancy between predicted and ground-truth conductivity maps and enforcing consistency with the forward PDE, PhyDNN reduces the black-box nature of deep networks and improves both physical plausibility and generalization. To enable efficient backpropagation, we design a differentiable forward-operator network that accurately approximates the nonlinear EIT response, allowing fast physics-guided training. Extensive simulations and real tactile experiments on a 16-electrode soft sensor show that PhyDNN consistently outperforms NOSER, TV, and standard DNNs in reconstructing contact shape, location, and pressure distribution. PhyDNN yields fewer artifacts, sharper boundaries, and higher metric scores, demonstrating its effectiveness for high-quality tomographic tactile sensing.", "AI": {"tldr": "This paper introduces PhyDNN, a reconstruction framework for EIT tactile sensing, which enhances accuracy and physical plausibility by integrating physics-driven deep learning.", "motivation": "To address the challenges of severe artifacts and inaccuracies in contact reconstruction caused by the non-linear inverse problem of EIT-based tactile sensing.", "method": "The proposed PhyDNN integrates the EIT forward model into the deep learning objective, employs a differentiable forward-operator network, and trains to minimize discrepancies between predictions, ground truths, and enforce physical consistency.", "result": "Simulations and tactile experiments show that PhyDNN outperforms traditional methods (NOSER, TV, and DNNs) by producing fewer artifacts and sharper reconstructions, achieving superior metric scores.", "conclusion": "PhyDNN is a promising advancement for EIT, offering improved reconstruction quality, accuracy, and applicability in tomographic tactile sensing."}}
{"id": "2512.03601", "pdf": "https://arxiv.org/pdf/2512.03601", "abs": "https://arxiv.org/abs/2512.03601", "authors": ["Haoran Zhou", "Gim Hee Lee"], "title": "Motion4D: Learning 3D-Consistent Motion and Semantics for 4D Scene Understanding", "categories": ["cs.CV"], "comment": "Accepted to NeurIPS 2025", "summary": "Recent advancements in foundation models for 2D vision have substantially improved the analysis of dynamic scenes from monocular videos. However, despite their strong generalization capabilities, these models often lack 3D consistency, a fundamental requirement for understanding scene geometry and motion, thereby causing severe spatial misalignment and temporal flickering in complex 3D environments. In this paper, we present Motion4D, a novel framework that addresses these challenges by integrating 2D priors from foundation models into a unified 4D Gaussian Splatting representation. Our method features a two-part iterative optimization framework: 1) Sequential optimization, which updates motion and semantic fields in consecutive stages to maintain local consistency, and 2) Global optimization, which jointly refines all attributes for long-term coherence. To enhance motion accuracy, we introduce a 3D confidence map that dynamically adjusts the motion priors, and an adaptive resampling process that inserts new Gaussians into under-represented regions based on per-pixel RGB and semantic errors. Furthermore, we enhance semantic coherence through an iterative refinement process that resolves semantic inconsistencies by alternately optimizing the semantic fields and updating prompts of SAM2. Extensive evaluations demonstrate that our Motion4D significantly outperforms both 2D foundation models and existing 3D-based approaches across diverse scene understanding tasks, including point-based tracking, video object segmentation, and novel view synthesis. Our code is available at https://hrzhou2.github.io/motion4d-web/.", "AI": {"tldr": "Motion4D integrates 2D priors from foundation models into a 4D Gaussian Splatting representation for improved 3D consistency in dynamic scene analysis.", "motivation": "Foundation models for 2D vision often lack the 3D consistency needed for accurate scene geometry and motion analysis, leading to misalignments and flickering.", "method": "Motion4D employs a two-part iterative optimization framework: sequential optimization (for local consistency) and global optimization (for coherence), supplemented by a 3D confidence map and adaptive resampling.", "result": "Motion4D outperforms existing 2D and 3D-based approaches across various tasks, including point-based tracking, video object segmentation, and novel view synthesis.", "conclusion": "The proposed framework significantly enhances 3D consistency in dynamic scene understanding and overcomes limitations of existing methods."}}
{"id": "2512.03525", "pdf": "https://arxiv.org/pdf/2512.03525", "abs": "https://arxiv.org/abs/2512.03525", "authors": ["Adil Rasheed", "Mikael Aleksander Jansen Shahly", "Muhammad Faisal Aftab"], "title": "Adaptive sampling using variational autoencoder and reinforcement learning", "categories": ["cs.LG"], "comment": null, "summary": "Compressed sensing enables sparse sampling but relies on generic bases and random measurements, limiting efficiency and reconstruction quality. Optimal sensor placement uses historcal data to design tailored sampling patterns, yet its fixed, linear bases cannot adapt to nonlinear or sample-specific variations. Generative model-based compressed sensing improves reconstruction using deep generative priors but still employs suboptimal random sampling. We propose an adaptive sparse sensing framework that couples a variational autoencoder prior with reinforcement learning to select measurements sequentially. Experiments show that this approach outperforms CS, OSP, and Generative model-based reconstruction from sparse measurements.", "AI": {"tldr": "The paper introduces an adaptive sparse sensing framework combining variational autoencoder and reinforcement learning, outperforming existing methods like compressed sensing, optimal sensor placement, and generative model-based reconstruction.", "motivation": "The paper aims to address limitations in existing methods for sparse sampling, which include fixed bases in optimal sensor placement and suboptimal random sampling in generative model-based compressed sensing.", "method": "A new framework is proposed that integrates a variational autoencoder to act as a prior and reinforcement learning for sequential measurement selection.", "result": "The model performs better than current techniques like compressed sensing (CS), optimal sensor placement (OSP), and generative model-based reconstruction when using sparse measurements.", "conclusion": "Using a combination of deep generative models and reinforcement learning allows for adaptive, efficient sparse sampling, demonstrating superior performance over traditional methods."}}
{"id": "2512.03278", "pdf": "https://arxiv.org/pdf/2512.03278", "abs": "https://arxiv.org/abs/2512.03278", "authors": ["Michael Theologitis", "Dan Suciu"], "title": "Thucy: An LLM-based Multi-Agent System for Claim Verification across Relational Databases", "categories": ["cs.DB", "cs.AI"], "comment": "Accepted at AAAI 2026 Workshop on LLM-based Multi-Agent Systems (LaMAS)", "summary": "In today's age, it is becoming increasingly difficult to decipher truth from lies. Every day, politicians, media outlets, and public figures make conflicting claims$\\unicode{x2014}$often about topics that can, in principle, be verified against structured data. For instance, statements about crime rates, economic growth or healthcare can all be verified against official public records and structured datasets. Building a system that can automatically do that would have sounded like science fiction just a few years ago. Yet, with the extraordinary progress in LLMs and agentic AI, this is now within reach. Still, there remains a striking gap between what is technically possible and what is being demonstrated by recent work. Most existing verification systems operate only on small, single-table databases$\\unicode{x2014}$typically a few hundred rows$\\unicode{x2014}$that conveniently fit within an LLM's context window.\n  In this paper we report our progress on Thucy, the first cross-database, cross-table multi-agent claim verification system that also provides concrete evidence for each verification verdict. Thucy remains completely agnostic to the underlying data sources before deployment and must therefore autonomously discover, inspect, and reason over all available relational databases to verify claims. Importantly, Thucy also reports the exact SQL queries that support its verdict (whether the claim is accurate or not) offering full transparency to expert users familiar with SQL. When evaluated on the TabFact dataset$\\unicode{x2014}$the standard benchmark for fact verification over structured data$\\unicode{x2014}$Thucy surpasses the previous state of the art by 5.6 percentage points in accuracy (94.3% vs. 88.7%).", "AI": {"tldr": "The paper introduces Thucy, a system for verifying claims across multiple databases and providing evidence through SQL queries, achieving state-of-the-art performance.", "motivation": "The increasing prevalence of dubious claims by public figures and the need for automatic methods to verify these claims motivate the development of systems like Thucy. Current systems are limited to small, single-table databases.", "method": "Thucy is a multi-agent claim verification system designed to work across multiple relational databases. It autonomously discovers and reasons over data, providing SQL-based evidence to support its verdicts.", "result": "Thucy outperformed previous benchmarks on the TabFact dataset, achieving an accuracy of 94.3%, surpassing the previous state-of-the-art by 5.6 percentage points.", "conclusion": "This advancement marks a significant step towards scalable, transparent, and automated claim verification systems capable of handling complex, cross-database queries."}}
{"id": "2512.03619", "pdf": "https://arxiv.org/pdf/2512.03619", "abs": "https://arxiv.org/abs/2512.03619", "authors": ["Muhammed Burak Kizil", "Enes Sanli", "Niloy J. Mitra", "Erkut Erdem", "Aykut Erdem", "Duygu Ceylan"], "title": "LAMP: Language-Assisted Motion Planning for Controllable Video Generation", "categories": ["cs.CV"], "comment": null, "summary": "Video generation has achieved remarkable progress in visual fidelity and controllability, enabling conditioning on text, layout, or motion. Among these, motion control - specifying object dynamics and camera trajectories - is essential for composing complex, cinematic scenes, yet existing interfaces remain limited. We introduce LAMP that leverages large language models (LLMs) as motion planners to translate natural language descriptions into explicit 3D trajectories for dynamic objects and (relatively defined) cameras. LAMP defines a motion domain-specific language (DSL), inspired by cinematography conventions. By harnessing program synthesis capabilities of LLMs, LAMP generates structured motion programs from natural language, which are deterministically mapped to 3D trajectories. We construct a large-scale procedural dataset pairing natural text descriptions with corresponding motion programs and 3D trajectories. Experiments demonstrate LAMP's improved performance in motion controllability and alignment with user intent compared to state-of-the-art alternatives establishing the first framework for generating both object and camera motions directly from natural language specifications.", "AI": {"tldr": "The paper introduces LAMP, a framework that uses large language models to translate natural language into 3D trajectories for dynamic objects and cameras.", "motivation": "To address the limitations of existing motion control interfaces that hamper composing cinematic scenes with precise object and camera dynamics.", "method": "LAMP utilizes a motion domain-specific language, inspired by cinematography conventions, and leverages program synthesis capabilities of large language models to convert natural language into motion programs and 3D trajectories.", "result": "LAMP demonstrates improved motion controllability and better alignment with user intent compared to current state-of-the-art methods.", "conclusion": "LAMP is the first framework enabling natural language-based generation of both object and camera motions, promising enhanced controllability for complex scene composition."}}
{"id": "2512.03621", "pdf": "https://arxiv.org/pdf/2512.03621", "abs": "https://arxiv.org/abs/2512.03621", "authors": ["Yaokun Li", "Shuaixian Wang", "Mantang Guo", "Jiehui Huang", "Taojun Ding", "Mu Hu", "Kaixuan Wang", "Shaojie Shen", "Guang Tan"], "title": "ReCamDriving: LiDAR-Free Camera-Controlled Novel Trajectory Video Generation", "categories": ["cs.CV"], "comment": "Project page: https://recamdriving.github.io/", "summary": "We propose ReCamDriving, a purely vision-based, camera-controlled novel-trajectory video generation framework. While repair-based methods fail to restore complex artifacts and LiDAR-based approaches rely on sparse and incomplete cues, ReCamDriving leverages dense and scene-complete 3DGS renderings for explicit geometric guidance, achieving precise camera-controllable generation. To mitigate overfitting to restoration behaviors when conditioned on 3DGS renderings, ReCamDriving adopts a two-stage training paradigm: the first stage uses camera poses for coarse control, while the second stage incorporates 3DGS renderings for fine-grained viewpoint and geometric guidance. Furthermore, we present a 3DGS-based cross-trajectory data curation strategy to eliminate the train-test gap in camera transformation patterns, enabling scalable multi-trajectory supervision from monocular videos. Based on this strategy, we construct the ParaDrive dataset, containing over 110K parallel-trajectory video pairs. Extensive experiments demonstrate that ReCamDriving achieves state-of-the-art camera controllability and structural consistency.", "AI": {"tldr": "The paper proposes ReCamDriving, a vision-based framework for generating novel-trajectory videos with precise camera control, leveraging 3DGS renderings for guidance.", "motivation": "Address limitations in video generation by overcoming challenges in restoring complex artifacts and reliance on LiDAR-based, sparse, or incomplete cues.", "method": "Introduces a two-stage training paradigm: 1) Using camera poses for coarse control, 2) Incorporating 3DGS renderings for fine-grained guidance, alongside a 3DGS-based data curation strategy and a new dataset called ParaDrive.", "result": "ReCamDriving achieves state-of-the-art performance in camera controllability and structural consistency, supported by experiments.", "conclusion": "ReCamDriving establishes a novel and scalable framework for vision-based video generation with enhanced precision in camera control and geometrical guidance."}}
{"id": "2512.03564", "pdf": "https://arxiv.org/pdf/2512.03564", "abs": "https://arxiv.org/abs/2512.03564", "authors": ["Xun Yuan", "Zilong Zhao", "Jiayu Li", "Aryan Pasikhani", "Prosanta Gope", "Biplab Sikdar"], "title": "Towards Irreversible Machine Unlearning for Diffusion Models", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Diffusion models are renowned for their state-of-the-art performance in generating synthetic images. However, concerns related to safety, privacy, and copyright highlight the need for machine unlearning, which can make diffusion models forget specific training data and prevent the generation of sensitive or unwanted content. Current machine unlearning methods for diffusion models are primarily designed for conditional diffusion models and focus on unlearning specific data classes or features. Among these methods, finetuning-based machine unlearning methods are recognized for their efficiency and effectiveness, which update the parameters of pre-trained diffusion models by minimizing carefully designed loss functions. However, in this paper, we propose a novel attack named Diffusion Model Relearning Attack (DiMRA), which can reverse the finetuning-based machine unlearning methods, posing a significant vulnerability of this kind of technique. Without prior knowledge of the unlearning elements, DiMRA optimizes the unlearned diffusion model on an auxiliary dataset to reverse the unlearning, enabling the model to regenerate previously unlearned elements. To mitigate this vulnerability, we propose a novel machine unlearning method for diffusion models, termed as Diffusion Model Unlearning by Memorization (DiMUM). Unlike traditional methods that focus on forgetting, DiMUM memorizes alternative data or features to replace targeted unlearning data or features in order to prevent generating such elements. In our experiments, we demonstrate the effectiveness of DiMRA in reversing state-of-the-art finetuning-based machine unlearning methods for diffusion models, highlighting the need for more robust solutions. We extensively evaluate DiMUM, demonstrating its superior ability to preserve the generative performance of diffusion models while enhancing robustness against DiMRA.", "AI": {"tldr": "This paper proposes Diffusion Model Relearning Attack (DiMRA) to demonstrate vulnerabilities in finetuning-based unlearning methods for diffusion models and introduces Diffusion Model Unlearning by Memorization (DiMUM) as a robust alternative.", "motivation": "Concerns such as safety, privacy, and copyright necessitate the ability for diffusion models to forget specific training data and avoid generating sensitive or unwanted content, while current solutions exhibit vulnerabilities.", "method": "The authors develop DiMRA, a novel attack that optimizes unlearned diffusion models to reverse unlearning effects using auxiliary datasets, and propose DiMUM, which replaces targeted data with alternative content to securely unlearn.", "result": "DiMRA demonstrates the ability to reverse state-of-the-art finetuning-based machine unlearning methods, while DiMUM exhibits improved robustness against DiMRA and maintains generative performance.", "conclusion": "The paper highlights limitations in current unlearning methods and emphasizes the importance of secure machine unlearning techniques, introducing DiMUM as an effective solution."}}
{"id": "2512.03625", "pdf": "https://arxiv.org/pdf/2512.03625", "abs": "https://arxiv.org/abs/2512.03625", "authors": ["Zhigang Yang", "Yuan Liu", "Jiawei Zhang", "Puning Zhang", "Xinqiang Ma"], "title": "FeatureLens: A Highly Generalizable and Interpretable Framework for Detecting Adversarial Examples Based on Image Features", "categories": ["cs.CV"], "comment": null, "summary": "Although the remarkable performance of deep neural networks (DNNs) in image classification, their vulnerability to adversarial attacks remains a critical challenge. Most existing detection methods rely on complex and poorly interpretable architectures, which compromise interpretability and generalization. To address this, we propose FeatureLens, a lightweight framework that acts as a lens to scrutinize anomalies in image features. Comprising an Image Feature Extractor (IFE) and shallow classifiers (e.g., SVM, MLP, or XGBoost) with model sizes ranging from 1,000 to 30,000 parameters, FeatureLens achieves high detection accuracy ranging from 97.8% to 99.75% in closed-set evaluation and 86.17% to 99.6% in generalization evaluation across FGSM, PGD, CW, and DAmageNet attacks, using only 51 dimensional features. By combining strong detection performance with excellent generalization, interpretability, and computational efficiency, FeatureLens offers a practical pathway toward transparent and effective adversarial defense.", "AI": {"tldr": "FeatureLens is a lightweight framework for detecting adversarial attacks in DNNs with high accuracy, generalizability, and interpretability.", "motivation": "Improve adversarial attack detection in DNNs by addressing the issues of poor interpretability and generalization in existing methods.", "method": "FeatureLens uses a two-component framework: an Image Feature Extractor (IFE) and shallow classifiers like SVM or XGBoost, utilizing only 51-dimensional features.", "result": "Achieves 97.8%-99.75% detection accuracy in closed-set evaluation and 86.17%-99.6% in generalization evaluation across multiple attack types.", "conclusion": "FeatureLens provides a computationally efficient, interpretable, and effective solution for adversarial attack defense in DNNs."}}
{"id": "2512.03578", "pdf": "https://arxiv.org/pdf/2512.03578", "abs": "https://arxiv.org/abs/2512.03578", "authors": ["Florent Forest", "Amaury Wei", "Olga Fink"], "title": "When, How Long and How Much? Interpretable Neural Networks for Time Series Regression by Learning to Mask and Aggregate", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 5 figures, 4 tables", "summary": "Time series extrinsic regression (TSER) refers to the task of predicting a continuous target variable from an input time series. It appears in many domains, including healthcare, finance, environmental monitoring, and engineering. In these settings, accurate predictions and trustworthy reasoning are both essential. Although state-of-the-art TSER models achieve strong predictive performance, they typically operate as black boxes, making it difficult to understand which temporal patterns drive their decisions. Post-hoc interpretability techniques, such as feature attribution, aim to to explain how the model arrives at its predictions, but often produce coarse, noisy, or unstable explanations. Recently, inherently interpretable approaches based on concepts, additive decompositions, or symbolic regression, have emerged as promising alternatives. However, these approaches remain limited: they require explicit supervision on the concepts themselves, often cannot capture interactions between time-series features, lack expressiveness for complex temporal patterns, and struggle to scale to high-dimensional multivariate data.\n  To address these limitations, we propose MAGNETS (Mask-and-AGgregate NEtwork for Time Series), an inherently interpretable neural architecture for TSER. MAGNETS learns a compact set of human-understandable concepts without requiring any annotations. Each concept corresponds to a learned, mask-based aggregation over selected input features, explicitly revealing both which features drive predictions and when they matter in the sequence. Predictions are formed as combinations of these learned concepts through a transparent, additive structure, enabling clear insight into the model's decision process.", "AI": {"tldr": "The paper introduces MAGNETS, an interpretable neural network for time series regression, solving challenges in black-box models and post-hoc interpretability approaches.", "motivation": "Current time series regression models are accurate but lack interpretability, and post-hoc interpretation methods are noisy or unstable. Additionally, existing inherently interpretable methods are limited in capturing complex temporal patterns and scaling to high-dimensional data.", "method": "The proposed MAGNETS model learns human-understandable concepts without annotations by employing mask-based aggregation to summarize important temporal features. It uses an interpretable additive structure for predictions, showing which features matter and when.", "result": "MAGNETS overcomes the limitations of noisy and coarse interpretability in black-box models while scaling well to complex, multivariate data.", "conclusion": "MAGNETS combines predictive performance with inherent interpretability by revealing critical feature interactions and their temporal importance directly within the model's architecture."}}
{"id": "2512.03640", "pdf": "https://arxiv.org/pdf/2512.03640", "abs": "https://arxiv.org/abs/2512.03640", "authors": ["Jiahao Zhang", "Xiao Zhao", "Guangyu Gao"], "title": "MKSNet: Advanced Small Object Detection in Remote Sensing Imagery with Multi-Kernel and Dual Attention Mechanisms", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Deep convolutional neural networks (DCNNs) have substantially advanced object detection capabilities, particularly in remote sensing imagery. However, challenges persist, especially in detecting small objects where the high resolution of these images and the small size of target objects often result in a loss of critical information in the deeper layers of conventional CNNs. Additionally, the extensive spatial redundancy and intricate background details typical in remote-sensing images tend to obscure these small targets. To address these challenges, we introduce Multi-Kernel Selection Network (MKSNet), a novel network architecture featuring a novel Multi-Kernel Selection mechanism. The MKS mechanism utilizes large convolutional kernels to effectively capture an extensive range of contextual information. This innovative design allows for adaptive kernel size selection, significantly enhancing the network's ability to dynamically process and emphasize crucial spatial details for small object detection. Furthermore, MKSNet also incorporates a dual attention mechanism, merging spatial and channel attention modules. The spatial attention module adaptively fine-tunes the spatial weights of feature maps, focusing more intensively on relevant regions while mitigating background noise. Simultaneously, the channel attention module optimizes channel information selection, improving feature representation and detection accuracy. Empirical evaluations on the DOTA-v1.0 and HRSC2016 benchmark demonstrate that MKSNet substantially surpasses existing state-of-the-art models in detecting small objects in remote sensing images. These results highlight MKSNet's superior ability to manage the complexities associated with multi-scale and high-resolution image data, confirming its effectiveness and innovation in remote sensing object detection.", "AI": {"tldr": "This paper introduces MKSNet, a novel architecture for detecting small objects in remote sensing imagery, featuring a Multi-Kernel Selection mechanism and dual attention modules.", "motivation": "Small object detection in high-resolution remote sensing images is challenging due to the small target sizes, loss of critical details in deeper CNN layers, spatial redundancies, and intricate background details.", "method": "The authors propose MKSNet, which includes a Multi-Kernel Selection mechanism for adaptive kernel size selection to better capture contextual information, and dual attention mechanisms (spatial and channel) to refine feature representation and noise reduction.", "result": "Empirical validation on DOTA-v1.0 and HRSC2016 benchmarks shows that MKSNet outperforms state-of-the-art models in small object detection for remote sensing images.", "conclusion": "MKSNet successfully addresses multi-scale challenges, enhances small object detection capabilities in high-resolution imagery, and demonstrates its effectiveness and innovation in this domain."}}
{"id": "2512.03579", "pdf": "https://arxiv.org/pdf/2512.03579", "abs": "https://arxiv.org/abs/2512.03579", "authors": ["Sanjit Dandapanthula", "Aleksandr Podkopaev", "Shiva Prasad Kasiviswanathan", "Aaditya Ramdas", "Ziv Goldfeld"], "title": "Optimal Transportation and Alignment Between Gaussian Measures", "categories": ["cs.LG", "math.PR", "math.ST"], "comment": null, "summary": "Optimal transport (OT) and Gromov-Wasserstein (GW) alignment provide interpretable geometric frameworks for comparing, transforming, and aggregating heterogeneous datasets -- tasks ubiquitous in data science and machine learning. Because these frameworks are computationally expensive, large-scale applications often rely on closed-form solutions for Gaussian distributions under quadratic cost. This work provides a comprehensive treatment of Gaussian, quadratic cost OT and inner product GW (IGW) alignment, closing several gaps in the literature to broaden applicability. First, we treat the open problem of IGW alignment between uncentered Gaussians on separable Hilbert spaces by giving a closed-form expression up to a quadratic optimization over unitary operators, for which we derive tight analytic upper and lower bounds. If at least one Gaussian measure is centered, the solution reduces to a fully closed-form expression, which we further extend to an analytic solution for the IGW barycenter between centered Gaussians. We also present a reduction of Gaussian multimarginal OT with pairwise quadratic costs to a tractable optimization problem and provide an efficient algorithm to solve it using a rank-deficiency constraint. To demonstrate utility, we apply our results to knowledge distillation and heterogeneous clustering on synthetic and real-world datasets.", "AI": {"tldr": "The paper addresses computational challenges in optimal transport (OT) and Gromov-Wasserstein (GW) alignment. It offers closed-form solutions for Gaussian distributions under quadratic cost and extends formulations to uncentered Gaussians and multimarginal problems.", "motivation": "OT and GW alignment frameworks are key for comparing and merging heterogeneous datasets in applications like data science and machine learning, but their computational cost limits scalability.", "method": "The authors derive closed-form solutions for Gaussian quadratic OT and IGW alignment, including uncentered cases, and reduce multimarginal OT problems to a tractable form with efficient algorithms.", "result": "Closed-form expressions are provided for IGW alignment and barycenters under specific conditions. An algorithm for multimarginal OT problems improves computational efficiency and applicability.", "conclusion": "These advancements expand the applicability of OT and GW methods to large-scale problems, demonstrated through use cases like knowledge distillation and heterogeneous clustering on real datasets."}}
{"id": "2512.03584", "pdf": "https://arxiv.org/pdf/2512.03584", "abs": "https://arxiv.org/abs/2512.03584", "authors": ["Thomas Gr\u00e4upl", "Andreas Reisenbauer", "Marcel Hecko", "Anil Rasouli", "Anita Graser", "Melitta Dragaschnig", "Axel Weissenfeld", "Gilles Dejaegere", "Mahmoud Sakr"], "title": "Federated Learning and Trajectory Compression for Enhanced AIS Coverage", "categories": ["cs.LG"], "comment": null, "summary": "This paper presents the VesselEdge system, which leverages federated learning and bandwidth-constrained trajectory compression to enhance maritime situational awareness by extending AIS coverage. VesselEdge transforms vessels into mobile sensors, enabling real-time anomaly detection and efficient data transmission over low-bandwidth connections. The system integrates the M3fed model for federated learning and the BWC-DR-A algorithm for trajectory compression, prioritizing anomalous data. Preliminary results demonstrate the effectiveness of VesselEdge in improving AIS coverage and situational awareness using historical data.", "AI": {"tldr": "The VesselEdge system improves maritime situational awareness by utilizing federated learning and trajectory compression to enhance AIS coverage.", "motivation": "Address the limited AIS coverage and enable real-time anomaly detection with efficient data transmission for maritime situational awareness.", "method": "Combines federated learning (M3fed model) and bandwidth-constrained trajectory compression (BWC-DR-A algorithm) to process data from vessels acting as mobile sensors.", "result": "Preliminary results show VesselEdge effectively expands AIS coverage and improves situational awareness using historical data.", "conclusion": "The system successfully leverages new technologies to address maritime challenges, proving its potential in operational scenarios."}}
{"id": "2512.03663", "pdf": "https://arxiv.org/pdf/2512.03663", "abs": "https://arxiv.org/abs/2512.03663", "authors": ["Salim Khazem"], "title": "Multi-Scale Visual Prompting for Lightweight Small-Image Classification", "categories": ["cs.CV"], "comment": null, "summary": "Visual prompting has recently emerged as an efficient strategy to adapt vision models using lightweight, learnable parameters injected into the input space. However, prior work mainly targets large Vision Transformers and high-resolution datasets such as ImageNet. In contrast, small-image benchmarks like MNIST, Fashion-MNIST, and CIFAR-10 remain widely used in education, prototyping, and research, yet have received little attention in the context of prompting. In this paper, we introduce \\textbf{Multi-Scale Visual Prompting (MSVP)}, a simple and generic module that learns a set of global, mid-scale, and local prompt maps fused with the input image via a lightweight $1 \\times 1$ convolution. MSVP is backbone-agnostic, adds less than $0.02\\%$ parameters, and significantly improves performance across CNN and Vision Transformer backbones.\n  We provide a unified benchmark on MNIST, Fashion-MNIST, and CIFAR-10 using a simple CNN, ResNet-18, and a small Vision Transformer. Our method yields consistent improvements with negligible computational overhead. We further include ablations on prompt scales, fusion strategies, and backbone architectures, along with qualitative analyzes using prompt visualizations and Grad-CAM. Our results demonstrate that multi-scale prompting provides an effective inductive bias even on low-resolution images.", "AI": {"tldr": "The paper introduces Multi-Scale Visual Prompting (MSVP), a method to adapt vision models by learning multi-scale prompt maps for better performance.", "motivation": "To address the lack of focus on visual prompting for small datasets and models, despite its success on large ones like ImageNet with Vision Transformers.", "method": "MSVP learns global, mid-scale, and local prompt maps fused with images using lightweight 1x1 convolution. It is backbone-agnostic and parameter-efficient.", "result": "MSVP outperforms prior methods on MNIST, Fashion-MNIST, and CIFAR-10 across various backbones like simple CNNs, ResNet-18, and small Vision Transformers, with negligible computational costs.", "conclusion": "Multi-scale prompting offers an effective inductive bias for low-resolution images and provides consistent performance enhancements with minimal resource usage."}}
{"id": "2512.03606", "pdf": "https://arxiv.org/pdf/2512.03606", "abs": "https://arxiv.org/abs/2512.03606", "authors": ["Matteo Peduto", "Qidong Yang", "Jonathan Giezendanner", "Devis Tuia", "Sherrie Wang"], "title": "Observation-driven correction of numerical weather prediction for marine winds", "categories": ["cs.LG"], "comment": null, "summary": "Accurate marine wind forecasts are essential for safe navigation, ship routing, and energy operations, yet they remain challenging because observations over the ocean are sparse, heterogeneous, and temporally variable. We reformulate wind forecasting as observation-informed correction of a global numerical weather prediction (NWP) model. Rather than forecasting winds directly, we learn local correction patterns by assimilating the latest in-situ observations to adjust the Global Forecast System (GFS) output. We propose a transformer-based deep learning architecture that (i) handles irregular and time-varying observation sets through masking and set-based attention mechanisms, (ii) conditions predictions on recent observation-forecast pairs via cross-attention, and (iii) employs cyclical time embeddings and coordinate-aware location representations to enable single-pass inference at arbitrary spatial coordinates. We evaluate our model over the Atlantic Ocean using observations from the International Comprehensive Ocean-Atmosphere Data Set (ICOADS) as reference. The model reduces GFS 10-meter wind RMSE at all lead times up to 48 hours, achieving 45% improvement at 1-hour lead time and 13% improvement at 48-hour lead time. Spatial analyses reveal the most persistent improvements along coastlines and shipping routes, where observations are most abundant. The tokenized architecture naturally accommodates heterogeneous observing platforms (ships, buoys, tide gauges, and coastal stations) and produces both site-specific predictions and basin-scale gridded products in a single forward pass. These results demonstrate a practical, low-latency post-processing approach that complements NWP by learning to correct systematic forecast errors.", "AI": {"tldr": "This paper introduces a transformer-based deep learning approach that improves marine wind forecasts by correcting global numerical weather prediction (NWP) models using local observations, resulting in significant error reduction.", "motivation": "Accurate marine wind forecasts are crucial for applications such as safe navigation, ship routing, and energy operations; however, these forecasts are challenging because over-ocean observations are sparse, heterogeneous, and time-varying.", "method": "The authors proposed a transformer-based model that utilizes masking and set-based attention for irregular/timed data, cross-attention for observation-forecast correlation, and spatial/temporal embeddings to enhance 10-meter wind forecasting at variable locations and times.", "result": "The transformer model reduced 10-meter wind RMSE of the GFS model by up to 45% at a 1-hour lead time and 13% at a 48-hour lead time, with the greatest improvements near coastlines and shipping routes due to high observation densities.", "conclusion": "The paper presents a low-latency, practical post-processing solution to complement NWP models, effectively correcting systematic forecast errors and accommodating heterogeneous data sources for targeted and basin-wide predictions."}}
{"id": "2512.03666", "pdf": "https://arxiv.org/pdf/2512.03666", "abs": "https://arxiv.org/abs/2512.03666", "authors": ["Qi'ao Xu", "Tianwen Qian", "Yuqian Fu", "Kailing Li", "Yang Jiao", "Jiacheng Zhang", "Xiaoling Wang", "Liang He"], "title": "ToG-Bench: Task-Oriented Spatio-Temporal Grounding in Egocentric Videos", "categories": ["cs.CV", "cs.AI"], "comment": "26 pages", "summary": "A core capability towards general embodied intelligence lies in localizing task-relevant objects from an egocentric perspective, formulated as Spatio-Temporal Video Grounding (STVG). Despite recent progress, existing STVG studies remain largely confined to object-centric and descriptive instructions, neglecting the task-oriented reasoning that is crucial for embodied agents to accomplish goal-directed interactions. To bridge this gap, we introduce \\textbf{ToG-Bench}, the first task-oriented spatio-temporal video grounding benchmark for egocentric videos. ToG-Bench is characterized by three key features: (1) \\textbf{Task-oriented Grounding}, which requires identifying and localizing objects based on intended tasks rather than straightforward descriptions; (2) \\textbf{Explicit-Implicit Dual Grounding}, where target objects can be either explicitly mentioned or implicitly inferred by contextual reasoning; (3) \\textbf{One-to-Many Grounding}, where a single instruction may correspond to multiple objects involved in task execution. Built upon videos sourced from ScanNet, ToG-Bench comprises 100 annotated clips with 2,704 task-oriented grounding instructions, constructed via a semi-automated pipeline that combines foundation model annotation and human refinement. In addition, we introduce a set of task-level evaluation metrics tailored for multi-object and explicit-implicit object grounding, and systematically benchmark seven state-of-the-art MLLMs. Extensive experiments reveal the intrinsic challenges of task-oriented STVG and substantial performance gaps across explicit-implicit and multi-object grounding, highlighting the difficulty of bridging perception and interaction in embodied scenarios. Data and code will be released at: \\href{https://github.com/qaxuDev/ToG-Bench}{https://github.com/qaxuDev/ToG-Bench}..", "AI": {"tldr": "The paper introduces ToG-Bench, a novel task-oriented video grounding benchmark for egocentric videos, addressing key gaps in existing studies. It highlights intrinsic challenges and evaluates state-of-the-art methods.", "motivation": "To address the limitations in current video grounding studies, which focus more on object-centric and descriptive tasks, and to introduce task-oriented reasoning critical for interactions in embodied agents.", "method": "Developed a benchmark called ToG-Bench, characterized by task-oriented grounding, explicit-implicit dual grounding, and one-to-many grounding. Includes annotated videos with task-level evaluation metrics and systematic benchmarking.", "result": "Created a dataset (ToG-Bench) with 2,704 grounding instructions and systematically evaluated seven state-of-the-art multimodal learning models, showing significant challenges in task-oriented STVG.", "conclusion": "The study offers a robust benchmark for task-oriented video grounding, revealing critical challenges in grounding tasks and emphasizing performance barriers in explicit-implicit and multi-object scenarios."}}
{"id": "2512.03610", "pdf": "https://arxiv.org/pdf/2512.03610", "abs": "https://arxiv.org/abs/2512.03610", "authors": ["Julius Lenz"], "title": "CoGraM: Context-sensitive granular optimization method with rollback for robust model fusion", "categories": ["cs.LG"], "comment": "15 pages, 4 figures, 8 equations", "summary": "Merging neural networks without retraining is central to federated and distributed learning. Common methods such as weight averaging or Fisher merging often lose accuracy and are unstable across seeds. CoGraM (Contextual Granular Merging) is a multi-stage, context-sensitive, loss-based, and iterative optimization method across layers, neurons, and weight levels that aligns decisions with loss differences and thresholds and prevents harmful updates through rollback. CoGraM is an optimization method that addresses the weaknesses of methods such as Fisher and can significantly improve the merged network.", "AI": {"tldr": "CoGraM is a new optimization method for merging neural networks without retraining, improving stability and accuracy compared to traditional methods.", "motivation": "To address the instability and accuracy loss observed in common neural network merging methods like weight averaging and Fisher merging.", "method": "The authors propose CoGraM, a multi-stage, context-sensitive, loss-based, and iterative optimization technique that operates across layers, neurons, and weights, aligning updates to minimize harmful effects.", "result": "CoGraM was shown to overcome the weaknesses of traditional merging methods and delivers significantly improved accuracy and stability in the merged network.", "conclusion": "CoGraM offers a more reliable alternative for merging neural networks in federated and distributed learning environments without the need for retraining."}}
{"id": "2512.03667", "pdf": "https://arxiv.org/pdf/2512.03667", "abs": "https://arxiv.org/abs/2512.03667", "authors": ["Ge-Peng Ji", "Jingyi Liu", "Deng-Ping Fan", "Nick Barnes"], "title": "Colon-X: Advancing Intelligent Colonoscopy from Multimodal Understanding to Clinical Reasoning", "categories": ["cs.CV"], "comment": "Technical report", "summary": "In this study, we present Colon-X, an open initiative aimed at advancing multimodal intelligence in colonoscopy. We begin by constructing ColonVQA, the most comprehensive multimodal dataset ever built for colonoscopy, featuring over 1.1M+ visual question answering entries across 76 clinical findings and 18 multimodal tasks. Beyond serving as a community-wide data foundation, we further investigate a critical yet underexplored transition in colonoscopy - evolving from multimodal understanding to clinical reasoning: (a) To capture the current landscape of multimodal understanding behaviors, we systematically assess the generalizability of 22 multimodal large language models and examine their reliability under human-induced perturbations. The results reveal that clinical outputs from leading MLLMs remain far from robust and trustworthy. (b) To narrow this gap, we further explore reasoning-centric intelligence tailored for colonoscopy. Specifically, we curate ColonReason, a clinically grounded reasoning dataset annotated through a multi-expert debating pipeline, and develop ColonR1, the first R1-styled model incorporating task-adaptive rewarding and gradient-stable optimization techniques. Under data-scarce conditions, our ColonR1 achieves 56.61% overall accuracy, outperforming supervised fine-tuning by 25.22%, and sets a new reasoning-enabled baseline for multimodal colonoscopy analysis. All data and model resources are publicly available at https://github.com/ai4colonoscopy/Colon-X.", "AI": {"tldr": "This study introduces Colon-X, including ColonVQA and ColonReason datasets, and develops the ColonR1 model for improved reasoning in multimodal colonoscopy analysis.", "motivation": "To enhance multimodal intelligence and clinical reasoning in colonoscopy, addressing the limitations of current large language models in this domain.", "method": "The study creates ColonVQA and ColonReason datasets, evaluates existing multimodal models, and develops ColonR1 using task-adaptive rewarding and gradient-stable optimization techniques.", "result": "ColonR1 achieves 56.61% accuracy under data-scarce conditions, outperforming traditional fine-tuning methods by 25.22%, setting a new multimodal reasoning baseline.", "conclusion": "Colon-X initiative offers open resources and establishes benchmarks to advance multimodal intelligence and clinical reasoning in colonoscopy, improving robustness and reliability in clinical outputs."}}
{"id": "2512.03623", "pdf": "https://arxiv.org/pdf/2512.03623", "abs": "https://arxiv.org/abs/2512.03623", "authors": ["Edward C. C. Steele", "Dinesh Mane", "Emilio Monti", "Luis Orus", "Rebecca Chantrill-Cheyette", "Matthew Couch", "Kirstine I. Dale", "Simon Eaton", "Govindarajan Rangarajan", "Amir Majlesi", "Steven Ramsdale", "Michael Sharpe", "Craig Smith", "Jonathan Smith", "Rebecca Yates", "Holly Ellis", "Charles Ewen"], "title": "The promising potential of vision language models for the generation of textual weather forecasts", "categories": ["cs.LG", "cs.AI", "physics.ao-ph"], "comment": "7 pages, 2 tables", "summary": "Despite the promising capability of multimodal foundation models, their application to the generation of meteorological products and services remains nascent. To accelerate aspiration and adoption, we explore the novel use of a vision language model for writing the iconic Shipping Forecast text directly from video-encoded gridded weather data. These early results demonstrate promising scalable technological opportunities for enhancing production efficiency and service innovation within the weather enterprise and beyond.", "AI": {"tldr": "This paper explores the use of multimodal vision language models to generate meteorological text products directly from gridded weather data.", "motivation": "The paper aims to accelerate the adoption of multimodal foundation models for meteorological applications, focusing on improving efficiency and innovation in weather services.", "method": "A vision language model is utilized to write Shipping Forecast text by processing video-encoded gridded weather data.", "result": "Early results show that employing scalable multimodal technology offers promising opportunities for enhancing production efficiency and service innovation.", "conclusion": "The study suggests that vision language models have the potential to significantly benefit meteorological service development and innovation."}}
{"id": "2512.03673", "pdf": "https://arxiv.org/pdf/2512.03673", "abs": "https://arxiv.org/abs/2512.03673", "authors": ["Feice Huang", "Zuliang Han", "Xing Zhou", "Yihuang Chen", "Lifei Zhu", "Haoqian Wang"], "title": "ConvRot: Rotation-Based Plug-and-Play 4-bit Quantization for Diffusion Transformers", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion transformers have demonstrated strong capabilities in generating high-quality images. However, as model size increases, the growing memory footprint and inference latency pose significant challenges for practical deployment. Recent studies in large language models (LLMs) show that rotation-based techniques can smooth outliers and enable 4-bit quantization, but these approaches often incur substantial overhead and struggle with row-wise outliers in diffusion transformers. To address these challenges, we propose ConvRot, a group-wise rotation-based quantization method that leverages regular Hadamard transform (RHT) to suppress both row-wise and column-wise outliers while reducing complexity from quadratic to linear. Building on this, we design ConvLinear4bit, a plug-and-play module that integrates rotation, quantization, GEMM, and dequantization, enabling W4A4 inference without retraining and preserving visual quality. Experiments on FLUX.1-dev demonstrate a 2.26$\\times$ speedup and 4.05$\\times$ memory reduction while maintaining image fidelity. To our knowledge, this is the first application of rotation-based quantization for plug-and-play W4A4 inference in diffusion transformers.", "AI": {"tldr": "The paper introduces a new quantization method (ConvRot) to enable efficient inference in diffusion transformers with reduced memory and latency, achieving W4A4 inference without retraining.", "motivation": "Diffusion transformers face deployment issues due to increased memory and inference latency as model size grows. Existing quantization techniques often fail with outliers and are inefficient for diffusion transformers.", "method": "The authors introduce ConvRot, a group-wise rotation-based quantization using regular Hadamard transform (RHT), and propose ConvLinear4bit, a plug-and-play module integrating rotation, quantization, GEMM, and dequantization for W4A4 inference.", "result": "Experiments on FLUX.1-dev show a 2.26\u00d7 speedup and 4.05\u00d7 memory reduction, while preserving image quality.", "conclusion": "This is the first instance of rotation-based quantization applied for plug-and-play W4A4 inference in diffusion transformers, optimizing both efficiency and fidelity without the need for retraining."}}
{"id": "2512.03653", "pdf": "https://arxiv.org/pdf/2512.03653", "abs": "https://arxiv.org/abs/2512.03653", "authors": ["Jan Saynisch-Wagner", "Saran Rajendran Sari"], "title": "Conditional updates of neural network weights for increased out of training performance", "categories": ["cs.LG", "physics.ao-ph", "physics.data-an"], "comment": null, "summary": "This study proposes a method to enhance neural network performance when training data and application data are not very similar, e.g., out of distribution problems, as well as pattern and regime shifts. The method consists of three main steps: 1) Retrain the neural network towards reasonable subsets of the training data set and note down the resulting weight anomalies. 2) Choose reasonable predictors and derive a regression between the predictors and the weight anomalies. 3) Extrapolate the weights, and thereby the neural network, to the application data. We show and discuss this method in three use cases from the climate sciences, which include successful temporal, spatial and cross-domain extrapolations of neural networks.", "AI": {"tldr": "The paper introduces a method to improve the performance of neural networks on out-of-distribution data by retraining on subsets, analyzing weight anomalies, and extrapolating to application data, applied in climate science scenarios.", "motivation": "The motivation is to address the challenges neural networks face with out-of-distribution problems, such as pattern and regime shifts, which affect their generalization and practical applicability.", "method": "The method includes three main steps: retraining on specific subsets of training data and observing weight anomalies, deriving a regression model between predictors and weight anomalies, and extrapolating weights to adapt the neural network to new application data.", "result": "The proposed method was validated through three use cases in climate science, demonstrating successful temporal, spatial, and cross-domain adaptations of neural networks.", "conclusion": "The study concludes that the method effectively enhances neural network generalization in scenarios with significant differences between training and application data, offering practical applications in challenging domains like climate science."}}
{"id": "2512.03683", "pdf": "https://arxiv.org/pdf/2512.03683", "abs": "https://arxiv.org/abs/2512.03683", "authors": ["Melis Ocal", "Xiaoyan Xing", "Yue Li", "Ngo Anh Vien", "Sezer Karaoglu", "Theo Gevers"], "title": "GaussianBlender: Instant Stylization of 3D Gaussians with Disentangled Latent Spaces", "categories": ["cs.CV"], "comment": null, "summary": "3D stylization is central to game development, virtual reality, and digital arts, where the demand for diverse assets calls for scalable methods that support fast, high-fidelity manipulation. Existing text-to-3D stylization methods typically distill from 2D image editors, requiring time-intensive per-asset optimization and exhibiting multi-view inconsistency due to the limitations of current text-to-image models, which makes them impractical for large-scale production. In this paper, we introduce GaussianBlender, a pioneering feed-forward framework for text-driven 3D stylization that performs edits instantly at inference. Our method learns structured, disentangled latent spaces with controlled information sharing for geometry and appearance from spatially-grouped 3D Gaussians. A latent diffusion model then applies text-conditioned edits on these learned representations. Comprehensive evaluations show that GaussianBlender not only delivers instant, high-fidelity, geometry-preserving, multi-view consistent stylization, but also surpasses methods that require per-instance test-time optimization - unlocking practical, democratized 3D stylization at scale.", "AI": {"tldr": "GaussianBlender offers text-to-3D stylization with instant, high-fidelity, and multi-view consistency, overcoming the inefficiencies of existing methods.", "motivation": "The demand for diverse 3D assets in areas like gaming and virtual reality necessitates scalable, efficient, and high-fidelity stylization methods, as existing techniques are slow and inconsistent.", "method": "The method introduces GaussianBlender, which uses spatially-grouped 3D Gaussians to disentangle geometry and appearance. Edits are applied through a latent diffusion model for instant text-driven 3D stylization.", "result": "GaussianBlender achieves fast, geometry-preserving, and multi-view consistent 3D stylization, outperforming optimization-heavy methods.", "conclusion": "GaussianBlender democratizes 3D stylization by providing an efficient, scalable, and practical solution for high-quality text-to-3D transformation."}}
{"id": "2512.03656", "pdf": "https://arxiv.org/pdf/2512.03656", "abs": "https://arxiv.org/abs/2512.03656", "authors": ["Salim Khazem", "Houssam Kanso"], "title": "Cyclical Temporal Encoding and Hybrid Deep Ensembles for Multistep Energy Forecasting", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Accurate electricity consumption forecasting is essential for demand management and smart grid operations. This paper introduces a unified deep learning framework that integrates cyclical temporal encoding with hybrid LSTM-CNN architectures to enhance multistep energy forecasting. We systematically transform calendar-based attributes using sine cosine encodings to preserve periodic structure and evaluate their predictive relevance through correlation analysis. To exploit both long-term seasonal effects and short-term local patterns, we employ an ensemble model composed of an LSTM, a CNN, and a meta-learner of MLP regressors specialized for each forecast horizon. Using a one year national consumption dataset, we conduct an extensive experimental study including ablation analyses with and without cyclical encodings and calendar features and comparisons with established baselines from the literature. Results demonstrate consistent improvements across all seven forecast horizons, with our hybrid model achieving lower RMSE and MAE than individual architectures and prior methods. These findings confirm the benefit of combining cyclical temporal representations with complementary deep learning structures. To our knowledge, this is the first work to jointly evaluate temporal encodings, calendar-based features, and hybrid ensemble architectures within a unified short-term energy forecasting framework.", "AI": {"tldr": "This paper proposes a hybrid deep learning model combining LSTM, CNN, and cyclical temporal encoding for accurate multistep energy forecasting, achieving superior performance compared to existing methods.", "motivation": "Accurate electricity consumption forecasting is necessary for effective demand management and smart grid operations.", "method": "The paper introduces a framework that applies cyclical sine-cosine encodings of temporal data, uses an ensemble of LSTM, CNN, and meta-learner MLP regressors, and includes ablation studies to evaluate performance.", "result": "The hybrid model outperforms existing baselines and individual methods across multiple forecast horizons, achieving better RMSE and MAE values.", "conclusion": "Combining cyclical temporal representations with hybrid deep learning architectures improves energy forecasting and this unified framework is a novel contribution in the field."}}
{"id": "2512.03687", "pdf": "https://arxiv.org/pdf/2512.03687", "abs": "https://arxiv.org/abs/2512.03687", "authors": ["Yian Li", "Xiaoyu Guo", "Hao Zhang", "Shuiwang Li", "Xiaowei Dai"], "title": "Active Visual Perception: Opportunities and Challenges", "categories": ["cs.CV"], "comment": null, "summary": "Active visual perception refers to the ability of a system to dynamically engage with its environment through sensing and action, allowing it to modify its behavior in response to specific goals or uncertainties. Unlike passive systems that rely solely on visual data, active visual perception systems can direct attention, move sensors, or interact with objects to acquire more informative data. This approach is particularly powerful in complex environments where static sensing methods may not provide sufficient information. Active visual perception plays a critical role in numerous applications, including robotics, autonomous vehicles, human-computer interaction, and surveillance systems. However, despite its significant promise, there are several challenges that need to be addressed, including real-time processing of complex visual data, decision-making in dynamic environments, and integrating multimodal sensory inputs. This paper explores both the opportunities and challenges inherent in active visual perception, providing a comprehensive overview of its potential, current research, and the obstacles that must be overcome for broader adoption.", "AI": {"tldr": "This paper examines active visual perception's potential, its applications, and challenges, providing a detailed analysis.", "motivation": "The paper aims to address the gap in understanding and implementing active visual perception by exploring its potential and challenges in real-world applications.", "method": "A comprehensive analysis of the opportunities and challenges in active visual perception across various domains, including robotics and surveillance, is provided.", "result": "It highlights the gaps in real-time processing, decision-making in dynamic settings, and multimodal sensory integration.", "conclusion": "Active visual perception offers significant promise, but solving its challenges is key to unlocking its wider adoption."}}
{"id": "2512.03661", "pdf": "https://arxiv.org/pdf/2512.03661", "abs": "https://arxiv.org/abs/2512.03661", "authors": ["Alex Ferrando", "Xavier Suau", "Jordi Gonz\u00e0lez", "Pau Rodriguez"], "title": "Dynamically Scaled Activation Steering", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Activation steering has emerged as a powerful method for guiding the behavior of generative models towards desired outcomes such as toxicity mitigation. However, most existing methods apply interventions uniformly across all inputs, degrading model performance when steering is unnecessary. We introduce Dynamically Scaled Activation Steering (DSAS), a method-agnostic steering framework that decouples when to steer from how to steer. DSAS adaptively modulates the strength of existing steering transformations across layers and inputs, intervening strongly only when undesired behavior is detected. At generation time, DSAS computes context-dependent scaling factors that selectively adjust the strength of any steering method. We also show how DSAS can be jointly optimized end-to-end together with the steering function. When combined with existing steering methods, DSAS consistently improves the Pareto front with respect to steering alone, achieving a better trade-off between toxicity mitigation and utility preservation. We further demonstrate DSAS's generality by applying it to a text-to-image diffusion model, showing how adaptive steering allows the modulation of specific concepts. Finally, DSAS introduces minimal computational overhead while improving interpretability, pinpointing which tokens require steering and by how much.", "AI": {"tldr": "DSAS is a dynamic framework to optimize activation steering in generative models, improving behavior adaptation while preserving performance.", "motivation": "Existing activation steering methods degrade model performance by applying interventions uniformly, prompting the need for adaptive and targeted methods.", "method": "DSAS computes context-dependent scaling factors to modulate steering transformations selectively, applying intervention only when necessary and optimizing steering end-to-end.", "result": "DSAS enhances the trade-off between toxicity mitigation and utility preservation, performs well across different steering methods, and adapts effectively in scenarios like text-to-image generation.", "conclusion": "DSAS offers a scalable, general method for dynamic steering with minimal computational overhead, improving both efficiency and interpretability of model interventions."}}
{"id": "2512.03701", "pdf": "https://arxiv.org/pdf/2512.03701", "abs": "https://arxiv.org/abs/2512.03701", "authors": ["Paula Seidler", "Neill D. F. Campbell", "Ivor J A Simpson"], "title": "Structured Uncertainty Similarity Score (SUSS): Learning a Probabilistic, Interpretable, Perceptual Metric Between Images", "categories": ["cs.CV"], "comment": null, "summary": "Perceptual similarity scores that align with human vision are critical for both training and evaluating computer vision models. Deep perceptual losses, such as LPIPS, achieve good alignment but rely on complex, highly non-linear discriminative features with unknown invariances, while hand-crafted measures like SSIM are interpretable but miss key perceptual properties.\n  We introduce the Structured Uncertainty Similarity Score (SUSS); it models each image through a set of perceptual components, each represented by a structured multivariate Normal distribution. These are trained in a generative, self-supervised manner to assign high likelihood to human-imperceptible augmentations. The final score is a weighted sum of component log-probabilities with weights learned from human perceptual datasets. Unlike feature-based methods, SUSS learns image-specific linear transformations of residuals in pixel space, enabling transparent inspection through decorrelated residuals and sampling.\n  SUSS aligns closely with human perceptual judgments, shows strong perceptual calibration across diverse distortion types, and provides localized, interpretable explanations of its similarity assessments. We further demonstrate stable optimization behavior and competitive performance when using SUSS as a perceptual loss for downstream imaging tasks.", "AI": {"tldr": "The study introduces SUSS, a novel similarity score aligning with human perception, offering improved interpretability over prior methods.", "motivation": "Current perceptual similarity scores often lack interpretability or alignment with human judgment; SUSS aims to address these gaps with a structured and interpretable approach.", "method": "SUSS uses structured multivariate normal distributions to capture perceptual components, trained with self-supervised generative models, and utilizes human dataset-derived weights for scoring.", "result": "The SUSS model aligns closely with human perceptual judgments, provides interpretable explanations, and demonstrates stable optimization and competitive performance in downstream tasks.", "conclusion": "SUSS improves perceptual similarity measurement, offers better alignment with human vision, and promotes interpretability and effectiveness in imaging tasks."}}
{"id": "2512.03678", "pdf": "https://arxiv.org/pdf/2512.03678", "abs": "https://arxiv.org/abs/2512.03678", "authors": ["Hao-Run Cai", "Han-Jia Ye"], "title": "Feature-aware Modulation for Learning from Temporal Tabular Data", "categories": ["cs.LG"], "comment": "17 pages, 6 figures, 8 tables. NeurIPS 2025", "summary": "While tabular machine learning has achieved remarkable success, temporal distribution shifts pose significant challenges in real-world deployment, as the relationships between features and labels continuously evolve. Static models assume fixed mappings to ensure generalization, whereas adaptive models may overfit to transient patterns, creating a dilemma between robustness and adaptability. In this paper, we analyze key factors essential for constructing an effective dynamic mapping for temporal tabular data. We discover that evolving feature semantics-particularly objective and subjective meanings-introduce concept drift over time. Crucially, we identify that feature transformation strategies are able to mitigate discrepancies in feature representations across temporal stages. Motivated by these insights, we propose a feature-aware temporal modulation mechanism that conditions feature representations on temporal context, modulating statistical properties such as scale and skewness. By aligning feature semantics across time, our approach achieves a lightweight yet powerful adaptation, effectively balancing generalizability and adaptability. Benchmark evaluations validate the effectiveness of our method in handling temporal shifts in tabular data.", "AI": {"tldr": "The paper addresses the challenge of temporal distribution shifts in tabular machine learning and proposes a feature-aware temporal modulation mechanism to balance robustness and adaptability.", "motivation": "Temporal distribution shifts disrupt real-world deployment of ML models, as feature-label relationships evolve, causing a tradeoff dilemma between static and adaptive models.", "method": "The method involves a feature-aware temporal modulation mechanism that adjusts feature representations based on temporal context by modulating statistical properties like scale and skewness.", "result": "The proposed approach effectively aligns feature semantics across time, ensuring lightweight yet powerful adaptation.", "conclusion": "The research presents an effective mechanism to handle temporal shifts, achieving a balance between generalizability and adaptability in temporal tabular data applications."}}
{"id": "2512.03715", "pdf": "https://arxiv.org/pdf/2512.03715", "abs": "https://arxiv.org/abs/2512.03715", "authors": ["Kaichen Zhang", "Tianxiang Sheng", "Xuanming Shi"], "title": "DINO-RotateMatch: A Rotation-Aware Deep Framework for Robust Image Matching in Large-Scale 3D Reconstruction", "categories": ["cs.CV"], "comment": "9 pages, 5 figures, 1 table", "summary": "This paper presents DINO-RotateMatch, a deep-learning framework designed to address the chal lenges of image matching in large-scale 3D reconstruction from unstructured Internet images. The\n  method integrates a dataset-adaptive image pairing strategy with rotation-aware keypoint extraction and\n  matching. DINO is employed to retrieve semantically relevant image pairs in large collections, while\n  rotation-based augmentation captures orientation-dependent local features using ALIKED and Light Glue. Experiments on the Kaggle Image Matching Challenge 2025 demonstrate consistent improve ments in mean Average Accuracy (mAA), achieving a Silver Award (47th of 943 teams). The results\n  confirm that combining self-supervised global descriptors with rotation-enhanced local matching offers\n  a robust and scalable solution for large-scale 3D reconstruction.", "AI": {"tldr": "The paper introduces DINO-RotateMatch, a deep-learning framework for image matching in large-scale 3D reconstruction, achieving notable improvements and recognition.", "motivation": "The motivation is to tackle the problem of image matching in unstructured Internet images for large-scale 3D reconstruction, particularly addressing issues related to scale and rotation.", "method": "The proposed method combines dataset-adaptive image pairing with rotation-aware keypoint extraction. DINO is used for retrieving semantic image pairs, while rotational augmentation employs ALIKED and Light Glue.", "result": "Experiments from the Kaggle Image Matching Challenge 2025 show consistent mean Average Accuracy (mAA) improvement, earning the team a Silver Award (47th of 943 teams).", "conclusion": "The integration of self-supervised global descriptors with rotation-aware local matching provides an effective solution for scalable and robust 3D reconstruction."}}
{"id": "2512.03696", "pdf": "https://arxiv.org/pdf/2512.03696", "abs": "https://arxiv.org/abs/2512.03696", "authors": ["Mohammad Doost", "Mohammad Manthouri"], "title": "Quantum Topological Graph Neural Networks for Detecting Complex Fraud Patterns", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We propose a novel QTGNN framework for detecting fraudulent transactions in large-scale financial networks. By integrating quantum embedding, variational graph convolutions, and topological data analysis, QTGNN captures complex transaction dynamics and structural anomalies indicative of fraud. The methodology includes quantum data embedding with entanglement enhancement, variational quantum graph convolutions with non-linear dynamics, extraction of higher-order topological invariants, hybrid quantum-classical anomaly learning with adaptive optimization, and interpretable decision-making via topological attribution. Rigorous convergence guarantees ensure stable training on noisy intermediate-scale quantum (NISQ) devices, while stability of topological signatures provides robust fraud detection. Optimized for NISQ hardware with circuit simplifications and graph sampling, the framework scales to large transaction networks. Simulations on financial datasets, such as PaySim and Elliptic, benchmark QTGNN against classical and quantum baselines, using metrics like ROC-AUC, precision, and false positive rate. An ablation study evaluates the contributions of quantum embeddings, topological features, non-linear channels, and hybrid learning. QTGNN offers a theoretically sound, interpretable, and practical solution for financial fraud detection, bridging quantum machine learning, graph theory, and topological analysis.", "AI": {"tldr": "The research introduces QTGNN, a quantum-enhanced framework for detecting fraudulent transactions using graph and topological analysis optimized for quantum devices.", "motivation": "Detecting financial fraud in large-scale transaction networks is challenging due to dynamic complexities and the structural subtleties of fraudulent patterns.", "method": "QTGNN combines quantum embedding, graph convolutions, topological data analysis, hybrid quantum-classical learning, and interpretable decision-making while using NISQ-optimized techniques for scaling and stability.", "result": "Simulations show that QTGNN outperforms classical and quantum baselines on datasets like PaySim and Elliptic, evidenced by metrics like ROC-AUC and precision.", "conclusion": "The study presents QTGNN as a robust, scalable, and theoretically sound method for financial fraud detection, leveraging quantum machine learning and topological insights."}}
{"id": "2512.03744", "pdf": "https://arxiv.org/pdf/2512.03744", "abs": "https://arxiv.org/abs/2512.03744", "authors": ["Xuhui Lin", "Qiuchen Lu"], "title": "Unlocking the Invisible Urban Traffic Dynamics under Extreme Weather: A New Physics-Constrained Hamiltonian Learning Algorithm", "categories": ["cs.LG"], "comment": null, "summary": "Urban transportation systems face increasing resilience challenges from extreme weather events, but current assessment methods rely on surface-level recovery indicators that miss hidden structural damage. Existing approaches cannot distinguish between true recovery and \"false recovery,\" where traffic metrics normalize, but the underlying system dynamics permanently degrade. To address this, a new physics-constrained Hamiltonian learning algorithm combining \"structural irreversibility detection\" and \"energy landscape reconstruction\" has been developed. Our approach extracts low-dimensional state representations, identifies quasi-Hamiltonian structures through physics-constrained optimization, and quantifies structural changes via energy landscape comparison. Analysis of London's extreme rainfall in 2021 demonstrates that while surface indicators were fully recovered, our algorithm detected 64.8\\% structural damage missed by traditional monitoring. Our framework provides tools for proactive structural risk assessment, enabling infrastructure investments based on true system health rather than misleading surface metrics.", "AI": {"tldr": "Urban transportation systems are affected by extreme weather events, requiring better assessments that identify hidden structural damage; this study introduces a physics-based algorithm identifying unseen damages using London's extreme rainfall in 2021 as an example.", "motivation": "Surface-level recovery indicators fail to capture hidden structural changes in transportation systems post-extreme weather, underestimating risks and potential permanent damage.", "method": "The study introduces a physics-constrained Hamiltonian learning algorithm which integrates structural irreversibility detection and energy landscape reconstruction for quantifying hidden structural damage.", "result": "The algorithm detected 64.8% of structural damage in London's transport system during 2021 rainfall events, missed by traditional monitoring approaches.", "conclusion": "The presented algorithm enables accurate structural risk assessment and ensures investments based on true system health rather than on misleading surface-level metrics."}}
{"id": "2512.03730", "pdf": "https://arxiv.org/pdf/2512.03730", "abs": "https://arxiv.org/abs/2512.03730", "authors": ["Melane Navaratnarajah", "David A. Kelly", "Hana Chockler"], "title": "Out-of-the-box: Black-box Causal Attacks on Object Detectors", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Adversarial perturbations are a useful way to expose vulnerabilities in object detectors. Existing perturbation methods are frequently white-box and architecture specific. More importantly, while they are often successful, it is rarely clear why they work. Insights into the mechanism of this success would allow developers to understand and analyze these attacks, as well as fine-tune the model to prevent them. This paper presents BlackCAtt, a black-box algorithm and a tool, which uses minimal, causally sufficient pixel sets to construct explainable, imperceptible, reproducible, architecture-agnostic attacks on object detectors. BlackCAtt combines causal pixels with bounding boxes produced by object detectors to create adversarial attacks that lead to the loss, modification or addition of a bounding box. BlackCAtt works across different object detectors of different sizes and architectures, treating the detector as a black box. We compare the performance of BlackCAtt with other black-box attack methods and show that identification of causal pixels leads to more precisely targeted and less perceptible attacks. On the COCO test dataset, our approach is 2.7 times better than the baseline in removing a detection, 3.86 times better in changing a detection, and 5.75 times better in triggering new, spurious, detections. The attacks generated by BlackCAtt are very close to the original image, and hence imperceptible, demonstrating the power of causal pixels.", "AI": {"tldr": "This paper presents BlackCAtt, a black-box algorithm for creating imperceptible, architecture-agnostic adversarial attacks on object detectors using causal pixel analysis.", "motivation": "The study aims to address the lack of understanding of success mechanisms in adversarial perturbations on object detectors, providing insight to improve model robustness against attacks.", "method": "BlackCAtt is a black-box tool that uses causally sufficient pixel sets and bounding boxes to generate explainable, effective, and imperceptible adversarial attacks across different object detector architectures.", "result": "The proposed approach outperforms baseline black-box attack methods, achieving significant improvements in removing, altering, or triggering detections, with results demonstrated on the COCO test dataset.", "conclusion": "BlackCAtt effectively reveals vulnerabilities in object detectors, showing the potential of causal pixel analysis for creating imperceptible yet impactful adversarial attacks."}}
{"id": "2512.03750", "pdf": "https://arxiv.org/pdf/2512.03750", "abs": "https://arxiv.org/abs/2512.03750", "authors": ["Sathya Edamadaka", "Soojung Yang", "Ju Li", "Rafael G\u00f3mez-Bombarelli"], "title": "Universally Converging Representations of Matter Across Scientific Foundation Models", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "comment": "Oral spotlight at NeurIPS 2025 UniReps Workshop", "summary": "Machine learning models of vastly different modalities and architectures are being trained to predict the behavior of molecules, materials, and proteins. However, it remains unclear whether they learn similar internal representations of matter. Understanding their latent structure is essential for building scientific foundation models that generalize reliably beyond their training domains. Although representational convergence has been observed in language and vision, its counterpart in the sciences has not been systematically explored. Here, we show that representations learned by nearly sixty scientific models, spanning string-, graph-, 3D atomistic, and protein-based modalities, are highly aligned across a wide range of chemical systems. Models trained on different datasets have highly similar representations of small molecules, and machine learning interatomic potentials converge in representation space as they improve in performance, suggesting that foundation models learn a common underlying representation of physical reality. We then show two distinct regimes of scientific models: on inputs similar to those seen during training, high-performing models align closely and weak models diverge into local sub-optima in representation space; on vastly different structures from those seen during training, nearly all models collapse onto a low-information representation, indicating that today's models remain limited by training data and inductive bias and do not yet encode truly universal structure. Our findings establish representational alignment as a quantitative benchmark for foundation-level generality in scientific models. More broadly, our work can track the emergence of universal representations of matter as models scale, and for selecting and distilling models whose learned representations transfer best across modalities, domains of matter, and scientific tasks.", "AI": {"tldr": "This paper explores representational alignment in nearly 60 scientific machine learning models and identifies a shared latent structure across these models. It reveals that high-performing models converge on similar internal representations, while limitations arise on data vastly different from training scenarios.", "motivation": "The motivation is to understand whether machine learning models of various modalities and architectures develop similar internal representations of scientific concepts, enabling reliable generalization beyond their training domains in molecular, material, and protein sciences.", "method": "The authors analyze representations from around 60 scientific models across different modalities, datasets, and tasks, assessing their alignment across chemical systems and scenarios, including both training-alike data and unseen structures.", "result": "They found representational convergence among high-performing models, indicating a shared underlying representation of physical reality. Weak models diverged, and models failed to generalize on vastly different data, revealing limits in their universality and an over-reliance on training data and inductive biases.", "conclusion": "The work establishes that representational alignment acts as a benchmark for assessing foundation-level generality in scientific models. It also provides a framework to evaluate and select models that better transfer representations across diverse scientific domains and tasks."}}
{"id": "2512.03745", "pdf": "https://arxiv.org/pdf/2512.03745", "abs": "https://arxiv.org/abs/2512.03745", "authors": ["Jiaze Li", "Yan Lu", "Bin Liu", "Guojun Yin", "Mang Ye"], "title": "Dual-level Modality Debiasing Learning for Unsupervised Visible-Infrared Person Re-Identification", "categories": ["cs.CV"], "comment": null, "summary": "Two-stage learning pipeline has achieved promising results in unsupervised visible-infrared person re-identification (USL-VI-ReID). It first performs single-modality learning and then operates cross-modality learning to tackle the modality discrepancy. Although promising, this pipeline inevitably introduces modality bias: modality-specific cues learned in the single-modality training naturally propagate into the following cross-modality learning, impairing identity discrimination and generalization. To address this issue, we propose a Dual-level Modality Debiasing Learning (DMDL) framework that implements debiasing at both the model and optimization levels. At the model level, we propose a Causality-inspired Adjustment Intervention (CAI) module that replaces likelihood-based modeling with causal modeling, preventing modality-induced spurious patterns from being introduced, leading to a low-biased model. At the optimization level, a Collaborative Bias-free Training (CBT) strategy is introduced to interrupt the propagation of modality bias across data, labels, and features by integrating modality-specific augmentation, label refinement, and feature alignment. Extensive experiments on benchmark datasets demonstrate that DMDL could enable modality-invariant feature learning and a more generalized model.", "AI": {"tldr": "The paper proposes a Dual-level Modality Debiasing Learning (DMDL) framework to address modality bias in unsupervised visible-infrared person re-identification (USL-VI-ReID), achieving more effective and generalized results.", "motivation": "Modality bias occurs in two-stage learning pipelines for USL-VI-ReID, impacting identity discrimination and generalization due to modality-specific cues being propagated between learning stages.", "method": "The method introduces debiasing strategies at two levels. At the model level, a Causality-inspired Adjustment Intervention (CAI) module is used for causal modeling to avoid modality-induced spurious patterns. At the optimization level, a Collaborative Bias-free Training (CBT) strategy combines modality-specific augmentation, label refinement, and feature alignment to mitigate bias propagation.", "result": "Extensive benchmarking demonstrates the effectiveness of DMDL in enabling modality-invariant feature learning and improving model generalization.", "conclusion": "The proposed DMDL framework effectively reduces modality bias in USL-VI-ReID and enhances cross-modality learning performance."}}
{"id": "2512.03755", "pdf": "https://arxiv.org/pdf/2512.03755", "abs": "https://arxiv.org/abs/2512.03755", "authors": ["Stephen Law", "Tao Yang", "Nanjiang Chen", "Xuhui Lin"], "title": "Origin-Conditional Trajectory Encoding: Measuring Urban Configurational Asymmetries through Neural Decomposition", "categories": ["cs.LG"], "comment": null, "summary": "Urban analytics increasingly relies on AI-driven trajectory analysis, yet current approaches suffer from methodological fragmentation: trajectory learning captures movement patterns but ignores spatial context, while spatial embedding methods encode street networks but miss temporal dynamics. Three gaps persist: (1) lack of joint training that integrates spatial and temporal representations, (2) origin-agnostic treatment that ignores directional asymmetries in navigation ($A \\to B \\ne B \\to A$), and (3) over-reliance on auxiliary data (POIs, imagery) rather than fundamental geometric properties of urban space. We introduce a conditional trajectory encoder that jointly learns spatial and movement representations while preserving origin-dependent asymmetries using geometric features. This framework decomposes urban navigation into shared cognitive patterns and origin-specific spatial narratives, enabling quantitative measurement of cognitive asymmetries across starting locations. Our bidirectional LSTM processes visibility ratio and curvature features conditioned on learnable origin embeddings, decomposing representations into shared urban patterns and origin-specific signatures through contrastive learning. Results from six synthetic cities and real-world validation on Beijing's Xicheng District demonstrate that urban morphology creates systematic cognitive inequalities. This provides urban planners quantitative tools for assessing experiential equity, offers architects insights into layout decisions' cognitive impacts, and enables origin-aware analytics for navigation systems.", "AI": {"tldr": "This study introduces a framework to integrate spatial and movement patterns for urban navigation using a conditional trajectory encoder, addressing key limitations in current AI-driven trajectory analysis.", "motivation": "To address the lack of joint modeling of spatial and temporal representations, the ignorance of directional navigation asymmetries, and the over-reliance on auxiliary data in trajectory analysis.", "method": "A conditional trajectory encoder is developed using bidirectional LSTM, leveraging geometric features (visibility ratio, curvature) with learnable origin embeddings, employing contrastive learning to decompose navigational patterns.", "result": "The framework reveals systematic cognitive inequalities in urban navigation caused by urban morphology, validated on synthetic cities and Beijing's Xicheng District.", "conclusion": "The study proposes tools for urban planners and architects to evaluate experiential equity and cognitive impacts of urban designs, as well as enables improved origin-aware navigation analytics."}}
{"id": "2512.03413", "pdf": "https://arxiv.org/pdf/2512.03413", "abs": "https://arxiv.org/abs/2512.03413", "authors": ["Shu Wang", "Yingli Zhou", "Yixiang Fang"], "title": "BookRAG: A Hierarchical Structure-aware Index-based Approach for Retrieval-Augmented Generation on Complex Documents", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "As an effective method to boost the performance of Large Language Models (LLMs) on the question answering (QA) task, Retrieval-Augmented Generation (RAG), which queries highly relevant information from external complex documents, has attracted tremendous attention from both industry and academia. Existing RAG approaches often focus on general documents, and they overlook the fact that many real-world documents (such as books, booklets, handbooks, etc.) have a hierarchical structure, which organizes their content from different granularity levels, leading to poor performance for the QA task. To address these limitations, we introduce BookRAG, a novel RAG approach targeted for documents with a hierarchical structure, which exploits logical hierarchies and traces entity relations to query the highly relevant information. Specifically, we build a novel index structure, called BookIndex, by extracting a hierarchical tree from the document, which serves as the role of its table of contents, using a graph to capture the intricate relationships between entities, and mapping entities to tree nodes. Leveraging the BookIndex, we then propose an agent-based query method inspired by the Information Foraging Theory, which dynamically classifies queries and employs a tailored retrieval workflow. Extensive experiments on three widely adopted benchmarks demonstrate that BookRAG achieves state-of-the-art performance, significantly outperforming baselines in both retrieval recall and QA accuracy while maintaining competitive efficiency.", "AI": {"tldr": "BookRAG is a novel Retrieval-Augmented Generation method optimized for hierarchical documents, improving question answering (QA) tasks by leveraging logical hierarchies and entity relationships.", "motivation": "Current Retrieval-Augmented Generation (RAG) methods fail on hierarchical documents like books due to their lack of understanding of structured content, necessitating a tailored approach.", "method": "BookRAG introduces a specialized index structure, BookIndex, that organizes document structures through hierarchical trees and entity graphs. It uses an agent-based query method inspired by Information Foraging Theory for more effective retrieval.", "result": "BookRAG demonstrates state-of-the-art performance on three QA benchmarks, significantly surpassing previous methods in recall, accuracy, and efficiency.", "conclusion": "BookRAG highlights the importance of leveraging hierarchical structures and entity relationships in RAG for QA tasks, providing a significant improvement over general RAG methods."}}
{"id": "2512.03768", "pdf": "https://arxiv.org/pdf/2512.03768", "abs": "https://arxiv.org/abs/2512.03768", "authors": ["Nir Shlezinger", "Santiago Segarra", "Yi Zhang", "Dvir Avrahami", "Zohar Davidov", "Tirza Routtenberg", "Yonina C. Eldar"], "title": "Deep Unfolding: Recent Developments, Theory, and Design Guidelines", "categories": ["cs.LG", "eess.SP"], "comment": "under review for publication in the IEEE", "summary": "Optimization methods play a central role in signal processing, serving as the mathematical foundation for inference, estimation, and control. While classical iterative optimization algorithms provide interpretability and theoretical guarantees, they often rely on surrogate objectives, require careful hyperparameter tuning, and exhibit substantial computational latency. Conversely, machine learning (ML ) offers powerful data-driven modeling capabilities but lacks the structure, transparency, and efficiency needed for optimization-driven inference. Deep unfolding has recently emerged as a compelling framework that bridges these two paradigms by systematically transforming iterative optimization algorithms into structured, trainable ML architectures. This article provides a tutorial-style overview of deep unfolding, presenting a unified perspective of methodologies for converting optimization solvers into ML models and highlighting their conceptual, theoretical, and practical implications. We review the foundations of optimization for inference and for learning, introduce four representative design paradigms for deep unfolding, and discuss the distinctive training schemes that arise from their iterative nature. Furthermore, we survey recent theoretical advances that establish convergence and generalization guarantees for unfolded optimizers, and provide comparative qualitative and empirical studies illustrating their relative trade-offs in complexity, interpretability, and robustness.", "AI": {"tldr": "This paper explores the integration of optimization methods and machine learning through a deep unfolding framework, aiming to combine their respective strengths for signal processing applications.", "motivation": "To address the shortcomings of traditional optimization methods (e.g., computational inefficiency, reliance on surrogate objectives, and tuning challenges) and data-driven ML approaches (e.g., lack of efficiency and structure for inference).", "method": "Deep unfolding transforms iterative optimization algorithms into structured, trainable machine learning models by systematically bridging optimization and ML approaches.", "result": "The paper reviews four deep unfolding paradigms, discusses training schemes, and surveys theoretical advancements ensuring convergence and generalization guarantees for these models, validating their practical and theoretical viability.", "conclusion": "Deep unfolding successfully combines optimization theory and ML frameworks, providing a new paradigm that balances structure, interpretability, efficiency, and learning capabilities."}}
{"id": "2512.03749", "pdf": "https://arxiv.org/pdf/2512.03749", "abs": "https://arxiv.org/abs/2512.03749", "authors": ["Korada Sri Vardhana", "Shrikrishna Lolla", "Soma Biswas"], "title": "Fully Unsupervised Self-debiasing of Text-to-Image Diffusion Models", "categories": ["cs.CV"], "comment": "Accepted at WACV 2026", "summary": "Text-to-image (T2I) diffusion models have achieved widespread success due to their ability to generate high-resolution, photorealistic images. These models are trained on large-scale datasets, like LAION-5B, often scraped from the internet. However, since this data contains numerous biases, the models inherently learn and reproduce them, resulting in stereotypical outputs. We introduce SelfDebias, a fully unsupervised test-time debiasing method applicable to any diffusion model that uses a UNet as its noise predictor. SelfDebias identifies semantic clusters in an image encoder's embedding space and uses these clusters to guide the diffusion process during inference, minimizing the KL divergence between the output distribution and the uniform distribution. Unlike supervised approaches, SelfDebias does not require human-annotated datasets or external classifiers trained for each generated concept. Instead, it is designed to automatically identify semantic modes. Extensive experiments show that SelfDebias generalizes across prompts and diffusion model architectures, including both conditional and unconditional models. It not only effectively debiases images along key demographic dimensions while maintaining the visual fidelity of the generated images, but also more abstract concepts for which identifying biases is also challenging.", "AI": {"tldr": "SelfDebias is an unsupervised debiasing method for text-to-image diffusion models, addressing biases without requiring labeled datasets.", "motivation": "T2I diffusion models often propagate biases inherent in internet-scraped training datasets, prompting the need for debiasing methods that don't rely on supervised data.", "method": "SelfDebias uses semantic clusters identified in an encoder's embedding space to guide the diffusion process, maintaining balance by minimizing KL divergence with a uniform distribution.", "result": "Experiments demonstrate SelfDebias effectively debiases images along demographic and abstract dimensions, generalizing across prompts and model architectures.", "conclusion": "SelfDebias achieves unsupervised debiasing while preserving image quality, offering adaptability and broad applicability across different T2I models."}}
{"id": "2512.03786", "pdf": "https://arxiv.org/pdf/2512.03786", "abs": "https://arxiv.org/abs/2512.03786", "authors": ["Conor McCarthy", "Jan Peter van Zandwijk", "Marcel Worring", "Zeno Geradts"], "title": "Forensic Activity Classification Using Digital Traces from iPhones: A Machine Learning-based Approach", "categories": ["cs.LG"], "comment": null, "summary": "Smartphones and smartwatches are ever-present in daily life, and provide a rich source of information on their users' behaviour. In particular, digital traces derived from the phone's embedded movement sensors present an opportunity for a forensic investigator to gain insight into a person's physical activities. In this work, we present a machine learning-based approach to translate digital traces into likelihood ratios (LRs) for different types of physical activities. Evaluating on a new dataset, NFI\\_FARED, which contains digital traces from four different types of iPhones labelled with 19 activities, it was found that our approach could produce useful LR systems to distinguish 167 out of a possible 171 activity pairings. The same approach was extended to analyse likelihoods for multiple activities (or groups of activities) simultaneously and create activity timelines to aid in both the early and latter stages of forensic investigations. The dataset and all code required to replicate the results have also been made public to encourage further research on this topic.", "AI": {"tldr": "The paper proposes a machine learning method to analyze movement sensor data from smartphones for forensic purposes, transforming them into likelihood ratios (LRs) for identifying physical activities.", "motivation": "To utilize data from embedded movement sensors in smartphones as a source for forensic insights into physical activities through advanced analytical methods.", "method": "The researchers developed a machine learning-based system to translate smartphone sensor data into LRs for various physical activities and verified its accuracy using a new dataset, NFI_FARED.", "result": "The proposed method effectively distinguished 167 out of 171 activity pairings, demonstrating its potential for forensic analysis.", "conclusion": "The approach is a successful first step in converting digital movement traces from smartphones into actionable forensic insights, enabling timelines and likelihood analyses; it also promotes further research with publicly available data."}}
{"id": "2512.03751", "pdf": "https://arxiv.org/pdf/2512.03751", "abs": "https://arxiv.org/abs/2512.03751", "authors": ["Yufeng Li", "Wenchao Zhao", "Bo Dang", "Weimin Wang"], "title": "Research on Brain Tumor Classification Method Based on Improved ResNet34 Network", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Previously, image interpretation in radiology relied heavily on manual methods. However, manual classification of brain tumor medical images is time-consuming and labor-intensive. Even with shallow convolutional neural network models, the accuracy is not ideal. To improve the efficiency and accuracy of brain tumor image classification, this paper proposes a brain tumor classification model based on an improved ResNet34 network. This model uses the ResNet34 residual network as the backbone network and incorporates multi-scale feature extraction. It uses a multi-scale input module as the first layer of the ResNet34 network and an Inception v2 module as the residual downsampling layer. Furthermore, a channel attention mechanism module assigns different weights to different channels of the image from a channel domain perspective, obtaining more important feature information. The results after a five-fold crossover experiment show that the average classification accuracy of the improved network model is approximately 98.8%, which is not only 1% higher than ResNet34, but also only 80% of the number of parameters of the original model. Therefore, the improved network model not only improves accuracy but also reduces clutter, achieving a classification effect with fewer parameters and higher accuracy.", "AI": {"tldr": "This paper proposes an improved ResNet34 model for classifying brain tumor images, achieving 98.8% accuracy with fewer parameters.", "motivation": "The paper aims to improve the efficiency and accuracy of brain tumor image classification, addressing limitations of manual methods and shallow convolutional neural networks.", "method": "The improved model modifies ResNet34 by incorporating multi-scale feature extraction, a multi-scale input module, an Inception v2 module for downsampling, and a channel attention mechanism.", "result": "The model achieved 98.8% classification accuracy via a five-fold crossover experiment, 1% higher than ResNet34, with only 80% of the original parameters.", "conclusion": "The improved ResNet34 network enhances classification accuracy and reduces parameter complexity, offering a more efficient and effective solution for brain tumor image analysis."}}
{"id": "2512.03787", "pdf": "https://arxiv.org/pdf/2512.03787", "abs": "https://arxiv.org/abs/2512.03787", "authors": ["Francesco Vitale", "Nicola Mazzocca"], "title": "Adaptive Identification and Modeling of Clinical Pathways with Process Mining", "categories": ["cs.LG"], "comment": "Accepted to the 41st ACM/SIGAPP Symposium On Applied Computing (ACM SAC 2026)", "summary": "Clinical pathways are specialized healthcare plans that model patient treatment procedures. They are developed to provide criteria-based progression and standardize patient treatment, thereby improving care, reducing resource use, and accelerating patient recovery. However, manual modeling of these pathways based on clinical guidelines and domain expertise is difficult and may not reflect the actual best practices for different variations or combinations of diseases. We propose a two-phase modeling method using process mining, which extends the knowledge base of clinical pathways by leveraging conformance checking diagnostics. In the first phase, historical data of a given disease is collected to capture treatment in the form of a process model. In the second phase, new data is compared against the reference model to verify conformance. Based on the conformance checking results, the knowledge base can be expanded with more specific models tailored to new variants or disease combinations. We demonstrate our approach using Synthea, a benchmark dataset simulating patient treatments for SARS-CoV-2 infections with varying COVID-19 complications. The results show that our method enables expanding the knowledge base of clinical pathways with sufficient precision, peaking to 95.62% AUC while maintaining an arc-degree simplicity of 67.11%.", "AI": {"tldr": "The paper presents a two-phase method to improve clinical pathway modeling using historical data and process mining, achieving high precision and simplicity.", "motivation": "Current manual modeling of clinical pathways is challenging and often doesn't reflect best practices for diverse disease combinations.", "method": "The method collects historical treatment data to create a model and compares new data for conformance to refine the knowledge base.", "result": "Using a benchmark dataset on COVID-19 complications, the proposed method achieved 95.62% AUC precision and 67.11% simplicity.", "conclusion": "The approach effectively expands clinical pathway knowledge bases with high accuracy while maintaining simplicity, improving pathway modeling for varying disease conditions."}}
{"id": "2512.03804", "pdf": "https://arxiv.org/pdf/2512.03804", "abs": "https://arxiv.org/abs/2512.03804", "authors": ["Hanhui Deng", "Xinglin Li", "Jie Luo", "Zhanpeng Jin", "Di Wu"], "title": "EfficientECG: Cross-Attention with Feature Fusion for Efficient Electrocardiogram Classification", "categories": ["cs.LG"], "comment": null, "summary": "Electrocardiogram is a useful diagnostic signal that can detect cardiac abnormalities by measuring the electrical activity generated by the heart. Due to its rapid, non-invasive, and richly informative characteristics, ECG has many emerging applications. In this paper, we study novel deep learning technologies to effectively manage and analyse ECG data, with the aim of building a diagnostic model, accurately and quickly, that can substantially reduce the burden on medical workers. Unlike the existing ECG models that exhibit a high misdiagnosis rate, our deep learning approaches can automatically extract the features of ECG data through end-to-end training. Specifically, we first devise EfficientECG, an accurate and lightweight classification model for ECG analysis based on the existing EfficientNet model, which can effectively handle high-frequency long-sequence ECG data with various leading types. On top of that, we next propose a cross-attention-based feature fusion model of EfficientECG for analysing multi-lead ECG data with multiple features (e.g., gender and age). Our evaluations on representative ECG datasets validate the superiority of our model against state-of-the-art works in terms of high precision, multi-feature fusion, and lightweights.", "AI": {"tldr": "This paper proposes deep learning models for electrocardiogram (ECG) analysis that improve diagnostic accuracy, reduce misdiagnosis rates, and ease the burden on medical workers.", "motivation": "To address the high misdiagnosis rate in current ECG models and improve management and analysis of ECG data with effective deep learning solutions.", "method": "Development of EfficientECG, a lightweight and accurate classification model based on EfficientNet, and a cross-attention feature fusion model for multi-lead ECG data incorporating demographic features like gender and age.", "result": "Experimental evaluations demonstrate superior classification accuracy, feature fusion capability, and computational efficiency when compared to existing techniques.", "conclusion": "The proposed approaches advance the reliability and efficiency of ECG analysis models, highlighting their applicability to reduce workload for medical practitioners and enhance clinical outcomes."}}
{"id": "2512.03796", "pdf": "https://arxiv.org/pdf/2512.03796", "abs": "https://arxiv.org/abs/2512.03796", "authors": ["Hong-Kai Zheng", "Piji Li"], "title": "LSRS: Latent Scale Rejection Sampling for Visual Autoregressive Modeling", "categories": ["cs.CV"], "comment": null, "summary": "Visual Autoregressive (VAR) modeling approach for image generation proposes autoregressive processing across hierarchical scales, decoding multiple tokens per scale in parallel. This method achieves high-quality generation while accelerating synthesis. However, parallel token sampling within a scale may lead to structural errors, resulting in suboptimal generated images. To mitigate this, we propose Latent Scale Rejection Sampling (LSRS), a method that progressively refines token maps in the latent scale during inference to enhance VAR models. Our method uses a lightweight scoring model to evaluate multiple candidate token maps sampled at each scale, selecting the high-quality map to guide subsequent scale generation. By prioritizing early scales critical for structural coherence, LSRS effectively mitigates autoregressive error accumulation while maintaining computational efficiency. Experiments demonstrate that LSRS significantly improves VAR's generation quality with minimal additional computational overhead. For the VAR-d30 model, LSRS increases the inference time by merely 1% while reducing its FID score from 1.95 to 1.78. When the inference time is increased by 15%, the FID score can be further reduced to 1.66. LSRS offers an efficient test-time scaling solution for enhancing VAR-based generation.", "AI": {"tldr": "The paper introduces Latent Scale Rejection Sampling (LSRS), which enhances Visual Autoregressive (VAR) models for image generation by refining token maps and preventing structural errors.", "motivation": "To address structural errors in parallel token sampling within VAR models and improve image generation quality while maintaining computational efficiency.", "method": "A lightweight scoring model evaluates candidate token maps at each scale to refine and select optimal maps during inference, reducing errors across hierarchical scales.", "result": "Applying LSRS to VAR models improves generation quality, decreasing FID scores significantly (from 1.95 to 1.78, and further to 1.66 with additional inference time) with minimal computational overhead.", "conclusion": "LSRS effectively enhances VAR image generation by balancing structural coherence and computational efficiency through test-time scaling."}}
{"id": "2512.03805", "pdf": "https://arxiv.org/pdf/2512.03805", "abs": "https://arxiv.org/abs/2512.03805", "authors": ["Tai Nguyen", "Phong Le", "Andr\u00e9 Biedenkapp", "Carola Doerr", "Nguyen Dang"], "title": "Deep Reinforcement Learning for Dynamic Algorithm Configuration: A Case Study on Optimizing OneMax with the (1+($\u03bb$,$\u03bb$))-GA", "categories": ["cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2502.20265", "summary": "Dynamic Algorithm Configuration (DAC) studies the efficient identification of control policies for parameterized optimization algorithms. Numerous studies have leveraged the robustness of decision-making in Reinforcement Learning (RL) to address the optimization challenges in algorithm configuration. However, applying RL to DAC is challenging and often requires extensive domain expertise. We conduct a comprehensive study of deep-RL algorithms in DAC through a systematic analysis of controlling the population size parameter of the (1+($\u03bb$,$\u03bb$))-GA on OneMax instances. Our investigation of DDQN and PPO reveals two fundamental challenges that limit their effectiveness in DAC: scalability degradation and learning instability. We trace these issues to two primary causes: under-exploration and planning horizon coverage, each of which can be effectively addressed through targeted solutions. To address under-exploration, we introduce an adaptive reward shifting mechanism that leverages reward distribution statistics to enhance DDQN agent exploration, eliminating the need for instance-specific hyperparameter tuning and ensuring consistent effectiveness across different problem scales. In dealing with the planning horizon coverage problem, we demonstrate that undiscounted learning effectively resolves it in DDQN, while PPO faces fundamental variance issues that necessitate alternative algorithmic designs. We further analyze the hyperparameter dependencies of PPO, showing that while hyperparameter optimization enhances learning stability, it consistently falls short in identifying effective policies across various configurations. Finally, we demonstrate that DDQN equipped with our adaptive reward shifting strategy achieves performance comparable to theoretically derived policies with vastly improved sample efficiency, outperforming prior DAC approaches by several orders of magnitude.", "AI": {"tldr": "The paper investigates challenges in applying deep reinforcement learning algorithms to dynamic algorithm configuration (DAC) and proposes solutions for scalability degradation and learning instability.", "motivation": "Reinforcement Learning methods have been used to solve challenges in DAC, but they are often limited by scalability and require domain expertise. The authors aim to systematically study these limitations.", "method": "The study focuses on controlling population size in a specific genetic algorithm using deep reinforcement learning approaches such as DDQN and PPO, and introduces solutions like adaptive reward shifting for exploration and tackling horizon coverage issues in learning.", "result": "The proposed adaptive reward shifting method enhances DDQN's exploration, while undiscounted learning resolves planning horizon issues. The DDQN method achieves sample efficiency and matches theoretical policies, outperforming prior DAC approaches.", "conclusion": "DDQN combined with adaptive reward shifting shows significant promise for DAC, removing reliance on hyperparameter tuning, resolving RL challenges, and achieving high sample efficiency compared to prior methods."}}
{"id": "2512.03460", "pdf": "https://arxiv.org/pdf/2512.03460", "abs": "https://arxiv.org/abs/2512.03460", "authors": ["Johnny Peng", "Thanh Tung Khuat", "Ellen Otte", "Katarzyna Musial", "Bogdan Gabrys"], "title": "Learning From Limited Data and Feedback for Cell Culture Process Monitoring: A Comparative Study", "categories": ["q-bio.QM", "cs.AI", "cs.CE", "cs.LG"], "comment": "This is a pre-print for submitting to computers & chemical engineering journal", "summary": "In cell culture bioprocessing, real-time batch process monitoring (BPM) refers to the continuous tracking and analysis of key process variables such as viable cell density, nutrient levels, metabolite concentrations, and product titer throughout the duration of a batch run. This enables early detection of deviations and supports timely control actions to ensure optimal cell growth and product quality. BPM plays a critical role in ensuring the quality and regulatory compliance of biopharmaceutical manufacturing processes. However, the development of accurate soft sensors for BPM is hindered by key challenges, including limited historical data, infrequent feedback, heterogeneous process conditions, and high-dimensional sensory inputs. This study presents a comprehensive benchmarking analysis of machine learning (ML) methods designed to address these challenges, with a focus on learning from historical data with limited volume and relevance in the context of bioprocess monitoring. We evaluate multiple ML approaches including feature dimensionality reduction, online learning, and just-in-time learning across three datasets, one in silico dataset and two real-world experimental datasets. Our findings highlight the importance of training strategies in handling limited data and feedback, with batch learning proving effective in homogeneous settings, while just-in-time learning and online learning demonstrate superior adaptability in cold-start scenarios. Additionally, we identify key meta-features, such as feed media composition and process control strategies, that significantly impact model transferability. The results also suggest that integrating Raman-based predictions with lagged offline measurements enhances monitoring accuracy, offering a promising direction for future bioprocess soft sensor development.", "AI": {"tldr": "This paper focuses on overcoming challenges in real-time monitoring of cell culture bioprocessing using machine learning methods by benchmarking various approaches.", "motivation": "To improve real-time batch process monitoring in cell culture bioprocessing by addressing challenges like limited data, infrequent feedback, and high-dimensional inputs to enhance process control and regulatory compliance.", "method": "A benchmarking analysis of different machine learning methods, including feature dimensionality reduction, online learning, and just-in-time learning, applied to one in silico and two real-world experimental datasets.", "result": "The study identifies training strategies like batch learning as effective for homogeneous settings while showing the adaptability of just-in-time and online learning in cold-start scenarios. It highlights the role of meta-features and the integration of Raman-based predictions for improved accuracy.", "conclusion": "Machine learning methods can address limitations in bioprocess monitoring, with specific strategies offering improved adaptability and accuracy. Integration of advanced metrics like Raman-based predictions is a significant step forward."}}
{"id": "2512.03817", "pdf": "https://arxiv.org/pdf/2512.03817", "abs": "https://arxiv.org/abs/2512.03817", "authors": ["Ahmed Nasser", "Marwan Mohamed", "Alaa Sherif", "Basmala Mahmoud", "Shereen Yehia", "Asmaa Saad", "Mariam S. El-Rahmany", "Ensaf H. Mohamed"], "title": "HieroGlyphTranslator: Automatic Recognition and Translation of Egyptian Hieroglyphs to English", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Egyptian hieroglyphs, the ancient Egyptian writing system, are composed entirely of drawings. Translating these glyphs into English poses various challenges, including the fact that a single glyph can have multiple meanings. Deep learning translation applications are evolving rapidly, producing remarkable results that significantly impact our lives. In this research, we propose a method for the automatic recognition and translation of ancient Egyptian hieroglyphs from images to English. This study utilized two datasets for classification and translation: the Morris Franken dataset and the EgyptianTranslation dataset. Our approach is divided into three stages: segmentation (using Contour and Detectron2), mapping symbols to Gardiner codes, and translation (using the CNN model). The model achieved a BLEU score of 42.2, a significant result compared to previous research.", "AI": {"tldr": "This paper proposes a method using deep learning for automatic recognition and translation of ancient Egyptian hieroglyphs from images to English, achieving notable performance improvements.", "motivation": "Challenges in translating Egyptian hieroglyphs include their complex nature where one glyph can have multiple meanings, and leveraging deep learning to address this issue could significantly improve translation methods.", "method": "The approach involves three stages: segmentation using Contour and Detectron2, mapping glyphs to Gardiner codes, and translation using a CNN model. Two datasets were used for training and testing.", "result": "The proposed model achieved a BLEU score of 42.2, marking significant improvement over prior research efforts.", "conclusion": "The study demonstrates the effectiveness of deep learning methods in enhancing the accuracy of translating ancient Egyptian hieroglyphs."}}
{"id": "2512.03816", "pdf": "https://arxiv.org/pdf/2512.03816", "abs": "https://arxiv.org/abs/2512.03816", "authors": ["Timoth\u00e9e Chauvin", "Erwan Le Merrer", "Fran\u00e7ois Ta\u00efani", "Gilles Tredan"], "title": "Log Probability Tracking of LLM APIs", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "When using an LLM through an API provider, users expect the served model to remain consistent over time, a property crucial for the reliability of downstream applications and the reproducibility of research. Existing audit methods are too costly to apply at regular time intervals to the wide range of available LLM APIs. This means that model updates are left largely unmonitored in practice. In this work, we show that while LLM log probabilities (logprobs) are usually non-deterministic, they can still be used as the basis for cost-effective continuous monitoring of LLM APIs. We apply a simple statistical test based on the average value of each token logprob, requesting only a single token of output. This is enough to detect changes as small as one step of fine-tuning, making this approach more sensitive than existing methods while being 1,000x cheaper. We introduce the TinyChange benchmark as a way to measure the sensitivity of audit methods in the context of small, realistic model changes.", "AI": {"tldr": "The paper presents a cost-effective method to monitor changes in LLMs served through APIs, using log probability statistics which are sensitive to even small updates.", "motivation": "Ensuring consistency of models provided by LLM APIs is critical for reliability and reproducibility, but monitoring them is expensive and often overlooked.", "method": "A simple and cost-effective statistical test is applied using token-level log probabilities, requiring minimal API interaction, to detect even minor model changes.", "result": "The proposed approach demonstrated sensitivity to small changes, such as one fine-tuning step, while being 1,000 times cheaper than traditional methods.", "conclusion": "The proposed method enables practical, efficient, and sensitive continuous monitoring of LLM APIs, improving reliability and reducing costs."}}
{"id": "2512.03827", "pdf": "https://arxiv.org/pdf/2512.03827", "abs": "https://arxiv.org/abs/2512.03827", "authors": ["Alexey Protopopov"], "title": "A Robust Camera-based Method for Breath Rate Measurement", "categories": ["cs.CV"], "comment": "9 pages, 4 figures, 2 tables", "summary": "Proliferation of cheap and accessible cameras makes it possible to measure a subject's breath rate from video footage alone. Recent works on this topic have proposed a variety of approaches for accurately measuring human breath rate, however they are either tested in near-ideal conditions, or produce results that are not sufficiently accurate. The present study proposes a more robust method to measure breath rate in humans with minimal hardware requirements using a combination of mathematical transforms with a relative deviation from the ground truth of less than 5%. The method was tested on videos taken from 14 volunteers with a total duration of over 2 hours 30 minutes. The obtained results were compared to reference data and the average mean absolute error was found to be at 0.57 respirations per minute, which is noticeably better than the results from previous works. The breath rate measurement method proposed in the present article is more resistant to distortions caused by subject movement and thus allows one to remotely measure the subject's breath rate without any significant limitations on the subject's behavior.", "AI": {"tldr": "The paper introduces a robust video-based method to measure human breath rate with minimal hardware, achieving accurate results and superior performance compared to previous methods.", "motivation": "To develop a more accurate and robust method for remotely measuring human breath rate from video footage, overcoming limitations like distortions and subject behavior that affect current methods.", "method": "A combination of mathematical transforms was applied to video footage, requiring minimal hardware, and tested on data from 14 volunteers with over 2.5 hours of total video duration.", "result": "The proposed method achieved a relative deviation of under 5% compared to ground truth, with an average mean absolute error of 0.57 respirations per minute, outperforming prior approaches.", "conclusion": "This method is more resistant to subject movement distortions, enabling reliable remote measurement of breath rate with minimal limitations on behavior."}}
{"id": "2512.03819", "pdf": "https://arxiv.org/pdf/2512.03819", "abs": "https://arxiv.org/abs/2512.03819", "authors": ["Junlin Chang", "Yubo Han", "Hnag Yue", "John S Thompson", "Rongke Liu"], "title": "Transmit Weights, Not Features: Orthogonal-Basis Aided Wireless Point-Cloud Transmission", "categories": ["cs.LG"], "comment": "5 pages, 5 figures", "summary": "The widespread adoption of depth sensors has substantially lowered the barrier to point-cloud acquisition. This letter proposes a semantic wireless transmission framework for three dimension (3D) point clouds built on Deep Joint Source - Channel Coding (DeepJSCC). Instead of sending raw features, the transmitter predicts combination weights over a receiver-side semantic orthogonal feature pool, enabling compact representations and robust reconstruction. A folding-based decoder deforms a 2D grid into 3D, enforcing manifold continuity while preserving geometric fidelity. Trained with Chamfer Distance (CD) and an orthogonality regularizer, the system is evaluated on ModelNet40 across varying Signal-to-Noise Ratios (SNRs) and bandwidths. Results show performance on par with SEmantic Point cloud Transmission (SEPT) at high bandwidth and clear gains in bandwidth-constrained regimes, with consistent improvements in both Peak Signal-to-Noise Ratio (PSNR) and CD. Ablation experiments confirm the benefits of orthogonalization and the folding prior.", "AI": {"tldr": "This paper introduces a semantic wireless transmission framework for 3D point clouds using DeepJSCC, achieving robust transmission and geometric fidelity under varying bandwidth and SNR conditions.", "motivation": "Depth sensors have made point-cloud acquisition accessible, but efficient transmission methods are needed for better performance under constrained bandwidth and SNR environments.", "method": "The transmitter predicts weights over a semantic orthogonal feature pool at the receiver. A folding-based decoder reconstructs the point cloud by deforming a 2D grid into 3D, while training focuses on Chamfer Distance and orthogonality regularization.", "result": "System performance matches SEPT at high bandwidths while outperforming in low-bandwidth scenarios, with improvements in PSNR and Chamfer Distance metrics.", "conclusion": "The proposed framework proves effective for semantic transmission of 3D point clouds, especially in bandwidth-constrained scenarios, and benefits from orthogonalization and folding prior techniques."}}
{"id": "2512.03466", "pdf": "https://arxiv.org/pdf/2512.03466", "abs": "https://arxiv.org/abs/2512.03466", "authors": ["Xavier Cadet", "Edward Koh", "Peter Chin"], "title": "AsymPuzl: An Asymmetric Puzzle for multi-agent cooperation", "categories": ["cs.MA", "cs.AI"], "comment": "Accepted at NeurIPS MTI-LLM 2025", "summary": "Large Language Model (LLM) agents are increasingly studied in multi-turn, multi-agent scenarios, yet most existing setups emphasize open-ended role-play rather than controlled evaluation. We introduce AsymPuzl, a minimal but expressive two-agent puzzle environment designed to isolate communication under information asymmetry. Each agent observes complementary but incomplete views of a symbolic puzzle and must exchange messages to solve it cooperatively. Using a diverse set of current-generation and open-source LLMs, we show that (i) strong models such as GPT-5 and Claude-4.0 reliably converge across puzzle sizes on the solution by sharing complete information in two turns, (ii) weaker models often ignore partner messages or over-correct their hypotheses, and (iii) feedback design is non-trivial: simple self-feedback improves success rates, while detailed joint feedback can hurt performance. These findings show that even in simple cooperative tasks, LLM communication strategies diverge and depend on the granularity of feedback signals. AsymPuzl thus provides a testbed for probing the limits of multi-turn cooperation and opens avenues for studying coordination mechanisms.", "AI": {"tldr": "The paper introduces AsymPuzl, a puzzle environment for evaluating LLM communication under information asymmetry and highlights divergences in their cooperative strategies.", "motivation": "Understanding and improving how LLMs communicate and cooperate effectively, especially in tasks requiring information exchange under asymmetric conditions.", "method": "Developed AsymPuzl, a two-agent puzzle environment with symbolic tasks and tested various LLMs to observe their performance in cooperative problem-solving scenarios.", "result": "Powerful LLMs, like GPT-5 and Claude-4.0, successfully solved puzzles with two-turn communication, while weaker models struggled. Feedback design significantly affected performance.", "conclusion": "AsymPuzl offers a controlled framework to assess LLM cooperation and shows that feedback and communication strategies critically impact performance in multi-agent setups."}}
{"id": "2512.03834", "pdf": "https://arxiv.org/pdf/2512.03834", "abs": "https://arxiv.org/abs/2512.03834", "authors": ["Ture Hassler", "Ida \u00c5kerholm", "Marcus Nordstr\u00f6m", "Gabriele Balletti", "Orcun Goksel"], "title": "Lean Unet: A Compact Model for Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Unet and its variations have been standard in semantic image segmentation, especially for computer assisted radiology. Current Unet architectures iteratively downsample spatial resolution while increasing channel dimensions to preserve information content. Such a structure demands a large memory footprint, limiting training batch sizes and increasing inference latency. Channel pruning compresses Unet architecture without accuracy loss, but requires lengthy optimization and may not generalize across tasks and datasets. By investigating Unet pruning, we hypothesize that the final structure is the crucial factor, not the channel selection strategy of pruning. Based on our observations, we propose a lean Unet architecture (LUnet) with a compact, flat hierarchy where channels are not doubled as resolution is halved. We evaluate on a public MRI dataset allowing comparable reporting, as well as on two internal CT datasets. We show that a state-of-the-art pruning solution (STAMP) mainly prunes from the layers with the highest number of channels. Comparatively, simply eliminating a random channel at the pruning-identified layer or at the largest layer achieves similar or better performance. Our proposed LUnet with fixed architectures and over 30 times fewer parameters achieves performance comparable to both conventional Unet counterparts and data-adaptively pruned networks. The proposed lean Unet with constant channel count across layers requires far fewer parameters while achieving performance superior to standard Unet for the same total number of parameters. Skip connections allow Unet bottleneck channels to be largely reduced, unlike standard encoder-decoder architectures requiring increased bottleneck channels for information propagation.", "AI": {"tldr": "This paper focuses on optimizing Unet for medical image segmentation by reducing its complexity and memory usage while maintaining performance.", "motivation": "The need for efficient deep learning models in medical image segmentation due to memory constraints, inference latency, and the inefficiencies of current pruning strategies.", "method": "The paper proposes a new lean Unet architecture (LUnet) that maintains a compact, flat hierarchy with constant channel counts and eliminates the typical doubling of channels while halving resolution.", "result": "LUnet achieves comparable or superior performance to standard Unet architectures and state-of-the-art pruned networks, while requiring far fewer parameters (over 30x fewer in some cases). Random channel pruning at specific layers often matches or exceeds performance of advanced pruning solutions.", "conclusion": "A compact, flat hierarchy design with constant channel counts, as proposed in LUnet, results in more efficient architectures for semantic image segmentation without sacrificing model accuracy or task applicability."}}
{"id": "2512.03847", "pdf": "https://arxiv.org/pdf/2512.03847", "abs": "https://arxiv.org/abs/2512.03847", "authors": ["Dingwei Zhu", "Zhiheng Xi", "Shihan Dou", "Yuhui Wang", "Sixian Li", "Junjie Ye", "Honglin Guo", "Shichun Liu", "Chenhao Huang", "Yajie Yang", "Junlin Shang", "Senjie Jin", "Ming Zhang", "Jiazheng Zhang", "Caishuang Huang", "Yunke Zhang", "Demei Yan", "Yuran Wang", "Tao Gui"], "title": "DVPO: Distributional Value Modeling-based Policy Optimization for LLM Post-Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has shown strong performance in LLM post-training, but real-world deployment often involves noisy or incomplete supervision. In such settings, complex and unreliable supervision signals can destabilize training and harm generalization. While existing approaches such as worst-case optimization (e.g., RFQI, CQL) and mean-based methods (e.g., PPO, GRPO) can improve stability, they often overlook generalization and may produce overly conservative policies, leading to uneven performance across diverse real scenarios. To this end, we introduce DVPO (Distributional Value Modeling with Risk-aware Policy Optimization), a new RL framework that combines conditional risk theory with distributional value modeling to better balance robustness and generalization. DVPO learns token-level value distributions to provide fine-grained supervision, and applies an asymmetric risk regularization to shape the distribution tails: it contracts the lower tail to dampen noisy negative deviations, while expanding the upper tail to preserve exploratory diversity. Across extensive experiments and analysis in multi-turn dialogue, math reasoning, and scientific QA, DVPO consistently outperforms PPO, GRPO, and robust Bellman-based PPO under noisy supervision, showing its potential for LLM post-training in the real-world.", "AI": {"tldr": "DVPO is a novel reinforcement learning framework aimed at improving robustness and generalization in noisy supervision scenarios for LLM post-training.", "motivation": "Existing RL methods either focus on stability or generalization but fail to balance both in scenarios involving noisy or incomplete supervision.", "method": "DVPO introduces token-level value distributions and asymmetric risk regularization. It contracts the lower tail to reduce noisy negative impacts and expands the upper tail to enhance exploratory diversity.", "result": "DVPO consistently outperforms methods like PPO, GRPO, and robust Bellman-based PPO in tasks like multi-turn dialogue, math reasoning, and scientific QA under noisy supervision.", "conclusion": "DVPO demonstrates strong potential as a reliable RL framework for real-world applications of LLM post-training."}}
{"id": "2512.03837", "pdf": "https://arxiv.org/pdf/2512.03837", "abs": "https://arxiv.org/abs/2512.03837", "authors": ["Mengyuan Liu", "Jinfu Liu", "Yongkang Jiang", "Bin He"], "title": "Heatmap Pooling Network for Action Recognition from RGB Videos", "categories": ["cs.CV"], "comment": "Final Version of IEEE Transactions on Pattern Analysis and Machine Intelligence", "summary": "Human action recognition (HAR) in videos has garnered widespread attention due to the rich information in RGB videos. Nevertheless, existing methods for extracting deep features from RGB videos face challenges such as information redundancy, susceptibility to noise and high storage costs. To address these issues and fully harness the useful information in videos, we propose a novel heatmap pooling network (HP-Net) for action recognition from videos, which extracts information-rich, robust and concise pooled features of the human body in videos through a feedback pooling module. The extracted pooled features demonstrate obvious performance advantages over the previously obtained pose data and heatmap features from videos. In addition, we design a spatial-motion co-learning module and a text refinement modulation module to integrate the extracted pooled features with other multimodal data, enabling more robust action recognition. Extensive experiments on several benchmarks namely NTU RGB+D 60, NTU RGB+D 120, Toyota-Smarthome and UAV-Human consistently verify the effectiveness of our HP-Net, which outperforms the existing human action recognition methods. Our code is publicly available at: https://github.com/liujf69/HPNet-Action.", "AI": {"tldr": "The paper introduces HP-Net for human action recognition (HAR) using a feedback pooling module and additional co-learning and modulation techniques, offering better performance than existing methods.", "motivation": "Existing HAR methods for RGB videos struggle with issues like data redundancy, noise, and high storage costs, necessitating more efficient and robust feature extraction approaches.", "method": "The proposed HP-Net uses a feedback pooling module to generate robust, concise pooled features. It also includes a spatial-motion co-learning module and a text refinement modulation module to integrate pooled features with multimodal data for improved recognition.", "result": "HP-Net outperforms existing HAR methods in experiments conducted on benchmarks like NTU RGB+D 60, NTU RGB+D 120, Toyota-Smarthome, and UAV-Human.", "conclusion": "HP-Net provides an effective, integrated method for action recognition, addressing the challenges faced by current RGB video-based HAR techniques, with publicly available implementation for replicability."}}
{"id": "2512.03861", "pdf": "https://arxiv.org/pdf/2512.03861", "abs": "https://arxiv.org/abs/2512.03861", "authors": ["Gaetano Signorelli", "Michele Lombardi"], "title": "Scalable Decision Focused Learning via Online Trainable Surrogates", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Decision support systems often rely on solving complex optimization problems that may require to estimate uncertain parameters beforehand. Recent studies have shown how using traditionally trained estimators for this task can lead to suboptimal solutions. Using the actual decision cost as a loss function (called Decision Focused Learning) can address this issue, but with a severe loss of scalability at training time. To address this issue, we propose an acceleration method based on replacing costly loss function evaluations with an efficient surrogate. Unlike previously defined surrogates, our approach relies on unbiased estimators reducing the risk of spurious local optima and can provide information on its local confidence allowing one to switch to a fallback method when needed. Furthermore, the surrogate is designed for a black-box setting, which enables compensating for simplifications in the optimization model and account- ing for recourse actions during cost computation. In our results, the method reduces costly inner solver calls, with a solution quality comparable to other state-of-the-art techniques.", "AI": {"tldr": "The paper introduces an accelerated method for Decision Focused Learning by creating an efficient surrogate to replace costly loss function evaluations, maintaining solution quality while reducing computational demand.", "motivation": "Traditional estimators in decision support systems can lead to suboptimal outcomes, and while Decision Focused Learning addresses this, it suffers from poor scalability during training. The study aims to overcome this scalability challenge.", "method": "The proposed method creates an efficient surrogate for loss function evaluations. This surrogate uses unbiased estimators, reduces the likelihood of local optima, and provides local confidence metrics for fallback strategies. It is designed for black-box settings to account for optimization and recourse complexities.", "result": "The method reduces the frequency of expensive solver calls while achieving a comparable solution quality to state-of-the-art techniques.", "conclusion": "The proposed acceleration strategy makes Decision Focused Learning more scalable without compromising on solution quality, demonstrating significant computational efficiency."}}
{"id": "2512.03497", "pdf": "https://arxiv.org/pdf/2512.03497", "abs": "https://arxiv.org/abs/2512.03497", "authors": ["Xiangzheng Cheng", "Haili Huang", "Ye Su", "Qing Nie", "Xiufen Zou", "Suoqin Jin"], "title": "Cell-cell communication inference and analysis: biological mechanisms, computational approaches, and future opportunities", "categories": ["q-bio.QM", "cs.AI", "q-bio.CB"], "comment": null, "summary": "In multicellular organisms, cells coordinate their activities through cell-cell communication (CCC), which are crucial for development, tissue homeostasis, and disease progression. Recent advances in single-cell and spatial omics technologies provide unprecedented opportunities to systematically infer and analyze CCC from these omics data, either by integrating prior knowledge of ligand-receptor interactions (LRIs) or through de novo approaches. A variety of computational methods have been developed, focusing on methodological innovations, accurate modeling of complex signaling mechanisms, and investigation of broader biological questions. These advances have greatly enhanced our ability to analyze CCC and generate biological hypotheses. Here, we introduce the biological mechanisms and modeling strategies of CCC, and provide a focused overview of more than 140 computational methods for inferring CCC from single-cell and spatial transcriptomic data, emphasizing the diversity in methodological frameworks and biological questions. Finally, we discuss the current challenges and future opportunities in this rapidly evolving field.", "AI": {"tldr": "This paper reviews the methods for analyzing cell-cell communication (CCC) using single-cell and spatial omics data and highlights over 140 computational approaches while discussing challenges and future directions.", "motivation": "To improve understanding and analysis of cell-cell communication, which is fundamental to multicellular organism function and disease, leveraging recent advancements in single-cell and spatial omics.", "method": "Reviewing over 140 computational methods for CCC inference from omics data, categorizing modeling strategies, discussing biological mechanisms, and summarizing methodological innovations.", "result": "A detailed overview and comparison of existing CCC computational methods, highlighting their diversity and contributions to biological research.", "conclusion": "This study emphasizes the advancements and challenges in CCC research, underlining the potential of single-cell and spatial omics in addressing biological questions, while identifying future opportunities for the field."}}
{"id": "2512.03844", "pdf": "https://arxiv.org/pdf/2512.03844", "abs": "https://arxiv.org/abs/2512.03844", "authors": ["Letian Zhou", "Songhua Liu", "Xinchao Wang"], "title": "CoDA: From Text-to-Image Diffusion Models to Training-Free Dataset Distillation", "categories": ["cs.CV"], "comment": "34 pages, 24 figures", "summary": "Prevailing Dataset Distillation (DD) methods leveraging generative models confront two fundamental limitations. First, despite pioneering the use of diffusion models in DD and delivering impressive performance, the vast majority of approaches paradoxically require a diffusion model pre-trained on the full target dataset, undermining the very purpose of DD and incurring prohibitive training costs. Second, although some methods turn to general text-to-image models without relying on such target-specific training, they suffer from a significant distributional mismatch, as the web-scale priors encapsulated in these foundation models fail to faithfully capture the target-specific semantics, leading to suboptimal performance. To tackle these challenges, we propose Core Distribution Alignment (CoDA), a framework that enables effective DD using only an off-the-shelf text-to-image model. Our key idea is to first identify the \"intrinsic core distribution\" of the target dataset using a robust density-based discovery mechanism. We then steer the generative process to align the generated samples with this core distribution. By doing so, CoDA effectively bridges the gap between general-purpose generative priors and target semantics, yielding highly representative distilled datasets. Extensive experiments suggest that, without relying on a generative model specifically trained on the target dataset, CoDA achieves performance on par with or even superior to previous methods with such reliance across all benchmarks, including ImageNet-1K and its subsets. Notably, it establishes a new state-of-the-art accuracy of 60.4% at the 50-images-per-class (IPC) setup on ImageNet-1K. Our code is available on the project webpage: https://github.com/zzzlt422/CoDA", "AI": {"tldr": "This paper introduces \"Core Distribution Alignment\" (CoDA), a technique enabling effective dataset distillation using standard text-to-image models without requiring dataset-specific pre-training.", "motivation": "The authors address the inefficiencies in existing dataset distillation (DD) techniques, such as high training costs from using pre-trained diffusion models and suboptimal results caused by distributional mismatches in general text-to-image models.", "method": "The proposed CoDA framework first identifies the \"intrinsic core distribution\" of the target dataset through a density-based mechanism. This is used to guide the generative model to align its outputs with the target dataset's distribution.", "result": "CoDA demonstrates superior or comparable performance to previous DD methods, achieving state-of-the-art accuracy of 60.4% with 50 images per class on the ImageNet-1K dataset, without requiring target-specific training.", "conclusion": "CoDA efficiently bridges the gap between general-purpose generative priors and dataset-specific semantics, offering a cost-effective and high-performing solution for dataset distillation."}}
{"id": "2512.03848", "pdf": "https://arxiv.org/pdf/2512.03848", "abs": "https://arxiv.org/abs/2512.03848", "authors": ["Hania Ghouse", "Maryam Alsharqi", "Farhad R. Nezami", "Muzammil Behzad"], "title": "PULSE: A Unified Multi-Task Architecture for Cardiac Segmentation, Diagnosis, and Few-Shot Cross-Modality Clinical Adaptation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Cardiac image analysis remains fragmented across tasks: anatomical segmentation, disease classification, and grounded clinical report generation are typically handled by separate networks trained under different data regimes. No existing framework unifies these objectives within a single architecture while retaining generalization across imaging modalities and datasets. We introduce PULSE, a multi-task vision-language framework built on self-supervised representations and optimized through a composite supervision strategy that balances region overlap learning, pixel wise classification fidelity, and boundary aware IoU refinement. A multi-scale token reconstruction decoder enables anatomical segmentation, while shared global representations support disease classification and clinically grounded text output allowing the model to transition from pixels to structures and finally clinical reasoning within one architecture. Unlike prior task-specific pipelines, PULSE learns task-invariant cardiac priors, generalizes robustly across datasets, and can be adapted to new imaging modalities with minimal supervision. This moves the field closer to a scalable, foundation style cardiac analysis framework.", "AI": {"tldr": "The paper presents PULSE, a unified multi-task framework combining anatomical segmentation, disease classification, and clinical report generation for cardiac image analysis.", "motivation": "Existing cardiac image analysis methods are fragmented, lacking a unified architecture that can generalize across tasks, imaging modalities, and datasets.", "method": "PULSE employs self-supervised learning, composite supervision strategies, and a multi-scale token reconstruction decoder to integrate segmentation, classification, and text generation tasks into one framework.", "result": "PULSE achieves task-invariant cardiac priors, generalizes effectively across datasets, and adapts to new imaging modalities with minimal supervision.", "conclusion": "PULSE represents a step towards a scalable and generalizable foundation framework for cardiac analysis, unifying multiple diagnostic tasks within a single architecture."}}
{"id": "2512.03882", "pdf": "https://arxiv.org/pdf/2512.03882", "abs": "https://arxiv.org/abs/2512.03882", "authors": ["Haidong Kang", "Wei Wu", "Hanling Wang"], "title": "Automatic Attack Discovery for Few-Shot Class-Incremental Learning via Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Few-shot class incremental learning (FSCIL) is a more realistic and challenging paradigm in continual learning to incrementally learn unseen classes and overcome catastrophic forgetting on base classes with only a few training examples. Previous efforts have primarily centered around studying more effective FSCIL approaches. By contrast, less attention was devoted to thinking the security issues in contributing to FSCIL. This paper aims to provide a holistic study of the impact of attacks on FSCIL. We first derive insights by systematically exploring how human expert-designed attack methods (i.e., PGD, FGSM) affect FSCIL. We find that those methods either fail to attack base classes, or suffer from huge labor costs due to relying on huge expert knowledge. This highlights the need to craft a specialized attack method for FSCIL. Grounded in these insights, in this paper, we propose a simple yet effective ACraft method to automatically steer and discover optimal attack methods targeted at FSCIL by leveraging Large Language Models (LLMs) without human experts. Moreover, to improve the reasoning between LLMs and FSCIL, we introduce a novel Proximal Policy Optimization (PPO) based reinforcement learning to optimize learning, making LLMs generate better attack methods in the next generation by establishing positive feedback. Experiments on mainstream benchmarks show that our ACraft significantly degrades the performance of state-of-the-art FSCIL methods and dramatically beyond human expert-designed attack methods while maintaining the lowest costs of attack.", "AI": {"tldr": "The paper explores the vulnerability of Few-shot Class Incremental Learning (FSCIL) to attacks and proposes a novel method, ACraft, to improve attack efficacy using LLMs and reinforcement learning.", "motivation": "To address the lack of exploration into the security vulnerabilities of FSCIL and the inefficiency of traditional manually-designed attack methods.", "method": "The paper introduces the ACraft method which utilizes Large Language Models (LLMs) and Proximal Policy Optimization (PPO)-based reinforcement learning to generate optimized attack strategies for FSCIL automatically.", "result": "Experiments demonstrated that ACraft significantly undermines the effectiveness of existing FSCIL methods, outperforms human-designed attacks, and achieves this at a lower cost.", "conclusion": "ACraft highlights the need to consider FSCIL security, showcasing an effective automated attack approach, and encourages integrating security awareness into future FSCIL development."}}
{"id": "2512.03852", "pdf": "https://arxiv.org/pdf/2512.03852", "abs": "https://arxiv.org/abs/2512.03852", "authors": ["Liwen Pan", "Longguang Wang", "Guangwei Gao", "Jun Wang", "Jun Shi", "Juncheng Li"], "title": "Traffic Image Restoration under Adverse Weather via Frequency-Aware Mamba", "categories": ["cs.CV"], "comment": "12pages, 13 figures, 5tables", "summary": "Traffic image restoration under adverse weather conditions remains a critical challenge for intelligent transportation systems. Existing methods primarily focus on spatial-domain modeling but neglect frequency-domain priors. Although the emerging Mamba architecture excels at long-range dependency modeling through patch-wise correlation analysis, its potential for frequency-domain feature extraction remains unexplored. To address this, we propose Frequency-Aware Mamba (FAMamba), a novel framework that integrates frequency guidance with sequence modeling for efficient image restoration. Our architecture consists of two key components: (1) a Dual-Branch Feature Extraction Block (DFEB) that enhances local-global interaction via bidirectional 2D frequency-adaptive scanning, dynamically adjusting traversal paths based on sub-band texture distributions; and (2) a Prior-Guided Block (PGB) that refines texture details through wavelet-based high-frequency residual learning, enabling high-quality image reconstruction with precise details. Meanwhile, we design a novel Adaptive Frequency Scanning Mechanism (AFSM) for the Mamba architecture, which enables the Mamba to achieve frequency-domain scanning across distinct subgraphs, thereby fully leveraging the texture distribution characteristics inherent in subgraph structures. Extensive experiments demonstrate the efficiency and effectiveness of FAMamba.", "AI": {"tldr": "The paper introduces FAMamba, a traffic image restoration method combining frequency guidance and sequence modeling for improved performance under harsh weather.", "motivation": "Address the gap in traffic image restoration where existing methods focus on spatial modeling but ignore frequency-domain priors.", "method": "Proposes FAMamba with key components like a Dual-Branch Feature Extraction Block and a Prior-Guided Block, along with an Adaptive Frequency Scanning Mechanism.", "result": "Extensive experiments validate that FAMamba efficiently and effectively restores high-quality traffic images under adverse weather conditions.", "conclusion": "FAMamba enhances local-global interactions and detailed texture refinement using frequency-aware methods, outperforming current models in restoring traffic images."}}
{"id": "2512.03854", "pdf": "https://arxiv.org/pdf/2512.03854", "abs": "https://arxiv.org/abs/2512.03854", "authors": ["Peshawa J. Muhammad Ali", "Navin Vincent", "Saman S. Abdulla", "Han N. Mohammed Fadhl", "Anders Blilie", "Kelvin Szolnoky", "Julia Anna Mielcarz", "Xiaoyi Ji", "Kimmo Kartasalo", "Abdulbasit K. Al-Talabani", "Nita Mulliqi"], "title": "Prostate biopsy whole slide image dataset from an underrepresented Middle Eastern population", "categories": ["cs.CV"], "comment": "13 pages, 2 figures and 1 table", "summary": "Artificial intelligence (AI) is increasingly used in digital pathology. Publicly available histopathology datasets remain scarce, and those that do exist predominantly represent Western populations. Consequently, the generalizability of AI models to populations from less digitized regions, such as the Middle East, is largely unknown. This motivates the public release of our dataset to support the development and validation of pathology AI models across globally diverse populations. We present 339 whole-slide images of prostate core needle biopsies from a consecutive series of 185 patients collected in Erbil, Iraq. The slides are associated with Gleason scores and International Society of Urological Pathology grades assigned independently by three pathologists. Scanning was performed using two high-throughput scanners (Leica and Hamamatsu) and one compact scanner (Grundium). All slides were de-identified and are provided in their native formats without further conversion. The dataset enables grading concordance analyses, color normalization, and cross-scanner robustness evaluations. Data will be deposited in the Bioimage Archive (BIA) under accession code: to be announced (TBA), and released under a CC BY 4.0 license.", "AI": {"tldr": "The paper introduces a publicly available histopathology dataset of prostate biopsies from Erbil, Iraq, aiding AI applications in pathology for diverse populations.", "motivation": "To address the lack of publicly available histopathology datasets from non-Western populations for robust AI model validation and generalization.", "method": "Collecting and digitizing 339 prostate biopsy slides from Erbil, Iraq using multiple scanners, assigning pathology grades independently by three experts, and de-identifying slides for public release.", "result": "The dataset provides material for analyses like grading concordance, color normalization, and assessing cross-scanner robustness.", "conclusion": "The public availability of this diverse dataset supports pathology AI advancements and enhances its global applicability."}}
{"id": "2512.03923", "pdf": "https://arxiv.org/pdf/2512.03923", "abs": "https://arxiv.org/abs/2512.03923", "authors": ["Xiang Rao", "Yina Liu", "Yuxuan Shen"], "title": "Quantum-Classical Physics-Informed Neural Networks for Solving Reservoir Seepage Equations", "categories": ["cs.LG", "math.NA", "physics.comp-ph"], "comment": null, "summary": "Solving partial differential equations (PDEs) for reservoir seepage is critical for optimizing oil and gas field development and predicting production performance. Traditional numerical methods suffer from mesh-dependent errors and high computational costs, while classical Physics-Informed Neural Networks (PINNs) face bottlenecks in parameter efficiency, high-dimensional expression, and strong nonlinear fitting. To address these limitations, we propose a Discrete Variable (DV)-Circuit Quantum-Classical Physics-Informed Neural Network (QCPINN) and apply it to three typical reservoir seepage models for the first time: the pressure diffusion equation for heterogeneous single-phase flow, the nonlinear Buckley-Leverett (BL) equation for two-phase waterflooding, and the convection-diffusion equation for compositional flow considering adsorption. The QCPINN integrates classical preprocessing/postprocessing networks with a DV quantum core, leveraging quantum superposition and entanglement to enhance high-dimensional feature mapping while embedding physical constraints to ensure solution consistency. We test three quantum circuit topologies (Cascade, Cross-mesh, Alternate) and demonstrate through numerical experiments that QCPINNs achieve high prediction accuracy with fewer parameters than classical PINNs. Specifically, the Alternate topology outperforms others in heterogeneous single-phase flow and two-phase BL equation simulations, while the Cascade topology excels in compositional flow with convection-dispersion-adsorption coupling. Our work verifies the feasibility of QCPINN for reservoir engineering applications, bridging the gap between quantum computing research and industrial practice in oil and gas engineering.", "AI": {"tldr": "The paper introduces a novel Discrete Variable (DV)-Circuit Quantum-Classical Physics-Informed Neural Network (QCPINN) for solving reservoir seepage equations, combining quantum computing with classical PINN methods to increase accuracy and reduce computational resource demand.", "motivation": "The motivation lies in addressing the limitations of traditional numerical methods and classical PINNs, which face issues like computational inefficiency, parameter inefficiency, and challenges in high-dimensional nonlinear PDEs.", "method": "The proposed QCPINN integrates classical neural networks for pre/post-processing with a quantum circuit core that enhances feature mapping via quantum superposition and entanglement while embedding physical constraints. It utilizes three quantum circuit topologies for experimentation.", "result": "Numerical experiments show that QCPINNs achieve high prediction accuracy with fewer parameters compared to classical PINNs. Specific circuit topologies perform better for different seepage models, demonstrating flexibility and efficiency.", "conclusion": "The QCPINN bridges quantum computing and industrial practice in reservoir engineering, offering a feasible solution for high-accuracy and low-cost prediction in oil and gas applications."}}
{"id": "2512.03862", "pdf": "https://arxiv.org/pdf/2512.03862", "abs": "https://arxiv.org/abs/2512.03862", "authors": ["Oli Bridge", "Huey Sun", "Botond Branyicskai-Nagy", "Charles D'Ornano", "Shomit Basu"], "title": "Diminishing Returns in Self-Supervised Learning", "categories": ["cs.CV"], "comment": null, "summary": "While transformer-based architectures have taken computer vision and NLP by storm, they often require a vast amount of parameters and training data to attain strong performance. In this work, we experiment with three distinct pre-training, intermediate fine-tuning, and downstream datasets and training objectives to explore their marginal benefits on a small 5M-parameter vision transformer. We find that while pre-training and fine-tuning always help our model but have diminishing returns, intermediate fine-tuning can actually show harmful impact on downstream performance, potentially due to dissimilarity in task mechanics. Taken together, our results suggest that small-scale ViTs benefit most from targeted pre-training and careful data selection, while indiscriminate stacking of intermediate tasks can waste compute and even degrade performance.", "AI": {"tldr": "This paper investigates how pre-training, intermediate fine-tuning, and downstream datasets affect a small 5M-parameter vision transformer.", "motivation": "Transformer-based models are powerful but require significant parameters and data to perform well. There is a need to study the marginal effects of pre-training and fine-tuning on smaller-scale vision transformers.", "method": "The authors experiment with three distinct datasets and training objectives. They evaluate pre-training, intermediate fine-tuning, and downstream performance on a 5M-parameter vision transformer.", "result": "Pre-training and fine-tuning consistently help improve the model but with diminishing returns. Intermediate fine-tuning can degrade downstream performance, likely due to task incompatibility.", "conclusion": "Small-scale vision transformers benefit most from selective pre-training and careful dataset curation. Intermediate fine-tuning on mismatched tasks can harm performance and waste resources."}}
{"id": "2512.03928", "pdf": "https://arxiv.org/pdf/2512.03928", "abs": "https://arxiv.org/abs/2512.03928", "authors": ["Michele Alessi", "Alessio Ansuini", "Alex Rodriguez"], "title": "Density-Informed VAE (DiVAE): Reliable Log-Prior Probability via Density Alignment Regularization", "categories": ["cs.LG"], "comment": "PriGM Workshop EurIPS 2025", "summary": "We introduce Density-Informed VAE (DiVAE), a lightweight, data-driven regularizer that aligns the VAE log-prior probability $\\log p_Z(z)$ with a log-density estimated from data. Standard VAEs match latents to a simple prior, overlooking density structure in the data-space. DiVAE encourages the encoder to allocate posterior mass in proportion to data-space density and, when the prior is learnable, nudges the prior toward high-density regions. This is realized by adding a robust, precision-weighted penalty to the ELBO, incurring negligible computational overhead. On synthetic datasets, DiVAE (i) improves distributional alignment of latent log-densities to its ground truth counterpart, (ii) improves prior coverage, and (iii) yields better OOD uncertainty calibration. On MNIST, DiVAE improves alignment of the prior with external estimates of the density, providing better interpretability, and improves OOD detection for learnable priors.", "AI": {"tldr": "DiVAE is a lightweight regularizer for VAEs that aligns latent log-prior probability with data density, improving interpretability and out-of-distribution detection.", "motivation": "To address the limitation of standard VAEs that ignore data-space density structure, aiming for better prior alignment and uncertainty calibration.", "method": "Introduces a density-informed penalty to the ELBO, which aligns the VAE's posterior and prior with data-space density, with minimal computational cost.", "result": "DiVAE enhances distribution alignment, prior coverage, OOD detection, and interpretability on synthetic datasets and MNIST.", "conclusion": "DiVAE offers a simple yet effective approach to improve VAEs by incorporating data density information, enhancing both performance and practicality."}}
{"id": "2512.03869", "pdf": "https://arxiv.org/pdf/2512.03869", "abs": "https://arxiv.org/abs/2512.03869", "authors": ["Daniele Falcetta", "Liane S. Canas", "Lorenzo Suppa", "Matteo Pentassuglia", "Jon Cleary", "Marc Modat", "S\u00e9bastien Ourselin", "Maria A. Zuluaga"], "title": "An Automated Framework for Large-Scale Graph-Based Cerebrovascular Analysis", "categories": ["cs.CV", "cs.CY"], "comment": "Submitted to ISBI 2026. 6 pages, 6 figures", "summary": "We present CaravelMetrics, a computational framework for automated cerebrovascular analysis that models vessel morphology through skeletonization-derived graph representations. The framework integrates atlas-based regional parcellation, centerline extraction, and graph construction to compute fifteen morphometric, topological, fractal, and geometric features. The features can be estimated globally from the complete vascular network or regionally within arterial territories, enabling multiscale characterization of cerebrovascular organization. Applied to 570 3D TOF-MRA scans from the IXI dataset (ages 20-86), CaravelMetrics yields reproducible vessel graphs capturing age- and sex-related variations and education-associated increases in vascular complexity, consistent with findings reported in the literature. The framework provides a scalable and fully automated approach for quantitative cerebrovascular feature extraction, supporting normative modeling and population-level studies of vascular health and aging.", "AI": {"tldr": "CaravelMetrics is a computational framework for analyzing cerebrovascular features using 3D imaging data.", "motivation": "To enable automated and detailed analysis of cerebrovascular morphology, including regional and global variations, for population-level studies.", "method": "The framework employs skeletonization-derived graph representations, regional parcellation, centerline extraction, and calculates fifteen cerebrovascular features.", "result": "CaravelMetrics was applied to 570 3D TOF-MRA scans, yielding reproducible vessel graphs that identified variations related to age, sex, and education.", "conclusion": "CaravelMetrics is an effective tool for scalable and automated analysis of cerebrovascular features, supporting studies on vascular health and aging."}}
{"id": "2512.03967", "pdf": "https://arxiv.org/pdf/2512.03967", "abs": "https://arxiv.org/abs/2512.03967", "authors": ["Keith Ando Ogawa", "Bruno Lopes Yamamoto", "Lucas Lauton de Alcantara", "Victor Zacarias", "Edson Bollis", "Lucas Pellicer", "Rosimeire Pereira Costa", "Anna Helena Reali Costa", "Artur Jordao"], "title": "Technical Report on Text Dataset Distillation", "categories": ["cs.LG"], "comment": null, "summary": "In the vision domain, dataset distillation arises as a technique to condense a large dataset into a smaller synthetic one that exhibits a similar result in the training process. While image data presents an extensive literature of distillation methods, text dataset distillation has fewer works in comparison. Text dataset distillation initially grew as an adaptation of efforts from the vision universe, as the particularities of the modality became clear obstacles, it rose into a separate branch of research. Several milestones mark the development of this area, such as the introduction of methods that use transformer models, the generation of discrete synthetic text, and the scaling to decoder-only models with over 1B parameters. Despite major advances in modern approaches, the field remains in a maturing phase, with room for improvement on benchmarking standardization, approaches to overcome the discrete nature of text, handling complex tasks, and providing explicit examples of real-world applications. In this report, we review past and recent advances in dataset distillation for text, highlighting different distillation strategies, key contributions, and general challenges.", "AI": {"tldr": "This paper reviews the advancements in text dataset distillation, highlighting milestones, key contributions, challenges, and outlining future opportunities.", "motivation": "Explores the motivation to condense large text datasets into smaller synthetic ones for improved efficiency in training while preserving performance, since text dataset distillation is less explored than in the vision domain.", "method": "Conducts a review of past and recent advances, covering various distillation strategies, milestones, and paradigms for dataset distillation in text tasks.", "result": "Examines important elements like transformer-based approaches, discrete synthetic text generation, and scaling techniques while identifying gaps in benchmarking and application areas for text dataset distillation.", "conclusion": "Text dataset distillation is still in its maturing phase, with significant potential for improvement in benchmarking, solving the discrete nature of text, handling complex tasks, and demonstrating real-world applications."}}
{"id": "2512.03883", "pdf": "https://arxiv.org/pdf/2512.03883", "abs": "https://arxiv.org/abs/2512.03883", "authors": ["Jorge Tapias Gomez", "Despoina Kanata", "Aneesh Rangnekar", "Christina Lee", "Julio Garcia-Aguilar", "Joshua Jesse Smith", "Harini Veeraraghavan"], "title": "Dual Cross-Attention Siamese Transformer for Rectal Tumor Regrowth Assessment in Watch-and-Wait Endoscopy", "categories": ["cs.CV"], "comment": "6 pages, 5 figures, 1 table, submitted to ISBI conference", "summary": "Increasing evidence supports watch-and-wait (WW) surveillance for patients with rectal cancer who show clinical complete response (cCR) at restaging following total neoadjuvant treatment (TNT). However, objectively accurate methods to early detect local regrowth (LR) from follow-up endoscopy images during WW are essential to manage care and prevent distant metastases. Hence, we developed a Siamese Swin Transformer with Dual Cross-Attention (SSDCA) to combine longitudinal endoscopic images at restaging and follow-up and distinguish cCR from LR. SSDCA leverages pretrained Swin transformers to extract domain agnostic features and enhance robustness to imaging variations. Dual cross attention is implemented to emphasize features from the two scans without requiring any spatial alignment of images to predict response. SSDCA as well as Swin-based baselines were trained using image pairs from 135 patients and evaluated on a held-out set of image pairs from 62 patients. SSDCA produced the best balanced accuracy (81.76\\% $\\pm$ 0.04), sensitivity (90.07\\% $\\pm$ 0.08), and specificity (72.86\\% $\\pm$ 0.05). Robustness analysis showed stable performance irrespective of artifacts including blood, stool, telangiectasia, and poor image quality. UMAP clustering of extracted features showed maximal inter-cluster separation (1.45 $\\pm$ 0.18) and minimal intra-cluster dispersion (1.07 $\\pm$ 0.19) with SSDCA, confirming discriminative representation learning.", "AI": {"tldr": "The paper introduces SSDCA, a Siamese Swin Transformer model, to enhance early detection of local regrowth in watch-and-wait rectal cancer patients through longitudinal endoscopic image analysis.", "motivation": "To improve detection of local regrowth (LR) in rectal cancer patients during watch-and-wait surveillance using accurate and robust endoscopic image analysis methods.", "method": "They developed the Siamese Swin Transformer with Dual Cross-Attention (SSDCA) that extracts features using Swin transformers and uses dual cross-attention to analyse longitudinal endoscopic images without spatial alignment.", "result": "SSDCA achieved balanced accuracy of 81.76%, sensitivity of 90.07%, and specificity of 72.86%, showing robustness across imaging artifacts and strong feature separation and clustering performance.", "conclusion": "SSDCA is a promising tool for distinguishing clinical complete response from local regrowth in rectal cancer patients, enhancing surveillance during the watch-and-wait approach."}}
{"id": "2512.03973", "pdf": "https://arxiv.org/pdf/2512.03973", "abs": "https://arxiv.org/abs/2512.03973", "authors": ["Franki Nguimatsia Tiofack", "Th\u00e9otime Le Hellard", "Fabian Schramm", "Nicolas Perrin-Gilbert", "Justin Carpentier"], "title": "Guided Flow Policy: Learning from High-Value Actions in Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Offline reinforcement learning often relies on behavior regularization that enforces policies to remain close to the dataset distribution. However, such approaches fail to distinguish between high-value and low-value actions in their regularization components. We introduce Guided Flow Policy (GFP), which couples a multi-step flow-matching policy with a distilled one-step actor. The actor directs the flow policy through weighted behavior cloning to focus on cloning high-value actions from the dataset rather than indiscriminately imitating all state-action pairs. In turn, the flow policy constrains the actor to remain aligned with the dataset's best transitions while maximizing the critic. This mutual guidance enables GFP to achieve state-of-the-art performance across 144 state and pixel-based tasks from the OGBench, Minari, and D4RL benchmarks, with substantial gains on suboptimal datasets and challenging tasks. Webpage: https://simple-robotics.github.io/publications/guided-flow-policy/", "AI": {"tldr": "The paper presents a Guided Flow Policy (GFP) for offline reinforcement learning that improves state-of-the-art performance by focusing on high-value actions using weighted behavior cloning and flow-matching policy.", "motivation": "The motivation is to address the limitations of traditional behavior regularization in offline reinforcement learning, which fails to differentiate between high-value and low-value actions.", "method": "The method introduces a Guided Flow Policy (GFP) combining a multi-step flow-matching policy and a distilled one-step actor to prioritize high-value actions, aligning the actor with the best dataset transitions while maximizing the critic.", "result": "GFP achieves state-of-the-art results on 144 tasks across various benchmarks, showing significant improvements on suboptimal datasets and challenging scenarios.", "conclusion": "The mutual guidance mechanism in GFP effectively enhances offline reinforcement learning by focusing on high-value actions, demonstrating performance gains over existing methods."}}
{"id": "2512.03905", "pdf": "https://arxiv.org/pdf/2512.03905", "abs": "https://arxiv.org/abs/2512.03905", "authors": ["Shuai Yang", "Junxin Lin", "Yifan Zhou", "Ziwei Liu", "Chen Change Loy"], "title": "Zero-Shot Video Translation and Editing with Frame Spatial-Temporal Correspondence", "categories": ["cs.CV"], "comment": "Code: https://github.com/Sunnycookies/FRESCO-v2, Project: https://williamyang1991.github.io/projects/FRESCOv2/", "summary": "The remarkable success in text-to-image diffusion models has motivated extensive investigation of their potential for video applications. Zero-shot techniques aim to adapt image diffusion models for videos without requiring further model training. Recent methods largely emphasize integrating inter-frame correspondence into attention mechanisms. However, the soft constraint applied to identify the valid features to attend is insufficient, which could lead to temporal inconsistency. In this paper, we present FRESCO, which integrates intra-frame correspondence with inter-frame correspondence to formulate a more robust spatial-temporal constraint. This enhancement ensures a consistent transformation of semantically similar content between frames. Our method goes beyond attention guidance to explicitly optimize features, achieving high spatial-temporal consistency with the input video, significantly enhancing the visual coherence of manipulated videos. We verify FRESCO adaptations on two zero-shot tasks of video-to-video translation and text-guided video editing. Comprehensive experiments demonstrate the effectiveness of our framework in generating high-quality, coherent videos, highlighting a significant advance over current zero-shot methods.", "AI": {"tldr": "The paper introduces FRESCO, a method to enhance spatial-temporal consistency in video manipulation for zero-shot video applications.", "motivation": "To address temporal inconsistency in zero-shot video adaptation by improving spatial-temporal constraints in image diffusion models.", "method": "FRESCO integrates intra-frame and inter-frame correspondence for robust spatial-temporal constraints and explicitly optimizes features for consistency and quality.", "result": "FRESCO achieves high spatial and temporal consistency in video edits and translations, outperforming other zero-shot methods in experiments.", "conclusion": "FRESCO significantly advances zero-shot video-to-video translation and text-guided video editing by generating coherent, high-quality videos."}}
{"id": "2512.03994", "pdf": "https://arxiv.org/pdf/2512.03994", "abs": "https://arxiv.org/abs/2512.03994", "authors": ["Oren Rachmil", "Roy Betser", "Itay Gershon", "Omer Hofman", "Nitay Yakoby", "Yuval Meron", "Idan Yankelev", "Asaf Shabtai", "Yuval Elovici", "Roman Vainshtein"], "title": "Training-Free Policy Violation Detection via Activation-Space Whitening in LLMs", "categories": ["cs.LG"], "comment": "Accepted to the AAAI 2026 Deployable AI (DAI) Workshop", "summary": "Aligning proprietary large language models (LLMs) with internal organizational policies has become an urgent priority as organizations increasingly deploy LLMs in sensitive domains such as legal support, finance, and medical services. Beyond generic safety filters, enterprises require reliable mechanisms to detect policy violations within their regulatory and operational frameworks, where breaches can trigger legal and reputational risks. Existing content moderation frameworks, such as guardrails, remain largely confined to the safety domain and lack the robustness to capture nuanced organizational policies. LLM-as-a-judge and fine-tuning approaches, though flexible, introduce significant latency and lack interpretability. To address these limitations, we propose a training-free and efficient method that treats policy violation detection as an out-of-distribution (OOD) detection problem. Inspired by whitening techniques, we apply a linear transformation to decorrelate the model's hidden activations and standardize them to zero mean and unit variance, yielding near-identity covariance matrix. In this transformed space, we use the Euclidean norm as a compliance score to detect policy violations. The method requires only the policy text and a small number of illustrative samples, which makes it light-weight and easily deployable. On a challenging policy benchmark, our approach achieves state-of-the-art results, surpassing both existing guardrails and fine-tuned reasoning models. This work provides organizations with a practical and statistically grounded framework for policy-aware oversight of LLMs, advancing the broader goal of deployable AI governance. Code is available at: https://tinyurl.com/policy-violation-detection", "AI": {"tldr": "The paper introduces a training-free method to detect policy violations in large language models (LLMs) using out-of-distribution detection principles, achieving better results compared to existing techniques.", "motivation": "Large language models are increasingly used in sensitive domains, requiring alignment with specific organizational policies to mitigate legal and reputational risks. Existing methods for policy violation detection are either inefficient or lack interpretability.", "method": "The authors propose a novel approach that treats policy violation detection as an out-of-distribution detection problem. They apply a linear whitening transformation to model activations, standardizing them for compliance scoring using the Euclidean norm. The approach works with minimal data and no additional training.", "result": "The proposed method outperforms existing frameworks, including guardrails and fine-tuned models, on policy violation detection benchmarks.", "conclusion": "This lightweight and efficient technique provides a statistically sound framework for oversight in organizational deployments of LLMs, contributing towards practical AI governance solutions."}}
{"id": "2512.03918", "pdf": "https://arxiv.org/pdf/2512.03918", "abs": "https://arxiv.org/abs/2512.03918", "authors": ["Youxin Pang", "Yong Zhang", "Ruizhi Shao", "Xiang Deng", "Feng Gao", "Xu Xiaoming", "Xiaoming Wei", "Yebin Liu"], "title": "UniMo: Unifying 2D Video and 3D Human Motion with an Autoregressive Framework", "categories": ["cs.CV"], "comment": "https://carlyx.github.io/UniMo/", "summary": "We propose UniMo, an innovative autoregressive model for joint modeling of 2D human videos and 3D human motions within a unified framework, enabling simultaneous generation and understanding of these two modalities for the first time. Current methods predominantly focus on generating one modality given another as the condition or integrating either of them with other modalities such as text and audio. Unifying 2D videos and 3D motions for simultaneous optimization and generation remains largely unexplored, presenting significant challenges due to their substantial structural and distributional differences. Inspired by the LLM's ability to unify different modalities, our method models videos and 3D motions as a unified tokens sequence, utilizing separate embedding layers to mitigate distribution gaps. Additionally, we devise a sequence modeling strategy that integrates two distinct tasks within a single framework, proving the effectiveness of unified modeling. Moreover, to efficiently align with visual tokens and preserve 3D spatial information, we design a novel 3D motion tokenizer with a temporal expansion strategy, using a single VQ-VAE to produce quantized motion tokens. It features multiple expert decoders that handle body shapes, translation, global orientation, and body poses for reliable 3D motion reconstruction. Extensive experiments demonstrate that our method simultaneously generates corresponding videos and motions while performing accurate motion capture. This work taps into the capacity of LLMs to fuse diverse data types, paving the way for integrating human-centric information into existing models and potentially enabling multimodal, controllable joint modeling of humans, objects, and scenes.", "AI": {"tldr": "UniMo is a novel autoregressive model unifying the modeling of 2D human videos and 3D motions, enabling simultaneous generation and understanding of these modalities.", "motivation": "The paper addresses the gap in simultaneous optimization and generation of 2D videos and 3D human motions, which are structurally and distributively different, as current methods are limited to generating or integrating modalities separately.", "method": "UniMo uses a unified token sequence to model the modalities with separate embedding layers to address distribution gaps. A novel sequence modeling strategy integrates tasks within one framework. It includes a 3D motion tokenizer for efficient alignment with visual tokens, utilizing a VQ-VAE and expert decoders for reconstruction of 3D motions.", "result": "Experiments show that UniMo can simultaneously generate corresponding videos and motions while achieving precise motion capture.", "conclusion": "UniMo demonstrates the capability of leveraging large-scale language model techniques to unify and jointly model different modalities, potentially advancing multimodal and controllable modeling of humans and their interactions with the environment."}}
{"id": "2512.04004", "pdf": "https://arxiv.org/pdf/2512.04004", "abs": "https://arxiv.org/abs/2512.04004", "authors": ["Yanlin Chen", "Kehua Chen", "Yinhai Wang"], "title": "Physics-Embedded Gaussian Process for Traffic State Estimation", "categories": ["cs.LG"], "comment": null, "summary": "Traffic state estimation (TSE) becomes challenging when probe-vehicle penetration is low and observations are spatially sparse. Pure data-driven methods lack physical explanations and have poor generalization when observed data is sparse. In contrast, physical models have difficulty integrating uncertainties and capturing the real complexity of traffic. To bridge this gap, recent studies have explored combining them by embedding physical structure into Gaussian process. These approaches typically introduce the governing equations as soft constraints through pseudo-observations, enabling the integration of model structure within a variational framework. However, these methods rely heavily on penalty tuning and lack principled uncertainty calibration, which makes them sensitive to model mis-specification. In this work, we address these limitations by presenting a novel Physics-Embedded Gaussian Process (PEGP), designed to integrate domain knowledge with data-driven methods in traffic state estimation. Specifically, we design two multi-output kernels informed by classic traffic flow models, constructed via the explicit application of the linearized differential operator. Experiments on HighD, NGSIM show consistent improvements over non-physics baselines. PEGP-ARZ proves more reliable under sparse observation, while PEGP-LWR achieves lower errors with denser observation. Ablation study further reveals that PEGP-ARZ residuals align closely with physics and yield calibrated, interpretable uncertainty, whereas PEGP-LWR residuals are more orthogonal and produce nearly constant variance fields. This PEGP framework combines physical priors, uncertainty quantification, which can provide reliable support for TSE.", "AI": {"tldr": "The paper proposes a Physics-Embedded Gaussian Process (PEGP) to improve traffic state estimation (TSE) using hybrid physical and data-driven methods.", "motivation": "To address challenges in TSE caused by low penetration of probe data and spatial sparsity, overcoming the shortcomings of purely data-driven or purely physical models.", "method": "Introduced PEGP, a framework embedding physical traffic flow models into Gaussian Process kernels, with tailored multi-output kernel designs for traffic dynamics.", "result": "Experiments on HighD and NGSIM datasets show PEGP-ARZ adapting well under sparse observations and PEGP-LWR reducing errors when data is denser.", "conclusion": "PEGP framework successfully integrates physics and data-driven modeling, offering reliable and interpretable TSE with calibrated uncertainties."}}
{"id": "2512.03563", "pdf": "https://arxiv.org/pdf/2512.03563", "abs": "https://arxiv.org/abs/2512.03563", "authors": ["Chengyu Tang", "Sanjeev Baskiyar"], "title": "State Space Models for Bioacoustics: A comparative Evaluation with Transformers", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "In this study, we evaluate the efficacy of the Mamba model in the field of bioacoustics. We first pretrain a Mamba-based audio large language model (LLM) on a large corpus of audio data using self-supervised learning. We fine-tune and evaluate BioMamba on the BEANS benchmark, a collection of diverse bioacoustic tasks including classification and detection, and compare its performance and efficiency with multiple baseline models, including AVES, a state-of-the-art Transformer-based model. The results show that BioMamba achieves comparable performance with AVES while consumption significantly less VRAM, demonstrating its potential in this domain.", "AI": {"tldr": "The study assesses the Mamba audio model for bioacoustics by pretraining it with audio data and fine-tuning on the BEANS benchmark. BioMamba performs comparably to AVES while using less VRAM.", "motivation": "To improve the efficiency and performance of bioacoustic models by utilizing the Mamba-based audio LLM.", "method": "Mamba-based model was pretrained on audio corpus using self-supervised learning and fine-tuned on bioacoustic tasks (classification, detection) using BEANS benchmark.", "result": "BioMamba showed similar performance to AVES, the state-of-the-art model, while consuming less VRAM.", "conclusion": "BioMamba is a promising and efficient alternative for bioacoustic analysis, combining competitive performance and reduced resource consumption."}}
{"id": "2512.03932", "pdf": "https://arxiv.org/pdf/2512.03932", "abs": "https://arxiv.org/abs/2512.03932", "authors": ["Donghun Ryou", "Inju Ha", "Sanghyeok Chu", "Bohyung Han"], "title": "Beyond the Ground Truth: Enhanced Supervision for Image Restoration", "categories": ["cs.CV"], "comment": null, "summary": "Deep learning-based image restoration has achieved significant success. However, when addressing real-world degradations, model performance is limited by the quality of ground-truth images in datasets due to practical constraints in data acquisition. To address this limitation, we propose a novel framework that enhances existing ground truth images to provide higher-quality supervision for real-world restoration. Our framework generates perceptually enhanced ground truth images using super-resolution by incorporating adaptive frequency masks, which are learned by a conditional frequency mask generator. These masks guide the optimal fusion of frequency components from the original ground truth and its super-resolved variants, yielding enhanced ground truth images. This frequency-domain mixup preserves the semantic consistency of the original content while selectively enriching perceptual details, preventing hallucinated artifacts that could compromise fidelity. The enhanced ground truth images are used to train a lightweight output refinement network that can be seamlessly integrated with existing restoration models. Extensive experiments demonstrate that our approach consistently improves the quality of restored images. We further validate the effectiveness of both supervision enhancement and output refinement through user studies. Code is available at https://github.com/dhryougit/Beyond-the-Ground-Truth.", "AI": {"tldr": "The paper introduces a framework to enhance ground truth images for better deep learning-based image restoration.", "motivation": "Improve the performance of image restoration models limited by ground-truth quality in datasets.", "method": "Creates perceptually enhanced ground truth using adaptive frequency masks for frequency-domain mixup.", "result": "Enhanced ground truth improves restoration quality and training of refinement networks; validated by user studies.", "conclusion": "The framework effectively enhances image restoration performance by improving training supervision quality."}}
{"id": "2512.03570", "pdf": "https://arxiv.org/pdf/2512.03570", "abs": "https://arxiv.org/abs/2512.03570", "authors": ["Stefano Scanzio", "Gabriele Formis", "Tullio Facchinetti", "Gianluca Cena"], "title": "Machine Learning to Predict Slot Usage in TSCH Wireless Sensor Networks", "categories": ["cs.NI", "cs.AI", "cs.LG"], "comment": "preprint accepted, 8 pages, 2025", "summary": "Wireless sensor networks (WSNs) are employed across a wide range of industrial applications where ultra-low power consumption is a critical prerequisite. At the same time, these systems must maintain a certain level of determinism to ensure reliable and predictable operation. In this view, time slotted channel hopping (TSCH) is a communication technology that meets both conditions, making it an attractive option for its usage in industrial WSNs. This work proposes the use of machine learning to learn the traffic pattern generated in networks based on the TSCH protocol, in order to turn nodes into a deep sleep state when no transmission is planned and thus to improve the energy efficiency of the WSN. The ability of machine learning models to make good predictions at different network levels in a typical tree network topology was analyzed in depth, showing how their capabilities degrade while approaching the root of the tree. The application of these models on simulated data based on an accurate modeling of wireless sensor nodes indicates that the investigated algorithms can be suitably used to further and substantially reduce the power consumption of a TSCH network.", "AI": {"tldr": "The paper integrates machine learning with TSCH protocol in WSNs to enhance energy efficiency by predicting traffic patterns and enabling deep sleep states.", "motivation": "To address critical energy consumption challenges in WSNs while maintaining deterministic operations demanded by industrial applications.", "method": "Machine learning algorithms are employed to predict traffic patterns within TSCH-based networks, enabling nodes to enter deep sleep states during idle periods.", "result": "The study demonstrates machine learning models can predict traffic patterns effectively, though accuracy diminishes near root nodes in a tree topology. Simulation data supports notable energy savings using the proposed approach.", "conclusion": "Machine learning can effectively enhance energy efficiency in TSCH-based industrial WSNs, with substantial reduction in power consumption achievable through accurate traffic predictions."}}
{"id": "2512.04008", "pdf": "https://arxiv.org/pdf/2512.04008", "abs": "https://arxiv.org/abs/2512.04008", "authors": ["Zo\u00eb Ruha Bell", "Anvith Thudi", "Olive Franzese-McLaughlin", "Nicolas Papernot", "Shafi Goldwasser"], "title": "Efficient Public Verification of Private ML via Regularization", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Training with differential privacy (DP) provides a guarantee to members in a dataset that they cannot be identified by users of the released model. However, those data providers, and, in general, the public, lack methods to efficiently verify that models trained on their data satisfy DP guarantees. The amount of compute needed to verify DP guarantees for current algorithms scales with the amount of compute required to train the model. In this paper we design the first DP algorithm with near optimal privacy-utility trade-offs but whose DP guarantees can be verified cheaper than training. We focus on DP stochastic convex optimization (DP-SCO), where optimal privacy-utility trade-offs are known. Here we show we can obtain tight privacy-utility trade-offs by privately minimizing a series of regularized objectives and only using the standard DP composition bound. Crucially, this method can be verified with much less compute than training. This leads to the first known DP-SCO algorithm with near optimal privacy-utility whose DP verification scales better than training cost, significantly reducing verification costs on large datasets.", "AI": {"tldr": "The paper introduces a novel DP algorithm for stochastic convex optimization (SCO) that achieves near-optimal privacy-utility trade-offs and allows efficient verification of DP guarantees, which is computationally cheaper than the training process.", "motivation": "The authors aim to address the gap in verifying differential privacy (DP) guarantees efficiently, as traditional methods require computational resources comparable to the training process itself, which is impractical for large datasets.", "method": "The proposed method involves privately minimizing a series of regularized objectives using the standard DP composition bound. This ensures tight privacy-utility trade-offs while reducing computational cost for DP verification.", "result": "The approach achieves near-optimal privacy-utility trade-offs while enabling DP verification with substantially lower computational requirements than the training process, especially for large datasets.", "conclusion": "The paper presents the first DP stochastic convex optimization algorithm that combines optimal privacy-utility performance with cost-efficient verification, making the process more practical and accessible for large-scale applications."}}
{"id": "2512.03963", "pdf": "https://arxiv.org/pdf/2512.03963", "abs": "https://arxiv.org/abs/2512.03963", "authors": ["Tao Wu", "Li Yang", "Gen Zhan", "Yiting Liao", "Junlin Li", "Deliang Fu", "Li Zhang", "Limin Wang"], "title": "TempR1: Improving Temporal Understanding of MLLMs via Temporal-Aware Multi-Task Reinforcement Learning", "categories": ["cs.CV"], "comment": null, "summary": "Enhancing the temporal understanding of Multimodal Large Language Models (MLLMs) is essential for advancing long-form video analysis, enabling tasks such as temporal localization, action detection, and time-sensitive question answering. While reinforcement learning (RL) has recently been explored for improving temporal reasoning, existing approaches are often confined to limited task types and data, restricting their generalization across diverse temporal understanding scenarios. To address this challenge, we present TempR1, a temporal-aware multi-task reinforcement learning framework that systematically strengthens MLLMs' temporal comprehension. We curate a multi-task corpus that exposes the model to diverse temporal structures and semantics, and build upon the Group Relative Policy Optimization (GRPO) algorithm to achieve stable and effective cross-task optimization. Specifically, we categorize temporal tasks into three correspondence types between predicted intervals and ground-truth instances, and design tailored localization rewards for each, enabling TempR1 to capture fine-grained temporal dependencies and adapt to different temporal patterns. Extensive experiments demonstrate that TempR1 attains state-of-the-art performance across multiple benchmarks. Moreover, its joint optimization over complementary tasks yields a strong synergistic effect, enhancing both generalization and single-task performance, establishing a scalable and principled paradigm for temporal reasoning in MLLMs.", "AI": {"tldr": "TempR1 introduces a temporal-aware multi-task reinforcement learning framework to improve the temporal comprehension of Multimodal Large Language Models (MLLMs), achieving state-of-the-art results in temporal reasoning tasks.", "motivation": "The paper aims to overcome limitations in existing RL-based approaches for temporal reasoning in MLLMs, which often lack generalization due to restricted task types and datasets.", "method": "TempR1 employs a multi-task corpus for diverse temporal exposure and uses the Group Relative Policy Optimization (GRPO) algorithm to achieve stable optimization across tasks. It assigns tailored localization rewards for different temporal correspondence types.", "result": "TempR1 demonstrates state-of-the-art performance across benchmarks, enhances generalization, and improves single-task abilities through its joint optimization approach.", "conclusion": "TempR1 sets a scalable and effective framework for temporal reasoning in MLLMs, providing significant improvements in generalization and multi-task synergies."}}
{"id": "2512.04034", "pdf": "https://arxiv.org/pdf/2512.04034", "abs": "https://arxiv.org/abs/2512.04034", "authors": ["Hong Yang", "Devroop Kar", "Qi Yu", "Alex Ororbia", "Travis Desell"], "title": "Domain Feature Collapse: Implications for Out-of-Distribution Detection and Solutions", "categories": ["cs.LG"], "comment": null, "summary": "Why do state-of-the-art OOD detection methods exhibit catastrophic failure when models are trained on single-domain datasets? We provide the first theoretical explanation for this phenomenon through the lens of information theory. We prove that supervised learning on single-domain data inevitably produces domain feature collapse -- representations where I(x_d; z) = 0, meaning domain-specific information is completely discarded. This is a fundamental consequence of information bottleneck optimization: models trained on single domains (e.g., medical images) learn to rely solely on class-specific features while discarding domain features, leading to catastrophic failure when detecting out-of-domain samples (e.g., achieving only 53% FPR@95 on MNIST). We extend our analysis using Fano's inequality to quantify partial collapse in practical scenarios. To validate our theory, we introduce Domain Bench, a benchmark of single-domain datasets, and demonstrate that preserving I(x_d; z) > 0 through domain filtering (using pretrained representations) resolves the failure mode. While domain filtering itself is conceptually straightforward, its effectiveness provides strong empirical evidence for our information-theoretic framework. Our work explains a puzzling empirical phenomenon, reveals fundamental limitations of supervised learning in narrow domains, and has broader implications for transfer learning and when to fine-tune versus freeze pretrained models.", "AI": {"tldr": "This paper investigates why out-of-distribution (OOD) detection methods fail on single-domain datasets, attributing it to domain feature collapse, where domain-specific information is entirely discarded during supervised learning.", "motivation": "The motivation is to understand the catastrophic failure of OOD detection when models are trained on single-domain datasets, and to provide a theoretical explanation grounded in information theory.", "method": "The authors used information-theoretic analysis, employing concepts like the information bottleneck principle and Fano's inequality, and introduced a benchmark (Domain Bench) to validate their findings. They evaluated domain filtering using pretrained representations as a solution.", "result": "The study shows that domain-specific information is discarded during supervised learning on single-domain data, causing OOD failure. Domain filtering preserves such information and improves OOD detection.", "conclusion": "The paper highlights a fundamental limitation of supervised learning in single domains, proposes a theoretical explanation, and suggests practical implications for improving OOD detection and transfer learning strategies."}}
{"id": "2512.03964", "pdf": "https://arxiv.org/pdf/2512.03964", "abs": "https://arxiv.org/abs/2512.03964", "authors": ["Lianyu Pang", "Ji Zhou", "Qiping Wang", "Baoquan Zhao", "Zhenguo Yang", "Qing Li", "Xudong Mao"], "title": "Training for Identity, Inference for Controllability: A Unified Approach to Tuning-Free Face Personalization", "categories": ["cs.CV"], "comment": "17 pages, 13 figures", "summary": "Tuning-free face personalization methods have developed along two distinct paradigms: text embedding approaches that map facial features into the text embedding space, and adapter-based methods that inject features through auxiliary cross-attention layers. While both paradigms have shown promise, existing methods struggle to simultaneously achieve high identity fidelity and flexible text controllability. We introduce UniID, a unified tuning-free framework that synergistically integrates both paradigms. Our key insight is that when merging these approaches, they should mutually reinforce only identity-relevant information while preserving the original diffusion prior for non-identity attributes. We realize this through a principled training-inference strategy: during training, we employ an identity-focused learning scheme that guides both branches to capture identity features exclusively; at inference, we introduce a normalized rescaling mechanism that recovers the text controllability of the base diffusion model while enabling complementary identity signals to enhance each other. This principled design enables UniID to achieve high-fidelity face personalization with flexible text controllability. Extensive experiments against six state-of-the-art methods demonstrate that UniID achieves superior performance in both identity preservation and text controllability. Code will be available at https://github.com/lyuPang/UniID", "AI": {"tldr": "UniID introduces a unified tuning-free framework for face personalization, integrating text embedding and adapter-based methods to achieve high identity fidelity and flexible text controllability.", "motivation": "Existing tuning-free methods for face personalization struggle to balance high identity fidelity with flexible text controllability.", "method": "UniID synergistically combines text embedding and adapter-based paradigms using an identity-focused training-inference strategy with a normalized rescaling mechanism.", "result": "UniID demonstrates superior performance over six state-of-the-art methods in identity preservation and text controllability.", "conclusion": "UniID offers a robust solution for high-fidelity face personalization, blending identity-focused learning and flexible text control in a unified framework."}}
{"id": "2512.04044", "pdf": "https://arxiv.org/pdf/2512.04044", "abs": "https://arxiv.org/abs/2512.04044", "authors": ["Yizhou Zhao", "Zhiwei Steven Wu", "Adam Block"], "title": "MarkTune: Improving the Quality-Detectability Trade-off in Open-Weight LLM Watermarking", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Watermarking aims to embed hidden signals in generated text that can be reliably detected when given access to a secret key. Open-weight language models pose acute challenges for such watermarking schemes because the inference-time interventions that dominate contemporary approaches cannot be enforced once model weights are public. Existing watermaking techniques for open-weight models, such as the recently proposed GaussMark, typically rely on small modifications to model weights, which can yield signals detectable to those equipped with a secret key, but achieving detection power comparable to inference-time watermarks generally requires weight perturbations that noticeably reduce generation quality. We introduce MarkTune, a theoretically principled, on-policy fine-tuning framework that treats the GaussMark signal as a reward while simultaneously regularizing against degradation in text quality. We derive MarkTune as an improvement on GaussMark and demonstrate that MarkTune consistently improves the quality-detectability trade-off over GaussMark by steering finer-grained, watermark-aware weight updates within the model's representation space while preserving generation quality. Empirically, we show that MarkTune pushes the quality-detectability frontier of GaussMark close to that of inference-time watermarking, remains robust to paraphrasing and fine-tuning attacks, and exhibits strong generalization: a model fine-tuned on one dataset retains substantial watermark detection power on unseen datasets. Together, these results establish MarkTune as a general strategy for embedding robust, high-quality watermarks into open-weight LMs.", "AI": {"tldr": "This paper presents MarkTune, a framework for embedding robust watermarks into open-weight language models by fine-tuning their weights without sacrificing text quality.", "motivation": "Existing watermarking methods for open-weight language models, such as GaussMark, struggle to achieve strong detection accuracy without compromising the text generation quality.", "method": "MarkTune introduces an on-policy fine-tuning approach using GaussMark's signal as a reward while regularizing against quality degradation. This enables more precise watermark-aware updates to the model's weights.", "result": "MarkTune improves the trade-off between watermark detectability and text quality, generalizes well to unseen datasets, and resists attacks like paraphrasing and fine-tuning.", "conclusion": "MarkTune is a robust and effective framework for embedding high-quality watermarks into open-weight language models, performing close to inference-time watermarking methods while maintaining output quality."}}
{"id": "2512.03979", "pdf": "https://arxiv.org/pdf/2512.03979", "abs": "https://arxiv.org/abs/2512.03979", "authors": ["Jin-Ting He", "Fu-Jen Tsai", "Yan-Tsung Peng", "Min-Hung Chen", "Chia-Wen Lin", "Yen-Yu Lin"], "title": "BlurDM: A Blur Diffusion Model for Image Deblurring", "categories": ["cs.CV", "cs.AI"], "comment": "NeurIPS 2025", "summary": "Diffusion models show promise for dynamic scene deblurring; however, existing studies often fail to leverage the intrinsic nature of the blurring process within diffusion models, limiting their full potential. To address it, we present a Blur Diffusion Model (BlurDM), which seamlessly integrates the blur formation process into diffusion for image deblurring. Observing that motion blur stems from continuous exposure, BlurDM implicitly models the blur formation process through a dual-diffusion forward scheme, diffusing both noise and blur onto a sharp image. During the reverse generation process, we derive a dual denoising and deblurring formulation, enabling BlurDM to recover the sharp image by simultaneously denoising and deblurring, given pure Gaussian noise conditioned on the blurred image as input. Additionally, to efficiently integrate BlurDM into deblurring networks, we perform BlurDM in the latent space, forming a flexible prior generation network for deblurring. Extensive experiments demonstrate that BlurDM significantly and consistently enhances existing deblurring methods on four benchmark datasets. The source code is available at https://github.com/Jin-Ting-He/BlurDM.", "AI": {"tldr": "Blur Diffusion Model (BlurDM) proposes incorporating blur formation into image deblurring using a dual-diffusion scheme for more effective results. It demonstrates improvements in performance on benchmarks.", "motivation": "Current diffusion models do not integrate the intrinsic blurring process effectively, limiting their capability in dynamic scene deblurring.", "method": "Introduced Blur Diffusion Model (BlurDM) using dual-diffusion: combining noise and blur formation in latent space during forward and reverse diffusion processes.", "result": "BlurDM substantially improves image deblurring performance across four datasets, demonstrating consistent enhancement in existing methods.", "conclusion": "Integrating blur formation into diffusion models proves beneficial for image deblurring, delivering notable improvements and flexibility in deblurring networks."}}
{"id": "2512.04051", "pdf": "https://arxiv.org/pdf/2512.04051", "abs": "https://arxiv.org/abs/2512.04051", "authors": ["Paul Wilson", "Fabio Zanasi", "George Constantinides"], "title": "Convergence for Discrete Parameter Updates", "categories": ["cs.LG", "math.OC"], "comment": "opt-ml 2025 workshop at NeurIPS", "summary": "Modern deep learning models require immense computational resources, motivating research into low-precision training. Quantised training addresses this by representing training components in low-bit integers, but typically relies on discretising real-valued updates. We introduce an alternative approach where the update rule itself is discrete, avoiding the quantisation of continuous updates by design. We establish convergence guarantees for a general class of such discrete schemes, and present a multinomial update rule as a concrete example, supported by empirical evaluation. This perspective opens new avenues for efficient training, particularly for models with inherently discrete structure.", "AI": {"tldr": "This paper introduces a novel approach to low-precision deep learning training using discrete update rules, avoiding traditional quantization methods.", "motivation": "To address the high computational demands of modern deep learning models, focusing on low-precision and more efficient training approaches.", "method": "The proposed method employs inherently discrete update rules instead of quantizing continuous updates, offering convergence guarantees and demonstrating a multinomial update rule as an example.", "result": "The authors provide both theoretical convergence guarantees and empirical evidence supporting the feasibility and effectiveness of the discrete update approach.", "conclusion": "The study presents a promising alternative for efficient low-precision training, especially beneficial for models with natural discrete structures, paving the way for further exploration in this direction."}}
{"id": "2512.03981", "pdf": "https://arxiv.org/pdf/2512.03981", "abs": "https://arxiv.org/abs/2512.03981", "authors": ["Sheng-Hao Liao", "Shang-Fu Chen", "Tai-Ming Huang", "Wen-Huang Cheng", "Kai-Lung Hua"], "title": "DirectDrag: High-Fidelity, Mask-Free, Prompt-Free Drag-based Image Editing via Readout-Guided Feature Alignment", "categories": ["cs.CV"], "comment": null, "summary": "Drag-based image editing using generative models provides intuitive control over image structures. However, existing methods rely heavily on manually provided masks and textual prompts to preserve semantic fidelity and motion precision. Removing these constraints creates a fundamental trade-off: visual artifacts without masks and poor spatial control without prompts. To address these limitations, we propose DirectDrag, a novel mask- and prompt-free editing framework. DirectDrag enables precise and efficient manipulation with minimal user input while maintaining high image fidelity and accurate point alignment. DirectDrag introduces two key innovations. First, we design an Auto Soft Mask Generation module that intelligently infers editable regions from point displacement, automatically localizing deformation along movement paths while preserving contextual integrity through the generative model's inherent capacity. Second, we develop a Readout-Guided Feature Alignment mechanism that leverages intermediate diffusion activations to maintain structural consistency during point-based edits, substantially improving visual fidelity. Despite operating without manual mask or prompt, DirectDrag achieves superior image quality compared to existing methods while maintaining competitive drag accuracy. Extensive experiments on DragBench and real-world scenarios demonstrate the effectiveness and practicality of DirectDrag for high-quality, interactive image manipulation. Project Page: https://frakw.github.io/DirectDrag/. Code is available at: https://github.com/frakw/DirectDrag.", "AI": {"tldr": "DirectDrag offers mask- and prompt-free image editing using generative models, improving spatial control and visual fidelity through auto soft mask generation and guided feature alignment.", "motivation": "To overcome the limitations in existing drag-based image editing methods that require manually provided masks and textual prompts, which lead to artifacts and reduced spatial control.", "method": "DirectDrag introduces an Auto Soft Mask Generation module for editable regions and a Readout-Guided Feature Alignment mechanism for maintaining structure during edits.", "result": "DirectDrag achieves superior image quality compared to current methods while providing precise spatial control and high interactive usability.", "conclusion": "This method sets a new standard for high-fidelity, mask- and prompt-free image manipulation, proving its effectiveness through experiments and real-world application."}}
{"id": "2512.04062", "pdf": "https://arxiv.org/pdf/2512.04062", "abs": "https://arxiv.org/abs/2512.04062", "authors": ["Florian Bordes", "Candace Ross", "Justine T Kao", "Evangelia Spiliopoulou", "Adina Williams"], "title": "Eval Factsheets: A Structured Framework for Documenting AI Evaluations", "categories": ["cs.LG"], "comment": null, "summary": "The rapid proliferation of benchmarks has created significant challenges in reproducibility, transparency, and informed decision-making. However, unlike datasets and models -- which benefit from structured documentation frameworks like Datasheets and Model Cards -- evaluation methodologies lack systematic documentation standards. We introduce Eval Factsheets, a structured, descriptive framework for documenting AI system evaluations through a comprehensive taxonomy and questionnaire-based approach. Our framework organizes evaluation characteristics across five fundamental dimensions: Context (Who made the evaluation and when?), Scope (What does it evaluate?), Structure (With what the evaluation is built?), Method (How does it work?) and Alignment (In what ways is it reliable/valid/robust?). We implement this taxonomy as a practical questionnaire spanning five sections with mandatory and recommended documentation elements. Through case studies on multiple benchmarks, we demonstrate that Eval Factsheets effectively captures diverse evaluation paradigms -- from traditional benchmarks to LLM-as-judge methodologies -- while maintaining consistency and comparability. We hope Eval Factsheets are incorporated into both existing and newly released evaluation frameworks and lead to more transparency and reproducibility.", "AI": {"tldr": "Eval Factsheets propose a structured documentation framework for AI evaluations, addressing reproducibility, transparency, and decision-making challenges.", "motivation": "The proliferation of benchmarks has raised challenges in reproducibility and transparency, with no established standards for documenting evaluation methodologies.", "method": "A taxonomy-based framework, Eval Factsheets, organizes evaluation documentation across five dimensions: Context, Scope, Structure, Method, and Alignment, operationalized through a questionnaire.", "result": "Eval Factsheets were applied to case studies, demonstrating their ability to capture diverse evaluation paradigms while ensuring consistency and comparability.", "conclusion": "Eval Factsheets aim to enhance transparency, reproducibility, and systematic documentation in AI evaluation frameworks."}}
{"id": "2512.03992", "pdf": "https://arxiv.org/pdf/2512.03992", "abs": "https://arxiv.org/abs/2512.03992", "authors": ["Zexin Lin", "Hawen Wan", "Yebin Zhong", "Xiaoqiang"], "title": "DIQ-H: Evaluating Hallucination Persistence in VLMs Under Temporal Visual Degradation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision-Language Models (VLMs) deployed in safety-critical applications such as autonomous driving must handle continuous visual streams under imperfect conditions. However, existing benchmarks focus on static, high-quality images and ignore temporal degradation and error propagation, which are critical failure modes where transient visual corruption induces hallucinations that persist across subsequent frames. We introduce DIQ-H, the first benchmark for evaluating VLM robustness under dynamic visual degradation in temporal sequences. DIQ-H applies physics-based corruptions including motion blur, sensor noise, and compression artifacts, and measures hallucination persistence, error recovery, and temporal consistency through multi-turn question-answering tasks. To enable scalable annotation, we propose Uncertainty-Guided Iterative Refinement (UIR), which generates reliable pseudo-ground-truth using lightweight VLMs with uncertainty filtering, achieving a 15.3 percent accuracy improvement. Experiments on 16 state-of-the-art VLMs reveal substantial robustness gaps: even advanced models such as GPT-4o achieve only a 78.5 percent recovery rate, while open-source models struggle with temporal consistency at less than 60 percent. DIQ-H provides a comprehensive platform for evaluating VLM reliability in real-world deployments.", "AI": {"tldr": "This paper presents DIQ-H, the first benchmark focused on evaluating Vision-Language Model (VLM) robustness under dynamic visual degradation in temporal sequences.", "motivation": "Existing VLM benchmarks are limited to static, high-quality images, disregarding temporal degradation and error propagation common in real-world conditions, especially for safety-critical applications like autonomous driving.", "method": "The proposed DIQ-H benchmark simulates real-world visual impairments such as motion blur and sensor noise and evaluates VLMs on persistence, recovery, and temporal consistency using a multi-turn question-answering framework. It introduces a scalable Uncertainty-Guided Iterative Refinement (UIR) approach for generating pseudo-ground-truth annotations.", "result": "Experiments across 16 state-of-the-art VLMs show significant robustness limitations, including a 78.5% recovery rate for advanced models and less than 60% temporal consistency for open-source models.", "conclusion": "DIQ-H offers a robust evaluation framework for assessing VLMs' capability in handling real-world challenges, highlighting critical performance gaps under visually degraded sequences."}}
{"id": "2512.04065", "pdf": "https://arxiv.org/pdf/2512.04065", "abs": "https://arxiv.org/abs/2512.04065", "authors": ["Ashlesha Gopinath Sawant", "Sahil S. Jadhav", "Vidhan R. Jain", "Shriraj S. Jagtap", "Prachi Jadhav", "Soham Jadhav", "Ichha Raina"], "title": "Fare Comparison App of Uber, Ola and Rapido", "categories": ["cs.LG", "cs.AI"], "comment": "4 pages", "summary": "In todays increasing world, it is very important to have good hailing services like Ola, Uber, and Rapido as it is very essential for our daily transportation. Users often face difficulties in choosing the most appropriate and efficient ride that would lead to both cost-effective and would take us to our destination in less time. This project provides you with the web application that helps you to select the most beneficial ride for you by providing users with the fare comparison between Ola, Uber, Rapido for the destination entered by the user. The backend is use to fetch the data, providing users with the fare comparison for the ride and finally providing with the best option using Python. This research paper also addresses the problem and challenges faced in accessing the data using APIs, Android Studios emulator, Appium and location comparison. Thus, the aim of the project is to provide transparency to the users in ride-hailing services and increase efficiency and provide users with better experience.", "AI": {"tldr": "This paper introduces a web application for comparing ride fares across Ola, Uber, and Rapido to help users select the most cost-effective and time-efficient ride.", "motivation": "Users face challenges in choosing the most appropriate and efficient ride in terms of cost and time for daily transportation.", "method": "A Python-based backend is used to compare fares by fetching data and handling challenges related to APIs, emulators, Appium, and location comparison.", "result": "A web application is developed that transparently provides ride fare comparisons and suggests the best options among Ola, Uber, and Rapido.", "conclusion": "This project enhances user experience by offering transparency, efficiency, and convenience in ride-hailing services."}}
{"id": "2512.03996", "pdf": "https://arxiv.org/pdf/2512.03996", "abs": "https://arxiv.org/abs/2512.03996", "authors": ["Hang Xu", "Linjiang Huang", "Feng Zhao"], "title": "Highly Efficient Test-Time Scaling for T2I Diffusion Models with Text Embedding Perturbation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Test-time scaling (TTS) aims to achieve better results by increasing random sampling and evaluating samples based on rules and metrics. However, in text-to-image(T2I) diffusion models, most related works focus on search strategies and reward models, yet the impact of the stochastic characteristic of noise in T2I diffusion models on the method's performance remains unexplored. In this work, we analyze the effects of randomness in T2I diffusion models and explore a new format of randomness for TTS: text embedding perturbation, which couples with existing randomness like SDE-injected noise to enhance generative diversity and quality. We start with a frequency-domain analysis of these formats of randomness and their impact on generation, and find that these two randomness exhibit complementary behavior in the frequency domain: spatial noise favors low-frequency components (early steps), while text embedding perturbation enhances high-frequency details (later steps), thereby compensating for the potential limitations of spatial noise randomness in high-frequency manipulation. Concurrently, text embedding demonstrates varying levels of tolerance to perturbation across different dimensions of the generation process. Specifically, our method consists of two key designs: (1) Introducing step-based text embedding perturbation, combining frequency-guided noise schedules with spatial noise perturbation. (2) Adapting the perturbation intensity selectively based on their frequency-specific contributions to generation and tolerance to perturbation. Our approach can be seamlessly integrated into existing TTS methods and demonstrates significant improvements on multiple benchmarks with almost no additional computation. Code is available at \\href{https://github.com/xuhang07/TEP-Diffusion}{https://github.com/xuhang07/TEP-Diffusion}.", "AI": {"tldr": "This paper explores integrating text embedding perturbation with spatial noise for better test-time scaling (TTS) in text-to-image diffusion models, achieving diverse and high-quality results with minimal computation overhead.", "motivation": "Most works on TTS in text-to-image diffusion models focus on search strategies and reward models, neglecting the performance impact of stochastic noise. This research aims to address the gap by investigating a new randomness format: text embedding perturbation.", "method": "The proposed method introduces step-based text embedding perturbation, combining frequency-guided noise schedules with spatial noise perturbation. Additionally, it adapts perturbation intensity selectively based on frequency-specific contributions and tolerance to perturbation.", "result": "The integration of text embedding perturbation enhances generative diversity and quality, especially in high-frequency details. This approach shows significant performance improvements across multiple benchmarks with almost no increase in computational cost.", "conclusion": "By leveraging complementary randomness formats (spatial noise and text embedding perturbation), the proposed TTS approach improves generative performance and quality, offering a practical and efficient addition to existing TTS methods."}}
{"id": "2512.04068", "pdf": "https://arxiv.org/pdf/2512.04068", "abs": "https://arxiv.org/abs/2512.04068", "authors": ["Jonathan Berant", "Maximillian Chen", "Adam Fisch", "Reza Aghajani", "Fantine Huot", "Mirella Lapata", "Jacob Eisenstein"], "title": "Learning Steerable Clarification Policies with Collaborative Self-play", "categories": ["cs.LG"], "comment": null, "summary": "To handle underspecified or ambiguous queries, AI assistants need a policy for managing their uncertainty to determine (a) when to guess the user intent and answer directly, (b) when to enumerate and answer multiple possible intents, and (c) when to ask a clarifying question. However, such policies are contextually dependent on factors such as user preferences or modality. For example, enumerating multiple possible user intentions is cumbersome on small screens or in a voice setting. In this work, we propose to train steerable policies for managing this uncertainty using self-play. Given two agents, one simulating a user and the other an AI assistant, we generate conversations where the user issues a potentially ambiguous query, and the assistant needs to determine how to respond. Importantly, the model takes as input the numerical cost of each clarification question, and each generated word, and is asked to take the action that will maximize its final reward, which is the cost-penalized accuracy. We use Reinforced Self-Training (ReST) to train our model to achieve high reward and show this leads to a steerable policy that changes its behavior predictably conditioned on the provided costs, leading to higher reward and accuracy. Moreover, our procedure also generalizes to numerical cost values that were unobserved at training time.", "AI": {"tldr": "The paper develops steerable policies for AI assistants to manage uncertainty in user queries using self-play, optimizing accuracy while minimizing the cost of actions.", "motivation": "Current AI assistants struggle with underspecified or ambiguous queries, requiring context-sensitive policies to decide between guessing, enumerating, or querying for clarification.", "method": "Uses self-play with two agents\u2014a user simulator and an AI assistant\u2014where the assistant optimizes reward based on cost-penalized accuracy, employing Reinforced Self-Training (ReST).", "result": "The approach produces steerable policies that adapt predictably to varying costs and achieve higher reward and accuracy. Policies also generalize to cost values unobserved during training.", "conclusion": "Training steerable policies using self-play allows AI assistants to effectively handle ambiguity, optimize user experience, and generalize across contexts."}}
{"id": "2512.04000", "pdf": "https://arxiv.org/pdf/2512.04000", "abs": "https://arxiv.org/abs/2512.04000", "authors": ["Jialuo Li", "Bin Li", "Jiahao Li", "Yan Lu"], "title": "Divide, then Ground: Adapting Frame Selection to Query Types for Long-Form Video Understanding", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "The application of Large Multimodal Models (LMMs) to long-form video understanding is constrained by limited context lengths and the computationally prohibitive cost of processing dense video tokens. Consequently, recent research has focused on query-aware frame selection, methods that often incur significant computational overhead. This paper challenges the assumption that such complex search mechanisms are universally necessary. We first identify and validate a query typology distinguishing between global query and localized query. We demonstrate that while uniform sampling is both effective and efficient for global queries, localized queries indeed necessitate query-aware selection for optimal performance. Building on this insight, we propose DIG, a training-free frame selection framework that adapts its strategy based on the query type. Specifically,DIG employs efficient uniform sampling for global queries while activating a specialized pipeline to extract query-relevant frames for localized queries. Experiments on three long-form video understanding benchmarks demonstrate that DIG consistently outperforms existing baselines and robustly improves LMM performance, even when scaling the input frame count to 256.", "AI": {"tldr": "This paper explores frame selection in long-form video understanding by proposing a training-free framework (DIG) that adjusts strategies based on query type for efficiency and performance.", "motivation": "Addressing limitations in applying Large Multimodal Models (LMMs) to long-form video understanding due to restricted context lengths and the high computational cost of dense video data.", "method": "Developed DIG, a framework that distinguishes between global and localized queries to allocate frame selection strategies: efficient uniform sampling for global queries and specialized pipeline extraction for localized queries.", "result": "DIG outperforms previous baselines in three benchmarks, improving LMM performance even with higher input frame counts up to 256.", "conclusion": "Query-aware mechanisms are not universally necessary; strategies like DIG can efficiently combine uniform sampling and targeted selection to optimize video understanding processes."}}
{"id": "2506.23888", "pdf": "https://arxiv.org/pdf/2506.23888", "abs": "https://arxiv.org/abs/2506.23888", "authors": ["Andr\u00e9 de Souza Loureiro", "Jorge Valverde-Rebaza", "Julieta Noguez", "David Escarcega", "Ricardo Marcacini"], "title": "Advancing Multi-Step Mathematical Reasoning in Large Language Models through Multi-Layered Self-Reflection with Auto-Prompting", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted for publication in: European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD 2025). Research Track", "summary": "Recent advancements in Large Language Models (LLMs) have significantly improved their problem-solving capabilities. However, these models still struggle when faced with complex multi-step reasoning tasks. In this paper, we propose the Multi-Layered Self-Reflection with Auto-Prompting (MAPS) framework, a novel approach designed to enhance multi-step mathematical reasoning in LLMs by integrating techniques such as Chain of Thought (CoT), Self-Reflection, and Auto-Prompting. Unlike traditional static prompting methods, MAPS employs an iterative refinement process. Initially, the model generates a solution using CoT prompting. When errors are detected, an adaptive self-reflection mechanism identifies and analyzes them, generating tailored prompts to guide corrections. These dynamically adjusted prompts enable the model to iteratively refine its reasoning. Experiments on four well-established benchmarks across multiple LLMs show that MAPS significantly outperforms standard CoT and achieves competitive results with reasoning-optimized models. In addition, MAPS enables general-purpose LLMs to reach performance levels comparable to specialized reasoning models. While deeper reflection layers improve accuracy, they also increase token usage and costs. To balance this trade-off, MAPS strategically limits reflection depth, ensuring an optimal balance between cost and reasoning performance.", "AI": {"tldr": "The paper introduces the MAPS framework, enhancing LLMs' multi-step reasoning by integrating adaptive self-reflection and auto-prompting, achieving notable improvements in benchmarks.", "motivation": "Large Language Models struggle with complex multi-step reasoning tasks, necessitating innovative methods to improve their accuracy and capabilities.", "method": "The MAPS framework uses an iterative refinement approach: starting with CoT prompting, incorporating self-reflection to identify errors, and generating dynamic auto-prompts for correction.", "result": "Experiments on four benchmarks demonstrate that MAPS outperforms standard CoT methods and rivals specialized reasoning-optimized models.", "conclusion": "MAPS significantly enhances general-purpose LLMs' reasoning skills, balancing accuracy and cost through strategic reflection depth control."}}
{"id": "2512.04007", "pdf": "https://arxiv.org/pdf/2512.04007", "abs": "https://arxiv.org/abs/2512.04007", "authors": ["Marcelo Isaias de Moraes Junior", "Moacir Antonelli Ponti"], "title": "On the Temporality for Sketch Representation Learning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Sketches are simple human hand-drawn abstractions of complex scenes and real-world objects. Although the field of sketch representation learning has advanced significantly, there is still a gap in understanding the true relevance of the temporal aspect to the quality of these representations. This work investigates whether it is indeed justifiable to treat sketches as sequences, as well as which internal orders play a more relevant role. The results indicate that, although the use of traditional positional encodings is valid for modeling sketches as sequences, absolute coordinates consistently outperform relative ones. Furthermore, non-autoregressive decoders outperform their autoregressive counterparts. Finally, the importance of temporality was shown to depend on both the order considered and the task evaluated.", "AI": {"tldr": "This paper examines the significance of temporality and order in sketch representation learning, comparing absolute versus relative coordinates, and autoregressive versus non-autoregressive decoders.", "motivation": "To address the gap in understanding how the temporal aspect influences the quality and effectiveness of sketch representations.", "method": "The study evaluates the impact of sketch temporality using positional encodings, coordinates (absolute/relative), and decoder types (autoregressive/non-autoregressive) in various tasks.", "result": "Absolute coordinates perform better than relative ones; non-autoregressive decoders outperform autoregressive ones; temporality varies in importance depending on order and task.", "conclusion": "Temporality plays a nuanced role in sketch representation learning; absolute positioning and non-autoregressive decoders are recommended approaches."}}
{"id": "2512.04012", "pdf": "https://arxiv.org/pdf/2512.04012", "abs": "https://arxiv.org/abs/2512.04012", "authors": ["Jisang Han", "Sunghwan Hong", "Jaewoo Jung", "Wooseok Jang", "Honggyu An", "Qianqian Wang", "Seungryong Kim", "Chen Feng"], "title": "Emergent Outlier View Rejection in Visual Geometry Grounded Transformers", "categories": ["cs.CV"], "comment": "Project page: https://cvlab-kaist.github.io/RobustVGGT/", "summary": "Reliable 3D reconstruction from in-the-wild image collections is often hindered by \"noisy\" images-irrelevant inputs with little or no view overlap with others. While traditional Structure-from-Motion pipelines handle such cases through geometric verification and outlier rejection, feed-forward 3D reconstruction models lack these explicit mechanisms, leading to degraded performance under in-the-wild conditions. In this paper, we discover that the existing feed-forward reconstruction model, e.g., VGGT, despite lacking explicit outlier-rejection mechanisms or noise-aware training, can inherently distinguish distractor images. Through an in-depth analysis under varying proportions of synthetic distractors, we identify a specific layer that naturally exhibits outlier-suppressing behavior. Further probing reveals that this layer encodes discriminative internal representations that enable an effective noise-filtering capability, which we simply leverage to perform outlier-view rejection in feed-forward 3D reconstruction without any additional fine-tuning or supervision. Extensive experiments on both controlled and in-the-wild datasets demonstrate that this implicit filtering mechanism is consistent and generalizes well across diverse scenarios.", "AI": {"tldr": "The paper uncovers a latent capability within a feed-forward 3D reconstruction model, VGGT, to filter irrelevant 'noisy' images without additional training, improving reconstruction performance.", "motivation": "Existing feed-forward 3D reconstruction models lack mechanisms to reject irrelevant 'noisy' images, leading to compromised results in diverse, uncontrolled environments.", "method": "Through analysis of the VGGT model under synthetic conditions, the researchers identify a layer with inherent outlier-filtering behavior and repurpose this layer for noise rejection without extra training.", "result": "The discovered layer demonstrated effective suppression of distractions and improved performance in 3D reconstruction tasks across controlled and real-world datasets.", "conclusion": "Feed-forward 3D reconstruction models possess implicit noise-rejection capabilities, which can be harnessed for reliable reconstructions in uncontrolled settings without modifying existing architectures."}}
{"id": "2512.04015", "pdf": "https://arxiv.org/pdf/2512.04015", "abs": "https://arxiv.org/abs/2512.04015", "authors": ["Farhana Hossain Swarnali", "Miaomiao Zhang", "Tonmoy Hossain"], "title": "Learning Group Actions In Disentangled Latent Image Representations", "categories": ["cs.CV"], "comment": null, "summary": "Modeling group actions on latent representations enables controllable transformations of high-dimensional image data. Prior works applying group-theoretic priors or modeling transformations typically operate in the high-dimensional data space, where group actions apply uniformly across the entire input, making it difficult to disentangle the subspace that varies under transformations. While latent-space methods offer greater flexibility, they still require manual partitioning of latent variables into equivariant and invariant subspaces, limiting the ability to robustly learn and operate group actions within the representation space. To address this, we introduce a novel end-to-end framework that for the first time learns group actions on latent image manifolds, automatically discovering transformation-relevant structures without manual intervention. Our method uses learnable binary masks with straight-through estimation to dynamically partition latent representations into transformation-sensitive and invariant components. We formulate this within a unified optimization framework that jointly learns latent disentanglement and group transformation mappings. The framework can be seamlessly integrated with any standard encoder-decoder architecture. We validate our approach on five 2D/3D image datasets, demonstrating its ability to automatically learn disentangled latent factors for group actions in diverse data, while downstream classification tasks confirm the effectiveness of the learned representations. Our code is publicly available at https://github.com/farhanaswarnali/Learning-Group-Actions-In-Disentangled-Latent-Image-Representations .", "AI": {"tldr": "This study presents a method for learning group actions on latent image manifolds, using binary masks to partition representations into transformation-sensitive and invariant components within a unified optimization framework. It works with encoder-decoder architectures and achieves robust disentanglement.", "motivation": "The paper addresses the challenge of disentangling transformation-sensitive and invariant subspaces in high-dimensional image representations, without requiring manual partitioning of latent variables.", "method": "The proposed method employs learnable binary masks with straight-through estimation in a unified optimization framework to automatically partition latent representations into transformation-sensitive and invariant parts. It integrates seamlessly with encoder-decoder architectures.", "result": "The approach demonstrates successful disentanglement of latent factors related to group actions across diverse 2D/3D datasets. The learned representations also improve downstream classification performance.", "conclusion": "The methodology robustly automates latent disentanglement and group transformation learning, advancing representation learning capabilities and demonstrating practical benefits for diverse datasets."}}
{"id": "2512.03718", "pdf": "https://arxiv.org/pdf/2512.03718", "abs": "https://arxiv.org/abs/2512.03718", "authors": ["Robert Ganian", "Hung P. Hoang", "Simon Wietheger"], "title": "Matrix Editing Meets Fair Clustering: Parameterized Algorithms and Complexity", "categories": ["cs.DS", "cs.AI"], "comment": null, "summary": "We study the computational problem of computing a fair means clustering of discrete vectors, which admits an equivalent formulation as editing a colored matrix into one with few distinct color-balanced rows by changing at most $k$ values. While NP-hard in both the fairness-oblivious and the fair settings, the problem is well-known to admit a fixed-parameter algorithm in the former ``vanilla'' setting. As our first contribution, we exclude an analogous algorithm even for highly restricted fair means clustering instances. We then proceed to obtain a full complexity landscape of the problem, and establish tractability results which capture three means of circumventing our obtained lower bound: placing additional constraints on the problem instances, fixed-parameter approximation, or using an alternative parameterization targeting tree-like matrices.", "AI": {"tldr": "The paper investigates the problem of fair means clustering for discrete vectors, showing its significant computational challenges and offering solutions under specific constraints and parameterizations.", "motivation": "The study is motivated by the need to develop fair clustering methods, addressing both computational feasibility and the challenge of balancing fair outcomes in edited matrix representations.", "method": "The authors analyze the computational complexity of fair means clustering by identifying intractable instances, establishing a detailed complexity framework, and proposing solutions through constraints, approximation, or alternative parameterizations.", "result": "The paper identifies NP-hardness in restricted fair settings, excludes fixed-parameter algorithms in certain instances, and proposes alternative approaches that ensure tractability.", "conclusion": "The findings provide a comprehensive understanding of fair means clustering's complexity and offer practical methods to address challenges, benefiting fair data analysis and algorithm design."}}
{"id": "2512.04019", "pdf": "https://arxiv.org/pdf/2512.04019", "abs": "https://arxiv.org/abs/2512.04019", "authors": ["Ho Man Kwan", "Tianhao Peng", "Ge Gao", "Fan Zhang", "Mike Nilsson", "Andrew Gower", "David Bull"], "title": "Ultra-lightweight Neural Video Representation Compression", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Recent works have demonstrated the viability of utilizing over-fitted implicit neural representations (INRs) as alternatives to autoencoder-based models for neural video compression. Among these INR-based video codecs, Neural Video Representation Compression (NVRC) was the first to adopt a fully end-to-end compression framework that compresses INRs, achieving state-of-the-art performance. Moreover, some recently proposed lightweight INRs have shown comparable performance to their baseline codecs with computational complexity lower than 10kMACs/pixel. In this work, we extend NVRC toward lightweight representations, and propose NVRC-Lite, which incorporates two key changes. Firstly, we integrated multi-scale feature grids into our lightweight neural representation, and the use of higher resolution grids significantly improves the performance of INRs at low complexity. Secondly, we address the issue that existing INRs typically leverage autoregressive models for entropy coding: these are effective but impractical due to their slow coding speed. In this work, we propose an octree-based context model for entropy coding high-dimensional feature grids, which accelerates the entropy coding module of the model. Our experimental results demonstrate that NVRC-Lite outperforms C3, one of the best lightweight INR-based video codecs, with up to 21.03% and 23.06% BD-rate savings when measured in PSNR and MS-SSIM, respectively, while achieving 8.4x encoding and 2.5x decoding speedup. The implementation of NVRC-Lite will be made available.", "AI": {"tldr": "This paper introduces NVRC-Lite, a lightweight neural video compression approach that improves compression efficiency and speed using multi-scale feature grids and an octree-based context model for entropy coding.", "motivation": "The goal is to create an efficient and lightweight alternative to existing neural video codecs that addresses the issues of computational complexity and slow entropy coding in prior methods.", "method": "NVRC-Lite incorporates multi-scale feature grids that allow higher resolution and integrates an octree-based context model for faster and more efficient entropy coding.", "result": "NVRC-Lite achieves higher performance compared to the C3 model, offering up to 21.03% (PSNR) and 23.06% (MS-SSIM) BD-rate savings, along with a significant 8.4x encoding and 2.5x decoding speedup.", "conclusion": "NVRC-Lite presents an efficient means for lightweight neural video compression, improving on both compression rates and processing speed over state-of-the-art methods. Its implementation will be released for broader use."}}
{"id": "2512.03719", "pdf": "https://arxiv.org/pdf/2512.03719", "abs": "https://arxiv.org/abs/2512.03719", "authors": ["Seyed Mohammad Azimi-Abarghouyi", "Carlo Fischione", "Kaibin Huang"], "title": "Over-the-Air Federated Learning: Rethinking Edge AI Through Signal Processing", "categories": ["cs.IT", "cs.AI", "cs.LG"], "comment": null, "summary": "Over-the-Air Federated Learning (AirFL) is an emerging paradigm that tightly integrates wireless signal processing and distributed machine learning to enable scalable AI at the network edge. By leveraging the superposition property of wireless signals, AirFL performs communication and model aggregation of the learning process simultaneously, significantly reducing latency, bandwidth, and energy consumption. This article offers a tutorial treatment of AirFL, presenting a novel classification into three design approaches: CSIT-aware, blind, and weighted AirFL. We provide a comprehensive guide to theoretical foundations, performance analysis, complexity considerations, practical limitations, and prospective research directions.", "AI": {"tldr": "Over-the-Air Federated Learning (AirFL) enables efficient model aggregation via wireless communication, reducing costs and supporting scalable edge AI.", "motivation": "The paper aims to address challenges in traditional federated learning by integrating communication and computation processes to improve efficiency at the edge.", "method": "The authors classify AirFL into CSIT-aware, blind, and weighted approaches, exploring theoretical foundations, performance, and limitations of each.", "result": "The study provides insights into reducing latency, bandwidth, and energy consumption while highlighting complexity and practical issues in AirFL.", "conclusion": "AirFL is a promising approach to scalable AI by leveraging wireless signal properties, but practical challenges and research gaps remain."}}
{"id": "2512.04021", "pdf": "https://arxiv.org/pdf/2512.04021", "abs": "https://arxiv.org/abs/2512.04021", "authors": ["Honggyu An", "Jaewoo Jung", "Mungyeom Kim", "Sunghwan Hong", "Chaehyun Kim", "Kazumi Fukuda", "Minkyeong Jeon", "Jisang Han", "Takuya Narihira", "Hyuna Ko", "Junsu Kim", "Yuki Mitsufuji", "Seungryong Kim"], "title": "C3G: Learning Compact 3D Representations with 2K Gaussians", "categories": ["cs.CV"], "comment": "Project Page : https://cvlab-kaist.github.io/C3G/", "summary": "Reconstructing and understanding 3D scenes from unposed sparse views in a feed-forward manner remains as a challenging task in 3D computer vision. Recent approaches use per-pixel 3D Gaussian Splatting for reconstruction, followed by a 2D-to-3D feature lifting stage for scene understanding. However, they generate excessive redundant Gaussians, causing high memory overhead and sub-optimal multi-view feature aggregation, leading to degraded novel view synthesis and scene understanding performance. We propose C3G, a novel feed-forward framework that estimates compact 3D Gaussians only at essential spatial locations, minimizing redundancy while enabling effective feature lifting. We introduce learnable tokens that aggregate multi-view features through self-attention to guide Gaussian generation, ensuring each Gaussian integrates relevant visual features across views. We then exploit the learned attention patterns for Gaussian decoding to efficiently lift features. Extensive experiments on pose-free novel view synthesis, 3D open-vocabulary segmentation, and view-invariant feature aggregation demonstrate our approach's effectiveness. Results show that a compact yet geometrically meaningful representation is sufficient for high-quality scene reconstruction and understanding, achieving superior memory efficiency and feature fidelity compared to existing methods.", "AI": {"tldr": "The paper proposes C3G, a novel framework for compact 3D Gaussian generation for 3D scene reconstruction and understanding from unposed sparse views, achieving higher efficiency and quality than existing methods.", "motivation": "Reconstructing 3D scenes from unposed sparse views in a feed-forward manner faces challenges like redundant Gaussians leading to memory overhead and degraded view synthesis and scene comprehension.", "method": "The method (C3G) uses learnable tokens with self-attention to guide compact 3D Gaussian generation and improve feature lifting for scene reconstruction and understanding.", "result": "C3G achieves superior memory efficiency, feature fidelity, and performance in tasks like pose-free novel view synthesis, 3D segmentation, and feature aggregation.", "conclusion": "A geometrically compact representation suffices for high-quality 3D scene reconstruction, offering advantages in memory and efficiency compared to existing techniques."}}
{"id": "2512.03720", "pdf": "https://arxiv.org/pdf/2512.03720", "abs": "https://arxiv.org/abs/2512.03720", "authors": ["Tengyun Ma", "Jiaqi Yao", "Daojing He", "Shihao Peng", "Yu Li", "Shaohui Liu", "Zhuotao Tian"], "title": "Context-Aware Hierarchical Learning: A Two-Step Paradigm towards Safer LLMs", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have emerged as powerful tools for diverse applications. However, their uniform token processing paradigm introduces critical vulnerabilities in instruction handling, particularly when exposed to adversarial scenarios. In this work, we identify and propose a novel class of vulnerabilities, termed Tool-Completion Attack (TCA), which exploits function-calling mechanisms to subvert model behavior. To evaluate LLM robustness against such threats, we introduce the Tool-Completion benchmark, a comprehensive security assessment framework, which reveals that even state-of-the-art models remain susceptible to TCA, with surprisingly high attack success rates. To address these vulnerabilities, we introduce Context-Aware Hierarchical Learning (CAHL), a sophisticated mechanism that dynamically balances semantic comprehension with role-specific instruction constraints. CAHL leverages the contextual correlations between different instruction segments to establish a robust, context-aware instruction hierarchy. Extensive experiments demonstrate that CAHL significantly enhances LLM robustness against both conventional attacks and the proposed TCA, exhibiting strong generalization capabilities in zero-shot evaluations while still preserving model performance on generic tasks. Our code is available at https://github.com/S2AILab/CAHL.", "AI": {"tldr": "This paper identifies a new type of vulnerability in Large Language Models (LLMs), termed Tool-Completion Attack (TCA), and proposes a solution called Context-Aware Hierarchical Learning (CAHL) to mitigate these issues while maintaining performance.", "motivation": "The paper addresses the critical security vulnerabilities in LLMs caused by their uniform token processing paradigm, particularly in handling adversarial instruction attacks like TCAs.", "method": "The authors introduce the Tool-Completion benchmark to assess LLM security and propose Context-Aware Hierarchical Learning (CAHL), which dynamically balances instruction comprehension and constraints using contextual segmentation.", "result": "Experiments show that CAHL enhances LLM robustness against TCAs and other conventional attacks, with strong generalization and preserved task performance in zero-shot evaluations.", "conclusion": "The proposed CAHL demonstrates effective mitigation of TCA vulnerabilities in LLMs, improving their security while maintaining task performance across various scenarios."}}
{"id": "2512.04025", "pdf": "https://arxiv.org/pdf/2512.04025", "abs": "https://arxiv.org/abs/2512.04025", "authors": ["Xiaolong Li", "Youping Gu", "Xi Lin", "Weijie Wang", "Bohan Zhuang"], "title": "PSA: Pyramid Sparse Attention for Efficient Video Understanding and Generation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Tech report", "summary": "Attention mechanisms are the core of foundation models, but their quadratic complexity remains a critical bottleneck for scaling. This challenge has driven the development of efficient attention mechanisms, with sparsity emerging as the dominant paradigm. Current methods typically retain or discard entire key-value blocks with binary masks, resulting in substantial information loss under high sparsity. To mitigate this gap, we present Pyramid Sparse Attention (PSA), a versatile module applicable to both video understanding and generation tasks. Instead of binary masking, PSA introduces multi-level pooled KV representations, enabling finer mask granularity. Specifically, each query block dynamically allocates lower pooling levels to critical KV blocks and higher levels to less important ones, creating an informative interpolation between full retention and complete pruning. This design, analogous to fixed-point quantization and classical feature pyramid networks in computer vision, effectively mitigates information loss while preserving computational efficiency under a low compute budget. It works with a native, hardware-friendly kernel that leverages decoupled block-tile design to ensure efficient execution. Across video understanding and generation benchmarks, PSA preserves contextual information and visual fidelity, consistently outperforming or achieving comparable performance over existing sparse attention baselines with superior efficiency-quality trade-offs. Our code and model weights are publicly available at: http://ziplab.co/PSA", "AI": {"tldr": "This paper introduces Pyramid Sparse Attention (PSA), a new mechanism to address the computational inefficiencies in attention models, particularly tackling high sparsity without significant loss of information.", "motivation": "Efficient attention mechanisms are crucial for scaling foundation models due to the quadratic complexity of traditional attention mechanisms. Current sparse attention methods lead to high information loss, especially under conditions of high sparsity, which limits their efficacy.", "method": "The authors propose PSA, a module with multi-level pooled key-value (KV) representations instead of binary masking. It dynamically allocates pooling levels to important and less critical KV blocks, creating an interpolation between full retention and pruning. The approach uses a hardware-friendly kernel for efficient execution, making it applicable for video understanding and generation tasks.", "result": "PSA consistently outperforms or matches existing sparse attention mechanisms in maintaining contextual integrity and visual quality while being more computationally efficient in both video understanding and generation tasks.", "conclusion": "PSA provides a practical and efficient alternative to existing attention mechanisms by reducing computational costs without compromising performance. It represents a significant improvement in the efficiency-quality trade-off for sparse attention mechanisms in video applications."}}
{"id": "2512.03728", "pdf": "https://arxiv.org/pdf/2512.03728", "abs": "https://arxiv.org/abs/2512.03728", "authors": ["Pradnya Taksande", "Shwetha Kiran", "Pranav Jha", "Prasanna Chaporkar"], "title": "AI/ML in 3GPP 5G Advanced - Services and Architecture", "categories": ["cs.ET", "cs.AI"], "comment": null, "summary": "The 3rd Generation Partnership Project (3GPP), the standards body for mobile networks, is in the final phase of Release 19 standardization and is beginning Release 20. Artificial Intelligence/ Machine Learning (AI/ML) has brought about a paradigm shift in technology and it is being adopted across industries and verticals. 3GPP has been integrating AI/ML into the 5G advanced system since Release 18. This paper focuses on the AI/ML related technological advancements and features introduced in Release 19 within the Service and System Aspects (SA) Technical specifications group of 3GPP. The advancements relate to two paradigms: (i) enhancements that AI/ML brought to the 5G advanced system (AI for network), e.g. resource optimization, and (ii) enhancements that were made to the 5G system to support AI/ML applications (Network for AI), e.g. image recognition.", "AI": {"tldr": "The paper discusses AI/ML advancements in 3GPP Release 19 for mobile network enhancements and support for AI/ML applications.", "motivation": "To explore and document how AI/ML technologies are integrated and advanced in the 5G system through 3GPP Release 19.", "method": "The study focuses on analyzing AI/ML technological advancements and features in the Service and System Aspects (SA) group of 3GPP Release 19.", "result": "AI/ML advancements in Release 19 are categorized into improvements for network operations (AI for network) and enhancements to support AI/ML applications (Network for AI).", "conclusion": "3GPP Release 19 incorporates AI/ML paradigms to optimize 5G network performance and support AI/ML applications, marking a progression in mobile network standardization."}}
{"id": "2512.04039", "pdf": "https://arxiv.org/pdf/2512.04039", "abs": "https://arxiv.org/abs/2512.04039", "authors": ["Sandeep Nagar"], "title": "Fast & Efficient Normalizing Flows and Applications of Image Generative Models", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "PhD Thesis", "summary": "This thesis presents novel contributions in two primary areas: advancing the efficiency of generative models, particularly normalizing flows, and applying generative models to solve real-world computer vision challenges. The first part introduce significant improvements to normalizing flow architectures through six key innovations: 1) Development of invertible 3x3 Convolution layers with mathematically proven necessary and sufficient conditions for invertibility, (2) introduction of a more efficient Quad-coupling layer, 3) Design of a fast and efficient parallel inversion algorithm for kxk convolutional layers, 4) Fast & efficient backpropagation algorithm for inverse of convolution, 5) Using inverse of convolution, in Inverse-Flow, for the forward pass and training it using proposed backpropagation algorithm, and 6) Affine-StableSR, a compact and efficient super-resolution model that leverages pre-trained weights and Normalizing Flow layers to reduce parameter count while maintaining performance.\n  The second part: 1) An automated quality assessment system for agricultural produce using Conditional GANs to address class imbalance, data scarcity and annotation challenges, achieving good accuracy in seed purity testing; 2) An unsupervised geological mapping framework utilizing stacked autoencoders for dimensionality reduction, showing improved feature extraction compared to conventional methods; 3) We proposed a privacy preserving method for autonomous driving datasets using on face detection and image inpainting; 4) Utilizing Stable Diffusion based image inpainting for replacing the detected face and license plate to advancing privacy-preserving techniques and ethical considerations in the field.; and 5) An adapted diffusion model for art restoration that effectively handles multiple types of degradation through unified fine-tuning.", "AI": {"tldr": "The paper introduces innovative contributions to enhance generative models like normalizing flows and applies them to computer vision problems, including super-resolution, quality assessment, mapping, privacy preservation, and art restoration.", "motivation": "To improve the efficiency of generative models and address real-world computer vision issues, such as handling class imbalance, privacy concerns, and art restoration challenges.", "method": "It introduces advancements in normalizing flows architectures (e.g., invertible convolutions, efficient algorithms, and compact super-resolution models) and applies techniques like Conditional GANs, stacked autoencoders, and Stable Diffusion for various tasks.", "result": "Key results include improved generative model efficiency, accurate agricultural quality assessment, effective geological feature extraction, enhanced privacy-preserving methods, and a robust art restoration model.", "conclusion": "The study highlights the potential of advancing generative models and their real-world applications, showcasing efficiency, versatility, and ethical advancements in computer vision tasks."}}
{"id": "2512.03094", "pdf": "https://arxiv.org/pdf/2512.03094", "abs": "https://arxiv.org/abs/2512.03094", "authors": ["Tom\u00e1s Villalba-Ferreiro", "Eduardo Mosqueira-Rey", "Diego Alvarez-Estevez"], "title": "Performance Analysis of Quantum Support Vector Classifiers and Quantum Neural Networks", "categories": ["quant-ph", "cs.LG"], "comment": "7 pages, 7 figures, conference", "summary": "This study explores the performance of Quantum Support Vector Classifiers (QSVCs) and Quantum Neural Networks (QNNs) in comparison to classical models for machine learning tasks. By evaluating these models on the Iris and MNIST-PCA datasets, we find that quantum models tend to outperform classical approaches as the problem complexity increases. While QSVCs generally provide more consistent results, QNNs exhibit superior performance in higher-complexity tasks due to their increased quantum load. Additionally, we analyze the impact of hyperparameter tuning, showing that feature maps and ansatz configurations significantly influence model accuracy. We also compare the PennyLane and Qiskit frameworks, concluding that Qiskit provides better optimization and efficiency for our implementation. These findings highlight the potential of Quantum Machine Learning (QML) for complex classification problems and provide insights into model selection and optimization strategies", "AI": {"tldr": "The study compares Quantum Support Vector Classifiers (QSVCs) and Quantum Neural Networks (QNNs) with classical models, finding quantum advantages for complex tasks.", "motivation": "Explore the effectiveness and advantages of quantum models over classical models in machine learning tasks.", "method": "Performance evaluation of QSVCs and QNNs using the Iris and MNIST-PCA datasets. Analysis of hyperparameter tuning effects and comparison of PennyLane with Qiskit frameworks.", "result": "Quantum models outperform classical models as problem complexity increases, with QSVCs showing consistency and QNNs excelling in higher-complexity tasks.", "conclusion": "Quantum Machine Learning models demonstrate promising potential, especially for complex classification problems, and Qiskit is more efficient for implementation."}}
{"id": "2512.04040", "pdf": "https://arxiv.org/pdf/2512.04040", "abs": "https://arxiv.org/abs/2512.04040", "authors": ["Yicong Hong", "Yiqun Mei", "Chongjian Ge", "Yiran Xu", "Yang Zhou", "Sai Bi", "Yannick Hold-Geoffroy", "Mike Roberts", "Matthew Fisher", "Eli Shechtman", "Kalyan Sunkavalli", "Feng Liu", "Zhengqi Li", "Hao Tan"], "title": "RELIC: Interactive Video World Model with Long-Horizon Memory", "categories": ["cs.CV"], "comment": "22 pages", "summary": "A truly interactive world model requires three key ingredients: real-time long-horizon streaming, consistent spatial memory, and precise user control. However, most existing approaches address only one of these aspects in isolation, as achieving all three simultaneously is highly challenging-for example, long-term memory mechanisms often degrade real-time performance. In this work, we present RELIC, a unified framework that tackles these three challenges altogether. Given a single image and a text description, RELIC enables memory-aware, long-duration exploration of arbitrary scenes in real time. Built upon recent autoregressive video-diffusion distillation techniques, our model represents long-horizon memory using highly compressed historical latent tokens encoded with both relative actions and absolute camera poses within the KV cache. This compact, camera-aware memory structure supports implicit 3D-consistent content retrieval and enforces long-term coherence with minimal computational overhead. In parallel, we fine-tune a bidirectional teacher video model to generate sequences beyond its original 5-second training horizon, and transform it into a causal student generator using a new memory-efficient self-forcing paradigm that enables full-context distillation over long-duration teacher as well as long student self-rollouts. Implemented as a 14B-parameter model and trained on a curated Unreal Engine-rendered dataset, RELIC achieves real-time generation at 16 FPS while demonstrating more accurate action following, more stable long-horizon streaming, and more robust spatial-memory retrieval compared with prior work. These capabilities establish RELIC as a strong foundation for the next generation of interactive world modeling.", "AI": {"tldr": "This paper introduces RELIC, a framework combining real-time performance, long-horizon memory, and precise user control for interactive world modeling.", "motivation": "Current models lack a unified system combining real-time streaming, consistent spatial memory, and precise user control, as addressing all simultaneously is difficult.", "method": "The authors propose RELIC, which uses autoregressive video-diffusion and a memory structure based on compact latent tokens encoded with camera poses and actions. This ensures efficient and coherent generation over extended durations.", "result": "RELIC achieves real-time generation at 16 FPS, demonstrating better action following, stable long-horizon streaming, and robust spatial-memory retrieval compared to existing approaches.", "conclusion": "RELIC provides a solid foundation for progress in interactive world modeling by addressing longstanding challenges in real-time performance and spatial memory integration for long-duration exploration."}}
{"id": "2512.03097", "pdf": "https://arxiv.org/pdf/2512.03097", "abs": "https://arxiv.org/abs/2512.03097", "authors": ["Adeela Bashir", "The Anh han", "Zia Ush Shamszaman"], "title": "Many-to-One Adversarial Consensus: Exposing Multi-Agent Collusion Risks in AI-Based Healthcare", "categories": ["cs.CR", "cs.LG", "cs.MA"], "comment": "7 pages Conference level paper", "summary": "The integration of large language models (LLMs) into healthcare IoT systems promises faster decisions and improved medical support. LLMs are also deployed as multi-agent teams to assist AI doctors by debating, voting, or advising on decisions. However, when multiple assistant agents interact, coordinated adversaries can collude to create false consensus, pushing an AI doctor toward harmful prescriptions. We develop an experimental framework with scripted and unscripted doctor agents, adversarial assistants, and a verifier agent that checks decisions against clinical guidelines. Using 50 representative clinical questions, we find that collusion drives the Attack Success Rate (ASR) and Harmful Recommendation Rates (HRR) up to 100% in unprotected systems. In contrast, the verifier agent restores 100% accuracy by blocking adversarial consensus. This work provides the first systematic evidence of collusion risk in AI healthcare and demonstrates a practical, lightweight defence that ensures guideline fidelity.", "AI": {"tldr": "This paper investigates collusion risks in healthcare IoT systems using LLMs and demonstrates a verification mechanism to prevent harmful recommendations.", "motivation": "To address potential collusion risks where adversarial language model agents could manipulate decision outcomes in healthcare IoT systems, leading to harmful medical suggestions.", "method": "The paper proposes an experimental framework consisting of scripted and unscripted AI doctors, adversarial assistants, and a verifier agent, and evaluates the system using 50 clinical questions.", "result": "Collusion among adversaries caused a 100% Attack Success Rate and Harmful Recommendation Rates in unprotected systems, but the verifier agent maintained 100% accuracy by blocking adversarial interference.", "conclusion": "The study provides the first evidence of collusion risks in AI healthcare and presents an effective defence mechanism ensuring clinical guideline compliance."}}
{"id": "2512.03098", "pdf": "https://arxiv.org/pdf/2512.03098", "abs": "https://arxiv.org/abs/2512.03098", "authors": ["Benoit L. Marteau", "Andrew Hornback", "Shaun Q. Tan", "Christian Lowson", "Jason Woloff", "May D. Wang"], "title": "An AI Implementation Science Study to Improve Trustworthy Data in a Large Healthcare System", "categories": ["q-bio.QM", "cs.LG"], "comment": "Submitted and Accepted to the IEEE International Conference on Biomedical and Health Informatics (BHI) 2025", "summary": "The rapid growth of Artificial Intelligence (AI) in healthcare has sparked interest in Trustworthy AI and AI Implementation Science, both of which are essential for accelerating clinical adoption. However, strict regulations, gaps between research and clinical settings, and challenges in evaluating AI systems continue to hinder real-world implementation. This study presents an AI implementation case study within Shriners Childrens (SC), a large multisite pediatric system, showcasing the modernization of SCs Research Data Warehouse (RDW) to OMOP CDM v5.4 within a secure Microsoft Fabric environment. We introduce a Python-based data quality assessment tool compatible with SCs infrastructure, extending OHDsi's R/Java-based Data Quality Dashboard (DQD) and integrating Trustworthy AI principles using the METRIC framework. This extension enhances data quality evaluation by addressing informative missingness, redundancy, timeliness, and distributional consistency. We also compare systematic and case-specific AI implementation strategies for Craniofacial Microsomia (CFM) using the FHIR standard. Our contributions include a real-world evaluation of AI implementations, integration of Trustworthy AI principles into data quality assessment, and insights into hybrid implementation strategies that blend systematic infrastructure with use-case-driven approaches to advance AI in healthcare.", "AI": {"tldr": "This study addresses barriers to implementing AI in healthcare, focusing on data quality and trustworthy AI principles within a pediatric system, showcasing a hybrid implementation strategy.", "motivation": "The study aims to overcome challenges such as strict regulations, research-clinical gaps, and evaluation hurdles that obstruct real-world AI implementation in healthcare settings.", "method": "The researchers modernized a pediatric system's data warehouse to OMOP CDM v5.4 within a secure environment and developed a Python-based tool to assess data quality, extending existing frameworks while integrating Trustworthy AI principles.", "result": "The study improved data quality assessment through metrics addressing gaps like missingness and timeliness, evaluated AI applications in craniofacial microsomia using hybrid strategies, and proposed a robust mix of systematic and case-specific approaches.", "conclusion": "This research advances AI implementation in healthcare by incorporating Trustworthy AI principles, hybrid strategies, and enhancing data quality and real-world applicability."}}
{"id": "2512.04082", "pdf": "https://arxiv.org/pdf/2512.04082", "abs": "https://arxiv.org/abs/2512.04082", "authors": ["Jiazhe Wei", "Ken Li", "Tianyu Lao", "Haofan Wang", "Liang Wang", "Caifeng Shan", "Chenyang Si"], "title": "PosterCopilot: Toward Layout Reasoning and Controllable Editing for Professional Graphic Design", "categories": ["cs.CV"], "comment": "Project page: https://postercopilot.github.io/", "summary": "Graphic design forms the cornerstone of modern visual communication, serving as a vital medium for promoting cultural and commercial events. Recent advances have explored automating this process using Large Multimodal Models (LMMs), yet existing methods often produce geometrically inaccurate layouts and lack the iterative, layer-specific editing required in professional workflows. To address these limitations, we present PosterCopilot, a framework that advances layout reasoning and controllable editing for professional graphic design. Specifically, we introduce a progressive three-stage training strategy that equips LMMs with geometric understanding and aesthetic reasoning for layout design, consisting of Perturbed Supervised Fine-Tuning, Reinforcement Learning for Visual-Reality Alignment, and Reinforcement Learning from Aesthetic Feedback. Furthermore, we develop a complete workflow that couples the trained LMM-based design model with generative models, enabling layer-controllable, iterative editing for precise element refinement while maintaining global visual consistency. Extensive experiments demonstrate that PosterCopilot achieves geometrically accurate and aesthetically superior layouts, offering unprecedented controllability for professional iterative design.", "AI": {"tldr": "PosterCopilot is a framework for improving graphic design automation using Large Multimodal Models (LMMs), focusing on geometric accuracy and layer-specific iterative editing.", "motivation": "The paper aims to address the limitations in current Large Multimodal Models (LMMs) for graphic design, which often produce geometrically inaccurate layouts and lack professional iterative editing capabilities.", "method": "The authors propose PosterCopilot, introducing a three-stage progressive training strategy: Perturbed Supervised Fine-Tuning, Reinforcement Learning for Visual-Reality Alignment, and Reinforcement Learning from Aesthetic Feedback. It also integrates trained LMM design models with generative models for iterative, layer-controllable editing.", "result": "PosterCopilot achieves geometrically accurate and aesthetically superior graphic layouts, enabling precise refinement and maintaining global consistency.", "conclusion": "PosterCopilot offers a significant advancement in professional graphic design automation, providing controllability and accuracy for iterative design workflows."}}
{"id": "2512.03113", "pdf": "https://arxiv.org/pdf/2512.03113", "abs": "https://arxiv.org/abs/2512.03113", "authors": ["Zhenglong Chen", "Zhao Zhang", "Xia Yan", "Jiayu Zhai", "Piyang Liu", "Kai Zhang"], "title": "A Discrete Neural Operator with Adaptive Sampling for Surrogate Modeling of Parametric Transient Darcy Flows in Porous Media", "categories": ["math.NA", "cs.LG"], "comment": null, "summary": "This study proposes a new discrete neural operator for surrogate modeling of transient Darcy flow fields in heterogeneous porous media with random parameters. The new method integrates temporal encoding, operator learning and UNet to approximate the mapping between vector spaces of random parameter and spatiotemporal flow fields. The new discrete neural operator can achieve higher prediction accuracy than the SOTA attention-residual-UNet structure. Derived from the finite volume method, the transmissibility matrices rather than permeability is adopted as the inputs of surrogates to enhance the prediction accuracy further. To increase sampling efficiency, a generative latent space adaptive sampling method is developed employing the Gaussian mixture model for density estimation of generalization error. Validation is conducted on test cases of 2D/3D single- and two-phase Darcy flow field prediction. Results reveal consistent enhancement in prediction accuracy given limited training set.", "AI": {"tldr": "The paper introduces a new discrete neural operator combining temporal encoding, operator learning, and UNet for mapping random parameters to transient Darcy flow fields in heterogeneous porous media, achieving higher prediction accuracy than current methods.", "motivation": "The motivation is to improve surrogate modeling of transient Darcy flow fields in heterogeneous porous media with random parameters by enhancing prediction accuracy and sampling efficiency.", "method": "The method integrates temporal encoding, operator learning, and UNet within the discrete neural operator. It uses transmissibility matrices instead of permeability as inputs and implements a generative latent space adaptive sampling method via Gaussian mixture models.", "result": "The approach consistently achieves higher prediction accuracy compared to the attention-residual-UNet structure, validated across 2D/3D single- and two-phase Darcy flow cases.", "conclusion": "The proposed discrete neural operator effectively models transient Darcy flow fields with a limited training dataset, demonstrating accuracy improvements and sampling efficiency."}}
{"id": "2512.04084", "pdf": "https://arxiv.org/pdf/2512.04084", "abs": "https://arxiv.org/abs/2512.04084", "authors": ["Qinyu Zhao", "Guangting Zheng", "Tao Yang", "Rui Zhu", "Xingjian Leng", "Stephen Gould", "Liang Zheng"], "title": "SimFlow: Simplified and End-to-End Training of Latent Normalizing Flows", "categories": ["cs.CV"], "comment": "Project Page: https://qinyu-allen-zhao.github.io/SimFlow/", "summary": "Normalizing Flows (NFs) learn invertible mappings between the data and a Gaussian distribution. Prior works usually suffer from two limitations. First, they add random noise to training samples or VAE latents as data augmentation, introducing complex pipelines including extra noising and denoising steps. Second, they use a pretrained and frozen VAE encoder, resulting in suboptimal reconstruction and generation quality. In this paper, we find that the two issues can be solved in a very simple way: just fixing the variance (which would otherwise be predicted by the VAE encoder) to a constant (e.g., 0.5). On the one hand, this method allows the encoder to output a broader distribution of tokens and the decoder to learn to reconstruct clean images from the augmented token distribution, avoiding additional noise or denoising design. On the other hand, fixed variance simplifies the VAE evidence lower bound, making it stable to train an NF with a VAE jointly. On the ImageNet $256 \\times 256$ generation task, our model SimFlow obtains a gFID score of 2.15, outperforming the state-of-the-art method STARFlow (gFID 2.40). Moreover, SimFlow can be seamlessly integrated with the end-to-end representation alignment (REPA-E) method and achieves an improved gFID of 1.91, setting a new state of the art among NFs.", "AI": {"tldr": "This paper introduces SimFlow, a Normalizing Flow model addressing limitations of prior NF methods by fixing the variance of VAE. It achieves state-of-the-art generation quality on ImageNet.", "motivation": "Current Normalizing Flow methods suffer from complex pipelines requiring additional noise steps and use suboptimal frozen VAE encoders, leading to degraded performance.", "method": "The paper proposes fixing the variance predicted by VAE encoders to a constant (e.g., 0.5), simplifying training and enabling joint optimization for improved results.", "result": "SimFlow achieves superior generation performance with a gFID score of 2.15 on ImageNet $256 \\times 256$, outperforming STARFlow. Integrated with REPA-E, it reaches gFID 1.91.", "conclusion": "Fixing variance streamlines Normalizing Flows and enhances both reconstruction and generation quality, enabling state-of-the-art results."}}
{"id": "2512.04085", "pdf": "https://arxiv.org/pdf/2512.04085", "abs": "https://arxiv.org/abs/2512.04085", "authors": ["Tengda Han", "Sayna Ebrahimi", "Dilara Gokay", "Li Yang Ku", "Maks Ovsjanikov", "Iva Babukova", "Daniel Zoran", "Viorica Patraucean", "Joao Carreira", "Andrew Zisserman", "Dima Damen"], "title": "Unique Lives, Shared World: Learning from Single-Life Videos", "categories": ["cs.CV"], "comment": null, "summary": "We introduce the \"single-life\" learning paradigm, where we train a distinct vision model exclusively on egocentric videos captured by one individual. We leverage the multiple viewpoints naturally captured within a single life to learn a visual encoder in a self-supervised manner. Our experiments demonstrate three key findings. First, models trained independently on different lives develop a highly aligned geometric understanding. We demonstrate this by training visual encoders on distinct datasets each capturing a different life, both indoors and outdoors, as well as introducing a novel cross-attention-based metric to quantify the functional alignment of the internal representations developed by different models. Second, we show that single-life models learn generalizable geometric representations that effectively transfer to downstream tasks, such as depth estimation, in unseen environments. Third, we demonstrate that training on up to 30 hours from one week of the same person's life leads to comparable performance to training on 30 hours of diverse web data, highlighting the strength of single-life representation learning. Overall, our results establish that the shared structure of the world, both leads to consistency in models trained on individual lives, and provides a powerful signal for visual representation learning.", "AI": {"tldr": "This paper introduces a \"single-life\" learning paradigm utilizing egocentric videos from one individual to train visual models, revealing aligned geometric understanding and strong representation learning for vision tasks.", "motivation": "Explore the ability to train visual models using egocentric videos from single individuals and extract geometric and transferable visual representations.", "method": "Self-supervised training of visual models on egocentric data from individual lives, leveraging multiple viewpoints and developing an alignment metric using cross-attention.", "result": "1. Models trained independently on different individuals show aligned geometric understanding. 2. Single-life models demonstrate transferable generalizable representations for tasks like depth estimation. 3. 30 hours of one person\u2019s life yielded comparable performance to web data training demonstrating the paradigm's strength.", "conclusion": "Single-life learning can effectively utilize personal egocentric video data to achieve aligned representations and generalizable geometric vision understanding, validating its utility for visual encoder training."}}
{"id": "2512.03193", "pdf": "https://arxiv.org/pdf/2512.03193", "abs": "https://arxiv.org/abs/2512.03193", "authors": ["Yulong Dong", "Christopher Kang", "Murphy Yuezhen Niu"], "title": "In Situ Quantum Analog Pulse Characterization via Structured Signal Processing", "categories": ["quant-ph", "cs.LG", "math.NA"], "comment": "48 pages, 10 figures", "summary": "Analog quantum simulators can directly emulate time-dependent Hamiltonian dynamics, enabling the exploration of diverse physical phenomena such as phase transitions, quench dynamics, and non-equilibrium processes. Realizing accurate analog simulations requires high-fidelity time-dependent pulse control, yet existing calibration schemes are tailored to digital gate characterization and cannot be readily extended to learn continuous pulse trajectories. We present a characterization algorithm for in situ learning of pulse trajectories by extending the Quantum Signal Processing (QSP) framework to analyze time-dependent pulses. By combining QSP with a logical-level analog-digital mapping paradigm, our method reconstructs a smooth pulse directly from queries of the time-ordered propagator, without requiring mid-circuit measurements or additional evolution. Unlike conventional Trotterization-based methods, our approach avoids unscalable performance degradation arising from accumulated local truncation errors as the logical-level segmentation increases. Through rigorous theoretical analysis and extensive numerical simulations, we demonstrate that our method achieves high accuracy with strong efficiency and robustness against SPAM as well as depolarizing errors, providing a lightweight and optimal validation protocol for analog quantum simulators capable of detecting major hardware faults.", "AI": {"tldr": "The paper introduces a method for effectively calibrating time-dependent pulses in analog quantum simulators using an extension of Quantum Signal Processing, providing high accuracy and robustness.", "motivation": "To address the lack of accurate calibration schemes for time-dependent pulse control in analog quantum simulators, which are essential for emulating complex physical phenomena.", "method": "The authors extend the Quantum Signal Processing framework and present an algorithm leveraging logical-level analog-digital mapping. This method reconstructs smooth pulses from time-ordered propagator queries without relying on mid-circuit measurements or additional evolution.", "result": "The method achieves high accuracy, is computationally efficient, and demonstrates robustness against SPAM and depolarizing errors in simulations.", "conclusion": "The proposed method serves as an optimal and lightweight validation protocol for analog quantum simulators, offering scalable performance and the ability to detect hardware faults effectively."}}
{"id": "2512.03052", "pdf": "https://arxiv.org/pdf/2512.03052", "abs": "https://arxiv.org/abs/2512.03052", "authors": ["Zeqiang Lai", "Yunfei Zhao", "Zibo Zhao", "Haolin Liu", "Qingxiang Lin", "Jingwei Huang", "Chunchao Guo", "Xiangyu Yue"], "title": "LATTICE: Democratize High-Fidelity 3D Generation at Scale", "categories": ["cs.GR", "cs.CV"], "comment": "Technical Report", "summary": "We present LATTICE, a new framework for high-fidelity 3D asset generation that bridges the quality and scalability gap between 3D and 2D generative models. While 2D image synthesis benefits from fixed spatial grids and well-established transformer architectures, 3D generation remains fundamentally more challenging due to the need to predict both spatial structure and detailed geometric surfaces from scratch. These challenges are exacerbated by the computational complexity of existing 3D representations and the lack of structured and scalable 3D asset encoding schemes. To address this, we propose VoxSet, a semi-structured representation that compresses 3D assets into a compact set of latent vectors anchored to a coarse voxel grid, enabling efficient and position-aware generation. VoxSet retains the simplicity and compression advantages of prior VecSet methods while introducing explicit structure into the latent space, allowing positional embeddings to guide generation and enabling strong token-level test-time scaling. Built upon this representation, LATTICE adopts a two-stage pipeline: first generating a sparse voxelized geometry anchor, then producing detailed geometry using a rectified flow transformer. Our method is simple at its core, but supports arbitrary resolution decoding, low-cost training, and flexible inference schemes, achieving state-of-the-art performance on various aspects, and offering a significant step toward scalable, high-quality 3D asset creation.", "AI": {"tldr": "LATTICE is a framework for high-quality 3D asset generation using a semi-structured representation called VoxSet to improve scalability and efficiency.", "motivation": "The motivation is to overcome the challenges in 3D asset generation, such as predicting spatial structures, geometric details, and issues with computational complexity and scalability.", "method": "The method uses VoxSet, which compresses 3D data into latent vectors tied to coarse voxel grids, and employs a two-stage pipeline: generating sparse geometry anchors and refining them with a rectified flow transformer.", "result": "LATTICE achieves state-of-the-art performance in scalable and high-fidelity 3D asset generation, supporting arbitrary resolution decoding and efficient training.", "conclusion": "LATTICE bridges the gap between 2D and 3D generative models, paving the way for scalable and high-quality 3D asset creation with improved computational efficiency."}}
{"id": "2512.03216", "pdf": "https://arxiv.org/pdf/2512.03216", "abs": "https://arxiv.org/abs/2512.03216", "authors": ["Alex Bocchieri", "John Mamish", "David Appleyard", "Andreas Velten"], "title": "Kaleidoscopic Scintillation Event Imaging", "categories": ["physics.ins-det", "cs.CV", "eess.IV"], "comment": null, "summary": "Scintillators are transparent materials that interact with high-energy particles and emit visible light as a result. They are used in state of the art methods of measuring high-energy particles and radiation sources. Most existing methods use fast single-pixel detectors to detect and time scintillation events. Cameras provide spatial resolution but can only capture an average over many events, making it difficult to image the events associated with an individual particle. Emerging single-photon avalanche diode cameras combine speed and spatial resolution to enable capturing images of individual events. This allows us to use machine vision techniques to analyze events, enabling new types of detectors. The main challenge is the very low brightness of the events. Techniques have to work with a very limited number of photons.\n  We propose a kaleidoscopic scintillator to increase light collection in a single-photon camera while preserving the event's spatial information. The kaleidoscopic geometry creates mirror reflections of the event in known locations for a given event location that are captured by the camera. We introduce theory for imaging an event in a kaleidoscopic scintillator and an algorithm to estimate the event's 3D position. We find that the kaleidoscopic scintillator design provides sufficient light collection to perform high-resolution event measurements for advanced radiation imaging techniques using a commercial CMOS single-photon camera. Code and data are available at https://github.com/bocchs/kaleidoscopic_scintillator.", "AI": {"tldr": "This paper proposes a kaleidoscopic scintillator for 3D spatial resolution of high-energy particle events using single-photon cameras and advanced imaging algorithms.", "motivation": "Current scintillation detection methods lack the ability to resolve events with both speed and spatial resolution, as existing methods either rely on single-pixel detectors or average multiple events with cameras. The motivation is to improve high-energy particle imaging using single-photon avalanche diode cameras, which are capable of resolving individual events but face the challenge of low light.", "method": "The proposed solution introduces a kaleidoscopic scintillator, leveraging mirror reflections to enhance light collection while preserving spatial resolution. The authors developed a theoretical framework for imaging, along with an algorithm to estimate the 3D position of events captured by a commercial CMOS single-photon camera.", "result": "The kaleidoscopic scintillator enables high-resolution measurements of scintillation events and successfully increases light collection, facilitating advanced radiation imaging techniques.", "conclusion": "This innovative design enhances single-photon camera performance in radiation imaging, allowing for advanced detection of high-energy particles with better light efficiency and spatial accuracy. Open-source code and data are provided to encourage further development and application."}}
{"id": "2512.03915", "pdf": "https://arxiv.org/pdf/2512.03915", "abs": "https://arxiv.org/abs/2512.03915", "authors": ["X. Y. Han", "Yuan Zhong"], "title": "A Theoretical Framework for Auxiliary-Loss-Free Load Balancing of Sparse Mixture-of-Experts in Large-Scale AI Models", "categories": ["math.OC", "cs.AI", "cs.LG"], "comment": null, "summary": "In large-scale AI training, Sparse Mixture-of-Experts (s-MoE) layers enable scaling by activating only a small subset of experts per token. An operational challenge in this design is load balancing: routing tokens to minimize the number of idle experts, which is important for the efficient utilization of (costly) GPUs. We provide a theoretical framework for analyzing the Auxiliary-Loss-Free Load Balancing (ALF-LB) procedure -- proposed by DeepSeek's Wang et al. (2024) -- by casting it as a one-step-per-iteration primal-dual method for an assignment problem. First, in a stylized deterministic setting, our framework yields several insightful structural properties: (i) a monotonic improvement of a Lagrangian objective, (ii) a preference rule that moves tokens from overloaded to underloaded experts, and (iii) an approximate-balancing guarantee. Then, we incorporate the stochastic and dynamic nature of AI training using a generalized online optimization formulation. In the online setting, we derive a strong convexity property of the objective that leads to a logarithmic expected regret bound under certain step-size choices. Additionally, we present real experiments on 1B-parameter DeepSeekMoE models to complement our theoretical findings. Together, these results build a principled framework for analyzing the Auxiliary-Loss-Free Load Balancing of s-MoE in AI models.", "AI": {"tldr": "The paper proposes a theoretical framework to analyze the Auxiliary-Loss-Free Load Balancing (ALF-LB) method in Sparse Mixture-of-Experts (s-MoE) AI models, addressing efficient token-routing for scalability.", "motivation": "Efficiently utilizing GPUs in large-scale AI training requires balancing token routing in s-MoE layers. The authors aim to understand and improve this through analysis of the ALF-LB method.", "method": "The study casts ALF-LB as a primal-dual approach to an assignment problem, deriving properties in deterministic and online settings, and couples theory with experiments on real AI models.", "result": "Key properties like monotonic Lagrangian improvement, approximate balancing guarantees, and strong convexity with logarithmic regret bounds are proven. Experiments validate these insights on large AI models.", "conclusion": "The paper establishes a comprehensive framework for analyzing ALF-LB in s-MoE layers, combining theoretical guarantees with experimental evidence to enhance scaling efficiency in large AI systems."}}
{"id": "2512.03975", "pdf": "https://arxiv.org/pdf/2512.03975", "abs": "https://arxiv.org/abs/2512.03975", "authors": ["Kshipra Bhawalkar", "Alexandros Psomas", "Di Wang"], "title": "Sponsored Questions and How to Auction Them", "categories": ["cs.GT", "cs.AI"], "comment": null, "summary": "Online platforms connect users with relevant products and services using ads. A key challenge is that a user's search query often leaves their true intent ambiguous. Typically, platforms passively predict relevance based on available signals and in some cases offer query refinements. The shift from traditional search to conversational AI provides a new approach. When a user's query is ambiguous, a Large Language Model (LLM) can proactively offer several clarifying follow-up prompts. In this paper we consider the following: what if some of these follow-up prompts can be ``sponsored,'' i.e., selected for their advertising potential. How should these ``suggestion slots'' be allocated? And, how does this new mechanism interact with the traditional ad auction that might follow?\n  This paper introduces a formal model for designing and analyzing these interactive platforms. We use this model to investigate a critical engineering choice: whether it is better to build an end-to-end pipeline that jointly optimizes the user interaction and the final ad auction, or to decouple them into separate mechanisms for the suggestion slots and another for the subsequent ad slot. We show that the VCG mechanism can be adopted to jointly optimize the sponsored suggestion and the ads that follow; while this mechanism is more complex, it achieves outcomes that are efficient and truthful. On the other hand, we prove that the simple-to-implement modular approach suffers from strategic inefficiency: its Price of Anarchy is unbounded.", "AI": {"tldr": "This paper explores introducing sponsored prompts in conversational AI platforms to address ambiguous user queries, analyzing models for optimizing suggestion slot allocation and subsequent ad auction.", "motivation": "To address ambiguity in user queries on online platforms and explore the potential of integrating sponsored content within conversational AI, enhancing ad efficacy.", "method": "The paper introduces a formal modeling approach to evaluate two methods: a joint optimization mechanism using the VCG method and a modular approach for suggestion slots and ad auctions.", "result": "The VCG mechanism achieves efficient and truthful outcomes but is complex, while the modular approach faces strategic inefficiency with an unbounded Price of Anarchy.", "conclusion": "Joint optimization via VCG is effective yet intricate, whereas modular separation compromises efficiency, highlighting trade-offs in engineering such platforms."}}
{"id": "2512.03962", "pdf": "https://arxiv.org/pdf/2512.03962", "abs": "https://arxiv.org/abs/2512.03962", "authors": ["Evan Bell", "Shijun Liang", "Ismail Alkhouri", "Saiprasad Ravishankar"], "title": "Tada-DIP: Input-adaptive Deep Image Prior for One-shot 3D Image Reconstruction", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "6 pages, 8 figures, 2025 Asilomar Conference on Signals, Systems, and Computers. Code is available at github.com/evanbell02/Tada-DIP/", "summary": "Deep Image Prior (DIP) has recently emerged as a promising one-shot neural-network based image reconstruction method. However, DIP has seen limited application to 3D image reconstruction problems. In this work, we introduce Tada-DIP, a highly effective and fully 3D DIP method for solving 3D inverse problems. By combining input-adaptation and denoising regularization, Tada-DIP produces high-quality 3D reconstructions while avoiding the overfitting phenomenon that is common in DIP. Experiments on sparse-view X-ray computed tomography reconstruction validate the effectiveness of the proposed method, demonstrating that Tada-DIP produces much better reconstructions than training-data-free baselines and achieves reconstruction performance on par with a supervised network trained using a large dataset with fully-sampled volumes.", "AI": {"tldr": "The paper introduces Tada-DIP, a 3D neural-network-based image reconstruction method achieving high-quality 3D reconstructions without overfitting, validated on sparse-view X-ray CT.", "motivation": "To address the limited application of Deep Image Prior (DIP) in 3D image reconstruction problems and enhance reconstruction quality while preventing overfitting.", "method": "Developed Tada-DIP by integrating input-adaptation and denoising regularization for highly effective 3D image reconstruction.", "result": "Tada-DIP outperformed training-data-free baselines and matched the performance of supervised models trained on large datasets using fully-sampled volumes.", "conclusion": "The proposed Tada-DIP method successfully extends the DIP framework to 3D image reconstruction, achieving competitive, high-quality results without relying on large datasets."}}
{"id": "2512.03296", "pdf": "https://arxiv.org/pdf/2512.03296", "abs": "https://arxiv.org/abs/2512.03296", "authors": ["Hsiao-Ying Lu", "Kwan-Liu Ma"], "title": "Associating Healthcare Teamwork with Patient Outcomes for Predictive Analysis", "categories": ["cs.SI", "cs.CY", "cs.LG"], "comment": null, "summary": "Cancer treatment outcomes are influenced not only by clinical and demographic factors but also by the collaboration of healthcare teams. However, prior work has largely overlooked the potential role of human collaboration in shaping patient survival. This paper presents an applied AI approach to uncovering the impact of healthcare professionals' (HCPs) collaboration-captured through electronic health record (EHR) systems-on cancer patient outcomes. We model EHR-mediated HCP interactions as networks and apply machine learning techniques to detect predictive signals of patient survival embedded in these collaborations. Our models are cross validated to ensure generalizability, and we explain the predictions by identifying key network traits associated with improved outcomes. Importantly, clinical experts and literature validate the relevance of the identified crucial collaboration traits, reinforcing their potential for real-world applications. This work contributes to a practical workflow for leveraging digital traces of collaboration and AI to assess and improve team-based healthcare. The approach is potentially transferable to other domains involving complex collaboration and offers actionable insights to support data-informed interventions in healthcare delivery.", "AI": {"tldr": "The paper uses AI and machine learning to analyze healthcare providers' collaboration captured in EHR systems to understand its impact on cancer patient survival.", "motivation": "To address gaps in understanding the role of healthcare team collaboration in influencing cancer treatment outcomes, which has been overlooked in previous studies.", "method": "The authors model healthcare provider collaborations from EHR data as networks, applying machine learning to identify predictive signals of patient survival and analyzing network characteristics linked to positive outcomes.", "result": "The study identified crucial collaboration traits that were validated by clinical expertise and literature as key to improved patient survival outcomes, showcasing predictive accuracy and generalizable models.", "conclusion": "The work demonstrates the feasibility of using AI to analyze collaboration data for improving healthcare delivery and offers actionable insights for interventions, emphasizing its transferability to other collaborative domains."}}
{"id": "2512.03312", "pdf": "https://arxiv.org/pdf/2512.03312", "abs": "https://arxiv.org/abs/2512.03312", "authors": ["Daniel D. Richman", "Jessica Karaguesian", "Carl-Mikael Suomivuori", "Ron O. Dror"], "title": "Unlocking hidden biomolecular conformational landscapes in diffusion models at inference time", "categories": ["q-bio.BM", "cs.LG"], "comment": "Project page: https://github.com/drorlab/conformix", "summary": "The function of biomolecules such as proteins depends on their ability to interconvert between a wide range of structures or \"conformations.\" Researchers have endeavored for decades to develop computational methods to predict the distribution of conformations, which is far harder to determine experimentally than a static folded structure. We present ConforMix, an inference-time algorithm that enhances sampling of conformational distributions using a combination of classifier guidance, filtering, and free energy estimation. Our approach upgrades diffusion models -- whether trained for static structure prediction or conformational generation -- to enable more efficient discovery of conformational variability without requiring prior knowledge of major degrees of freedom. ConforMix is orthogonal to improvements in model pretraining and would benefit even a hypothetical model that perfectly reproduced the Boltzmann distribution. Remarkably, when applied to a diffusion model trained for static structure prediction, ConforMix captures structural changes including domain motion, cryptic pocket flexibility, and transporter cycling, while avoiding unphysical states. Case studies of biologically critical proteins demonstrate the scalability, accuracy, and utility of this method.", "AI": {"tldr": "ConforMix enhances computational prediction of biomolecule conformational distributions via a novel algorithm combining classifier guidance, filtering, and free energy estimation.", "motivation": "Understanding biomolecular conformations is vital since their functions depend on their structural variability, which is harder to discern experimentally compared to static structures.", "method": "An inference-time algorithm called ConforMix combines classifier guidance, filtering, and free energy estimation to improve sampling in diffusion models for conformational variability.", "result": "ConforMix successfully captures structural transitions (e.g., domain motion, cryptic pocket flexibility) and avoids unphysical states when applied to models for static structure prediction, showcasing scalability and accuracy.", "conclusion": "ConforMix is a significant contribution to biomolecular studies, leveraging existing models to improve conformational variability discovery without requiring prior knowledge or perfect distributions."}}
{"id": "2512.04076", "pdf": "https://arxiv.org/pdf/2512.04076", "abs": "https://arxiv.org/abs/2512.04076", "authors": ["Alexander Mai", "Trevor Hedstrom", "George Kopanas", "Janne Kontkanen", "Falko Kuester", "Jonathan T. Barron"], "title": "Radiance Meshes for Volumetric Reconstruction", "categories": ["cs.GR", "cs.CV"], "comment": "Website: half-potato.gitlab.io/rm", "summary": "We introduce radiance meshes, a technique for representing radiance fields with constant density tetrahedral cells produced with a Delaunay tetrahedralization. Unlike a Voronoi diagram, a Delaunay tetrahedralization yields simple triangles that are natively supported by existing hardware. As such, our model is able to perform exact and fast volume rendering using both rasterization and ray-tracing. We introduce a new rasterization method that achieves faster rendering speeds than all prior radiance field representations (assuming an equivalent number of primitives and resolution) across a variety of platforms. Optimizing the positions of Delaunay vertices introduces topological discontinuities (edge flips). To solve this, we use a Zip-NeRF-style backbone which allows us to express a smoothly varying field even when the topology changes. Our rendering method exactly evaluates the volume rendering equation and enables high quality, real-time view synthesis on standard consumer hardware. Our tetrahedral meshes also lend themselves to a variety of exciting applications including fisheye lens distortion, physics-based simulation, editing, and mesh extraction.", "AI": {"tldr": "Radiance meshes utilize Delaunay tetrahedralization to represent radiance fields, allowing fast and accurate rendering using rasterization and ray-tracing.", "motivation": "Current approaches for rendering radiance fields often face limitations in speed and hardware compatibility. The paper aims to develop a representation that is computationally efficient and compatible with existing rendering infrastructure.", "method": "A novel technique involving constant density tetrahedral cells through Delaunay tetrahedralization is proposed. Alongside, a new rasterization method and a Zip-NeRF-style backbone are introduced for optimized rendering and smooth field expression.", "result": "The proposed method achieves faster rendering than previous approaches, supports high-quality, real-time view synthesis on consumer hardware, and enables additional applications, such as fisheye lens distortion and mesh extraction.", "conclusion": "This new representation efficiently evaluates the volume rendering equation, significantly improving rendering speed and adaptability for various applications."}}
{"id": "2512.04016", "pdf": "https://arxiv.org/pdf/2512.04016", "abs": "https://arxiv.org/abs/2512.04016", "authors": ["Davut Emre Tasar", "Ceren Ocal Tasar"], "title": "TARA Test-by-Adaptive-Ranks for Quantum Anomaly Detection with Conformal Prediction Guarantees", "categories": ["quant-ph", "cs.AI"], "comment": null, "summary": "Quantum key distribution (QKD) security fundamentally relies on the ability to distinguish genuine quantum correlations from classical eavesdropper simulations, yet existing certification methods lack rigorous statistical guarantees under finite-sample conditions and adversarial scenarios. We introduce TARA (Test by Adaptive Ranks), a novel framework combining conformal prediction with sequential martingale testing for quantum anomaly detection that provides distribution-free validity guarantees. TARA offers two complementary approaches. TARA k, based on Kolmogorov Smirnov calibration against local hidden variable (LHV) null distributions, achieving ROC AUC = 0.96 for quantum-classical discrimination. And TARA-m, employing betting martingales for streaming detection with anytime valid type I error control that enables real time monitoring of quantum channels. We establish theoretical guarantees proving that under (context conditional) exchangeability, conformal p-values remain uniformly distributed even for strongly contextual quantum data, confirming that quantum contextuality does not break conformal prediction validity a result with implications beyond quantum certification to any application of distribution-free methods to nonclassical data. Extensive validation on both IBM Torino (superconducting, CHSH = 2.725) and IonQ Forte Enterprise (trapped ion, CHSH = 2.716) quantum processors demonstrates cross-platform robustness, achieving 36% security margins above the classical CHSH bound of 2. Critically, our framework reveals a methodological concern affecting quantum certification more broadly: same-distribution calibration can inflate detection performance by up to 44 percentage points compared to proper cross-distribution calibration, suggesting that prior quantum certification studies using standard train test splits may have systematically overestimated adversarial robustness.", "AI": {"tldr": "The paper introduces TARA, a quantum anomaly detection framework for secure quantum key distribution, which combines conformal prediction with sequential testing, providing robust statistical guarantees.", "motivation": "Improve the security and robustness of quantum key distribution by overcoming limitations in existing methods for distinguishing quantum correlations from classical simulations under finite-sample and adversarial conditions.", "method": "The TARA framework is based on two approaches: TARA-k (Kolmogorov-Smirnov calibration for quantum-classical discrimination) and TARA-m (betting martingales for real-time anomaly detection). Both methods ensure validity under distribution-free and contextual data conditions.", "result": "TARA achieved high discrimination accuracy (ROC AUC = 0.96) and validated quantum correlations above classical bounds on IBM and IonQ quantum processors, with findings revealing cross-platform robustness and highlighting methodological limitations in prior studies.", "conclusion": "TARA provides a statistically rigorous and practical solution for quantum certification, emphasizing the importance of cross-distribution calibration and uncovering potential overestimation of robustness in prior quantum studies."}}
{"id": "2512.04031", "pdf": "https://arxiv.org/pdf/2512.04031", "abs": "https://arxiv.org/abs/2512.04031", "authors": ["Yixuan Li", "Yuhao Lu", "Yang Liu", "Liang Li", "R. Ruffini", "Di Li", "Rong-Gen Cai", "Xiaoyan Zhu", "Wenbin Lin", "Yu Wang"], "title": "Large Language Models for Limited Noisy Data: A Gravitational Wave Identification Study", "categories": ["astro-ph.IM", "astro-ph.HE", "cs.AI"], "comment": "10 pages, 5 figures", "summary": "This work investigates whether large language models (LLMs) offer advantages over traditional neural networks for astronomical data processing, in regimes with non-Gaussian, non-stationary noise and limited labeled samples. Gravitational wave observations provide an suitable test case, using only 90 LIGO events, finetuned LLMs achieve 97.4\\% accuracy for identifying signals. Further experiments show that, in contrast to traditional networks that rely on large simulated datasets, additional simulated samples do not improve LLM performance, while scaling studies reveal predictable gains with increasing model size and dataset size. These results indicate that LLMs can extract discriminative structure directly from observational data and provide an efficient assessment for gravitational wave identification. The same strategy may extend to other astronomical domains with similar noise properties, such as radio or pulsar observations.", "AI": {"tldr": "This paper demonstrates that large language models (LLMs) perform effectively in noisy astronomical data processing, using gravitational wave observations as a test case, achieving high accuracy with limited data.", "motivation": "To explore whether large language models (LLMs) can outperform traditional neural networks in analyzing astronomical data characterized by non-Gaussian noise and scarcity of labeled samples.", "method": "The study involved fine-tuning LLMs with a limited dataset of 90 LIGO gravitational wave events to classify signals, along with experiments comparing LLM scalability and reliance on simulated datasets vs. traditional methods.", "result": "LLMs achieved a 97.4% accuracy in identifying gravitational wave signals and showed predictable performance improvements with larger models and datasets, without dependence on additional simulated data.", "conclusion": "LLMs offer a robust and efficient approach to gravitational wave detection directly from observational data and have the potential for application to other complex noise-laden astronomical areas."}}
{"id": "2512.03419", "pdf": "https://arxiv.org/pdf/2512.03419", "abs": "https://arxiv.org/abs/2512.03419", "authors": ["Bharat Sharman", "Elkafi Hassini"], "title": "Comparative algorithm performance evaluation and prediction for the maximum clique problem using instance space analysis", "categories": ["cs.DS", "cs.DM", "cs.LG"], "comment": null, "summary": "The maximum clique problem, a well-known graph-based combinatorial optimization problem, has been addressed through various algorithmic approaches, though systematic analyses of the problem instances remain sparse. This study employs the instance space analysis (ISA) methodology to systematically analyze the instance space of this problem and assess & predict the performance of state-of-the-art (SOTA) algorithms, including exact, heuristic, and graph neural network (GNN)-based methods. A dataset was compiled using graph instances from TWITTER, COLLAB and IMDB-BINARY benchmarks commonly used in graph machine learning research. A set of 33 generic and 2 problem-specific polynomial-time-computable graph-based features, including several spectral properties, was employed for the ISA. A composite performance mea- sure incorporating both solution quality and algorithm runtime was utilized. The comparative analysis demonstrated that the exact algorithm Mixed Order Maximum Clique (MOMC) exhib- ited superior performance across approximately 74.7% of the instance space constituted by the compiled dataset. Gurobi & CliSAT accounted for superior performance in 13.8% and 11% of the instance space, respectively. The ISA-based algorithm performance prediction model run on 34 challenging test instances compiled from the BHOSLIB and DIMACS datasets yielded top-1 and top-2 best performing algorithm prediction accuracies of 88% and 97%, respectively.", "AI": {"tldr": "This paper applies instance space analysis (ISA) to the maximum clique problem, systematically analyzing problem instances and algorithm performance.", "motivation": "To address the sparse systematic analysis of problem instances in the maximum clique problem and predict performance of various state-of-the-art algorithms.", "method": "A dataset was created from graph instances (TWITTER, COLLAB, IMDB-BINARY), features were extracted, and ISA was applied to analyze and predict algorithm performance across the dataset.", "result": "The exact algorithm (MOMC) performed best in 74.7% of instances, with Gurobi and CliSAT performing best in the remaining instances. Performance prediction on test datasets yielded high accuracies (88% top-1 and 97% top-2).", "conclusion": "ISA effectively identifies high-performing algorithms for specific instances, showcasing its utility in optimizing algorithm selection and performance prediction for the maximum clique problem."}}
{"id": "2512.03458", "pdf": "https://arxiv.org/pdf/2512.03458", "abs": "https://arxiv.org/abs/2512.03458", "authors": ["Maryam Maghsoudi", "Mohsen Rezaeizadeh", "Shihab Shamma"], "title": "A Convolutional Framework for Mapping Imagined Auditory MEG into Listened Brain Responses", "categories": ["eess.SP", "cs.LG", "cs.SD", "eess.AS"], "comment": null, "summary": "Decoding imagined speech engages complex neural processes that are difficult to interpret due to uncertainty in timing and the limited availability of imagined-response datasets. In this study, we present a Magnetoencephalography (MEG) dataset collected from trained musicians as they imagined and listened to musical and poetic stimuli. We show that both imagined and perceived brain responses contain consistent, condition-specific information. Using a sliding-window ridge regression model, we first mapped imagined responses to listened responses at the single-subject level, but found limited generalization across subjects. At the group level, we developed an encoder-decoder convolutional neural network with a subject-specific calibration layer that produced stable and generalizable mappings. The CNN consistently outperformed the null model, yielding significantly higher correlations between predicted and true listened responses for nearly all held-out subjects. Our findings demonstrate that imagined neural activity can be transformed into perception-like responses, providing a foundation for future brain-computer interface applications involving imagined speech and music.", "AI": {"tldr": "This study uses MEG data to transform imagined brain responses into perception-like responses through subject-specific neural modeling.", "motivation": "To interpret and decode imagined speech and musical stimuli by addressing challenges of timing uncertainty and limited datasets.", "method": "Used MEG data from trained musicians, sliding-window ridge regression, and a CNN with subject-specific calibration to map imagined responses to listened ones.", "result": "The CNN model outperformed null models, showing high correlations between predicted and actual listened responses, even across subjects.", "conclusion": "Imagined neural activity can be decoded into perception-like responses, advancing brain-computer interface applications for speech and music."}}
{"id": "2512.04047", "pdf": "https://arxiv.org/pdf/2512.04047", "abs": "https://arxiv.org/abs/2512.04047", "authors": ["Nadav Kunievsky"], "title": "Polarization by Design: How Elites Could Shape Mass Preferences as AI Reduces Persuasion Costs", "categories": ["econ.GN", "cs.AI", "cs.CY"], "comment": null, "summary": "In democracies, major policy decisions typically require some form of majority or consensus, so elites must secure mass support to govern. Historically, elites could shape support only through limited instruments like schooling and mass media; advances in AI-driven persuasion sharply reduce the cost and increase the precision of shaping public opinion, making the distribution of preferences itself an object of deliberate design. We develop a dynamic model in which elites choose how much to reshape the distribution of policy preferences, subject to persuasion costs and a majority rule constraint. With a single elite, any optimal intervention tends to push society toward more polarized opinion profiles - a ``polarization pull'' - and improvements in persuasion technology accelerate this drift. When two opposed elites alternate in power, the same technology also creates incentives to park society in ``semi-lock'' regions where opinions are more cohesive and harder for a rival to overturn, so advances in persuasion can either heighten or dampen polarization depending on the environment. Taken together, cheaper persuasion technologies recast polarization as a strategic instrument of governance rather than a purely emergent social byproduct, with important implications for democratic stability as AI capabilities advance.", "AI": {"tldr": "The paper develops a dynamic model to analyze how advances in AI-driven persuasion affect public opinion, concluding that such technologies can strategically drive and modulate societal polarization, impacting democratic stability.", "motivation": "The motivation is to understand how advancements in AI-driven persuasion technologies reshape the ability of elites to influence public opinion and the implications for democratic stability, given that such technologies drastically reduce costs and increase precision.", "method": "The authors develop a dynamic model wherein elites decide how to reshape policy preferences while balancing persuasion costs and the majority rule constraint. They examine scenarios of single elite governance and two opposing elites alternating in power.", "result": "The study reveals that optimal interventions by a single elite tend to foster societal polarization, which grows faster with advancements in AI persuasion. However, under two opposing elites, technologies can stabilize opinions in semi-lock regions, either amplifying or dampening polarization.", "conclusion": "AI-driven persuasion technologies redefine societal polarization as a deliberate strategy for political control rather than an unintended consequence. This shift holds significant implications for the stability and functionality of democratic systems."}}
{"id": "2512.03462", "pdf": "https://arxiv.org/pdf/2512.03462", "abs": "https://arxiv.org/abs/2512.03462", "authors": ["Berkani Khaled", "Zeraoulia Rafik"], "title": "A Hybrid Deep Learning and Anomaly Detection Framework for Real-Time Malicious URL Classification", "categories": ["cs.CR", "cs.LG"], "comment": "14 pages,2 figures", "summary": "Malicious URLs remain a primary vector for phishing, malware, and cyberthreats. This study proposes a hybrid deep learning framework combining \\texttt{HashingVectorizer} n-gram analysis, SMOTE balancing, Isolation Forest anomaly filtering, and a lightweight neural network classifier for real-time URL classification. The multi-stage pipeline processes URLs from open-source repositories with statistical features (length, dot count, entropy), achieving $O(NL + EBdh)$ training complexity and a 20\\,ms prediction latency. Empirical evaluation yields 96.4\\% accuracy, 95.4\\% F1-score, and 97.3\\% ROC-AUC, outperforming CNN (94.8\\%) and SVM baselines with a $50\\!\\times$--$100\\!\\times$ speedup (Table~\\ref{tab:comp-complexity}). A multilingual Tkinter GUI (Arabic/English/French) enables real-time threat assessment with clipboard integration. The framework demonstrates superior scalability and resilience against obfuscated URL patterns.", "AI": {"tldr": "This paper introduces a hybrid deep learning framework for real-time malicious URL detection, achieving high accuracy and efficiency using a multi-stage pipeline.", "motivation": "Combat the persistent challenge of phishing, malware, and cyber threats enabled by malicious URLs.", "method": "The framework uses a combination of techniques: HashingVectorizer n-gram parsing, SMOTE balancing for datasets, Isolation Forest for anomaly detection, and a lightweight neural network for classification. It processes statistical features of URLs for classification and includes a real-time multilingual GUI.", "result": "Empirical evaluations report 96.4% accuracy, 95.4% F1-score, and 97.3% ROC-AUC, outperforming baselines with significant speed advantages.", "conclusion": "The proposed system offers superior accuracy, speed, scalability, and robustness in malicious URL detection, supported by a user-friendly GUI for real-time usage."}}
{"id": "2512.03521", "pdf": "https://arxiv.org/pdf/2512.03521", "abs": "https://arxiv.org/abs/2512.03521", "authors": ["Xiaosen Lyu", "Jiayu Xiong", "Yuren Chen", "Wanlong Wang", "Xiaoqing Dai", "Jing Wang"], "title": "Cross-Space Synergy: A Unified Framework for Multimodal Emotion Recognition in Conversation", "categories": ["cs.MM", "cs.LG"], "comment": "Accepted to AAAI 2026", "summary": "Multimodal Emotion Recognition in Conversation (MERC) aims to predict speakers' emotions by integrating textual, acoustic, and visual cues. Existing approaches either struggle to capture complex cross-modal interactions or experience gradient conflicts and unstable training when using deeper architectures. To address these issues, we propose Cross-Space Synergy (CSS), which couples a representation component with an optimization component. Synergistic Polynomial Fusion (SPF) serves the representation role, leveraging low-rank tensor factorization to efficiently capture high-order cross-modal interactions. Pareto Gradient Modulator (PGM) serves the optimization role, steering updates along Pareto-optimal directions across competing objectives to alleviate gradient conflicts and improve stability. Experiments show that CSS outperforms existing representative methods on IEMOCAP and MELD in both accuracy and training stability, demonstrating its effectiveness in complex multimodal scenarios.", "AI": {"tldr": "This paper proposes CSS, a novel approach to improve multimodal emotion recognition in conversations by effectively capturing cross-modal interactions and resolving training stability issues.", "motivation": "Existing multimodal emotion recognition approaches struggle with complex cross-modal interactions and suffer from gradient conflicts and training instability in deeper architectures.", "method": "The proposed CSS framework introduces Synergistic Polynomial Fusion (SPF) for efficient cross-modal representation and Pareto Gradient Modulator (PGM) to optimize multi-objective training, addressing interaction and gradient issues.", "result": "CSS outperforms baseline methods on IEMOCAP and MELD datasets in terms of both accuracy and training stability.", "conclusion": "The CSS approach successfully enhances multimodal emotion recognition, demonstrating its effectiveness in capturing complex interactions and ensuring stable model training."}}
{"id": "2512.03706", "pdf": "https://arxiv.org/pdf/2512.03706", "abs": "https://arxiv.org/abs/2512.03706", "authors": ["Vahid Nateghi", "Lara Neureither", "Selma Moqvist", "Carsten Hartmann", "Simon Olsson", "Feliks N\u00fcske"], "title": "Consistent Projection of Langevin Dynamics: Preserving Thermodynamics and Kinetics in Coarse-Grained Models", "categories": ["physics.comp-ph", "cs.LG", "math.DS"], "comment": null, "summary": "Coarse graining (CG) is an important task for efficient modeling and simulation of complex multi-scale systems, such as the conformational dynamics of biomolecules. This work presents a projection-based coarse-graining formalism for general underdamped Langevin dynamics. Following the Zwanzig projection approach, we derive a closed-form expression for the coarse grained dynamics. In addition, we show how the generator Extended Dynamic Mode Decomposition (gEDMD) method, which was developed in the context of Koopman operator methods, can be used to model the CG dynamics and evaluate its kinetic properties, such as transition timescales. Finally, we combine our approach with thermodynamic interpolation (TI), a generative approach to transform samples between thermodynamic conditions, to extend the scope of the approach across thermodynamic states without repeated numerical simulations. Using a two-dimensional model system, we demonstrate that the proposed method allows to accurately capture the thermodynamic and kinetic properties of the full-space model.", "AI": {"tldr": "The paper introduces a projection-based coarse-graining (CG) framework for modeling complex multi-scale systems and evaluates dynamics through Extended Dynamic Mode Decomposition (gEDMD). It integrates thermodynamic interpolation to generalize across thermodynamic states.", "motivation": "Efficiently model and simulate complex multi-scale systems, specifically biomolecular conformational dynamics, using coarse-graining techniques.", "method": "Derive the coarse-grained dynamics using the Zwanzig projection approach and utilize gEDMD for kinetic modeling. Combine with thermodynamic interpolation for cross-thermodynamic state adaptation.", "result": "Demonstrated accurate capture of both thermodynamic and kinetic properties of a 2D model system, validating the approach.", "conclusion": "The proposed coarse-graining framework effectively simulates complex dynamics, is adaptable across thermodynamic states, and provides insight into multi-scale system properties."}}
{"id": "2512.03974", "pdf": "https://arxiv.org/pdf/2512.03974", "abs": "https://arxiv.org/abs/2512.03974", "authors": ["Paul Fuchs", "Julija Zavadlav"], "title": "Refining Machine Learning Potentials through Thermodynamic Theory of Phase Transitions", "categories": ["physics.comp-ph", "cs.LG"], "comment": null, "summary": "Foundational Machine Learning Potentials can resolve the accuracy and transferability limitations of classical force fields. They enable microscopic insights into material behavior through Molecular Dynamics simulations, which can crucially expedite material design and discovery. However, insufficiently broad and systematically biased reference data affect the predictive quality of the learned models. Often, these models exhibit significant deviations from experimentally observed phase transition temperatures, in the order of several hundred kelvins. Thus, fine-tuning is necessary to achieve adequate accuracy in many practical problems. This work proposes a fine-tuning strategy via top-down learning, directly correcting the wrongly predicted transition temperatures to match the experimental reference data. Our approach leverages the Differentiable Trajectory Reweighting algorithm to minimize the free energy differences between phases at the experimental target pressures and temperatures. We demonstrate that our approach can accurately correct the phase diagram of pure Titanium in a pressure range of up to 5 GPa, matching the experimental reference within tenths of kelvins and improving the liquid-state diffusion constant. Our approach is model-agnostic, applicable to multi-component systems with solid-solid and solid-liquid transitions, and compliant with top-down training on other experimental properties. Therefore, our approach can serve as an essential step towards highly accurate application-specific and foundational machine learning potentials.", "AI": {"tldr": "The paper proposes a machine learning fine-tuning strategy using Differentiable Trajectory Reweighting to correct inaccuracies in phase transition predictions, achieving high agreement with experimental data.", "motivation": "To address accuracy and transferability limitations in machine learning potentials caused by insufficient and biased reference data, and to correct significant deviations in predicted phase transition temperatures.", "method": "A fine-tuning method using top-down learning and Differentiable Trajectory Reweighting to match predicted transition temperatures to experimental reference data by minimizing phase free energy differences.", "result": "The proposed approach accurately corrected the phase diagram of pure Titanium across a pressure range (up to 5 GPa), achieving deviations within tenths of kelvins and enhancing liquid-state diffusion predictions.", "conclusion": "The method is model-agnostic, adaptable to multi-component systems with various transitions, and provides groundwork for more accurate application-specific machine learning potentials and foundational materials science insights."}}
{"id": "2512.04058", "pdf": "https://arxiv.org/pdf/2512.04058", "abs": "https://arxiv.org/abs/2512.04058", "authors": ["Shashaank Khanna", "Matthew Pusey", "Roger Colbeck"], "title": "Closing the problem of which causal structures of up to six total nodes have a classical-quantum gap", "categories": ["quant-ph", "cs.LG", "math.ST"], "comment": "5 pages, 3 figures, 1 table", "summary": "The discovery of Bell that there exist quantum correlations that cannot be reproduced classically is one of the most important in the foundations of quantum mechanics, as well as having practical implications. Bell's result was originally proven in a simple bipartite causal structure, but analogous results have also been shown in further causal structures. Here we study the only causal structure with six or fewer nodes in which the question of whether or not there exist quantum correlations that cannot be achieved classically was open. In this causal structure we show that such quantum correlations exist using a method that involves imposing additional restrictions on the correlations. This hence completes the picture of which causal structures of up to six nodes support non-classical quantum correlations. We also provide further illustrations of our method using other causal structures.", "AI": {"tldr": "This paper examines a unique causal structure with six or fewer nodes to confirm the existence of non-classical quantum correlations, completing the study of such cases for small causal structures.", "motivation": "To address the open question of whether non-classical quantum correlations exist in a specific causal structure with six or fewer nodes, completing the analysis for small causal structures.", "method": "The authors used a methodology that imposes additional restrictions on the correlations to identify non-classical quantum correlations within the specified causal structure.", "result": "They demonstrated the existence of non-classical quantum correlations in the only remaining causal structure with six or fewer nodes, confirming it supports such correlations.", "conclusion": "This study finalizes the understanding of which causal structures with six or fewer nodes support non-classical quantum correlations and provides additional examples demonstrating the methodology."}}
